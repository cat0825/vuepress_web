{"/Users/qianyuhe/Desktop/my-project/docs/README.md":"1747799918516.2344"}"/Users/qianyuhe/Desktop/my-project/docs/notes_bak/Welcome🎉.md":"1747369031491.7102","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/关于我.md":"1747797693163.086","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/导航.md":"1747744317964.4138","/Users/qianyuhe/Desktop/my-project/docs/preview/custom-component.example.md":"1747364165147.5369","/Users/qianyuhe/Desktop/my-project/docs/preview/markdown.md":"1747364165147.7114","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/c++ primer plus/using和namespace.md":"1747744317933.6335","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/c++ primer plus/关于过程编程,面向对象编程和泛型编程.md":"1747744317933.7551","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/c++ primer plus/函数声明.md":"1747744317933.8684","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/c++ primer plus/初始化.md":"1747744317933.9705","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/c++ primer plus/导航.md":"1747744317934.1685","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/c++ primer plus/局部和全局的命名空间引入.md":"1747744317934.3103","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/demo/README.md":"1747364165111.61","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/demo/bar.md":"1747364165111.7488","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/demo/foo.md":"1747364165111.8845","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/leetcode/导航.md":"1747744317934.5461","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/thino/2024-12-25.md":"1747364165113.2944","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/thino/导航.md":"1747744317934.6814","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/transformer/什么是transformer.md":"1747364165113.585","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/transformer/导航.md":"1747744317934.8057","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/导航.md":"1747744770879.5461","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/机器学习/关于单变量线性回归的思考.md":"1747744317964.8354","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/机器学习/关于逻辑回归中的代价函数.md":"1747364165146.813","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/机器学习/关于逻辑回归的思考.md":"1747364165146.9824","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/机器学习/导航.md":"1747744317965.0703","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/机器学习/引言.md":"1747364165147.175","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/毕业设计/学习资料.md":"1747364165147.3743","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/毕业设计/导航.md":"1747744317965.313","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/leetcode/链表/分隔链表.md":"1747364165112.6897","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/leetcode/链表/合并零之间的节点.md":"1747364165112.8496","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Attention注意力机制/Attention机制详解与应用.md":"1747364165113.8562","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Attention注意力机制/DCA：长文本处理的新突破（Dual Chunk Attention）.md":"1747364165114.0793","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Attention注意力机制/KV Cache技术详解：优化Transformer自回归生成效率.md":"1747364165114.3022","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Attention注意力机制/Transformer中的Attention详解与应用指南.md":"1747364165114.5244","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Attention注意力机制/【长上下文模型优化】基于Shifted Sparse Attention的创新方法.md":"1747364165114.73","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Attention注意力机制/优化Attention计算复杂度的技术探讨.md":"1747364165114.935","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Attention注意力机制/深度学习中的注意力机制优化：从MHA到MLA.md":"1747364165115.1514","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Common Models常见模型/发展历史.md":"1747744317939.0103","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/MCP/介绍.md":"1747744317940.0334","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/FFN、Add & LN 的作用与应用/Transformer核心模块解析：FFN、Add & LN 的作用与应用.md":"1747744317939.2173","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/FFN、Add & LN 的作用与应用/深度学习中的Layer Norm设计：Post-Norm、Pre-Norm与Sandwich-Norm比较.md":"1747744317939.3894","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/FFN、Add & LN 的作用与应用/激活函数与FFN结构优化：SwiGLU、GeGLU及其应用解析.md":"1747744317939.672","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/FFN、Add & LN 的作用与应用/激活函数详解与比较：从Sigmoid到Swish.md":"1747744317939.8381","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Pre-training 预训练/推理耗时.md":"1747744317942.164","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Pre-training 预训练/数据多样性与模型优化探索.md":"1747744317942.326","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Pre-training 预训练/数据清洗.md":"1747744317942.5286","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Pre-training 预训练/数据爬取.md":"1747744317942.7007","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Pre-training 预训练/数据配比与训练顺序优化指南.md":"1747744317942.9233","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Pre-training 预训练/模型打分与数据去重.md":"1747744317943.1267","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Pre-training 预训练/深度学习中的显存优化与梯度处理方法.md":"1747744317943.278","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Pre-training 预训练/混合精度训练.md":"1747744317943.4312","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Pre-training 预训练/继续预训练.md":"1747744317943.579","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Pre-training 预训练/训练容灾及训练监控.md":"1747744317943.729","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Pre-training 预训练/预训练定义以及数据来源.md":"1747744317943.8936","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Pre-training 预训练/预训练评估.md":"1747744317944.025","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/Actor-Critic算法.md":"1747364165124.6577","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/PPO算法.md":"1747364165128.0623","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/PPO训练的trick和问题.md":"1747744317947.9775","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/RL在NLP场景下的拓展.md":"1747364165130.311","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/SARSA-λ与Q-learning对比.md":"1747744317949.4314","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/SARSA算法.md":"1747364165130.7485","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/价值迭代算法.md":"1747364165130.949","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/强化学习分类.md":"1747744317951.138","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/强化学习的独特性.md":"1747364165132.9763","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/强化学习问题,流程.md":"1747744317951.3323","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/时序差分算法.md":"1747364165133.2825","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/深度Q网络.md":"1747364165133.4536","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/策略梯度算法.md":"1747364165133.6257","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/策略迭代算法.md":"1747364165133.8047","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/蒙特卡洛方法.md":"1747364165133.9558","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/贝尔曼方程.md":"1747364165134.1165","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/马尔可夫决策过程.md":"1747744317951.4949","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Structure & Decoding Policy 结构和解码策略/大模型结构与混合专家（LLM & MoE）解析.md":"1747744317951.8748","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Structure & Decoding Policy 结构和解码策略/深度解析语言模型采样方法：Top-K、Top-P、Temperature及综合策略.md":"1747744317952.0427","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Structure & Decoding Policy 结构和解码策略/解码采样策略：Greedy Search与Beam Search的实现与优化.md":"1747744317952.2102","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/大模型应用/Prompt Tech 提示技术.md":"1747744317955.951","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Positional Encoding位置编码/NTK插值方法解析与优化：从NTK-aware到NTK-by-parts.md":"1747744317940.2546","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Positional Encoding位置编码/YaRN方法解析：扩展RoPE嵌入与注意力优化的实践.md":"1747744317940.4177","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Positional Encoding位置编码/介绍.md":"1747744317940.569","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Positional Encoding位置编码/位置内插法扩展语言模型上下文长度.md":"1747744317940.722","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Positional Encoding位置编码/数字输入优化与外推方法解析.md":"1747744317940.8691","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Positional Encoding位置编码/旋转位置编码与ALiBi：深度学习中的位置嵌入优化.md":"1747744317941.03","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/分词/BBPE：字节级别的BPE分词技术解析与应用.md":"1747744317952.4236","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/分词/WordPiece分词算法解析与实践.md":"1747364165135.1335","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/分词/使用Byte Pair Encoding (BPE)优化子词分词的技巧与实践.md":"1747364165135.2925","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/分词/使用Unigram语言模型（ULM）优化分词算法：核心思路与实践.md":"1747744317952.7441","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/分词/分词算法的比较.md":"1747364165135.6328","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/分词/常用分词库.md":"1747364165135.8054","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/模型压缩/Knowledge Distillation 知识蒸馏.md":"1747744317958.9983","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/模型压缩/Low-Rank Factorization 低秩分解.md":"1747364165141.8926","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/模型压缩/介绍.md":"1747744317959.628","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/模型压缩/模型剪枝.md":"1747744317960.0828","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/模型压缩/模型量化.md":"1747744317960.531","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/训练推理优化/PageAttention原理.md":"1747744317961.7935","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/训练推理优化/大模型的packing技巧.md":"1747744317962.1216","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/词嵌入/FastText.md":"1747364165145.8967","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/词嵌入/Word2Vec.md":"1747364165146.1003","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/词嵌入/oneHot.md":"1747364165146.305","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/词嵌入/介绍.md":"1747364165146.4934","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/leetcode/滑动窗口/定长滑动/半径为k的子数组平均值.md":"1747364165112.0544","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/leetcode/滑动窗口/定长滑动/大小为k平均值大于等于阈值的子数组个数.md":"1747376284488.3164","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/leetcode/滑动窗口/定长滑动/定长子串中元音的最大数目.md":"1747364165112.4954","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Common Models常见模型/BERT及其变体/BART.md":"1747744317935.0183","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Common Models常见模型/BERT及其变体/RoBERTa.md":"1747744317935.1284","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Common Models常见模型/BERT及其变体/T5.md":"1747744317935.2354","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Common Models常见模型/BERT及其变体/介绍.md":"1747744317935.3418","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Common Models常见模型/DeepSeek系列/DeepSeek-R1.md":"1747744317935.5535","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Common Models常见模型/DeepSeek系列/DeepSeek-V3.md":"1747744317935.7754","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Common Models常见模型/DeepSeek系列/Deepseek-V1.md":"1747744317935.884","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Common Models常见模型/DeepSeek系列/Deepseek-math.md":"1747744317935.9924","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Common Models常见模型/GLM系列/GLM1.md":"1747744317936.1423","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Common Models常见模型/GLM系列/GLM3.md":"1747744317936.3557","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Common Models常见模型/GLM系列/GLM4.md":"1747744317936.4639","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Common Models常见模型/GPT系列/GPT-1.md":"1747744317936.7957","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Common Models常见模型/GPT系列/GPT-3.md":"1747744317937.0913","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Common Models常见模型/LLama系列/LLaMA1.md":"1747744317937.2773","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Common Models常见模型/LLama系列/LLama 3.md":"1747744317937.5085","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Common Models常见模型/MOE系列/GShard.md":"1747744317937.668","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Common Models常见模型/MOE系列/Mistral.md":"1747744317937.8745","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Common Models常见模型/MOE系列/Switch Transformer.md":"1747744317937.9976","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Common Models常见模型/PLaM系列/PLaM.md":"1747744317938.1738","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Common Models常见模型/Qwen系列/Qwen1.md":"1747744317938.6072","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Common Models常见模型/Qwen系列/Qwen2.5.md":"1747744317938.7615","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Pre-training 预训练/预训练过程/训练Tokenizer.md":"1747744317944.489","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Pre-training 预训练/预训练过程/预训练的Scaling Law.md":"1747744317944.6428","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Pre-training 预训练/预训练过程/预训练策略.md":"1747744317944.794","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Pre-training 预训练/预训练过程/高效深度学习模型训练框架选择与优化指南.md":"1747744317944.9573","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/DPO直接偏好优化/DPO介绍及RLHF-PPO缺点.md":"1747744317945.188","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/DPO直接偏好优化/DPO公式推导.md":"1747364165125.0247","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/DPO直接偏好优化/人类建模偏好角度理解DPO.md":"1747364165125.177","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/DPO直接偏好优化/对比学习角度理解DPO.md":"1747364165125.3489","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/DPO直接偏好优化/深度偏好优化（DPO）损失函数解析与代码示例.md":"1747744317945.3977","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/LoRA及其变体/AdaLoRA.md":"1747744317945.559","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/LoRA及其变体/DoRA.md":"1747364165125.8547","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/LoRA及其变体/LoRA+.md":"1747744317945.9065","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/LoRA及其变体/LoRA-FA.md":"1747744317946.0562","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/LoRA及其变体/LoRA.md":"1747744317946.2407","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/LoRA及其变体/QLoRA.md":"1747744317946.3909","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/LoRA及其变体/VeRA.md":"1747744317946.5698","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/LoRA及其变体/X-LoRA.md":"1747744317946.7432","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/LoRA及其变体/参考文献.md":"1747364165126.9824","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/PEFT参数高效微调/LLaMA-Adapter.md":"1747744317947.0303","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/PEFT参数高效微调/P-Tuning.md":"1747744317947.3535","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/PEFT参数高效微调/Prefix-Tuning.md":"1747744317947.6516","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/PEFT参数高效微调/Prompt Tuning.md":"1747744317947.7842","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/PEFT参数高效微调/介绍.md":"1747364165127.8604","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/Actor-Model.md":"1747744317948.1472","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/Instruct-GPT.md":"1747744317948.322","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/RLHF流程.md":"1747364165128.804","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/RLHF研究方法及研究总结.md":"1747744317948.4895","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/RL在NLP场景下的拓展.md":"1747744317948.6501","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/Reference-Model.md":"1747744317948.8167","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/Reward-Model.md":"1747744317948.9656","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/critic-model.md":"1747744317949.1287","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/在线与离线RLHF的比较与应用.md":"1747364165129.9736","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/深入理解Prompt到Response的MDP模型分析.md":"1747364165130.1445","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/优化DPO方向的算法/DPOP.md":"1747364165131.1323","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/优化DPO方向的算法/Self-Reward.md":"1747744317949.6997","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/优化DPO方向的算法/TDPO.md":"1747744317949.8584","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/优化PPO方向的算法/DAPO.md":"1747744317950.0723","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/优化PPO方向的算法/GRPO.md":"1747744317950.3892","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/优化PPO方向的算法/REINFORCE算法改进：RLOO与REINFORCE++.md":"1747744317950.5503","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/优化PPO方向的算法/ReMax-improvement.md":"1747744317950.7468","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/优化PPO方向的算法/ReMax.md":"1747744317950.949","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/优化PPO方向的算法/VAPO.md":"1747364165132.638","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/后训练/SFT监督微调/监督微调与预训练的区别.md":"1747364165137.4246","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/大模型应用/LLM-based Agent 基于大模型的智能体/Agent评估框架汇总.md":"1747744317953.8242","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/大模型应用/LLM-based Agent 基于大模型的智能体/基于大模型的智能体原理.md":"1747744317954.3164","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/大模型应用/LLM-based Agent 基于大模型的智能体/定义以及历史发展.md":"1747744317954.5515","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/大模型应用/LLM-based Agent 基于大模型的智能体/智能体的分类.md":"1747744317954.8093","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/大模型应用/LLM-based Agent 基于大模型的智能体/智能体的框架和应用.md":"1747744317955.0986","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/大模型应用/LLM-based Agent 基于大模型的智能体/智能体系统分类.md":"1747744317955.4985","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/大模型应用/RAG检索增强生成/RAG优化.md":"1747744317956.372","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/大模型应用/RAG检索增强生成/RAG优化中查询索引阶段.md":"1747364165139.6038","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/大模型应用/RAG检索增强生成/RAG方向.md":"1747364165139.8022","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/大模型应用/RAG检索增强生成/RAG流程和分类.md":"1747744317956.8364","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/大模型应用/RAG检索增强生成/RAG评估.md":"1747364165140.301","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/大模型应用/RAG检索增强生成/固定长度分块.md":"1747744317957.1865","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/大模型应用/RAG检索增强生成/基于大模型的分块.md":"1747744317957.569","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/大模型应用/RAG检索增强生成/基于文档结构分块.md":"1747744317957.8723","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/大模型应用/RAG检索增强生成/基于语义分块.md":"1747744317958.142","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/大模型应用/RAG检索增强生成/常见索引优化算法实现.md":"1747364165141.298","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Positional Encoding位置编码/相对位置编码/DeBERTa的相对位置编码与绝对位置编码解析.md":"1747744317941.2505","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Positional Encoding位置编码/相对位置编码/T5模型与相对位置编码优化解析.md":"1747744317941.412","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Positional Encoding位置编码/相对位置编码/相对位置编码与XLNet位置编码详解 深入理解Transformer机制.md":"1747744317941.5847","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Positional Encoding位置编码/绝对位置编码/BERT与RNN位置编码的对比与应用.md":"1747744317941.8137","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Positional Encoding位置编码/绝对位置编码/Transformer绝对位置编码详解与改进分析.md":"1747744317941.9758","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/训练推理优化/FlashAttention/FlashAttention Forword流程.md":"1747744317960.9224","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/训练推理优化/FlashAttention/介绍.md":"1747364165142.811","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/训练推理优化/FlashAttention/标准Attention与Safe softmax.md":"1747744317961.1628","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/训练推理优化/FlashAttention/计算与内存限制.md":"1747744317961.4807","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/训练推理优化/推理框架/HuggingFace TGI.md":"1747744317962.405","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/训练推理优化/推理框架/vLLM.md":"1747744317962.6711","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/训练推理优化/推理耗时及优化/推理耗时.md":"1747364165143.9805","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/训练推理优化/推理耗时及优化/首Token时延优化.md":"1747744317962.9421","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/训练推理优化/训练推理显存占用分析/显存优化与推理显存分析.md":"1747364165144.312","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/训练推理优化/训练推理显存占用分析/模型显存总体分析.md":"1747364165144.4678","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/训练推理优化/训练推理显存占用分析/训练阶段的显存分析.md":"1747364165144.6208","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/训练推理优化/训练框架/Accelerate.md":"1747364165144.7888","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/训练推理优化/训练框架/DeepSpeed.md":"1747744317963.2192","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/训练推理优化/训练框架/Megatron-LM.md":"1747744317963.6472","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/训练推理优化/训练框架/Megatron和DeepSpeed后端实现的区别.md":"1747744317963.9314","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/训练推理优化/训练框架/X-ray.md":"1747744317964.239","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/后训练/SFT监督微调/SFT数据及处理/开源数据集.md":"1747364165135.979","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/后训练/SFT监督微调/SFT数据及处理/数据多样性探索.md":"1747364165136.137","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/后训练/SFT监督微调/SFT数据及处理/数据生产合成与质量过滤.md":"1747744317953.0674","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/后训练/SFT监督微调/SFT数据及处理/数据飞轮在SFT中的应用与优化.md":"1747744317953.2473","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/后训练/SFT监督微调/STF训练/多轮对话专项提升.md":"1747744317953.4172","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/后训练/SFT监督微调/STF训练/训练启动脚本.md":"1747364165136.945","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/后训练/SFT监督微调/STF训练/训练技巧和训练策略.md":"1747744317953.5967","/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/后训练/SFT监督微调/STF训练/训练框架及参数设置.md":"1747364165137.2644"}