{"content":"<h2 id=\"_1-问题背景\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#_1-问题背景\"><span>1. <strong>问题背景</strong></span></a></h2>\n<p>逻辑回归是用来解决分类问题的，比如判断一封邮件是垃圾邮件还是正常邮件，或者预测一个人是否患有某种疾病。它的特点是输出是一个概率值（0到1之间），然后根据概率值做出分类决策。</p>\n<hr>\n<h2 id=\"_2-逻辑回归的核心思想\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#_2-逻辑回归的核心思想\"><span>2. <strong>逻辑回归的核心思想</strong></span></a></h2>\n<p>逻辑回归的核心思想是：</p>\n<ul>\n<li>先用一条直线（或超平面）对数据进行划分。</li>\n<li>然后通过一个特殊的函数（S型函数）将直线输出的值转换成概率。</li>\n<li>最后根据概率值判断类别。</li>\n</ul>\n<hr>\n<h2 id=\"_3-逻辑回归的全流程\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#_3-逻辑回归的全流程\"><span>3. <strong>逻辑回归的全流程</strong></span></a></h2>\n<h3 id=\"第一步-输入数据\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#第一步-输入数据\"><span><strong>第一步：输入数据</strong></span></a></h3>\n<ul>\n<li>假设我们有一组数据，比如病人的年龄、血压、血糖等特征，以及是否患病的标签（0或1）。</li>\n<li>我们的目标是通过这些特征预测一个新病人是否患病。</li>\n</ul>\n<h3 id=\"第二步-线性回归部分\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#第二步-线性回归部分\"><span><strong>第二步：线性回归部分</strong></span></a></h3>\n<ul>\n<li>逻辑回归首先像线性回归一样，计算一个线性方程：<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>z</mi><mo>=</mo><msub><mi>w</mi><mn>1</mn></msub><mo>⋅</mo><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>w</mi><mn>2</mn></msub><mo>⋅</mo><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><mo>⋯</mo><mo>+</mo><msub><mi>w</mi><mi>n</mi></msub><mo>⋅</mo><msub><mi>x</mi><mi>n</mi></msub><mo>+</mo><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">z = w_1 \\cdot x_1 + w_2 \\cdot x_2 + \\dots + w_n \\cdot x_n + b\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.5945em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.5945em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6667em;vertical-align:-0.0833em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.5945em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">b</span></span></span></span></span></p>\n其中：\n<ul>\n<li>( x_1, x_2, \\dots, x_n ) 是输入特征（比如年龄、血压等）。</li>\n<li>( w_1, w_2, \\dots, w_n ) 是权重（表示每个特征的重要性）。</li>\n<li>( b ) 是偏置项（可以理解为一个调整值）。</li>\n<li>( z ) 是线性回归的输出。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"第三步-通过s型函数转换概率\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#第三步-通过s型函数转换概率\"><span><strong>第三步：通过S型函数转换概率</strong></span></a></h3>\n<ul>\n<li>线性回归的输出 ( z ) 是一个任意实数（可能是负数或很大的数），但我们想要的是一个概率值（0到1之间）。</li>\n<li>于是，我们用S型函数（也叫Sigmoid函数）将 ( z ) 转换成概率：<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>σ</mi><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>z</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\sigma(z) = \\frac{1}{1 + e^{-z}}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.0908em;vertical-align:-0.7693em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3214em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6973em;\"><span style=\"top:-2.989em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.04398em;\">z</span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7693em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n这个函数的输出值在0到1之间，可以理解为“属于正类的概率”。</li>\n</ul>\n<h3 id=\"第四步-设定阈值进行分类\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#第四步-设定阈值进行分类\"><span><strong>第四步：设定阈值进行分类</strong></span></a></h3>\n<ul>\n<li>得到概率值后，我们需要设定一个阈值（比如0.5）来判断类别：\n<ul>\n<li>如果概率 ≥ 0.5，预测为正类（比如患病）。</li>\n<li>如果概率 &lt; 0.5，预测为负类（比如健康）。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"第五步-训练模型\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#第五步-训练模型\"><span><strong>第五步：训练模型</strong></span></a></h3>\n<ul>\n<li>逻辑回归的目标是找到一组权重 ( w ) 和偏置 ( b )，使得模型的预测结果尽可能接近真实标签。</li>\n<li>训练过程是通过“最大似然估计”或“梯度下降法”来不断调整 ( w ) 和 ( b )，使得模型的预测误差最小。</li>\n</ul>\n<h3 id=\"第六步-预测新数据\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#第六步-预测新数据\"><span><strong>第六步：预测新数据</strong></span></a></h3>\n<ul>\n<li>当模型训练好后，我们可以用它对新的数据进行预测。比如输入一个新病人的年龄、血压等特征，模型会输出一个概率值，告诉我们这个病人患病的可能性有多大。</li>\n</ul>\n<hr>\n<h2 id=\"_4-举个例子\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#_4-举个例子\"><span>4. <strong>举个例子</strong></span></a></h2>\n<p>假设我们用逻辑回归预测一个人是否会购买某款产品：</p>\n<ul>\n<li>输入特征：年龄、收入、浏览时长。</li>\n<li>模型计算：<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>z</mi><mo>=</mo><mn>0.1</mn><mo>⋅</mo><mtext>年龄</mtext><mo>+</mo><mn>0.5</mn><mo>⋅</mo><mtext>收入</mtext><mo>+</mo><mn>0.3</mn><mo>⋅</mo><mtext>浏览时长</mtext><mo>−</mo><mn>5</mn></mrow><annotation encoding=\"application/x-tex\">z = 0.1 \\cdot \\text{年龄} + 0.5 \\cdot \\text{收入} + 0.3 \\cdot \\text{浏览时长} - 5\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0.1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">年龄</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0.5</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">收入</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0.3</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">浏览时长</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">5</span></span></span></span></span></p>\n</li>\n<li>通过S型函数转换：<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>σ</mi><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>z</mi></mrow></msup></mrow></mfrac><mo>=</mo><mn>0.7</mn></mrow><annotation encoding=\"application/x-tex\">\\sigma(z) = \\frac{1}{1 + e^{-z}} = 0.7\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.0908em;vertical-align:-0.7693em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3214em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6973em;\"><span style=\"top:-2.989em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.04398em;\">z</span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7693em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0.7</span></span></span></span></span></p>\n</li>\n<li>因为0.7 &gt; 0.5，所以预测这个人会购买产品。</li>\n</ul>\n<hr>\n<h2 id=\"_5-总结\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#_5-总结\"><span>5. <strong>总结</strong></span></a></h2>\n<p>逻辑回归的全流程可以简单概括为：</p>\n<ol>\n<li>输入特征数据。</li>\n<li>用线性方程计算得分 ( z )。</li>\n<li>用S型函数将 ( z ) 转换成概率。</li>\n<li>根据概率值和阈值进行分类。</li>\n<li>训练模型，调整参数，使预测更准确。</li>\n<li>用训练好的模型预测新数据。</li>\n</ol>\n<p>逻辑回归虽然简单，但在很多实际问题中都非常有效，是机器学习的经典算法之一！</p>\n","env":{"base":"/","filePath":"/Users/qianyuhe/Desktop/my-project/docs/notes_bak/机器学习/关于逻辑回归的思考.md","filePathRelative":"notes_bak/机器学习/关于逻辑回归的思考.md","frontmatter":{"dg-publish":true,"dg-permalink":"/机器学习/逻辑回归","permalink":"/机器学习/逻辑回归/","dgPassFrontmatter":true,"noteIcon":null,"created":"2025-01-05T02:20:18.000Z","updated":"2025-01-05T02:22:45.248Z","title":"关于逻辑回归的思考","createTime":"2025/05/13 17:33:52"},"sfcBlocks":{"template":{"type":"template","content":"<template><h2 id=\"_1-问题背景\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#_1-问题背景\"><span>1. <strong>问题背景</strong></span></a></h2>\n<p>逻辑回归是用来解决分类问题的，比如判断一封邮件是垃圾邮件还是正常邮件，或者预测一个人是否患有某种疾病。它的特点是输出是一个概率值（0到1之间），然后根据概率值做出分类决策。</p>\n<hr>\n<h2 id=\"_2-逻辑回归的核心思想\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#_2-逻辑回归的核心思想\"><span>2. <strong>逻辑回归的核心思想</strong></span></a></h2>\n<p>逻辑回归的核心思想是：</p>\n<ul>\n<li>先用一条直线（或超平面）对数据进行划分。</li>\n<li>然后通过一个特殊的函数（S型函数）将直线输出的值转换成概率。</li>\n<li>最后根据概率值判断类别。</li>\n</ul>\n<hr>\n<h2 id=\"_3-逻辑回归的全流程\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#_3-逻辑回归的全流程\"><span>3. <strong>逻辑回归的全流程</strong></span></a></h2>\n<h3 id=\"第一步-输入数据\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#第一步-输入数据\"><span><strong>第一步：输入数据</strong></span></a></h3>\n<ul>\n<li>假设我们有一组数据，比如病人的年龄、血压、血糖等特征，以及是否患病的标签（0或1）。</li>\n<li>我们的目标是通过这些特征预测一个新病人是否患病。</li>\n</ul>\n<h3 id=\"第二步-线性回归部分\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#第二步-线性回归部分\"><span><strong>第二步：线性回归部分</strong></span></a></h3>\n<ul>\n<li>逻辑回归首先像线性回归一样，计算一个线性方程：<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>z</mi><mo>=</mo><msub><mi>w</mi><mn>1</mn></msub><mo>⋅</mo><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>w</mi><mn>2</mn></msub><mo>⋅</mo><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><mo>⋯</mo><mo>+</mo><msub><mi>w</mi><mi>n</mi></msub><mo>⋅</mo><msub><mi>x</mi><mi>n</mi></msub><mo>+</mo><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">z = w_1 \\cdot x_1 + w_2 \\cdot x_2 + \\dots + w_n \\cdot x_n + b\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.5945em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.5945em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6667em;vertical-align:-0.0833em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.5945em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">b</span></span></span></span></span></p>\n其中：\n<ul>\n<li>( x_1, x_2, \\dots, x_n ) 是输入特征（比如年龄、血压等）。</li>\n<li>( w_1, w_2, \\dots, w_n ) 是权重（表示每个特征的重要性）。</li>\n<li>( b ) 是偏置项（可以理解为一个调整值）。</li>\n<li>( z ) 是线性回归的输出。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"第三步-通过s型函数转换概率\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#第三步-通过s型函数转换概率\"><span><strong>第三步：通过S型函数转换概率</strong></span></a></h3>\n<ul>\n<li>线性回归的输出 ( z ) 是一个任意实数（可能是负数或很大的数），但我们想要的是一个概率值（0到1之间）。</li>\n<li>于是，我们用S型函数（也叫Sigmoid函数）将 ( z ) 转换成概率：<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>σ</mi><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>z</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\sigma(z) = \\frac{1}{1 + e^{-z}}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.0908em;vertical-align:-0.7693em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3214em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6973em;\"><span style=\"top:-2.989em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.04398em;\">z</span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7693em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n这个函数的输出值在0到1之间，可以理解为“属于正类的概率”。</li>\n</ul>\n<h3 id=\"第四步-设定阈值进行分类\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#第四步-设定阈值进行分类\"><span><strong>第四步：设定阈值进行分类</strong></span></a></h3>\n<ul>\n<li>得到概率值后，我们需要设定一个阈值（比如0.5）来判断类别：\n<ul>\n<li>如果概率 ≥ 0.5，预测为正类（比如患病）。</li>\n<li>如果概率 &lt; 0.5，预测为负类（比如健康）。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"第五步-训练模型\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#第五步-训练模型\"><span><strong>第五步：训练模型</strong></span></a></h3>\n<ul>\n<li>逻辑回归的目标是找到一组权重 ( w ) 和偏置 ( b )，使得模型的预测结果尽可能接近真实标签。</li>\n<li>训练过程是通过“最大似然估计”或“梯度下降法”来不断调整 ( w ) 和 ( b )，使得模型的预测误差最小。</li>\n</ul>\n<h3 id=\"第六步-预测新数据\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#第六步-预测新数据\"><span><strong>第六步：预测新数据</strong></span></a></h3>\n<ul>\n<li>当模型训练好后，我们可以用它对新的数据进行预测。比如输入一个新病人的年龄、血压等特征，模型会输出一个概率值，告诉我们这个病人患病的可能性有多大。</li>\n</ul>\n<hr>\n<h2 id=\"_4-举个例子\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#_4-举个例子\"><span>4. <strong>举个例子</strong></span></a></h2>\n<p>假设我们用逻辑回归预测一个人是否会购买某款产品：</p>\n<ul>\n<li>输入特征：年龄、收入、浏览时长。</li>\n<li>模型计算：<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>z</mi><mo>=</mo><mn>0.1</mn><mo>⋅</mo><mtext>年龄</mtext><mo>+</mo><mn>0.5</mn><mo>⋅</mo><mtext>收入</mtext><mo>+</mo><mn>0.3</mn><mo>⋅</mo><mtext>浏览时长</mtext><mo>−</mo><mn>5</mn></mrow><annotation encoding=\"application/x-tex\">z = 0.1 \\cdot \\text{年龄} + 0.5 \\cdot \\text{收入} + 0.3 \\cdot \\text{浏览时长} - 5\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0.1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">年龄</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0.5</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">收入</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0.3</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">浏览时长</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">5</span></span></span></span></span></p>\n</li>\n<li>通过S型函数转换：<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>σ</mi><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>z</mi></mrow></msup></mrow></mfrac><mo>=</mo><mn>0.7</mn></mrow><annotation encoding=\"application/x-tex\">\\sigma(z) = \\frac{1}{1 + e^{-z}} = 0.7\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.0908em;vertical-align:-0.7693em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3214em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6973em;\"><span style=\"top:-2.989em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.04398em;\">z</span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7693em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0.7</span></span></span></span></span></p>\n</li>\n<li>因为0.7 &gt; 0.5，所以预测这个人会购买产品。</li>\n</ul>\n<hr>\n<h2 id=\"_5-总结\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#_5-总结\"><span>5. <strong>总结</strong></span></a></h2>\n<p>逻辑回归的全流程可以简单概括为：</p>\n<ol>\n<li>输入特征数据。</li>\n<li>用线性方程计算得分 ( z )。</li>\n<li>用S型函数将 ( z ) 转换成概率。</li>\n<li>根据概率值和阈值进行分类。</li>\n<li>训练模型，调整参数，使预测更准确。</li>\n<li>用训练好的模型预测新数据。</li>\n</ol>\n<p>逻辑回归虽然简单，但在很多实际问题中都非常有效，是机器学习的经典算法之一！</p>\n</template>","contentStripped":"<h2 id=\"_1-问题背景\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#_1-问题背景\"><span>1. <strong>问题背景</strong></span></a></h2>\n<p>逻辑回归是用来解决分类问题的，比如判断一封邮件是垃圾邮件还是正常邮件，或者预测一个人是否患有某种疾病。它的特点是输出是一个概率值（0到1之间），然后根据概率值做出分类决策。</p>\n<hr>\n<h2 id=\"_2-逻辑回归的核心思想\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#_2-逻辑回归的核心思想\"><span>2. <strong>逻辑回归的核心思想</strong></span></a></h2>\n<p>逻辑回归的核心思想是：</p>\n<ul>\n<li>先用一条直线（或超平面）对数据进行划分。</li>\n<li>然后通过一个特殊的函数（S型函数）将直线输出的值转换成概率。</li>\n<li>最后根据概率值判断类别。</li>\n</ul>\n<hr>\n<h2 id=\"_3-逻辑回归的全流程\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#_3-逻辑回归的全流程\"><span>3. <strong>逻辑回归的全流程</strong></span></a></h2>\n<h3 id=\"第一步-输入数据\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#第一步-输入数据\"><span><strong>第一步：输入数据</strong></span></a></h3>\n<ul>\n<li>假设我们有一组数据，比如病人的年龄、血压、血糖等特征，以及是否患病的标签（0或1）。</li>\n<li>我们的目标是通过这些特征预测一个新病人是否患病。</li>\n</ul>\n<h3 id=\"第二步-线性回归部分\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#第二步-线性回归部分\"><span><strong>第二步：线性回归部分</strong></span></a></h3>\n<ul>\n<li>逻辑回归首先像线性回归一样，计算一个线性方程：<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>z</mi><mo>=</mo><msub><mi>w</mi><mn>1</mn></msub><mo>⋅</mo><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>w</mi><mn>2</mn></msub><mo>⋅</mo><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><mo>⋯</mo><mo>+</mo><msub><mi>w</mi><mi>n</mi></msub><mo>⋅</mo><msub><mi>x</mi><mi>n</mi></msub><mo>+</mo><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">z = w_1 \\cdot x_1 + w_2 \\cdot x_2 + \\dots + w_n \\cdot x_n + b\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.5945em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.5945em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6667em;vertical-align:-0.0833em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.5945em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">b</span></span></span></span></span></p>\n其中：\n<ul>\n<li>( x_1, x_2, \\dots, x_n ) 是输入特征（比如年龄、血压等）。</li>\n<li>( w_1, w_2, \\dots, w_n ) 是权重（表示每个特征的重要性）。</li>\n<li>( b ) 是偏置项（可以理解为一个调整值）。</li>\n<li>( z ) 是线性回归的输出。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"第三步-通过s型函数转换概率\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#第三步-通过s型函数转换概率\"><span><strong>第三步：通过S型函数转换概率</strong></span></a></h3>\n<ul>\n<li>线性回归的输出 ( z ) 是一个任意实数（可能是负数或很大的数），但我们想要的是一个概率值（0到1之间）。</li>\n<li>于是，我们用S型函数（也叫Sigmoid函数）将 ( z ) 转换成概率：<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>σ</mi><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>z</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\sigma(z) = \\frac{1}{1 + e^{-z}}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.0908em;vertical-align:-0.7693em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3214em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6973em;\"><span style=\"top:-2.989em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.04398em;\">z</span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7693em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n这个函数的输出值在0到1之间，可以理解为“属于正类的概率”。</li>\n</ul>\n<h3 id=\"第四步-设定阈值进行分类\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#第四步-设定阈值进行分类\"><span><strong>第四步：设定阈值进行分类</strong></span></a></h3>\n<ul>\n<li>得到概率值后，我们需要设定一个阈值（比如0.5）来判断类别：\n<ul>\n<li>如果概率 ≥ 0.5，预测为正类（比如患病）。</li>\n<li>如果概率 &lt; 0.5，预测为负类（比如健康）。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"第五步-训练模型\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#第五步-训练模型\"><span><strong>第五步：训练模型</strong></span></a></h3>\n<ul>\n<li>逻辑回归的目标是找到一组权重 ( w ) 和偏置 ( b )，使得模型的预测结果尽可能接近真实标签。</li>\n<li>训练过程是通过“最大似然估计”或“梯度下降法”来不断调整 ( w ) 和 ( b )，使得模型的预测误差最小。</li>\n</ul>\n<h3 id=\"第六步-预测新数据\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#第六步-预测新数据\"><span><strong>第六步：预测新数据</strong></span></a></h3>\n<ul>\n<li>当模型训练好后，我们可以用它对新的数据进行预测。比如输入一个新病人的年龄、血压等特征，模型会输出一个概率值，告诉我们这个病人患病的可能性有多大。</li>\n</ul>\n<hr>\n<h2 id=\"_4-举个例子\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#_4-举个例子\"><span>4. <strong>举个例子</strong></span></a></h2>\n<p>假设我们用逻辑回归预测一个人是否会购买某款产品：</p>\n<ul>\n<li>输入特征：年龄、收入、浏览时长。</li>\n<li>模型计算：<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>z</mi><mo>=</mo><mn>0.1</mn><mo>⋅</mo><mtext>年龄</mtext><mo>+</mo><mn>0.5</mn><mo>⋅</mo><mtext>收入</mtext><mo>+</mo><mn>0.3</mn><mo>⋅</mo><mtext>浏览时长</mtext><mo>−</mo><mn>5</mn></mrow><annotation encoding=\"application/x-tex\">z = 0.1 \\cdot \\text{年龄} + 0.5 \\cdot \\text{收入} + 0.3 \\cdot \\text{浏览时长} - 5\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0.1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">年龄</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0.5</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">收入</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0.3</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">浏览时长</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">5</span></span></span></span></span></p>\n</li>\n<li>通过S型函数转换：<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>σ</mi><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>z</mi></mrow></msup></mrow></mfrac><mo>=</mo><mn>0.7</mn></mrow><annotation encoding=\"application/x-tex\">\\sigma(z) = \\frac{1}{1 + e^{-z}} = 0.7\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.0908em;vertical-align:-0.7693em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3214em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6973em;\"><span style=\"top:-2.989em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.04398em;\">z</span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7693em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0.7</span></span></span></span></span></p>\n</li>\n<li>因为0.7 &gt; 0.5，所以预测这个人会购买产品。</li>\n</ul>\n<hr>\n<h2 id=\"_5-总结\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#_5-总结\"><span>5. <strong>总结</strong></span></a></h2>\n<p>逻辑回归的全流程可以简单概括为：</p>\n<ol>\n<li>输入特征数据。</li>\n<li>用线性方程计算得分 ( z )。</li>\n<li>用S型函数将 ( z ) 转换成概率。</li>\n<li>根据概率值和阈值进行分类。</li>\n<li>训练模型，调整参数，使预测更准确。</li>\n<li>用训练好的模型预测新数据。</li>\n</ol>\n<p>逻辑回归虽然简单，但在很多实际问题中都非常有效，是机器学习的经典算法之一！</p>\n","tagOpen":"<template>","tagClose":"</template>"},"script":null,"scriptSetup":null,"scripts":[],"styles":[],"customBlocks":[]},"content":"\n## 1. **问题背景**\n逻辑回归是用来解决分类问题的，比如判断一封邮件是垃圾邮件还是正常邮件，或者预测一个人是否患有某种疾病。它的特点是输出是一个概率值（0到1之间），然后根据概率值做出分类决策。\n\n---\n\n\n## 2. **逻辑回归的核心思想**\n逻辑回归的核心思想是：\n- 先用一条直线（或超平面）对数据进行划分。\n- 然后通过一个特殊的函数（S型函数）将直线输出的值转换成概率。\n- 最后根据概率值判断类别。\n\n---\n\n\n## 3. **逻辑回归的全流程**\n\n### **第一步：输入数据**\n- 假设我们有一组数据，比如病人的年龄、血压、血糖等特征，以及是否患病的标签（0或1）。\n- 我们的目标是通过这些特征预测一个新病人是否患病。\n\n\n### **第二步：线性回归部分**\n- 逻辑回归首先像线性回归一样，计算一个线性方程：\n  $$\n  z = w_1 \\cdot x_1 + w_2 \\cdot x_2 + \\dots + w_n \\cdot x_n + b\n  $$\n  其中：\n  - \\( x_1, x_2, \\dots, x_n \\) 是输入特征（比如年龄、血压等）。\n  - \\( w_1, w_2, \\dots, w_n \\) 是权重（表示每个特征的重要性）。\n  - \\( b \\) 是偏置项（可以理解为一个调整值）。\n  - \\( z \\) 是线性回归的输出。\n\n\n### **第三步：通过S型函数转换概率**\n- 线性回归的输出 \\( z \\) 是一个任意实数（可能是负数或很大的数），但我们想要的是一个概率值（0到1之间）。\n- 于是，我们用S型函数（也叫Sigmoid函数）将 \\( z \\) 转换成概率：\n  $$\n  \\sigma(z) = \\frac{1}{1 + e^{-z}}\n  $$\n  这个函数的输出值在0到1之间，可以理解为“属于正类的概率”。\n\n\n### **第四步：设定阈值进行分类**\n- 得到概率值后，我们需要设定一个阈值（比如0.5）来判断类别：\n  - 如果概率 ≥ 0.5，预测为正类（比如患病）。\n  - 如果概率 < 0.5，预测为负类（比如健康）。\n\n\n### **第五步：训练模型**\n- 逻辑回归的目标是找到一组权重 \\( w \\) 和偏置 \\( b \\)，使得模型的预测结果尽可能接近真实标签。\n- 训练过程是通过“最大似然估计”或“梯度下降法”来不断调整 \\( w \\) 和 \\( b \\)，使得模型的预测误差最小。\n\n\n### **第六步：预测新数据**\n- 当模型训练好后，我们可以用它对新的数据进行预测。比如输入一个新病人的年龄、血压等特征，模型会输出一个概率值，告诉我们这个病人患病的可能性有多大。\n\n---\n\n\n## 4. **举个例子**\n假设我们用逻辑回归预测一个人是否会购买某款产品：\n- 输入特征：年龄、收入、浏览时长。\n- 模型计算：\n  $$\n  z = 0.1 \\cdot \\text{年龄} + 0.5 \\cdot \\text{收入} + 0.3 \\cdot \\text{浏览时长} - 5\n  $$\n- 通过S型函数转换：\n  $$\n  \\sigma(z) = \\frac{1}{1 + e^{-z}} = 0.7\n  $$\n- 因为0.7 > 0.5，所以预测这个人会购买产品。\n\n---\n\n\n## 5. **总结**\n逻辑回归的全流程可以简单概括为：\n1. 输入特征数据。\n2. 用线性方程计算得分 \\( z \\)。\n3. 用S型函数将 \\( z \\) 转换成概率。\n4. 根据概率值和阈值进行分类。\n5. 训练模型，调整参数，使预测更准确。\n6. 用训练好的模型预测新数据。\n\n逻辑回归虽然简单，但在很多实际问题中都非常有效，是机器学习的经典算法之一！","excerpt":"","includedFiles":[],"tasklistId":0,"title":"","headers":[{"level":2,"title":"1. 问题背景","slug":"_1-问题背景","link":"#_1-问题背景","children":[]},{"level":2,"title":"2. 逻辑回归的核心思想","slug":"_2-逻辑回归的核心思想","link":"#_2-逻辑回归的核心思想","children":[]},{"level":2,"title":"3. 逻辑回归的全流程","slug":"_3-逻辑回归的全流程","link":"#_3-逻辑回归的全流程","children":[{"level":3,"title":"第一步：输入数据","slug":"第一步-输入数据","link":"#第一步-输入数据","children":[]},{"level":3,"title":"第二步：线性回归部分","slug":"第二步-线性回归部分","link":"#第二步-线性回归部分","children":[]},{"level":3,"title":"第三步：通过S型函数转换概率","slug":"第三步-通过s型函数转换概率","link":"#第三步-通过s型函数转换概率","children":[]},{"level":3,"title":"第四步：设定阈值进行分类","slug":"第四步-设定阈值进行分类","link":"#第四步-设定阈值进行分类","children":[]},{"level":3,"title":"第五步：训练模型","slug":"第五步-训练模型","link":"#第五步-训练模型","children":[]},{"level":3,"title":"第六步：预测新数据","slug":"第六步-预测新数据","link":"#第六步-预测新数据","children":[]}]},{"level":2,"title":"4. 举个例子","slug":"_4-举个例子","link":"#_4-举个例子","children":[]},{"level":2,"title":"5. 总结","slug":"_5-总结","link":"#_5-总结","children":[]}]}}
