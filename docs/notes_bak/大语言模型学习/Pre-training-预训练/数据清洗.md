---
dg-publish: true
dg-permalink: /大语言模型学习/Pre-training-预训练/数据清洗
dg-home: false
dg-description: 在此输入笔记的描述
dg-hide: false
dg-hide-title: false
dg-show-backlinks: true
dg-show-local-graph: true
dg-show-inline-title: true
dg-pinned: false
dg-passphrase: 在此输入访问密码
dg-enable-mathjax: false
dg-enable-mermaid: false
dg-enable-uml: false
dg-note-icon: 0
dg-enable-dataview: false
tags:
  - NLP
permalink: /大语言模型学习/Pre-training-预训练/数据清洗/
dgShowBacklinks: true
dgShowLocalGraph: true
dgShowInlineTitle: true
dgPassFrontmatter: true
noteIcon: 0
created: 2025-04-08T12:10:33.000+08:00
updated: 2025-04-13T13:06:02.000+08:00
title: 数据清洗
createTime: 2025/05/13 17:33:53
---



## 元数据
**分类**：机器学习/自然语言处理  
**标签**：数据清洗、预训练、语言模型、数据质量  
**日期**：2023年10月25日  

---



## 核心观点总结
数据清洗是预训练模型构建过程中最重要的环节之一，数据的质量和多样性直接影响模型的通用能力与性能。本篇内容详细介绍了数据清洗的关键步骤，包括URL过滤、内容提取、语言识别及低质内容过滤，并分享了相关技术实现与注意事项。

---



## 重点内容提取

### URL 过滤
通过制定URL黑名单（如成人网站）和计算URL分数来筛选内容。此外，为了避免模型过于依赖某些特定数据源，像Arxiv和WikiPedia等精心构建的数据集内容也会被过滤。

💡 **启发点**：避免模型对单一来源的过度依赖，可以提升模型的泛化能力。

---


### 内容提取
在获取到已过滤的URL后，需进一步提取有效文本信息，去除目录、标题、广告等无关内容。  
推荐工具：`trafilatura`库，用于高效抓取网页内容。

```python
# 示例代码：使用trafilatura抓取网页内容
import trafilatura

url = 'https://example.com'
downloaded = trafilatura.fetch_url(url)
text = trafilatura.extract(downloaded)
print(text)
```

⚠ **注意**：确保抓取内容时合法合规，避免侵犯版权。

---


### 语言识别
使用`FastText`或`langid`工具进行语言检测，将语言阈值分数低于0.65的文章剔除，以确保数据集中语言一致性。

```python
# 核心代码示例：基于FastText的语言识别
def compute_stats_single(self, sample):
    text = sample[self.text_key].lower().replace('\n', ' ')
    ft_model = get_model(self.model_key)
    pred = ft_model.predict(text)
    lang_id = pred[0][0].replace('__label__', '')
    lang_score = pred[1][0]
    sample[Fields.stats][StatsKeys.lang] = lang_id
    sample[Fields.stats][StatsKeys.lang_score] = lang_score
    return sample
```

---


### 低质内容过滤
1. **篇章级别过滤**  
   - 去除重复段落或包含错误信息（如抓取超时）的文章。  
   - 根据文章长度、标点符号比例等标准筛选不正规文章。  

2. **句子级别过滤**  
   - 删除由纯大写字符或纯数字组成的句子。  
   - 丢弃命中特定关键词（如“关注”“转发”“点赞”）的句子。  
   - 过滤掉长度小于10且符合特定模板（如以“登录”开头或以“展开”结尾）的句子。  

💡 **启发点**：利用启发式规则进行数据清洗，可以显著提升数据质量。

---



## 常见错误警告
> **⚠ 数据清洗易犯错误：**
> 1. 过度过滤导致数据量不足，影响模型训练效果。
> 2. 未充分考虑多语言数据的多样性，可能导致模型表现偏向某些语言。
> 3. 忽略版权或数据合法性问题，可能引发法律风险。

---



## 行动清单
1. 熟悉并实践`trafilatura`库的网页内容抓取功能。
2. 学习FastText和langid工具的语言识别实现。
3. 根据本指南设计并优化自己的数据清洗Pipeline。

---



## 📈 趋势预测
随着大规模语言模型的普及，数据清洗技术将更加关注以下方向：
- 更智能的自动化过滤工具，如结合深度学习的内容分类器。
- 跨领域数据质量标准化，确保多样性与公平性。
- 更高效的多语言支持，特别是低资源语言的数据增强。

---



## [思考]板块
1. 数据清洗中如何平衡“数据量”和“数据质量”之间的矛盾？  
2. 是否可以通过生成式AI辅助生成高质量数据以弥补清洗后的数据缺失？  
3. 对于低资源语言，是否需要不同于主流语言的数据清洗策略？

---

> **原始出处**：深度学习技术报告及相关文档（如DeepSeek-Math技术报告）
>[[大语言模型学习/Pre-training 预训练/模型打分与数据去重\|模型打分与数据去重]]
