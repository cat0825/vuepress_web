{"preview/custom-component.example.md":"762fa0a8","README.md":"b91cda0e","notes_bak/导航.md":"7688a1ef","preview/markdown.md":"d374692c","notes_bak/c++ primer plus/关于过程编程,面向对象编程和泛型编程.md":"9c3ed454","notes_bak/Welcome🎉.md":"49c6e6b8","notes_bak/c++ primer plus/using和namespace.md":"c489fd14","notes_bak/c++ primer plus/函数声明.md":"581e6443","notes_bak/c++ primer plus/初始化.md":"34cc76f7","notes_bak/c++ primer plus/局部和全局的命名空间引入.md":"272f9d2b","notes_bak/thino/2024-12-25.md":"5e5b658a","notes_bak/demo/README.md":"98493ba6","notes_bak/transformer/什么是transformer.md":"1ecf48e2","notes_bak/机器学习/关于单变量线性回归的思考.md":"071eed6d","notes_bak/机器学习/关于逻辑回归的思考.md":"39f2e327","notes_bak/机器学习/引言.md":"3bd680e2","notes_bak/大语言模型学习/导航.md":"cb973d8c","notes_bak/毕业设计/学习资料.md":"be613af0","notes_bak/leetcode/链表/分隔链表.md":"00fcf45f","notes_bak/leetcode/链表/合并零之间的节点.md":"c2f1cd5c","notes_bak/大语言模型学习/Attention注意力机制/Attention机制详解与应用.md":"59093a9d","notes_bak/大语言模型学习/Attention注意力机制/DCA：长文本处理的新突破（Dual Chunk Attention）.md":"3e7b0e5c","notes_bak/大语言模型学习/Attention注意力机制/KV Cache技术详解：优化Transformer自回归生成效率.md":"72be0a9c","notes_bak/大语言模型学习/Attention注意力机制/Transformer中的Attention详解与应用指南.md":"746ed8b4","notes_bak/大语言模型学习/Attention注意力机制/【长上下文模型优化】基于Shifted Sparse Attention的创新方法.md":"20bb4829","notes_bak/大语言模型学习/Attention注意力机制/优化Attention计算复杂度的技术探讨.md":"4d1436c0","notes_bak/大语言模型学习/Attention注意力机制/深度学习中的注意力机制优化：从MHA到MLA.md":"5ec814c0","notes_bak/大语言模型学习/MCP/介绍.md":"5043271e","notes_bak/大语言模型学习/FFN、Add & LN 的作用与应用/Transformer核心模块解析：FFN、Add & LN 的作用与应用.md":"c4d777ec","notes_bak/大语言模型学习/FFN、Add & LN 的作用与应用/深度学习中的Layer Norm设计：Post-Norm、Pre-Norm与Sandwich-Norm比较.md":"0718b65b","notes_bak/大语言模型学习/FFN、Add & LN 的作用与应用/激活函数与FFN结构优化：SwiGLU、GeGLU及其应用解析.md":"7f675048","notes_bak/大语言模型学习/Common Models常见模型/发展历史.md":"0f73d21a","notes_bak/大语言模型学习/Pre-training 预训练/推理耗时.md":"15b7482c","notes_bak/大语言模型学习/Pre-training 预训练/数据多样性与模型优化探索.md":"a86f7352","notes_bak/大语言模型学习/Pre-training 预训练/数据清洗.md":"147bffba","notes_bak/大语言模型学习/FFN、Add & LN 的作用与应用/激活函数详解与比较：从Sigmoid到Swish.md":"47515cde","notes_bak/大语言模型学习/Pre-training 预训练/数据爬取.md":"823af8d8","notes_bak/大语言模型学习/Pre-training 预训练/数据配比与训练顺序优化指南.md":"74752c02","notes_bak/大语言模型学习/Pre-training 预训练/深度学习中的显存优化与梯度处理方法.md":"003f33b4","notes_bak/大语言模型学习/Pre-training 预训练/混合精度训练.md":"356135e0","notes_bak/大语言模型学习/Pre-training 预训练/模型打分与数据去重.md":"2b0b5ca8","notes_bak/大语言模型学习/Pre-training 预训练/继续预训练.md":"085bc899","notes_bak/大语言模型学习/Pre-training 预训练/预训练定义以及数据来源.md":"348eca62","notes_bak/大语言模型学习/Pre-training 预训练/训练容灾及训练监控.md":"a596e2a0","notes_bak/大语言模型学习/Pre-training 预训练/预训练评估.md":"ffd0bf1e","notes_bak/大语言模型学习/Pre-training 预训练/预训练评估2.md":"20531733","notes_bak/大语言模型学习/Positional Encoding位置编码/YaRN方法解析：扩展RoPE嵌入与注意力优化的实践.md":"44d1ea28","notes_bak/大语言模型学习/Positional Encoding位置编码/位置内插法扩展语言模型上下文长度.md":"a9d31212","notes_bak/大语言模型学习/Positional Encoding位置编码/NTK插值方法解析与优化：从NTK-aware到NTK-by-parts.md":"5544ac46","notes_bak/大语言模型学习/Positional Encoding位置编码/数字输入优化与外推方法解析.md":"34b1c35e","notes_bak/大语言模型学习/Positional Encoding位置编码/旋转位置编码与ALiBi：深度学习中的位置嵌入优化.md":"1e2e5a70","notes_bak/大语言模型学习/Structure & Decoding Policy 结构和解码策略/大模型结构与混合专家（LLM & MoE）解析.md":"ee9a5dda","notes_bak/大语言模型学习/Structure & Decoding Policy 结构和解码策略/深度解析语言模型采样方法：Top-K、Top-P、Temperature及综合策略.md":"268b28eb","notes_bak/大语言模型学习/Structure & Decoding Policy 结构和解码策略/解码采样策略：Greedy Search与Beam Search的实现与优化.md":"6065cc30","notes_bak/大语言模型学习/RL强化学习基础/Actor-Critic算法.md":"24fe3a50","notes_bak/大语言模型学习/Positional Encoding位置编码/介绍.md":"2ffaa1d2","notes_bak/大语言模型学习/RL强化学习基础/PPO算法.md":"e126f434","notes_bak/大语言模型学习/RL强化学习基础/PPO训练的trick和问题.md":"1e1f330f","notes_bak/大语言模型学习/RL强化学习基础/RL在NLP场景下的拓展.md":"a9d55f08","notes_bak/大语言模型学习/RL强化学习基础/SARSA-λ与Q-learning对比.md":"6d4f0892","notes_bak/大语言模型学习/RL强化学习基础/SARSA算法.md":"455ac130","notes_bak/大语言模型学习/RL强化学习基础/价值迭代算法.md":"37f4ce66","notes_bak/大语言模型学习/RL强化学习基础/强化学习分类.md":"fb51f50e","notes_bak/大语言模型学习/RL强化学习基础/强化学习的独特性.md":"76fbcba0","notes_bak/大语言模型学习/RL强化学习基础/强化学习问题,流程.md":"30102fe6","notes_bak/大语言模型学习/RL强化学习基础/时序差分算法.md":"b7ddeed8","notes_bak/大语言模型学习/RL强化学习基础/深度Q网络.md":"35e249c3","notes_bak/大语言模型学习/RL强化学习基础/策略梯度算法.md":"e50caf5c","notes_bak/大语言模型学习/RL强化学习基础/策略迭代算法.md":"be086158","notes_bak/大语言模型学习/RL强化学习基础/蒙特卡洛方法.md":"3303340b","notes_bak/大语言模型学习/RL强化学习基础/贝尔曼方程.md":"21262789","notes_bak/大语言模型学习/RL强化学习基础/马尔可夫决策过程.md":"51c2f1ab","notes_bak/大语言模型学习/分词/BBPE：字节级别的BPE分词技术解析与应用.md":"04e643a4","notes_bak/大语言模型学习/分词/使用Byte Pair Encoding (BPE)优化子词分词的技巧与实践.md":"36d883c6","notes_bak/大语言模型学习/分词/WordPiece分词算法解析与实践.md":"2a26ca5d","notes_bak/大语言模型学习/分词/分词算法的比较.md":"b506f648","notes_bak/大语言模型学习/分词/使用Unigram语言模型（ULM）优化分词算法：核心思路与实践.md":"12a77d09","notes_bak/大语言模型学习/分词/常用分词库.md":"0c434c00","notes_bak/大语言模型学习/大模型应用/Prompt Tech 提示技术.md":"734c28ba","notes_bak/大语言模型学习/模型压缩/Knowledge Distillation 知识蒸馏.md":"29a2ea7f","notes_bak/大语言模型学习/模型压缩/Low-Rank Factorization 低秩分解.md":"7c13079d","notes_bak/大语言模型学习/模型压缩/介绍.md":"519c8a1e","notes_bak/大语言模型学习/模型压缩/模型量化.md":"33acce60","notes_bak/大语言模型学习/训练推理优化/PageAttention原理.md":"0ad29f12","notes_bak/大语言模型学习/训练推理优化/大模型的packing技巧.md":"68c15062","notes_bak/大语言模型学习/词嵌入/FastText.md":"8ccc5498","notes_bak/大语言模型学习/模型压缩/模型剪枝.md":"299a6058","notes_bak/大语言模型学习/词嵌入/Word2Vec.md":"704f6bb1","notes_bak/大语言模型学习/词嵌入/oneHot.md":"e46a563c","notes_bak/大语言模型学习/词嵌入/介绍.md":"18efe662","notes_bak/leetcode/滑动窗口/定长滑动/半径为k的子数组平均值.md":"728549d6","notes_bak/leetcode/滑动窗口/定长滑动/大小为k平均值大于等于阈值的子数组个数.md":"58707c54","notes_bak/leetcode/滑动窗口/定长滑动/定长子串中元音的最大数目.md":"204b76d1","notes_bak/大语言模型学习/Common Models常见模型/BERT及其变体/BART.md":"525c5c88","notes_bak/大语言模型学习/Common Models常见模型/BERT及其变体/RoBERTa.md":"644be26e","notes_bak/大语言模型学习/Common Models常见模型/BERT及其变体/介绍.md":"25e175d8","notes_bak/大语言模型学习/Common Models常见模型/BERT及其变体/T5.md":"22fbefde","notes_bak/大语言模型学习/Common Models常见模型/DeepSeek系列/DeepSeek-V2.md":"a4b3beac","notes_bak/大语言模型学习/Common Models常见模型/DeepSeek系列/DeepSeek-R1.md":"767b461f","notes_bak/大语言模型学习/Common Models常见模型/DeepSeek系列/DeepSeek-V3.md":"7cef7f32","notes_bak/大语言模型学习/Common Models常见模型/DeepSeek系列/Deepseek-V1.md":"a36eda52","notes_bak/大语言模型学习/Common Models常见模型/DeepSeek系列/Deepseek-math.md":"15a3ef57","notes_bak/大语言模型学习/Common Models常见模型/GLM系列/GLM1.md":"0cb4e61d","notes_bak/大语言模型学习/Common Models常见模型/GLM系列/GLM2.md":"387bbcfe","notes_bak/大语言模型学习/Common Models常见模型/GLM系列/GLM3.md":"5c33a5fa","notes_bak/大语言模型学习/Common Models常见模型/GLM系列/GLM4.md":"4688357a","notes_bak/大语言模型学习/Common Models常见模型/GPT系列/GPT-1.md":"4e163cc0","notes_bak/大语言模型学习/Common Models常见模型/GPT系列/GPT-2.md":"f0002982","notes_bak/大语言模型学习/Common Models常见模型/GPT系列/GPT-3.md":"57f4dc03","notes_bak/大语言模型学习/Common Models常见模型/LLama系列/LLaMA1.md":"724e91dd","notes_bak/大语言模型学习/Common Models常见模型/LLama系列/LLama 2.md":"1b81c746","notes_bak/大语言模型学习/Common Models常见模型/LLama系列/LLama 3.md":"3e7dbc59","notes_bak/大语言模型学习/Common Models常见模型/MOE系列/GShard.md":"5b54faa2","notes_bak/大语言模型学习/Common Models常见模型/MOE系列/Mistral.md":"7d8e9f43","notes_bak/大语言模型学习/Common Models常见模型/MOE系列/Switch Transformer.md":"58c97349","notes_bak/大语言模型学习/Common Models常见模型/PLaM系列/PLaM2.md":"2d78f717","notes_bak/大语言模型学习/Common Models常见模型/PLaM系列/PLaM.md":"252ba4f4","notes_bak/大语言模型学习/Common Models常见模型/Qwen系列/Qwen1.md":"c2fe2752","notes_bak/大语言模型学习/Pre-training 预训练/预训练过程/预训练的Scaling Law.md":"1bff7590","notes_bak/大语言模型学习/Common Models常见模型/Qwen系列/Qwen2.5.md":"47f5d710","notes_bak/大语言模型学习/Pre-training 预训练/预训练过程/训练Tokenizer.md":"a96d1c16","notes_bak/大语言模型学习/Pre-training 预训练/预训练过程/高效深度学习模型训练框架选择与优化指南.md":"1d4851b5","notes_bak/大语言模型学习/Positional Encoding位置编码/相对位置编码/DeBERTa的相对位置编码与绝对位置编码解析.md":"722322b7","notes_bak/大语言模型学习/Positional Encoding位置编码/相对位置编码/T5模型与相对位置编码优化解析.md":"1ca312e8","notes_bak/大语言模型学习/Positional Encoding位置编码/相对位置编码/相对位置编码与XLNet位置编码详解 深入理解Transformer机制.md":"18a11c69","notes_bak/大语言模型学习/Positional Encoding位置编码/绝对位置编码/Transformer绝对位置编码详解与改进分析.md":"6afb3314","notes_bak/大语言模型学习/Pre-training 预训练/预训练过程/预训练策略.md":"5b10ffcc","notes_bak/大语言模型学习/Positional Encoding位置编码/绝对位置编码/BERT与RNN位置编码的对比与应用.md":"3505a50c","notes_bak/大语言模型学习/RL强化学习基础/DPO直接偏好优化/DPO公式推导.md":"52aba00d","notes_bak/大语言模型学习/Common Models常见模型/Qwen系列/Qwen2.md":"5caf6f02","notes_bak/大语言模型学习/RL强化学习基础/DPO直接偏好优化/深度偏好优化（DPO）损失函数解析与代码示例.md":"487a15a6","notes_bak/大语言模型学习/RL强化学习基础/LoRA及其变体/AdaLoRA.md":"0764aa09","notes_bak/大语言模型学习/RL强化学习基础/DPO直接偏好优化/DPO介绍及RLHF-PPO缺点.md":"9a4a2b0e","notes_bak/大语言模型学习/RL强化学习基础/DPO直接偏好优化/对比学习角度理解DPO.md":"436a1990","notes_bak/大语言模型学习/RL强化学习基础/LoRA及其变体/LoRA+.md":"baf4d2f4","notes_bak/大语言模型学习/RL强化学习基础/LoRA及其变体/LoRA.md":"3263666f","notes_bak/大语言模型学习/RL强化学习基础/LoRA及其变体/DoRA.md":"55178a65","notes_bak/大语言模型学习/RL强化学习基础/LoRA及其变体/X-LoRA.md":"5bec4138","notes_bak/大语言模型学习/RL强化学习基础/LoRA及其变体/参考文献.md":"cdaae78c","notes_bak/大语言模型学习/RL强化学习基础/PEFT参数高效微调/P-Tuning V2.md":"1b0746ab","notes_bak/大语言模型学习/RL强化学习基础/LoRA及其变体/QLoRA.md":"2bc22b39","notes_bak/大语言模型学习/RL强化学习基础/LoRA及其变体/VeRA.md":"65a5eeb0","notes_bak/大语言模型学习/RL强化学习基础/PEFT参数高效微调/P-Tuning.md":"52c26f82","notes_bak/大语言模型学习/RL强化学习基础/PEFT参数高效微调/Prefix-Tuning.md":"50d208be","notes_bak/大语言模型学习/RL强化学习基础/PEFT参数高效微调/Prompt Tuning.md":"44a4a6b6","notes_bak/大语言模型学习/RL强化学习基础/PEFT参数高效微调/介绍.md":"05a9c195","notes_bak/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/Actor-Model.md":"4963f6be","notes_bak/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/Instruct-GPT.md":"2ae2a14d","notes_bak/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/RLHF研究方法及研究总结.md":"6c31f4d2","notes_bak/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/RLHF流程.md":"12986d20","notes_bak/大语言模型学习/RL强化学习基础/PEFT参数高效微调/LLaMA-Adapter.md":"7132f25c","notes_bak/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/RL在NLP场景下的拓展.md":"40c8e89a","notes_bak/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/Reference-Model.md":"6ecfff4d","notes_bak/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/Reward-Model.md":"b6c93a4a","notes_bak/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/在线与离线RLHF的比较与应用.md":"2072c7be","notes_bak/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/深入理解Prompt到Response的MDP模型分析.md":"dd54153a","notes_bak/大语言模型学习/RL强化学习基础/优化PPO方向的算法/DAPO.md":"2d3363b5","notes_bak/大语言模型学习/RL强化学习基础/优化PPO方向的算法/GRPO.md":"78b95800","notes_bak/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/critic-model.md":"076992e5","notes_bak/大语言模型学习/RL强化学习基础/优化PPO方向的算法/REINFORCE算法改进：RLOO与REINFORCE++.md":"1324e2da","notes_bak/大语言模型学习/RL强化学习基础/优化PPO方向的算法/ReMax-improvement.md":"5e74eded","notes_bak/大语言模型学习/RL强化学习基础/优化PPO方向的算法/ReMax.md":"664f1ed0","notes_bak/大语言模型学习/RL强化学习基础/优化PPO方向的算法/VAPO.md":"7ab20d8c","notes_bak/大语言模型学习/RL强化学习基础/优化DPO方向的算法/DPOP.md":"4dcef19b","notes_bak/大语言模型学习/RL强化学习基础/优化DPO方向的算法/Self-Reward.md":"11f93f52","notes_bak/大语言模型学习/RL强化学习基础/优化DPO方向的算法/TDPO.md":"e85ad844","notes_bak/大语言模型学习/后训练/SFT监督微调/监督微调与预训练的区别.md":"c019ef5c","notes_bak/大语言模型学习/大模型应用/LLM-based Agent 基于大模型的智能体/Agent评估框架汇总.md":"7c0876f8","notes_bak/大语言模型学习/大模型应用/LLM-based Agent 基于大模型的智能体/定义以及历史发展.md":"7d4fa2e2","notes_bak/大语言模型学习/大模型应用/LLM-based Agent 基于大模型的智能体/基于大模型的智能体原理.md":"08760d77","notes_bak/大语言模型学习/大模型应用/LLM-based Agent 基于大模型的智能体/智能体的分类.md":"68bf5e87","notes_bak/大语言模型学习/大模型应用/LLM-based Agent 基于大模型的智能体/智能体的框架和应用.md":"27eb81d4","notes_bak/大语言模型学习/大模型应用/LLM-based Agent 基于大模型的智能体/智能体系统分类.md":"08f2ede6","notes_bak/大语言模型学习/大模型应用/RAG检索增强生成/RAG优化中查询索引阶段.md":"4b9a9750","notes_bak/大语言模型学习/大模型应用/RAG检索增强生成/RAG优化.md":"eec8af7a","notes_bak/大语言模型学习/大模型应用/RAG检索增强生成/RAG流程和分类.md":"16917aa6","notes_bak/大语言模型学习/大模型应用/RAG检索增强生成/RAG评估.md":"6e3531ae","notes_bak/大语言模型学习/大模型应用/RAG检索增强生成/固定长度分块.md":"59ab0e2a","notes_bak/大语言模型学习/大模型应用/RAG检索增强生成/基于大模型的分块.md":"3ea298e0","notes_bak/大语言模型学习/大模型应用/RAG检索增强生成/基于文档结构分块.md":"72f16c33","notes_bak/大语言模型学习/大模型应用/RAG检索增强生成/基于语义分块.md":"d0197f9c","notes_bak/大语言模型学习/训练推理优化/FlashAttention/FlashAttention Forword流程.md":"953faf5a","notes_bak/大语言模型学习/训练推理优化/FlashAttention/标准Attention与Safe softmax.md":"32d2bd41","notes_bak/大语言模型学习/训练推理优化/FlashAttention/介绍.md":"706d5f26","notes_bak/大语言模型学习/训练推理优化/推理框架/HuggingFace TGI.md":"26a1f455","notes_bak/大语言模型学习/训练推理优化/FlashAttention/计算与内存限制.md":"0c78b5ac","notes_bak/大语言模型学习/训练推理优化/推理框架/vLLM.md":"19190aea","notes_bak/大语言模型学习/训练推理优化/推理耗时及优化/推理耗时.md":"4f815574","notes_bak/大语言模型学习/训练推理优化/推理耗时及优化/首Token时延优化.md":"3082c46f","notes_bak/大语言模型学习/训练推理优化/训练推理显存占用分析/模型显存总体分析.md":"2563a184","notes_bak/大语言模型学习/训练推理优化/训练推理显存占用分析/显存优化与推理显存分析.md":"1217948e","notes_bak/大语言模型学习/训练推理优化/训练推理显存占用分析/训练阶段的显存分析.md":"0fac84b9","notes_bak/大语言模型学习/训练推理优化/训练框架/Accelerate.md":"d11a5a2e","notes_bak/大语言模型学习/训练推理优化/训练框架/Megatron-LM.md":"836d9afe","notes_bak/大语言模型学习/训练推理优化/训练框架/Megatron和DeepSpeed后端实现的区别.md":"5297a2c0","notes_bak/大语言模型学习/训练推理优化/训练框架/X-ray.md":"6ae74dea","notes_bak/大语言模型学习/训练推理优化/训练框架/DeepSpeed.md":"7acd3189","notes_bak/大语言模型学习/后训练/SFT监督微调/STF训练/多轮对话专项提升.md":"05e0b280","notes_bak/大语言模型学习/后训练/SFT监督微调/STF训练/多轮对话专项提升2.md":"e75420a0","notes_bak/大语言模型学习/后训练/SFT监督微调/STF训练/训练启动脚本.md":"7451fc0b","notes_bak/大语言模型学习/后训练/SFT监督微调/STF训练/训练框架及参数设置.md":"2ab70c7a","notes_bak/大语言模型学习/后训练/SFT监督微调/SFT数据及处理/开源数据集.md":"444ef08a","notes_bak/大语言模型学习/后训练/SFT监督微调/SFT数据及处理/数据多样性探索.md":"abab67ae","notes_bak/大语言模型学习/后训练/SFT监督微调/STF训练/训练技巧和训练策略.md":"49e057aa","notes_bak/大语言模型学习/后训练/SFT监督微调/SFT数据及处理/数据生产合成与质量过滤.md":"52b5720a","notes_bak/大语言模型学习/后训练/SFT监督微调/SFT数据及处理/数据飞轮在SFT中的应用与优化.md":"1ce1fdcd","notes_bak/demo/foo.md":"5460e585","notes_bak/机器学习/关于逻辑回归中的代价函数.md":"9605ed12","notes_bak/demo/bar.md":"3f850c9e","notes_bak/大语言模型学习/RL强化学习基础/DPO直接偏好优化/人类建模偏好角度理解DPO.md":"406296ac","notes_bak/大语言模型学习/RL强化学习基础/LoRA及其变体/LoRA-FA.md":"563e5f02","notes_bak/大语言模型学习/大模型应用/RAG检索增强生成/RAG方向.md":"3c49e152","notes_bak/大语言模型学习/大模型应用/RAG检索增强生成/常见索引优化算法实现.md":"19f804bb","notes_bak/c++ primer plus/导航.md":"114250cf","notes_bak/transformer/导航.md":"67110568","notes_bak/leetcode/导航.md":"38405c2a","notes_bak/毕业设计/导航.md":"f82bd366","notes_bak/机器学习/导航.md":"2b824499","notes_bak/thino/导航.md":"8b2484a4"}
