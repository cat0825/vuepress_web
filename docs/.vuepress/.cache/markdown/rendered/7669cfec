{"content":"<h2 id=\"元数据\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#元数据\"><span>元数据</span></a></h2>\n<ul>\n<li>分类：人工智能</li>\n<li>标签：ChatGLM3, 模型优化, 人工智能, 机器学习</li>\n<li>日期：2025年4月12日</li>\n</ul>\n<h2 id=\"内容概述\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#内容概述\"><span>内容概述</span></a></h2>\n<p>ChatGLM3 是 ChatGLM 系列的最新版本，其模型结构与 ChatGLM2 完全一致，但与初代 ChatGLM 有显著不同。本文将详细探讨 ChatGLM2 和 ChatGLM3 的优化和变化。</p>\n<h2 id=\"主要优化点\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#主要优化点\"><span>主要优化点</span></a></h2>\n<h3 id=\"词表大小调整\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#词表大小调整\"><span>词表大小调整</span></a></h3>\n<p>相对于初代 ChatGLM，ChatGLM2 和 ChatGLM3 将词表大小从 150,528 缩小至 65,024。这一改变使得模型加载速度显著提升。</p>\n<h3 id=\"位置编码改进\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#位置编码改进\"><span>位置编码改进</span></a></h3>\n<p>位置编码从每个 GLMBlock 独立配置，改为在全局共享一份。这种改进提高了模型的效率和一致性。</p>\n<h3 id=\"前馈网络激活函数更改\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#前馈网络激活函数更改\"><span>前馈网络激活函数更改</span></a></h3>\n<ul>\n<li><strong>ChatGLM</strong> 使用 GeLU 激活函数。</li>\n<li><strong>ChatGLM2 和 ChatGLM3</strong> 则采用 SwiGLU 激活函数，提供了更好的性能表现。</li>\n</ul>\n<h2 id=\"操作步骤\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#操作步骤\"><span>操作步骤</span></a></h2>\n<ol>\n<li>✅ 确认词表大小调整至 65,024。</li>\n<li>⚠ 检查位置编码是否已全局共享。</li>\n<li>❗ 确认前馈网络激活函数已更改为 SwiGLU。</li>\n</ol>\n<h2 id=\"常见错误\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#常见错误\"><span>常见错误</span></a></h2>\n<blockquote>\n<p>在进行模型加载时，未能正确缩小词表大小可能导致加载速度减慢。</p>\n</blockquote>\n<h2 id=\"💡启发点\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#💡启发点\"><span>💡启发点</span></a></h2>\n<ul>\n<li>通过合理缩小词表大小和优化位置编码，模型性能可以显著提升。</li>\n<li>激活函数的选择对模型性能有直接影响。</li>\n</ul>\n<h2 id=\"数据表格\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#数据表格\"><span>数据表格</span></a></h2>\n<table>\n<thead>\n<tr>\n<th>模型版本</th>\n<th>词表大小</th>\n<th>激活函数</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>ChatGLM</td>\n<td>150,528</td>\n<td>GeLU</td>\n</tr>\n<tr>\n<td>ChatGLM2</td>\n<td>65,024</td>\n<td>SwiGLU</td>\n</tr>\n<tr>\n<td>ChatGLM3</td>\n<td>65,024</td>\n<td>SwiGLU</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"行动清单\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#行动清单\"><span>行动清单</span></a></h2>\n<ul>\n<li>研究更多激活函数对模型性能的影响。</li>\n<li>探索进一步优化位置编码的方法。</li>\n<li>测试不同词表大小对加载速度的具体影响。</li>\n</ul>\n<blockquote>\n<p>原始出处：<a href=\"https://github.com/THUDM/ChatGLM3\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a></p>\n</blockquote>\n","env":{"base":"/","filePath":"/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Common Models常见模型/GLM系列/GLM3.md","filePathRelative":"notes_bak/大语言模型学习/Common Models常见模型/GLM系列/GLM3.md","frontmatter":{"dg-publish":true,"dg-permalink":"/大语言模型学习/Common-Models常见模型/GLM系列/GLM3","dg-home":false,"dg-description":"在此输入笔记的描述","dg-hide":false,"dg-hide-title":false,"dg-show-backlinks":true,"dg-show-local-graph":true,"dg-show-inline-title":true,"dg-pinned":false,"dg-passphrase":"在此输入访问密码","dg-enable-mathjax":false,"dg-enable-mermaid":false,"dg-enable-uml":false,"dg-note-icon":0,"dg-enable-dataview":false,"tags":["NLP"],"permalink":"/大语言模型学习/Common-Models常见模型/GLM系列/GLM3/","dgShowBacklinks":true,"dgShowLocalGraph":true,"dgShowInlineTitle":true,"dgPassFrontmatter":true,"noteIcon":0,"created":"2025-04-25T02:50:12.000Z","updated":"2025-04-25T02:51:06.000Z","title":"GLM3","createTime":"2025/05/13 17:33:53"},"sfcBlocks":{"template":{"type":"template","content":"<template><h2 id=\"元数据\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#元数据\"><span>元数据</span></a></h2>\n<ul>\n<li>分类：人工智能</li>\n<li>标签：ChatGLM3, 模型优化, 人工智能, 机器学习</li>\n<li>日期：2025年4月12日</li>\n</ul>\n<h2 id=\"内容概述\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#内容概述\"><span>内容概述</span></a></h2>\n<p>ChatGLM3 是 ChatGLM 系列的最新版本，其模型结构与 ChatGLM2 完全一致，但与初代 ChatGLM 有显著不同。本文将详细探讨 ChatGLM2 和 ChatGLM3 的优化和变化。</p>\n<h2 id=\"主要优化点\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#主要优化点\"><span>主要优化点</span></a></h2>\n<h3 id=\"词表大小调整\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#词表大小调整\"><span>词表大小调整</span></a></h3>\n<p>相对于初代 ChatGLM，ChatGLM2 和 ChatGLM3 将词表大小从 150,528 缩小至 65,024。这一改变使得模型加载速度显著提升。</p>\n<h3 id=\"位置编码改进\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#位置编码改进\"><span>位置编码改进</span></a></h3>\n<p>位置编码从每个 GLMBlock 独立配置，改为在全局共享一份。这种改进提高了模型的效率和一致性。</p>\n<h3 id=\"前馈网络激活函数更改\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#前馈网络激活函数更改\"><span>前馈网络激活函数更改</span></a></h3>\n<ul>\n<li><strong>ChatGLM</strong> 使用 GeLU 激活函数。</li>\n<li><strong>ChatGLM2 和 ChatGLM3</strong> 则采用 SwiGLU 激活函数，提供了更好的性能表现。</li>\n</ul>\n<h2 id=\"操作步骤\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#操作步骤\"><span>操作步骤</span></a></h2>\n<ol>\n<li>✅ 确认词表大小调整至 65,024。</li>\n<li>⚠ 检查位置编码是否已全局共享。</li>\n<li>❗ 确认前馈网络激活函数已更改为 SwiGLU。</li>\n</ol>\n<h2 id=\"常见错误\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#常见错误\"><span>常见错误</span></a></h2>\n<blockquote>\n<p>在进行模型加载时，未能正确缩小词表大小可能导致加载速度减慢。</p>\n</blockquote>\n<h2 id=\"💡启发点\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#💡启发点\"><span>💡启发点</span></a></h2>\n<ul>\n<li>通过合理缩小词表大小和优化位置编码，模型性能可以显著提升。</li>\n<li>激活函数的选择对模型性能有直接影响。</li>\n</ul>\n<h2 id=\"数据表格\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#数据表格\"><span>数据表格</span></a></h2>\n<table>\n<thead>\n<tr>\n<th>模型版本</th>\n<th>词表大小</th>\n<th>激活函数</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>ChatGLM</td>\n<td>150,528</td>\n<td>GeLU</td>\n</tr>\n<tr>\n<td>ChatGLM2</td>\n<td>65,024</td>\n<td>SwiGLU</td>\n</tr>\n<tr>\n<td>ChatGLM3</td>\n<td>65,024</td>\n<td>SwiGLU</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"行动清单\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#行动清单\"><span>行动清单</span></a></h2>\n<ul>\n<li>研究更多激活函数对模型性能的影响。</li>\n<li>探索进一步优化位置编码的方法。</li>\n<li>测试不同词表大小对加载速度的具体影响。</li>\n</ul>\n<blockquote>\n<p>原始出处：<a href=\"https://github.com/THUDM/ChatGLM3\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a></p>\n</blockquote>\n</template>","contentStripped":"<h2 id=\"元数据\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#元数据\"><span>元数据</span></a></h2>\n<ul>\n<li>分类：人工智能</li>\n<li>标签：ChatGLM3, 模型优化, 人工智能, 机器学习</li>\n<li>日期：2025年4月12日</li>\n</ul>\n<h2 id=\"内容概述\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#内容概述\"><span>内容概述</span></a></h2>\n<p>ChatGLM3 是 ChatGLM 系列的最新版本，其模型结构与 ChatGLM2 完全一致，但与初代 ChatGLM 有显著不同。本文将详细探讨 ChatGLM2 和 ChatGLM3 的优化和变化。</p>\n<h2 id=\"主要优化点\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#主要优化点\"><span>主要优化点</span></a></h2>\n<h3 id=\"词表大小调整\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#词表大小调整\"><span>词表大小调整</span></a></h3>\n<p>相对于初代 ChatGLM，ChatGLM2 和 ChatGLM3 将词表大小从 150,528 缩小至 65,024。这一改变使得模型加载速度显著提升。</p>\n<h3 id=\"位置编码改进\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#位置编码改进\"><span>位置编码改进</span></a></h3>\n<p>位置编码从每个 GLMBlock 独立配置，改为在全局共享一份。这种改进提高了模型的效率和一致性。</p>\n<h3 id=\"前馈网络激活函数更改\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#前馈网络激活函数更改\"><span>前馈网络激活函数更改</span></a></h3>\n<ul>\n<li><strong>ChatGLM</strong> 使用 GeLU 激活函数。</li>\n<li><strong>ChatGLM2 和 ChatGLM3</strong> 则采用 SwiGLU 激活函数，提供了更好的性能表现。</li>\n</ul>\n<h2 id=\"操作步骤\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#操作步骤\"><span>操作步骤</span></a></h2>\n<ol>\n<li>✅ 确认词表大小调整至 65,024。</li>\n<li>⚠ 检查位置编码是否已全局共享。</li>\n<li>❗ 确认前馈网络激活函数已更改为 SwiGLU。</li>\n</ol>\n<h2 id=\"常见错误\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#常见错误\"><span>常见错误</span></a></h2>\n<blockquote>\n<p>在进行模型加载时，未能正确缩小词表大小可能导致加载速度减慢。</p>\n</blockquote>\n<h2 id=\"💡启发点\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#💡启发点\"><span>💡启发点</span></a></h2>\n<ul>\n<li>通过合理缩小词表大小和优化位置编码，模型性能可以显著提升。</li>\n<li>激活函数的选择对模型性能有直接影响。</li>\n</ul>\n<h2 id=\"数据表格\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#数据表格\"><span>数据表格</span></a></h2>\n<table>\n<thead>\n<tr>\n<th>模型版本</th>\n<th>词表大小</th>\n<th>激活函数</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>ChatGLM</td>\n<td>150,528</td>\n<td>GeLU</td>\n</tr>\n<tr>\n<td>ChatGLM2</td>\n<td>65,024</td>\n<td>SwiGLU</td>\n</tr>\n<tr>\n<td>ChatGLM3</td>\n<td>65,024</td>\n<td>SwiGLU</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"行动清单\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#行动清单\"><span>行动清单</span></a></h2>\n<ul>\n<li>研究更多激活函数对模型性能的影响。</li>\n<li>探索进一步优化位置编码的方法。</li>\n<li>测试不同词表大小对加载速度的具体影响。</li>\n</ul>\n<blockquote>\n<p>原始出处：<a href=\"https://github.com/THUDM/ChatGLM3\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a></p>\n</blockquote>\n","tagOpen":"<template>","tagClose":"</template>"},"script":null,"scriptSetup":null,"scripts":[],"styles":[],"customBlocks":[]},"content":"\n## 元数据\n- 分类：人工智能\n- 标签：ChatGLM3, 模型优化, 人工智能, 机器学习\n- 日期：2025年4月12日\n\n\n## 内容概述\nChatGLM3 是 ChatGLM 系列的最新版本，其模型结构与 ChatGLM2 完全一致，但与初代 ChatGLM 有显著不同。本文将详细探讨 ChatGLM2 和 ChatGLM3 的优化和变化。\n\n\n## 主要优化点\n\n### 词表大小调整\n相对于初代 ChatGLM，ChatGLM2 和 ChatGLM3 将词表大小从 150,528 缩小至 65,024。这一改变使得模型加载速度显著提升。\n\n\n### 位置编码改进\n位置编码从每个 GLMBlock 独立配置，改为在全局共享一份。这种改进提高了模型的效率和一致性。\n\n\n### 前馈网络激活函数更改\n- **ChatGLM** 使用 GeLU 激活函数。\n- **ChatGLM2 和 ChatGLM3** 则采用 SwiGLU 激活函数，提供了更好的性能表现。\n\n\n## 操作步骤\n1. ✅ 确认词表大小调整至 65,024。\n2. ⚠ 检查位置编码是否已全局共享。\n3. ❗ 确认前馈网络激活函数已更改为 SwiGLU。\n\n\n## 常见错误\n> 在进行模型加载时，未能正确缩小词表大小可能导致加载速度减慢。\n\n\n## 💡启发点\n- 通过合理缩小词表大小和优化位置编码，模型性能可以显著提升。\n- 激活函数的选择对模型性能有直接影响。\n\n\n## 数据表格\n| 模型版本 | 词表大小 | 激活函数 |\n|----------|----------|----------|\n| ChatGLM  | 150,528  | GeLU     |\n| ChatGLM2 | 65,024   | SwiGLU   |\n| ChatGLM3 | 65,024   | SwiGLU   |\n\n\n## 行动清单\n- 研究更多激活函数对模型性能的影响。\n- 探索进一步优化位置编码的方法。\n- 测试不同词表大小对加载速度的具体影响。\n\n> 原始出处：[GitHub](https://github.com/THUDM/ChatGLM3)","excerpt":"","includedFiles":[],"tasklistId":0,"title":"","headers":[{"level":2,"title":"元数据","slug":"元数据","link":"#元数据","children":[]},{"level":2,"title":"内容概述","slug":"内容概述","link":"#内容概述","children":[]},{"level":2,"title":"主要优化点","slug":"主要优化点","link":"#主要优化点","children":[{"level":3,"title":"词表大小调整","slug":"词表大小调整","link":"#词表大小调整","children":[]},{"level":3,"title":"位置编码改进","slug":"位置编码改进","link":"#位置编码改进","children":[]},{"level":3,"title":"前馈网络激活函数更改","slug":"前馈网络激活函数更改","link":"#前馈网络激活函数更改","children":[]}]},{"level":2,"title":"操作步骤","slug":"操作步骤","link":"#操作步骤","children":[]},{"level":2,"title":"常见错误","slug":"常见错误","link":"#常见错误","children":[]},{"level":2,"title":"💡启发点","slug":"💡启发点","link":"#💡启发点","children":[]},{"level":2,"title":"数据表格","slug":"数据表格","link":"#数据表格","children":[]},{"level":2,"title":"行动清单","slug":"行动清单","link":"#行动清单","children":[]}]}}
