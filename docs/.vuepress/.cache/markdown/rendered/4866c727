{"content":"<h2 id=\"元数据\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#元数据\"><span>元数据</span></a></h2>\n<p>分类：深度学习显存优化</p>\n<p>标签：显存优化、大模型、GPU</p>\n<p>日期：2025年4月12日</p>\n<h2 id=\"内容总结\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#内容总结\"><span>内容总结</span></a></h2>\n<p>在深度学习中，随着大模型参数的增长，显存优化变得尤为重要。显存优化可以通过提高算法效率或扩大显存空间来实现。推理阶段的显存占用可以通过公式估算，而显存优化则需要从多方面着手，包括多卡并行、算子优化、数据类型修改等。</p>\n<h3 id=\"推理阶段显存分析\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#推理阶段显存分析\"><span>推理阶段显存分析</span></a></h3>\n<p>推理阶段的显存占用可以通过以下公式估算：</p>\n<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>I</mi><mi>n</mi><mi>f</mi><mi>e</mi><mi>r</mi><mi>M</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>r</mi><mi>y</mi><mo>≈</mo><mn>1.2</mn><mo>×</mo><mi>M</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi><mi>M</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>r</mi><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">InferMemory \\approx 1.2 \\times ModelMemory\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">er</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">m</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">ory</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">≈</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">1.2</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">d</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">lM</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">m</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">ory</span></span></span></span></span></p>\n<p>此公式帮助我们快速了解推理阶段的显存需求。</p>\n<h3 id=\"显存优化方法\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#显存优化方法\"><span>显存优化方法</span></a></h3>\n<p>显存优化方法包括：</p>\n<ul>\n<li><strong>多卡并行</strong>：使用频率最高的方法，通过设计新的参数来降低显存消耗。</li>\n<li><strong>算子优化</strong>：选择精度相同但显存消耗更低的算子。</li>\n<li><strong>数据类型修改</strong>：使用低精度数据替换高精度数据。</li>\n<li><strong>消除框架副本</strong>：优化AI框架中产生的中间副本。</li>\n<li><strong>显存管理</strong>：通过优化显存管理减少碎片。</li>\n<li><strong>底层API替换</strong>：使用更节省显存的API替换默认操作。</li>\n</ul>\n<p>💡启发点：这些方法不仅能降低显存消耗，还可能提高计算效率。</p>\n<h2 id=\"操作步骤\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#操作步骤\"><span>操作步骤</span></a></h2>\n<ol>\n<li>✅ 使用多卡并行设计新的参数。</li>\n<li>⚠ 选择精度相同但显存消耗更低的算子。</li>\n<li>❗ 使用低精度数据替换高精度数据。</li>\n</ol>\n<h2 id=\"常见错误\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#常见错误\"><span>常见错误</span></a></h2>\n<blockquote>\n<p>在进行数据类型修改时，可能会影响训练收敛性或推理性能。</p>\n</blockquote>\n<h2 id=\"行动清单\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#行动清单\"><span>行动清单</span></a></h2>\n<ul>\n<li>研究多卡并行策略以进一步降低显存消耗。</li>\n<li>探索更节省显存的算子和API。</li>\n<li>优化AI框架的显存管理。</li>\n</ul>\n<blockquote>\n<p>原始出处：<a href=\"https://kipp.ly/transformer-inference-arithmetic/\" target=\"_blank\" rel=\"noopener noreferrer\">推理阶段显存分析</a></p>\n</blockquote>\n<p>以上是关于显存优化与推理阶段显存分析的博客笔记，希望对您有所帮助。</p>\n","env":{"base":"/","filePath":"/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/训练推理优化/训练推理显存占用分析/显存优化与推理显存分析.md","filePathRelative":"notes_bak/大语言模型学习/训练推理优化/训练推理显存占用分析/显存优化与推理显存分析.md","frontmatter":{"dg-publish":true,"dg-permalink":"/大语言模型学习/训练推理优化/训练推理显存占用分析/显存优化与推理显存分析","dg-home":false,"dg-description":"在此输入笔记的描述","dg-hide":false,"dg-hide-title":false,"dg-show-backlinks":true,"dg-show-local-graph":true,"dg-show-inline-title":true,"dg-pinned":false,"dg-passphrase":"在此输入访问密码","dg-enable-mathjax":false,"dg-enable-mermaid":false,"dg-enable-uml":false,"dg-note-icon":0,"dg-enable-dataview":false,"tags":["NLP"],"permalink":"/大语言模型学习/训练推理优化/训练推理显存占用分析/显存优化与推理显存分析/","dgShowBacklinks":true,"dgShowLocalGraph":true,"dgShowInlineTitle":true,"dgPassFrontmatter":true,"noteIcon":0,"created":"2025-04-28T14:18:54.000Z","updated":"2025-04-29T03:00:58.000Z","title":"显存优化与推理显存分析","createTime":"2025/05/13 17:33:53"},"sfcBlocks":{"template":{"type":"template","content":"<template><h2 id=\"元数据\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#元数据\"><span>元数据</span></a></h2>\n<p>分类：深度学习显存优化</p>\n<p>标签：显存优化、大模型、GPU</p>\n<p>日期：2025年4月12日</p>\n<h2 id=\"内容总结\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#内容总结\"><span>内容总结</span></a></h2>\n<p>在深度学习中，随着大模型参数的增长，显存优化变得尤为重要。显存优化可以通过提高算法效率或扩大显存空间来实现。推理阶段的显存占用可以通过公式估算，而显存优化则需要从多方面着手，包括多卡并行、算子优化、数据类型修改等。</p>\n<h3 id=\"推理阶段显存分析\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#推理阶段显存分析\"><span>推理阶段显存分析</span></a></h3>\n<p>推理阶段的显存占用可以通过以下公式估算：</p>\n<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>I</mi><mi>n</mi><mi>f</mi><mi>e</mi><mi>r</mi><mi>M</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>r</mi><mi>y</mi><mo>≈</mo><mn>1.2</mn><mo>×</mo><mi>M</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi><mi>M</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>r</mi><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">InferMemory \\approx 1.2 \\times ModelMemory\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">er</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">m</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">ory</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">≈</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">1.2</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">d</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">lM</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">m</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">ory</span></span></span></span></span></p>\n<p>此公式帮助我们快速了解推理阶段的显存需求。</p>\n<h3 id=\"显存优化方法\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#显存优化方法\"><span>显存优化方法</span></a></h3>\n<p>显存优化方法包括：</p>\n<ul>\n<li><strong>多卡并行</strong>：使用频率最高的方法，通过设计新的参数来降低显存消耗。</li>\n<li><strong>算子优化</strong>：选择精度相同但显存消耗更低的算子。</li>\n<li><strong>数据类型修改</strong>：使用低精度数据替换高精度数据。</li>\n<li><strong>消除框架副本</strong>：优化AI框架中产生的中间副本。</li>\n<li><strong>显存管理</strong>：通过优化显存管理减少碎片。</li>\n<li><strong>底层API替换</strong>：使用更节省显存的API替换默认操作。</li>\n</ul>\n<p>💡启发点：这些方法不仅能降低显存消耗，还可能提高计算效率。</p>\n<h2 id=\"操作步骤\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#操作步骤\"><span>操作步骤</span></a></h2>\n<ol>\n<li>✅ 使用多卡并行设计新的参数。</li>\n<li>⚠ 选择精度相同但显存消耗更低的算子。</li>\n<li>❗ 使用低精度数据替换高精度数据。</li>\n</ol>\n<h2 id=\"常见错误\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#常见错误\"><span>常见错误</span></a></h2>\n<blockquote>\n<p>在进行数据类型修改时，可能会影响训练收敛性或推理性能。</p>\n</blockquote>\n<h2 id=\"行动清单\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#行动清单\"><span>行动清单</span></a></h2>\n<ul>\n<li>研究多卡并行策略以进一步降低显存消耗。</li>\n<li>探索更节省显存的算子和API。</li>\n<li>优化AI框架的显存管理。</li>\n</ul>\n<blockquote>\n<p>原始出处：<a href=\"https://kipp.ly/transformer-inference-arithmetic/\" target=\"_blank\" rel=\"noopener noreferrer\">推理阶段显存分析</a></p>\n</blockquote>\n<p>以上是关于显存优化与推理阶段显存分析的博客笔记，希望对您有所帮助。</p>\n</template>","contentStripped":"<h2 id=\"元数据\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#元数据\"><span>元数据</span></a></h2>\n<p>分类：深度学习显存优化</p>\n<p>标签：显存优化、大模型、GPU</p>\n<p>日期：2025年4月12日</p>\n<h2 id=\"内容总结\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#内容总结\"><span>内容总结</span></a></h2>\n<p>在深度学习中，随着大模型参数的增长，显存优化变得尤为重要。显存优化可以通过提高算法效率或扩大显存空间来实现。推理阶段的显存占用可以通过公式估算，而显存优化则需要从多方面着手，包括多卡并行、算子优化、数据类型修改等。</p>\n<h3 id=\"推理阶段显存分析\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#推理阶段显存分析\"><span>推理阶段显存分析</span></a></h3>\n<p>推理阶段的显存占用可以通过以下公式估算：</p>\n<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>I</mi><mi>n</mi><mi>f</mi><mi>e</mi><mi>r</mi><mi>M</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>r</mi><mi>y</mi><mo>≈</mo><mn>1.2</mn><mo>×</mo><mi>M</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi><mi>M</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>r</mi><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">InferMemory \\approx 1.2 \\times ModelMemory\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">er</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">m</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">ory</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">≈</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">1.2</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">d</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">lM</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">m</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">ory</span></span></span></span></span></p>\n<p>此公式帮助我们快速了解推理阶段的显存需求。</p>\n<h3 id=\"显存优化方法\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#显存优化方法\"><span>显存优化方法</span></a></h3>\n<p>显存优化方法包括：</p>\n<ul>\n<li><strong>多卡并行</strong>：使用频率最高的方法，通过设计新的参数来降低显存消耗。</li>\n<li><strong>算子优化</strong>：选择精度相同但显存消耗更低的算子。</li>\n<li><strong>数据类型修改</strong>：使用低精度数据替换高精度数据。</li>\n<li><strong>消除框架副本</strong>：优化AI框架中产生的中间副本。</li>\n<li><strong>显存管理</strong>：通过优化显存管理减少碎片。</li>\n<li><strong>底层API替换</strong>：使用更节省显存的API替换默认操作。</li>\n</ul>\n<p>💡启发点：这些方法不仅能降低显存消耗，还可能提高计算效率。</p>\n<h2 id=\"操作步骤\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#操作步骤\"><span>操作步骤</span></a></h2>\n<ol>\n<li>✅ 使用多卡并行设计新的参数。</li>\n<li>⚠ 选择精度相同但显存消耗更低的算子。</li>\n<li>❗ 使用低精度数据替换高精度数据。</li>\n</ol>\n<h2 id=\"常见错误\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#常见错误\"><span>常见错误</span></a></h2>\n<blockquote>\n<p>在进行数据类型修改时，可能会影响训练收敛性或推理性能。</p>\n</blockquote>\n<h2 id=\"行动清单\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#行动清单\"><span>行动清单</span></a></h2>\n<ul>\n<li>研究多卡并行策略以进一步降低显存消耗。</li>\n<li>探索更节省显存的算子和API。</li>\n<li>优化AI框架的显存管理。</li>\n</ul>\n<blockquote>\n<p>原始出处：<a href=\"https://kipp.ly/transformer-inference-arithmetic/\" target=\"_blank\" rel=\"noopener noreferrer\">推理阶段显存分析</a></p>\n</blockquote>\n<p>以上是关于显存优化与推理阶段显存分析的博客笔记，希望对您有所帮助。</p>\n","tagOpen":"<template>","tagClose":"</template>"},"script":null,"scriptSetup":null,"scripts":[],"styles":[],"customBlocks":[]},"content":"## 元数据\n分类：深度学习显存优化\n\n标签：显存优化、大模型、GPU\n\n日期：2025年4月12日\n\n\n\n## 内容总结\n在深度学习中，随着大模型参数的增长，显存优化变得尤为重要。显存优化可以通过提高算法效率或扩大显存空间来实现。推理阶段的显存占用可以通过公式估算，而显存优化则需要从多方面着手，包括多卡并行、算子优化、数据类型修改等。\n\n### 推理阶段显存分析\n推理阶段的显存占用可以通过以下公式估算：\n\n$$\nInferMemory \\approx 1.2 \\times ModelMemory\n$$\n\n此公式帮助我们快速了解推理阶段的显存需求。\n\n\n### 显存优化方法\n显存优化方法包括：\n\n- **多卡并行**：使用频率最高的方法，通过设计新的参数来降低显存消耗。\n- **算子优化**：选择精度相同但显存消耗更低的算子。\n- **数据类型修改**：使用低精度数据替换高精度数据。\n- **消除框架副本**：优化AI框架中产生的中间副本。\n- **显存管理**：通过优化显存管理减少碎片。\n- **底层API替换**：使用更节省显存的API替换默认操作。\n\n💡启发点：这些方法不仅能降低显存消耗，还可能提高计算效率。\n\n\n\n## 操作步骤\n1. ✅ 使用多卡并行设计新的参数。\n2. ⚠ 选择精度相同但显存消耗更低的算子。\n3. ❗ 使用低精度数据替换高精度数据。\n\n\n\n## 常见错误\n> 在进行数据类型修改时，可能会影响训练收敛性或推理性能。\n\n\n\n## 行动清单\n- 研究多卡并行策略以进一步降低显存消耗。\n- 探索更节省显存的算子和API。\n- 优化AI框架的显存管理。\n\n> 原始出处：[推理阶段显存分析](https://kipp.ly/transformer-inference-arithmetic/)\n\n以上是关于显存优化与推理阶段显存分析的博客笔记，希望对您有所帮助。","excerpt":"","includedFiles":[],"tasklistId":0,"title":"","headers":[{"level":2,"title":"元数据","slug":"元数据","link":"#元数据","children":[]},{"level":2,"title":"内容总结","slug":"内容总结","link":"#内容总结","children":[{"level":3,"title":"推理阶段显存分析","slug":"推理阶段显存分析","link":"#推理阶段显存分析","children":[]},{"level":3,"title":"显存优化方法","slug":"显存优化方法","link":"#显存优化方法","children":[]}]},{"level":2,"title":"操作步骤","slug":"操作步骤","link":"#操作步骤","children":[]},{"level":2,"title":"常见错误","slug":"常见错误","link":"#常见错误","children":[]},{"level":2,"title":"行动清单","slug":"行动清单","link":"#行动清单","children":[]}]}}
