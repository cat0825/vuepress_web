---
title: 大语言模型学习导航
createTime: 2025/05/13 17:33:52
permalink: /article/zx5zbgr5/
---

# 大语言模型学习导航

## 1. 基础概念

### 1.1 分词
- [介绍](/大语言模型学习/词嵌入/介绍)
- [oneHot](/大语言模型学习/词嵌入/oneHot)
- [Word2Vec](/大语言模型学习/词嵌入/Word2Vec)
- [FastText](/大语言模型学习/词嵌入/FastText)

### 1.2 词嵌入
- [介绍](/大语言模型学习/词嵌入/介绍)
- [oneHot](/大语言模型学习/词嵌入/oneHot)
- [Word2Vec](/大语言模型学习/词嵌入/Word2Vec)
- [FastText](/大语言模型学习/词嵌入/FastText)

## 2. 核心机制

### 2.1 Attention
- [Attention机制详解与应用](/大语言模型学习/Attention注意力机制/Attention机制详解与应用)
- [Transformer中的Attention详解与应用指南](/大语言模型学习/Attention注意力机制/Transformer中的Attention详解与应用指南)
- [优化Attention计算复杂度的技术探讨](/大语言模型学习/Attention注意力机制/优化Attention计算复杂度的技术探讨)
- [KV Cache技术详解](/大语言模型学习/Attention注意力机制/KV-Cache技术详解)
- [深度学习中的注意力机制优化：从MHA到MLA](/大语言模型学习/Attention注意力机制/深度学习中的注意力机制优化：从MHA到MLA)
- [DCA：长文本处理的新突破](/大语言模型学习/Attention注意力机制/DCA：长文本处理的新突破（Dual-Chunk-Attention）)
- [基于Shifted Sparse Attention的创新方法](/大语言模型学习/Attention注意力机制/长上下文模型优化-基于Shifted-Sparse-Attention的创新方法)

### 2.2 FFN, Add & LN
- [Transformer核心模块解析](/大语言模型学习/FFN-Add-LN-的作用与应用/Transformer核心模块解析：FFN-Add-LN-的作用与应用)
- [Layer Norm设计比较](/大语言模型学习/FFN-Add-LN-的作用与应用/深度学习中的Layer-Norm设计：Post-Norm-Pre-Norm与Sandwich-Norm比较)
- [激活函数与FFN结构优化](/大语言模型学习/FFN-Add-LN-的作用与应用/激活函数与FFN结构优化：SwiGLU-GeGLU及其应用解析)
- [激活函数详解与比较](/大语言模型学习/FFN-Add-LN-的作用与应用/激活函数详解与比较：从Sigmoid到Swish)

### 2.3 Positional Encoding
- [介绍](/大语言模型学习/Positional-Encoding位置编码/介绍)
- [绝对位置编码详解](/大语言模型学习/Positional-Encoding位置编码/绝对位置编码/Transformer绝对位置编码详解与改进分析)
- [BERT与RNN位置编码对比](/大语言模型学习/Positional-Encoding位置编码/绝对位置编码/BERT与RNN位置编码的对比与应用)
- [相对位置编码详解](/大语言模型学习/Positional-Encoding位置编码/相对位置编码/相对位置编码与XLNet位置编码详解-深入理解Transformer机制)
- [T5模型位置编码优化](/大语言模型学习/Positional-Encoding位置编码/相对位置编码/T5模型与相对位置编码优化解析)
- [DeBERTa位置编码解析](/大语言模型学习/Positional-Encoding位置编码/相对位置编码/DeBERTa的相对位置编码与绝对位置编码解析)
- [旋转位置编码与ALiBi](/大语言模型学习/Positional-Encoding位置编码/旋转位置编码与ALiBi：深度学习中的位置嵌入优化)
- [数字输入优化与外推方法](/大语言模型学习/Positional-Encoding位置编码/数字输入优化与外推方法解析)
- [位置内插法扩展上下文](/大语言模型学习/Positional-Encoding位置编码/位置内插法扩展语言模型上下文长度)
- [NTK插值方法解析](/大语言模型学习/Positional-Encoding位置编码/NTK插值方法解析与优化：从NTK-aware到NTK-by-parts)
- [YaRN方法解析](/大语言模型学习/Positional-Encoding位置编码/YaRN方法解析：扩展RoPE嵌入与注意力优化的实践)

## 3. 模型结构与训练

### 3.1 结构与解码策略
- [大模型结构与混合专家](/大语言模型学习/Structure-Decoding-Policy-结构和解码策略/大模型结构与混合专家（LLM-MoE）解析)
- [解码采样策略](/大语言模型学习/Structure-Decoding-Policy-结构和解码策略/解码采样策略：Greedy-Search与Beam-Search的实现与优化)
- [语言模型采样方法](/大语言模型学习/Structure-Decoding-Policy-结构和解码策略/深度解析语言模型采样方法：Top-K-Top-P-Temperature及综合策略)

### 3.2 预训练
- [预训练定义与数据来源](/大语言模型学习/Pre-training-预训练/预训练定义以及数据来源)
- [数据爬取](/大语言模型学习/Pre-training-预训练/数据爬取)
- [数据清洗](/大语言模型学习/Pre-training-预训练/数据清洗)
- [模型打分与数据去重](/大语言模型学习/Pre-training-预训练/模型打分与数据去重)
- [数据多样性与模型优化](/大语言模型学习/Pre-training-预训练/数据多样性与模型优化探索)
- [数据配比与训练顺序](/大语言模型学习/Pre-training-预训练/数据配比与训练顺序优化指南)
- [训练Tokenizer](/大语言模型学习/Pre-training-预训练/预训练过程/训练Tokenizer)
- [训练框架选择与优化](/大语言模型学习/Pre-training-预训练/预训练过程/高效深度学习模型训练框架选择与优化指南)
- [预训练策略](/大语言模型学习/Pre-training-预训练/预训练过程/预训练策略)
- [训练容灾及监控](/大语言模型学习/Pre-training-预训练/训练容灾及训练监控)
- [预训练的Scaling Law](/大语言模型学习/Pre-training-预训练/预训练过程/预训练的Scaling-Law)
- [混合精度训练](/大语言模型学习/Pre-training-预训练/混合精度训练)
- [显存优化与梯度处理](/大语言模型学习/Pre-training-预训练/深度学习中的显存优化与梯度处理方法)
- [继续预训练](/大语言模型学习/Pre-training-预训练/继续预训练)
- [推理耗时](/大语言模型学习/Pre-training-预训练/推理耗时)
- [预训练评估](/大语言模型学习/Pre-training-预训练/预训练评估)
- [预训练评估2](/大语言模型学习/Pre-training-预训练/预训练评估2)

### 3.3 后训练
- [监督微调与预训练的区别](/大语言模型学习/后训练/SFT监督微调/监督微调与预训练的区别)
- [数据飞轮应用](/大语言模型学习/后训练/SFT监督微调/SFT数据及处理/数据飞轮在SFT中的应用与优化)
- [数据生产合成与质量过滤](/大语言模型学习/后训练/SFT监督微调/SFT数据及处理/数据生产合成与质量过滤)
- [数据多样性探索](/大语言模型学习/后训练/SFT监督微调/SFT数据及处理/数据多样性探索)
- [开源数据集](/大语言模型学习/后训练/SFT监督微调/SFT数据及处理/开源数据集)
- [训练框架及参数设置](/大语言模型学习/后训练/SFT监督微调/STF训练/训练框架及参数设置)
- [训练技巧和训练策略](/大语言模型学习/后训练/SFT监督微调/STF训练/训练技巧和训练策略)
- [多轮对话专项提升](/大语言模型学习/后训练/SFT监督微调/STF训练/多轮对话专项提升)
- [多轮对话专项提升2](/大语言模型学习/后训练/SFT监督微调/STF训练/多轮对话专项提升2)
- [训练启动脚本](/大语言模型学习/后训练/SFT监督微调/STF训练/训练启动脚本)

## 4. 强化学习与优化

### 4.1 强化学习基础
- [强化学习问题与流程](/大语言模型学习/RL强化学习基础/强化学习问题,流程)
- [强化学习的独特性](/大语言模型学习/RL强化学习基础/强化学习的独特性)
- [马尔可夫决策过程](/大语言模型学习/RL强化学习基础/马尔可夫决策过程)
- [贝尔曼方程](/大语言模型学习/RL强化学习基础/贝尔曼方程)
- [蒙特卡洛方法](/大语言模型学习/RL强化学习基础/蒙特卡洛方法)
- [策略迭代算法](/大语言模型学习/RL强化学习基础/策略迭代算法)
- [价值迭代算法](/大语言模型学习/RL强化学习基础/价值迭代算法)
- [时序差分算法](/大语言模型学习/RL强化学习基础/时序差分算法)
- [SARSA算法](/大语言模型学习/RL强化学习基础/SARSA算法)
- [SARSA-λ与Q-learning对比](/大语言模型学习/RL强化学习基础/SARSA-λ与Q-learning对比)
- [强化学习分类](/大语言模型学习/RL强化学习基础/强化学习分类)
- [深度Q网络](/大语言模型学习/RL强化学习基础/深度Q网络)
- [策略梯度算法](/大语言模型学习/RL强化学习基础/策略梯度算法)
- [Actor-Critic算法](/大语言模型学习/RL强化学习基础/Actor-Critic算法)
- [PPO算法](/大语言模型学习/RL强化学习基础/PPO算法)
- [RL在NLP场景下的拓展](/大语言模型学习/RL强化学习基础/RL在NLP场景下的拓展)

### 4.2 RLHF
- [RLHF流程](/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/RLHF流程)
- [RLHF研究方法总结](/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/RLHF研究方法及研究总结)
- [Instruct-GPT](/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/Instruct-GPT)
- [Actor-Model](/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/Actor-Model)
- [Critic-Model](/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/critic-model)
- [Reward-Model](/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/Reward-Model)
- [Prompt到Response的MDP模型](/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/深入理解Prompt到Response的MDP模型分析)
- [Reference-Model](/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/Reference-Model)
- [在线与离线RLHF比较](/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/在线与离线RLHF的比较与应用)

### 4.3 PPO优化
- [PPO训练的trick和问题](/大语言模型学习/RL强化学习基础/PPO训练的trick和问题)
- [GRPO](/大语言模型学习/RL强化学习基础/优化PPO方向的算法/GRPO)
- [ReMax-improvement](/大语言模型学习/RL强化学习基础/优化PPO方向的算法/ReMax-improvement)
- [ReMax](/大语言模型学习/RL强化学习基础/优化PPO方向的算法/ReMax)
- [RLOO与REINFORCE++](/大语言模型学习/RL强化学习基础/优化PPO方向的算法/REINFORCE算法改进：RLOO与REINFORCE++)
- [DAPO](/大语言模型学习/RL强化学习基础/优化PPO方向的算法/DAPO)
- [VAPO](/大语言模型学习/RL强化学习基础/优化PPO方向的算法/VAPO)

### 4.4 DPO
- [DPO介绍及RLHF-PPO缺点](/大语言模型学习/RL强化学习基础/DPO直接偏好优化/DPO介绍及RLHF-PPO缺点)
- [DPO公式推导](/大语言模型学习/RL强化学习基础/DPO直接偏好优化/DPO公式推导)
- [DPO损失函数解析](/大语言模型学习/RL强化学习基础/DPO直接偏好优化/深度偏好优化（DPO）损失函数解析与代码示例)
- [人类建模偏好角度理解DPO](/大语言模型学习/RL强化学习基础/DPO直接偏好优化/人类建模偏好角度理解DPO)
- [对比学习角度理解DPO](/大语言模型学习/RL强化学习基础/DPO直接偏好优化/对比学习角度理解DPO)

### 4.5 DPO优化
- [DPOP](/大语言模型学习/RL强化学习基础/优化DPO方向的算法/DPOP)
- [TDPO](/大语言模型学习/RL强化学习基础/优化DPO方向的算法/TDPO)
- [Self-Reward](/大语言模型学习/RL强化学习基础/优化DPO方向的算法/Self-Reward)

### 4.6 PEFT
- [介绍](/大语言模型学习/RL强化学习基础/PEFT参数高效微调/介绍)
- [Prompt Tuning](/大语言模型学习/RL强化学习基础/PEFT参数高效微调/Prompt-Tuning)
- [P-Tuning](/大语言模型学习/RL强化学习基础/PEFT参数高效微调/P-Tuning)
- [Prefix-Tuning](/大语言模型学习/RL强化学习基础/PEFT参数高效微调/Prefix-Tuning)
- [P-Tuning V2](/大语言模型学习/RL强化学习基础/PEFT参数高效微调/P-Tuning-V2)
- [LLaMA-Adapter](/大语言模型学习/RL强化学习基础/PEFT参数高效微调/LLaMA-Adapter)

### 4.7 LoRA
- [LoRA](/大语言模型学习/RL强化学习基础/LoRA及其变体/LoRA)
- [QLoRA](/大语言模型学习/RL强化学习基础/LoRA及其变体/QLoRA)
- [LoRA+](/大语言模型学习/RL强化学习基础/LoRA及其变体/LoRA+)
- [VeRA](/大语言模型学习/RL强化学习基础/LoRA及其变体/VeRA)
- [LoRA-FA](/大语言模型学习/RL强化学习基础/LoRA及其变体/LoRA-FA)
- [AdaLoRA](/大语言模型学习/RL强化学习基础/LoRA及其变体/AdaLoRA)
- [DoRA](/大语言模型学习/RL强化学习基础/LoRA及其变体/DoRA)
- [X-LoRA](/大语言模型学习/RL强化学习基础/LoRA及其变体/X-LoRA)
- [参考文献](/大语言模型学习/RL强化学习基础/LoRA及其变体/参考文献)

## 5. 常见模型

### 5.1 发展历史
- [介绍](/大语言模型学习/Common-Models常见模型/发展历史)

### 5.2 BERT系列
- [介绍](/大语言模型学习/Common-Models常见模型/BERT及其变体/介绍)
- [BART](/大语言模型学习/Common-Models常见模型/BERT及其变体/BART)
- [T5](/大语言模型学习/Common-Models常见模型/BERT及其变体/T5)
- [DeBERTa](/大语言模型学习/Common-Models常见模型/BERT及其变体/DeBERTa)
- [RoBERTa](/大语言模型学习/Common-Models常见模型/BERT及其变体/RoBERTa)

### 5.3 PaLM系列
- [PaLM](/大语言模型学习/Common-Models常见模型/PLaM系列/PLaM)
- [PaLM2](/大语言模型学习/Common-Models常见模型/PLaM系列/PLaM2)

### 5.4 GPT系列
- [GPT-1](/大语言模型学习/Common-Models常见模型/GPT系列/GPT-1)
- [GPT-2](/大语言模型学习/Common-Models常见模型/GPT系列/GPT-2)
- [GPT-3](/大语言模型学习/Common-Models常见模型/GPT系列/GPT-3)

### 5.5 LLaMA系列
- [LLaMA1](/大语言模型学习/Common-Models常见模型/LLama系列/LLaMA1)
- [LLaMA2](/大语言模型学习/Common-Models常见模型/LLama系列/LLama-2)
- [CodeLlama](/大语言模型学习/Common-Models常见模型/LLama系列/CodeLlama)
- [LLaMA3](/大语言模型学习/Common-Models常见模型/LLama系列/LLama-3)

### 5.6 GLM系列
- [GLM1](/大语言模型学习/Common-Models常见模型/GLM系列/GLM1)
- [GLM2](/大语言模型学习/Common-Models常见模型/GLM系列/GLM2)
- [GLM3](/大语言模型学习/Common-Models常见模型/GLM系列/GLM3)
- [GLM4](/大语言模型学习/Common-Models常见模型/GLM系列/GLM4)

### 5.7 Qwen系列
- [Qwen1](/大语言模型学习/Common-Models常见模型/Qwen系列/Qwen1)
- [Qwen2](/大语言模型学习/Common-Models常见模型/Qwen系列/Qwen2)
- [Qwen2.5](/大语言模型学习/Common-Models常见模型/Qwen系列/Qwen2.5)

### 5.8 DeepSeek系列
- [DeepSeek-V1](/大语言模型学习/Common-Models常见模型/DeepSeek系列/Deepseek-V1)
- [DeepSeek-math](/大语言模型学习/Common-Models常见模型/DeepSeek系列/Deepseek-math)
- [DeepSeek-V2](/大语言模型学习/Common-Models常见模型/DeepSeek系列/DeepSeek-V2)
- [DeepSeek-V3](/大语言模型学习/Common-Models常见模型/DeepSeek系列/DeepSeek-V3)
- [DeepSeek-R1](/大语言模型学习/Common-Models常见模型/DeepSeek系列/DeepSeek-R1)

### 5.9 MoE系列
- [GShard](/大语言模型学习/Common-Models常见模型/MOE系列/GShard)
- [Mistral](/大语言模型学习/Common-Models常见模型/MOE系列/Mistral)
- [Switch Transformer](/大语言模型学习/Common-Models常见模型/MOE系列/Switch-Transformer)

## 6. 训练推理优化

### 6.1 显存优化
- [模型显存总体分析](/大语言模型学习/训练推理优化/训练推理显存占用分析/模型显存总体分析)
- [训练阶段的显存分析](/大语言模型学习/训练推理优化/训练推理显存占用分析/训练阶段的显存分析)
- [显存优化与推理显存分析](/大语言模型学习/训练推理优化/训练推理显存占用分析/显存优化与推理显存分析)

### 6.2 FlashAttention
- [介绍](/大语言模型学习/训练推理优化/FlashAttention/介绍)
- [计算与内存限制](/大语言模型学习/训练推理优化/FlashAttention/计算与内存限制)
- [标准Attention与Safe softmax](/大语言模型学习/训练推理优化/FlashAttention/标准Attention与Safe-softmax)
- [FlashAttention Forward流程](/大语言模型学习/训练推理优化/FlashAttention/FlashAttention-Forword流程)

### 6.3 其他优化
- [PageAttention原理](/大语言模型学习/训练推理优化/PageAttention原理)
- [Megatron-LM](/大语言模型学习/训练推理优化/训练框架/Megatron-LM)
