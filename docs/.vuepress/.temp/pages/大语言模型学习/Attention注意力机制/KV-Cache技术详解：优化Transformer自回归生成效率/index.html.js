import comp from "/Users/qianyuhe/Desktop/my-project/docs/.vuepress/.temp/pages/大语言模型学习/Attention注意力机制/KV-Cache技术详解：优化Transformer自回归生成效率/index.html.vue"
const data = JSON.parse("{\"path\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/KV-Cache%E6%8A%80%E6%9C%AF%E8%AF%A6%E8%A7%A3%EF%BC%9A%E4%BC%98%E5%8C%96Transformer%E8%87%AA%E5%9B%9E%E5%BD%92%E7%94%9F%E6%88%90%E6%95%88%E7%8E%87/\",\"title\":\"KV Cache技术详解：优化Transformer自回归生成效率\",\"lang\":\"zh-CN\",\"frontmatter\":{\"dg-publish\":true,\"dg-permalink\":\"/大语言模型学习/Attention注意力机制/KV-Cache技术详解：优化Transformer自回归生成效率\",\"dg-home\":false,\"dg-description\":\"在此输入笔记的描述\",\"dg-hide\":false,\"dg-hide-title\":false,\"dg-show-backlinks\":true,\"dg-show-local-graph\":true,\"dg-show-inline-title\":true,\"dg-pinned\":false,\"dg-passphrase\":\"在此输入访问密码\",\"dg-enable-mathjax\":false,\"dg-enable-mermaid\":false,\"dg-enable-uml\":false,\"dg-note-icon\":0,\"dg-enable-dataview\":false,\"tags\":[\"NLP\"],\"permalink\":\"/大语言模型学习/Attention注意力机制/KV-Cache技术详解：优化Transformer自回归生成效率/\",\"dgShowBacklinks\":true,\"dgShowLocalGraph\":true,\"dgShowInlineTitle\":true,\"dgPassFrontmatter\":true,\"noteIcon\":0,\"created\":\"2025-04-04T03:10:49.000Z\",\"updated\":\"2025-04-13T05:06:02.000Z\",\"title\":\"KV Cache技术详解：优化Transformer自回归生成效率\",\"createTime\":\"2025/05/13 17:33:53\"},\"readingTime\":{\"minutes\":3.7,\"words\":1110},\"filePathRelative\":\"notes_bak/大语言模型学习/Attention注意力机制/KV Cache技术详解：优化Transformer自回归生成效率.md\",\"headers\":[],\"categoryList\":[{\"id\":\"9672d7\",\"sort\":10001,\"name\":\"notes_bak\"},{\"id\":\"c8d1d7\",\"sort\":10006,\"name\":\"大语言模型学习\"},{\"id\":\"d92a1b\",\"sort\":10009,\"name\":\"Attention注意力机制\"}]}")
export { comp, data }

if (import.meta.webpackHot) {
  import.meta.webpackHot.accept()
  if (__VUE_HMR_RUNTIME__.updatePageData) {
    __VUE_HMR_RUNTIME__.updatePageData(data)
  }
}

if (import.meta.hot) {
  import.meta.hot.accept(({ data }) => {
    __VUE_HMR_RUNTIME__.updatePageData(data)
  })
}
