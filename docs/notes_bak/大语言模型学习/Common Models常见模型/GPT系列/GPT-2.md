---
dg-publish: true
dg-permalink: /å¤§è¯­è¨€æ¨¡å‹å­¦ä¹ /Common-Modelså¸¸è§æ¨¡å‹/GPTç³»åˆ—/GPT-2
dg-home: false
dg-description: åœ¨æ­¤è¾“å…¥ç¬”è®°çš„æè¿°
dg-hide: false
dg-hide-title: false
dg-show-backlinks: true
dg-show-local-graph: true
dg-show-inline-title: true
dg-pinned: false
dg-passphrase: åœ¨æ­¤è¾“å…¥è®¿é—®å¯†ç 
dg-enable-mathjax: false
dg-enable-mermaid: false
dg-enable-uml: false
dg-note-icon: 0
dg-enable-dataview: false
tags:
  - NLP
permalink: /å¤§è¯­è¨€æ¨¡å‹å­¦ä¹ /Common-Modelså¸¸è§æ¨¡å‹/GPTç³»åˆ—/GPT-2/
dgShowBacklinks: true
dgShowLocalGraph: true
dgShowInlineTitle: true
dgPassFrontmatter: true
noteIcon: 0
created: 2025-04-24T22:25:24.000+08:00
updated: 2025-04-25T19:05:57.000+08:00
title: GPT-2
createTime: 2025/05/13 17:33:53
---



# GPT-2çš„æ ¸å¿ƒæ€æƒ³ä¸åº”ç”¨ï¼šå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„æ— ç›‘ç£å­¦ä¹ 

## å…ƒæ•°æ®
- åˆ†ç±»ï¼šè‡ªç„¶è¯­è¨€å¤„ç†
- æ ‡ç­¾ï¼šGPT-2, è¯­è¨€æ¨¡å‹, æ— ç›‘ç£å­¦ä¹ , å¤šä»»åŠ¡å­¦ä¹ , Zero-shot
- æ—¥æœŸï¼š2025å¹´4æœˆ12æ—¥


## å†…å®¹æ¦‚è¿°
GPT-2æ¨¡å‹æ˜¯ä¸€ä¸ªå¤§è§„æ¨¡çš„æ— ç›‘ç£è¯­è¨€æ¨¡å‹ï¼Œå®ƒé€šè¿‡é¢„è®­ç»ƒå’Œzero-shotè®¾å®šå®ç°äº†å¤šä»»åŠ¡å­¦ä¹ ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯è®¤ä¸ºä»»ä½•æœ‰ç›‘ç£ä»»åŠ¡éƒ½æ˜¯è¯­è¨€æ¨¡å‹çš„ä¸€éƒ¨åˆ†ï¼Œå½“æ¨¡å‹çš„å®¹é‡å’Œæ•°æ®é‡è¶³å¤Ÿå¤§æ—¶ï¼Œä»…é è¯­è¨€æ¨¡å‹çš„å­¦ä¹ ä¾¿å¯ä»¥å®Œæˆå…¶ä»–æœ‰ç›‘ç£å­¦ä¹ çš„ä»»åŠ¡ã€‚


## é‡ç‚¹å†…å®¹

### æ¨¡å‹ç»“æ„ä¸è®­ç»ƒèŒƒå¼
- GPT-2ä¸GPT-1åŸºæœ¬ä¸€è‡´ï¼Œä½†åœ¨ç»“æ„ä¸Šåšäº†ä¸€äº›æ”¹åŠ¨ï¼Œå¦‚å°†post-normæ”¹ä¸ºpre-normï¼Œè¾“å…¥åºåˆ—é•¿åº¦ä»512å¢åŠ åˆ°1024ï¼Œå¹¶ä¸”åŒ…å«48å±‚ã€‚
- è®­ç»ƒèŒƒå¼é‡‡ç”¨é¢„è®­ç»ƒåŠ zero-shotçš„æ–¹å¼ï¼Œä¸»è¦æ€æƒ³æ˜¯å¤šä»»åŠ¡å­¦ä¹ ã€‚


### æ•°æ®ä¸å®éªŒ
- æ•°æ®é›†æ¥è‡ªRedditï¼ŒåŒ…å«800ä¸‡ä¸ªæ–‡æ¡£ï¼Œæ€»è®¡40GBã€‚
- GPT-2éªŒè¯äº†é€šè¿‡å¤§é‡æ•°æ®å’Œå‚æ•°è®­ç»ƒå‡ºæ¥çš„è¯å‘é‡æ¨¡å‹å¯ä»¥è¿ç§»åˆ°å…¶ä»–ä»»åŠ¡ä¸­ï¼Œè€Œä¸éœ€è¦é¢å¤–çš„è®­ç»ƒã€‚


### Zero-shotå­¦ä¹ 
- åœ¨zero-shotè®¾å®šä¸‹ï¼Œä¸‹æ¸¸ä»»åŠ¡ä¸éœ€è¦ç”¨æ ‡ç­¾æ•°æ®è¿›è¡Œå¾®è°ƒã€‚
- é€šè¿‡promptï¼ˆæç¤ºï¼‰çš„æ–¹å¼å®ç°zero-shotï¼Œä¾‹å¦‚æœºå™¨ç¿»è¯‘æ—¶æ„é€ è¾“å…¥ä¸ºâ€œè¯·å°†ä¸‹é¢çš„ä¸€æ®µè‹±è¯­ç¿»è¯‘æˆæ³•è¯­ï¼Œè‹±è¯­ï¼Œæ³•è¯­â€ã€‚


## æ“ä½œæ­¥éª¤
1. âœ… ç¡®å®šæ¨¡å‹ç»“æ„ï¼šé€‰æ‹©pre-normç»“æ„ï¼Œè¾“å…¥åºåˆ—é•¿åº¦ä¸º1024ã€‚
2. âš  æ”¶é›†æ•°æ®ï¼šä»å¤šæ ·åŒ–çš„æ•°æ®é›†ä¸­è·å–è‡ªç„¶è¯­è¨€æè¿°ç¤ºä¾‹ã€‚
3. â— è®­ç»ƒæ¨¡å‹ï¼šä½¿ç”¨å¤§é‡æ•°æ®å’Œå‚æ•°è¿›è¡Œé¢„è®­ç»ƒã€‚


## å¸¸è§é”™è¯¯
> âš  åœ¨ä½¿ç”¨zero-shotæ—¶ï¼Œé¿å…åœ¨è¾“å…¥ä¸­åŠ å…¥ç‰¹æ®Šå­—ç¬¦ï¼Œè¿™äº›å­—ç¬¦åœ¨é¢„è®­ç»ƒæ—¶æœªè§è¿‡ã€‚


## ğŸ’¡ å¯å‘ç‚¹
GPT-2å±•ç¤ºäº†å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹åœ¨å¤šä»»åŠ¡å­¦ä¹ ä¸­çš„æ½œåŠ›ï¼Œé€šè¿‡å¤§é‡æ•°æ®å’Œå‚æ•°ï¼Œæ¨¡å‹å¯ä»¥åœ¨æ²¡æœ‰é¢å¤–è®­ç»ƒçš„æƒ…å†µä¸‹å¤„ç†å¤šç§ä»»åŠ¡ã€‚


## è¡ŒåŠ¨æ¸…å•
- æ¢ç´¢æ›´å¤šå…³äºGPT-2åœ¨ä¸åŒä»»åŠ¡ä¸­çš„åº”ç”¨åœºæ™¯ã€‚
- å®éªŒä¸åŒçš„æ•°æ®é›†å¯¹GPT-2æ€§èƒ½çš„å½±å“ã€‚
- ç ”ç©¶å¦‚ä½•è¿›ä¸€æ­¥ä¼˜åŒ–promptè®¾è®¡ä»¥æé«˜zero-shotæ•ˆæœã€‚


## æ•°æ®è½¬æ¢
| æ¨¡å‹ç‰ˆæœ¬ | æ•°æ®é‡ | æœ€å¤§å‚æ•°æ•°é‡ |
|----------|--------|--------------|
| GPT-1    | 5G     | 1äº¿          |
| GPT-2    | 40G    | 15äº¿         |

> åŸå§‹å‡ºå¤„ï¼šLanguage Models are Unsupervised Multitask Learners
