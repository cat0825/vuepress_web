{"content":"<h2 id=\"元数据\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#元数据\"><span>元数据</span></a></h2>\n<p>分类：自动推断</p>\n<p>标签：动态适配、低秩分解、奇异值、深度学习、AdaLoRA</p>\n<p>日期：2025年4月12日</p>\n<h2 id=\"核心观点\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心观点\"><span>核心观点</span></a></h2>\n<p>AdaLoRA是一种创新的深度学习技术，它通过动态调整不同层和参数类型的秩，根据下游任务需求进行优化。这种方法采用基于SVD（奇异值分解）的参数化形式，可以有效裁剪不重要的奇异值，降低计算复杂度。\n<img src=\"/img/user/附件/Pasted image 20250424111842.png\" alt=\"Pasted image 20250424111842.png\">\n💡启发点：通过动态分配秩和使用SVD参数化，AdaLoRA实现了计算效率与性能优化的平衡。</p>\n<h2 id=\"重点段落\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#重点段落\"><span>重点段落</span></a></h2>\n<h3 id=\"动态秩分配\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#动态秩分配\"><span>动态秩分配</span></a></h3>\n<p>AdaLoRA不仅为每个Adapter分配相同的秩，而是根据任务需求动态调整各层和参数类型的秩。这种灵活性使得模型能够更加高效地处理不同的任务。</p>\n<h3 id=\"svd参数化增量更新\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#svd参数化增量更新\"><span>SVD参数化增量更新</span></a></h3>\n<p>采用SVD形式参数化增量更新，能够在规避复杂计算的同时高效裁剪不重要的奇异值。这种方法大大降低了计算量，并提高了模型的适应能力。</p>\n<h3 id=\"核心代码解析\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心代码解析\"><span>核心代码解析</span></a></h3>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code><span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">class</span><span style=\"--shiki-light:#2E8F82;--shiki-dark:#5DA994\"> AdaLoraLayer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">LoraLayer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\"> update_layer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> adapter_name</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> r</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> lora_alpha</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> lora_dropout</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> init_lora_weights</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">lora_A</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">adapter_name</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">]</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> =</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Parameter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">randn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">r</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">in_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">))</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # Singular values</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">lora_E</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">adapter_name</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">]</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> =</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Parameter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">randn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">r</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">))</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # Left singular vectors</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">lora_B</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">adapter_name</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">]</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> =</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Parameter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">randn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">out_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> r</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">))</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # The current rank</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">ranknum</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">adapter_name</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">]</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> =</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Parameter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">randn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">),</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> requires_grad</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">False</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">ranknum</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">adapter_name</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">].</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">data</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">fill_</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">float</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">r</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">))</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">ranknum</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">adapter_name</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">].</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">requires_grad </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\"> False</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">scaling</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">adapter_name</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">]</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> =</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> lora_alpha </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">if</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> lora_alpha </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">></span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 0</span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\"> else</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\"> float</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">r</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h2 id=\"操作步骤\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#操作步骤\"><span>操作步骤</span></a></h2>\n<ol>\n<li>✅ 初始化参数矩阵并分配秩。</li>\n<li>⚠ 使用SVD进行奇异值裁剪。</li>\n<li>❗ 根据任务需求动态调整适配器权重。</li>\n</ol>\n<h2 id=\"常见错误\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#常见错误\"><span>常见错误</span></a></h2>\n<blockquote>\n<p>⚠ 在调整秩时，可能会忽略特定任务对参数的特殊需求，导致模型性能下降。</p>\n</blockquote>\n<h2 id=\"行动清单\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#行动清单\"><span>行动清单</span></a></h2>\n<ul>\n<li>研究AdaLoRA在不同任务中的表现。</li>\n<li>探索其他基于SVD的优化技术。</li>\n<li>实验不同参数设置对模型性能的影响。</li>\n</ul>\n<h2 id=\"数据转换\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#数据转换\"><span>数据转换</span></a></h2>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>r</td>\n<td>当前秩</td>\n</tr>\n<tr>\n<td>lora_alpha</td>\n<td>调整因子</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"公式显示\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#公式显示\"><span>公式显示</span></a></h2>\n<p>使用公式表示奇异值与秩关系：</p>\n<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>ranknum</mtext><mo>=</mo><mi>α</mi><mo>⋅</mo><mtext>scaling</mtext></mrow><annotation encoding=\"application/x-tex\">\\text{ranknum} = \\alpha \\cdot \\text{scaling} \n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord text\"><span class=\"mord\">ranknum</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.4445em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\"><span class=\"mord\">scaling</span></span></span></span></span></span></p>\n<blockquote>\n<p>原始内容来自PEFT/src/peft/tuners/adalora/layer.py。</p>\n</blockquote>\n","env":{"base":"/","filePath":"/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/LoRA及其变体/AdaLoRA.md","filePathRelative":"notes_bak/大语言模型学习/RL强化学习基础/LoRA及其变体/AdaLoRA.md","frontmatter":{"dg-publish":true,"dg-permalink":"/大语言模型学习/RL强化学习基础/LoRA及其变体/AdaLoRA","dg-home":false,"dg-description":"在此输入笔记的描述","dg-hide":false,"dg-hide-title":false,"dg-show-backlinks":true,"dg-show-local-graph":true,"dg-show-inline-title":true,"dg-pinned":false,"dg-passphrase":"在此输入访问密码","dg-enable-mathjax":false,"dg-enable-mermaid":false,"dg-enable-uml":false,"dg-note-icon":0,"dg-enable-dataview":false,"tags":["NLP"],"permalink":"/大语言模型学习/RL强化学习基础/LoRA及其变体/AdaLoRA/","dgShowBacklinks":true,"dgShowLocalGraph":true,"dgShowInlineTitle":true,"dgPassFrontmatter":true,"noteIcon":0,"created":"2025-04-24T03:18:17.739Z","updated":"2025-04-24T03:18:43.096Z","title":"AdaLoRA","createTime":"2025/05/13 17:33:52"},"sfcBlocks":{"template":{"type":"template","content":"<template><h2 id=\"元数据\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#元数据\"><span>元数据</span></a></h2>\n<p>分类：自动推断</p>\n<p>标签：动态适配、低秩分解、奇异值、深度学习、AdaLoRA</p>\n<p>日期：2025年4月12日</p>\n<h2 id=\"核心观点\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心观点\"><span>核心观点</span></a></h2>\n<p>AdaLoRA是一种创新的深度学习技术，它通过动态调整不同层和参数类型的秩，根据下游任务需求进行优化。这种方法采用基于SVD（奇异值分解）的参数化形式，可以有效裁剪不重要的奇异值，降低计算复杂度。\n<img src=\"/img/user/附件/Pasted image 20250424111842.png\" alt=\"Pasted image 20250424111842.png\">\n💡启发点：通过动态分配秩和使用SVD参数化，AdaLoRA实现了计算效率与性能优化的平衡。</p>\n<h2 id=\"重点段落\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#重点段落\"><span>重点段落</span></a></h2>\n<h3 id=\"动态秩分配\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#动态秩分配\"><span>动态秩分配</span></a></h3>\n<p>AdaLoRA不仅为每个Adapter分配相同的秩，而是根据任务需求动态调整各层和参数类型的秩。这种灵活性使得模型能够更加高效地处理不同的任务。</p>\n<h3 id=\"svd参数化增量更新\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#svd参数化增量更新\"><span>SVD参数化增量更新</span></a></h3>\n<p>采用SVD形式参数化增量更新，能够在规避复杂计算的同时高效裁剪不重要的奇异值。这种方法大大降低了计算量，并提高了模型的适应能力。</p>\n<h3 id=\"核心代码解析\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心代码解析\"><span>核心代码解析</span></a></h3>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code><span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">class</span><span style=\"--shiki-light:#2E8F82;--shiki-dark:#5DA994\"> AdaLoraLayer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">LoraLayer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\"> update_layer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> adapter_name</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> r</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> lora_alpha</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> lora_dropout</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> init_lora_weights</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">lora_A</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">adapter_name</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">]</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> =</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Parameter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">randn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">r</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">in_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">))</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # Singular values</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">lora_E</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">adapter_name</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">]</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> =</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Parameter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">randn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">r</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">))</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # Left singular vectors</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">lora_B</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">adapter_name</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">]</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> =</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Parameter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">randn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">out_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> r</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">))</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # The current rank</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">ranknum</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">adapter_name</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">]</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> =</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Parameter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">randn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">),</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> requires_grad</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">False</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">ranknum</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">adapter_name</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">].</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">data</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">fill_</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">float</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">r</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">))</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">ranknum</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">adapter_name</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">].</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">requires_grad </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\"> False</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">scaling</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">adapter_name</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">]</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> =</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> lora_alpha </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">if</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> lora_alpha </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">></span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 0</span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\"> else</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\"> float</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">r</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h2 id=\"操作步骤\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#操作步骤\"><span>操作步骤</span></a></h2>\n<ol>\n<li>✅ 初始化参数矩阵并分配秩。</li>\n<li>⚠ 使用SVD进行奇异值裁剪。</li>\n<li>❗ 根据任务需求动态调整适配器权重。</li>\n</ol>\n<h2 id=\"常见错误\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#常见错误\"><span>常见错误</span></a></h2>\n<blockquote>\n<p>⚠ 在调整秩时，可能会忽略特定任务对参数的特殊需求，导致模型性能下降。</p>\n</blockquote>\n<h2 id=\"行动清单\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#行动清单\"><span>行动清单</span></a></h2>\n<ul>\n<li>研究AdaLoRA在不同任务中的表现。</li>\n<li>探索其他基于SVD的优化技术。</li>\n<li>实验不同参数设置对模型性能的影响。</li>\n</ul>\n<h2 id=\"数据转换\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#数据转换\"><span>数据转换</span></a></h2>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>r</td>\n<td>当前秩</td>\n</tr>\n<tr>\n<td>lora_alpha</td>\n<td>调整因子</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"公式显示\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#公式显示\"><span>公式显示</span></a></h2>\n<p>使用公式表示奇异值与秩关系：</p>\n<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>ranknum</mtext><mo>=</mo><mi>α</mi><mo>⋅</mo><mtext>scaling</mtext></mrow><annotation encoding=\"application/x-tex\">\\text{ranknum} = \\alpha \\cdot \\text{scaling} \n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord text\"><span class=\"mord\">ranknum</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.4445em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\"><span class=\"mord\">scaling</span></span></span></span></span></span></p>\n<blockquote>\n<p>原始内容来自PEFT/src/peft/tuners/adalora/layer.py。</p>\n</blockquote>\n</template>","contentStripped":"<h2 id=\"元数据\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#元数据\"><span>元数据</span></a></h2>\n<p>分类：自动推断</p>\n<p>标签：动态适配、低秩分解、奇异值、深度学习、AdaLoRA</p>\n<p>日期：2025年4月12日</p>\n<h2 id=\"核心观点\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心观点\"><span>核心观点</span></a></h2>\n<p>AdaLoRA是一种创新的深度学习技术，它通过动态调整不同层和参数类型的秩，根据下游任务需求进行优化。这种方法采用基于SVD（奇异值分解）的参数化形式，可以有效裁剪不重要的奇异值，降低计算复杂度。\n<img src=\"/img/user/附件/Pasted image 20250424111842.png\" alt=\"Pasted image 20250424111842.png\">\n💡启发点：通过动态分配秩和使用SVD参数化，AdaLoRA实现了计算效率与性能优化的平衡。</p>\n<h2 id=\"重点段落\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#重点段落\"><span>重点段落</span></a></h2>\n<h3 id=\"动态秩分配\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#动态秩分配\"><span>动态秩分配</span></a></h3>\n<p>AdaLoRA不仅为每个Adapter分配相同的秩，而是根据任务需求动态调整各层和参数类型的秩。这种灵活性使得模型能够更加高效地处理不同的任务。</p>\n<h3 id=\"svd参数化增量更新\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#svd参数化增量更新\"><span>SVD参数化增量更新</span></a></h3>\n<p>采用SVD形式参数化增量更新，能够在规避复杂计算的同时高效裁剪不重要的奇异值。这种方法大大降低了计算量，并提高了模型的适应能力。</p>\n<h3 id=\"核心代码解析\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心代码解析\"><span>核心代码解析</span></a></h3>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code><span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">class</span><span style=\"--shiki-light:#2E8F82;--shiki-dark:#5DA994\"> AdaLoraLayer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">LoraLayer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\"> update_layer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> adapter_name</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> r</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> lora_alpha</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> lora_dropout</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> init_lora_weights</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">lora_A</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">adapter_name</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">]</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> =</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Parameter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">randn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">r</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">in_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">))</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # Singular values</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">lora_E</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">adapter_name</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">]</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> =</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Parameter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">randn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">r</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">))</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # Left singular vectors</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">lora_B</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">adapter_name</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">]</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> =</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Parameter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">randn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">out_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> r</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">))</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # The current rank</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">ranknum</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">adapter_name</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">]</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> =</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Parameter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">randn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">),</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> requires_grad</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">False</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">ranknum</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">adapter_name</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">].</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">data</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">fill_</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">float</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">r</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">))</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">ranknum</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">adapter_name</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">].</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">requires_grad </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\"> False</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">scaling</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">adapter_name</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">]</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> =</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> lora_alpha </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">if</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> lora_alpha </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">></span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 0</span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\"> else</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\"> float</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">r</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h2 id=\"操作步骤\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#操作步骤\"><span>操作步骤</span></a></h2>\n<ol>\n<li>✅ 初始化参数矩阵并分配秩。</li>\n<li>⚠ 使用SVD进行奇异值裁剪。</li>\n<li>❗ 根据任务需求动态调整适配器权重。</li>\n</ol>\n<h2 id=\"常见错误\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#常见错误\"><span>常见错误</span></a></h2>\n<blockquote>\n<p>⚠ 在调整秩时，可能会忽略特定任务对参数的特殊需求，导致模型性能下降。</p>\n</blockquote>\n<h2 id=\"行动清单\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#行动清单\"><span>行动清单</span></a></h2>\n<ul>\n<li>研究AdaLoRA在不同任务中的表现。</li>\n<li>探索其他基于SVD的优化技术。</li>\n<li>实验不同参数设置对模型性能的影响。</li>\n</ul>\n<h2 id=\"数据转换\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#数据转换\"><span>数据转换</span></a></h2>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>r</td>\n<td>当前秩</td>\n</tr>\n<tr>\n<td>lora_alpha</td>\n<td>调整因子</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"公式显示\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#公式显示\"><span>公式显示</span></a></h2>\n<p>使用公式表示奇异值与秩关系：</p>\n<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>ranknum</mtext><mo>=</mo><mi>α</mi><mo>⋅</mo><mtext>scaling</mtext></mrow><annotation encoding=\"application/x-tex\">\\text{ranknum} = \\alpha \\cdot \\text{scaling} \n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord text\"><span class=\"mord\">ranknum</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.4445em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\"><span class=\"mord\">scaling</span></span></span></span></span></span></p>\n<blockquote>\n<p>原始内容来自PEFT/src/peft/tuners/adalora/layer.py。</p>\n</blockquote>\n","tagOpen":"<template>","tagClose":"</template>"},"script":null,"scriptSetup":null,"scripts":[],"styles":[],"customBlocks":[]},"content":"\n## 元数据\n分类：自动推断\n\n标签：动态适配、低秩分解、奇异值、深度学习、AdaLoRA\n\n日期：2025年4月12日\n\n\n## 核心观点\nAdaLoRA是一种创新的深度学习技术，它通过动态调整不同层和参数类型的秩，根据下游任务需求进行优化。这种方法采用基于SVD（奇异值分解）的参数化形式，可以有效裁剪不重要的奇异值，降低计算复杂度。\n![Pasted image 20250424111842.png](/img/user/%E9%99%84%E4%BB%B6/Pasted%20image%2020250424111842.png)\n💡启发点：通过动态分配秩和使用SVD参数化，AdaLoRA实现了计算效率与性能优化的平衡。\n\n\n## 重点段落\n\n### 动态秩分配\nAdaLoRA不仅为每个Adapter分配相同的秩，而是根据任务需求动态调整各层和参数类型的秩。这种灵活性使得模型能够更加高效地处理不同的任务。\n\n\n### SVD参数化增量更新\n采用SVD形式参数化增量更新，能够在规避复杂计算的同时高效裁剪不重要的奇异值。这种方法大大降低了计算量，并提高了模型的适应能力。\n\n\n### 核心代码解析\n```python\nclass AdaLoraLayer(LoraLayer):\n    def update_layer(self, adapter_name, r, lora_alpha, lora_dropout, init_lora_weights):\n        self.lora_A[adapter_name] = nn.Parameter(torch.randn(r, self.in_features))\n        # Singular values\n        self.lora_E[adapter_name] = nn.Parameter(torch.randn(r, 1))\n        # Left singular vectors\n        self.lora_B[adapter_name] = nn.Parameter(torch.randn(self.out_features, r))\n        # The current rank\n        self.ranknum[adapter_name] = nn.Parameter(torch.randn(1), requires_grad=False)\n        self.ranknum[adapter_name].data.fill_(float(r))\n        self.ranknum[adapter_name].requires_grad = False\n        self.scaling[adapter_name] = lora_alpha if lora_alpha > 0 else float(r)\n```\n\n\n## 操作步骤\n1. ✅ 初始化参数矩阵并分配秩。\n2. ⚠ 使用SVD进行奇异值裁剪。\n3. ❗ 根据任务需求动态调整适配器权重。\n\n\n## 常见错误\n> ⚠ 在调整秩时，可能会忽略特定任务对参数的特殊需求，导致模型性能下降。\n\n\n## 行动清单\n- 研究AdaLoRA在不同任务中的表现。\n- 探索其他基于SVD的优化技术。\n- 实验不同参数设置对模型性能的影响。\n\n\n## 数据转换\n| 参数 | 描述 |\n|------|------|\n| r    | 当前秩 |\n| lora_alpha | 调整因子 |\n\n\n## 公式显示\n使用公式表示奇异值与秩关系：\n$$ \\text{ranknum} = \\alpha \\cdot \\text{scaling} $$\n\n> 原始内容来自PEFT/src/peft/tuners/adalora/layer.py。","excerpt":"","includedFiles":[],"tasklistId":0,"title":"","headers":[{"level":2,"title":"元数据","slug":"元数据","link":"#元数据","children":[]},{"level":2,"title":"核心观点","slug":"核心观点","link":"#核心观点","children":[]},{"level":2,"title":"重点段落","slug":"重点段落","link":"#重点段落","children":[{"level":3,"title":"动态秩分配","slug":"动态秩分配","link":"#动态秩分配","children":[]},{"level":3,"title":"SVD参数化增量更新","slug":"svd参数化增量更新","link":"#svd参数化增量更新","children":[]},{"level":3,"title":"核心代码解析","slug":"核心代码解析","link":"#核心代码解析","children":[]}]},{"level":2,"title":"操作步骤","slug":"操作步骤","link":"#操作步骤","children":[]},{"level":2,"title":"常见错误","slug":"常见错误","link":"#常见错误","children":[]},{"level":2,"title":"行动清单","slug":"行动清单","link":"#行动清单","children":[]},{"level":2,"title":"数据转换","slug":"数据转换","link":"#数据转换","children":[]},{"level":2,"title":"公式显示","slug":"公式显示","link":"#公式显示","children":[]}]}}
