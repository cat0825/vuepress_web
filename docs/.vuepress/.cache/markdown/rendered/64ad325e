{"content":"<p>元数据：</p>\n<p>分类：自然语言处理</p>\n<p>标签：P-Tuning V2, 自然语言理解, 提示优化</p>\n<p>日期：2025年4月12日</p>\n<h2 id=\"核心观点总结\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心观点总结\"><span>核心观点总结</span></a></h2>\n<p>P-Tuning V2 是一种改进的提示优化技术，旨在解决之前方法中存在的模型参数规模和任务通用性问题。通过在每一层加入提示（Prompts）而不仅仅是输入层，P-Tuning V2 提供了更多可学习的参数，并能更直接影响模型预测。💡这使得提示优化在较小模型和多任务学习中表现更为优异。</p>\n<h2 id=\"重点段落\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#重点段落\"><span>重点段落</span></a></h2>\n<ol>\n<li>\n<p><strong>缺乏模型参数规模和任务通用性</strong><br>\n之前的提示优化方法在大规模模型中表现良好，但在较小模型（100M到1B参数）上与全量微调差异显著，限制了其适用性。</p>\n</li>\n<li>\n<p><strong>深度提示优化的引入</strong><br>\n在每一层加入提示令可学习参数增加，从而提升了参数效率和模型预测的直接影响。</p>\n</li>\n<li>\n<p><strong>多任务学习和提示长度优化</strong><br>\n针对不同任务采用不同提示长度，并通过多任务学习进行预训练，以缓解优化困难。</p>\n</li>\n</ol>\n<h2 id=\"技术术语通俗转述\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#技术术语通俗转述\"><span>技术术语通俗转述</span></a></h2>\n<ul>\n<li><strong>提示优化（Prompt Tuning）</strong>：一种通过在输入中插入特殊提示来引导模型学习的技术。</li>\n<li><strong>全量微调</strong>：对整个模型进行参数调整以提高性能的方法。</li>\n<li><strong>多任务学习</strong>：同时学习多个相关任务，以提高模型在各个任务上的表现。</li>\n</ul>\n<h2 id=\"实施步骤\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#实施步骤\"><span>实施步骤</span></a></h2>\n<ol>\n<li>✅ 在每一层加入 Prompts tokens 作为输入。</li>\n<li>⚠ 移除重参数化的编码器以提高训练速度和鲁棒性。</li>\n<li>❗ 针对不同任务选择合适的提示长度。</li>\n<li>✅ 引入多任务学习进行预训练。\n<img src=\"/img/user/附件/Pasted image 20250424105959.png\" alt=\"Pasted image 20250424105959.png\"></li>\n</ol>\n<h2 id=\"代码实现\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#代码实现\"><span>代码实现</span></a></h2>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code><span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">#设置virtual_token的数量及past_key_values维度</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">prompt_tokens </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> prompt_tokens</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[:,</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> :</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> peft_config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">num_virtual_tokens</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">]</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">past_key_values </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> past_key_values</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">view</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">batch_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">peft_config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">num_virtual_tokens</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">peft_config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">num_layers </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">*</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 2</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> ,</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">peft_config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">num_attention_heads</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">peft_config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">token_dim </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">//</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> peft_config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">num_attention_heads</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># prefix encoder类的定义</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">class</span><span style=\"--shiki-light:#2E8F82;--shiki-dark:#5DA994\"> PrefixEncoder</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> (</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">Module</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">The torch.nn model to encode the prefix Input shape: (batch-size, prefix-length) Output shape: (batch-size, prefix-length, 2*layers*hidden) </span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">def</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\"> __init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> (</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">:</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> ChatGLMConfig </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">super</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> ().</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">__init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">prefix_projection </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">prefix_projection</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># self.prefix_projection=True-->prefix tuning</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># self.prefix_projection=False-->p-tuning v2</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">if</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">prefix_projection</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">:</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># Use a two-layer MLP to encode the prefix</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">kv_size </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">num_layers </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">*</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">kv_channels </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">*</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">multi_query_group_num </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">*</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 2</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">embedding </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">pre_seq_len</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> kv_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">trans </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Sequential</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Linear</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">kv_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">hidden_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">),</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Tanh</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(),</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Linear</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">hidden_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> kv_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">else</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> :</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">embedding </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">pre_seq_len</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">num_layers </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">*</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">kv_channels </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">*</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">multi_query_group_num </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">*</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 2</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> )</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">def</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\"> forward</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> (</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> prefix</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">:</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Tensor </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">if</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">prefix_projection</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">:</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">prefix_tokens </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">prefix</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">past_key_values </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">trans</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">prefix_tokens</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">else</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> :</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">past_key_values </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">prefix</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">return</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> past_key_values</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h2 id=\"常见错误\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#常见错误\"><span>常见错误</span></a></h2>\n<blockquote>\n<p>⚠ 使用不合适的提示长度可能导致性能下降。确保根据具体任务调整提示长度。</p>\n</blockquote>\n<h2 id=\"行动清单\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#行动清单\"><span>行动清单</span></a></h2>\n<ul>\n<li>研究如何在现有项目中集成 P-Tuning V2。</li>\n<li>针对特定任务测试不同的提示长度。</li>\n<li>探索多任务学习在其他领域的应用潜力。</li>\n</ul>\n<blockquote>\n<p>来源：本文内容来源于对 P-Tuning V2 技术的总结与分析。</p>\n</blockquote>\n","env":{"base":"/","filePath":"/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/PEFT参数高效微调/P-Tuning V2 2.md","filePathRelative":"notes_bak/大语言模型学习/RL强化学习基础/PEFT参数高效微调/P-Tuning V2 2.md","frontmatter":{"dg-publish":true,"dg-permalink":"/大语言模型学习/RL强化学习基础/PEFT参数高效微调/P-Tuning-V2","dg-home":false,"dg-description":"在此输入笔记的描述","dg-hide":false,"dg-hide-title":false,"dg-show-backlinks":true,"dg-show-local-graph":true,"dg-show-inline-title":true,"dg-pinned":false,"dg-passphrase":"在此输入访问密码","dg-enable-mathjax":false,"dg-enable-mermaid":false,"dg-enable-uml":false,"dg-note-icon":0,"dg-enable-dataview":false,"tags":["NLP"],"permalink":"/大语言模型学习/RL强化学习基础/PEFT参数高效微调/P-Tuning-V2/","dgShowBacklinks":true,"dgShowLocalGraph":true,"dgShowInlineTitle":true,"dgPassFrontmatter":true,"noteIcon":0,"created":"2025-04-23T14:55:47.000Z","updated":"2025-04-24T03:10:28.000Z","title":"P-Tuning V2","createTime":"2025/05/13 17:33:52"},"sfcBlocks":{"template":{"type":"template","content":"<template><p>元数据：</p>\n<p>分类：自然语言处理</p>\n<p>标签：P-Tuning V2, 自然语言理解, 提示优化</p>\n<p>日期：2025年4月12日</p>\n<h2 id=\"核心观点总结\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心观点总结\"><span>核心观点总结</span></a></h2>\n<p>P-Tuning V2 是一种改进的提示优化技术，旨在解决之前方法中存在的模型参数规模和任务通用性问题。通过在每一层加入提示（Prompts）而不仅仅是输入层，P-Tuning V2 提供了更多可学习的参数，并能更直接影响模型预测。💡这使得提示优化在较小模型和多任务学习中表现更为优异。</p>\n<h2 id=\"重点段落\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#重点段落\"><span>重点段落</span></a></h2>\n<ol>\n<li>\n<p><strong>缺乏模型参数规模和任务通用性</strong><br>\n之前的提示优化方法在大规模模型中表现良好，但在较小模型（100M到1B参数）上与全量微调差异显著，限制了其适用性。</p>\n</li>\n<li>\n<p><strong>深度提示优化的引入</strong><br>\n在每一层加入提示令可学习参数增加，从而提升了参数效率和模型预测的直接影响。</p>\n</li>\n<li>\n<p><strong>多任务学习和提示长度优化</strong><br>\n针对不同任务采用不同提示长度，并通过多任务学习进行预训练，以缓解优化困难。</p>\n</li>\n</ol>\n<h2 id=\"技术术语通俗转述\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#技术术语通俗转述\"><span>技术术语通俗转述</span></a></h2>\n<ul>\n<li><strong>提示优化（Prompt Tuning）</strong>：一种通过在输入中插入特殊提示来引导模型学习的技术。</li>\n<li><strong>全量微调</strong>：对整个模型进行参数调整以提高性能的方法。</li>\n<li><strong>多任务学习</strong>：同时学习多个相关任务，以提高模型在各个任务上的表现。</li>\n</ul>\n<h2 id=\"实施步骤\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#实施步骤\"><span>实施步骤</span></a></h2>\n<ol>\n<li>✅ 在每一层加入 Prompts tokens 作为输入。</li>\n<li>⚠ 移除重参数化的编码器以提高训练速度和鲁棒性。</li>\n<li>❗ 针对不同任务选择合适的提示长度。</li>\n<li>✅ 引入多任务学习进行预训练。\n<img src=\"/img/user/附件/Pasted image 20250424105959.png\" alt=\"Pasted image 20250424105959.png\"></li>\n</ol>\n<h2 id=\"代码实现\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#代码实现\"><span>代码实现</span></a></h2>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code><span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">#设置virtual_token的数量及past_key_values维度</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">prompt_tokens </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> prompt_tokens</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[:,</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> :</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> peft_config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">num_virtual_tokens</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">]</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">past_key_values </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> past_key_values</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">view</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">batch_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">peft_config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">num_virtual_tokens</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">peft_config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">num_layers </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">*</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 2</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> ,</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">peft_config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">num_attention_heads</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">peft_config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">token_dim </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">//</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> peft_config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">num_attention_heads</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># prefix encoder类的定义</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">class</span><span style=\"--shiki-light:#2E8F82;--shiki-dark:#5DA994\"> PrefixEncoder</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> (</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">Module</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">The torch.nn model to encode the prefix Input shape: (batch-size, prefix-length) Output shape: (batch-size, prefix-length, 2*layers*hidden) </span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">def</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\"> __init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> (</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">:</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> ChatGLMConfig </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">super</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> ().</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">__init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">prefix_projection </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">prefix_projection</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># self.prefix_projection=True-->prefix tuning</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># self.prefix_projection=False-->p-tuning v2</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">if</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">prefix_projection</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">:</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># Use a two-layer MLP to encode the prefix</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">kv_size </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">num_layers </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">*</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">kv_channels </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">*</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">multi_query_group_num </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">*</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 2</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">embedding </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">pre_seq_len</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> kv_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">trans </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Sequential</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Linear</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">kv_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">hidden_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">),</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Tanh</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(),</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Linear</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">hidden_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> kv_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">else</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> :</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">embedding </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">pre_seq_len</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">num_layers </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">*</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">kv_channels </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">*</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">multi_query_group_num </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">*</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 2</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> )</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">def</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\"> forward</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> (</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> prefix</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">:</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Tensor </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">if</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">prefix_projection</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">:</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">prefix_tokens </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">prefix</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">past_key_values </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">trans</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">prefix_tokens</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">else</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> :</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">past_key_values </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">prefix</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">return</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> past_key_values</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h2 id=\"常见错误\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#常见错误\"><span>常见错误</span></a></h2>\n<blockquote>\n<p>⚠ 使用不合适的提示长度可能导致性能下降。确保根据具体任务调整提示长度。</p>\n</blockquote>\n<h2 id=\"行动清单\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#行动清单\"><span>行动清单</span></a></h2>\n<ul>\n<li>研究如何在现有项目中集成 P-Tuning V2。</li>\n<li>针对特定任务测试不同的提示长度。</li>\n<li>探索多任务学习在其他领域的应用潜力。</li>\n</ul>\n<blockquote>\n<p>来源：本文内容来源于对 P-Tuning V2 技术的总结与分析。</p>\n</blockquote>\n</template>","contentStripped":"<p>元数据：</p>\n<p>分类：自然语言处理</p>\n<p>标签：P-Tuning V2, 自然语言理解, 提示优化</p>\n<p>日期：2025年4月12日</p>\n<h2 id=\"核心观点总结\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心观点总结\"><span>核心观点总结</span></a></h2>\n<p>P-Tuning V2 是一种改进的提示优化技术，旨在解决之前方法中存在的模型参数规模和任务通用性问题。通过在每一层加入提示（Prompts）而不仅仅是输入层，P-Tuning V2 提供了更多可学习的参数，并能更直接影响模型预测。💡这使得提示优化在较小模型和多任务学习中表现更为优异。</p>\n<h2 id=\"重点段落\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#重点段落\"><span>重点段落</span></a></h2>\n<ol>\n<li>\n<p><strong>缺乏模型参数规模和任务通用性</strong><br>\n之前的提示优化方法在大规模模型中表现良好，但在较小模型（100M到1B参数）上与全量微调差异显著，限制了其适用性。</p>\n</li>\n<li>\n<p><strong>深度提示优化的引入</strong><br>\n在每一层加入提示令可学习参数增加，从而提升了参数效率和模型预测的直接影响。</p>\n</li>\n<li>\n<p><strong>多任务学习和提示长度优化</strong><br>\n针对不同任务采用不同提示长度，并通过多任务学习进行预训练，以缓解优化困难。</p>\n</li>\n</ol>\n<h2 id=\"技术术语通俗转述\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#技术术语通俗转述\"><span>技术术语通俗转述</span></a></h2>\n<ul>\n<li><strong>提示优化（Prompt Tuning）</strong>：一种通过在输入中插入特殊提示来引导模型学习的技术。</li>\n<li><strong>全量微调</strong>：对整个模型进行参数调整以提高性能的方法。</li>\n<li><strong>多任务学习</strong>：同时学习多个相关任务，以提高模型在各个任务上的表现。</li>\n</ul>\n<h2 id=\"实施步骤\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#实施步骤\"><span>实施步骤</span></a></h2>\n<ol>\n<li>✅ 在每一层加入 Prompts tokens 作为输入。</li>\n<li>⚠ 移除重参数化的编码器以提高训练速度和鲁棒性。</li>\n<li>❗ 针对不同任务选择合适的提示长度。</li>\n<li>✅ 引入多任务学习进行预训练。\n<img src=\"/img/user/附件/Pasted image 20250424105959.png\" alt=\"Pasted image 20250424105959.png\"></li>\n</ol>\n<h2 id=\"代码实现\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#代码实现\"><span>代码实现</span></a></h2>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code><span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">#设置virtual_token的数量及past_key_values维度</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">prompt_tokens </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> prompt_tokens</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[:,</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> :</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> peft_config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">num_virtual_tokens</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">]</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">past_key_values </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> past_key_values</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">view</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">batch_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">peft_config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">num_virtual_tokens</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">peft_config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">num_layers </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">*</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 2</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> ,</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">peft_config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">num_attention_heads</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">peft_config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">token_dim </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">//</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> peft_config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">num_attention_heads</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># prefix encoder类的定义</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">class</span><span style=\"--shiki-light:#2E8F82;--shiki-dark:#5DA994\"> PrefixEncoder</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> (</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">Module</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">The torch.nn model to encode the prefix Input shape: (batch-size, prefix-length) Output shape: (batch-size, prefix-length, 2*layers*hidden) </span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">def</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\"> __init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> (</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">:</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> ChatGLMConfig </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">super</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> ().</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">__init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">prefix_projection </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">prefix_projection</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># self.prefix_projection=True-->prefix tuning</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># self.prefix_projection=False-->p-tuning v2</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">if</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">prefix_projection</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">:</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># Use a two-layer MLP to encode the prefix</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">kv_size </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">num_layers </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">*</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">kv_channels </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">*</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">multi_query_group_num </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">*</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 2</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">embedding </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">pre_seq_len</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> kv_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">trans </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Sequential</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Linear</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">kv_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">hidden_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">),</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Tanh</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(),</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Linear</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">hidden_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> kv_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">else</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> :</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">embedding </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">pre_seq_len</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">num_layers </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">*</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">kv_channels </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">*</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> config</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">multi_query_group_num </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">*</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 2</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> )</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">def</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\"> forward</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> (</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> prefix</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">:</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Tensor </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">if</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">prefix_projection</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">:</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">prefix_tokens </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">prefix</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">past_key_values </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">trans</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">prefix_tokens</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">else</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> :</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">past_key_values </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">prefix</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">return</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> past_key_values</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h2 id=\"常见错误\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#常见错误\"><span>常见错误</span></a></h2>\n<blockquote>\n<p>⚠ 使用不合适的提示长度可能导致性能下降。确保根据具体任务调整提示长度。</p>\n</blockquote>\n<h2 id=\"行动清单\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#行动清单\"><span>行动清单</span></a></h2>\n<ul>\n<li>研究如何在现有项目中集成 P-Tuning V2。</li>\n<li>针对特定任务测试不同的提示长度。</li>\n<li>探索多任务学习在其他领域的应用潜力。</li>\n</ul>\n<blockquote>\n<p>来源：本文内容来源于对 P-Tuning V2 技术的总结与分析。</p>\n</blockquote>\n","tagOpen":"<template>","tagClose":"</template>"},"script":null,"scriptSetup":null,"scripts":[],"styles":[],"customBlocks":[]},"content":"元数据：\n\n分类：自然语言处理\n\n标签：P-Tuning V2, 自然语言理解, 提示优化\n\n日期：2025年4月12日\n\n## 核心观点总结\nP-Tuning V2 是一种改进的提示优化技术，旨在解决之前方法中存在的模型参数规模和任务通用性问题。通过在每一层加入提示（Prompts）而不仅仅是输入层，P-Tuning V2 提供了更多可学习的参数，并能更直接影响模型预测。💡这使得提示优化在较小模型和多任务学习中表现更为优异。\n\n\n## 重点段落\n1. **缺乏模型参数规模和任务通用性**  \n   之前的提示优化方法在大规模模型中表现良好，但在较小模型（100M到1B参数）上与全量微调差异显著，限制了其适用性。\n\n2. **深度提示优化的引入**  \n   在每一层加入提示令可学习参数增加，从而提升了参数效率和模型预测的直接影响。\n\n3. **多任务学习和提示长度优化**  \n   针对不同任务采用不同提示长度，并通过多任务学习进行预训练，以缓解优化困难。\n\n\n## 技术术语通俗转述\n- **提示优化（Prompt Tuning）**：一种通过在输入中插入特殊提示来引导模型学习的技术。\n- **全量微调**：对整个模型进行参数调整以提高性能的方法。\n- **多任务学习**：同时学习多个相关任务，以提高模型在各个任务上的表现。\n\n\n## 实施步骤\n1. ✅ 在每一层加入 Prompts tokens 作为输入。\n2. ⚠ 移除重参数化的编码器以提高训练速度和鲁棒性。\n3. ❗ 针对不同任务选择合适的提示长度。\n4. ✅ 引入多任务学习进行预训练。\n![Pasted image 20250424105959.png](/img/user/%E9%99%84%E4%BB%B6/Pasted%20image%2020250424105959.png)\n\n\n## 代码实现\n```Python\n#设置virtual_token的数量及past_key_values维度\nprompt_tokens = prompt_tokens[:, : peft_config.num_virtual_tokens]\npast_key_values = past_key_values.view(\nbatch_size,peft_config.num_virtual_tokens,\npeft_config.num_layers * 2 ,\npeft_config.num_attention_heads,\npeft_config.token_dim // peft_config.num_attention_heads,\n)\n# prefix encoder类的定义\nclass PrefixEncoder (torch.nn.Module):\n\"\"\"\nThe torch.nn model to encode the prefix Input shape: (batch-size, prefix-length) Output shape: (batch-size, prefix-length, 2*layers*hidden) \"\"\"\ndef __init__ ( self, config: ChatGLMConfig ):\nsuper ().__init__()\nself.prefix_projection = config.prefix_projection\n# self.prefix_projection=True-->prefix tuning\n# self.prefix_projection=False-->p-tuning v2\nif self.prefix_projection:\n# Use a two-layer MLP to encode the prefix\nkv_size = config.num_layers * config.kv_channels * config.multi_query_group_num * 2\nself.embedding = torch.nn.Embedding(config.pre_seq_len, kv_size)\nself.trans = torch.nn.Sequential(\ntorch.nn.Linear(kv_size, config.hidden_size),\ntorch.nn.Tanh(),\ntorch.nn.Linear(config.hidden_size, kv_size)\n)\nelse :\nself.embedding = torch.nn.Embedding(config.pre_seq_len,\nconfig.num_layers * config.kv_channels * config.multi_query_group_num * 2 )\ndef forward ( self, prefix: torch.Tensor ):\nif self.prefix_projection:\nprefix_tokens = self.embedding(prefix)\npast_key_values = self.trans(prefix_tokens)\nelse :\npast_key_values = self.embedding(prefix)\nreturn past_key_values\n\n```\n\n\n## 常见错误\n> ⚠ 使用不合适的提示长度可能导致性能下降。确保根据具体任务调整提示长度。\n\n\n## 行动清单\n- 研究如何在现有项目中集成 P-Tuning V2。\n- 针对特定任务测试不同的提示长度。\n- 探索多任务学习在其他领域的应用潜力。\n\n> 来源：本文内容来源于对 P-Tuning V2 技术的总结与分析。","excerpt":"","includedFiles":[],"tasklistId":0,"title":"","headers":[{"level":2,"title":"核心观点总结","slug":"核心观点总结","link":"#核心观点总结","children":[]},{"level":2,"title":"重点段落","slug":"重点段落","link":"#重点段落","children":[]},{"level":2,"title":"技术术语通俗转述","slug":"技术术语通俗转述","link":"#技术术语通俗转述","children":[]},{"level":2,"title":"实施步骤","slug":"实施步骤","link":"#实施步骤","children":[]},{"level":2,"title":"代码实现","slug":"代码实现","link":"#代码实现","children":[]},{"level":2,"title":"常见错误","slug":"常见错误","link":"#常见错误","children":[]},{"level":2,"title":"行动清单","slug":"行动清单","link":"#行动清单","children":[]}]}}
