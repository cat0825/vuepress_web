{"content":"<h2 id=\"元数据\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#元数据\"><span>元数据</span></a></h2>\n<p><strong>分类</strong>：数据处理与机器学习<br>\n<strong>标签</strong>：数据清洗、预训练模型、去重算法<br>\n<strong>日期</strong>：2023-10-31</p>\n<hr>\n<h2 id=\"核心观点总结\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心观点总结\"><span>核心观点总结</span></a></h2>\n<p>在预训练模型开发过程中，数据质量直接影响模型性能。通过模型打分和数据去重，可以有效提升训练数据的质量。本文探讨了如何利用打分模型评估数据质量，以及在预训练阶段进行数据去重的具体方法和注意事项。</p>\n<hr>\n<h2 id=\"数据质量评估与打分\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#数据质量评估与打分\"><span>数据质量评估与打分</span></a></h2>\n<h3 id=\"✅-模型打分器的选择\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#✅-模型打分器的选择\"><span>✅ <strong>模型打分器的选择</strong></span></a></h3>\n<ul>\n<li><strong>BERT模型优先</strong>：在相同大小下，BERT结构的表征能力优于Transformer-Decoder模型，因此推荐使用BERT类型模型进行微调。</li>\n<li><strong>强闭源模型</strong>：如GPT-4o，可以用于对训练数据进行打分。\n<img src=\"/img/user/附件/Pasted image 20250408122345.png\" alt=\"Pasted image 20250408122345.png\"></li>\n</ul>\n<h3 id=\"⚠-训练打分器的注意事项\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#⚠-训练打分器的注意事项\"><span>⚠ <strong>训练打分器的注意事项</strong></span></a></h3>\n<ul>\n<li>不必追求打分器100%的准确率，&quot;凑合能用&quot;即可。</li>\n<li>数据规模不必完全匹配：例如，32K语料只需用4K规模的打分器即可。</li>\n</ul>\n<p>💡 <strong>启发点</strong>：打分器的训练时间和资源投入应适度，避免过度优化导致效率低下。</p>\n<hr>\n<h2 id=\"数据去重的三大类别\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#数据去重的三大类别\"><span>数据去重的三大类别</span></a></h2>\n<h3 id=\"❗-数据重复类型\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#❗-数据重复类型\"><span>❗ <strong>数据重复类型</strong></span></a></h3>\n<ol>\n<li>\n<p><strong>训练数据集内部重复</strong>：</p>\n<ul>\n<li>单个文档内部的重复（如重复行、段落、n-grams）。</li>\n<li>多个文档之间的完全匹配或模糊匹配。</li>\n<li>示例：CommonCrawl 和 T5 的 C4 数据集存在来源重复。</li>\n</ul>\n</li>\n<li>\n<p><strong>训练迭代设置的重复</strong>：</p>\n<ul>\n<li>不同数据集采样时设定的重复轮次（Epochs）。</li>\n</ul>\n</li>\n<li>\n<p><strong>训练与测试集的重复</strong>：</p>\n<ul>\n<li>测试集应从训练集移除相似数据，以避免影响评估结果。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h2 id=\"数据去重流程\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#数据去重流程\"><span>数据去重流程</span></a></h2>\n<h3 id=\"✅-操作步骤\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#✅-操作步骤\"><span>✅ <strong>操作步骤</strong></span></a></h3>\n<ol>\n<li>\n<p><strong>确定处理单元（Unit）</strong>：</p>\n<ul>\n<li>根据数据来源和特征选择基本处理单元。</li>\n<li>示例：\n<ul>\n<li>CommonCrawl：按行级别去重（Line-level）。</li>\n<li>Books3：按书籍覆盖率超过90%进行去重。</li>\n<li>Github代码：按文件级别完全匹配去重。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>Unit自身去重</strong>：</p>\n<ul>\n<li>分析单元内部是否存在大量重复内容（如重复行或段落）。</li>\n<li>如果重复比例过高，则直接丢弃整个单元。</li>\n</ul>\n</li>\n<li>\n<p><strong>Unit之间去重</strong>：</p>\n<ul>\n<li>检查多个单元之间是否存在完全匹配或模糊匹配重复。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h2 id=\"常见错误与注意事项\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#常见错误与注意事项\"><span>常见错误与注意事项</span></a></h2>\n<h3 id=\"⚠-警告区块\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#⚠-警告区块\"><span>⚠ <strong>警告区块</strong></span></a></h3>\n<ul>\n<li><strong>误区1</strong>：过度依赖打分器的准确率，忽略其实际应用价值。</li>\n<li><strong>误区2</strong>：未对测试集和训练集进行严格去重，导致评估结果失真。</li>\n<li><strong>误区3</strong>：忽视单元内部质量，直接使用低质量数据。</li>\n</ul>\n<hr>\n<h2 id=\"📈-趋势预测\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#📈-趋势预测\"><span>📈 趋势预测</span></a></h2>\n<ol>\n<li>随着预训练模型规模扩大，数据清洗和去重算法将更加智能化，可能出现基于深度学习的自动化质量评估工具。</li>\n<li>数据来源多样化将进一步增加去重难度，未来或需更复杂的模糊匹配算法。</li>\n</ol>\n<hr>\n<h2 id=\"思考-延伸问题\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#思考-延伸问题\"><span>[思考] 延伸问题</span></a></h2>\n<ol>\n<li>如何平衡数据清洗效率与模型性能提升之间的资源投入？</li>\n<li>对于多语言预训练模型，是否需要针对不同语言定制化的去重策略？</li>\n<li>是否可以通过生成式AI辅助更高效地完成数据质量评估？</li>\n</ol>\n<hr>\n<h2 id=\"行动清单\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#行动清单\"><span>行动清单</span></a></h2>\n<ul class=\"task-list-container\">\n<li class=\"task-list-item\"><input type=\"checkbox\" class=\"task-list-item-checkbox\" id=\"task-item-0\" disabled=\"disabled\"><label class=\"task-list-item-label\" for=\"task-item-0\"> 研究并尝试使用BERT或FastText进行打分器微调。</label></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" class=\"task-list-item-checkbox\" id=\"task-item-1\" disabled=\"disabled\"><label class=\"task-list-item-label\" for=\"task-item-1\"> 针对不同类型数据集设计适配性强的去重流程。</label></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" class=\"task-list-item-checkbox\" id=\"task-item-2\" disabled=\"disabled\"><label class=\"task-list-item-label\" for=\"task-item-2\"> 探索自动化工具以提升数据清洗效率。</label></li>\n</ul>\n<hr>\n<h2 id=\"后续追踪\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#后续追踪\"><span>后续追踪</span></a></h2>\n<ul>\n<li>深入研究基于模糊匹配算法的数据去重方法。</li>\n<li>调研现有闭源模型（如GPT系列）在数据质量评估中的应用案例。</li>\n<li>开发通用型打分器以适配多类型数据集。</li>\n</ul>\n<hr>\n<blockquote>\n<p>原文出处：《模型打分与数据去重在预训练中的应用》</p>\n</blockquote>\n","env":{"base":"/","filePath":"/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Pre-training 预训练/模型打分与数据去重 2.md","filePathRelative":"notes_bak/大语言模型学习/Pre-training 预训练/模型打分与数据去重 2.md","frontmatter":{"dg-publish":true,"dg-permalink":"/大语言模型学习/Pre-training-预训练/模型打分与数据去重","dg-home":false,"dg-description":"在此输入笔记的描述","dg-hide":false,"dg-hide-title":false,"dg-show-backlinks":true,"dg-show-local-graph":true,"dg-show-inline-title":true,"dg-pinned":false,"dg-passphrase":"在此输入访问密码","dg-enable-mathjax":false,"dg-enable-mermaid":false,"dg-enable-uml":false,"dg-note-icon":0,"dg-enable-dataview":false,"tags":["NLP"],"permalink":"/大语言模型学习/Pre-training-预训练/模型打分与数据去重/","dgShowBacklinks":true,"dgShowLocalGraph":true,"dgShowInlineTitle":true,"dgPassFrontmatter":true,"noteIcon":0,"created":"2025-04-08T04:21:31.000Z","updated":"2025-04-13T05:06:02.000Z","title":"模型打分与数据去重","createTime":"2025/05/13 17:33:53"},"sfcBlocks":{"template":{"type":"template","content":"<template><h2 id=\"元数据\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#元数据\"><span>元数据</span></a></h2>\n<p><strong>分类</strong>：数据处理与机器学习<br>\n<strong>标签</strong>：数据清洗、预训练模型、去重算法<br>\n<strong>日期</strong>：2023-10-31</p>\n<hr>\n<h2 id=\"核心观点总结\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心观点总结\"><span>核心观点总结</span></a></h2>\n<p>在预训练模型开发过程中，数据质量直接影响模型性能。通过模型打分和数据去重，可以有效提升训练数据的质量。本文探讨了如何利用打分模型评估数据质量，以及在预训练阶段进行数据去重的具体方法和注意事项。</p>\n<hr>\n<h2 id=\"数据质量评估与打分\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#数据质量评估与打分\"><span>数据质量评估与打分</span></a></h2>\n<h3 id=\"✅-模型打分器的选择\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#✅-模型打分器的选择\"><span>✅ <strong>模型打分器的选择</strong></span></a></h3>\n<ul>\n<li><strong>BERT模型优先</strong>：在相同大小下，BERT结构的表征能力优于Transformer-Decoder模型，因此推荐使用BERT类型模型进行微调。</li>\n<li><strong>强闭源模型</strong>：如GPT-4o，可以用于对训练数据进行打分。\n<img src=\"/img/user/附件/Pasted image 20250408122345.png\" alt=\"Pasted image 20250408122345.png\"></li>\n</ul>\n<h3 id=\"⚠-训练打分器的注意事项\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#⚠-训练打分器的注意事项\"><span>⚠ <strong>训练打分器的注意事项</strong></span></a></h3>\n<ul>\n<li>不必追求打分器100%的准确率，&quot;凑合能用&quot;即可。</li>\n<li>数据规模不必完全匹配：例如，32K语料只需用4K规模的打分器即可。</li>\n</ul>\n<p>💡 <strong>启发点</strong>：打分器的训练时间和资源投入应适度，避免过度优化导致效率低下。</p>\n<hr>\n<h2 id=\"数据去重的三大类别\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#数据去重的三大类别\"><span>数据去重的三大类别</span></a></h2>\n<h3 id=\"❗-数据重复类型\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#❗-数据重复类型\"><span>❗ <strong>数据重复类型</strong></span></a></h3>\n<ol>\n<li>\n<p><strong>训练数据集内部重复</strong>：</p>\n<ul>\n<li>单个文档内部的重复（如重复行、段落、n-grams）。</li>\n<li>多个文档之间的完全匹配或模糊匹配。</li>\n<li>示例：CommonCrawl 和 T5 的 C4 数据集存在来源重复。</li>\n</ul>\n</li>\n<li>\n<p><strong>训练迭代设置的重复</strong>：</p>\n<ul>\n<li>不同数据集采样时设定的重复轮次（Epochs）。</li>\n</ul>\n</li>\n<li>\n<p><strong>训练与测试集的重复</strong>：</p>\n<ul>\n<li>测试集应从训练集移除相似数据，以避免影响评估结果。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h2 id=\"数据去重流程\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#数据去重流程\"><span>数据去重流程</span></a></h2>\n<h3 id=\"✅-操作步骤\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#✅-操作步骤\"><span>✅ <strong>操作步骤</strong></span></a></h3>\n<ol>\n<li>\n<p><strong>确定处理单元（Unit）</strong>：</p>\n<ul>\n<li>根据数据来源和特征选择基本处理单元。</li>\n<li>示例：\n<ul>\n<li>CommonCrawl：按行级别去重（Line-level）。</li>\n<li>Books3：按书籍覆盖率超过90%进行去重。</li>\n<li>Github代码：按文件级别完全匹配去重。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>Unit自身去重</strong>：</p>\n<ul>\n<li>分析单元内部是否存在大量重复内容（如重复行或段落）。</li>\n<li>如果重复比例过高，则直接丢弃整个单元。</li>\n</ul>\n</li>\n<li>\n<p><strong>Unit之间去重</strong>：</p>\n<ul>\n<li>检查多个单元之间是否存在完全匹配或模糊匹配重复。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h2 id=\"常见错误与注意事项\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#常见错误与注意事项\"><span>常见错误与注意事项</span></a></h2>\n<h3 id=\"⚠-警告区块\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#⚠-警告区块\"><span>⚠ <strong>警告区块</strong></span></a></h3>\n<ul>\n<li><strong>误区1</strong>：过度依赖打分器的准确率，忽略其实际应用价值。</li>\n<li><strong>误区2</strong>：未对测试集和训练集进行严格去重，导致评估结果失真。</li>\n<li><strong>误区3</strong>：忽视单元内部质量，直接使用低质量数据。</li>\n</ul>\n<hr>\n<h2 id=\"📈-趋势预测\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#📈-趋势预测\"><span>📈 趋势预测</span></a></h2>\n<ol>\n<li>随着预训练模型规模扩大，数据清洗和去重算法将更加智能化，可能出现基于深度学习的自动化质量评估工具。</li>\n<li>数据来源多样化将进一步增加去重难度，未来或需更复杂的模糊匹配算法。</li>\n</ol>\n<hr>\n<h2 id=\"思考-延伸问题\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#思考-延伸问题\"><span>[思考] 延伸问题</span></a></h2>\n<ol>\n<li>如何平衡数据清洗效率与模型性能提升之间的资源投入？</li>\n<li>对于多语言预训练模型，是否需要针对不同语言定制化的去重策略？</li>\n<li>是否可以通过生成式AI辅助更高效地完成数据质量评估？</li>\n</ol>\n<hr>\n<h2 id=\"行动清单\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#行动清单\"><span>行动清单</span></a></h2>\n<ul class=\"task-list-container\">\n<li class=\"task-list-item\"><input type=\"checkbox\" class=\"task-list-item-checkbox\" id=\"task-item-0\" disabled=\"disabled\"><label class=\"task-list-item-label\" for=\"task-item-0\"> 研究并尝试使用BERT或FastText进行打分器微调。</label></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" class=\"task-list-item-checkbox\" id=\"task-item-1\" disabled=\"disabled\"><label class=\"task-list-item-label\" for=\"task-item-1\"> 针对不同类型数据集设计适配性强的去重流程。</label></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" class=\"task-list-item-checkbox\" id=\"task-item-2\" disabled=\"disabled\"><label class=\"task-list-item-label\" for=\"task-item-2\"> 探索自动化工具以提升数据清洗效率。</label></li>\n</ul>\n<hr>\n<h2 id=\"后续追踪\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#后续追踪\"><span>后续追踪</span></a></h2>\n<ul>\n<li>深入研究基于模糊匹配算法的数据去重方法。</li>\n<li>调研现有闭源模型（如GPT系列）在数据质量评估中的应用案例。</li>\n<li>开发通用型打分器以适配多类型数据集。</li>\n</ul>\n<hr>\n<blockquote>\n<p>原文出处：《模型打分与数据去重在预训练中的应用》</p>\n</blockquote>\n</template>","contentStripped":"<h2 id=\"元数据\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#元数据\"><span>元数据</span></a></h2>\n<p><strong>分类</strong>：数据处理与机器学习<br>\n<strong>标签</strong>：数据清洗、预训练模型、去重算法<br>\n<strong>日期</strong>：2023-10-31</p>\n<hr>\n<h2 id=\"核心观点总结\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心观点总结\"><span>核心观点总结</span></a></h2>\n<p>在预训练模型开发过程中，数据质量直接影响模型性能。通过模型打分和数据去重，可以有效提升训练数据的质量。本文探讨了如何利用打分模型评估数据质量，以及在预训练阶段进行数据去重的具体方法和注意事项。</p>\n<hr>\n<h2 id=\"数据质量评估与打分\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#数据质量评估与打分\"><span>数据质量评估与打分</span></a></h2>\n<h3 id=\"✅-模型打分器的选择\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#✅-模型打分器的选择\"><span>✅ <strong>模型打分器的选择</strong></span></a></h3>\n<ul>\n<li><strong>BERT模型优先</strong>：在相同大小下，BERT结构的表征能力优于Transformer-Decoder模型，因此推荐使用BERT类型模型进行微调。</li>\n<li><strong>强闭源模型</strong>：如GPT-4o，可以用于对训练数据进行打分。\n<img src=\"/img/user/附件/Pasted image 20250408122345.png\" alt=\"Pasted image 20250408122345.png\"></li>\n</ul>\n<h3 id=\"⚠-训练打分器的注意事项\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#⚠-训练打分器的注意事项\"><span>⚠ <strong>训练打分器的注意事项</strong></span></a></h3>\n<ul>\n<li>不必追求打分器100%的准确率，&quot;凑合能用&quot;即可。</li>\n<li>数据规模不必完全匹配：例如，32K语料只需用4K规模的打分器即可。</li>\n</ul>\n<p>💡 <strong>启发点</strong>：打分器的训练时间和资源投入应适度，避免过度优化导致效率低下。</p>\n<hr>\n<h2 id=\"数据去重的三大类别\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#数据去重的三大类别\"><span>数据去重的三大类别</span></a></h2>\n<h3 id=\"❗-数据重复类型\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#❗-数据重复类型\"><span>❗ <strong>数据重复类型</strong></span></a></h3>\n<ol>\n<li>\n<p><strong>训练数据集内部重复</strong>：</p>\n<ul>\n<li>单个文档内部的重复（如重复行、段落、n-grams）。</li>\n<li>多个文档之间的完全匹配或模糊匹配。</li>\n<li>示例：CommonCrawl 和 T5 的 C4 数据集存在来源重复。</li>\n</ul>\n</li>\n<li>\n<p><strong>训练迭代设置的重复</strong>：</p>\n<ul>\n<li>不同数据集采样时设定的重复轮次（Epochs）。</li>\n</ul>\n</li>\n<li>\n<p><strong>训练与测试集的重复</strong>：</p>\n<ul>\n<li>测试集应从训练集移除相似数据，以避免影响评估结果。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h2 id=\"数据去重流程\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#数据去重流程\"><span>数据去重流程</span></a></h2>\n<h3 id=\"✅-操作步骤\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#✅-操作步骤\"><span>✅ <strong>操作步骤</strong></span></a></h3>\n<ol>\n<li>\n<p><strong>确定处理单元（Unit）</strong>：</p>\n<ul>\n<li>根据数据来源和特征选择基本处理单元。</li>\n<li>示例：\n<ul>\n<li>CommonCrawl：按行级别去重（Line-level）。</li>\n<li>Books3：按书籍覆盖率超过90%进行去重。</li>\n<li>Github代码：按文件级别完全匹配去重。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>Unit自身去重</strong>：</p>\n<ul>\n<li>分析单元内部是否存在大量重复内容（如重复行或段落）。</li>\n<li>如果重复比例过高，则直接丢弃整个单元。</li>\n</ul>\n</li>\n<li>\n<p><strong>Unit之间去重</strong>：</p>\n<ul>\n<li>检查多个单元之间是否存在完全匹配或模糊匹配重复。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h2 id=\"常见错误与注意事项\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#常见错误与注意事项\"><span>常见错误与注意事项</span></a></h2>\n<h3 id=\"⚠-警告区块\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#⚠-警告区块\"><span>⚠ <strong>警告区块</strong></span></a></h3>\n<ul>\n<li><strong>误区1</strong>：过度依赖打分器的准确率，忽略其实际应用价值。</li>\n<li><strong>误区2</strong>：未对测试集和训练集进行严格去重，导致评估结果失真。</li>\n<li><strong>误区3</strong>：忽视单元内部质量，直接使用低质量数据。</li>\n</ul>\n<hr>\n<h2 id=\"📈-趋势预测\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#📈-趋势预测\"><span>📈 趋势预测</span></a></h2>\n<ol>\n<li>随着预训练模型规模扩大，数据清洗和去重算法将更加智能化，可能出现基于深度学习的自动化质量评估工具。</li>\n<li>数据来源多样化将进一步增加去重难度，未来或需更复杂的模糊匹配算法。</li>\n</ol>\n<hr>\n<h2 id=\"思考-延伸问题\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#思考-延伸问题\"><span>[思考] 延伸问题</span></a></h2>\n<ol>\n<li>如何平衡数据清洗效率与模型性能提升之间的资源投入？</li>\n<li>对于多语言预训练模型，是否需要针对不同语言定制化的去重策略？</li>\n<li>是否可以通过生成式AI辅助更高效地完成数据质量评估？</li>\n</ol>\n<hr>\n<h2 id=\"行动清单\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#行动清单\"><span>行动清单</span></a></h2>\n<ul class=\"task-list-container\">\n<li class=\"task-list-item\"><input type=\"checkbox\" class=\"task-list-item-checkbox\" id=\"task-item-0\" disabled=\"disabled\"><label class=\"task-list-item-label\" for=\"task-item-0\"> 研究并尝试使用BERT或FastText进行打分器微调。</label></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" class=\"task-list-item-checkbox\" id=\"task-item-1\" disabled=\"disabled\"><label class=\"task-list-item-label\" for=\"task-item-1\"> 针对不同类型数据集设计适配性强的去重流程。</label></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" class=\"task-list-item-checkbox\" id=\"task-item-2\" disabled=\"disabled\"><label class=\"task-list-item-label\" for=\"task-item-2\"> 探索自动化工具以提升数据清洗效率。</label></li>\n</ul>\n<hr>\n<h2 id=\"后续追踪\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#后续追踪\"><span>后续追踪</span></a></h2>\n<ul>\n<li>深入研究基于模糊匹配算法的数据去重方法。</li>\n<li>调研现有闭源模型（如GPT系列）在数据质量评估中的应用案例。</li>\n<li>开发通用型打分器以适配多类型数据集。</li>\n</ul>\n<hr>\n<blockquote>\n<p>原文出处：《模型打分与数据去重在预训练中的应用》</p>\n</blockquote>\n","tagOpen":"<template>","tagClose":"</template>"},"script":null,"scriptSetup":null,"scripts":[],"styles":[],"customBlocks":[]},"content":"## 元数据\n**分类**：数据处理与机器学习  \n**标签**：数据清洗、预训练模型、去重算法  \n**日期**：2023-10-31  \n\n---\n\n\n\n## 核心观点总结\n在预训练模型开发过程中，数据质量直接影响模型性能。通过模型打分和数据去重，可以有效提升训练数据的质量。本文探讨了如何利用打分模型评估数据质量，以及在预训练阶段进行数据去重的具体方法和注意事项。\n\n---\n\n\n\n## 数据质量评估与打分\n\n### ✅ **模型打分器的选择**\n- **BERT模型优先**：在相同大小下，BERT结构的表征能力优于Transformer-Decoder模型，因此推荐使用BERT类型模型进行微调。\n- **强闭源模型**：如GPT-4o，可以用于对训练数据进行打分。\n![Pasted image 20250408122345.png](/img/user/%E9%99%84%E4%BB%B6/Pasted%20image%2020250408122345.png)\n\n\n### ⚠ **训练打分器的注意事项**\n- 不必追求打分器100%的准确率，\"凑合能用\"即可。\n- 数据规模不必完全匹配：例如，32K语料只需用4K规模的打分器即可。\n  \n💡 **启发点**：打分器的训练时间和资源投入应适度，避免过度优化导致效率低下。\n\n---\n\n\n\n## 数据去重的三大类别\n\n### ❗ **数据重复类型**\n1. **训练数据集内部重复**：\n   - 单个文档内部的重复（如重复行、段落、n-grams）。\n   - 多个文档之间的完全匹配或模糊匹配。\n   - 示例：CommonCrawl 和 T5 的 C4 数据集存在来源重复。\n   \n2. **训练迭代设置的重复**：\n   - 不同数据集采样时设定的重复轮次（Epochs）。\n   \n3. **训练与测试集的重复**：\n   - 测试集应从训练集移除相似数据，以避免影响评估结果。\n\n---\n\n\n\n## 数据去重流程\n\n### ✅ **操作步骤**\n1. **确定处理单元（Unit）**：\n   - 根据数据来源和特征选择基本处理单元。\n   - 示例：\n     - CommonCrawl：按行级别去重（Line-level）。\n     - Books3：按书籍覆盖率超过90%进行去重。\n     - Github代码：按文件级别完全匹配去重。\n\n2. **Unit自身去重**：\n   - 分析单元内部是否存在大量重复内容（如重复行或段落）。\n   - 如果重复比例过高，则直接丢弃整个单元。\n\n3. **Unit之间去重**：\n   - 检查多个单元之间是否存在完全匹配或模糊匹配重复。\n\n---\n\n\n\n## 常见错误与注意事项\n\n### ⚠ **警告区块**\n- **误区1**：过度依赖打分器的准确率，忽略其实际应用价值。\n- **误区2**：未对测试集和训练集进行严格去重，导致评估结果失真。\n- **误区3**：忽视单元内部质量，直接使用低质量数据。\n\n---\n\n\n\n## 📈 趋势预测\n1. 随着预训练模型规模扩大，数据清洗和去重算法将更加智能化，可能出现基于深度学习的自动化质量评估工具。\n2. 数据来源多样化将进一步增加去重难度，未来或需更复杂的模糊匹配算法。\n\n---\n\n\n\n## [思考] 延伸问题\n1. 如何平衡数据清洗效率与模型性能提升之间的资源投入？\n2. 对于多语言预训练模型，是否需要针对不同语言定制化的去重策略？\n3. 是否可以通过生成式AI辅助更高效地完成数据质量评估？\n\n---\n\n\n\n## 行动清单\n- [ ] 研究并尝试使用BERT或FastText进行打分器微调。\n- [ ] 针对不同类型数据集设计适配性强的去重流程。\n- [ ] 探索自动化工具以提升数据清洗效率。\n\n---\n\n\n\n## 后续追踪\n- 深入研究基于模糊匹配算法的数据去重方法。\n- 调研现有闭源模型（如GPT系列）在数据质量评估中的应用案例。\n- 开发通用型打分器以适配多类型数据集。\n\n---\n\n> 原文出处：《模型打分与数据去重在预训练中的应用》","excerpt":"","includedFiles":[],"tasklistId":3,"title":"","headers":[{"level":2,"title":"元数据","slug":"元数据","link":"#元数据","children":[]},{"level":2,"title":"核心观点总结","slug":"核心观点总结","link":"#核心观点总结","children":[]},{"level":2,"title":"数据质量评估与打分","slug":"数据质量评估与打分","link":"#数据质量评估与打分","children":[{"level":3,"title":"✅ 模型打分器的选择","slug":"✅-模型打分器的选择","link":"#✅-模型打分器的选择","children":[]},{"level":3,"title":"⚠ 训练打分器的注意事项","slug":"⚠-训练打分器的注意事项","link":"#⚠-训练打分器的注意事项","children":[]}]},{"level":2,"title":"数据去重的三大类别","slug":"数据去重的三大类别","link":"#数据去重的三大类别","children":[{"level":3,"title":"❗ 数据重复类型","slug":"❗-数据重复类型","link":"#❗-数据重复类型","children":[]}]},{"level":2,"title":"数据去重流程","slug":"数据去重流程","link":"#数据去重流程","children":[{"level":3,"title":"✅ 操作步骤","slug":"✅-操作步骤","link":"#✅-操作步骤","children":[]}]},{"level":2,"title":"常见错误与注意事项","slug":"常见错误与注意事项","link":"#常见错误与注意事项","children":[{"level":3,"title":"⚠ 警告区块","slug":"⚠-警告区块","link":"#⚠-警告区块","children":[]}]},{"level":2,"title":"📈 趋势预测","slug":"📈-趋势预测","link":"#📈-趋势预测","children":[]},{"level":2,"title":"[思考] 延伸问题","slug":"思考-延伸问题","link":"#思考-延伸问题","children":[]},{"level":2,"title":"行动清单","slug":"行动清单","link":"#行动清单","children":[]},{"level":2,"title":"后续追踪","slug":"后续追踪","link":"#后续追踪","children":[]}]}}
