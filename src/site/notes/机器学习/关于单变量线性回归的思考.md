---
{"dg-publish":true,"tags":["机器学习"],"title":"单变量线性回归","dg-permalink":"/机器学习/单变量","permalink":"/机器学习/单变量/","dgPassFrontmatter":true,"noteIcon":"","created":"2024-12-25T19:00:30.000+08:00","updated":"2025-01-01T22:37:56.000+08:00"}
---



2. 机器学习的训练过程的核心就是通过调整模型的参数，使得预测值与真实值之间的差距（即代价函数的值）最小化。而具体的优化过程通常是通过 **梯度下降** 等方法完成的
3. 通过确定参数,然后根据特定参数给出的预测值与真实值的平方差和来确定是不是合适的参数
4. ![Pasted image 20241225190332.png](/img/user/%E9%99%84%E4%BB%B6/Pasted%20image%2020241225190332.png)
5. 代价函数优化的核心：为什么是梯度
优化过程是**寻找代价函数的最小值**，而梯度在这个过程中起到了关键作用。
**什么是梯度？**

• 梯度是指函数的偏导数，表示函数在某一点处的变化率或斜率。

• 在多维空间中，梯度是一个向量，指向函数增长最快的方向。

**为什么用梯度优化参数？**

• **梯度指引方向**：

• 梯度指出了代价函数增大的方向。如果我们希望减小代价函数值，只需要朝梯度的**反方向**移动。

• 换句话说，梯度下降法是一种从高处“下坡”的方法，沿着坡度最陡的方向下降，直到找到最低点（全局最小值或局部最小值）。
