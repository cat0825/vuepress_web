---
dg-publish: true
dg-permalink: /å¤§è¯­è¨€æ¨¡åž‹å­¦ä¹ /RLå¼ºåŒ–å­¦ä¹ åŸºç¡€/LoRAåŠå…¶å˜ä½“/X-LoRA
dg-home: false
dg-description: åœ¨æ­¤è¾“å…¥ç¬”è®°çš„æè¿°
dg-hide: false
dg-hide-title: false
dg-show-backlinks: true
dg-show-local-graph: true
dg-show-inline-title: true
dg-pinned: false
dg-passphrase: åœ¨æ­¤è¾“å…¥è®¿é—®å¯†ç 
dg-enable-mathjax: false
dg-enable-mermaid: false
dg-enable-uml: false
dg-note-icon: 0
dg-enable-dataview: false
tags:
  - NLP
permalink: /å¤§è¯­è¨€æ¨¡åž‹å­¦ä¹ /RLå¼ºåŒ–å­¦ä¹ åŸºç¡€/LoRAåŠå…¶å˜ä½“/X-LoRA/
dgShowBacklinks: true
dgShowLocalGraph: true
dgShowInlineTitle: true
dgPassFrontmatter: true
noteIcon: 0
created: 2025-04-24T11:19:18.000+08:00
updated: 2025-04-24T11:21:31.000+08:00
title: X-LoRA
createTime: 2025/05/13 17:33:52
---



# X-Loraï¼šåŠ¨æ€ç¼©æ”¾çš„å¤šé¢†åŸŸé¢„è®­ç»ƒæ¨¡åž‹é›†æˆ

## å…ƒæ•°æ®
- åˆ†ç±»ï¼šæœºå™¨å­¦ä¹ 
- æ ‡ç­¾ï¼šX-Lora, é¢„è®­ç»ƒæ¨¡åž‹, åŠ¨æ€ç¼©æ”¾, ä½Žç§©é€‚åº”
- æ—¥æœŸï¼š2025å¹´4æœˆ12æ—¥


## æ ¸å¿ƒè§‚ç‚¹
X-Loraé€šè¿‡ç»“åˆå¤šä¸ªä¸åŒé¢†åŸŸçš„é¢„è®­ç»ƒçš„Loraæ¨¡åž‹ï¼Œå¹¶é€šè¿‡ä¸€ä¸ªå¯è®­ç»ƒçš„ç¼©æ”¾å¤´æ¥åŠ¨æ€è°ƒæ•´æ¯ä¸ªLoraæ¨¡åž‹çš„è´¡çŒ®ã€‚è¿™ç§æ–¹æ³•å…è®¸åœ¨ä¸åŒä»»åŠ¡ä¸­çµæ´»åº”ç”¨å¤šä¸ªä½Žç§©é€‚åº”æŠ€æœ¯ï¼Œä»¥æé«˜æ¨¡åž‹çš„æ•ˆçŽ‡å’Œæ€§èƒ½ã€‚

![Pasted-image-20250424111942.png](/img/user/%E9%99%84%E4%BB%B6/Pasted%20image%2020250424111942.png)


## é‡ç‚¹å†…å®¹

### åŠ¨æ€ç¼©æ”¾æœºåˆ¶
X-Loraä½¿ç”¨ä¸€ä¸ªåŠ¨æ€ç¼©æ”¾æœºåˆ¶æ¥è°ƒæ•´æ¯ä¸ªLoraæ¨¡åž‹åœ¨æœ€ç»ˆè¾“å‡ºä¸­çš„è´¡çŒ®ã€‚è¿™ä¸ªè¿‡ç¨‹åŒ…æ‹¬ï¼š

1. **èŽ·å–ç¼©æ”¾å€¼**ï¼šä»Žç»™å®šçš„ç¼©æ”¾çŸ©é˜µä¸­æå–ç‰¹å®šå±‚çš„ç¼©æ”¾å€¼ã€‚
2. **é€‰æ‹©Top-Kç¼©æ”¾**ï¼šæ ¹æ®é…ç½®ï¼Œé€‰æ‹©è´¡çŒ®æœ€å¤§çš„Top-Kä¸ªç¼©æ”¾å€¼ã€‚
3. **åº”ç”¨Softmax**ï¼šå¦‚æžœå¯ç”¨ï¼Œä½¿ç”¨Softmaxå‡½æ•°å¯¹éžé›¶ç¼©æ”¾å€¼è¿›è¡Œå½’ä¸€åŒ–å¤„ç†ã€‚


### XLoraLinearLayerçš„å‰å‘ä¼ æ’­
åœ¨XLoraLinearLayerç±»ä¸­ï¼Œå‰å‘ä¼ æ’­è¿‡ç¨‹å¦‚ä¸‹ï¼š

1. æ£€æŸ¥ç›®æ ‡æ˜¯å¦å·²åˆå¹¶ã€‚
2. éåŽ†æ¯ä¸ªæ´»è·ƒçš„é€‚é…å™¨ï¼ŒèŽ·å–ç›¸åº”çš„Loraæƒé‡å’Œç¼©æ”¾å‚æ•°ã€‚
3. æ ¹æ®éœ€è¦åº”ç”¨ç¼©æ”¾è°ƒæ•´ã€‚
4. è®¡ç®—ç»“æžœå¹¶è¿”å›žã€‚


### ä»£ç ç¤ºä¾‹
```python
def get_maybe_topk_scalings(self, scalings) -> torch.Tensor:
    xlora_scalings = scalings[:, :, self.layer_number, :]
    if self.config.top_k_lora is not None:
        _, topk_indices = torch.topk(xlora_scalings, k=self.config.top_k_lora, dim=-1)
        mask = torch.zeros_like(xlora_scalings, dtype=torch.bool)
        mask.scatter_(-1, topk_indices, True)
        xlora_scalings = xlora_scalings * mask.to(xlora_scalings.dtype)

    if self.config.enable_softmax_topk:
        nonzero_mask = xlora_scalings != 0
        softmax_res_nonzero = torch.softmax(xlora_scalings[nonzero_mask], dim=-1)
        xlora_scalings[nonzero_mask] = softmax_res_nonzero

    return xlora_scalings
```


### ðŸ’¡ å¯å‘ç‚¹
è¿™ç§æ–¹æ³•ä¸ä»…æé«˜äº†æ¨¡åž‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„é€‚åº”èƒ½åŠ›ï¼Œè¿˜å¯ä»¥åœ¨ä¸æ˜¾è‘—å¢žåŠ è®¡ç®—æˆæœ¬çš„æƒ…å†µä¸‹ï¼Œåˆ©ç”¨å¤šä¸ªé¢†åŸŸçš„çŸ¥è¯†ã€‚


## è­¦å‘ŠåŒºå—
âš ï¸ å¸¸è§é”™è¯¯ï¼šç¡®ä¿åœ¨åº”ç”¨ç¼©æ”¾æ—¶ï¼Œéžé›¶æŽ©ç å’ŒSoftmaxå‡½æ•°æ­£ç¡®é…ç½®ï¼Œå¦åˆ™å¯èƒ½å¯¼è‡´ç¼©æ”¾ä¸å‡†ç¡®ã€‚


## è¡ŒåŠ¨æ¸…å•
- æŽ¢ç´¢æ›´å¤šçš„ä½Žç§©é€‚åº”æŠ€æœ¯ä¸ŽX-Loraç»“åˆçš„å¯èƒ½æ€§ã€‚
- è¯„ä¼°X-Loraåœ¨ä¸åŒé¢†åŸŸä»»åŠ¡ä¸­çš„æ€§èƒ½è¡¨çŽ°ã€‚
- ä¼˜åŒ–åŠ¨æ€ç¼©æ”¾å¤´çš„è®­ç»ƒç­–ç•¥ä»¥æé«˜æ¨¡åž‹æ•ˆçŽ‡ã€‚

> åŽŸå§‹å‡ºå¤„ï¼š[LoRA: Low-Rank Adaptation of Large Language Models](https://example.com)
