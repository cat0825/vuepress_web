{"content":"<h2 id=\"什么是llm-agent\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#什么是llm-agent\"><span>什么是LLM Agent？</span></a></h2>\n<p>LLM Agent是一种超越简单文本生成的人工智能系统。它以大语言模型（LLM）作为核心计算引擎，使其能够与用户进行对话、执行任务、进行推理，并展现出一定程度的自主性。简而言之，LLM Agent是一个具有复杂推理能力、记忆和执行任务能力的系统。\n<img src=\"/img/user/附件/Pasted image 20250504190059.png\" alt=\"Pasted image 20250504190059.png\">\nLLM Agent的定义可以概括为：通过与生成式人工智能（GenAI）本身之外的系统交互来服务于用户目标的GenAI系统。\n<img src=\"/img/user/附件/Pasted image 20250504190109.png\" alt=\"Pasted image 20250504190109.png\"></p>\n<h3 id=\"llm-agent的核心组成\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#llm-agent的核心组成\"><span>LLM Agent的核心组成</span></a></h3>\n<p>LLM Agent可能涉及单个外部系统（如计算器），也可能需要解决更复杂的路由问题，以决定需要使用哪种外部系统（通常包括记忆和规划功能）。总体而言，基于大模型的智能体（LLM-based Agent）的核心组成可以表示为：</p>\n<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>LLM-based Agent</mtext><mo>=</mo><mtext>LLM</mtext><mo>+</mo><mtext>工具调用</mtext><mo>+</mo><mtext>规划</mtext><mo>+</mo><mtext>记忆</mtext></mrow><annotation encoding=\"application/x-tex\">\\text{LLM-based Agent} = \\text{LLM} + \\text{工具调用} + \\text{规划} + \\text{记忆}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\"><span class=\"mord\">LLM-based Agent</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord text\"><span class=\"mord\">LLM</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">工具调用</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">规划</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">记忆</span></span></span></span></span></span></p>\n<hr>\n<h2 id=\"规划-planning\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#规划-planning\"><span>规划（Planning）</span></a></h2>\n<h3 id=\"子目标分解\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#子目标分解\"><span>子目标分解</span></a></h3>\n<p>在规划过程中，Agent会将一个复杂的大任务拆分为更小、更易于管理的子目标，从而能够更加高效地完成复杂任务。</p>\n<h4 id=\"目的\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#目的\"><span>目的</span></a></h4>\n<p>很多复杂任务通常由多个步骤组成，Agent需要清楚这些步骤是什么，并提前规划。例如，在前面提到的5.1.2章节中，CoT（Chain of Thought）以及其改进方法实际上就是在进行任务分解。</p>\n<h4 id=\"任务分解的实现方式\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#任务分解的实现方式\"><span>任务分解的实现方式</span></a></h4>\n<p>以下是实现任务分解的几种方式：</p>\n<ol>\n<li>\n<p><strong>直接提示</strong>：给LLM一个简单的提示词，例如：</p>\n<div class=\"language- line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code><span class=\"line\"><span>Steps for XYZ.</span></span>\n<span class=\"line\"><span>1.</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>或者：</p>\n<div class=\"language- line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code><span class=\"line\"><span>What are the subgoals for achieving XYZ?</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div></div></div></li>\n<li>\n<p><strong>具体指令</strong>：针对特定任务提供明确指令。例如，对于写小说的任务，可以先给出“Write a story outline.”这样的指令。</p>\n</li>\n<li>\n<p><strong>用户输入</strong>：由使用者直接输入明确的任务需求。</p>\n</li>\n</ol>\n<p>无论是CoT还是ToT（Tree of Thought），其本质都是通过精心设计的Prompt，激发模型原有的元认知（Metacognition）。关键在于如何通过某条神经元的线索，更加精准地调动模型中最擅长规划（Planning）的部分。</p>\n<hr>\n<p><img src=\"/img/user/附件/Pasted image 20250504190157.png\" alt=\"Pasted image 20250504190157.png\"></p>\n<h3 id=\"llm与pddl结合的规划方法\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#llm与pddl结合的规划方法\"><span>LLM与PDDL结合的规划方法</span></a></h3>\n<p>一种更为高级的规划方法是利用LLM进行长序列的整体规划。具体来说，这种方法使用规划域定义语言（PDDL，Planning Domain Definition Language）作为中间接口来描述规划问题。以下是具体步骤：</p>\n<ol>\n<li><strong>问题翻译</strong>：首先，LLM将问题翻译为PDDL格式的问题描述（问题PDDL）。</li>\n<li><strong>调用经典Planner</strong>：接着，请求经典Planner根据现有的领域PDDL生成一个PDDL计划。</li>\n<li><strong>自然语言翻译</strong>：最后，将PDDL计划翻译回自然语言，这一步由LLM完成。</li>\n</ol>\n<p>从根本上讲，Planning步骤被外包给了外部工具。但这需要满足一个前提条件：必须有特定领域的PDDL定义和合适的Planner工具。</p>\n<hr>\n<h2 id=\"反思与完善\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#反思与完善\"><span>反思与完善</span></a></h2>\n<h3 id=\"自我批评与反思\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#自我批评与反思\"><span>自我批评与反思</span></a></h3>\n<p>Agent能够对历史动作进行自我批评和反思，从错误中学习，并在后续步骤中不断完善，从而提高最终结果的质量。自我反思（Self-reflection）是一个非常重要的环节，它允许Agent通过完善过去的行动决策和纠正以前的错误来持续改进。</p>\n<p>在现实世界中的任务中，试错往往是无法避免的，而自我反思在其中发挥着至关重要的作用。</p>\n<hr>\n<h2 id=\"react-结合推理与行动\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#react-结合推理与行动\"><span>ReAct：结合推理与行动</span></a></h2>\n<p>ReAct是一种被分类在5.2.3章节中的Observation-based Agent方法，其全称为Reason+Act。该方法通过将Action Space扩展为特定任务的离散动作和语言空间的组合，在LLM内部整合了推理（Reasoning）和行动（Action）。</p>\n<ul>\n<li><strong>推理</strong>：使得LLM能够与环境交互。</li>\n<li><strong>行动</strong>：通过提示词，使得LLM用自然语言生成整体推理过程。</li>\n</ul>\n<p>ReAct提示词模板包含特定设计，以支持这种推理与行动结合的方法。\n<img src=\"/img/user/附件/Pasted image 20250504190209.png\" alt=\"Pasted image 20250504190209.png\"></p>\n<h1 id=\"记忆-memory\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#记忆-memory\"><span>记忆（Memory）</span></a></h1>\n<h2 id=\"短期记忆与长期记忆\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#短期记忆与长期记忆\"><span>短期记忆与长期记忆</span></a></h2>\n<h3 id=\"短期记忆-上下文学习\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#短期记忆-上下文学习\"><span>短期记忆：上下文学习</span></a></h3>\n<p>短期记忆指的是利用模型的短期记忆进行学习的能力。在上下文学习中，模型能够在短时间内获取、存储并处理信息，从而完成任务。</p>\n<h3 id=\"长期记忆\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#长期记忆\"><span>长期记忆</span></a></h3>\n<p>长期记忆为智能体（agent）提供保留和召回长期信息的能力。通常，这种能力通过外部向量存储和检索来实现。长期记忆的特点在于它能够支持信息的长时间保存与高效访问。\n<img src=\"/img/user/附件/Pasted image 20250504190306.png\" alt=\"Pasted image 20250504190306.png\"></p>\n<hr>\n<h2 id=\"记忆的定义与分类\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#记忆的定义与分类\"><span>记忆的定义与分类</span></a></h2>\n<p>记忆可以定义为一种用于获取、存储、保留和随后检索信息的过程。在人脑中，记忆可以分为以下几种类型：</p>\n<h3 id=\"感官记忆\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#感官记忆\"><span>感官记忆</span></a></h3>\n<p>感官记忆是记忆的最早期阶段，它指的是对原始刺激的感官印象（如视觉、听觉等）的保留能力。这类记忆通常只能持续几秒钟，包含以下三种类型：</p>\n<ul>\n<li><strong>图标记忆</strong>：与视觉相关的记忆。</li>\n<li><strong>回声记忆</strong>：与听觉相关的记忆。</li>\n<li><strong>触碰记忆</strong>：与触觉相关的记忆。</li>\n</ul>\n<h3 id=\"短时记忆-stm-或工作记忆\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#短时记忆-stm-或工作记忆\"><span>短时记忆（STM）或工作记忆</span></a></h3>\n<p>短时记忆存储我们当前意识到的信息，以及执行复杂认知任务（如学习和推理）所需的信息。短时记忆的容量通常为 <strong>7 个项目左右</strong>，并能够持续 <strong>20-30 秒</strong>。</p>\n<h3 id=\"长时记忆-ltm\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#长时记忆-ltm\"><span>长时记忆（LTM）</span></a></h3>\n<p>长时记忆能够将信息存储很长时间，从几天到几十年不等，其存储容量基本上是无限的。长时记忆可进一步分为以下两种类型：</p>\n<ol>\n<li>\n<p><strong>显性/陈述性记忆</strong><br>\n显性记忆是对事实和事件的记忆，指那些可以有意识地回忆起的内容，包括：</p>\n<ul>\n<li><strong>外显记忆</strong>：关于事件和经历的记忆。</li>\n<li><strong>语义记忆</strong>：关于事实和概括的记忆。</li>\n</ul>\n</li>\n<li>\n<p><strong>隐性/程序性记忆</strong><br>\n隐性记忆是无意识的，涉及自动执行的技能和例行程序，例如骑自行车或在键盘上打字。</p>\n</li>\n</ol>\n<hr>\n<h2 id=\"最大内部产品搜索-maximum-inner-product-search-mips\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#最大内部产品搜索-maximum-inner-product-search-mips\"><span>最大内部产品搜索（Maximum Inner Product Search, MIPS）</span></a></h2>\n<p>在利用外部存储器缓解关注范围有限的问题时，最大内部产品搜索（MIPS）是一种有效的方法。为了优化检索速度，常采用近似最近邻（ANN）算法。这些算法通过牺牲少量精度来显著提升速度，并返回近似的前 <span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span> 个近邻。以下是几种常见的 ANN 算法：</p>\n<h3 id=\"lsh-局部敏感哈希\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#lsh-局部敏感哈希\"><span>LSH （局部敏感哈希）</span></a></h3>\n<p>LSH 引入了一种哈希函数，该函数能够最大限度地将相似的输入项映射到同一个桶中。桶的数量远小于输入内容的数量，从而实现快速检索。</p>\n<h3 id=\"annoy-approximate-nearest-neighbors-oh-yeah\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#annoy-approximate-nearest-neighbors-oh-yeah\"><span>ANNOY （Approximate Nearest Neighbors Oh Yeah）</span></a></h3>\n<p>ANNOY 的核心数据结构是随机投影树，这是一种二叉树集合。具体而言：</p>\n<ul>\n<li>每个非叶子节点表示将输入空间划分为两半的一个超平面。</li>\n<li>每个叶子节点存储一个数据点。</li>\n</ul>\n<p>这些树是独立随机构建的，在某种程度上模拟了哈希函数的作用。在搜索过程中，ANNOY 会在所有树中迭代地搜索最接近查询点的一半，然后聚合结果。其思想与 KD 树非常相关，但具有更强的可扩展性。</p>\n<h3 id=\"hnsw-hierarchical-navigable-small-world\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#hnsw-hierarchical-navigable-small-world\"><span>HNSW （Hierarchical Navigable Small World）</span></a></h3>\n<p>HNSW 的设计思想来源于小世界网络。在小世界网络中，每个节点只需通过很少的步数即可连接到其他任何节点，例如社交网络中的“六度分隔”理论。</p>\n<ul>\n<li>HNSW 构建了多层的小世界网络结构，其中底层包含实际的数据点。</li>\n<li>中间层创建了一些“快捷键”，以加速搜索过程。</li>\n</ul>\n<p>通过这种分层结构，HNSW 能够在大规模数据集上实现高效搜索。</p>\n<hr>\n<h1 id=\"工具使用-tool-use\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#工具使用-tool-use\"><span>工具使用（Tool Use）</span></a></h1>\n<p>在人工智能领域，模型的能力在很多情况下可能受到权重丢失信息的限制。为了弥补这一不足，智能体（Agent）可以通过调用外部API获取额外的信息。这些信息包括但不限于：</p>\n<ul>\n<li>当前的实时信息</li>\n<li>代码执行能力</li>\n<li>专有信息源的访问</li>\n</ul>\n<p>这种工具的使用，使得智能体能够更好地应对复杂的任务，同时提升其处理问题的灵活性和准确性。</p>\n<hr>\n<h1 id=\"智能体与llm的区别\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#智能体与llm的区别\"><span>智能体与LLM的区别</span></a></h1>\n<h2 id=\"与llm的交互方式\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#与llm的交互方式\"><span>与LLM的交互方式</span></a></h2>\n<p>与大语言模型（LLM, Large Language Model）的交互非常直接——你只需要输入一个提示，大模型会基于输入生成一个回答。这种交互模式简单直观，但往往缺乏深入的思考和迭代过程。\n<img src=\"/img/user/附件/Pasted image 20250504190351.png\" alt=\"Pasted image 20250504190351.png\"></p>\n<hr>\n<h2 id=\"与agent的交互方式\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#与agent的交互方式\"><span>与Agent的交互方式</span></a></h2>\n<p>与智能体（Agent）的交互则更加复杂和动态。它不仅仅是简单地生成回答，而是模拟一种助手的行为。以下是一个典型的Agent交互流程：</p>\n<ol>\n<li>你提出一个问题或任务。</li>\n<li>Agent会先询问是否需要进行一些网络研究。</li>\n<li>在必要时，Agent会主动获取相关信息，写下初稿。</li>\n<li>Agent会回顾初稿，并思考哪些部分需要修改。</li>\n<li>Agent对草稿进行修改。</li>\n<li>这个过程会不断进行思考和迭代，直到最终得到满意的结果。</li>\n</ol>\n<p>这个流程可以总结为一个 <strong>思考 + 迭代</strong> 的过程，体现了Agent在解决问题时的主动性和灵活性。\n<img src=\"/img/user/附件/Pasted image 20250504190359.png\" alt=\"Pasted image 20250504190359.png\"></p>\n<hr>\n<h1 id=\"与强化学习智能体的区别\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#与强化学习智能体的区别\"><span>与强化学习智能体的区别</span></a></h1>\n<h2 id=\"强化学习智能体\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#强化学习智能体\"><span>强化学习智能体</span></a></h2>\n<p>强化学习（Reinforcement Learning, RL）智能体的输入和输出通常局限于特定的环境中。具体来说：</p>\n<ul>\n<li><strong>输入</strong>：强化学习智能体接收的是预设好的向量化环境状态，或者是图像等结构化数据。</li>\n<li><strong>策略</strong>：策略通常由简单的神经网络结构初始化，并通过不断训练进行优化。</li>\n<li><strong>输出</strong>：输出动作多为底层控制，例如移动、攻击等。</li>\n</ul>\n<p>这种智能体主要应用于特定的任务场景，例如游戏AI、机器人控制等。</p>\n<hr>\n<h2 id=\"基于大模型的智能体\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#基于大模型的智能体\"><span>基于大模型的智能体</span></a></h2>\n<p>相比于传统强化学习智能体，基于大语言模型（LLM）的智能体具有更广泛的适用场景和更高层次的处理能力：</p>\n<ul>\n<li><strong>输入</strong>：基于大模型的智能体接受的是文字输入。在多模态场景下，还可以处理视觉、语音等信息。</li>\n<li><strong>策略</strong>：策略基于预训练的大语言模型，这些模型具备丰富的世界知识。</li>\n<li><strong>输出</strong>：输出形式为文本，但可以通过结构化输出和提取实现 <code v-pre>function_call</code>，从而与现实环境进行进一步交互。</li>\n</ul>\n<p>这种智能体不仅能处理复杂的文字任务，还能通过调用函数或API，与外部世界互动。例如，它可以通过命令控制外部设备，或者从数据库中提取信息，从而实现更高效的信息处理和决策支持。</p>\n<hr>\n","env":{"base":"/","filePath":"/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/大模型应用/LLM-based Agent 基于大模型的智能体/基于大模型的智能体原理.md","filePathRelative":"notes_bak/大语言模型学习/大模型应用/LLM-based Agent 基于大模型的智能体/基于大模型的智能体原理.md","frontmatter":{"dg-publish":true,"dg-permalink":"/大语言模型学习/大模型应用/LLM-based-Agent-基于大模型的智能体/基于大模型的智能体原理","dg-home":false,"dg-description":"在此输入笔记的描述","dg-hide":false,"dg-hide-title":false,"dg-show-backlinks":true,"dg-show-local-graph":true,"dg-show-inline-title":true,"dg-pinned":false,"dg-passphrase":"在此输入访问密码","dg-enable-mathjax":false,"dg-enable-mermaid":false,"dg-enable-uml":false,"dg-note-icon":0,"dg-enable-dataview":false,"tags":["NLP"],"permalink":"/大语言模型学习/大模型应用/LLM-based-Agent-基于大模型的智能体/基于大模型的智能体原理/","dgShowBacklinks":true,"dgShowLocalGraph":true,"dgShowInlineTitle":true,"dgPassFrontmatter":true,"noteIcon":0,"created":"2025-05-04T10:58:58.000Z","updated":"2025-05-06T02:29:38.000Z","title":"基于大模型的智能体原理","createTime":"2025/05/13 17:33:52"},"sfcBlocks":{"template":{"type":"template","content":"<template><h2 id=\"什么是llm-agent\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#什么是llm-agent\"><span>什么是LLM Agent？</span></a></h2>\n<p>LLM Agent是一种超越简单文本生成的人工智能系统。它以大语言模型（LLM）作为核心计算引擎，使其能够与用户进行对话、执行任务、进行推理，并展现出一定程度的自主性。简而言之，LLM Agent是一个具有复杂推理能力、记忆和执行任务能力的系统。\n<img src=\"/img/user/附件/Pasted image 20250504190059.png\" alt=\"Pasted image 20250504190059.png\">\nLLM Agent的定义可以概括为：通过与生成式人工智能（GenAI）本身之外的系统交互来服务于用户目标的GenAI系统。\n<img src=\"/img/user/附件/Pasted image 20250504190109.png\" alt=\"Pasted image 20250504190109.png\"></p>\n<h3 id=\"llm-agent的核心组成\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#llm-agent的核心组成\"><span>LLM Agent的核心组成</span></a></h3>\n<p>LLM Agent可能涉及单个外部系统（如计算器），也可能需要解决更复杂的路由问题，以决定需要使用哪种外部系统（通常包括记忆和规划功能）。总体而言，基于大模型的智能体（LLM-based Agent）的核心组成可以表示为：</p>\n<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>LLM-based Agent</mtext><mo>=</mo><mtext>LLM</mtext><mo>+</mo><mtext>工具调用</mtext><mo>+</mo><mtext>规划</mtext><mo>+</mo><mtext>记忆</mtext></mrow><annotation encoding=\"application/x-tex\">\\text{LLM-based Agent} = \\text{LLM} + \\text{工具调用} + \\text{规划} + \\text{记忆}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\"><span class=\"mord\">LLM-based Agent</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord text\"><span class=\"mord\">LLM</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">工具调用</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">规划</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">记忆</span></span></span></span></span></span></p>\n<hr>\n<h2 id=\"规划-planning\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#规划-planning\"><span>规划（Planning）</span></a></h2>\n<h3 id=\"子目标分解\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#子目标分解\"><span>子目标分解</span></a></h3>\n<p>在规划过程中，Agent会将一个复杂的大任务拆分为更小、更易于管理的子目标，从而能够更加高效地完成复杂任务。</p>\n<h4 id=\"目的\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#目的\"><span>目的</span></a></h4>\n<p>很多复杂任务通常由多个步骤组成，Agent需要清楚这些步骤是什么，并提前规划。例如，在前面提到的5.1.2章节中，CoT（Chain of Thought）以及其改进方法实际上就是在进行任务分解。</p>\n<h4 id=\"任务分解的实现方式\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#任务分解的实现方式\"><span>任务分解的实现方式</span></a></h4>\n<p>以下是实现任务分解的几种方式：</p>\n<ol>\n<li>\n<p><strong>直接提示</strong>：给LLM一个简单的提示词，例如：</p>\n<div class=\"language- line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code><span class=\"line\"><span>Steps for XYZ.</span></span>\n<span class=\"line\"><span>1.</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>或者：</p>\n<div class=\"language- line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code><span class=\"line\"><span>What are the subgoals for achieving XYZ?</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div></div></div></li>\n<li>\n<p><strong>具体指令</strong>：针对特定任务提供明确指令。例如，对于写小说的任务，可以先给出“Write a story outline.”这样的指令。</p>\n</li>\n<li>\n<p><strong>用户输入</strong>：由使用者直接输入明确的任务需求。</p>\n</li>\n</ol>\n<p>无论是CoT还是ToT（Tree of Thought），其本质都是通过精心设计的Prompt，激发模型原有的元认知（Metacognition）。关键在于如何通过某条神经元的线索，更加精准地调动模型中最擅长规划（Planning）的部分。</p>\n<hr>\n<p><img src=\"/img/user/附件/Pasted image 20250504190157.png\" alt=\"Pasted image 20250504190157.png\"></p>\n<h3 id=\"llm与pddl结合的规划方法\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#llm与pddl结合的规划方法\"><span>LLM与PDDL结合的规划方法</span></a></h3>\n<p>一种更为高级的规划方法是利用LLM进行长序列的整体规划。具体来说，这种方法使用规划域定义语言（PDDL，Planning Domain Definition Language）作为中间接口来描述规划问题。以下是具体步骤：</p>\n<ol>\n<li><strong>问题翻译</strong>：首先，LLM将问题翻译为PDDL格式的问题描述（问题PDDL）。</li>\n<li><strong>调用经典Planner</strong>：接着，请求经典Planner根据现有的领域PDDL生成一个PDDL计划。</li>\n<li><strong>自然语言翻译</strong>：最后，将PDDL计划翻译回自然语言，这一步由LLM完成。</li>\n</ol>\n<p>从根本上讲，Planning步骤被外包给了外部工具。但这需要满足一个前提条件：必须有特定领域的PDDL定义和合适的Planner工具。</p>\n<hr>\n<h2 id=\"反思与完善\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#反思与完善\"><span>反思与完善</span></a></h2>\n<h3 id=\"自我批评与反思\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#自我批评与反思\"><span>自我批评与反思</span></a></h3>\n<p>Agent能够对历史动作进行自我批评和反思，从错误中学习，并在后续步骤中不断完善，从而提高最终结果的质量。自我反思（Self-reflection）是一个非常重要的环节，它允许Agent通过完善过去的行动决策和纠正以前的错误来持续改进。</p>\n<p>在现实世界中的任务中，试错往往是无法避免的，而自我反思在其中发挥着至关重要的作用。</p>\n<hr>\n<h2 id=\"react-结合推理与行动\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#react-结合推理与行动\"><span>ReAct：结合推理与行动</span></a></h2>\n<p>ReAct是一种被分类在5.2.3章节中的Observation-based Agent方法，其全称为Reason+Act。该方法通过将Action Space扩展为特定任务的离散动作和语言空间的组合，在LLM内部整合了推理（Reasoning）和行动（Action）。</p>\n<ul>\n<li><strong>推理</strong>：使得LLM能够与环境交互。</li>\n<li><strong>行动</strong>：通过提示词，使得LLM用自然语言生成整体推理过程。</li>\n</ul>\n<p>ReAct提示词模板包含特定设计，以支持这种推理与行动结合的方法。\n<img src=\"/img/user/附件/Pasted image 20250504190209.png\" alt=\"Pasted image 20250504190209.png\"></p>\n<h1 id=\"记忆-memory\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#记忆-memory\"><span>记忆（Memory）</span></a></h1>\n<h2 id=\"短期记忆与长期记忆\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#短期记忆与长期记忆\"><span>短期记忆与长期记忆</span></a></h2>\n<h3 id=\"短期记忆-上下文学习\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#短期记忆-上下文学习\"><span>短期记忆：上下文学习</span></a></h3>\n<p>短期记忆指的是利用模型的短期记忆进行学习的能力。在上下文学习中，模型能够在短时间内获取、存储并处理信息，从而完成任务。</p>\n<h3 id=\"长期记忆\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#长期记忆\"><span>长期记忆</span></a></h3>\n<p>长期记忆为智能体（agent）提供保留和召回长期信息的能力。通常，这种能力通过外部向量存储和检索来实现。长期记忆的特点在于它能够支持信息的长时间保存与高效访问。\n<img src=\"/img/user/附件/Pasted image 20250504190306.png\" alt=\"Pasted image 20250504190306.png\"></p>\n<hr>\n<h2 id=\"记忆的定义与分类\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#记忆的定义与分类\"><span>记忆的定义与分类</span></a></h2>\n<p>记忆可以定义为一种用于获取、存储、保留和随后检索信息的过程。在人脑中，记忆可以分为以下几种类型：</p>\n<h3 id=\"感官记忆\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#感官记忆\"><span>感官记忆</span></a></h3>\n<p>感官记忆是记忆的最早期阶段，它指的是对原始刺激的感官印象（如视觉、听觉等）的保留能力。这类记忆通常只能持续几秒钟，包含以下三种类型：</p>\n<ul>\n<li><strong>图标记忆</strong>：与视觉相关的记忆。</li>\n<li><strong>回声记忆</strong>：与听觉相关的记忆。</li>\n<li><strong>触碰记忆</strong>：与触觉相关的记忆。</li>\n</ul>\n<h3 id=\"短时记忆-stm-或工作记忆\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#短时记忆-stm-或工作记忆\"><span>短时记忆（STM）或工作记忆</span></a></h3>\n<p>短时记忆存储我们当前意识到的信息，以及执行复杂认知任务（如学习和推理）所需的信息。短时记忆的容量通常为 <strong>7 个项目左右</strong>，并能够持续 <strong>20-30 秒</strong>。</p>\n<h3 id=\"长时记忆-ltm\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#长时记忆-ltm\"><span>长时记忆（LTM）</span></a></h3>\n<p>长时记忆能够将信息存储很长时间，从几天到几十年不等，其存储容量基本上是无限的。长时记忆可进一步分为以下两种类型：</p>\n<ol>\n<li>\n<p><strong>显性/陈述性记忆</strong><br>\n显性记忆是对事实和事件的记忆，指那些可以有意识地回忆起的内容，包括：</p>\n<ul>\n<li><strong>外显记忆</strong>：关于事件和经历的记忆。</li>\n<li><strong>语义记忆</strong>：关于事实和概括的记忆。</li>\n</ul>\n</li>\n<li>\n<p><strong>隐性/程序性记忆</strong><br>\n隐性记忆是无意识的，涉及自动执行的技能和例行程序，例如骑自行车或在键盘上打字。</p>\n</li>\n</ol>\n<hr>\n<h2 id=\"最大内部产品搜索-maximum-inner-product-search-mips\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#最大内部产品搜索-maximum-inner-product-search-mips\"><span>最大内部产品搜索（Maximum Inner Product Search, MIPS）</span></a></h2>\n<p>在利用外部存储器缓解关注范围有限的问题时，最大内部产品搜索（MIPS）是一种有效的方法。为了优化检索速度，常采用近似最近邻（ANN）算法。这些算法通过牺牲少量精度来显著提升速度，并返回近似的前 <span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span> 个近邻。以下是几种常见的 ANN 算法：</p>\n<h3 id=\"lsh-局部敏感哈希\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#lsh-局部敏感哈希\"><span>LSH （局部敏感哈希）</span></a></h3>\n<p>LSH 引入了一种哈希函数，该函数能够最大限度地将相似的输入项映射到同一个桶中。桶的数量远小于输入内容的数量，从而实现快速检索。</p>\n<h3 id=\"annoy-approximate-nearest-neighbors-oh-yeah\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#annoy-approximate-nearest-neighbors-oh-yeah\"><span>ANNOY （Approximate Nearest Neighbors Oh Yeah）</span></a></h3>\n<p>ANNOY 的核心数据结构是随机投影树，这是一种二叉树集合。具体而言：</p>\n<ul>\n<li>每个非叶子节点表示将输入空间划分为两半的一个超平面。</li>\n<li>每个叶子节点存储一个数据点。</li>\n</ul>\n<p>这些树是独立随机构建的，在某种程度上模拟了哈希函数的作用。在搜索过程中，ANNOY 会在所有树中迭代地搜索最接近查询点的一半，然后聚合结果。其思想与 KD 树非常相关，但具有更强的可扩展性。</p>\n<h3 id=\"hnsw-hierarchical-navigable-small-world\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#hnsw-hierarchical-navigable-small-world\"><span>HNSW （Hierarchical Navigable Small World）</span></a></h3>\n<p>HNSW 的设计思想来源于小世界网络。在小世界网络中，每个节点只需通过很少的步数即可连接到其他任何节点，例如社交网络中的“六度分隔”理论。</p>\n<ul>\n<li>HNSW 构建了多层的小世界网络结构，其中底层包含实际的数据点。</li>\n<li>中间层创建了一些“快捷键”，以加速搜索过程。</li>\n</ul>\n<p>通过这种分层结构，HNSW 能够在大规模数据集上实现高效搜索。</p>\n<hr>\n<h1 id=\"工具使用-tool-use\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#工具使用-tool-use\"><span>工具使用（Tool Use）</span></a></h1>\n<p>在人工智能领域，模型的能力在很多情况下可能受到权重丢失信息的限制。为了弥补这一不足，智能体（Agent）可以通过调用外部API获取额外的信息。这些信息包括但不限于：</p>\n<ul>\n<li>当前的实时信息</li>\n<li>代码执行能力</li>\n<li>专有信息源的访问</li>\n</ul>\n<p>这种工具的使用，使得智能体能够更好地应对复杂的任务，同时提升其处理问题的灵活性和准确性。</p>\n<hr>\n<h1 id=\"智能体与llm的区别\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#智能体与llm的区别\"><span>智能体与LLM的区别</span></a></h1>\n<h2 id=\"与llm的交互方式\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#与llm的交互方式\"><span>与LLM的交互方式</span></a></h2>\n<p>与大语言模型（LLM, Large Language Model）的交互非常直接——你只需要输入一个提示，大模型会基于输入生成一个回答。这种交互模式简单直观，但往往缺乏深入的思考和迭代过程。\n<img src=\"/img/user/附件/Pasted image 20250504190351.png\" alt=\"Pasted image 20250504190351.png\"></p>\n<hr>\n<h2 id=\"与agent的交互方式\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#与agent的交互方式\"><span>与Agent的交互方式</span></a></h2>\n<p>与智能体（Agent）的交互则更加复杂和动态。它不仅仅是简单地生成回答，而是模拟一种助手的行为。以下是一个典型的Agent交互流程：</p>\n<ol>\n<li>你提出一个问题或任务。</li>\n<li>Agent会先询问是否需要进行一些网络研究。</li>\n<li>在必要时，Agent会主动获取相关信息，写下初稿。</li>\n<li>Agent会回顾初稿，并思考哪些部分需要修改。</li>\n<li>Agent对草稿进行修改。</li>\n<li>这个过程会不断进行思考和迭代，直到最终得到满意的结果。</li>\n</ol>\n<p>这个流程可以总结为一个 <strong>思考 + 迭代</strong> 的过程，体现了Agent在解决问题时的主动性和灵活性。\n<img src=\"/img/user/附件/Pasted image 20250504190359.png\" alt=\"Pasted image 20250504190359.png\"></p>\n<hr>\n<h1 id=\"与强化学习智能体的区别\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#与强化学习智能体的区别\"><span>与强化学习智能体的区别</span></a></h1>\n<h2 id=\"强化学习智能体\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#强化学习智能体\"><span>强化学习智能体</span></a></h2>\n<p>强化学习（Reinforcement Learning, RL）智能体的输入和输出通常局限于特定的环境中。具体来说：</p>\n<ul>\n<li><strong>输入</strong>：强化学习智能体接收的是预设好的向量化环境状态，或者是图像等结构化数据。</li>\n<li><strong>策略</strong>：策略通常由简单的神经网络结构初始化，并通过不断训练进行优化。</li>\n<li><strong>输出</strong>：输出动作多为底层控制，例如移动、攻击等。</li>\n</ul>\n<p>这种智能体主要应用于特定的任务场景，例如游戏AI、机器人控制等。</p>\n<hr>\n<h2 id=\"基于大模型的智能体\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#基于大模型的智能体\"><span>基于大模型的智能体</span></a></h2>\n<p>相比于传统强化学习智能体，基于大语言模型（LLM）的智能体具有更广泛的适用场景和更高层次的处理能力：</p>\n<ul>\n<li><strong>输入</strong>：基于大模型的智能体接受的是文字输入。在多模态场景下，还可以处理视觉、语音等信息。</li>\n<li><strong>策略</strong>：策略基于预训练的大语言模型，这些模型具备丰富的世界知识。</li>\n<li><strong>输出</strong>：输出形式为文本，但可以通过结构化输出和提取实现 <code v-pre>function_call</code>，从而与现实环境进行进一步交互。</li>\n</ul>\n<p>这种智能体不仅能处理复杂的文字任务，还能通过调用函数或API，与外部世界互动。例如，它可以通过命令控制外部设备，或者从数据库中提取信息，从而实现更高效的信息处理和决策支持。</p>\n<hr>\n</template>","contentStripped":"<h2 id=\"什么是llm-agent\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#什么是llm-agent\"><span>什么是LLM Agent？</span></a></h2>\n<p>LLM Agent是一种超越简单文本生成的人工智能系统。它以大语言模型（LLM）作为核心计算引擎，使其能够与用户进行对话、执行任务、进行推理，并展现出一定程度的自主性。简而言之，LLM Agent是一个具有复杂推理能力、记忆和执行任务能力的系统。\n<img src=\"/img/user/附件/Pasted image 20250504190059.png\" alt=\"Pasted image 20250504190059.png\">\nLLM Agent的定义可以概括为：通过与生成式人工智能（GenAI）本身之外的系统交互来服务于用户目标的GenAI系统。\n<img src=\"/img/user/附件/Pasted image 20250504190109.png\" alt=\"Pasted image 20250504190109.png\"></p>\n<h3 id=\"llm-agent的核心组成\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#llm-agent的核心组成\"><span>LLM Agent的核心组成</span></a></h3>\n<p>LLM Agent可能涉及单个外部系统（如计算器），也可能需要解决更复杂的路由问题，以决定需要使用哪种外部系统（通常包括记忆和规划功能）。总体而言，基于大模型的智能体（LLM-based Agent）的核心组成可以表示为：</p>\n<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>LLM-based Agent</mtext><mo>=</mo><mtext>LLM</mtext><mo>+</mo><mtext>工具调用</mtext><mo>+</mo><mtext>规划</mtext><mo>+</mo><mtext>记忆</mtext></mrow><annotation encoding=\"application/x-tex\">\\text{LLM-based Agent} = \\text{LLM} + \\text{工具调用} + \\text{规划} + \\text{记忆}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\"><span class=\"mord\">LLM-based Agent</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord text\"><span class=\"mord\">LLM</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">工具调用</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">规划</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">记忆</span></span></span></span></span></span></p>\n<hr>\n<h2 id=\"规划-planning\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#规划-planning\"><span>规划（Planning）</span></a></h2>\n<h3 id=\"子目标分解\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#子目标分解\"><span>子目标分解</span></a></h3>\n<p>在规划过程中，Agent会将一个复杂的大任务拆分为更小、更易于管理的子目标，从而能够更加高效地完成复杂任务。</p>\n<h4 id=\"目的\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#目的\"><span>目的</span></a></h4>\n<p>很多复杂任务通常由多个步骤组成，Agent需要清楚这些步骤是什么，并提前规划。例如，在前面提到的5.1.2章节中，CoT（Chain of Thought）以及其改进方法实际上就是在进行任务分解。</p>\n<h4 id=\"任务分解的实现方式\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#任务分解的实现方式\"><span>任务分解的实现方式</span></a></h4>\n<p>以下是实现任务分解的几种方式：</p>\n<ol>\n<li>\n<p><strong>直接提示</strong>：给LLM一个简单的提示词，例如：</p>\n<div class=\"language- line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code><span class=\"line\"><span>Steps for XYZ.</span></span>\n<span class=\"line\"><span>1.</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>或者：</p>\n<div class=\"language- line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code><span class=\"line\"><span>What are the subgoals for achieving XYZ?</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div></div></div></li>\n<li>\n<p><strong>具体指令</strong>：针对特定任务提供明确指令。例如，对于写小说的任务，可以先给出“Write a story outline.”这样的指令。</p>\n</li>\n<li>\n<p><strong>用户输入</strong>：由使用者直接输入明确的任务需求。</p>\n</li>\n</ol>\n<p>无论是CoT还是ToT（Tree of Thought），其本质都是通过精心设计的Prompt，激发模型原有的元认知（Metacognition）。关键在于如何通过某条神经元的线索，更加精准地调动模型中最擅长规划（Planning）的部分。</p>\n<hr>\n<p><img src=\"/img/user/附件/Pasted image 20250504190157.png\" alt=\"Pasted image 20250504190157.png\"></p>\n<h3 id=\"llm与pddl结合的规划方法\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#llm与pddl结合的规划方法\"><span>LLM与PDDL结合的规划方法</span></a></h3>\n<p>一种更为高级的规划方法是利用LLM进行长序列的整体规划。具体来说，这种方法使用规划域定义语言（PDDL，Planning Domain Definition Language）作为中间接口来描述规划问题。以下是具体步骤：</p>\n<ol>\n<li><strong>问题翻译</strong>：首先，LLM将问题翻译为PDDL格式的问题描述（问题PDDL）。</li>\n<li><strong>调用经典Planner</strong>：接着，请求经典Planner根据现有的领域PDDL生成一个PDDL计划。</li>\n<li><strong>自然语言翻译</strong>：最后，将PDDL计划翻译回自然语言，这一步由LLM完成。</li>\n</ol>\n<p>从根本上讲，Planning步骤被外包给了外部工具。但这需要满足一个前提条件：必须有特定领域的PDDL定义和合适的Planner工具。</p>\n<hr>\n<h2 id=\"反思与完善\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#反思与完善\"><span>反思与完善</span></a></h2>\n<h3 id=\"自我批评与反思\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#自我批评与反思\"><span>自我批评与反思</span></a></h3>\n<p>Agent能够对历史动作进行自我批评和反思，从错误中学习，并在后续步骤中不断完善，从而提高最终结果的质量。自我反思（Self-reflection）是一个非常重要的环节，它允许Agent通过完善过去的行动决策和纠正以前的错误来持续改进。</p>\n<p>在现实世界中的任务中，试错往往是无法避免的，而自我反思在其中发挥着至关重要的作用。</p>\n<hr>\n<h2 id=\"react-结合推理与行动\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#react-结合推理与行动\"><span>ReAct：结合推理与行动</span></a></h2>\n<p>ReAct是一种被分类在5.2.3章节中的Observation-based Agent方法，其全称为Reason+Act。该方法通过将Action Space扩展为特定任务的离散动作和语言空间的组合，在LLM内部整合了推理（Reasoning）和行动（Action）。</p>\n<ul>\n<li><strong>推理</strong>：使得LLM能够与环境交互。</li>\n<li><strong>行动</strong>：通过提示词，使得LLM用自然语言生成整体推理过程。</li>\n</ul>\n<p>ReAct提示词模板包含特定设计，以支持这种推理与行动结合的方法。\n<img src=\"/img/user/附件/Pasted image 20250504190209.png\" alt=\"Pasted image 20250504190209.png\"></p>\n<h1 id=\"记忆-memory\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#记忆-memory\"><span>记忆（Memory）</span></a></h1>\n<h2 id=\"短期记忆与长期记忆\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#短期记忆与长期记忆\"><span>短期记忆与长期记忆</span></a></h2>\n<h3 id=\"短期记忆-上下文学习\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#短期记忆-上下文学习\"><span>短期记忆：上下文学习</span></a></h3>\n<p>短期记忆指的是利用模型的短期记忆进行学习的能力。在上下文学习中，模型能够在短时间内获取、存储并处理信息，从而完成任务。</p>\n<h3 id=\"长期记忆\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#长期记忆\"><span>长期记忆</span></a></h3>\n<p>长期记忆为智能体（agent）提供保留和召回长期信息的能力。通常，这种能力通过外部向量存储和检索来实现。长期记忆的特点在于它能够支持信息的长时间保存与高效访问。\n<img src=\"/img/user/附件/Pasted image 20250504190306.png\" alt=\"Pasted image 20250504190306.png\"></p>\n<hr>\n<h2 id=\"记忆的定义与分类\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#记忆的定义与分类\"><span>记忆的定义与分类</span></a></h2>\n<p>记忆可以定义为一种用于获取、存储、保留和随后检索信息的过程。在人脑中，记忆可以分为以下几种类型：</p>\n<h3 id=\"感官记忆\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#感官记忆\"><span>感官记忆</span></a></h3>\n<p>感官记忆是记忆的最早期阶段，它指的是对原始刺激的感官印象（如视觉、听觉等）的保留能力。这类记忆通常只能持续几秒钟，包含以下三种类型：</p>\n<ul>\n<li><strong>图标记忆</strong>：与视觉相关的记忆。</li>\n<li><strong>回声记忆</strong>：与听觉相关的记忆。</li>\n<li><strong>触碰记忆</strong>：与触觉相关的记忆。</li>\n</ul>\n<h3 id=\"短时记忆-stm-或工作记忆\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#短时记忆-stm-或工作记忆\"><span>短时记忆（STM）或工作记忆</span></a></h3>\n<p>短时记忆存储我们当前意识到的信息，以及执行复杂认知任务（如学习和推理）所需的信息。短时记忆的容量通常为 <strong>7 个项目左右</strong>，并能够持续 <strong>20-30 秒</strong>。</p>\n<h3 id=\"长时记忆-ltm\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#长时记忆-ltm\"><span>长时记忆（LTM）</span></a></h3>\n<p>长时记忆能够将信息存储很长时间，从几天到几十年不等，其存储容量基本上是无限的。长时记忆可进一步分为以下两种类型：</p>\n<ol>\n<li>\n<p><strong>显性/陈述性记忆</strong><br>\n显性记忆是对事实和事件的记忆，指那些可以有意识地回忆起的内容，包括：</p>\n<ul>\n<li><strong>外显记忆</strong>：关于事件和经历的记忆。</li>\n<li><strong>语义记忆</strong>：关于事实和概括的记忆。</li>\n</ul>\n</li>\n<li>\n<p><strong>隐性/程序性记忆</strong><br>\n隐性记忆是无意识的，涉及自动执行的技能和例行程序，例如骑自行车或在键盘上打字。</p>\n</li>\n</ol>\n<hr>\n<h2 id=\"最大内部产品搜索-maximum-inner-product-search-mips\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#最大内部产品搜索-maximum-inner-product-search-mips\"><span>最大内部产品搜索（Maximum Inner Product Search, MIPS）</span></a></h2>\n<p>在利用外部存储器缓解关注范围有限的问题时，最大内部产品搜索（MIPS）是一种有效的方法。为了优化检索速度，常采用近似最近邻（ANN）算法。这些算法通过牺牲少量精度来显著提升速度，并返回近似的前 <span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span> 个近邻。以下是几种常见的 ANN 算法：</p>\n<h3 id=\"lsh-局部敏感哈希\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#lsh-局部敏感哈希\"><span>LSH （局部敏感哈希）</span></a></h3>\n<p>LSH 引入了一种哈希函数，该函数能够最大限度地将相似的输入项映射到同一个桶中。桶的数量远小于输入内容的数量，从而实现快速检索。</p>\n<h3 id=\"annoy-approximate-nearest-neighbors-oh-yeah\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#annoy-approximate-nearest-neighbors-oh-yeah\"><span>ANNOY （Approximate Nearest Neighbors Oh Yeah）</span></a></h3>\n<p>ANNOY 的核心数据结构是随机投影树，这是一种二叉树集合。具体而言：</p>\n<ul>\n<li>每个非叶子节点表示将输入空间划分为两半的一个超平面。</li>\n<li>每个叶子节点存储一个数据点。</li>\n</ul>\n<p>这些树是独立随机构建的，在某种程度上模拟了哈希函数的作用。在搜索过程中，ANNOY 会在所有树中迭代地搜索最接近查询点的一半，然后聚合结果。其思想与 KD 树非常相关，但具有更强的可扩展性。</p>\n<h3 id=\"hnsw-hierarchical-navigable-small-world\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#hnsw-hierarchical-navigable-small-world\"><span>HNSW （Hierarchical Navigable Small World）</span></a></h3>\n<p>HNSW 的设计思想来源于小世界网络。在小世界网络中，每个节点只需通过很少的步数即可连接到其他任何节点，例如社交网络中的“六度分隔”理论。</p>\n<ul>\n<li>HNSW 构建了多层的小世界网络结构，其中底层包含实际的数据点。</li>\n<li>中间层创建了一些“快捷键”，以加速搜索过程。</li>\n</ul>\n<p>通过这种分层结构，HNSW 能够在大规模数据集上实现高效搜索。</p>\n<hr>\n<h1 id=\"工具使用-tool-use\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#工具使用-tool-use\"><span>工具使用（Tool Use）</span></a></h1>\n<p>在人工智能领域，模型的能力在很多情况下可能受到权重丢失信息的限制。为了弥补这一不足，智能体（Agent）可以通过调用外部API获取额外的信息。这些信息包括但不限于：</p>\n<ul>\n<li>当前的实时信息</li>\n<li>代码执行能力</li>\n<li>专有信息源的访问</li>\n</ul>\n<p>这种工具的使用，使得智能体能够更好地应对复杂的任务，同时提升其处理问题的灵活性和准确性。</p>\n<hr>\n<h1 id=\"智能体与llm的区别\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#智能体与llm的区别\"><span>智能体与LLM的区别</span></a></h1>\n<h2 id=\"与llm的交互方式\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#与llm的交互方式\"><span>与LLM的交互方式</span></a></h2>\n<p>与大语言模型（LLM, Large Language Model）的交互非常直接——你只需要输入一个提示，大模型会基于输入生成一个回答。这种交互模式简单直观，但往往缺乏深入的思考和迭代过程。\n<img src=\"/img/user/附件/Pasted image 20250504190351.png\" alt=\"Pasted image 20250504190351.png\"></p>\n<hr>\n<h2 id=\"与agent的交互方式\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#与agent的交互方式\"><span>与Agent的交互方式</span></a></h2>\n<p>与智能体（Agent）的交互则更加复杂和动态。它不仅仅是简单地生成回答，而是模拟一种助手的行为。以下是一个典型的Agent交互流程：</p>\n<ol>\n<li>你提出一个问题或任务。</li>\n<li>Agent会先询问是否需要进行一些网络研究。</li>\n<li>在必要时，Agent会主动获取相关信息，写下初稿。</li>\n<li>Agent会回顾初稿，并思考哪些部分需要修改。</li>\n<li>Agent对草稿进行修改。</li>\n<li>这个过程会不断进行思考和迭代，直到最终得到满意的结果。</li>\n</ol>\n<p>这个流程可以总结为一个 <strong>思考 + 迭代</strong> 的过程，体现了Agent在解决问题时的主动性和灵活性。\n<img src=\"/img/user/附件/Pasted image 20250504190359.png\" alt=\"Pasted image 20250504190359.png\"></p>\n<hr>\n<h1 id=\"与强化学习智能体的区别\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#与强化学习智能体的区别\"><span>与强化学习智能体的区别</span></a></h1>\n<h2 id=\"强化学习智能体\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#强化学习智能体\"><span>强化学习智能体</span></a></h2>\n<p>强化学习（Reinforcement Learning, RL）智能体的输入和输出通常局限于特定的环境中。具体来说：</p>\n<ul>\n<li><strong>输入</strong>：强化学习智能体接收的是预设好的向量化环境状态，或者是图像等结构化数据。</li>\n<li><strong>策略</strong>：策略通常由简单的神经网络结构初始化，并通过不断训练进行优化。</li>\n<li><strong>输出</strong>：输出动作多为底层控制，例如移动、攻击等。</li>\n</ul>\n<p>这种智能体主要应用于特定的任务场景，例如游戏AI、机器人控制等。</p>\n<hr>\n<h2 id=\"基于大模型的智能体\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#基于大模型的智能体\"><span>基于大模型的智能体</span></a></h2>\n<p>相比于传统强化学习智能体，基于大语言模型（LLM）的智能体具有更广泛的适用场景和更高层次的处理能力：</p>\n<ul>\n<li><strong>输入</strong>：基于大模型的智能体接受的是文字输入。在多模态场景下，还可以处理视觉、语音等信息。</li>\n<li><strong>策略</strong>：策略基于预训练的大语言模型，这些模型具备丰富的世界知识。</li>\n<li><strong>输出</strong>：输出形式为文本，但可以通过结构化输出和提取实现 <code v-pre>function_call</code>，从而与现实环境进行进一步交互。</li>\n</ul>\n<p>这种智能体不仅能处理复杂的文字任务，还能通过调用函数或API，与外部世界互动。例如，它可以通过命令控制外部设备，或者从数据库中提取信息，从而实现更高效的信息处理和决策支持。</p>\n<hr>\n","tagOpen":"<template>","tagClose":"</template>"},"script":null,"scriptSetup":null,"scripts":[],"styles":[],"customBlocks":[]},"content":"\n## 什么是LLM Agent？\nLLM Agent是一种超越简单文本生成的人工智能系统。它以大语言模型（LLM）作为核心计算引擎，使其能够与用户进行对话、执行任务、进行推理，并展现出一定程度的自主性。简而言之，LLM Agent是一个具有复杂推理能力、记忆和执行任务能力的系统。\n![Pasted image 20250504190059.png](/img/user/%E9%99%84%E4%BB%B6/Pasted%20image%2020250504190059.png)\nLLM Agent的定义可以概括为：通过与生成式人工智能（GenAI）本身之外的系统交互来服务于用户目标的GenAI系统。\n![Pasted image 20250504190109.png](/img/user/%E9%99%84%E4%BB%B6/Pasted%20image%2020250504190109.png)\n\n### LLM Agent的核心组成\nLLM Agent可能涉及单个外部系统（如计算器），也可能需要解决更复杂的路由问题，以决定需要使用哪种外部系统（通常包括记忆和规划功能）。总体而言，基于大模型的智能体（LLM-based Agent）的核心组成可以表示为：\n\n$$\n\\text{LLM-based Agent} = \\text{LLM} + \\text{工具调用} + \\text{规划} + \\text{记忆}\n$$\n\n---\n\n\n## 规划（Planning）\n\n### 子目标分解\n在规划过程中，Agent会将一个复杂的大任务拆分为更小、更易于管理的子目标，从而能够更加高效地完成复杂任务。\n\n#### 目的\n很多复杂任务通常由多个步骤组成，Agent需要清楚这些步骤是什么，并提前规划。例如，在前面提到的5.1.2章节中，CoT（Chain of Thought）以及其改进方法实际上就是在进行任务分解。\n\n\n#### 任务分解的实现方式\n以下是实现任务分解的几种方式：\n\n1. **直接提示**：给LLM一个简单的提示词，例如：\n   ```\n   Steps for XYZ.\n   1.\n   ```\n   或者：\n   ```\n   What are the subgoals for achieving XYZ?\n   ```\n\n2. **具体指令**：针对特定任务提供明确指令。例如，对于写小说的任务，可以先给出“Write a story outline.”这样的指令。\n\n3. **用户输入**：由使用者直接输入明确的任务需求。\n\n无论是CoT还是ToT（Tree of Thought），其本质都是通过精心设计的Prompt，激发模型原有的元认知（Metacognition）。关键在于如何通过某条神经元的线索，更加精准地调动模型中最擅长规划（Planning）的部分。\n\n---\n![Pasted image 20250504190157.png](/img/user/%E9%99%84%E4%BB%B6/Pasted%20image%2020250504190157.png)\n\n\n### LLM与PDDL结合的规划方法\n一种更为高级的规划方法是利用LLM进行长序列的整体规划。具体来说，这种方法使用规划域定义语言（PDDL，Planning Domain Definition Language）作为中间接口来描述规划问题。以下是具体步骤：\n\n1. **问题翻译**：首先，LLM将问题翻译为PDDL格式的问题描述（问题PDDL）。\n2. **调用经典Planner**：接着，请求经典Planner根据现有的领域PDDL生成一个PDDL计划。\n3. **自然语言翻译**：最后，将PDDL计划翻译回自然语言，这一步由LLM完成。\n\n从根本上讲，Planning步骤被外包给了外部工具。但这需要满足一个前提条件：必须有特定领域的PDDL定义和合适的Planner工具。\n\n---\n\n\n## 反思与完善\n\n### 自我批评与反思\nAgent能够对历史动作进行自我批评和反思，从错误中学习，并在后续步骤中不断完善，从而提高最终结果的质量。自我反思（Self-reflection）是一个非常重要的环节，它允许Agent通过完善过去的行动决策和纠正以前的错误来持续改进。\n\n在现实世界中的任务中，试错往往是无法避免的，而自我反思在其中发挥着至关重要的作用。\n\n---\n\n\n## ReAct：结合推理与行动\nReAct是一种被分类在5.2.3章节中的Observation-based Agent方法，其全称为Reason+Act。该方法通过将Action Space扩展为特定任务的离散动作和语言空间的组合，在LLM内部整合了推理（Reasoning）和行动（Action）。\n\n- **推理**：使得LLM能够与环境交互。\n- **行动**：通过提示词，使得LLM用自然语言生成整体推理过程。\n\nReAct提示词模板包含特定设计，以支持这种推理与行动结合的方法。\n![Pasted image 20250504190209.png](/img/user/%E9%99%84%E4%BB%B6/Pasted%20image%2020250504190209.png)\n\n\n\n# 记忆（Memory）\n\n## 短期记忆与长期记忆\n\n### 短期记忆：上下文学习\n短期记忆指的是利用模型的短期记忆进行学习的能力。在上下文学习中，模型能够在短时间内获取、存储并处理信息，从而完成任务。\n\n\n### 长期记忆\n长期记忆为智能体（agent）提供保留和召回长期信息的能力。通常，这种能力通过外部向量存储和检索来实现。长期记忆的特点在于它能够支持信息的长时间保存与高效访问。\n![Pasted image 20250504190306.png](/img/user/%E9%99%84%E4%BB%B6/Pasted%20image%2020250504190306.png)\n\n---\n\n\n## 记忆的定义与分类\n记忆可以定义为一种用于获取、存储、保留和随后检索信息的过程。在人脑中，记忆可以分为以下几种类型：\n\n### 感官记忆\n感官记忆是记忆的最早期阶段，它指的是对原始刺激的感官印象（如视觉、听觉等）的保留能力。这类记忆通常只能持续几秒钟，包含以下三种类型：\n- **图标记忆**：与视觉相关的记忆。\n- **回声记忆**：与听觉相关的记忆。\n- **触碰记忆**：与触觉相关的记忆。\n\n\n### 短时记忆（STM）或工作记忆\n短时记忆存储我们当前意识到的信息，以及执行复杂认知任务（如学习和推理）所需的信息。短时记忆的容量通常为 **7 个项目左右**，并能够持续 **20-30 秒**。\n\n\n### 长时记忆（LTM）\n长时记忆能够将信息存储很长时间，从几天到几十年不等，其存储容量基本上是无限的。长时记忆可进一步分为以下两种类型：\n1. **显性/陈述性记忆**  \n   显性记忆是对事实和事件的记忆，指那些可以有意识地回忆起的内容，包括：\n   - **外显记忆**：关于事件和经历的记忆。\n   - **语义记忆**：关于事实和概括的记忆。\n   \n2. **隐性/程序性记忆**  \n   隐性记忆是无意识的，涉及自动执行的技能和例行程序，例如骑自行车或在键盘上打字。\n\n---\n\n\n## 最大内部产品搜索（Maximum Inner Product Search, MIPS）\n在利用外部存储器缓解关注范围有限的问题时，最大内部产品搜索（MIPS）是一种有效的方法。为了优化检索速度，常采用近似最近邻（ANN）算法。这些算法通过牺牲少量精度来显著提升速度，并返回近似的前 $k$ 个近邻。以下是几种常见的 ANN 算法：\n\n### LSH （局部敏感哈希）\nLSH 引入了一种哈希函数，该函数能够最大限度地将相似的输入项映射到同一个桶中。桶的数量远小于输入内容的数量，从而实现快速检索。\n\n\n### ANNOY （Approximate Nearest Neighbors Oh Yeah）\nANNOY 的核心数据结构是随机投影树，这是一种二叉树集合。具体而言：\n- 每个非叶子节点表示将输入空间划分为两半的一个超平面。\n- 每个叶子节点存储一个数据点。\n  \n这些树是独立随机构建的，在某种程度上模拟了哈希函数的作用。在搜索过程中，ANNOY 会在所有树中迭代地搜索最接近查询点的一半，然后聚合结果。其思想与 KD 树非常相关，但具有更强的可扩展性。\n\n\n### HNSW （Hierarchical Navigable Small World）\nHNSW 的设计思想来源于小世界网络。在小世界网络中，每个节点只需通过很少的步数即可连接到其他任何节点，例如社交网络中的“六度分隔”理论。\n- HNSW 构建了多层的小世界网络结构，其中底层包含实际的数据点。\n- 中间层创建了一些“快捷键”，以加速搜索过程。\n\n通过这种分层结构，HNSW 能够在大规模数据集上实现高效搜索。\n\n---\n\n\n\n# 工具使用（Tool Use）\n在人工智能领域，模型的能力在很多情况下可能受到权重丢失信息的限制。为了弥补这一不足，智能体（Agent）可以通过调用外部API获取额外的信息。这些信息包括但不限于：\n\n- 当前的实时信息\n- 代码执行能力\n- 专有信息源的访问\n\n这种工具的使用，使得智能体能够更好地应对复杂的任务，同时提升其处理问题的灵活性和准确性。\n\n---\n\n\n\n# 智能体与LLM的区别\n\n## 与LLM的交互方式\n与大语言模型（LLM, Large Language Model）的交互非常直接——你只需要输入一个提示，大模型会基于输入生成一个回答。这种交互模式简单直观，但往往缺乏深入的思考和迭代过程。\n![Pasted image 20250504190351.png](/img/user/%E9%99%84%E4%BB%B6/Pasted%20image%2020250504190351.png)\n\n---\n\n\n## 与Agent的交互方式\n与智能体（Agent）的交互则更加复杂和动态。它不仅仅是简单地生成回答，而是模拟一种助手的行为。以下是一个典型的Agent交互流程：\n\n1. 你提出一个问题或任务。\n2. Agent会先询问是否需要进行一些网络研究。\n3. 在必要时，Agent会主动获取相关信息，写下初稿。\n4. Agent会回顾初稿，并思考哪些部分需要修改。\n5. Agent对草稿进行修改。\n6. 这个过程会不断进行思考和迭代，直到最终得到满意的结果。\n\n这个流程可以总结为一个 **思考 + 迭代** 的过程，体现了Agent在解决问题时的主动性和灵活性。\n![Pasted image 20250504190359.png](/img/user/%E9%99%84%E4%BB%B6/Pasted%20image%2020250504190359.png)\n\n---\n\n\n\n# 与强化学习智能体的区别\n\n## 强化学习智能体\n强化学习（Reinforcement Learning, RL）智能体的输入和输出通常局限于特定的环境中。具体来说：\n\n- **输入**：强化学习智能体接收的是预设好的向量化环境状态，或者是图像等结构化数据。\n- **策略**：策略通常由简单的神经网络结构初始化，并通过不断训练进行优化。\n- **输出**：输出动作多为底层控制，例如移动、攻击等。\n\n这种智能体主要应用于特定的任务场景，例如游戏AI、机器人控制等。\n\n---\n\n\n## 基于大模型的智能体\n相比于传统强化学习智能体，基于大语言模型（LLM）的智能体具有更广泛的适用场景和更高层次的处理能力：\n\n- **输入**：基于大模型的智能体接受的是文字输入。在多模态场景下，还可以处理视觉、语音等信息。\n- **策略**：策略基于预训练的大语言模型，这些模型具备丰富的世界知识。\n- **输出**：输出形式为文本，但可以通过结构化输出和提取实现 `function_call`，从而与现实环境进行进一步交互。\n\n这种智能体不仅能处理复杂的文字任务，还能通过调用函数或API，与外部世界互动。例如，它可以通过命令控制外部设备，或者从数据库中提取信息，从而实现更高效的信息处理和决策支持。\n\n---","excerpt":"","includedFiles":[],"tasklistId":0,"title":"记忆（Memory）","headers":[{"level":2,"title":"什么是LLM Agent？","slug":"什么是llm-agent","link":"#什么是llm-agent","children":[{"level":3,"title":"LLM Agent的核心组成","slug":"llm-agent的核心组成","link":"#llm-agent的核心组成","children":[]}]},{"level":2,"title":"规划（Planning）","slug":"规划-planning","link":"#规划-planning","children":[{"level":3,"title":"子目标分解","slug":"子目标分解","link":"#子目标分解","children":[]},{"level":3,"title":"LLM与PDDL结合的规划方法","slug":"llm与pddl结合的规划方法","link":"#llm与pddl结合的规划方法","children":[]}]},{"level":2,"title":"反思与完善","slug":"反思与完善","link":"#反思与完善","children":[{"level":3,"title":"自我批评与反思","slug":"自我批评与反思","link":"#自我批评与反思","children":[]}]},{"level":2,"title":"ReAct：结合推理与行动","slug":"react-结合推理与行动","link":"#react-结合推理与行动","children":[]},{"level":2,"title":"短期记忆与长期记忆","slug":"短期记忆与长期记忆","link":"#短期记忆与长期记忆","children":[{"level":3,"title":"短期记忆：上下文学习","slug":"短期记忆-上下文学习","link":"#短期记忆-上下文学习","children":[]},{"level":3,"title":"长期记忆","slug":"长期记忆","link":"#长期记忆","children":[]}]},{"level":2,"title":"记忆的定义与分类","slug":"记忆的定义与分类","link":"#记忆的定义与分类","children":[{"level":3,"title":"感官记忆","slug":"感官记忆","link":"#感官记忆","children":[]},{"level":3,"title":"短时记忆（STM）或工作记忆","slug":"短时记忆-stm-或工作记忆","link":"#短时记忆-stm-或工作记忆","children":[]},{"level":3,"title":"长时记忆（LTM）","slug":"长时记忆-ltm","link":"#长时记忆-ltm","children":[]}]},{"level":2,"title":"最大内部产品搜索（Maximum Inner Product Search, MIPS）","slug":"最大内部产品搜索-maximum-inner-product-search-mips","link":"#最大内部产品搜索-maximum-inner-product-search-mips","children":[{"level":3,"title":"LSH （局部敏感哈希）","slug":"lsh-局部敏感哈希","link":"#lsh-局部敏感哈希","children":[]},{"level":3,"title":"ANNOY （Approximate Nearest Neighbors Oh Yeah）","slug":"annoy-approximate-nearest-neighbors-oh-yeah","link":"#annoy-approximate-nearest-neighbors-oh-yeah","children":[]},{"level":3,"title":"HNSW （Hierarchical Navigable Small World）","slug":"hnsw-hierarchical-navigable-small-world","link":"#hnsw-hierarchical-navigable-small-world","children":[]}]},{"level":2,"title":"与LLM的交互方式","slug":"与llm的交互方式","link":"#与llm的交互方式","children":[]},{"level":2,"title":"与Agent的交互方式","slug":"与agent的交互方式","link":"#与agent的交互方式","children":[]},{"level":2,"title":"强化学习智能体","slug":"强化学习智能体","link":"#强化学习智能体","children":[]},{"level":2,"title":"基于大模型的智能体","slug":"基于大模型的智能体","link":"#基于大模型的智能体","children":[]}]}}
