export default "{\"documentCount\":2712,\"nextId\":2712,\"documentIds\":{\"0\":\"/article/oie1xumy/\",\"1\":\"/article/j7ahduvk/\",\"2\":\"/welcome/\",\"3\":\"/article/j7ahduvk/#heading-2\",\"4\":\"/notes_bak/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AF%BC%E8%88%AA/\",\"5\":\"/welcome/#关于大语言模型学习导航\",\"6\":\"/article/j7ahduvk/#heading-3\",\"7\":\"/cpp/using/\",\"8\":\"/cpp/%E8%BF%87%E7%A8%8B%E8%B0%83%E7%94%A8/\",\"9\":\"/article/j7ahduvk/#heading-4\",\"10\":\"/cpp/using/#_1-namespace-名称空间\",\"11\":\"/cpp/%E5%87%BD%E6%95%B0%E5%A3%B0%E6%98%8E/\",\"12\":\"/cpp/%E8%BF%87%E7%A8%8B%E8%B0%83%E7%94%A8/#_1-过程编程-procedural-programming\",\"13\":\"/article/j7ahduvk/#heading-5\",\"14\":\"/article/ydsotbz8/\",\"15\":\"/cpp/%E8%BF%87%E7%A8%8B%E8%B0%83%E7%94%A8/#泛型编程-generic-programming\",\"16\":\"/c__%20primer%20plus/%E5%AF%BC%E8%88%AA/\",\"17\":\"/cpp/%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4/\",\"18\":\"/article/j7ahduvk/#heading-6\",\"19\":\"/demo/\",\"20\":\"/cpp/%E8%BF%87%E7%A8%8B%E8%B0%83%E7%94%A8/#区别与联系\",\"21\":\"/c__%20primer%20plus/%E5%AF%BC%E8%88%AA/#c-核心\",\"22\":\"/cpp/%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4/#_1-using-std-cout\",\"23\":\"/demo/0wrw0m9x/\",\"24\":\"/c__%20primer%20plus/%E5%AF%BC%E8%88%AA/#高级特性\",\"25\":\"/demo/b9pbxayh/\",\"26\":\"/transformer/%E5%BC%95%E8%A8%80/\",\"27\":\"/cpp/%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4/#_2-using-namespace-std\",\"28\":\"/transformer/%E5%AF%BC%E8%88%AA/\",\"29\":\"/transformer/%E5%BC%95%E8%A8%80/#transformer-模型与迁移学习整合解析\",\"30\":\"/leetcode/%E5%AF%BC%E8%88%AA/\",\"31\":\"/transformer/%E5%AF%BC%E8%88%AA/#模型变体\",\"32\":\"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%8D%95%E5%8F%98%E9%87%8F/\",\"33\":\"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0/\",\"34\":\"/transformer/%E5%BC%95%E8%A8%80/#一、transformer-模型的核心结构与工作原理\",\"35\":\"/leetcode/%E5%AF%BC%E8%88%AA/#链表\",\"36\":\"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/\",\"37\":\"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%AF%BC%E8%88%AA/\",\"38\":\"/transformer/%E5%AF%BC%E8%88%AA/#应用实践\",\"39\":\"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%BC%95%E8%A8%80/\",\"40\":\"/transformer/%E5%BC%95%E8%A8%80/#二、迁移学习的定义与实施流程\",\"41\":\"/leetcode/%E5%AF%BC%E8%88%AA/#树\",\"42\":\"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/#_1-问题背景\",\"43\":\"/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/\",\"44\":\"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%AF%BC%E8%88%AA/#深度学习\",\"45\":\"/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AF%BC%E8%88%AA/\",\"46\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%AF%BC%E8%88%AA/\",\"47\":\"/leetcode/%E9%93%BE%E8%A1%A8/%E5%88%86%E9%9A%94%E9%93%BE%E8%A1%A8/\",\"48\":\"/leetcode/%E9%93%BE%E8%A1%A8/%E5%90%88%E5%B9%B6%E9%9B%B6%E4%B9%8B%E9%97%B4%E7%9A%84%E8%8A%82%E7%82%B9/\",\"49\":\"/transformer/%E5%BC%95%E8%A8%80/#三、整合应用案例与最佳实践\",\"50\":\"/leetcode/%E5%AF%BC%E8%88%AA/#动态规划\",\"51\":\"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/#_2-逻辑回归的核心思想\",\"52\":\"/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/#_1-自然语言处理-nlp-基础\",\"53\":\"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%AF%BC%E8%88%AA/#实践项目\",\"54\":\"/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AF%BC%E8%88%AA/#系统设计\",\"55\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%AF%BC%E8%88%AA/#词嵌入\",\"56\":\"/xv6/demo/\",\"57\":\"/transformer/%E5%BC%95%E8%A8%80/#四、挑战与前沿技术\",\"58\":\"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/#_3-逻辑回归的全流程\",\"59\":\"/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/#需要学习的知识\",\"60\":\"/thino/%E5%AF%BC%E8%88%AA/\",\"61\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Attention%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%BA%94%E7%94%A8/\",\"62\":\"/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AF%BC%E8%88%AA/#实现过程\",\"63\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%AF%BC%E8%88%AA/#attention\",\"64\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/DCA%EF%BC%9A%E9%95%BF%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E7%9A%84%E6%96%B0%E7%AA%81%E7%A0%B4%EF%BC%88Dual-Chunk-Attention%EF%BC%89/\",\"65\":\"/transformer/%E5%BC%95%E8%A8%80/#五、工具与资源推荐\",\"66\":\"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/#第一步-输入数据\",\"67\":\"/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/#学习资源\",\"68\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/KV-Cache%E6%8A%80%E6%9C%AF%E8%AF%A6%E8%A7%A3%EF%BC%9A%E4%BC%98%E5%8C%96Transformer%E8%87%AA%E5%9B%9E%E5%BD%92%E7%94%9F%E6%88%90%E6%95%88%E7%8E%87/\",\"69\":\"/thino/%E5%AF%BC%E8%88%AA/#开发文档\",\"70\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Transformer%E4%B8%AD%E7%9A%84Attention%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/\",\"71\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Attention%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%BA%94%E7%94%A8/#元数据\",\"72\":\"/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AF%BC%E8%88%AA/#论文撰写\",\"73\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%AF%BC%E8%88%AA/#ffn-add-ln\",\"74\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/DCA%EF%BC%9A%E9%95%BF%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E7%9A%84%E6%96%B0%E7%AA%81%E7%A0%B4%EF%BC%88Dual-Chunk-Attention%EF%BC%89/#元数据\",\"75\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E3%80%90%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E3%80%91%E5%9F%BA%E4%BA%8EShifted-Sparse-Attention%E7%9A%84%E5%88%9B%E6%96%B0%E6%96%B9%E6%B3%95/\",\"76\":\"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/#第二步-线性回归部分\",\"77\":\"/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/#_2-机器学习基础\",\"78\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/KV-Cache%E6%8A%80%E6%9C%AF%E8%AF%A6%E8%A7%A3%EF%BC%9A%E4%BC%98%E5%8C%96Transformer%E8%87%AA%E5%9B%9E%E5%BD%92%E7%94%9F%E6%88%90%E6%95%88%E7%8E%87/#博客标题-kv-cache技术详解-优化transformer自回归生成效率\",\"79\":\"/thino/%E5%AF%BC%E8%88%AA/#部署文档\",\"80\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Transformer%E4%B8%AD%E7%9A%84Attention%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#元数据\",\"81\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E4%BC%98%E5%8C%96Attention%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E5%BA%A6%E7%9A%84%E6%8A%80%E6%9C%AF%E6%8E%A2%E8%AE%A8/\",\"82\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8EMHA%E5%88%B0MLA/\",\"83\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Attention%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%BA%94%E7%94%A8/#attention机制的核心思想与计算方法\",\"84\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%AF%BC%E8%88%AA/#positional-encoding\",\"85\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/%E5%8F%91%E5%B1%95%E5%8E%86%E5%8F%B2/\",\"86\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/DCA%EF%BC%9A%E9%95%BF%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E7%9A%84%E6%96%B0%E7%AA%81%E7%A0%B4%EF%BC%88Dual-Chunk-Attention%EF%BC%89/#什么是dca\",\"87\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E3%80%90%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E3%80%91%E5%9F%BA%E4%BA%8EShifted-Sparse-Attention%E7%9A%84%E5%88%9B%E6%96%B0%E6%96%B9%E6%B3%95/#元数据\",\"88\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/MCP/%E4%BB%8B%E7%BB%8D/\",\"89\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Transformer%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97%E8%A7%A3%E6%9E%90%EF%BC%9AFFN%E3%80%81Add-_-LN-%E7%9A%84%E4%BD%9C%E7%94%A8%E4%B8%8E%E5%BA%94%E7%94%A8/\",\"90\":\"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/#第三步-通过s型函数转换概率\",\"91\":\"/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/#需要学习的知识-1\",\"92\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/KV-Cache%E6%8A%80%E6%9C%AF%E8%AF%A6%E8%A7%A3%EF%BC%9A%E4%BC%98%E5%8C%96Transformer%E8%87%AA%E5%9B%9E%E5%BD%92%E7%94%9F%E6%88%90%E6%95%88%E7%8E%87/#元数据\",\"93\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Transformer%E4%B8%AD%E7%9A%84Attention%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#内容概述\",\"94\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E4%BC%98%E5%8C%96Attention%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E5%BA%A6%E7%9A%84%E6%8A%80%E6%9C%AF%E6%8E%A2%E8%AE%A8/#元数据\",\"95\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84Layer-Norm%E8%AE%BE%E8%AE%A1%EF%BC%9APost-Norm%E3%80%81Pre-Norm%E4%B8%8ESandwich-Norm%E6%AF%94%E8%BE%83/\",\"96\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8EMHA%E5%88%B0MLA/#元数据\",\"97\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Attention%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%BA%94%E7%94%A8/#💡-核心思想\",\"98\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%AF%BC%E8%88%AA/#structure-decoding-policy-结构和解码策略\",\"99\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/%E5%8F%91%E5%B1%95%E5%8E%86%E5%8F%B2/#核心观点总结\",\"100\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/DCA%EF%BC%9A%E9%95%BF%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E7%9A%84%E6%96%B0%E7%AA%81%E7%A0%B4%EF%BC%88Dual-Chunk-Attention%EF%BC%89/#核心思想与实现\",\"101\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E3%80%90%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E3%80%91%E5%9F%BA%E4%BA%8EShifted-Sparse-Attention%E7%9A%84%E5%88%9B%E6%96%B0%E6%96%B9%E6%B3%95/#核心观点总结\",\"102\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/MCP/%E4%BB%8B%E7%BB%8D/#mcp架构概览\",\"103\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E4%B8%8EFFN%E7%BB%93%E6%9E%84%E4%BC%98%E5%8C%96%EF%BC%9ASwiGLU%E3%80%81GeGLU%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E8%A7%A3%E6%9E%90/\",\"104\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Transformer%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97%E8%A7%A3%E6%9E%90%EF%BC%9AFFN%E3%80%81Add-_-LN-%E7%9A%84%E4%BD%9C%E7%94%A8%E4%B8%8E%E5%BA%94%E7%94%A8/#元数据\",\"105\":\"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/#第四步-设定阈值进行分类\",\"106\":\"/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/#学习资源-1\",\"107\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/KV-Cache%E6%8A%80%E6%9C%AF%E8%AF%A6%E8%A7%A3%EF%BC%9A%E4%BC%98%E5%8C%96Transformer%E8%87%AA%E5%9B%9E%E5%BD%92%E7%94%9F%E6%88%90%E6%95%88%E7%8E%87/#kv-cache技术简介\",\"108\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Transformer%E4%B8%AD%E7%9A%84Attention%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#核心内容\",\"109\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E4%BC%98%E5%8C%96Attention%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E5%BA%A6%E7%9A%84%E6%8A%80%E6%9C%AF%E6%8E%A2%E8%AE%A8/#内容概述\",\"110\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84Layer-Norm%E8%AE%BE%E8%AE%A1%EF%BC%9APost-Norm%E3%80%81Pre-Norm%E4%B8%8ESandwich-Norm%E6%AF%94%E8%BE%83/#元数据\",\"111\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8EMHA%E5%88%B0MLA/#简介\",\"112\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Attention%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%BA%94%E7%94%A8/#✅-attention的基本概念\",\"113\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%AF%BC%E8%88%AA/#pre-training-预训练\",\"114\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/FFN%E3%80%81Add-_-LN-%E7%9A%84%E4%BD%9C%E7%94%A8%E4%B8%8E%E5%BA%94%E7%94%A8/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3%E4%B8%8E%E6%AF%94%E8%BE%83%EF%BC%9A%E4%BB%8ESigmoid%E5%88%B0Swish/\",\"115\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/%E5%8F%91%E5%B1%95%E5%8E%86%E5%8F%B2/#重点段落\",\"116\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/DCA%EF%BC%9A%E9%95%BF%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E7%9A%84%E6%96%B0%E7%AA%81%E7%A0%B4%EF%BC%88Dual-Chunk-Attention%EF%BC%89/#_1️⃣-dca的工作流程\",\"117\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E3%80%90%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E3%80%91%E5%9F%BA%E4%BA%8EShifted-Sparse-Attention%E7%9A%84%E5%88%9B%E6%96%B0%E6%96%B9%E6%B3%95/#技术解析\",\"118\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/MCP/%E4%BB%8B%E7%BB%8D/#mcp系统组成\",\"119\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E4%B8%8EFFN%E7%BB%93%E6%9E%84%E4%BC%98%E5%8C%96%EF%BC%9ASwiGLU%E3%80%81GeGLU%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E8%A7%A3%E6%9E%90/#元数据\",\"120\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/NTK%E6%8F%92%E5%80%BC%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90%E4%B8%8E%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8ENTK-aware%E5%88%B0NTK-by-parts/\",\"121\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Transformer%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97%E8%A7%A3%E6%9E%90%EF%BC%9AFFN%E3%80%81Add-_-LN-%E7%9A%84%E4%BD%9C%E7%94%A8%E4%B8%8E%E5%BA%94%E7%94%A8/#核心内容总结\",\"122\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/YaRN%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90%EF%BC%9A%E6%89%A9%E5%B1%95RoPE%E5%B5%8C%E5%85%A5%E4%B8%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E4%BC%98%E5%8C%96%E7%9A%84%E5%AE%9E%E8%B7%B5/\",\"123\":\"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/#第五步-训练模型\",\"124\":\"/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/#_3-深度学习基础\",\"125\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/KV-Cache%E6%8A%80%E6%9C%AF%E8%AF%A6%E8%A7%A3%EF%BC%9A%E4%BC%98%E5%8C%96Transformer%E8%87%AA%E5%9B%9E%E5%BD%92%E7%94%9F%E6%88%90%E6%95%88%E7%8E%87/#kv-cache工作原理\",\"126\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Transformer%E4%B8%AD%E7%9A%84Attention%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#✅-self-attention机制\",\"127\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E4%BC%98%E5%8C%96Attention%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E5%BA%A6%E7%9A%84%E6%8A%80%E6%9C%AF%E6%8E%A2%E8%AE%A8/#核心内容\",\"128\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84Layer-Norm%E8%AE%BE%E8%AE%A1%EF%BC%9APost-Norm%E3%80%81Pre-Norm%E4%B8%8ESandwich-Norm%E6%AF%94%E8%BE%83/#内容摘要\",\"129\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8EMHA%E5%88%B0MLA/#核心观点总结\",\"130\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Attention%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%BA%94%E7%94%A8/#⚠️-scaled-dot-product的计算公式\",\"131\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%AF%BC%E8%88%AA/#后训练\",\"132\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/FFN%E3%80%81Add-_-LN-%E7%9A%84%E4%BD%9C%E7%94%A8%E4%B8%8E%E5%BA%94%E7%94%A8/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3%E4%B8%8E%E6%AF%94%E8%BE%83%EF%BC%9A%E4%BB%8ESigmoid%E5%88%B0Swish/#元数据\",\"133\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/%E5%8F%91%E5%B1%95%E5%8E%86%E5%8F%B2/#操作步骤\",\"134\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E4%BB%8B%E7%BB%8D/\",\"135\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/DCA%EF%BC%9A%E9%95%BF%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E7%9A%84%E6%96%B0%E7%AA%81%E7%A0%B4%EF%BC%88Dual-Chunk-Attention%EF%BC%89/#_2️⃣-dca代码实现\",\"136\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E3%80%90%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E3%80%91%E5%9F%BA%E4%BA%8EShifted-Sparse-Attention%E7%9A%84%E5%88%9B%E6%96%B0%E6%96%B9%E6%B3%95/#✅-核心原理-shifted-sparse-attention\",\"137\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/MCP/%E4%BB%8B%E7%BB%8D/#api集成的挑战\",\"138\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E4%B8%8EFFN%E7%BB%93%E6%9E%84%E4%BC%98%E5%8C%96%EF%BC%9ASwiGLU%E3%80%81GeGLU%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E8%A7%A3%E6%9E%90/#核心内容概述\",\"139\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/NTK%E6%8F%92%E5%80%BC%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90%E4%B8%8E%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8ENTK-aware%E5%88%B0NTK-by-parts/#元数据\",\"140\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E4%BD%8D%E7%BD%AE%E5%86%85%E6%8F%92%E6%B3%95%E6%89%A9%E5%B1%95%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E9%95%BF%E5%BA%A6/\",\"141\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Transformer%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97%E8%A7%A3%E6%9E%90%EF%BC%9AFFN%E3%80%81Add-_-LN-%E7%9A%84%E4%BD%9C%E7%94%A8%E4%B8%8E%E5%BA%94%E7%94%A8/#详细解析\",\"142\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/YaRN%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90%EF%BC%9A%E6%89%A9%E5%B1%95RoPE%E5%B5%8C%E5%85%A5%E4%B8%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E4%BC%98%E5%8C%96%E7%9A%84%E5%AE%9E%E8%B7%B5/#元数据\",\"143\":\"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/#第六步-预测新数据\",\"144\":\"/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/#需要学习的知识-2\",\"145\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/KV-Cache%E6%8A%80%E6%9C%AF%E8%AF%A6%E8%A7%A3%EF%BC%9A%E4%BC%98%E5%8C%96Transformer%E8%87%AA%E5%9B%9E%E5%BD%92%E7%94%9F%E6%88%90%E6%95%88%E7%8E%87/#kv-cache-vs-不使用缓存\",\"146\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Transformer%E4%B8%AD%E7%9A%84Attention%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#encoder中的self-attention\",\"147\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E4%BC%98%E5%8C%96Attention%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E5%BA%A6%E7%9A%84%E6%8A%80%E6%9C%AF%E6%8E%A2%E8%AE%A8/#self-attention的计算复杂度问题\",\"148\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84Layer-Norm%E8%AE%BE%E8%AE%A1%EF%BC%9APost-Norm%E3%80%81Pre-Norm%E4%B8%8ESandwich-Norm%E6%AF%94%E8%BE%83/#核心内容\",\"149\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8EMHA%E5%88%B0MLA/#✅-mha-multi-head-attention\",\"150\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Attention%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%BA%94%E7%94%A8/#📈-技术趋势与优化点\",\"151\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%AF%BC%E8%88%AA/#强化学习基础\",\"152\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/FFN%E3%80%81Add-_-LN-%E7%9A%84%E4%BD%9C%E7%94%A8%E4%B8%8E%E5%BA%94%E7%94%A8/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3%E4%B8%8E%E6%AF%94%E8%BE%83%EF%BC%9A%E4%BB%8ESigmoid%E5%88%B0Swish/#内容摘要\",\"153\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/%E5%8F%91%E5%B1%95%E5%8E%86%E5%8F%B2/#行动清单\",\"154\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E4%BB%8B%E7%BB%8D/#元数据\",\"155\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/DCA%EF%BC%9A%E9%95%BF%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E7%9A%84%E6%96%B0%E7%AA%81%E7%A0%B4%EF%BC%88Dual-Chunk-Attention%EF%BC%89/#📈-数据总结与优势\",\"156\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E3%80%90%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E3%80%91%E5%9F%BA%E4%BA%8EShifted-Sparse-Attention%E7%9A%84%E5%88%9B%E6%96%B0%E6%96%B9%E6%B3%95/#⚠️-操作步骤\",\"157\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/MCP/%E4%BB%8B%E7%BB%8D/#认证与集成复杂性\",\"158\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E4%B8%8EFFN%E7%BB%93%E6%9E%84%E4%BC%98%E5%8C%96%EF%BC%9ASwiGLU%E3%80%81GeGLU%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E8%A7%A3%E6%9E%90/#关键内容解析\",\"159\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/NTK%E6%8F%92%E5%80%BC%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90%E4%B8%8E%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8ENTK-aware%E5%88%B0NTK-by-parts/#核心观点总结\",\"160\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E4%BD%8D%E7%BD%AE%E5%86%85%E6%8F%92%E6%B3%95%E6%89%A9%E5%B1%95%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E9%95%BF%E5%BA%A6/#元数据\",\"161\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E6%95%B0%E5%AD%97%E8%BE%93%E5%85%A5%E4%BC%98%E5%8C%96%E4%B8%8E%E5%A4%96%E6%8E%A8%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90/\",\"162\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Transformer%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97%E8%A7%A3%E6%9E%90%EF%BC%9AFFN%E3%80%81Add-_-LN-%E7%9A%84%E4%BD%9C%E7%94%A8%E4%B8%8E%E5%BA%94%E7%94%A8/#✅-ffn-前馈网络-独立计算的核心\",\"163\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/YaRN%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90%EF%BC%9A%E6%89%A9%E5%B1%95RoPE%E5%B5%8C%E5%85%A5%E4%B8%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E4%BC%98%E5%8C%96%E7%9A%84%E5%AE%9E%E8%B7%B5/#内容概要\",\"164\":\"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/#_4-举个例子\",\"165\":\"/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/#学习资源-2\",\"166\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/KV-Cache%E6%8A%80%E6%9C%AF%E8%AF%A6%E8%A7%A3%EF%BC%9A%E4%BC%98%E5%8C%96Transformer%E8%87%AA%E5%9B%9E%E5%BD%92%E7%94%9F%E6%88%90%E6%95%88%E7%8E%87/#不使用kv-cache的流程\",\"167\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Transformer%E4%B8%AD%E7%9A%84Attention%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#decoder中的self-attention\",\"168\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E4%BC%98%E5%8C%96Attention%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E5%BA%A6%E7%9A%84%E6%8A%80%E6%9C%AF%E6%8E%A2%E8%AE%A8/#sparse-attention-局部与远程稀疏相关\",\"169\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84Layer-Norm%E8%AE%BE%E8%AE%A1%EF%BC%9APost-Norm%E3%80%81Pre-Norm%E4%B8%8ESandwich-Norm%E6%AF%94%E8%BE%83/#layer-norm的位置对模型的影响\",\"170\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8EMHA%E5%88%B0MLA/#⚠️-mqa-multi-query-attention\",\"171\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Attention%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%BA%94%E7%94%A8/#常见错误与注意事项\",\"172\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%AF%BC%E8%88%AA/#common-models\",\"173\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/FFN%E3%80%81Add-_-LN-%E7%9A%84%E4%BD%9C%E7%94%A8%E4%B8%8E%E5%BA%94%E7%94%A8/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3%E4%B8%8E%E6%AF%94%E8%BE%83%EF%BC%9A%E4%BB%8ESigmoid%E5%88%B0Swish/#常见激活函数解析\",\"174\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E4%BB%8B%E7%BB%8D/#核心内容总结\",\"175\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/DCA%EF%BC%9A%E9%95%BF%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E7%9A%84%E6%96%B0%E7%AA%81%E7%A0%B4%EF%BC%88Dual-Chunk-Attention%EF%BC%89/#常见错误\",\"176\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E3%80%90%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E3%80%91%E5%9F%BA%E4%BA%8EShifted-Sparse-Attention%E7%9A%84%E5%88%9B%E6%96%B0%E6%96%B9%E6%B3%95/#数据与示例\",\"177\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/MCP/%E4%BB%8B%E7%BB%8D/#如何应对这些挑战\",\"178\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E4%B8%8EFFN%E7%BB%93%E6%9E%84%E4%BC%98%E5%8C%96%EF%BC%9ASwiGLU%E3%80%81GeGLU%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E8%A7%A3%E6%9E%90/#_1-ffn结构与激活函数基础\",\"179\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/NTK%E6%8F%92%E5%80%BC%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90%E4%B8%8E%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8ENTK-aware%E5%88%B0NTK-by-parts/#关键内容解析\",\"180\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E4%BD%8D%E7%BD%AE%E5%86%85%E6%8F%92%E6%B3%95%E6%89%A9%E5%B1%95%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E9%95%BF%E5%BA%A6/#核心观点\",\"181\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E6%95%B0%E5%AD%97%E8%BE%93%E5%85%A5%E4%BC%98%E5%8C%96%E4%B8%8E%E5%A4%96%E6%8E%A8%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90/#元数据\",\"182\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E6%97%8B%E8%BD%AC%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8EALiBi%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%BD%8D%E7%BD%AE%E5%B5%8C%E5%85%A5%E4%BC%98%E5%8C%96/\",\"183\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Transformer%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97%E8%A7%A3%E6%9E%90%EF%BC%9AFFN%E3%80%81Add-_-LN-%E7%9A%84%E4%BD%9C%E7%94%A8%E4%B8%8E%E5%BA%94%E7%94%A8/#⚠️-add-残差连接-优化深层网络的梯度回传\",\"184\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/YaRN%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90%EF%BC%9A%E6%89%A9%E5%B1%95RoPE%E5%B5%8C%E5%85%A5%E4%B8%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E4%BC%98%E5%8C%96%E7%9A%84%E5%AE%9E%E8%B7%B5/#核心观点\",\"185\":\"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/#_5-总结\",\"186\":\"/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/#_4-智能阅读模型相关技术\",\"187\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/KV-Cache%E6%8A%80%E6%9C%AF%E8%AF%A6%E8%A7%A3%EF%BC%9A%E4%BC%98%E5%8C%96Transformer%E8%87%AA%E5%9B%9E%E5%BD%92%E7%94%9F%E6%88%90%E6%95%88%E7%8E%87/#使用kv-cache的流程\",\"188\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Transformer%E4%B8%AD%E7%9A%84Attention%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#✅-cross-attention机制\",\"189\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E4%BC%98%E5%8C%96Attention%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E5%BA%A6%E7%9A%84%E6%8A%80%E6%9C%AF%E6%8E%A2%E8%AE%A8/#linear-attention-从平方复杂度到线性复杂度\",\"190\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84Layer-Norm%E8%AE%BE%E8%AE%A1%EF%BC%9APost-Norm%E3%80%81Pre-Norm%E4%B8%8ESandwich-Norm%E6%AF%94%E8%BE%83/#layer-norm的计算公式\",\"191\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8EMHA%E5%88%B0MLA/#❗️-gqa-grouped-query-attention\",\"192\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Attention%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%BA%94%E7%94%A8/#❗️-常见错误\",\"193\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%AF%BC%E8%88%AA/#训练推理优化\",\"194\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/FFN%E3%80%81Add-_-LN-%E7%9A%84%E4%BD%9C%E7%94%A8%E4%B8%8E%E5%BA%94%E7%94%A8/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3%E4%B8%8E%E6%AF%94%E8%BE%83%EF%BC%9A%E4%BB%8ESigmoid%E5%88%B0Swish/#sigmoid\",\"195\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E4%BB%8B%E7%BB%8D/#关键内容解析\",\"196\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/DCA%EF%BC%9A%E9%95%BF%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E7%9A%84%E6%96%B0%E7%AA%81%E7%A0%B4%EF%BC%88Dual-Chunk-Attention%EF%BC%89/#行动清单\",\"197\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E3%80%90%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E3%80%91%E5%9F%BA%E4%BA%8EShifted-Sparse-Attention%E7%9A%84%E5%88%9B%E6%96%B0%E6%96%B9%E6%B3%95/#📊-数据表格-上下文长度分组与注意力计算\",\"198\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/MCP/%E4%BB%8B%E7%BB%8D/#解决方案\",\"199\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E4%B8%8EFFN%E7%BB%93%E6%9E%84%E4%BC%98%E5%8C%96%EF%BC%9ASwiGLU%E3%80%81GeGLU%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E8%A7%A3%E6%9E%90/#_2-glu与其变种-swiglu、geglu-的改进\",\"200\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/NTK%E6%8F%92%E5%80%BC%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90%E4%B8%8E%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8ENTK-aware%E5%88%B0NTK-by-parts/#ntk-aware插值-高频外推与低频内插\",\"201\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E4%BD%8D%E7%BD%AE%E5%86%85%E6%8F%92%E6%B3%95%E6%89%A9%E5%B1%95%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E9%95%BF%E5%BA%A6/#重点内容\",\"202\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E6%95%B0%E5%AD%97%E8%BE%93%E5%85%A5%E4%BC%98%E5%8C%96%E4%B8%8E%E5%A4%96%E6%8E%A8%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90/#数字输入优化的核心方法\",\"203\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E6%97%8B%E8%BD%AC%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8EALiBi%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%BD%8D%E7%BD%AE%E5%B5%8C%E5%85%A5%E4%BC%98%E5%8C%96/#概述\",\"204\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E4%B8%8E%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%EF%BC%88LLM-_-MoE%EF%BC%89%E8%A7%A3%E6%9E%90/\",\"205\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Transformer%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97%E8%A7%A3%E6%9E%90%EF%BC%9AFFN%E3%80%81Add-_-LN-%E7%9A%84%E4%BD%9C%E7%94%A8%E4%B8%8E%E5%BA%94%E7%94%A8/#❗️-ln-层归一化-nlp-中的收敛加速器\",\"206\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/YaRN%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90%EF%BC%9A%E6%89%A9%E5%B1%95RoPE%E5%B5%8C%E5%85%A5%E4%B8%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E4%BC%98%E5%8C%96%E7%9A%84%E5%AE%9E%E8%B7%B5/#技术细节\",\"207\":\"/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/#需要学习的知识-3\",\"208\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/KV-Cache%E6%8A%80%E6%9C%AF%E8%AF%A6%E8%A7%A3%EF%BC%9A%E4%BC%98%E5%8C%96Transformer%E8%87%AA%E5%9B%9E%E5%BD%92%E7%94%9F%E6%88%90%E6%95%88%E7%8E%87/#技术实现示例\",\"209\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Transformer%E4%B8%AD%E7%9A%84Attention%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#⚠️-常见错误\",\"210\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E4%BC%98%E5%8C%96Attention%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E5%BA%A6%E7%9A%84%E6%8A%80%E6%9C%AF%E6%8E%A2%E8%AE%A8/#常见错误\",\"211\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84Layer-Norm%E8%AE%BE%E8%AE%A1%EF%BC%9APost-Norm%E3%80%81Pre-Norm%E4%B8%8ESandwich-Norm%E6%AF%94%E8%BE%83/#技术术语通俗解释\",\"212\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8EMHA%E5%88%B0MLA/#📈-mla-multi-head-latent-attention\",\"213\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Attention%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%BA%94%E7%94%A8/#代码示例-scaled-dot-product计算\",\"214\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%AF%BC%E8%88%AA/#模型压缩\",\"215\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/FFN%E3%80%81Add-_-LN-%E7%9A%84%E4%BD%9C%E7%94%A8%E4%B8%8E%E5%BA%94%E7%94%A8/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3%E4%B8%8E%E6%AF%94%E8%BE%83%EF%BC%9A%E4%BB%8ESigmoid%E5%88%B0Swish/#tanh\",\"216\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E4%BB%8B%E7%BB%8D/#_1-为什么需要位置编码\",\"217\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/DCA%EF%BC%9A%E9%95%BF%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E7%9A%84%E6%96%B0%E7%AA%81%E7%A0%B4%EF%BC%88Dual-Chunk-Attention%EF%BC%89/#思考-延伸问题\",\"218\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E3%80%90%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E3%80%91%E5%9F%BA%E4%BA%8EShifted-Sparse-Attention%E7%9A%84%E5%88%9B%E6%96%B0%E6%96%B9%E6%B3%95/#示例代码-分组与移位处理\",\"219\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/MCP/%E4%BB%8B%E7%BB%8D/#思考-延伸问题\",\"220\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E4%B8%8EFFN%E7%BB%93%E6%9E%84%E4%BC%98%E5%8C%96%EF%BC%9ASwiGLU%E3%80%81GeGLU%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E8%A7%A3%E6%9E%90/#_3-llama2中的参数优化\",\"221\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/NTK%E6%8F%92%E5%80%BC%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90%E4%B8%8E%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8ENTK-aware%E5%88%B0NTK-by-parts/#核心思想\",\"222\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E4%BD%8D%E7%BD%AE%E5%86%85%E6%8F%92%E6%B3%95%E6%89%A9%E5%B1%95%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E9%95%BF%E5%BA%A6/#rope的问题与位置内插法的解决方案\",\"223\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E6%95%B0%E5%AD%97%E8%BE%93%E5%85%A5%E4%BC%98%E5%8C%96%E4%B8%8E%E5%A4%96%E6%8E%A8%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90/#✅-数字输入的进制表示与直接外推\",\"224\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E6%97%8B%E8%BD%AC%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8EALiBi%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%BD%8D%E7%BD%AE%E5%B5%8C%E5%85%A5%E4%BC%98%E5%8C%96/#核心内容\",\"225\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E4%B8%8E%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%EF%BC%88LLM-_-MoE%EF%BC%89%E8%A7%A3%E6%9E%90/#元数据\",\"226\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E9%87%87%E6%A0%B7%E6%96%B9%E6%B3%95%EF%BC%9ATop-K%E3%80%81Top-P%E3%80%81Temperature%E5%8F%8A%E7%BB%BC%E5%90%88%E7%AD%96%E7%95%A5/\",\"227\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Transformer%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97%E8%A7%A3%E6%9E%90%EF%BC%9AFFN%E3%80%81Add-_-LN-%E7%9A%84%E4%BD%9C%E7%94%A8%E4%B8%8E%E5%BA%94%E7%94%A8/#📈-数据对比表-batch-norm-vs-layer-norm\",\"228\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/YaRN%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90%EF%BC%9A%E6%89%A9%E5%B1%95RoPE%E5%B5%8C%E5%85%A5%E4%B8%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E4%BC%98%E5%8C%96%E7%9A%84%E5%AE%9E%E8%B7%B5/#_1-温度参数对注意力机制的优化\",\"229\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E8%A7%A3%E7%A0%81%E9%87%87%E6%A0%B7%E7%AD%96%E7%95%A5%EF%BC%9AGreedy-Search%E4%B8%8EBeam-Search%E7%9A%84%E5%AE%9E%E7%8E%B0%E4%B8%8E%E4%BC%98%E5%8C%96/\",\"230\":\"/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/#学习资源-3\",\"231\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/KV-Cache%E6%8A%80%E6%9C%AF%E8%AF%A6%E8%A7%A3%EF%BC%9A%E4%BC%98%E5%8C%96Transformer%E8%87%AA%E5%9B%9E%E5%BD%92%E7%94%9F%E6%88%90%E6%95%88%E7%8E%87/#常见错误及警告\",\"232\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Transformer%E4%B8%AD%E7%9A%84Attention%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#💡-启发点\",\"233\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E4%BC%98%E5%8C%96Attention%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E5%BA%A6%E7%9A%84%E6%8A%80%E6%9C%AF%E6%8E%A2%E8%AE%A8/#思考与延伸问题\",\"234\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84Layer-Norm%E8%AE%BE%E8%AE%A1%EF%BC%9APost-Norm%E3%80%81Pre-Norm%E4%B8%8ESandwich-Norm%E6%AF%94%E8%BE%83/#行动清单\",\"235\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8EMHA%E5%88%B0MLA/#数据与公式解读\",\"236\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Attention%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%BA%94%E7%94%A8/#作者观点-vs-个人观点\",\"237\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%AF%BC%E8%88%AA/#大模型应用\",\"238\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/FFN%E3%80%81Add-_-LN-%E7%9A%84%E4%BD%9C%E7%94%A8%E4%B8%8E%E5%BA%94%E7%94%A8/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3%E4%B8%8E%E6%AF%94%E8%BE%83%EF%BC%9A%E4%BB%8ESigmoid%E5%88%B0Swish/#relu\",\"239\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E4%BB%8B%E7%BB%8D/#_2-位置编码的设计要求\",\"240\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/DCA%EF%BC%9A%E9%95%BF%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E7%9A%84%E6%96%B0%E7%AA%81%E7%A0%B4%EF%BC%88Dual-Chunk-Attention%EF%BC%89/#后续追踪研究计划\",\"241\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E3%80%90%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E3%80%91%E5%9F%BA%E4%BA%8EShifted-Sparse-Attention%E7%9A%84%E5%88%9B%E6%96%B0%E6%96%B9%E6%B3%95/#常见错误警告-⚠️\",\"242\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/MCP/%E4%BB%8B%E7%BB%8D/#行动清单\",\"243\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E4%B8%8EFFN%E7%BB%93%E6%9E%84%E4%BC%98%E5%8C%96%EF%BC%9ASwiGLU%E3%80%81GeGLU%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E8%A7%A3%E6%9E%90/#_4-常见错误与注意事项\",\"244\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/NTK%E6%8F%92%E5%80%BC%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90%E4%B8%8E%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8ENTK-aware%E5%88%B0NTK-by-parts/#缺点\",\"245\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E4%BD%8D%E7%BD%AE%E5%86%85%E6%8F%92%E6%B3%95%E6%89%A9%E5%B1%95%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E9%95%BF%E5%BA%A6/#微调对效果的影响\",\"246\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E6%95%B0%E5%AD%97%E8%BE%93%E5%85%A5%E4%BC%98%E5%8C%96%E4%B8%8E%E5%A4%96%E6%8E%A8%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90/#⚠-线性内插与进制转换的优化策略\",\"247\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E6%97%8B%E8%BD%AC%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8EALiBi%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%BD%8D%E7%BD%AE%E5%B5%8C%E5%85%A5%E4%BC%98%E5%8C%96/#_1-什么是rope\",\"248\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E4%B8%8E%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%EF%BC%88LLM-_-MoE%EF%BC%89%E8%A7%A3%E6%9E%90/#核心内容总结\",\"249\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E9%87%87%E6%A0%B7%E6%96%B9%E6%B3%95%EF%BC%9ATop-K%E3%80%81Top-P%E3%80%81Temperature%E5%8F%8A%E7%BB%BC%E5%90%88%E7%AD%96%E7%95%A5/#什么是语言模型采样方法\",\"250\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/BBPE%EF%BC%9A%E5%AD%97%E8%8A%82%E7%BA%A7%E5%88%AB%E7%9A%84BPE%E5%88%86%E8%AF%8D%E6%8A%80%E6%9C%AF%E8%A7%A3%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8/\",\"251\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Transformer%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97%E8%A7%A3%E6%9E%90%EF%BC%9AFFN%E3%80%81Add-_-LN-%E7%9A%84%E4%BD%9C%E7%94%A8%E4%B8%8E%E5%BA%94%E7%94%A8/#常见错误警告区块\",\"252\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/YaRN%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90%EF%BC%9A%E6%89%A9%E5%B1%95RoPE%E5%B5%8C%E5%85%A5%E4%B8%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E4%BC%98%E5%8C%96%E7%9A%84%E5%AE%9E%E8%B7%B5/#_2-rope嵌入的比例缩放\",\"253\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E8%A7%A3%E7%A0%81%E9%87%87%E6%A0%B7%E7%AD%96%E7%95%A5%EF%BC%9AGreedy-Search%E4%B8%8EBeam-Search%E7%9A%84%E5%AE%9E%E7%8E%B0%E4%B8%8E%E4%BC%98%E5%8C%96/#核心观点总结\",\"254\":\"/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/#_5-编程与工具\",\"255\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/KV-Cache%E6%8A%80%E6%9C%AF%E8%AF%A6%E8%A7%A3%EF%BC%9A%E4%BC%98%E5%8C%96Transformer%E8%87%AA%E5%9B%9E%E5%BD%92%E7%94%9F%E6%88%90%E6%95%88%E7%8E%87/#💡启发点\",\"256\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Transformer%E4%B8%AD%E7%9A%84Attention%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#行动清单\",\"257\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E4%BC%98%E5%8C%96Attention%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E5%BA%A6%E7%9A%84%E6%8A%80%E6%9C%AF%E6%8E%A2%E8%AE%A8/#作者观点-vs-个人观点\",\"258\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84Layer-Norm%E8%AE%BE%E8%AE%A1%EF%BC%9APost-Norm%E3%80%81Pre-Norm%E4%B8%8ESandwich-Norm%E6%AF%94%E8%BE%83/#思考-板块\",\"259\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8EMHA%E5%88%B0MLA/#kv缓存需求对比\",\"260\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Attention%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%BA%94%E7%94%A8/#思考-💭\",\"261\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/FFN%E3%80%81Add-_-LN-%E7%9A%84%E4%BD%9C%E7%94%A8%E4%B8%8E%E5%BA%94%E7%94%A8/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3%E4%B8%8E%E6%AF%94%E8%BE%83%EF%BC%9A%E4%BB%8ESigmoid%E5%88%B0Swish/#leaky-relu\",\"262\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/wordpiece/\",\"263\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E4%BB%8B%E7%BB%8D/#_3-数学实现-正弦函数的应用\",\"264\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E3%80%90%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E3%80%91%E5%9F%BA%E4%BA%8EShifted-Sparse-Attention%E7%9A%84%E5%88%9B%E6%96%B0%E6%96%B9%E6%B3%95/#💡-启发点\",\"265\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/MCP/%E4%BB%8B%E7%BB%8D/#后续追踪\",\"266\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E4%B8%8EFFN%E7%BB%93%E6%9E%84%E4%BC%98%E5%8C%96%EF%BC%9ASwiGLU%E3%80%81GeGLU%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E8%A7%A3%E6%9E%90/#代码示例\",\"267\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/NTK%E6%8F%92%E5%80%BC%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90%E4%B8%8E%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8ENTK-aware%E5%88%B0NTK-by-parts/#ntk-by-parts插值-波长与上下文长度的关系\",\"268\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E4%BD%8D%E7%BD%AE%E5%86%85%E6%8F%92%E6%B3%95%E6%89%A9%E5%B1%95%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E9%95%BF%E5%BA%A6/#困惑度指标的重要性\",\"269\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E6%95%B0%E5%AD%97%E8%BE%93%E5%85%A5%E4%BC%98%E5%8C%96%E4%B8%8E%E5%A4%96%E6%8E%A8%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90/#常见错误提醒\",\"270\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E6%97%8B%E8%BD%AC%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8EALiBi%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%BD%8D%E7%BD%AE%E5%B5%8C%E5%85%A5%E4%BC%98%E5%8C%96/#💡-启发点-由于旋转矩阵-r-m-是正交矩阵-不改变向量模长-因此rope不会破坏模型的稳定性。\",\"271\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E4%B8%8E%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%EF%BC%88LLM-_-MoE%EF%BC%89%E8%A7%A3%E6%9E%90/#模型结构分类\",\"272\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E9%87%87%E6%A0%B7%E6%96%B9%E6%B3%95%EF%BC%9ATop-K%E3%80%81Top-P%E3%80%81Temperature%E5%8F%8A%E7%BB%BC%E5%90%88%E7%AD%96%E7%95%A5/#top-k-sampling\",\"273\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/BBPE%EF%BC%9A%E5%AD%97%E8%8A%82%E7%BA%A7%E5%88%AB%E7%9A%84BPE%E5%88%86%E8%AF%8D%E6%8A%80%E6%9C%AF%E8%A7%A3%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8/#元数据\",\"274\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/BPE/\",\"275\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Transformer%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97%E8%A7%A3%E6%9E%90%EF%BC%9AFFN%E3%80%81Add-_-LN-%E7%9A%84%E4%BD%9C%E7%94%A8%E4%B8%8E%E5%BA%94%E7%94%A8/#行动清单-📋\",\"276\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/YaRN%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90%EF%BC%9A%E6%89%A9%E5%B1%95RoPE%E5%B5%8C%E5%85%A5%E4%B8%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E4%BC%98%E5%8C%96%E7%9A%84%E5%AE%9E%E8%B7%B5/#_3-llama模型的推荐公式\",\"277\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E8%A7%A3%E7%A0%81%E9%87%87%E6%A0%B7%E7%AD%96%E7%95%A5%EF%BC%9AGreedy-Search%E4%B8%8EBeam-Search%E7%9A%84%E5%AE%9E%E7%8E%B0%E4%B8%8E%E4%BC%98%E5%8C%96/#解码策略详解\",\"278\":\"/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/#需要学习的知识-4\",\"279\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/KV-Cache%E6%8A%80%E6%9C%AF%E8%AF%A6%E8%A7%A3%EF%BC%9A%E4%BC%98%E5%8C%96Transformer%E8%87%AA%E5%9B%9E%E5%BD%92%E7%94%9F%E6%88%90%E6%95%88%E7%8E%87/#思考-板块\",\"280\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Transformer%E4%B8%AD%E7%9A%84Attention%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#个人见解\",\"281\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E4%BC%98%E5%8C%96Attention%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E5%BA%A6%E7%9A%84%E6%8A%80%E6%9C%AF%E6%8E%A2%E8%AE%A8/#行动清单\",\"282\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84Layer-Norm%E8%AE%BE%E8%AE%A1%EF%BC%9APost-Norm%E3%80%81Pre-Norm%E4%B8%8ESandwich-Norm%E6%AF%94%E8%BE%83/#后续追踪计划\",\"283\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8EMHA%E5%88%B0MLA/#mla核心公式\",\"284\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Attention%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%BA%94%E7%94%A8/#行动清单-✅\",\"285\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/FFN%E3%80%81Add-_-LN-%E7%9A%84%E4%BD%9C%E7%94%A8%E4%B8%8E%E5%BA%94%E7%94%A8/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3%E4%B8%8E%E6%AF%94%E8%BE%83%EF%BC%9A%E4%BB%8ESigmoid%E5%88%B0Swish/#elu\",\"286\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/wordpiece/#元数据\",\"287\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E4%BB%8B%E7%BB%8D/#_4-技术实现步骤\",\"288\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E3%80%90%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E3%80%91%E5%9F%BA%E4%BA%8EShifted-Sparse-Attention%E7%9A%84%E5%88%9B%E6%96%B0%E6%96%B9%E6%B3%95/#行动清单\",\"289\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E4%B8%8EFFN%E7%BB%93%E6%9E%84%E4%BC%98%E5%8C%96%EF%BC%9ASwiGLU%E3%80%81GeGLU%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E8%A7%A3%E6%9E%90/#个人见解-思考\",\"290\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/NTK%E6%8F%92%E5%80%BC%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90%E4%B8%8E%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8ENTK-aware%E5%88%B0NTK-by-parts/#核心思想-1\",\"291\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E4%BD%8D%E7%BD%AE%E5%86%85%E6%8F%92%E6%B3%95%E6%89%A9%E5%B1%95%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E9%95%BF%E5%BA%A6/#应用位置内插的操作步骤\",\"292\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E6%95%B0%E5%AD%97%E8%BE%93%E5%85%A5%E4%BC%98%E5%8C%96%E4%B8%8E%E5%A4%96%E6%8E%A8%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90/#表格数据整理\",\"293\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E6%97%8B%E8%BD%AC%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8EALiBi%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%BD%8D%E7%BD%AE%E5%B5%8C%E5%85%A5%E4%BC%98%E5%8C%96/#_2-什么是alibi\",\"294\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E4%B8%8E%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%EF%BC%88LLM-_-MoE%EF%BC%89%E8%A7%A3%E6%9E%90/#decoder-only-模型\",\"295\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E9%87%87%E6%A0%B7%E6%96%B9%E6%B3%95%EF%BC%9ATop-K%E3%80%81Top-P%E3%80%81Temperature%E5%8F%8A%E7%BB%BC%E5%90%88%E7%AD%96%E7%95%A5/#核心概念\",\"296\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/BBPE%EF%BC%9A%E5%AD%97%E8%8A%82%E7%BA%A7%E5%88%AB%E7%9A%84BPE%E5%88%86%E8%AF%8D%E6%8A%80%E6%9C%AF%E8%A7%A3%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8/#bbpe-字节级别的bpe分词技术\",\"297\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/BPE/#元数据\",\"298\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E4%BD%BF%E7%94%A8Unigram%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88ULM%EF%BC%89%E4%BC%98%E5%8C%96%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95%EF%BC%9A%E6%A0%B8%E5%BF%83%E6%80%9D%E8%B7%AF%E4%B8%8E%E5%AE%9E%E8%B7%B5/\",\"299\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Transformer%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97%E8%A7%A3%E6%9E%90%EF%BC%9AFFN%E3%80%81Add-_-LN-%E7%9A%84%E4%BD%9C%E7%94%A8%E4%B8%8E%E5%BA%94%E7%94%A8/#思考-延伸问题\",\"300\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/YaRN%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90%EF%BC%9A%E6%89%A9%E5%B1%95RoPE%E5%B5%8C%E5%85%A5%E4%B8%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E4%BC%98%E5%8C%96%E7%9A%84%E5%AE%9E%E8%B7%B5/#思考板块\",\"301\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E8%A7%A3%E7%A0%81%E9%87%87%E6%A0%B7%E7%AD%96%E7%95%A5%EF%BC%9AGreedy-Search%E4%B8%8EBeam-Search%E7%9A%84%E5%AE%9E%E7%8E%B0%E4%B8%8E%E4%BC%98%E5%8C%96/#greedy-search\",\"302\":\"/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/#学习资源-4\",\"303\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/KV-Cache%E6%8A%80%E6%9C%AF%E8%AF%A6%E8%A7%A3%EF%BC%9A%E4%BC%98%E5%8C%96Transformer%E8%87%AA%E5%9B%9E%E5%BD%92%E7%94%9F%E6%88%90%E6%95%88%E7%8E%87/#行动清单\",\"304\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Transformer%E4%B8%AD%E7%9A%84Attention%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#思考-板块\",\"305\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E4%BC%98%E5%8C%96Attention%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E5%BA%A6%E7%9A%84%E6%8A%80%E6%9C%AF%E6%8E%A2%E8%AE%A8/#数据表格\",\"306\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8EMHA%E5%88%B0MLA/#📈-趋势预测\",\"307\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/FFN%E3%80%81Add-_-LN-%E7%9A%84%E4%BD%9C%E7%94%A8%E4%B8%8E%E5%BA%94%E7%94%A8/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3%E4%B8%8E%E6%AF%94%E8%BE%83%EF%BC%9A%E4%BB%8ESigmoid%E5%88%B0Swish/#swish\",\"308\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/wordpiece/#wordpiece分词算法简介\",\"309\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E4%BB%8B%E7%BB%8D/#常见错误与警告\",\"310\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E3%80%90%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E3%80%91%E5%9F%BA%E4%BA%8EShifted-Sparse-Attention%E7%9A%84%E5%88%9B%E6%96%B0%E6%96%B9%E6%B3%95/#思考-🤔\",\"311\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E4%B8%8EFFN%E7%BB%93%E6%9E%84%E4%BC%98%E5%8C%96%EF%BC%9ASwiGLU%E3%80%81GeGLU%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E8%A7%A3%E6%9E%90/#行动清单\",\"312\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/NTK%E6%8F%92%E5%80%BC%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90%E4%B8%8E%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8ENTK-aware%E5%88%B0NTK-by-parts/#缺点-1\",\"313\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E4%BD%8D%E7%BD%AE%E5%86%85%E6%8F%92%E6%B3%95%E6%89%A9%E5%B1%95%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E9%95%BF%E5%BA%A6/#常见错误与警告\",\"314\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E6%95%B0%E5%AD%97%E8%BE%93%E5%85%A5%E4%BC%98%E5%8C%96%E4%B8%8E%E5%A4%96%E6%8E%A8%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90/#📈-趋势预测\",\"315\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E6%97%8B%E8%BD%AC%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8EALiBi%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%BD%8D%E7%BD%AE%E5%B5%8C%E5%85%A5%E4%BC%98%E5%8C%96/#_3-rope与alibi的对比\",\"316\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E4%B8%8E%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%EF%BC%88LLM-_-MoE%EF%BC%89%E8%A7%A3%E6%9E%90/#encoder-only-模型\",\"317\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E9%87%87%E6%A0%B7%E6%96%B9%E6%B3%95%EF%BC%9ATop-K%E3%80%81Top-P%E3%80%81Temperature%E5%8F%8A%E7%BB%BC%E5%90%88%E7%AD%96%E7%95%A5/#top-p-sampling\",\"318\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/BBPE%EF%BC%9A%E5%AD%97%E8%8A%82%E7%BA%A7%E5%88%AB%E7%9A%84BPE%E5%88%86%E8%AF%8D%E6%8A%80%E6%9C%AF%E8%A7%A3%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8/#bbpe的核心特点与优势\",\"319\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/BPE/#核心观点概述\",\"320\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E4%BD%BF%E7%94%A8Unigram%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88ULM%EF%BC%89%E4%BC%98%E5%8C%96%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95%EF%BC%9A%E6%A0%B8%E5%BF%83%E6%80%9D%E8%B7%AF%E4%B8%8E%E5%AE%9E%E8%B7%B5/#元数据\",\"321\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95%E7%9A%84%E6%AF%94%E8%BE%83/\",\"322\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/YaRN%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90%EF%BC%9A%E6%89%A9%E5%B1%95RoPE%E5%B5%8C%E5%85%A5%E4%B8%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E4%BC%98%E5%8C%96%E7%9A%84%E5%AE%9E%E8%B7%B5/#行动清单\",\"323\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E5%B8%B8%E7%94%A8%E5%88%86%E8%AF%8D%E5%BA%93/\",\"324\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E8%A7%A3%E7%A0%81%E9%87%87%E6%A0%B7%E7%AD%96%E7%95%A5%EF%BC%9AGreedy-Search%E4%B8%8EBeam-Search%E7%9A%84%E5%AE%9E%E7%8E%B0%E4%B8%8E%E4%BC%98%E5%8C%96/#beam-search\",\"325\":\"/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/#_6-数据集与实验设计\",\"326\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Transformer%E4%B8%AD%E7%9A%84Attention%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#作者观点-vs-个人观点对比\",\"327\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E4%BC%98%E5%8C%96Attention%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E5%BA%A6%E7%9A%84%E6%8A%80%E6%9C%AF%E6%8E%A2%E8%AE%A8/#后续追踪研究计划\",\"328\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6/\",\"329\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8EMHA%E5%88%B0MLA/#行动清单\",\"330\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/FFN%E3%80%81Add-_-LN-%E7%9A%84%E4%BD%9C%E7%94%A8%E4%B8%8E%E5%BA%94%E7%94%A8/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3%E4%B8%8E%E6%AF%94%E8%BE%83%EF%BC%9A%E4%BB%8ESigmoid%E5%88%B0Swish/#激活函数优缺点对比表\",\"331\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/wordpiece/#核心观点与实现步骤\",\"332\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E4%BB%8B%E7%BB%8D/#示例代码\",\"333\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E3%80%90%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E3%80%91%E5%9F%BA%E4%BA%8EShifted-Sparse-Attention%E7%9A%84%E5%88%9B%E6%96%B0%E6%96%B9%E6%B3%95/#延伸问题\",\"334\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E4%B8%8EFFN%E7%BB%93%E6%9E%84%E4%BC%98%E5%8C%96%EF%BC%9ASwiGLU%E3%80%81GeGLU%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E8%A7%A3%E6%9E%90/#后续追踪研究计划\",\"335\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/NTK%E6%8F%92%E5%80%BC%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90%E4%B8%8E%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8ENTK-aware%E5%88%B0NTK-by-parts/#常见错误与注意事项\",\"336\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E4%BD%8D%E7%BD%AE%E5%86%85%E6%8F%92%E6%B3%95%E6%89%A9%E5%B1%95%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E9%95%BF%E5%BA%A6/#💡启发点\",\"337\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E6%95%B0%E5%AD%97%E8%BE%93%E5%85%A5%E4%BC%98%E5%8C%96%E4%B8%8E%E5%A4%96%E6%8E%A8%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90/#思考-板块\",\"338\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E6%97%8B%E8%BD%AC%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8EALiBi%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%BD%8D%E7%BD%AE%E5%B5%8C%E5%85%A5%E4%BC%98%E5%8C%96/#常见错误\",\"339\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E4%B8%8E%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%EF%BC%88LLM-_-MoE%EF%BC%89%E8%A7%A3%E6%9E%90/#encoder-decoder-模型\",\"340\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E9%87%87%E6%A0%B7%E6%96%B9%E6%B3%95%EF%BC%9ATop-K%E3%80%81Top-P%E3%80%81Temperature%E5%8F%8A%E7%BB%BC%E5%90%88%E7%AD%96%E7%95%A5/#核心概念-1\",\"341\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/BBPE%EF%BC%9A%E5%AD%97%E8%8A%82%E7%BA%A7%E5%88%AB%E7%9A%84BPE%E5%88%86%E8%AF%8D%E6%8A%80%E6%9C%AF%E8%A7%A3%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8/#bbpe的局限性与挑战\",\"342\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/BPE/#重点内容提取\",\"343\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E4%BD%BF%E7%94%A8Unigram%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88ULM%EF%BC%89%E4%BC%98%E5%8C%96%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95%EF%BC%9A%E6%A0%B8%E5%BF%83%E6%80%9D%E8%B7%AF%E4%B8%8E%E5%AE%9E%E8%B7%B5/#核心观点总结\",\"344\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95%E7%9A%84%E6%AF%94%E8%BE%83/#元数据\",\"345\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E5%A4%9A%E6%A0%B7%E6%80%A7%E4%B8%8E%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E6%8E%A2%E7%B4%A2/\",\"346\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/YaRN%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90%EF%BC%9A%E6%89%A9%E5%B1%95RoPE%E5%B5%8C%E5%85%A5%E4%B8%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E4%BC%98%E5%8C%96%E7%9A%84%E5%AE%9E%E8%B7%B5/#数据表格示例\",\"347\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E5%B8%B8%E7%94%A8%E5%88%86%E8%AF%8D%E5%BA%93/#元数据\",\"348\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E8%A7%A3%E7%A0%81%E9%87%87%E6%A0%B7%E7%AD%96%E7%95%A5%EF%BC%9AGreedy-Search%E4%B8%8EBeam-Search%E7%9A%84%E5%AE%9E%E7%8E%B0%E4%B8%8E%E4%BC%98%E5%8C%96/#常见错误警告\",\"349\":\"/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/#需要学习的知识-5\",\"350\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Transformer%E4%B8%AD%E7%9A%84Attention%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#后续追踪研究计划\",\"351\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6/#推理机制概述\",\"352\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/\",\"353\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8EMHA%E5%88%B0MLA/#✅-工程实践建议\",\"354\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/FFN%E3%80%81Add-_-LN-%E7%9A%84%E4%BD%9C%E7%94%A8%E4%B8%8E%E5%BA%94%E7%94%A8/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3%E4%B8%8E%E6%AF%94%E8%BE%83%EF%BC%9A%E4%BB%8ESigmoid%E5%88%B0Swish/#常见错误与警示区块\",\"355\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/wordpiece/#wordpiece的核心思想\",\"356\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E4%BB%8B%E7%BB%8D/#思考-延伸问题\",\"357\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E7%88%AC%E5%8F%96/\",\"358\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E3%80%90%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E3%80%91%E5%9F%BA%E4%BA%8EShifted-Sparse-Attention%E7%9A%84%E5%88%9B%E6%96%B0%E6%96%B9%E6%B3%95/#来源标注\",\"359\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/NTK%E6%8F%92%E5%80%BC%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90%E4%B8%8E%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8ENTK-aware%E5%88%B0NTK-by-parts/#操作步骤-如何应用ntk-aware和ntk-by-parts插值\",\"360\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E4%BD%8D%E7%BD%AE%E5%86%85%E6%8F%92%E6%B3%95%E6%89%A9%E5%B1%95%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E9%95%BF%E5%BA%A6/#📈趋势预测\",\"361\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E6%95%B0%E5%AD%97%E8%BE%93%E5%85%A5%E4%BC%98%E5%8C%96%E4%B8%8E%E5%A4%96%E6%8E%A8%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90/#行动清单\",\"362\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E6%97%8B%E8%BD%AC%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8EALiBi%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%BD%8D%E7%BD%AE%E5%B5%8C%E5%85%A5%E4%BC%98%E5%8C%96/#思考\",\"363\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E4%B8%8E%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%EF%BC%88LLM-_-MoE%EF%BC%89%E8%A7%A3%E6%9E%90/#prefix-lm-前缀语言模型\",\"364\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E9%87%87%E6%A0%B7%E6%96%B9%E6%B3%95%EF%BC%9ATop-K%E3%80%81Top-P%E3%80%81Temperature%E5%8F%8A%E7%BB%BC%E5%90%88%E7%AD%96%E7%95%A5/#代码实现\",\"365\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/BBPE%EF%BC%9A%E5%AD%97%E8%8A%82%E7%BA%A7%E5%88%AB%E7%9A%84BPE%E5%88%86%E8%AF%8D%E6%8A%80%E6%9C%AF%E8%A7%A3%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8/#bbpe与bpe的对比\",\"366\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/BPE/#bpe的核心思想\",\"367\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E4%BD%BF%E7%94%A8Unigram%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88ULM%EF%BC%89%E4%BC%98%E5%8C%96%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95%EF%BC%9A%E6%A0%B8%E5%BF%83%E6%80%9D%E8%B7%AF%E4%B8%8E%E5%AE%9E%E8%B7%B5/#重点内容解析\",\"368\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95%E7%9A%84%E6%AF%94%E8%BE%83/#_1️⃣-核心观点总结\",\"369\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E5%A4%9A%E6%A0%B7%E6%80%A7%E4%B8%8E%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E6%8E%A2%E7%B4%A2/#数据多样性的核心价值\",\"370\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E9%85%8D%E6%AF%94%E4%B8%8E%E8%AE%AD%E7%BB%83%E9%A1%BA%E5%BA%8F%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97/\",\"371\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%A8%A1%E5%9E%8B%E6%89%93%E5%88%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%8E%BB%E9%87%8D/\",\"372\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/YaRN%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90%EF%BC%9A%E6%89%A9%E5%B1%95RoPE%E5%B5%8C%E5%85%A5%E4%B8%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E4%BC%98%E5%8C%96%E7%9A%84%E5%AE%9E%E8%B7%B5/#后续追踪\",\"373\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E5%B8%B8%E7%94%A8%E5%88%86%E8%AF%8D%E5%BA%93/#核心内容总结\",\"374\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E8%A7%A3%E7%A0%81%E9%87%87%E6%A0%B7%E7%AD%96%E7%95%A5%EF%BC%9AGreedy-Search%E4%B8%8EBeam-Search%E7%9A%84%E5%AE%9E%E7%8E%B0%E4%B8%8E%E4%BC%98%E5%8C%96/#数据与公式\",\"375\":\"/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/#学习资源-5\",\"376\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6/#关键瓶颈\",\"377\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/#元数据\",\"378\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8EMHA%E5%88%B0MLA/#⚠️-常见错误\",\"379\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%98%BE%E5%AD%98%E4%BC%98%E5%8C%96%E4%B8%8E%E6%A2%AF%E5%BA%A6%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/\",\"380\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/FFN%E3%80%81Add-_-LN-%E7%9A%84%E4%BD%9C%E7%94%A8%E4%B8%8E%E5%BA%94%E7%94%A8/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3%E4%B8%8E%E6%AF%94%E8%BE%83%EF%BC%9A%E4%BB%8ESigmoid%E5%88%B0Swish/#行动清单\",\"381\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/wordpiece/#wordpiece的实现步骤\",\"382\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%E8%AE%AD%E7%BB%83/\",\"383\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E4%BB%8B%E7%BB%8D/#行动清单\",\"384\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E7%88%AC%E5%8F%96/#元数据\",\"385\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E3%80%90%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E3%80%91%E5%9F%BA%E4%BA%8EShifted-Sparse-Attention%E7%9A%84%E5%88%9B%E6%96%B0%E6%96%B9%E6%B3%95/#后续追踪-📈\",\"386\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/NTK%E6%8F%92%E5%80%BC%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90%E4%B8%8E%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8ENTK-aware%E5%88%B0NTK-by-parts/#💡启发点\",\"387\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E4%BD%8D%E7%BD%AE%E5%86%85%E6%8F%92%E6%B3%95%E6%89%A9%E5%B1%95%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E9%95%BF%E5%BA%A6/#行动清单\",\"388\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E6%97%8B%E8%BD%AC%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8EALiBi%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%BD%8D%E7%BD%AE%E5%B5%8C%E5%85%A5%E4%BC%98%E5%8C%96/#行动清单\",\"389\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E4%B8%8E%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%EF%BC%88LLM-_-MoE%EF%BC%89%E8%A7%A3%E6%9E%90/#混合专家-moe-架构\",\"390\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E9%87%87%E6%A0%B7%E6%96%B9%E6%B3%95%EF%BC%9ATop-K%E3%80%81Top-P%E3%80%81Temperature%E5%8F%8A%E7%BB%BC%E5%90%88%E7%AD%96%E7%95%A5/#temperature-sampling\",\"391\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/BBPE%EF%BC%9A%E5%AD%97%E8%8A%82%E7%BA%A7%E5%88%AB%E7%9A%84BPE%E5%88%86%E8%AF%8D%E6%8A%80%E6%9C%AF%E8%A7%A3%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8/#bbpe代码实现示例\",\"392\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/BPE/#bpe的操作步骤\",\"393\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E4%BD%BF%E7%94%A8Unigram%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88ULM%EF%BC%89%E4%BC%98%E5%8C%96%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95%EF%BC%9A%E6%A0%B8%E5%BF%83%E6%80%9D%E8%B7%AF%E4%B8%8E%E5%AE%9E%E8%B7%B5/#_1-ulm的核心思路\",\"394\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95%E7%9A%84%E6%AF%94%E8%BE%83/#_2️⃣-重点内容解析\",\"395\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E5%A4%9A%E6%A0%B7%E6%80%A7%E4%B8%8E%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E6%8E%A2%E7%B4%A2/#核心数据筛选方法\",\"396\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E9%85%8D%E6%AF%94%E4%B8%8E%E8%AE%AD%E7%BB%83%E9%A1%BA%E5%BA%8F%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97/#元数据\",\"397\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E7%BB%A7%E7%BB%AD%E9%A2%84%E8%AE%AD%E7%BB%83/\",\"398\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%A8%A1%E5%9E%8B%E6%89%93%E5%88%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%8E%BB%E9%87%8D/#元数据\",\"399\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E5%B8%B8%E7%94%A8%E5%88%86%E8%AF%8D%E5%BA%93/#重点内容\",\"400\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E8%A7%A3%E7%A0%81%E9%87%87%E6%A0%B7%E7%AD%96%E7%95%A5%EF%BC%9AGreedy-Search%E4%B8%8EBeam-Search%E7%9A%84%E5%AE%9E%E7%8E%B0%E4%B8%8E%E4%BC%98%E5%8C%96/#数据表格示例\",\"401\":\"/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/#_7-论文写作与学术规范\",\"402\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6/#时延计算\",\"403\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/#核心观点总结\",\"404\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8EMHA%E5%88%B0MLA/#💡-启发点\",\"405\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%98%BE%E5%AD%98%E4%BC%98%E5%8C%96%E4%B8%8E%E6%A2%AF%E5%BA%A6%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/#元数据\",\"406\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/FFN%E3%80%81Add-_-LN-%E7%9A%84%E4%BD%9C%E7%94%A8%E4%B8%8E%E5%BA%94%E7%94%A8/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3%E4%B8%8E%E6%AF%94%E8%BE%83%EF%BC%9A%E4%BB%8ESigmoid%E5%88%B0Swish/#思考与启发\",\"407\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/wordpiece/#实现代码片段\",\"408\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%E8%AE%AD%E7%BB%83/#什么是混合精度训练\",\"409\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E4%BB%8B%E7%BB%8D/#后续追踪\",\"410\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E8%AE%AD%E7%BB%83%E5%AE%B9%E7%81%BE%E5%8F%8A%E8%AE%AD%E7%BB%83%E7%9B%91%E6%8E%A7/\",\"411\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E7%88%AC%E5%8F%96/#核心观点总结\",\"412\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/NTK%E6%8F%92%E5%80%BC%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90%E4%B8%8E%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8ENTK-aware%E5%88%B0NTK-by-parts/#📈趋势预测\",\"413\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E4%BD%8D%E7%BD%AE%E5%86%85%E6%8F%92%E6%B3%95%E6%89%A9%E5%B1%95%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E9%95%BF%E5%BA%A6/#思考-板块\",\"414\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E6%97%8B%E8%BD%AC%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8EALiBi%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%BD%8D%E7%BD%AE%E5%B5%8C%E5%85%A5%E4%BC%98%E5%8C%96/#后续追踪\",\"415\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E4%B8%8E%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%EF%BC%88LLM-_-MoE%EF%BC%89%E8%A7%A3%E6%9E%90/#什么是-moe\",\"416\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E9%87%87%E6%A0%B7%E6%96%B9%E6%B3%95%EF%BC%9ATop-K%E3%80%81Top-P%E3%80%81Temperature%E5%8F%8A%E7%BB%BC%E5%90%88%E7%AD%96%E7%95%A5/#核心概念-2\",\"417\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/BBPE%EF%BC%9A%E5%AD%97%E8%8A%82%E7%BA%A7%E5%88%AB%E7%9A%84BPE%E5%88%86%E8%AF%8D%E6%8A%80%E6%9C%AF%E8%A7%A3%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8/#常见错误提示\",\"418\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/BPE/#示例-从语料库中生成子词表\",\"419\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E4%BD%BF%E7%94%A8Unigram%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88ULM%EF%BC%89%E4%BC%98%E5%8C%96%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95%EF%BC%9A%E6%A0%B8%E5%BF%83%E6%80%9D%E8%B7%AF%E4%B8%8E%E5%AE%9E%E8%B7%B5/#_2-ulm的优势与挑战\",\"420\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95%E7%9A%84%E6%AF%94%E8%BE%83/#💡-wordpiece与bpe的对比\",\"421\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E5%A4%9A%E6%A0%B7%E6%80%A7%E4%B8%8E%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E6%8E%A2%E7%B4%A2/#方法1-基于k-means聚类的多样性采样\",\"422\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E9%85%8D%E6%AF%94%E4%B8%8E%E8%AE%AD%E7%BB%83%E9%A1%BA%E5%BA%8F%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97/#核心观点总结\",\"423\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E7%BB%A7%E7%BB%AD%E9%A2%84%E8%AE%AD%E7%BB%83/#核心观点总结\",\"424\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90/\",\"425\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%A8%A1%E5%9E%8B%E6%89%93%E5%88%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%8E%BB%E9%87%8D/#核心观点总结\",\"426\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E5%B8%B8%E7%94%A8%E5%88%86%E8%AF%8D%E5%BA%93/#_1-sentencepiece-的核心特点\",\"427\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E8%A7%A3%E7%A0%81%E9%87%87%E6%A0%B7%E7%AD%96%E7%95%A5%EF%BC%9AGreedy-Search%E4%B8%8EBeam-Search%E7%9A%84%E5%AE%9E%E7%8E%B0%E4%B8%8E%E4%BC%98%E5%8C%96/#公式示例\",\"428\":\"/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/#需要学习的知识-6\",\"429\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6/#数据量分析\",\"430\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/#重点内容提取\",\"431\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%84%E4%BC%B0/\",\"432\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8EMHA%E5%88%B0MLA/#思考-板块\",\"433\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%98%BE%E5%AD%98%E4%BC%98%E5%8C%96%E4%B8%8E%E6%A2%AF%E5%BA%A6%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/#核心内容总结\",\"434\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/wordpiece/#优缺点分析\",\"435\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%E8%AE%AD%E7%BB%83/#混合精度训练的核心流程\",\"436\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%84%E4%BC%B02/\",\"437\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E8%AE%AD%E7%BB%83%E5%AE%B9%E7%81%BE%E5%8F%8A%E8%AE%AD%E7%BB%83%E7%9B%91%E6%8E%A7/#元数据\",\"438\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E7%88%AC%E5%8F%96/#重点内容解析\",\"439\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/NTK%E6%8F%92%E5%80%BC%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90%E4%B8%8E%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8ENTK-aware%E5%88%B0NTK-by-parts/#行动清单\",\"440\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E4%B8%8E%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%EF%BC%88LLM-_-MoE%EF%BC%89%E8%A7%A3%E6%9E%90/#构成要素\",\"441\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E9%87%87%E6%A0%B7%E6%96%B9%E6%B3%95%EF%BC%9ATop-K%E3%80%81Top-P%E3%80%81Temperature%E5%8F%8A%E7%BB%BC%E5%90%88%E7%AD%96%E7%95%A5/#综合采样策略-kpt\",\"442\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/BBPE%EF%BC%9A%E5%AD%97%E8%8A%82%E7%BA%A7%E5%88%AB%E7%9A%84BPE%E5%88%86%E8%AF%8D%E6%8A%80%E6%9C%AF%E8%A7%A3%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8/#行动清单\",\"443\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/BPE/#初始语料库-带频次\",\"444\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E4%BD%BF%E7%94%A8Unigram%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88ULM%EF%BC%89%E4%BC%98%E5%8C%96%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95%EF%BC%9A%E6%A0%B8%E5%BF%83%E6%80%9D%E8%B7%AF%E4%B8%8E%E5%AE%9E%E8%B7%B5/#_3-ulm操作流程示例\",\"445\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95%E7%9A%84%E6%AF%94%E8%BE%83/#💡-wordpiece与ulm的对比\",\"446\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E5%A4%9A%E6%A0%B7%E6%80%A7%E4%B8%8E%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E6%8E%A2%E7%B4%A2/#方法2-加权采样-基于聚类簇的多样性权重和质量权重\",\"447\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E9%85%8D%E6%AF%94%E4%B8%8E%E8%AE%AD%E7%BB%83%E9%A1%BA%E5%BA%8F%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97/#重点内容提取\",\"448\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E7%BB%A7%E7%BB%AD%E9%A2%84%E8%AE%AD%E7%BB%83/#重点内容\",\"449\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90/#核心观点总结\",\"450\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/\",\"451\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%A8%A1%E5%9E%8B%E6%89%93%E5%88%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%8E%BB%E9%87%8D/#数据质量评估与打分\",\"452\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E5%B8%B8%E7%94%A8%E5%88%86%E8%AF%8D%E5%BA%93/#_2-tokenizers库的编码流程\",\"453\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E8%A7%A3%E7%A0%81%E9%87%87%E6%A0%B7%E7%AD%96%E7%95%A5%EF%BC%9AGreedy-Search%E4%B8%8EBeam-Search%E7%9A%84%E5%AE%9E%E7%8E%B0%E4%B8%8E%E4%BC%98%E5%8C%96/#思考-延伸问题\",\"454\":\"/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/#学习资源-6\",\"455\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6/#kv-cache读取\",\"456\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/#url-过滤\",\"457\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%84%E4%BC%B0/#预训练评估的核心观点\",\"458\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/Actor-Critic%E7%AE%97%E6%B3%95/\",\"459\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%98%BE%E5%AD%98%E4%BC%98%E5%8C%96%E4%B8%8E%E6%A2%AF%E5%BA%A6%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/#主要内容\",\"460\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E7%AE%97%E6%B3%95/\",\"461\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/wordpiece/#常见错误与注意事项\",\"462\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%E8%AE%AD%E7%BB%83/#混合精度训练的优势\",\"463\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%84%E4%BC%B02/#大海捞针测试\",\"464\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E8%AE%AD%E7%BB%83%E5%AE%B9%E7%81%BE%E5%8F%8A%E8%AE%AD%E7%BB%83%E7%9B%91%E6%8E%A7/#核心观点总结\",\"465\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E7%88%AC%E5%8F%96/#✅-高质量pdf数据解析方法\",\"466\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/NTK%E6%8F%92%E5%80%BC%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90%E4%B8%8E%E4%BC%98%E5%8C%96%EF%BC%9A%E4%BB%8ENTK-aware%E5%88%B0NTK-by-parts/#思考-板块\",\"467\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E4%B8%8E%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%EF%BC%88LLM-_-MoE%EF%BC%89%E8%A7%A3%E6%9E%90/#放置位置\",\"468\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E9%87%87%E6%A0%B7%E6%96%B9%E6%B3%95%EF%BC%9ATop-K%E3%80%81Top-P%E3%80%81Temperature%E5%8F%8A%E7%BB%BC%E5%90%88%E7%AD%96%E7%95%A5/#核心概念-3\",\"469\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/BBPE%EF%BC%9A%E5%AD%97%E8%8A%82%E7%BA%A7%E5%88%AB%E7%9A%84BPE%E5%88%86%E8%AF%8D%E6%8A%80%E6%9C%AF%E8%A7%A3%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8/#思考-板块\",\"470\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/BPE/#基础字符频次统计\",\"471\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E4%BD%BF%E7%94%A8Unigram%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88ULM%EF%BC%89%E4%BC%98%E5%8C%96%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95%EF%BC%9A%E6%A0%B8%E5%BF%83%E6%80%9D%E8%B7%AF%E4%B8%8E%E5%AE%9E%E8%B7%B5/#_4-数据与趋势📈\",\"472\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95%E7%9A%84%E6%AF%94%E8%BE%83/#⚠️-常见错误\",\"473\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E5%A4%9A%E6%A0%B7%E6%80%A7%E4%B8%8E%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E6%8E%A2%E7%B4%A2/#方法3-基于knn聚类的权重采样\",\"474\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E9%85%8D%E6%AF%94%E4%B8%8E%E8%AE%AD%E7%BB%83%E9%A1%BA%E5%BA%8F%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97/#数据分类与配比方法\",\"475\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E7%BB%A7%E7%BB%AD%E9%A2%84%E8%AE%AD%E7%BB%83/#_1-什么是继续预训练\",\"476\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90/#重点内容解析\",\"477\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#icl概念原理\",\"478\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E8%AE%AD%E7%BB%83%E7%9A%84trick%E5%92%8C%E9%97%AE%E9%A2%98/\",\"479\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%A8%A1%E5%9E%8B%E6%89%93%E5%88%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%8E%BB%E9%87%8D/#✅-模型打分器的选择\",\"480\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E5%B8%B8%E7%94%A8%E5%88%86%E8%AF%8D%E5%BA%93/#✅-normalization-标准化\",\"481\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E8%A7%A3%E7%A0%81%E9%87%87%E6%A0%B7%E7%AD%96%E7%95%A5%EF%BC%9AGreedy-Search%E4%B8%8EBeam-Search%E7%9A%84%E5%AE%9E%E7%8E%B0%E4%B8%8E%E4%BC%98%E5%8C%96/#行动清单\",\"482\":\"/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/#_8-实践与项目\",\"483\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6/#计算时延\",\"484\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RL%E5%9C%A8NLP%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E6%8B%93%E5%B1%95/\",\"485\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/#内容提取\",\"486\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%84%E4%BC%B0/#重点内容\",\"487\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/Actor-Critic%E7%AE%97%E6%B3%95/#元数据\",\"488\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%98%BE%E5%AD%98%E4%BC%98%E5%8C%96%E4%B8%8E%E6%A2%AF%E5%BA%A6%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/#显存占用与数据类型的影响\",\"489\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E7%AE%97%E6%B3%95/#元数据\",\"490\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/wordpiece/#思考与延伸问题\",\"491\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%E8%AE%AD%E7%BB%83/#常见问题与解决方法\",\"492\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%84%E4%BC%B02/#核心观点\",\"493\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E8%AE%AD%E7%BB%83%E5%AE%B9%E7%81%BE%E5%8F%8A%E8%AE%AD%E7%BB%83%E7%9B%91%E6%8E%A7/#核心内容解析\",\"494\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E7%88%AC%E5%8F%96/#✅-爬虫分类与实现方式\",\"495\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E4%B8%8E%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%EF%BC%88LLM-_-MoE%EF%BC%89%E8%A7%A3%E6%9E%90/#应用场景\",\"496\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E9%87%87%E6%A0%B7%E6%96%B9%E6%B3%95%EF%BC%9ATop-K%E3%80%81Top-P%E3%80%81Temperature%E5%8F%8A%E7%BB%BC%E5%90%88%E7%AD%96%E7%95%A5/#多答案选择策略\",\"497\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/BPE/#第一次迭代-合并频率最高的字符对\",\"498\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E4%BD%BF%E7%94%A8Unigram%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88ULM%EF%BC%89%E4%BC%98%E5%8C%96%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95%EF%BC%9A%E6%A0%B8%E5%BF%83%E6%80%9D%E8%B7%AF%E4%B8%8E%E5%AE%9E%E8%B7%B5/#_5-常见错误⚠️\",\"499\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95%E7%9A%84%E6%AF%94%E8%BE%83/#_3️⃣-技术术语通俗解读\",\"500\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E5%A4%9A%E6%A0%B7%E6%80%A7%E4%B8%8E%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E6%8E%A2%E7%B4%A2/#垂域数据扩充流程\",\"501\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E9%85%8D%E6%AF%94%E4%B8%8E%E8%AE%AD%E7%BB%83%E9%A1%BA%E5%BA%8F%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97/#领域数据的使用策略\",\"502\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E7%BB%A7%E7%BB%AD%E9%A2%84%E8%AE%AD%E7%BB%83/#_2-长文本预训练的技术细节\",\"503\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90/#_1-预训练的定义与目标\",\"504\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#核心概念\",\"505\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E8%AE%AD%E7%BB%83%E7%9A%84trick%E5%92%8C%E9%97%AE%E9%A2%98/#ppo训练中的关键技巧\",\"506\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/SARSA-%CE%BB%E4%B8%8EQ-learning%E5%AF%B9%E6%AF%94/\",\"507\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%A8%A1%E5%9E%8B%E6%89%93%E5%88%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%8E%BB%E9%87%8D/#⚠-训练打分器的注意事项\",\"508\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E5%B8%B8%E7%94%A8%E5%88%86%E8%AF%8D%E5%BA%93/#⚠️-pre-tokenization-预分词\",\"509\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/SARSA%E7%AE%97%E6%B3%95/\",\"510\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E8%A7%A3%E7%A0%81%E9%87%87%E6%A0%B7%E7%AD%96%E7%95%A5%EF%BC%9AGreedy-Search%E4%B8%8EBeam-Search%E7%9A%84%E5%AE%9E%E7%8E%B0%E4%B8%8E%E4%BC%98%E5%8C%96/#后续追踪\",\"511\":\"/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/#需要学习的知识-7\",\"512\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BB%B7%E5%80%BC%E8%BF%AD%E4%BB%A3%E7%AE%97%E6%B3%95/\",\"513\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6/#公式总结\",\"514\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RL%E5%9C%A8NLP%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E6%8B%93%E5%B1%95/#核心观点总结\",\"515\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/#语言识别\",\"516\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%84%E4%BC%B0/#困惑度-ppl-测量\",\"517\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%88%86%E7%B1%BB/\",\"518\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/Actor-Critic%E7%AE%97%E6%B3%95/#核心观点总结\",\"519\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%8B%AC%E7%89%B9%E6%80%A7/\",\"520\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%98%BE%E5%AD%98%E4%BC%98%E5%8C%96%E4%B8%8E%E6%A2%AF%E5%BA%A6%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/#loss-scale-的两种策略\",\"521\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E7%AE%97%E6%B3%95/#核心观点\",\"522\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/wordpiece/#行动清单\",\"523\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%E8%AE%AD%E7%BB%83/#⚠-舍入误差\",\"524\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%84%E4%BC%B02/#重点段落\",\"525\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E8%AE%AD%E7%BB%83%E5%AE%B9%E7%81%BE%E5%8F%8A%E8%AE%AD%E7%BB%83%E7%9B%91%E6%8E%A7/#监控-loss-和-spike\",\"526\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E7%88%AC%E5%8F%96/#⚙-基本配置建议-代码片段\",\"527\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E4%B8%8E%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%EF%BC%88LLM-_-MoE%EF%BC%89%E8%A7%A3%E6%9E%90/#常见错误\",\"528\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E9%87%87%E6%A0%B7%E6%96%B9%E6%B3%95%EF%BC%9ATop-K%E3%80%81Top-P%E3%80%81Temperature%E5%8F%8A%E7%BB%BC%E5%90%88%E7%AD%96%E7%95%A5/#best-of-n\",\"529\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/BPE/#优缺点分析\",\"530\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E4%BD%BF%E7%94%A8Unigram%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88ULM%EF%BC%89%E4%BC%98%E5%8C%96%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95%EF%BC%9A%E6%A0%B8%E5%BF%83%E6%80%9D%E8%B7%AF%E4%B8%8E%E5%AE%9E%E8%B7%B5/#行动清单\",\"531\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95%E7%9A%84%E6%AF%94%E8%BE%83/#_4️⃣-行动清单\",\"532\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E5%A4%9A%E6%A0%B7%E6%80%A7%E4%B8%8E%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E6%8E%A2%E7%B4%A2/#数据处理与筛选流程\",\"533\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E9%85%8D%E6%AF%94%E4%B8%8E%E8%AE%AD%E7%BB%83%E9%A1%BA%E5%BA%8F%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97/#数据训练顺序与课程学习\",\"534\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E7%BB%A7%E7%BB%AD%E9%A2%84%E8%AE%AD%E7%BB%83/#_3-数据与采样\",\"535\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90/#_2-预训练数据的来源与规模\",\"536\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#上下文依赖\",\"537\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E8%AE%AD%E7%BB%83%E7%9A%84trick%E5%92%8C%E9%97%AE%E9%A2%98/#token-level-kl-penalty\",\"538\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/SARSA-%CE%BB%E4%B8%8EQ-learning%E5%AF%B9%E6%AF%94/#分类\",\"539\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E9%97%AE%E9%A2%98_%E6%B5%81%E7%A8%8B/\",\"540\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E6%97%B6%E5%BA%8F%E5%B7%AE%E5%88%86%E7%AE%97%E6%B3%95/\",\"541\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%A8%A1%E5%9E%8B%E6%89%93%E5%88%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%8E%BB%E9%87%8D/#数据去重的三大类别\",\"542\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E5%B8%B8%E7%94%A8%E5%88%86%E8%AF%8D%E5%BA%93/#❗️-模型分词与后处理\",\"543\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/SARSA%E7%AE%97%E6%B3%95/#元数据\",\"544\":\"/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/#学习资源-7\",\"545\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BB%B7%E5%80%BC%E8%BF%AD%E4%BB%A3%E7%AE%97%E6%B3%95/#元数据\",\"546\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6/#常见错误\",\"547\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RL%E5%9C%A8NLP%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E6%8B%93%E5%B1%95/#重点段落\",\"548\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/#低质内容过滤\",\"549\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%84%E4%BC%B0/#benchmark评估\",\"550\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%88%86%E7%B1%BB/#元数据\",\"551\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/Actor-Critic%E7%AE%97%E6%B3%95/#重点内容\",\"552\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%8B%AC%E7%89%B9%E6%80%A7/#元数据\",\"553\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%98%BE%E5%AD%98%E4%BC%98%E5%8C%96%E4%B8%8E%E6%A2%AF%E5%BA%A6%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/#_1-常量损失放大\",\"554\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E7%AE%97%E6%B3%95/#重点段落\",\"555\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/wordpiece/#后续追踪计划\",\"556\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%E8%AE%AD%E7%BB%83/#⚠-梯度下溢\",\"557\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%84%E4%BC%B02/#概率探针\",\"558\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E8%AE%AD%E7%BB%83%E5%AE%B9%E7%81%BE%E5%8F%8A%E8%AE%AD%E7%BB%83%E7%9B%91%E6%8E%A7/#困惑度-perplexity-分析\",\"559\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E7%88%AC%E5%8F%96/#📋-指定平台爬虫id列表示例\",\"560\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E4%B8%8E%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%EF%BC%88LLM-_-MoE%EF%BC%89%E8%A7%A3%E6%9E%90/#操作步骤\",\"561\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E9%87%87%E6%A0%B7%E6%96%B9%E6%B3%95%EF%BC%9ATop-K%E3%80%81Top-P%E3%80%81Temperature%E5%8F%8A%E7%BB%BC%E5%90%88%E7%AD%96%E7%95%A5/#majority-vote\",\"562\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/BPE/#常见错误与注意事项\",\"563\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E4%BD%BF%E7%94%A8Unigram%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88ULM%EF%BC%89%E4%BC%98%E5%8C%96%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95%EF%BC%9A%E6%A0%B8%E5%BF%83%E6%80%9D%E8%B7%AF%E4%B8%8E%E5%AE%9E%E8%B7%B5/#思考-延伸问题\",\"564\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95%E7%9A%84%E6%AF%94%E8%BE%83/#思考-板块\",\"565\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E5%A4%9A%E6%A0%B7%E6%80%A7%E4%B8%8E%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E6%8E%A2%E7%B4%A2/#常见错误与注意事项\",\"566\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E9%85%8D%E6%AF%94%E4%B8%8E%E8%AE%AD%E7%BB%83%E9%A1%BA%E5%BA%8F%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97/#警告区块\",\"567\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E7%BB%A7%E7%BB%AD%E9%A2%84%E8%AE%AD%E7%BB%83/#_4-主要步骤\",\"568\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90/#_3-数据处理的挑战\",\"569\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#无参数更新\",\"570\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E8%AE%AD%E7%BB%83%E7%9A%84trick%E5%92%8C%E9%97%AE%E9%A2%98/#generalized-advantage-estimation-gae\",\"571\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/SARSA-%CE%BB%E4%B8%8EQ-learning%E5%AF%B9%E6%AF%94/#标签\",\"572\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E9%97%AE%E9%A2%98_%E6%B5%81%E7%A8%8B/#强化学习问题与流程\",\"573\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E6%B7%B1%E5%BA%A6Q%E7%BD%91%E7%BB%9C/\",\"574\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E6%97%B6%E5%BA%8F%E5%B7%AE%E5%88%86%E7%AE%97%E6%B3%95/#核心观点\",\"575\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%A8%A1%E5%9E%8B%E6%89%93%E5%88%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%8E%BB%E9%87%8D/#❗-数据重复类型\",\"576\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E5%B8%B8%E7%94%A8%E5%88%86%E8%AF%8D%E5%BA%93/#_3-常见错误与注意事项\",\"577\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/SARSA%E7%AE%97%E6%B3%95/#内容概述\",\"578\":\"/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/#总结\",\"579\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BB%B7%E5%80%BC%E8%BF%AD%E4%BB%A3%E7%AE%97%E6%B3%95/#内容处理\",\"580\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6/#💡启发点\",\"581\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RL%E5%9C%A8NLP%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E6%8B%93%E5%B1%95/#nlp中的mdp建模\",\"582\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/#常见错误警告\",\"583\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%84%E4%BC%B0/#技术术语解释\",\"584\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AD%96%E7%95%A5%E6%A2%AF%E5%BA%A6%E7%AE%97%E6%B3%95/\",\"585\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%88%86%E7%B1%BB/#内容概要\",\"586\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/Actor-Critic%E7%AE%97%E6%B3%95/#策略梯度与q值函数\",\"587\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%8B%AC%E7%89%B9%E6%80%A7/#核心观点总结\",\"588\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AD%96%E7%95%A5%E8%BF%AD%E4%BB%A3%E7%AE%97%E6%B3%95/\",\"589\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%98%BE%E5%AD%98%E4%BC%98%E5%8C%96%E4%B8%8E%E6%A2%AF%E5%BA%A6%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/#_2-动量损失放大\",\"590\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E7%AE%97%E6%B3%95/#ppo算法的基本原理\",\"591\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%E8%AE%AD%E7%BB%83/#数据支持\",\"592\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%84%E4%BC%B02/#核心观点-1\",\"593\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E8%AE%AD%E7%BB%83%E5%AE%B9%E7%81%BE%E5%8F%8A%E8%AE%AD%E7%BB%83%E7%9B%91%E6%8E%A7/#解决-loss-spike-的方法\",\"594\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E7%88%AC%E5%8F%96/#常见错误警告-⚠️\",\"595\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E4%B8%8E%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%EF%BC%88LLM-_-MoE%EF%BC%89%E8%A7%A3%E6%9E%90/#数据表格示例\",\"596\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E9%87%87%E6%A0%B7%E6%96%B9%E6%B3%95%EF%BC%9ATop-K%E3%80%81Top-P%E3%80%81Temperature%E5%8F%8A%E7%BB%BC%E5%90%88%E7%AD%96%E7%95%A5/#self-consistency\",\"597\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/BPE/#行动清单\",\"598\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E5%A4%9A%E6%A0%B7%E6%80%A7%E4%B8%8E%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E6%8E%A2%E7%B4%A2/#📈-未来趋势预测\",\"599\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E9%85%8D%E6%AF%94%E4%B8%8E%E8%AE%AD%E7%BB%83%E9%A1%BA%E5%BA%8F%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97/#行动清单\",\"600\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E7%BB%A7%E7%BB%AD%E9%A2%84%E8%AE%AD%E7%BB%83/#常见错误\",\"601\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90/#常见错误与注意事项\",\"602\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#动态适应\",\"603\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E8%AE%AD%E7%BB%83%E7%9A%84trick%E5%92%8C%E9%97%AE%E9%A2%98/#adding-sft-loss\",\"604\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/SARSA-%CE%BB%E4%B8%8EQ-learning%E5%AF%B9%E6%AF%94/#日期\",\"605\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E9%97%AE%E9%A2%98_%E6%B5%81%E7%A8%8B/#应用场景\",\"606\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E6%B7%B1%E5%BA%A6Q%E7%BD%91%E7%BB%9C/#dqn简介\",\"607\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%96%B9%E6%B3%95/\",\"608\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E6%97%B6%E5%BA%8F%E5%B7%AE%E5%88%86%E7%AE%97%E6%B3%95/#重点段落\",\"609\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%A8%A1%E5%9E%8B%E6%89%93%E5%88%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%8E%BB%E9%87%8D/#数据去重流程\",\"610\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E5%B8%B8%E7%94%A8%E5%88%86%E8%AF%8D%E5%BA%93/#作者观点-vs-个人观点\",\"611\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/SARSA%E7%AE%97%E6%B3%95/#核心观点\",\"612\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BB%B7%E5%80%BC%E8%BF%AD%E4%BB%A3%E7%AE%97%E6%B3%95/#核心观点\",\"613\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6/#行动清单\",\"614\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RL%E5%9C%A8NLP%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E6%8B%93%E5%B1%95/#强化学习优化目标\",\"615\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/#行动清单\",\"616\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%84%E4%BC%B0/#思考\",\"617\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AD%96%E7%95%A5%E6%A2%AF%E5%BA%A6%E7%AE%97%E6%B3%95/#元数据\",\"618\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%88%86%E7%B1%BB/#以数据来源划分\",\"619\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/Actor-Critic%E7%AE%97%E6%B3%95/#actor-critic算法简介\",\"620\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%8B%AC%E7%89%B9%E6%80%A7/#重点内容提取\",\"621\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AD%96%E7%95%A5%E8%BF%AD%E4%BB%A3%E7%AE%97%E6%B3%95/#核心观点总结\",\"622\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%98%BE%E5%AD%98%E4%BC%98%E5%8C%96%E4%B8%8E%E6%A2%AF%E5%BA%A6%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/#梯度裁剪-clip-gradients\",\"623\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E7%AE%97%E6%B3%95/#重要性采样技术\",\"624\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E8%B4%9D%E5%B0%94%E6%9B%BC%E6%96%B9%E7%A8%8B/\",\"625\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%E8%AE%AD%E7%BB%83/#💡启发点\",\"626\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%84%E4%BC%B02/#重点段落-1\",\"627\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E8%AE%AD%E7%BB%83%E5%AE%B9%E7%81%BE%E5%8F%8A%E8%AE%AD%E7%BB%83%E7%9B%91%E6%8E%A7/#常见错误警告\",\"628\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E7%88%AC%E5%8F%96/#思考板块-思考\",\"629\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E4%B8%8E%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%EF%BC%88LLM-_-MoE%EF%BC%89%E8%A7%A3%E6%9E%90/#📈-趋势预测\",\"630\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E9%87%87%E6%A0%B7%E6%96%B9%E6%B3%95%EF%BC%9ATop-K%E3%80%81Top-P%E3%80%81Temperature%E5%8F%8A%E7%BB%BC%E5%90%88%E7%AD%96%E7%95%A5/#常见错误-⚠️\",\"631\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/BPE/#思考-延伸问题\",\"632\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E5%A4%9A%E6%A0%B7%E6%80%A7%E4%B8%8E%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E6%8E%A2%E7%B4%A2/#思考板块\",\"633\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E9%85%8D%E6%AF%94%E4%B8%8E%E8%AE%AD%E7%BB%83%E9%A1%BA%E5%BA%8F%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97/#📈趋势预测\",\"634\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E7%BB%A7%E7%BB%AD%E9%A2%84%E8%AE%AD%E7%BB%83/#💡启发点\",\"635\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90/#思考-延伸问题\",\"636\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#工作原理\",\"637\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E8%AE%AD%E7%BB%83%E7%9A%84trick%E5%92%8C%E9%97%AE%E9%A2%98/#操作步骤\",\"638\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/SARSA-%CE%BB%E4%B8%8EQ-learning%E5%AF%B9%E6%AF%94/#内容概述\",\"639\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E9%97%AE%E9%A2%98_%E6%B5%81%E7%A8%8B/#强化学习的流程\",\"640\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E6%B7%B1%E5%BA%A6Q%E7%BD%91%E7%BB%9C/#q-learning的更新方式\",\"641\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%96%B9%E6%B3%95/#元数据\",\"642\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B/\",\"643\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E6%97%B6%E5%BA%8F%E5%B7%AE%E5%88%86%E7%AE%97%E6%B3%95/#技术术语转述\",\"644\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%A8%A1%E5%9E%8B%E6%89%93%E5%88%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%8E%BB%E9%87%8D/#✅-操作步骤\",\"645\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E5%B8%B8%E7%94%A8%E5%88%86%E8%AF%8D%E5%BA%93/#行动清单\",\"646\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/SARSA%E7%AE%97%E6%B3%95/#重点段落\",\"647\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BB%B7%E5%80%BC%E8%BF%AD%E4%BB%A3%E7%AE%97%E6%B3%95/#重点段落\",\"648\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6/#📈趋势预测\",\"649\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RL%E5%9C%A8NLP%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E6%8B%93%E5%B1%95/#关键步骤\",\"650\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/#📈-趋势预测\",\"651\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%84%E4%BC%B0/#操作步骤\",\"652\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AD%96%E7%95%A5%E6%A2%AF%E5%BA%A6%E7%AE%97%E6%B3%95/#核心观点\",\"653\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%88%86%E7%B1%BB/#以采样策略和更新策略划分\",\"654\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/Actor-Critic%E7%AE%97%E6%B3%95/#其他指导策略更新的方法\",\"655\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%8B%AC%E7%89%B9%E6%80%A7/#_1-优化目标的核心区别\",\"656\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AD%96%E7%95%A5%E8%BF%AD%E4%BB%A3%E7%AE%97%E6%B3%95/#重点段落\",\"657\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%98%BE%E5%AD%98%E4%BC%98%E5%8C%96%E4%B8%8E%E6%A2%AF%E5%BA%A6%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/#常见错误与注意事项\",\"658\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E7%AE%97%E6%B3%95/#策略截断与稳定性\",\"659\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E8%B4%9D%E5%B0%94%E6%9B%BC%E6%96%B9%E7%A8%8B/#元数据\",\"660\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%E8%AE%AD%E7%BB%83/#思考\",\"661\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%84%E4%BC%B02/#续写能力\",\"662\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E8%AE%AD%E7%BB%83%E5%AE%B9%E7%81%BE%E5%8F%8A%E8%AE%AD%E7%BB%83%E7%9B%91%E6%8E%A7/#行动清单\",\"663\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E7%88%AC%E5%8F%96/#行动清单\",\"664\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E4%B8%8E%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%EF%BC%88LLM-_-MoE%EF%BC%89%E8%A7%A3%E6%9E%90/#💡-启发点\",\"665\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E9%87%87%E6%A0%B7%E6%96%B9%E6%B3%95%EF%BC%9ATop-K%E3%80%81Top-P%E3%80%81Temperature%E5%8F%8A%E7%BB%BC%E5%90%88%E7%AD%96%E7%95%A5/#💡启发点\",\"666\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E5%A4%9A%E6%A0%B7%E6%80%A7%E4%B8%8E%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E6%8E%A2%E7%B4%A2/#行动清单\",\"667\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E9%85%8D%E6%AF%94%E4%B8%8E%E8%AE%AD%E7%BB%83%E9%A1%BA%E5%BA%8F%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97/#后续追踪\",\"668\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E7%BB%A7%E7%BB%AD%E9%A2%84%E8%AE%AD%E7%BB%83/#行动清单\",\"669\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90/#行动清单\",\"670\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#提示词和示例\",\"671\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E8%AE%AD%E7%BB%83%E7%9A%84trick%E5%92%8C%E9%97%AE%E9%A2%98/#常见错误\",\"672\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/SARSA-%CE%BB%E4%B8%8EQ-learning%E5%AF%B9%E6%AF%94/#sarsa-λ算法\",\"673\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E9%97%AE%E9%A2%98_%E6%B5%81%E7%A8%8B/#常见错误\",\"674\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E6%B7%B1%E5%BA%A6Q%E7%BD%91%E7%BB%9C/#dqn的重要改进\",\"675\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%96%B9%E6%B3%95/#内容概述\",\"676\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B/#🚀-核心观点\",\"677\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge-Distillation-%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/\",\"678\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E6%97%B6%E5%BA%8F%E5%B7%AE%E5%88%86%E7%AE%97%E6%B3%95/#常见错误警告\",\"679\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%A8%A1%E5%9E%8B%E6%89%93%E5%88%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%8E%BB%E9%87%8D/#常见错误与注意事项\",\"680\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E5%B8%B8%E7%94%A8%E5%88%86%E8%AF%8D%E5%BA%93/#📈-趋势预测\",\"681\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/SARSA%E7%AE%97%E6%B3%95/#操作步骤\",\"682\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Low-Rank-Factorization-%E4%BD%8E%E7%A7%A9%E5%88%86%E8%A7%A3/\",\"683\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6/#后续追踪\",\"684\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RL%E5%9C%A8NLP%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E6%8B%93%E5%B1%95/#常见错误\",\"685\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/#思考-板块\",\"686\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%84%E4%BC%B0/#常见错误\",\"687\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AD%96%E7%95%A5%E6%A2%AF%E5%BA%A6%E7%AE%97%E6%B3%95/#重点段落\",\"688\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%88%86%E7%B1%BB/#以需不需要环境动态划分\",\"689\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/Actor-Critic%E7%AE%97%E6%B3%95/#常见错误\",\"690\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%8B%AC%E7%89%B9%E6%80%A7/#_2-数据类型与来源\",\"691\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AD%96%E7%95%A5%E8%BF%AD%E4%BB%A3%E7%AE%97%E6%B3%95/#常见错误\",\"692\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E4%BB%8B%E7%BB%8D/\",\"693\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D/\",\"694\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%98%BE%E5%AD%98%E4%BC%98%E5%8C%96%E4%B8%8E%E6%A2%AF%E5%BA%A6%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/#思考-板块\",\"695\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E7%AE%97%E6%B3%95/#操作步骤\",\"696\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E8%B4%9D%E5%B0%94%E6%9B%BC%E6%96%B9%E7%A8%8B/#内容处理\",\"697\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/\",\"698\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%E8%AE%AD%E7%BB%83/#行动清单\",\"699\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%84%E4%BC%B02/#核心观点-2\",\"700\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E8%AE%AD%E7%BB%83%E5%AE%B9%E7%81%BE%E5%8F%8A%E8%AE%AD%E7%BB%83%E7%9B%91%E6%8E%A7/#📈-趋势预测\",\"701\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E7%88%AC%E5%8F%96/#📈趋势预测\",\"702\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E4%B8%8E%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%EF%BC%88LLM-_-MoE%EF%BC%89%E8%A7%A3%E6%9E%90/#思考-延伸问题\",\"703\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E9%87%87%E6%A0%B7%E6%96%B9%E6%B3%95%EF%BC%9ATop-K%E3%80%81Top-P%E3%80%81Temperature%E5%8F%8A%E7%BB%BC%E5%90%88%E7%AD%96%E7%95%A5/#📈趋势预测\",\"704\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E5%A4%9A%E6%A0%B7%E6%80%A7%E4%B8%8E%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E6%8E%A2%E7%B4%A2/#后续追踪计划\",\"705\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E9%85%8D%E6%AF%94%E4%B8%8E%E8%AE%AD%E7%BB%83%E9%A1%BA%E5%BA%8F%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97/#思考-板块\",\"706\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E7%BB%A7%E7%BB%AD%E9%A2%84%E8%AE%AD%E7%BB%83/#📈趋势预测\",\"707\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90/#后续追踪\",\"708\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#上下文提供\",\"709\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E8%AE%AD%E7%BB%83%E7%9A%84trick%E5%92%8C%E9%97%AE%E9%A2%98/#行动清单\",\"710\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/SARSA-%CE%BB%E4%B8%8EQ-learning%E5%AF%B9%E6%AF%94/#q-learning算法\",\"711\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E9%97%AE%E9%A2%98_%E6%B5%81%E7%A8%8B/#💡-启发点\",\"712\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E6%B7%B1%E5%BA%A6Q%E7%BD%91%E7%BB%9C/#repaly-buffer-经验回放\",\"713\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%96%B9%E6%B3%95/#核心观点\",\"714\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B/#📊-重点段落\",\"715\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge-Distillation-%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/#知识蒸馏的基本组成部分\",\"716\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/PageAttention%E6%9C%BA%E5%88%B6/\",\"717\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E6%97%B6%E5%BA%8F%E5%B7%AE%E5%88%86%E7%AE%97%E6%B3%95/#💡启发点\",\"718\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%A8%A1%E5%9E%8B%E6%89%93%E5%88%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%8E%BB%E9%87%8D/#⚠-警告区块\",\"719\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%88%86%E8%AF%8D/%E5%B8%B8%E7%94%A8%E5%88%86%E8%AF%8D%E5%BA%93/#思考-延伸问题\",\"720\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/SARSA%E7%AE%97%E6%B3%95/#常见错误\",\"721\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RL%E5%9C%A8NLP%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E6%8B%93%E5%B1%95/#💡启发点\",\"722\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%84%E4%BC%B0/#💡启发点\",\"723\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AD%96%E7%95%A5%E6%A2%AF%E5%BA%A6%E7%AE%97%E6%B3%95/#策略梯度算法\",\"724\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%88%86%E7%B1%BB/#以如何学习策略划分\",\"725\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/Actor-Critic%E7%AE%97%E6%B3%95/#💡启发点\",\"726\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%8B%AC%E7%89%B9%E6%80%A7/#_3-学习方式的差异\",\"727\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AD%96%E7%95%A5%E8%BF%AD%E4%BB%A3%E7%AE%97%E6%B3%95/#个人见解-思考\",\"728\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E4%BB%8B%E7%BB%8D/#模型变得越来越大\",\"729\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D/#模型量化与剪枝的区别\",\"730\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%98%BE%E5%AD%98%E4%BC%98%E5%8C%96%E4%B8%8E%E6%A2%AF%E5%BA%A6%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/#行动清单\",\"731\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E7%AE%97%E6%B3%95/#常见错误\",\"732\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E8%B4%9D%E5%B0%94%E6%9B%BC%E6%96%B9%E7%A8%8B/#贝尔曼期望方程\",\"733\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/#模型量化\",\"734\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%E8%AE%AD%E7%BB%83/#后续追踪\",\"735\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%84%E4%BC%B02/#重点段落-2\",\"736\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E8%AE%AD%E7%BB%83%E5%AE%B9%E7%81%BE%E5%8F%8A%E8%AE%AD%E7%BB%83%E7%9B%91%E6%8E%A7/#思考-延伸问题\",\"737\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%95%B0%E6%8D%AE%E7%88%AC%E5%8F%96/#后续追踪\",\"738\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E4%B8%8E%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%EF%BC%88LLM-_-MoE%EF%BC%89%E8%A7%A3%E6%9E%90/#行动清单\",\"739\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E9%87%87%E6%A0%B7%E6%96%B9%E6%B3%95%EF%BC%9ATop-K%E3%80%81Top-P%E3%80%81Temperature%E5%8F%8A%E7%BB%BC%E5%90%88%E7%AD%96%E7%95%A5/#行动清单\",\"740\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E7%BB%A7%E7%BB%AD%E9%A2%84%E8%AE%AD%E7%BB%83/#后续追踪\",\"741\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90/#数据资源概览\",\"742\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#推理和生成\",\"743\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E8%AE%AD%E7%BB%83%E7%9A%84trick%E5%92%8C%E9%97%AE%E9%A2%98/#ppo优化与对齐税影响分析\",\"744\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/SARSA-%CE%BB%E4%B8%8EQ-learning%E5%AF%B9%E6%AF%94/#算法流程\",\"745\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E9%97%AE%E9%A2%98_%E6%B5%81%E7%A8%8B/#📈-趋势预测\",\"746\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E6%B7%B1%E5%BA%A6Q%E7%BD%91%E7%BB%9C/#target-network-目标网络\",\"747\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%96%B9%E6%B3%95/#重点段落\",\"748\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B/#状态价值函数\",\"749\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge-Distillation-%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/#白盒知识蒸馏\",\"750\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/PageAttention%E6%9C%BA%E5%88%B6/#核心机制\",\"751\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84packing%E6%8A%80%E5%B7%A7/\",\"752\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E6%97%B6%E5%BA%8F%E5%B7%AE%E5%88%86%E7%AE%97%E6%B3%95/#行动清单\",\"753\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%A8%A1%E5%9E%8B%E6%89%93%E5%88%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%8E%BB%E9%87%8D/#📈-趋势预测\",\"754\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/SARSA%E7%AE%97%E6%B3%95/#思考\",\"755\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RL%E5%9C%A8NLP%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E6%8B%93%E5%B1%95/#行动清单\",\"756\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%84%E4%BC%B0/#行动清单\",\"757\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AD%96%E7%95%A5%E6%A2%AF%E5%BA%A6%E7%AE%97%E6%B3%95/#reinforce算法\",\"758\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%88%86%E7%B1%BB/#常见错误\",\"759\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/Actor-Critic%E7%AE%97%E6%B3%95/#行动清单\",\"760\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%8B%AC%E7%89%B9%E6%80%A7/#_4-智能体的作用\",\"761\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AD%96%E7%95%A5%E8%BF%AD%E4%BB%A3%E7%AE%97%E6%B3%95/#行动清单\",\"762\":\"/leetcode/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/%E5%8D%8A%E5%BE%84%E4%B8%BAk%E7%9A%84%E5%AD%90%E6%95%B0%E7%BB%84%E5%B9%B3%E5%9D%87%E5%80%BC/\",\"763\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E4%BB%8B%E7%BB%8D/#需要一些大模型压缩技术\",\"764\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D/#剪枝流程\",\"765\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%98%BE%E5%AD%98%E4%BC%98%E5%8C%96%E4%B8%8E%E6%A2%AF%E5%BA%A6%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/#后续追踪\",\"766\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E7%AE%97%E6%B3%95/#💡启发点\",\"767\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E8%B4%9D%E5%B0%94%E6%9B%BC%E6%96%B9%E7%A8%8B/#最优策略与贝尔曼最优方程\",\"768\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/#常用的数据类型\",\"769\":\"/leetcode/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/%E5%A4%A7%E5%B0%8F%E4%B8%BAk%E5%B9%B3%E5%9D%87%E5%80%BC%E5%A4%A7%E4%BA%8E%E7%AD%89%E4%BA%8E%E9%98%88%E5%80%BC%E7%9A%84%E5%AD%90%E6%95%B0%E7%BB%84%E4%B8%AA%E6%95%B0/\",\"770\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%84%E4%BC%B02/#思考\",\"771\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Structure-_-Decoding-Policy-%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5/%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E9%87%87%E6%A0%B7%E6%96%B9%E6%B3%95%EF%BC%9ATop-K%E3%80%81Top-P%E3%80%81Temperature%E5%8F%8A%E7%BB%BC%E5%90%88%E7%AD%96%E7%95%A5/#思考-延伸问题\",\"772\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90/#数据采样与分布策略\",\"773\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#icl形式化定义\",\"774\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E8%AE%AD%E7%BB%83%E7%9A%84trick%E5%92%8C%E9%97%AE%E9%A2%98/#分类\",\"775\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/SARSA-%CE%BB%E4%B8%8EQ-learning%E5%AF%B9%E6%AF%94/#q-learning算法流程\",\"776\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E9%97%AE%E9%A2%98_%E6%B5%81%E7%A8%8B/#思考-板块\",\"777\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E6%B7%B1%E5%BA%A6Q%E7%BD%91%E7%BB%9C/#常见错误\",\"778\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%96%B9%E6%B3%95/#操作步骤\",\"779\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B/#动作价值函数\",\"780\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge-Distillation-%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/#知识的类型\",\"781\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/PageAttention%E6%9C%BA%E5%88%B6/#不同解码策略下的用法\",\"782\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84packing%E6%8A%80%E5%B7%A7/#why\",\"783\":\"/leetcode/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/%E5%AE%9A%E9%95%BF%E5%AD%90%E4%B8%B2%E4%B8%AD%E5%85%83%E9%9F%B3%E7%9A%84%E6%9C%80%E5%A4%A7%E6%95%B0%E7%9B%AE/\",\"784\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E6%97%B6%E5%BA%8F%E5%B7%AE%E5%88%86%E7%AE%97%E6%B3%95/#📈趋势预测\",\"785\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%A8%A1%E5%9E%8B%E6%89%93%E5%88%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%8E%BB%E9%87%8D/#思考-延伸问题\",\"786\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/SARSA%E7%AE%97%E6%B3%95/#💡启发点\",\"787\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RL%E5%9C%A8NLP%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E6%8B%93%E5%B1%95/#📈趋势预测\",\"788\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%84%E4%BC%B0/#📈趋势预测\",\"789\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AD%96%E7%95%A5%E6%A2%AF%E5%BA%A6%E7%AE%97%E6%B3%95/#算法流程\",\"790\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%88%86%E7%B1%BB/#💡启发点\",\"791\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/Actor-Critic%E7%AE%97%E6%B3%95/#📈趋势预测\",\"792\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%8B%AC%E7%89%B9%E6%80%A7/#常见错误\",\"793\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AD%96%E7%95%A5%E8%BF%AD%E4%BB%A3%E7%AE%97%E6%B3%95/#📈趋势预测\",\"794\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E4%BB%8B%E7%BB%8D/#降低模型部署的成本\",\"795\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D/#_1-先训练模型-然后剪枝-最后微调\",\"796\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E7%AE%97%E6%B3%95/#行动清单\",\"797\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E8%B4%9D%E5%B0%94%E6%9B%BC%E6%96%B9%E7%A8%8B/#思考\",\"798\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/FastText/\",\"799\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/#量化对象\",\"800\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%84%E4%BC%B02/#操作步骤\",\"801\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/Word2Vec/\",\"802\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/oneHot/\",\"803\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90/#数据分布比例\",\"804\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#icl示例设计\",\"805\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E8%AE%AD%E7%BB%83%E7%9A%84trick%E5%92%8C%E9%97%AE%E9%A2%98/#标签\",\"806\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/SARSA-%CE%BB%E4%B8%8EQ-learning%E5%AF%B9%E6%AF%94/#常见错误\",\"807\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E9%97%AE%E9%A2%98_%E6%B5%81%E7%A8%8B/#行动清单\",\"808\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E6%B7%B1%E5%BA%A6Q%E7%BD%91%E7%BB%9C/#💡启发点\",\"809\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%96%B9%E6%B3%95/#常见错误\",\"810\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B/#策略与价值函数的关系\",\"811\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge-Distillation-%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/#_1-response-based\",\"812\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/PageAttention%E6%9C%BA%E5%88%B6/#prefill阶段\",\"813\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84packing%E6%8A%80%E5%B7%A7/#what\",\"814\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/%E4%BB%8B%E7%BB%8D/\",\"815\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E6%97%B6%E5%BA%8F%E5%B7%AE%E5%88%86%E7%AE%97%E6%B3%95/#后续追踪\",\"816\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%A8%A1%E5%9E%8B%E6%89%93%E5%88%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%8E%BB%E9%87%8D/#行动清单\",\"817\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/SARSA%E7%AE%97%E6%B3%95/#行动清单\",\"818\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RL%E5%9C%A8NLP%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E6%8B%93%E5%B1%95/#后续追踪\",\"819\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%84%E4%BC%B0/#后续追踪\",\"820\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AD%96%E7%95%A5%E6%A2%AF%E5%BA%A6%E7%AE%97%E6%B3%95/#代码示例\",\"821\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%88%86%E7%B1%BB/#行动清单\",\"822\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/Actor-Critic%E7%AE%97%E6%B3%95/#后续追踪\",\"823\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%8B%AC%E7%89%B9%E6%80%A7/#💡启发点\",\"824\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AD%96%E7%95%A5%E8%BF%AD%E4%BB%A3%E7%AE%97%E6%B3%95/#后续追踪\",\"825\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E4%BB%8B%E7%BB%8D/#提升模型的推理性能\",\"826\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D/#_2-模型训练的过程中剪枝-然后微调\",\"827\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/BART/\",\"828\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/RoBERTa/\",\"829\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E7%AE%97%E6%B3%95/#📈趋势预测\",\"830\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/T5/\",\"831\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E8%B4%9D%E5%B0%94%E6%9B%BC%E6%96%B9%E7%A8%8B/#操作步骤\",\"832\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/FastText/#元数据\",\"833\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/#量化形式\",\"834\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%84%E4%BC%B02/#常见错误\",\"835\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/Word2Vec/#元数据\",\"836\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/oneHot/#元数据\",\"837\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90/#中文语料采样\",\"838\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#示例选择\",\"839\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E8%AE%AD%E7%BB%83%E7%9A%84trick%E5%92%8C%E9%97%AE%E9%A2%98/#日期\",\"840\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/SARSA-%CE%BB%E4%B8%8EQ-learning%E5%AF%B9%E6%AF%94/#代码示例\",\"841\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E9%97%AE%E9%A2%98_%E6%B5%81%E7%A8%8B/#后续追踪\",\"842\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E6%B7%B1%E5%BA%A6Q%E7%BD%91%E7%BB%9C/#行动清单\",\"843\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%96%B9%E6%B3%95/#代码示例\",\"844\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B/#✅-操作步骤\",\"845\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge-Distillation-%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/#_2-feature-based\",\"846\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/PageAttention%E6%9C%BA%E5%88%B6/#decode阶段\",\"847\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84packing%E6%8A%80%E5%B7%A7/#_5-7-1-预训练阶段\",\"848\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/%E4%BB%8B%E7%BB%8D/#元数据\",\"849\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/%E4%BB%8B%E7%BB%8D/\",\"850\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E6%97%B6%E5%BA%8F%E5%B7%AE%E5%88%86%E7%AE%97%E6%B3%95/#思考-板块\",\"851\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E6%A8%A1%E5%9E%8B%E6%89%93%E5%88%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%8E%BB%E9%87%8D/#后续追踪\",\"852\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/SARSA%E7%AE%97%E6%B3%95/#📈趋势预测\",\"853\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM1/\",\"854\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM2/\",\"855\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM3/\",\"856\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AD%96%E7%95%A5%E6%A2%AF%E5%BA%A6%E7%AE%97%E6%B3%95/#常见错误\",\"857\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%88%86%E7%B1%BB/#📈趋势预测\",\"858\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%8B%AC%E7%89%B9%E6%80%A7/#操作步骤\",\"859\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM4/\",\"860\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D/#_3-进行剪枝-然后从头训练剪枝的模型\",\"861\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/BART/#元数据\",\"862\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/RoBERTa/#元数据\",\"863\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/\",\"864\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E7%AE%97%E6%B3%95/#后续追踪\",\"865\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/T5/#元数据\",\"866\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E8%B4%9D%E5%B0%94%E6%9B%BC%E6%96%B9%E7%A8%8B/#常见错误\",\"867\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/FastText/#fasttext算法核心概述\",\"868\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/#根据量化数据表示的原始数据范围是否均匀-可以将量化方法分为线性量化和非线性量化\",\"869\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%84%E4%BC%B02/#💡启发点\",\"870\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/Word2Vec/#什么是word2vec\",\"871\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/oneHot/#什么是独热编码-onehot-encoding\",\"872\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-V2/\",\"873\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90/#英文语料采样\",\"874\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#启发式方法\",\"875\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E8%AE%AD%E7%BB%83%E7%9A%84trick%E5%92%8C%E9%97%AE%E9%A2%98/#内容概述\",\"876\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/SARSA-%CE%BB%E4%B8%8EQ-learning%E5%AF%B9%E6%AF%94/#思考\",\"877\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E6%B7%B1%E5%BA%A6Q%E7%BD%91%E7%BB%9C/#📈趋势预测\",\"878\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%96%B9%E6%B3%95/#💡启发点\",\"879\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B/#⚠-常见错误\",\"880\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge-Distillation-%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/#_3-relation-based\",\"881\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84packing%E6%8A%80%E5%B7%A7/#_5-7-2-微调阶段\",\"882\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/%E4%BB%8B%E7%BB%8D/#_1-什么是词嵌入-embedding\",\"883\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/%E4%BB%8B%E7%BB%8D/#元数据\",\"884\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-V3/\",\"885\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/Deepseek-V1/\",\"886\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/SARSA%E7%AE%97%E6%B3%95/#后续追踪\",\"887\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM1/#元数据\",\"888\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/Deepseek-math/\",\"889\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM2/#模型结构概述\",\"890\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM3/#元数据\",\"891\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AD%96%E7%95%A5%E6%A2%AF%E5%BA%A6%E7%AE%97%E6%B3%95/#💡启发点\",\"892\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%88%86%E7%B1%BB/#后续追踪\",\"893\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%8B%AC%E7%89%B9%E6%80%A7/#📈趋势预测\",\"894\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM4/#模型结构\",\"895\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-1/\",\"896\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D/#_7-2-3-剪枝分类\",\"897\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/BART/#内容概述\",\"898\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/RoBERTa/#内容简介\",\"899\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#元数据\",\"900\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-2/\",\"901\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/T5/#内容概述\",\"902\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E8%B4%9D%E5%B0%94%E6%9B%BC%E6%96%B9%E7%A8%8B/#行动清单\",\"903\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/FastText/#技术细节与优化点\",\"904\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/#根据-和-的共享范围即量化粒度-量化方法可以进行以下分类\",\"905\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%84%E4%BC%B02/#行动清单\",\"906\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/Word2Vec/#word2vec的加速方法\",\"907\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/oneHot/#优缺点分析\",\"908\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-V2/#元数据\",\"909\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90/#code语料采样\",\"910\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#基于语义相似度\",\"911\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E8%AE%AD%E7%BB%83%E7%9A%84trick%E5%92%8C%E9%97%AE%E9%A2%98/#核心观点\",\"912\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/SARSA-%CE%BB%E4%B8%8EQ-learning%E5%AF%B9%E6%AF%94/#行动清单\",\"913\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E6%B7%B1%E5%BA%A6Q%E7%BD%91%E7%BB%9C/#后续追踪\",\"914\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%96%B9%E6%B3%95/#行动清单\",\"915\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B/#💡-启发点\",\"916\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge-Distillation-%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/#蒸馏的方法\",\"917\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84packing%E6%8A%80%E5%B7%A7/#咱们来看看-llama-factory-是如何优化的\",\"918\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/%E4%BB%8B%E7%BB%8D/#核心特性\",\"919\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/%E4%BB%8B%E7%BB%8D/#内容处理\",\"920\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-V3/#元数据\",\"921\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-3/\",\"922\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/Deepseek-V1/#元数据\",\"923\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM1/#内容概述\",\"924\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/Deepseek-math/#分类-自动推断\",\"925\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM2/#训练目标\",\"926\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM3/#内容概述\",\"927\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AD%96%E7%95%A5%E6%A2%AF%E5%BA%A6%E7%AE%97%E6%B3%95/#📈趋势预测\",\"928\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%8B%AC%E7%89%B9%E6%80%A7/#行动清单\",\"929\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM4/#预训练数据处理\",\"930\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-1/#元数据\",\"931\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D/#非结构化剪枝\",\"932\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/BART/#核心观点\",\"933\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/RoBERTa/#核心观点\",\"934\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#内容概述\",\"935\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-2/#元数据\",\"936\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/T5/#关键点\",\"937\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E8%B4%9D%E5%B0%94%E6%9B%BC%E6%96%B9%E7%A8%8B/#📈趋势预测\",\"938\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/FastText/#✅-模型结构与输入输出\",\"939\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/#逐层量化-per-tensor\",\"940\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%84%E4%BC%B02/#📈趋势预测\",\"941\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/Word2Vec/#hierarchical-softmax-霍夫曼树\",\"942\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/LLama%E7%B3%BB%E5%88%97/LLaMA1/\",\"943\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/oneHot/#✅-优点\",\"944\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/LLama%E7%B3%BB%E5%88%97/LLama-2/\",\"945\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/LLama%E7%B3%BB%E5%88%97/LLama-3/\",\"946\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/GShard/\",\"947\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-V2/#内容处理\",\"948\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/\",\"949\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#基于多样性\",\"950\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E8%AE%AD%E7%BB%83%E7%9A%84trick%E5%92%8C%E9%97%AE%E9%A2%98/#重点段落\",\"951\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/SARSA-%CE%BB%E4%B8%8EQ-learning%E5%AF%B9%E6%AF%94/#后续追踪\",\"952\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%96%B9%E6%B3%95/#📈趋势预测\",\"953\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B/#📈-趋势预测\",\"954\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge-Distillation-%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/#_1-offline-distillation\",\"955\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/%E4%BB%8B%E7%BB%8D/#_2-embedding-的实现与工作机制\",\"956\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/%E4%BB%8B%E7%BB%8D/#bert-embedding\",\"957\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-V3/#核心架构演进\",\"958\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-3/#分类\",\"959\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Switch-Transformer/\",\"960\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/Deepseek-V1/#内容概述\",\"961\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM1/#模型结构与创新点\",\"962\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/Deepseek-math/#标签-数学预训练、强化学习、数据处理、deepseek\",\"963\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM2/#解码器架构的选择\",\"964\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM3/#主要优化点\",\"965\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AD%96%E7%95%A5%E6%A2%AF%E5%BA%A6%E7%AE%97%E6%B3%95/#思考\",\"966\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%8B%AC%E7%89%B9%E6%80%A7/#思考-板块\",\"967\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM4/#对齐训练技术\",\"968\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-1/#内容摘要\",\"969\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D/#优点\",\"970\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/BART/#技术术语简化\",\"971\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/RoBERTa/#重点段落\",\"972\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#研究背景与内容\",\"973\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/PLaM%E7%B3%BB%E5%88%97/PaLM/\",\"974\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/PLaM%E7%B3%BB%E5%88%97/PLaM2/\",\"975\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-2/#内容概述\",\"976\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen1/\",\"977\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen2.5/\",\"978\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/T5/#t5模型的核心思想\",\"979\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E8%B4%9D%E5%B0%94%E6%9B%BC%E6%96%B9%E7%A8%8B/#后续追踪\",\"980\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/FastText/#✅-损失函数与分层softmax\",\"981\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/#逐通道量化-per-token-per-channel\",\"982\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%84%E4%BC%B02/#后续追踪\",\"983\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/Word2Vec/#negative-sampling-负采样\",\"984\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/LLama%E7%B3%BB%E5%88%97/LLaMA1/#分类-机器学习模型\",\"985\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/oneHot/#⚠️-缺点\",\"986\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/LLama%E7%B3%BB%E5%88%97/LLama-2/#元数据\",\"987\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/LLama%E7%B3%BB%E5%88%97/LLama-3/#元数据\",\"988\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/GShard/#元数据\",\"989\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-V2/#核心观点总结\",\"990\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#元数据\",\"991\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#llm-based方法\",\"992\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E8%AE%AD%E7%BB%83%E7%9A%84trick%E5%92%8C%E9%97%AE%E9%A2%98/#ppo-ptx优化目标\",\"993\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%96%B9%E6%B3%95/#后续追踪\",\"994\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B/#思考-板块\",\"995\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge-Distillation-%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/#_2-online-distillation\",\"996\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/%E4%BB%8B%E7%BB%8D/#_2-1-pytorch-实现\",\"997\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/%E4%BB%8B%E7%BB%8D/#masked-lm-mlm\",\"998\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-V3/#混合专家系统革新\",\"999\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-3/#标签\",\"1000\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Switch-Transformer/#元数据\",\"1001\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen2/\",\"1002\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/Deepseek-V1/#模型结构\",\"1003\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/DeBERTa%E7%9A%84%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8E%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%A7%A3%E6%9E%90/\",\"1004\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM1/#自回归填空任务\",\"1005\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/Deepseek-math/#日期-2025年4月12日\",\"1006\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM2/#为什么选择-decoder-only-架构\",\"1007\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM3/#词表大小调整\",\"1008\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM4/#chatglm技术创新\",\"1009\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-1/#模型结构\",\"1010\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D/#缺点\",\"1011\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/BART/#操作步骤\",\"1012\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/RoBERTa/#模型规模与算力\",\"1013\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#研究背景\",\"1014\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/PLaM%E7%B3%BB%E5%88%97/PaLM/#分类\",\"1015\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/PLaM%E7%B3%BB%E5%88%97/PLaM2/#元数据\",\"1016\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-2/#重点内容\",\"1017\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen1/#元数据\",\"1018\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen2.5/#元数据\",\"1019\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/T5/#任务与数据集\",\"1020\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/T5%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%BC%98%E5%8C%96%E8%A7%A3%E6%9E%90/\",\"1021\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/FastText/#✅-n-gram特征与优化点\",\"1022\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/#逐组量化-per-group\",\"1023\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/Word2Vec/#技术对比表格\",\"1024\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/LLama%E7%B3%BB%E5%88%97/LLaMA1/#标签-llama1-自监督学习-机器学习-gpt-adamw\",\"1025\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/oneHot/#示例代码-如何实现独热编码\",\"1026\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/LLama%E7%B3%BB%E5%88%97/LLama-2/#内容概要\",\"1027\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8EXLNet%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%AF%A6%E8%A7%A3-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Transformer%E6%9C%BA%E5%88%B6/\",\"1028\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/LLama%E7%B3%BB%E5%88%97/LLama-3/#内容概述\",\"1029\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/GShard/#内容处理\",\"1030\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-V2/#重点段落提取\",\"1031\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#核心观点总结\",\"1032\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#直接用llm生成demonstration\",\"1033\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E8%AE%AD%E7%BB%83%E7%9A%84trick%E5%92%8C%E9%97%AE%E9%A2%98/#kl-reward系数设置\",\"1034\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B/#行动清单\",\"1035\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge-Distillation-%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/#_3-self-distillation\",\"1036\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/%E4%BB%8B%E7%BB%8D/#_2-2-embedding-的物理意义\",\"1037\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/%E4%BB%8B%E7%BB%8D/#next-sentence-prediction-nsp\",\"1038\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-V3/#通信优化机制\",\"1039\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-3/#日期\",\"1040\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Switch-Transformer/#模型特点\",\"1041\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen2/#模型结构与创新\",\"1042\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/BERT%E4%B8%8ERNN%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E7%9A%84%E5%AF%B9%E6%AF%94%E4%B8%8E%E5%BA%94%E7%94%A8/\",\"1043\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/Deepseek-V1/#训练过程\",\"1044\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/DeBERTa%E7%9A%84%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8E%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%A7%A3%E6%9E%90/#元数据\",\"1045\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM1/#二维位置编码技术\",\"1046\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/Deepseek-math/#核心观点总结\",\"1047\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM2/#样本构建与损失计算\",\"1048\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM3/#位置编码改进\",\"1049\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-1/#训练范式\",\"1050\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D/#非结构化剪枝方法\",\"1051\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/BART/#常见错误\",\"1052\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/RoBERTa/#训练数据与方法\",\"1053\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#研究内容\",\"1054\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/Transformer%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%AF%A6%E8%A7%A3%E4%B8%8E%E6%94%B9%E8%BF%9B%E5%88%86%E6%9E%90/\",\"1055\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/PLaM%E7%B3%BB%E5%88%97/PaLM/#标签\",\"1056\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83%E4%B8%8E%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E5%8C%BA%E5%88%AB/\",\"1057\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/PLaM%E7%B3%BB%E5%88%97/PLaM2/#内容概述\",\"1058\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E8%AE%AD%E7%BB%83Tokenizer/\",\"1059\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-2/#模型结构与训练范式\",\"1060\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen1/#核心观点总结\",\"1061\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen2.5/#核心观点总结\",\"1062\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/T5/#模型训练方式\",\"1063\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/T5%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%BC%98%E5%8C%96%E8%A7%A3%E6%9E%90/#元数据\",\"1064\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/FastText/#常见错误与解决方法\",\"1065\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/#llama3-技术报告中提供的-tensor-wise-和-row-wise-fp8-量化示意图\",\"1066\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/Word2Vec/#常见错误警告-⚠️\",\"1067\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/LLama%E7%B3%BB%E5%88%97/LLaMA1/#日期-2025年4月12日\",\"1068\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/oneHot/#为什么需要独热编码\",\"1069\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/LLama%E7%B3%BB%E5%88%97/LLama-2/#模型结构改进\",\"1070\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8EXLNet%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%AF%A6%E8%A7%A3-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Transformer%E6%9C%BA%E5%88%B6/#元数据\",\"1071\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/LLama%E7%B3%BB%E5%88%97/LLama-3/#模型结构\",\"1072\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/GShard/#核心观点总结\",\"1073\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-V2/#通俗语言转述\",\"1074\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#重点段落与数据\",\"1075\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#基于prompt召回\",\"1076\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E8%AE%AD%E7%BB%83%E7%9A%84trick%E5%92%8C%E9%97%AE%E9%A2%98/#预训练损失ptx-loss\",\"1077\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B/#后续追踪\",\"1078\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge-Distillation-%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/#黑盒知识蒸馏\",\"1079\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/%E4%BB%8B%E7%BB%8D/#_3-常见错误与注意事项\",\"1080\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/%E4%BB%8B%E7%BB%8D/#常见错误\",\"1081\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-V3/#多目标训练体系\",\"1082\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-3/#内容概述\",\"1083\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Switch-Transformer/#创新点\",\"1084\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen2/#模型训练与数据处理\",\"1085\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/BERT%E4%B8%8ERNN%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E7%9A%84%E5%AF%B9%E6%AF%94%E4%B8%8E%E5%BA%94%E7%94%A8/#元数据\",\"1086\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84Scaling-Law/\",\"1087\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/Deepseek-V1/#sft训练\",\"1088\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/DeBERTa%E7%9A%84%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8E%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%A7%A3%E6%9E%90/#核心观点总结\",\"1089\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM1/#多任务预训练策略\",\"1090\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/Deepseek-math/#重点段落与数据\",\"1091\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM2/#常见错误\",\"1092\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM3/#前馈网络激活函数更改\",\"1093\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-1/#预训练\",\"1094\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D/#结构化剪枝\",\"1095\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/BART/#💡启发点\",\"1096\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/RoBERTa/#文本编码与词汇表\",\"1097\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#研究贡献\",\"1098\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/Transformer%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%AF%A6%E8%A7%A3%E4%B8%8E%E6%94%B9%E8%BF%9B%E5%88%86%E6%9E%90/#元数据\",\"1099\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5/\",\"1100\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/PLaM%E7%B3%BB%E5%88%97/PaLM/#日期\",\"1101\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83%E4%B8%8E%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E5%8C%BA%E5%88%AB/#元数据\",\"1102\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/PLaM%E7%B3%BB%E5%88%97/PLaM2/#模型结构与预训练\",\"1103\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E8%AE%AD%E7%BB%83Tokenizer/#元数据\",\"1104\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-2/#数据与实验\",\"1105\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen1/#重点段落\",\"1106\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen2.5/#重点段落\",\"1107\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/T5/#操作步骤\",\"1108\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/T5%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%BC%98%E5%8C%96%E8%A7%A3%E6%9E%90/#核心观点总结\",\"1109\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/FastText/#⚠️-常见错误\",\"1110\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/#量化分类\",\"1111\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/Word2Vec/#示例代码\",\"1112\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/LLama%E7%B3%BB%E5%88%97/LLaMA1/#模型结构改进\",\"1113\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/oneHot/#常见错误警告区块\",\"1114\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/LLama%E7%B3%BB%E5%88%97/LLama-2/#训练数据策略\",\"1115\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%AB%98%E6%95%88%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E9%80%89%E6%8B%A9%E4%B8%8E%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97/\",\"1116\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8EXLNet%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%AF%A6%E8%A7%A3-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Transformer%E6%9C%BA%E5%88%B6/#内容处理\",\"1117\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/LLama%E7%B3%BB%E5%88%97/LLama-3/#训练数据\",\"1118\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/Agent%E8%AF%84%E4%BC%B0%E6%A1%86%E6%9E%B6%E6%B1%87%E6%80%BB/\",\"1119\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/GShard/#重点段落提取\",\"1120\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-V2/#操作步骤\",\"1121\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#模型结构与工作原理\",\"1122\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#基于主动学习-强化学习\",\"1123\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E8%AE%AD%E7%BB%83%E7%9A%84trick%E5%92%8C%E9%97%AE%E9%A2%98/#操作步骤-1\",\"1124\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge-Distillation-%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/#白盒知识蒸馏与黑盒知识蒸馏的区别\",\"1125\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/%E4%BB%8B%E7%BB%8D/#_5-行动清单\",\"1126\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/%E4%BB%8B%E7%BB%8D/#💡启发点\",\"1127\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-V3/#多token预测-mtp\",\"1128\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-3/#模型结构与技术创新\",\"1129\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Switch-Transformer/#模型结构设计\",\"1130\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen2/#预训练阶段\",\"1131\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/BERT%E4%B8%8ERNN%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E7%9A%84%E5%AF%B9%E6%AF%94%E4%B8%8E%E5%BA%94%E7%94%A8/#核心观点总结\",\"1132\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84Scaling-Law/#核心观点总结\",\"1133\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E5%8E%9F%E7%90%86/\",\"1134\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/Deepseek-V1/#dpo训练\",\"1135\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/DeBERTa%E7%9A%84%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8E%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%A7%A3%E6%9E%90/#重点内容解析\",\"1136\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E5%8E%86%E5%8F%B2%E5%8F%91%E5%B1%95/\",\"1137\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM1/#操作步骤\",\"1138\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/Deepseek-math/#训练数据与来源\",\"1139\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/\",\"1140\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM2/#行动清单\",\"1141\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM3/#操作步骤\",\"1142\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-1/#微调\",\"1143\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D/#结构化剪枝方法\",\"1144\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/BART/#行动清单\",\"1145\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/RoBERTa/#操作步骤\",\"1146\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#强化学习在大模型上的应用\",\"1147\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/Transformer%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%AF%A6%E8%A7%A3%E4%B8%8E%E6%94%B9%E8%BF%9B%E5%88%86%E6%9E%90/#核心内容总结\",\"1148\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5/#元数据\",\"1149\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/PLaM%E7%B3%BB%E5%88%97/PaLM/#内容概述\",\"1150\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83%E4%B8%8E%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E5%8C%BA%E5%88%AB/#核心观点总结\",\"1151\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E6%A1%86%E6%9E%B6%E5%92%8C%E5%BA%94%E7%94%A8/\",\"1152\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/PLaM%E7%B3%BB%E5%88%97/PLaM2/#scaling-law-与优化\",\"1153\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E8%AE%AD%E7%BB%83Tokenizer/#核心内容总结\",\"1154\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-2/#zero-shot学习\",\"1155\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen1/#模型结构与创新之处\",\"1156\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen2.5/#模型系列与结构\",\"1157\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/T5/#常见错误\",\"1158\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/T5%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%BC%98%E5%8C%96%E8%A7%A3%E6%9E%90/#重点内容提取\",\"1159\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/FastText/#❗️解决方法\",\"1160\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/#量化感知训练-quantization-aware-training-qat\",\"1161\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/Word2Vec/#行动清单-✅\",\"1162\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/LLama%E7%B3%BB%E5%88%97/LLaMA1/#训练方式\",\"1163\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/oneHot/#作者观点-vs-个人观点\",\"1164\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/LLama%E7%B3%BB%E5%88%97/LLama-2/#拒绝采样方法\",\"1165\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%AB%98%E6%95%88%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E9%80%89%E6%8B%A9%E4%B8%8E%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97/#元数据\",\"1166\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8EXLNet%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%AF%A6%E8%A7%A3-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Transformer%E6%9C%BA%E5%88%B6/#核心观点概述\",\"1167\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/LLama%E7%B3%BB%E5%88%97/LLama-3/#数据过滤流程\",\"1168\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/Agent%E8%AF%84%E4%BC%B0%E6%A1%86%E6%9E%B6%E6%B1%87%E6%80%BB/#agentbench\",\"1169\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%B3%BB%E7%BB%9F%E5%88%86%E7%B1%BB/\",\"1170\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/GShard/#技术术语转述\",\"1171\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-V2/#常见错误\",\"1172\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#moe并行训练\",\"1173\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#主动学习思路\",\"1174\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E8%AE%AD%E7%BB%83%E7%9A%84trick%E5%92%8C%E9%97%AE%E9%A2%98/#常见错误-1\",\"1175\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge-Distillation-%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/#icl-上下文少样本学习蒸馏\",\"1176\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/%E4%BB%8B%E7%BB%8D/#_6-思考-延伸问题\",\"1177\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/%E4%BB%8B%E7%BB%8D/#行动清单\",\"1178\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-V3/#性能对比\",\"1179\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-3/#sparse-attention\",\"1180\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Switch-Transformer/#负载均衡\",\"1181\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen2/#后训练数据合成\",\"1182\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/BERT%E4%B8%8ERNN%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E7%9A%84%E5%AF%B9%E6%AF%94%E4%B8%8E%E5%BA%94%E7%94%A8/#内容详解\",\"1183\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84Scaling-Law/#核心内容\",\"1184\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E5%8E%9F%E7%90%86/#什么是llm-agent\",\"1185\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/\",\"1186\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/Deepseek-V1/#数据表格\",\"1187\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/DeBERTa%E7%9A%84%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8E%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%A7%A3%E6%9E%90/#deberta位置编码的公式解析\",\"1188\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E5%8E%86%E5%8F%B2%E5%8F%91%E5%B1%95/#openai-在-agi-五级分类中对于-agent-的定义\",\"1189\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM1/#常见错误\",\"1190\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/Deepseek-math/#数据集收集和清洗过程\",\"1191\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#按照数量分类\",\"1192\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM3/#常见错误\",\"1193\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-1/#输入形式的改变\",\"1194\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/RoBERTa/#常见错误\",\"1195\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#蒸馏技术的应用\",\"1196\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/Transformer%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%AF%A6%E8%A7%A3%E4%B8%8E%E6%94%B9%E8%BF%9B%E5%88%86%E6%9E%90/#重点内容解析\",\"1197\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5/#核心观点总结\",\"1198\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/PLaM%E7%B3%BB%E5%88%97/PaLM/#模型结构\",\"1199\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83%E4%B8%8E%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E5%8C%BA%E5%88%AB/#重点段落\",\"1200\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E6%A1%86%E6%9E%B6%E5%92%8C%E5%BA%94%E7%94%A8/#智能体框架\",\"1201\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/PLaM%E7%B3%BB%E5%88%97/PLaM2/#flops-计算成本\",\"1202\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E8%AE%AD%E7%BB%83Tokenizer/#重点内容解析\",\"1203\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-2/#操作步骤\",\"1204\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen1/#模型训练方法\",\"1205\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen2.5/#预训练数据与方法\",\"1206\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/T5/#💡启发点\",\"1207\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/T5%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%BC%98%E5%8C%96%E8%A7%A3%E6%9E%90/#相对位置编码的简化\",\"1208\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/FastText/#示例代码\",\"1209\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/#量化感知微调-quantization-aware-fine-tuning-qaf\",\"1210\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/Word2Vec/#思考-延伸问题\",\"1211\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/LLama%E7%B3%BB%E5%88%97/LLaMA1/#训练数据\",\"1212\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/oneHot/#行动清单\",\"1213\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/LLama%E7%B3%BB%E5%88%97/LLama-2/#后训练总结\",\"1214\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%AB%98%E6%95%88%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E9%80%89%E6%8B%A9%E4%B8%8E%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97/#分类-深度学习-模型训练标签-llama架构、megatron-lm、预训练、模型优化、深度学习框架日期-2023年10月xx日\",\"1215\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8EXLNet%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%AF%A6%E8%A7%A3-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Transformer%E6%9C%BA%E5%88%B6/#相对位置编码的基础原理\",\"1216\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/LLama%E7%B3%BB%E5%88%97/LLama-3/#训练流程\",\"1217\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/Agent%E8%AF%84%E4%BC%B0%E6%A1%86%E6%9E%B6%E6%B1%87%E6%80%BB/#核心思想\",\"1218\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%B3%BB%E7%BB%9F%E5%88%86%E7%B1%BB/#从架构上看-agentic-system-可以分为两大类系统\",\"1219\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/GShard/#操作步骤\",\"1220\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-V2/#💡启发点\",\"1221\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#分类\",\"1222\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#强化学习方法\",\"1223\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E8%AE%AD%E7%BB%83%E7%9A%84trick%E5%92%8C%E9%97%AE%E9%A2%98/#💡启发点\",\"1224\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge-Distillation-%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/#cot-中间推理步骤蒸馏\",\"1225\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/%E4%BB%8B%E7%BB%8D/#_7-后续追踪研究计划\",\"1226\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/%E4%BB%8B%E7%BB%8D/#数据转换\",\"1227\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-V3/#实现规范\",\"1228\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-3/#训练范式\",\"1229\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Switch-Transformer/#公式与设定\",\"1230\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen2/#训练过程的阶段划分\",\"1231\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/BERT%E4%B8%8ERNN%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E7%9A%84%E5%AF%B9%E6%AF%94%E4%B8%8E%E5%BA%94%E7%94%A8/#什么是位置编码\",\"1232\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84Scaling-Law/#_1-计算预算公式及其意义\",\"1233\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E5%8E%9F%E7%90%86/#llm-agent的核心组成\",\"1234\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#数据清洗\",\"1235\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96%E4%B8%AD%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E9%98%B6%E6%AE%B5/\",\"1236\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/Deepseek-V1/#警告区块\",\"1237\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/DeBERTa%E7%9A%84%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8E%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%A7%A3%E6%9E%90/#模型结构-encoder与decoder的分工\",\"1238\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E5%8E%86%E5%8F%B2%E5%8F%91%E5%B1%95/#level-1-conversational-ai\",\"1239\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM1/#行动清单\",\"1240\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/Deepseek-math/#指令微调与强化学习\",\"1241\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#singleagent-单个智能体进行任务规划与行动\",\"1242\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM3/#💡启发点\",\"1243\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-1/#操作步骤\",\"1244\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/RoBERTa/#💡启发点\",\"1245\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#操作步骤\",\"1246\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/Transformer%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%AF%A6%E8%A7%A3%E4%B8%8E%E6%94%B9%E8%BF%9B%E5%88%86%E6%9E%90/#_1-位置编码的定义与公式\",\"1247\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5/#重点内容\",\"1248\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/PLaM%E7%B3%BB%E5%88%97/PaLM/#训练设置\",\"1249\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83%E4%B8%8E%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E5%8C%BA%E5%88%AB/#技术术语通俗解释\",\"1250\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E6%A1%86%E6%9E%B6%E5%92%8C%E5%BA%94%E7%94%A8/#全代码框架\",\"1251\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%96%B9%E5%90%91/\",\"1252\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/PLaM%E7%B3%BB%E5%88%97/PLaM2/#reasoning-能力优化\",\"1253\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E8%AE%AD%E7%BB%83Tokenizer/#tokenizer的作用与训练方法\",\"1254\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-2/#常见错误\",\"1255\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen1/#外推能力扩展技术\",\"1256\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen2.5/#长文本预训练\",\"1257\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/T5/#行动清单\",\"1258\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/T5%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%BC%98%E5%8C%96%E8%A7%A3%E6%9E%90/#分桶-处理机制\",\"1259\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/FastText/#作者观点-vs-个人观点对比表格\",\"1260\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/#训练后量化-post-training-quantization-ptq\",\"1261\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/Word2Vec/#后续追踪-📈\",\"1262\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/LLama%E7%B3%BB%E5%88%97/LLaMA1/#⚠️-常见错误\",\"1263\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/oneHot/#后续追踪研究计划\",\"1264\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/LLama%E7%B3%BB%E5%88%97/LLama-2/#操作步骤\",\"1265\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%AB%98%E6%95%88%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E9%80%89%E6%8B%A9%E4%B8%8E%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97/#核心内容总结\",\"1266\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8EXLNet%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%AF%A6%E8%A7%A3-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Transformer%E6%9C%BA%E5%88%B6/#改进点\",\"1267\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/LLama%E7%B3%BB%E5%88%97/LLama-3/#整体流程\",\"1268\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/Agent%E8%AF%84%E4%BC%B0%E6%A1%86%E6%9E%B6%E6%B1%87%E6%80%BB/#评估方式\",\"1269\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%B3%BB%E7%BB%9F%E5%88%86%E7%B1%BB/#工作流-workflow\",\"1270\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/GShard/#常见错误\",\"1271\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-V2/#行动清单\",\"1272\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#标签\",\"1273\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#基于自生成的\",\"1274\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E8%AE%AD%E7%BB%83%E7%9A%84trick%E5%92%8C%E9%97%AE%E9%A2%98/#行动清单-1\",\"1275\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge-Distillation-%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/#if-基于指令跟随的蒸馏\",\"1276\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/%E4%BB%8B%E7%BB%8D/#来源标注\",\"1277\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-V3/#创新启示\",\"1278\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-3/#与gpt-2区别\",\"1279\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Switch-Transformer/#负载均衡损失设计\",\"1280\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen2/#常见错误警告\",\"1281\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/BERT%E4%B8%8ERNN%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E7%9A%84%E5%AF%B9%E6%AF%94%E4%B8%8E%E5%BA%94%E7%94%A8/#bert的可学习位置编码\",\"1282\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84Scaling-Law/#_2-数据与模型尺寸的平衡\",\"1283\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E5%8E%9F%E7%90%86/#规划-planning\",\"1284\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#_1-确保数据的准确性\",\"1285\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96%E4%B8%AD%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E9%98%B6%E6%AE%B5/#多级索引\",\"1286\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/\",\"1287\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/Deepseek-V1/#行动清单\",\"1288\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/DeBERTa%E7%9A%84%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8E%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%A7%A3%E6%9E%90/#下游任务微调方式\",\"1289\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E5%8E%86%E5%8F%B2%E5%8F%91%E5%B1%95/#level-2-reasoners\",\"1290\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/Deepseek-math/#数据表格\",\"1291\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#multiagent-多样化的智能体协作与集体决策\",\"1292\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM3/#数据表格\",\"1293\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-1/#常见错误\",\"1294\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/RoBERTa/#行动清单\",\"1295\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#常见错误\",\"1296\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/Transformer%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%AF%A6%E8%A7%A3%E4%B8%8E%E6%94%B9%E8%BF%9B%E5%88%86%E6%9E%90/#_2-编码可视化特点\",\"1297\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5/#最优-batch-size-的选择\",\"1298\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/PLaM%E7%B3%BB%E5%88%97/PaLM/#操作步骤\",\"1299\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83%E4%B8%8E%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E5%8C%BA%E5%88%AB/#重点步骤\",\"1300\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E6%A1%86%E6%9E%B6%E5%92%8C%E5%BA%94%E7%94%A8/#多智能体协作框架\",\"1301\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/PLaM%E7%B3%BB%E5%88%97/PLaM2/#常见错误\",\"1302\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E8%AE%AD%E7%BB%83Tokenizer/#✅-tokenizer训练步骤\",\"1303\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-2/#💡-启发点\",\"1304\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen1/#操作步骤\",\"1305\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen2.5/#操作步骤\",\"1306\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/T5%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%BC%98%E5%8C%96%E8%A7%A3%E6%9E%90/#设计思想的直观性\",\"1307\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/FastText/#行动清单-📋\",\"1308\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/#qat-量化感知训练\",\"1309\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/\",\"1310\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/LLama%E7%B3%BB%E5%88%97/LLaMA1/#行动清单\",\"1311\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/LLama%E7%B3%BB%E5%88%97/LLama-2/#常见错误\",\"1312\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%AB%98%E6%95%88%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E9%80%89%E6%8B%A9%E4%B8%8E%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97/#主要内容\",\"1313\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8EXLNet%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%AF%A6%E8%A7%A3-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Transformer%E6%9C%BA%E5%88%B6/#xlnet中的位置编码\",\"1314\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/LLama%E7%B3%BB%E5%88%97/LLama-3/#常见错误\",\"1315\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/Agent%E8%AF%84%E4%BC%B0%E6%A1%86%E6%9E%B6%E6%B1%87%E6%80%BB/#toolemu\",\"1316\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%B3%BB%E7%BB%9F%E5%88%86%E7%B1%BB/#自主智能体-autonomous-agent\",\"1317\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/GShard/#💡启发点\",\"1318\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-V2/#数据转换\",\"1319\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#日期\",\"1320\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9B%BA%E5%AE%9A%E9%95%BF%E5%BA%A6%E5%88%86%E5%9D%97/\",\"1321\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%88%86%E5%9D%97/\",\"1322\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#示例格式\",\"1323\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E8%AE%AD%E7%BB%83%E7%9A%84trick%E5%92%8C%E9%97%AE%E9%A2%98/#数据表格示例\",\"1324\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-V3/#应用路线图\",\"1325\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-3/#常见错误\",\"1326\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Switch-Transformer/#数据表格\",\"1327\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen2/#行动清单\",\"1328\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/BERT%E4%B8%8ERNN%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E7%9A%84%E5%AF%B9%E6%AF%94%E4%B8%8E%E5%BA%94%E7%94%A8/#rnn位置编码\",\"1329\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84Scaling-Law/#_3-scaling-law实验结果\",\"1330\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E5%8E%9F%E7%90%86/#子目标分解\",\"1331\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#_2-基本数据清理\",\"1332\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96%E4%B8%AD%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E9%98%B6%E6%AE%B5/#多级路由机制\",\"1333\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#什么是rag\",\"1334\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9F%BA%E4%BA%8E%E6%96%87%E6%A1%A3%E7%BB%93%E6%9E%84%E5%88%86%E5%9D%97/\",\"1335\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/DeBERTa%E7%9A%84%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8E%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%A7%A3%E6%9E%90/#常见错误\",\"1336\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E5%8E%86%E5%8F%B2%E5%8F%91%E5%B1%95/#level-3-agents\",\"1337\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/Deepseek-math/#操作步骤\",\"1338\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#多个智能体系统的核心特征\",\"1339\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GLM%E7%B3%BB%E5%88%97/GLM3/#行动清单\",\"1340\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-1/#💡启发点\",\"1341\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/RoBERTa/#数据表格\",\"1342\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#💡启发点\",\"1343\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/Transformer%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%AF%A6%E8%A7%A3%E4%B8%8E%E6%94%B9%E8%BF%9B%E5%88%86%E6%9E%90/#_3-缺点与局限性\",\"1344\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5/#wsd-调度器的三阶段学习率策略\",\"1345\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/PLaM%E7%B3%BB%E5%88%97/PaLM/#常见错误\",\"1346\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83%E4%B8%8E%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E5%8C%BA%E5%88%AB/#常见错误\",\"1347\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E6%A1%86%E6%9E%B6%E5%92%8C%E5%BA%94%E7%94%A8/#可视化低代码平台\",\"1348\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/PLaM%E7%B3%BB%E5%88%97/PLaM2/#💡-启发点\",\"1349\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E8%AE%AD%E7%BB%83Tokenizer/#中文预训练的独特挑战\",\"1350\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-2/#行动清单\",\"1351\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen1/#常见错误\",\"1352\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen2.5/#常见错误\",\"1353\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/T5%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%BC%98%E5%8C%96%E8%A7%A3%E6%9E%90/#操作步骤\",\"1354\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%B5%8C%E5%85%A5/FastText/#思考-延伸问题\",\"1355\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/#量化感知训练的基本原理\",\"1356\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#rag评估的核心维度\",\"1357\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/LLama%E7%B3%BB%E5%88%97/LLama-2/#💡-启发点\",\"1358\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%AB%98%E6%95%88%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E9%80%89%E6%8B%A9%E4%B8%8E%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97/#模型结构与参数选择\",\"1359\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8EXLNet%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%AF%A6%E8%A7%A3-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Transformer%E6%9C%BA%E5%88%B6/#核心公式展开\",\"1360\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/LLama%E7%B3%BB%E5%88%97/LLama-3/#数据表格\",\"1361\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/Agent%E8%AF%84%E4%BC%B0%E6%A1%86%E6%9E%B6%E6%B1%87%E6%80%BB/#核心目标\",\"1362\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%B3%BB%E7%BB%9F%E5%88%86%E7%B1%BB/#基础构建模块-增强型-llm\",\"1363\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/GShard/#行动清单\",\"1364\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-V2/#公式显示\",\"1365\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#内容概述\",\"1366\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9B%BA%E5%AE%9A%E9%95%BF%E5%BA%A6%E5%88%86%E5%9D%97/#最简单直观的文本分块方法\",\"1367\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%88%86%E5%9D%97/#dense-x-retrieval-检索粒度的选择\",\"1368\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#cross-task-generalization-via-natural-language-crowdsourcing-instructions\",\"1369\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E8%AE%AD%E7%BB%83%E7%9A%84trick%E5%92%8C%E9%97%AE%E9%A2%98/#来源标注\",\"1370\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-3/#行动清单\",\"1371\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Switch-Transformer/#常见错误\",\"1372\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen2/#💡-启发点\",\"1373\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/BERT%E4%B8%8ERNN%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E7%9A%84%E5%AF%B9%E6%AF%94%E4%B8%8E%E5%BA%94%E7%94%A8/#数据呈现\",\"1374\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84Scaling-Law/#操作步骤\",\"1375\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E5%8E%9F%E7%90%86/#目的\",\"1376\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#_3-实体解析\",\"1377\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96%E4%B8%AD%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E9%98%B6%E6%AE%B5/#索引-查询算法\",\"1378\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#llm本身的局限性\",\"1379\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9F%BA%E4%BA%8E%E6%96%87%E6%A1%A3%E7%BB%93%E6%9E%84%E5%88%86%E5%9D%97/#利用文档内部结构进行分块\",\"1380\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9F%BA%E4%BA%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%9D%97/\",\"1381\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/DeBERTa%E7%9A%84%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8E%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%A7%A3%E6%9E%90/#行动清单\",\"1382\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E5%8E%86%E5%8F%B2%E5%8F%91%E5%B1%95/#level-4-innovators\",\"1383\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/Deepseek-math/#常见错误\",\"1384\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#多个智能体系统的优势\",\"1385\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-1/#行动清单\",\"1386\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/BERT%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/RoBERTa/#来源标注\",\"1387\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#行动清单\",\"1388\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/Transformer%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%AF%A6%E8%A7%A3%E4%B8%8E%E6%94%B9%E8%BF%9B%E5%88%86%E6%9E%90/#_4-改进方向\",\"1389\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5/#提高效率的预训练技巧\",\"1390\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/PLaM%E7%B3%BB%E5%88%97/PaLM/#数据与公式\",\"1391\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83%E4%B8%8E%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E5%8C%BA%E5%88%AB/#💡启发点\",\"1392\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E6%A1%86%E6%9E%B6%E5%92%8C%E5%BA%94%E7%94%A8/#使用这些框架时的注意事项\",\"1393\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/PLaM%E7%B3%BB%E5%88%97/PLaM2/#数据表格\",\"1394\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E8%AE%AD%E7%BB%83Tokenizer/#⚠-常见问题\",\"1395\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-2/#数据转换\",\"1396\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%B8%B8%E8%A7%81%E7%B4%A2%E5%BC%95%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/\",\"1397\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen1/#💡-启发点\",\"1398\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen2.5/#数据表格\",\"1399\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/T5%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%BC%98%E5%8C%96%E8%A7%A3%E6%9E%90/#常见错误\",\"1400\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/#qat方法\",\"1401\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/DPO%E4%BB%8B%E7%BB%8D%E5%8F%8ARLHF-PPO%E7%BC%BA%E7%82%B9/\",\"1402\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#rag的难点\",\"1403\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/LLama%E7%B3%BB%E5%88%97/LLama-2/#行动清单\",\"1404\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%AB%98%E6%95%88%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E9%80%89%E6%8B%A9%E4%B8%8E%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97/#训练框架推荐\",\"1405\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8EXLNet%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%AF%A6%E8%A7%A3-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Transformer%E6%9C%BA%E5%88%B6/#操作步骤\",\"1406\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/LLama%E7%B3%BB%E5%88%97/LLama-3/#行动清单\",\"1407\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/Agent%E8%AF%84%E4%BC%B0%E6%A1%86%E6%9E%B6%E6%B1%87%E6%80%BB/#评估方式-1\",\"1408\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%B3%BB%E7%BB%9F%E5%88%86%E7%B1%BB/#自主智能体-autonomous-agent-1\",\"1409\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/GShard/#数据转换\",\"1410\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#分布式初始化\",\"1411\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9B%BA%E5%AE%9A%E9%95%BF%E5%BA%A6%E5%88%86%E5%9D%97/#问题与挑战\",\"1412\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%88%86%E5%9D%97/#proposition-的特点\",\"1413\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#示例顺序\",\"1414\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E8%AE%AD%E7%BB%83%E7%9A%84trick%E5%92%8C%E9%97%AE%E9%A2%98/#强化学习中的奖励利用与泛化问题\",\"1415\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/DPO%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/\",\"1416\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-3/#数据表格\",\"1417\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Switch-Transformer/#行动清单\",\"1418\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/BERT%E4%B8%8ERNN%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E7%9A%84%E5%AF%B9%E6%AF%94%E4%B8%8E%E5%BA%94%E7%94%A8/#通俗化说明\",\"1419\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84Scaling-Law/#数据表格\",\"1420\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E5%8E%9F%E7%90%86/#任务分解的实现方式\",\"1421\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#文档划分\",\"1422\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96%E4%B8%AD%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E9%98%B6%E6%AE%B5/#常见的向量搜索算法\",\"1423\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#_1-知识的局限性\",\"1424\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9F%BA%E4%BA%8E%E6%96%87%E6%A1%A3%E7%BB%93%E6%9E%84%E5%88%86%E5%9D%97/#优点\",\"1425\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9F%BA%E4%BA%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%9D%97/#什么是基于语义分块\",\"1426\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/%E4%BA%BA%E7%B1%BB%E5%BB%BA%E6%A8%A1%E5%81%8F%E5%A5%BD%E8%A7%92%E5%BA%A6%E7%90%86%E8%A7%A3DPO/\",\"1427\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/DeBERTa%E7%9A%84%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8E%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%A7%A3%E6%9E%90/#📈-趋势预测\",\"1428\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E8%A7%92%E5%BA%A6%E7%90%86%E8%A7%A3DPO/\",\"1429\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E5%8E%86%E5%8F%B2%E5%8F%91%E5%B1%95/#level-5-organizers\",\"1430\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/Deepseek-math/#💡启发点\",\"1431\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#应用场景\",\"1432\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/%E6%B7%B1%E5%BA%A6%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96%EF%BC%88DPO%EF%BC%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%A7%A3%E6%9E%90%E4%B8%8E%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B/\",\"1433\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Actor-Model/\",\"1434\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#method\",\"1435\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/Transformer%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%AF%A6%E8%A7%A3%E4%B8%8E%E6%94%B9%E8%BF%9B%E5%88%86%E6%9E%90/#示例代码\",\"1436\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5/#✅-四阶段预训练设置流程\",\"1437\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/PLaM%E7%B3%BB%E5%88%97/PaLM/#公式\",\"1438\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83%E4%B8%8E%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E5%8C%BA%E5%88%AB/#行动清单\",\"1439\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E6%A1%86%E6%9E%B6%E5%92%8C%E5%BA%94%E7%94%A8/#单智能体应用\",\"1440\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Instruct-GPT/\",\"1441\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/PLaM%E7%B3%BB%E5%88%97/PLaM2/#行动清单\",\"1442\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E8%AE%AD%E7%BB%83Tokenizer/#词表扩充实例对比\",\"1443\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/RLHF%E6%B5%81%E7%A8%8B/\",\"1444\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen1/#行动清单\",\"1445\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/RLHF%E6%B5%81%E7%A8%8B2/\",\"1446\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen2.5/#💡启发点\",\"1447\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/T5%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%BC%98%E5%8C%96%E8%A7%A3%E6%9E%90/#思考-延伸问题\",\"1448\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/#llm-qat\",\"1449\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/DPO%E4%BB%8B%E7%BB%8D%E5%8F%8ARLHF-PPO%E7%BC%BA%E7%82%B9/#元数据\",\"1450\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#_1-如何建立知识向量库\",\"1451\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%AB%98%E6%95%88%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E9%80%89%E6%8B%A9%E4%B8%8E%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97/#选择megatron-lm的原因\",\"1452\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8EXLNet%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%AF%A6%E8%A7%A3-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Transformer%E6%9C%BA%E5%88%B6/#常见错误\",\"1453\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/Agent%E8%AF%84%E4%BC%B0%E6%A1%86%E6%9E%B6%E6%B1%87%E6%80%BB/#agentboard-的核心目标\",\"1454\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%B3%BB%E7%BB%9F%E5%88%86%E7%B1%BB/#_1-执行过程中获取环境真实反馈\",\"1455\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/GShard/#公式显示\",\"1456\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#fwd与bwd过程\",\"1457\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9B%BA%E5%AE%9A%E9%95%BF%E5%BA%A6%E5%88%86%E5%9D%97/#上下文割裂\",\"1458\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%88%86%E5%9D%97/#llamaindex-的实现方案\",\"1459\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#icl-的挑战\",\"1460\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E8%AE%AD%E7%BB%83%E7%9A%84trick%E5%92%8C%E9%97%AE%E9%A2%98/#核心观点-1\",\"1461\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/DPO%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/#元数据\",\"1462\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GPT%E7%B3%BB%E5%88%97/GPT-3/#来源标注\",\"1463\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/BERT%E4%B8%8ERNN%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E7%9A%84%E5%AF%B9%E6%AF%94%E4%B8%8E%E5%BA%94%E7%94%A8/#常见错误提示\",\"1464\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84Scaling-Law/#📈-趋势预测\",\"1465\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E5%8E%9F%E7%90%86/#llm与pddl结合的规划方法\",\"1466\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#数据增强\",\"1467\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96%E4%B8%AD%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E9%98%B6%E6%AE%B5/#_1-聚类算法-k-means-等\",\"1468\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#_2-幻觉问题\",\"1469\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9F%BA%E4%BA%8E%E6%96%87%E6%A1%A3%E7%BB%93%E6%9E%84%E5%88%86%E5%9D%97/#前提条件\",\"1470\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9F%BA%E4%BA%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%9D%97/#做法\",\"1471\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/RL%E5%9C%A8NLP%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E6%8B%93%E5%B1%95/\",\"1472\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/DeBERTa%E7%9A%84%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8E%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%A7%A3%E6%9E%90/#思考-板块\",\"1473\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E8%A7%92%E5%BA%A6%E7%90%86%E8%A7%A3DPO/#元数据\",\"1474\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E5%8E%86%E5%8F%B2%E5%8F%91%E5%B1%95/#智能体的核心定义\",\"1475\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/Deepseek-math/#行动清单\",\"1476\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#按行为模式分类\",\"1477\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/%E6%B7%B1%E5%BA%A6%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96%EF%BC%88DPO%EF%BC%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%A7%A3%E6%9E%90%E4%B8%8E%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B/#分类\",\"1478\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Reference-Model/\",\"1479\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Actor-Model/#元数据\",\"1480\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#强化学习算法\",\"1481\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/Transformer%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%AF%A6%E8%A7%A3%E4%B8%8E%E6%94%B9%E8%BF%9B%E5%88%86%E6%9E%90/#思考-延伸问题\",\"1482\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5/#⚠-常见错误与注意事项\",\"1483\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/PLaM%E7%B3%BB%E5%88%97/PaLM/#数据表格\",\"1484\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83%E4%B8%8E%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E5%8C%BA%E5%88%AB/#📈趋势预测\",\"1485\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E6%A1%86%E6%9E%B6%E5%92%8C%E5%BA%94%E7%94%A8/#多智能体应用\",\"1486\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Instruct-GPT/#元数据\",\"1487\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E8%AE%AD%E7%BB%83Tokenizer/#📊-数据表格示例\",\"1488\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/RLHF%E6%B5%81%E7%A8%8B/#分类\",\"1489\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Reward-Model/\",\"1490\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen1/#数据转换\",\"1491\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/RLHF%E6%B5%81%E7%A8%8B2/#核心观点总结\",\"1492\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen2.5/#行动清单\",\"1493\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/T5%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%BC%98%E5%8C%96%E8%A7%A3%E6%9E%90/#行动清单\",\"1494\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/#qaf-量化感知微调\",\"1495\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/DPO%E4%BB%8B%E7%BB%8D%E5%8F%8ARLHF-PPO%E7%BC%BA%E7%82%B9/#内容概述\",\"1496\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#_2-检索优化\",\"1497\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/critic-model/\",\"1498\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%AB%98%E6%95%88%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E9%80%89%E6%8B%A9%E4%B8%8E%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97/#操作步骤\",\"1499\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8EXLNet%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%AF%A6%E8%A7%A3-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Transformer%E6%9C%BA%E5%88%B6/#数据表格-截断范围示例\",\"1500\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/Agent%E8%AF%84%E4%BC%B0%E6%A1%86%E6%9E%B6%E6%B1%87%E6%80%BB/#agentboard-的评估方法与指标\",\"1501\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%B3%BB%E7%BB%9F%E5%88%86%E7%B1%BB/#_2-支持人工检查点干预\",\"1502\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#关键步骤\",\"1503\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9B%BA%E5%AE%9A%E9%95%BF%E5%BA%A6%E5%88%86%E5%9D%97/#语义完整性受损\",\"1504\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#_1-长上下文问题\",\"1505\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E8%AE%AD%E7%BB%83%E7%9A%84trick%E5%92%8C%E9%97%AE%E9%A2%98/#重点段落-1\",\"1506\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/DPO%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/#核心目标函数推导\",\"1507\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/BERT%E4%B8%8ERNN%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E7%9A%84%E5%AF%B9%E6%AF%94%E4%B8%8E%E5%BA%94%E7%94%A8/#启发标注\",\"1508\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84Scaling-Law/#思考-板块\",\"1509\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E5%8E%9F%E7%90%86/#反思与完善\",\"1510\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#用户反馈循环\",\"1511\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96%E4%B8%AD%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E9%98%B6%E6%AE%B5/#_2-位置敏感哈希\",\"1512\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#_3-数据安全性\",\"1513\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9F%BA%E4%BA%8E%E6%96%87%E6%A1%A3%E7%BB%93%E6%9E%84%E5%88%86%E5%9D%97/#不同长度的问题\",\"1514\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9F%BA%E4%BA%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%9D%97/#优势\",\"1515\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/RL%E5%9C%A8NLP%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E6%8B%93%E5%B1%95/#核心观点总结\",\"1516\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/%E5%9C%A8%E7%BA%BF%E4%B8%8E%E7%A6%BB%E7%BA%BFRLHF%E7%9A%84%E6%AF%94%E8%BE%83%E4%B8%8E%E5%BA%94%E7%94%A8/\",\"1517\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E8%A7%92%E5%BA%A6%E7%90%86%E8%A7%A3DPO/#内容概述\",\"1518\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E5%8E%86%E5%8F%B2%E5%8F%91%E5%B1%95/#感知-智能体的-眼睛\",\"1519\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/LLM%E5%AF%B9%E9%BD%90%E4%B8%8B%E7%9A%84RLHF_PPO/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Prompt%E5%88%B0Response%E7%9A%84MDP%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90/\",\"1520\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#tool-use-agent\",\"1521\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/%E6%B7%B1%E5%BA%A6%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96%EF%BC%88DPO%EF%BC%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%A7%A3%E6%9E%90%E4%B8%8E%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B/#标签\",\"1522\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Reference-Model/#核心观点总结\",\"1523\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Actor-Model/#文章内容\",\"1524\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96DPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DPOP/\",\"1525\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#重点段落\",\"1526\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5/#📈-趋势预测\",\"1527\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/PLaM%E7%B3%BB%E5%88%97/PaLM/#行动清单\",\"1528\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83%E4%B8%8E%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E5%8C%BA%E5%88%AB/#后续追踪\",\"1529\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E6%A1%86%E6%9E%B6%E5%92%8C%E5%BA%94%E7%94%A8/#agent-rl-框架\",\"1530\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Instruct-GPT/#内容概述\",\"1531\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E8%AE%AD%E7%BB%83Tokenizer/#技术术语通俗解释\",\"1532\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/RLHF%E6%B5%81%E7%A8%8B/#标签\",\"1533\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Reward-Model/#核心观点总结\",\"1534\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96DPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/Self-Reward/\",\"1535\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Qwen%E7%B3%BB%E5%88%97/Qwen1/#公式显示\",\"1536\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/RLHF%E6%B5%81%E7%A8%8B2/#重点段落\",\"1537\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/T5%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%BC%98%E5%8C%96%E8%A7%A3%E6%9E%90/#📈-趋势预测\",\"1538\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/#qaf方法\",\"1539\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/DPO%E4%BB%8B%E7%BB%8D%E5%8F%8ARLHF-PPO%E7%BC%BA%E7%82%B9/#核心观点\",\"1540\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#_3-归纳总结\",\"1541\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/critic-model/#核心观点总结\",\"1542\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%AB%98%E6%95%88%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E9%80%89%E6%8B%A9%E4%B8%8E%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97/#如何选择与配置训练框架\",\"1543\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8EXLNet%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%AF%A6%E8%A7%A3-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Transformer%E6%9C%BA%E5%88%B6/#📈-趋势预测\",\"1544\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/Agent%E8%AF%84%E4%BC%B0%E6%A1%86%E6%9E%B6%E6%B1%87%E6%80%BB/#_1-处理率-process-rate\",\"1545\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%B3%BB%E7%BB%9F%E5%88%86%E7%B1%BB/#_3-设置终止条件\",\"1546\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96DPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/TDPO/\",\"1547\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#常见错误\",\"1548\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9B%BA%E5%AE%9A%E9%95%BF%E5%BA%A6%E5%88%86%E5%9D%97/#改进方法\",\"1549\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/AdaLoRA/\",\"1550\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#_2-选择适当的上下文\",\"1551\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E8%AE%AD%E7%BB%83%E7%9A%84trick%E5%92%8C%E9%97%AE%E9%A2%98/#操作步骤-2\",\"1552\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/DPO%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/#_1-原始约束目标\",\"1553\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/DoRA/\",\"1554\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/LoRA_/\",\"1555\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/BERT%E4%B8%8ERNN%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E7%9A%84%E5%AF%B9%E6%AF%94%E4%B8%8E%E5%BA%94%E7%94%A8/#行动清单\",\"1556\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84Scaling-Law/#行动清单\",\"1557\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E5%8E%9F%E7%90%86/#自我批评与反思\",\"1558\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#时间敏感数据处理\",\"1559\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96%E4%B8%AD%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E9%98%B6%E6%AE%B5/#核心思想\",\"1560\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#rag的特点\",\"1561\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9F%BA%E4%BA%8E%E6%96%87%E6%A1%A3%E7%BB%93%E6%9E%84%E5%88%86%E5%9D%97/#解决方案-结合递归式分块\",\"1562\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9F%BA%E4%BA%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%9D%97/#局限性\",\"1563\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/RL%E5%9C%A8NLP%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E6%8B%93%E5%B1%95/#重点段落\",\"1564\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/%E5%9C%A8%E7%BA%BF%E4%B8%8E%E7%A6%BB%E7%BA%BFRLHF%E7%9A%84%E6%AF%94%E8%BE%83%E4%B8%8E%E5%BA%94%E7%94%A8/#在线与离线rlhf的核心思想\",\"1565\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/LoRA-FA/\",\"1566\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E8%A7%92%E5%BA%A6%E7%90%86%E8%A7%A3DPO/#核心观点\",\"1567\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E5%8E%86%E5%8F%B2%E5%8F%91%E5%B1%95/#决策-智能体的-大脑\",\"1568\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/LLM%E5%AF%B9%E9%BD%90%E4%B8%8B%E7%9A%84RLHF_PPO/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Prompt%E5%88%B0Response%E7%9A%84MDP%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90/#元数据\",\"1569\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#mrkl-system-modular-reasoning-knowledge-and-language\",\"1570\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/%E6%B7%B1%E5%BA%A6%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96%EF%BC%88DPO%EF%BC%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%A7%A3%E6%9E%90%E4%B8%8E%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B/#日期\",\"1571\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Reference-Model/#重点内容\",\"1572\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Actor-Model/#核心观点\",\"1573\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/LoRA/\",\"1574\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/QLoRA/\",\"1575\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96DPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DPOP/#元数据\",\"1576\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#强化学习算法的优化\",\"1577\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5/#思考-延伸问题\",\"1578\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E6%A1%86%E6%9E%B6%E5%92%8C%E5%BA%94%E7%94%A8/#结合-llm-与-rl-的双向优势\",\"1579\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Instruct-GPT/#关键流程与技术\",\"1580\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E8%AE%AD%E7%BB%83Tokenizer/#思考-板块\",\"1581\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/RLHF%E6%B5%81%E7%A8%8B/#日期\",\"1582\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Reward-Model/#奖励模型训练\",\"1583\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/VeRA/\",\"1584\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96DPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/Self-Reward/#分类-机器学习\",\"1585\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/X-LoRA/\",\"1586\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/RLHF%E6%B5%81%E7%A8%8B2/#操作步骤\",\"1587\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/T5%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%BC%98%E5%8C%96%E8%A7%A3%E6%9E%90/#后续追踪\",\"1588\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/#peqa-memory-efficient-fine-tuning-of-compressed-large-language-models-via-sub-4-bit-integer-quantization\",\"1589\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/DPO%E4%BB%8B%E7%BB%8D%E5%8F%8ARLHF-PPO%E7%BC%BA%E7%82%B9/#技术术语通俗解释\",\"1590\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#针对检索环节的评估\",\"1591\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/critic-model/#重点段落\",\"1592\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%AB%98%E6%95%88%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E9%80%89%E6%8B%A9%E4%B8%8E%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97/#常见错误\",\"1593\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8EXLNet%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%AF%A6%E8%A7%A3-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Transformer%E6%9C%BA%E5%88%B6/#思考-延伸问题\",\"1594\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/Agent%E8%AF%84%E4%BC%B0%E6%A1%86%E6%9E%B6%E6%B1%87%E6%80%BB/#_2-grounding-精度\",\"1595\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%B3%BB%E7%BB%9F%E5%88%86%E7%B1%BB/#工作流-workflow-1\",\"1596\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96DPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/TDPO/#tdpo与ppo中的kl约束\",\"1597\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#💡启发点\",\"1598\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9B%BA%E5%AE%9A%E9%95%BF%E5%BA%A6%E5%88%86%E5%9D%97/#_1-引入重叠\",\"1599\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/AdaLoRA/#元数据\",\"1600\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#_3-输出一致性\",\"1601\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E8%AE%AD%E7%BB%83%E7%9A%84trick%E5%92%8C%E9%97%AE%E9%A2%98/#常见错误-2\",\"1602\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/DPO%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/#_2-目标函数变形\",\"1603\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE/\",\"1604\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/DoRA/#元数据\",\"1605\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/LoRA_/#元数据\",\"1606\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/BERT%E4%B8%8ERNN%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E7%9A%84%E5%AF%B9%E6%AF%94%E4%B8%8E%E5%BA%94%E7%94%A8/#思考\",\"1607\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84Scaling-Law/#后续追踪\",\"1608\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E5%8E%9F%E7%90%86/#react-结合推理与行动\",\"1609\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#解析pdf文件的主流方法详解\",\"1610\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96%E4%B8%AD%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E9%98%B6%E6%AE%B5/#_3-查询转换\",\"1611\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#_1-依赖llm来强化信息检索和输出\",\"1612\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9F%BA%E4%BA%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%9D%97/#nltk-的文本切分功能\",\"1613\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/RL%E5%9C%A8NLP%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E6%8B%93%E5%B1%95/#nlp-mdp建模\",\"1614\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/%E5%9C%A8%E7%BA%BF%E4%B8%8E%E7%A6%BB%E7%BA%BFRLHF%E7%9A%84%E6%AF%94%E8%BE%83%E4%B8%8E%E5%BA%94%E7%94%A8/#在线-online-rlhf\",\"1615\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/LLaMA-Adapter/\",\"1616\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E8%A7%92%E5%BA%A6%E7%90%86%E8%A7%A3DPO/#重点段落\",\"1617\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E5%8E%86%E5%8F%B2%E5%8F%91%E5%B1%95/#与其讨论-agent-不如讨论-agentic\",\"1618\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/LLM%E5%AF%B9%E9%BD%90%E4%B8%8B%E7%9A%84RLHF_PPO/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Prompt%E5%88%B0Response%E7%9A%84MDP%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90/#内容概述\",\"1619\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#critic-self-correcting-with-tool-interactive-critiquing\",\"1620\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/%E6%B7%B1%E5%BA%A6%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96%EF%BC%88DPO%EF%BC%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%A7%A3%E6%9E%90%E4%B8%8E%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B/#内容概要\",\"1621\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Reference-Model/#kl约束在ppo训练中的应用\",\"1622\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Actor-Model/#重点段落\",\"1623\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/LoRA/#分类-机器学习\",\"1624\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/QLoRA/#元数据\",\"1625\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/P-Tuning-V2/\",\"1626\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96DPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DPOP/#内容概述\",\"1627\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/P-Tuning/\",\"1628\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#优化公式\",\"1629\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5/#行动清单\",\"1630\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E6%A1%86%E6%9E%B6%E5%92%8C%E5%BA%94%E7%94%A8/#gair-torl-框架\",\"1631\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Instruct-GPT/#instructgpt的训练流程\",\"1632\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E8%AE%AD%E7%BB%83Tokenizer/#常见错误警告区块\",\"1633\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/RLHF%E6%B5%81%E7%A8%8B/#研究背景\",\"1634\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Reward-Model/#与传统强化学习的对比\",\"1635\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/Prefix-Tuning/\",\"1636\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/VeRA/#核心观点\",\"1637\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96DPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/Self-Reward/#标签-语言模型、指令遵循、奖励评估、自我训练\",\"1638\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/X-LoRA/#元数据\",\"1639\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/RLHF%E6%B5%81%E7%A8%8B2/#常见错误\",\"1640\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/Prompt-Tuning/\",\"1641\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/#qlora\",\"1642\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/DPO%E4%BB%8B%E7%BB%8D%E5%8F%8ARLHF-PPO%E7%BC%BA%E7%82%B9/#操作步骤\",\"1643\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/%E4%BB%8B%E7%BB%8D/\",\"1644\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#mrr计算方法\",\"1645\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/critic-model/#技术术语转述\",\"1646\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%AB%98%E6%95%88%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E9%80%89%E6%8B%A9%E4%B8%8E%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97/#示例代码\",\"1647\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Positional-Encoding%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8EXLNet%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%AF%A6%E8%A7%A3-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Transformer%E6%9C%BA%E5%88%B6/#行动清单\",\"1648\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/Agent%E8%AF%84%E4%BC%B0%E6%A1%86%E6%9E%B6%E6%B1%87%E6%80%BB/#_3-简单和困难任务区分\",\"1649\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%B3%BB%E7%BB%9F%E5%88%86%E7%B1%BB/#_1-提示链-prompt-chaining\",\"1650\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96DPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/TDPO/#tdpo的优势\",\"1651\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#行动清单\",\"1652\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9B%BA%E5%AE%9A%E9%95%BF%E5%BA%A6%E5%88%86%E5%9D%97/#_2-智能截断\",\"1653\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/AdaLoRA/#核心观点\",\"1654\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/\",\"1655\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#chain-of-thought-思维链\",\"1656\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E8%AE%AD%E7%BB%83%E7%9A%84trick%E5%92%8C%E9%97%AE%E9%A2%98/#💡-启发点\",\"1657\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/DPO%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/#步骤1-展开kl散度\",\"1658\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE/#参考文献\",\"1659\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/DoRA/#核心观点\",\"1660\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/LoRA_/#内容摘要\",\"1661\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E5%8E%9F%E7%90%86/#记忆-memory\",\"1662\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#一、基于规则的解析算法\",\"1663\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96%E4%B8%AD%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E9%98%B6%E6%AE%B5/#结合历史对话的重新表述\",\"1664\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#_2-能与外部数据有效集成\",\"1665\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9F%BA%E4%BA%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%9D%97/#原理\",\"1666\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/RL%E5%9C%A8NLP%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E6%8B%93%E5%B1%95/#强化学习优化目标\",\"1667\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/%E5%9C%A8%E7%BA%BF%E4%B8%8E%E7%A6%BB%E7%BA%BFRLHF%E7%9A%84%E6%AF%94%E8%BE%83%E4%B8%8E%E5%BA%94%E7%94%A8/#离线-offline-rlhf\",\"1668\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/LLaMA-Adapter/#核心观点总结\",\"1669\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/\",\"1670\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/REINFORCE%E7%AE%97%E6%B3%95%E6%94%B9%E8%BF%9B%EF%BC%9ARLOO%E4%B8%8EREINFORCE__/\",\"1671\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E8%A7%92%E5%BA%A6%E7%90%86%E8%A7%A3DPO/#对比学习的损失函数\",\"1672\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E5%8E%86%E5%8F%B2%E5%8F%91%E5%B1%95/#系统的-agentic-程度由什么决定\",\"1673\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/LLM%E5%AF%B9%E9%BD%90%E4%B8%8B%E7%9A%84RLHF_PPO/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Prompt%E5%88%B0Response%E7%9A%84MDP%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90/#核心观点总结\",\"1674\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#code-generation-agent\",\"1675\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/%E6%B7%B1%E5%BA%A6%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96%EF%BC%88DPO%EF%BC%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%A7%A3%E6%9E%90%E4%B8%8E%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B/#理解dpo损失函数\",\"1676\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Reference-Model/#奖励机制的调整\",\"1677\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Actor-Model/#操作步骤\",\"1678\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/LoRA/#标签-lora-微调-低秩矩阵-大语言模型\",\"1679\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/QLoRA/#内容摘要\",\"1680\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/P-Tuning-V2/#核心观点总结\",\"1681\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96DPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DPOP/#核心观点\",\"1682\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/P-Tuning/#元数据\",\"1683\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#优势函数计算\",\"1684\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E6%A1%86%E6%9E%B6%E5%92%8C%E5%BA%94%E7%94%A8/#核心理念\",\"1685\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Instruct-GPT/#强化学习目标修改\",\"1686\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E8%AE%AD%E7%BB%83Tokenizer/#行动清单\",\"1687\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/RLHF%E6%B5%81%E7%A8%8B/#研究目标\",\"1688\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Reward-Model/#聚合操作\",\"1689\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/Prefix-Tuning/#元数据\",\"1690\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/VeRA/#重点段落\",\"1691\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96DPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/Self-Reward/#日期-2025年4月12日\",\"1692\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/X-LoRA/#核心观点\",\"1693\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/RLHF%E6%B5%81%E7%A8%8B2/#💡-启发点\",\"1694\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/Prompt-Tuning/#元数据\",\"1695\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/#peft-参数高效微调\",\"1696\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/DPO%E4%BB%8B%E7%BB%8D%E5%8F%8ARLHF-PPO%E7%BC%BA%E7%82%B9/#常见错误\",\"1697\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/%E4%BB%8B%E7%BB%8D/#分类-机器学习技术\",\"1698\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#mrr的意义\",\"1699\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/critic-model/#操作步骤\",\"1700\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%AB%98%E6%95%88%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E9%80%89%E6%8B%A9%E4%B8%8E%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97/#📈趋势预测\",\"1701\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/Agent%E8%AF%84%E4%BC%B0%E6%A1%86%E6%9E%B6%E6%B1%87%E6%80%BB/#_4-多回合交互\",\"1702\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%B3%BB%E7%BB%9F%E5%88%86%E7%B1%BB/#定义\",\"1703\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96DPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/TDPO/#代码示例与计算步骤\",\"1704\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#路由与门控机制\",\"1705\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9B%BA%E5%AE%9A%E9%95%BF%E5%BA%A6%E5%88%86%E5%9D%97/#langchain-的优化方案\",\"1706\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/AdaLoRA/#重点段落\",\"1707\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#元数据\",\"1708\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#cot-概念原理\",\"1709\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PPO%E8%AE%AD%E7%BB%83%E7%9A%84trick%E5%92%8C%E9%97%AE%E9%A2%98/#行动清单-2\",\"1710\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax-improvement/\",\"1711\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax/\",\"1712\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/DPO%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/#步骤2-转换为最小化问题\",\"1713\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/DoRA/#重点段落\",\"1714\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/LoRA_/#核心内容\",\"1715\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E5%8E%9F%E7%90%86/#短期记忆与长期记忆\",\"1716\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#方法简介\",\"1717\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96%E4%B8%AD%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E9%98%B6%E6%AE%B5/#假设文档嵌入-hyde\",\"1718\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#_3-数据隐私和安全保障\",\"1719\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9F%BA%E4%BA%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%9D%97/#中文支持现状\",\"1720\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/RL%E5%9C%A8NLP%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E6%8B%93%E5%B1%95/#行为约束优化目标\",\"1721\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/%E5%9C%A8%E7%BA%BF%E4%B8%8E%E7%A6%BB%E7%BA%BFRLHF%E7%9A%84%E6%AF%94%E8%BE%83%E4%B8%8E%E5%BA%94%E7%94%A8/#关键步骤\",\"1722\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/LLaMA-Adapter/#重点段落与数据\",\"1723\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#分类-自动推断为机器学习与强化学习\",\"1724\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/VAPO/\",\"1725\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6/HuggingFace-TGI/\",\"1726\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/REINFORCE%E7%AE%97%E6%B3%95%E6%94%B9%E8%BF%9B%EF%BC%9ARLOO%E4%B8%8EREINFORCE__/#元数据\",\"1727\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E8%A7%92%E5%BA%A6%E7%90%86%E8%A7%A3DPO/#dpo中的损失函数\",\"1728\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E5%8E%86%E5%8F%B2%E5%8F%91%E5%B1%95/#_1-初步的-agentic-路由器-router\",\"1729\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/LLM%E5%AF%B9%E9%BD%90%E4%B8%8B%E7%9A%84RLHF_PPO/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Prompt%E5%88%B0Response%E7%9A%84MDP%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90/#重点段落\",\"1730\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#program-aided-lm\",\"1731\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/%E6%B7%B1%E5%BA%A6%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96%EF%BC%88DPO%EF%BC%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%A7%A3%E6%9E%90%E4%B8%8E%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B/#核心代码解析\",\"1732\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Reference-Model/#奖励公式的具体表达\",\"1733\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Actor-Model/#常见错误\",\"1734\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/LoRA/#日期-2025年4月12日\",\"1735\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/QLoRA/#核心观点\",\"1736\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/P-Tuning-V2/#重点段落\",\"1737\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96DPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DPOP/#重点段落\",\"1738\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/P-Tuning/#内容概述\",\"1739\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#奖励建模\",\"1740\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E6%A1%86%E6%9E%B6%E5%92%8C%E5%BA%94%E7%94%A8/#具体做法\",\"1741\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Instruct-GPT/#警告区块\",\"1742\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E8%AE%AD%E7%BB%83Tokenizer/#📈趋势预测\",\"1743\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/RLHF%E6%B5%81%E7%A8%8B/#常见错误\",\"1744\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Reward-Model/#操作步骤\",\"1745\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/Prefix-Tuning/#核心观点总结\",\"1746\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/VeRA/#_1-vera的创新机制\",\"1747\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96DPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/Self-Reward/#核心观点总结\",\"1748\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6/vLLM/\",\"1749\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/X-LoRA/#重点内容\",\"1750\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/\",\"1751\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/RLHF%E6%B5%81%E7%A8%8B2/#行动清单\",\"1752\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/Prompt-Tuning/#核心观点总结\",\"1753\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/#ptq-训练后量化\",\"1754\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/DPO%E4%BB%8B%E7%BB%8D%E5%8F%8ARLHF-PPO%E7%BC%BA%E7%82%B9/#💡启发点\",\"1755\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/%E4%BB%8B%E7%BB%8D/#标签-peft-微调-大模型-参数优化\",\"1756\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#示例计算\",\"1757\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/critic-model/#常见错误\",\"1758\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%AB%98%E6%95%88%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E9%80%89%E6%8B%A9%E4%B8%8E%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97/#思考-延伸问题\",\"1759\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/Agent%E8%AF%84%E4%BC%B0%E6%A1%86%E6%9E%B6%E6%B1%87%E6%80%BB/#_5-各项子能力分析\",\"1760\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%B3%BB%E7%BB%9F%E5%88%86%E7%B1%BB/#适用场景\",\"1761\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96DPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/TDPO/#操作步骤\",\"1762\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#优化细节\",\"1763\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9B%BA%E5%AE%9A%E9%95%BF%E5%BA%A6%E5%88%86%E5%9D%97/#recursivecharactertextsplitter\",\"1764\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/AdaLoRA/#动态秩分配\",\"1765\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#内容概述\",\"1766\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#cot-和普通提示的区别\",\"1767\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax-improvement/#标签\",\"1768\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax/#分类\",\"1769\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/DPO%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/#_3-引入配分函数\",\"1770\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/DoRA/#dora的基本步骤\",\"1771\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/LoRA_/#lora-优化器创建\",\"1772\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E5%8E%9F%E7%90%86/#短期记忆-上下文学习\",\"1773\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#优点\",\"1774\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96%E4%B8%AD%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E9%98%B6%E6%AE%B5/#退后提示-step-back-prompting\",\"1775\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#_4-表现效果因多方面因素而异\",\"1776\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9F%BA%E4%BA%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%9D%97/#在-langchain-中的应用\",\"1777\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/RL%E5%9C%A8NLP%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E6%8B%93%E5%B1%95/#常见错误\",\"1778\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/%E5%9C%A8%E7%BA%BF%E4%B8%8E%E7%A6%BB%E7%BA%BFRLHF%E7%9A%84%E6%AF%94%E8%BE%83%E4%B8%8E%E5%BA%94%E7%94%A8/#常见错误\",\"1779\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/LLaMA-Adapter/#操作步骤\",\"1780\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#标签-ppo优化、grpo、强化学习、actor-critic、llm\",\"1781\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/VAPO/#分类-自动推断\",\"1782\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6/HuggingFace-TGI/#prefill和decode\",\"1783\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/REINFORCE%E7%AE%97%E6%B3%95%E6%94%B9%E8%BF%9B%EF%BC%9ARLOO%E4%B8%8EREINFORCE__/#核心观点总结\",\"1784\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E8%A7%92%E5%BA%A6%E7%90%86%E8%A7%A3DPO/#操作步骤\",\"1785\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/%E4%BB%8B%E7%BB%8D/\",\"1786\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E5%8E%86%E5%8F%B2%E5%8F%91%E5%B1%95/#_2-多级路由决策-介于路由器与状态机之间\",\"1787\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/LLM%E5%AF%B9%E9%BD%90%E4%B8%8B%E7%9A%84RLHF_PPO/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Prompt%E5%88%B0Response%E7%9A%84MDP%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90/#单步mdp模型\",\"1788\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#tool-integrated-reasoning-agent\",\"1789\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/%E6%B7%B1%E5%BA%A6%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96%EF%BC%88DPO%EF%BC%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%A7%A3%E6%9E%90%E4%B8%8E%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B/#操作步骤\",\"1790\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Reference-Model/#操作步骤\",\"1791\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Actor-Model/#💡启发点\",\"1792\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/LoRA/#文章概述\",\"1793\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/QLoRA/#技术术语通俗解释\",\"1794\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/P-Tuning-V2/#技术术语通俗转述\",\"1795\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96DPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DPOP/#dpop算法的痛点解决\",\"1796\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/P-Tuning/#主要观点\",\"1797\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#奖励建模核心观点\",\"1798\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E6%A1%86%E6%9E%B6%E5%92%8C%E5%BA%94%E7%94%A8/#openmanus-openmanus-rl-框架\",\"1799\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Instruct-GPT/#💡启发点\",\"1800\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E8%AE%AD%E7%BB%83Tokenizer/#后续追踪方向\",\"1801\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/RLHF%E6%B5%81%E7%A8%8B/#💡启发点\",\"1802\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Reward-Model/#常见错误\",\"1803\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/Prefix-Tuning/#重点段落\",\"1804\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/VeRA/#_2-微调过程\",\"1805\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96DPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/Self-Reward/#实现方法\",\"1806\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/%E6%A0%87%E5%87%86Attention%E4%B8%8ESafe-softmax/\",\"1807\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/%E8%AE%A1%E7%AE%97%E4%B8%8E%E5%86%85%E5%AD%98%E9%99%90%E5%88%B6/\",\"1808\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6/vLLM/#vllm\",\"1809\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/X-LoRA/#动态缩放机制\",\"1810\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#tiling-分块计算\",\"1811\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/RLHF%E6%B5%81%E7%A8%8B2/#后续追踪\",\"1812\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/Prompt-Tuning/#重点段落\",\"1813\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/#qat-插入-伪量化节点-后微调\",\"1814\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/DPO%E4%BB%8B%E7%BB%8D%E5%8F%8ARLHF-PPO%E7%BC%BA%E7%82%B9/#行动清单\",\"1815\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/%E4%BB%8B%E7%BB%8D/#日期-2025年4月12日\",\"1816\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#mrr代码实现\",\"1817\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/critic-model/#代码示例\",\"1818\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%AB%98%E6%95%88%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E9%80%89%E6%8B%A9%E4%B8%8E%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97/#行动清单\",\"1819\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/Agent%E8%AF%84%E4%BC%B0%E6%A1%86%E6%9E%B6%E6%B1%87%E6%80%BB/#_6-探索能力\",\"1820\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%B3%BB%E7%BB%9F%E5%88%86%E7%B1%BB/#示例\",\"1821\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96DPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/TDPO/#常见错误\",\"1822\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#操作步骤\",\"1823\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9B%BA%E5%AE%9A%E9%95%BF%E5%BA%A6%E5%88%86%E5%9D%97/#使用示例\",\"1824\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/AdaLoRA/#svd参数化增量更新\",\"1825\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#dapo算法的核心改进\",\"1826\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#zero-shot-cot-与-few-shot-cot\",\"1827\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6%E5%8F%8A%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6/\",\"1828\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax-improvement/#日期\",\"1829\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax/#标签\",\"1830\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/DPO%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/#关键操作-构造指数形式\",\"1831\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/DoRA/#代码示例\",\"1832\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/LoRA_/#调整trainer类方法\",\"1833\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E5%8E%9F%E7%90%86/#长期记忆\",\"1834\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#缺点\",\"1835\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96%E4%B8%AD%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E9%98%B6%E6%AE%B5/#多查询检索-多路召回-multi-query-retrieval\",\"1836\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#rag流程与分类\",\"1837\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9F%BA%E4%BA%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%9D%97/#使用示例\",\"1838\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/RL%E5%9C%A8NLP%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E6%8B%93%E5%B1%95/#💡启发点\",\"1839\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/%E5%9C%A8%E7%BA%BF%E4%B8%8E%E7%A6%BB%E7%BA%BFRLHF%E7%9A%84%E6%AF%94%E8%BE%83%E4%B8%8E%E5%BA%94%E7%94%A8/#行动清单\",\"1840\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/LLaMA-Adapter/#常见错误\",\"1841\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#日期-2025年4月12日\",\"1842\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/VAPO/#标签-强化学习、vapo算法、推理任务\",\"1843\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6/HuggingFace-TGI/#concatenate和filter\",\"1844\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/REINFORCE%E7%AE%97%E6%B3%95%E6%94%B9%E8%BF%9B%EF%BC%9ARLOO%E4%B8%8EREINFORCE__/#重点段落\",\"1845\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E8%A7%92%E5%BA%A6%E7%90%86%E8%A7%A3DPO/#常见错误\",\"1846\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/%E4%BB%8B%E7%BB%8D/#核心观点总结\",\"1847\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E5%8E%86%E5%8F%B2%E5%8F%91%E5%B1%95/#_3-状态机-state-machine-允许循环运行\",\"1848\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/LLM%E5%AF%B9%E9%BD%90%E4%B8%8B%E7%9A%84RLHF_PPO/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Prompt%E5%88%B0Response%E7%9A%84MDP%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90/#多步mdp模型\",\"1849\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#taskweaver\",\"1850\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/%E6%B7%B1%E5%BA%A6%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96%EF%BC%88DPO%EF%BC%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%A7%A3%E6%9E%90%E4%B8%8E%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B/#常见错误\",\"1851\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Reference-Model/#常见错误\",\"1852\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Actor-Model/#行动清单\",\"1853\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/LoRA/#核心观点\",\"1854\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6%E5%8F%8A%E4%BC%98%E5%8C%96/%E9%A6%96Token%E6%97%B6%E5%BB%B6%E4%BC%98%E5%8C%96/\",\"1855\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/QLoRA/#操作步骤\",\"1856\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/P-Tuning-V2/#实施步骤\",\"1857\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96DPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DPOP/#正则化系数的应用\",\"1858\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/P-Tuning/#操作步骤\",\"1859\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#训练模板设计\",\"1860\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E6%A1%86%E6%9E%B6%E5%92%8C%E5%BA%94%E7%94%A8/#核心理念-1\",\"1861\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Instruct-GPT/#行动清单\",\"1862\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%88%86%E6%9E%90/%E6%98%BE%E5%AD%98%E4%BC%98%E5%8C%96%E4%B8%8E%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%88%86%E6%9E%90/\",\"1863\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/RLHF%E6%B5%81%E7%A8%8B/#行动清单\",\"1864\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Reward-Model/#💡启发点\",\"1865\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/Prefix-Tuning/#prefix-tuning的实现\",\"1866\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/VeRA/#_3-技术术语解释\",\"1867\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96DPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/Self-Reward/#初始化与种子数据\",\"1868\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/%E6%A0%87%E5%87%86Attention%E4%B8%8ESafe-softmax/#标准attention\",\"1869\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/%E8%AE%A1%E7%AE%97%E4%B8%8E%E5%86%85%E5%AD%98%E9%99%90%E5%88%B6/#近似注意力方法\",\"1870\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6/vLLM/#prefill\",\"1871\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/X-LoRA/#xloralinearlayer的前向传播\",\"1872\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#分块计算的难点\",\"1873\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/Prompt-Tuning/#prompt-tuning-的基本原理\",\"1874\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/#训练后量化-ptq\",\"1875\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/%E4%BB%8B%E7%BB%8D/#核心观点总结\",\"1876\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#mrr-衡量标准\",\"1877\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/critic-model/#💡启发点\",\"1878\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Pre-training-%E9%A2%84%E8%AE%AD%E7%BB%83/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/%E9%AB%98%E6%95%88%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E9%80%89%E6%8B%A9%E4%B8%8E%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97/#后续追踪\",\"1879\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%B3%BB%E7%BB%9F%E5%88%86%E7%B1%BB/#_2-路由-routing\",\"1880\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96DPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/TDPO/#行动清单\",\"1881\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#常见错误-1\",\"1882\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9B%BA%E5%AE%9A%E9%95%BF%E5%BA%A6%E5%88%86%E5%9D%97/#参数说明\",\"1883\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/AdaLoRA/#核心代码解析\",\"1884\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#关键技术改进\",\"1885\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#zero-shot-cot\",\"1886\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6%E5%8F%8A%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6/#推理机制\",\"1887\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax-improvement/#内容摘要\",\"1888\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax/#日期\",\"1889\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/DPO%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/#_4-定义最优策略\",\"1890\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/DoRA/#操作步骤\",\"1891\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/LoRA_/#公式调整\",\"1892\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E5%8E%9F%E7%90%86/#记忆的定义与分类\",\"1893\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#二、基于多模态大模型的解析技术\",\"1894\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96%E4%B8%AD%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E9%98%B6%E6%AE%B5/#_4-检索参数\",\"1895\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#表现效果因多方面因素而异\",\"1896\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9F%BA%E4%BA%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%9D%97/#扩展-基于-spacy-的文本切块\",\"1897\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/RL%E5%9C%A8NLP%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E6%8B%93%E5%B1%95/#思考\",\"1898\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/LLaMA-Adapter/#💡启发点\",\"1899\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#核心观点\",\"1900\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/VAPO/#日期-2025年4月12日\",\"1901\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/REINFORCE%E7%AE%97%E6%B3%95%E6%94%B9%E8%BF%9B%EF%BC%9ARLOO%E4%B8%8EREINFORCE__/#rloo的分析\",\"1902\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E8%A7%92%E5%BA%A6%E7%90%86%E8%A7%A3DPO/#行动清单\",\"1903\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/%E4%BB%8B%E7%BB%8D/#重点段落与数据\",\"1904\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E5%8E%86%E5%8F%B2%E5%8F%91%E5%B1%95/#_4-自主-agent-autonomous-agent-顶层智能体\",\"1905\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/LLM%E5%AF%B9%E9%BD%90%E4%B8%8B%E7%9A%84RLHF_PPO/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Prompt%E5%88%B0Response%E7%9A%84MDP%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90/#奖励机制设计\",\"1906\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#observation-based-agent\",\"1907\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/%E6%B7%B1%E5%BA%A6%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96%EF%BC%88DPO%EF%BC%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%A7%A3%E6%9E%90%E4%B8%8E%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B/#行动清单\",\"1908\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Reference-Model/#💡-启发点\",\"1909\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/LoRA/#重点段落\",\"1910\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6%E5%8F%8A%E4%BC%98%E5%8C%96/%E9%A6%96Token%E6%97%B6%E5%BB%B6%E4%BC%98%E5%8C%96/#首token时延\",\"1911\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/QLoRA/#常见错误\",\"1912\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/P-Tuning-V2/#代码实现\",\"1913\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96DPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DPOP/#策略模型的拟合\",\"1914\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/P-Tuning/#常见错误\",\"1915\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#性能\",\"1916\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%88%86%E6%9E%90/%E6%A8%A1%E5%9E%8B%E6%98%BE%E5%AD%98%E6%80%BB%E4%BD%93%E5%88%86%E6%9E%90/\",\"1917\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E6%A1%86%E6%9E%B6%E5%92%8C%E5%BA%94%E7%94%A8/#具体总结\",\"1918\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Instruct-GPT/#后续追踪\",\"1919\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%88%86%E6%9E%90/%E6%98%BE%E5%AD%98%E4%BC%98%E5%8C%96%E4%B8%8E%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%88%86%E6%9E%90/#元数据\",\"1920\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/RLHF%E6%B5%81%E7%A8%8B/#后续追踪\",\"1921\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Reward-Model/#行动清单\",\"1922\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/Prefix-Tuning/#应用于不同模型结构\",\"1923\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/VeRA/#操作步骤\",\"1924\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96DPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/Self-Reward/#自我指令创建\",\"1925\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/%E6%A0%87%E5%87%86Attention%E4%B8%8ESafe-softmax/#标准safe-softmax\",\"1926\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/%E8%AE%A1%E7%AE%97%E4%B8%8E%E5%86%85%E5%AD%98%E9%99%90%E5%88%B6/#注意区分flops和flops\",\"1927\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6/vLLM/#decode\",\"1928\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/X-LoRA/#代码示例\",\"1929\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#flashattention的做法\",\"1930\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/Prompt-Tuning/#prompt-ensembling-方法\",\"1931\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/#ptq方法\",\"1932\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/%E4%BB%8B%E7%BB%8D/#重点段落\",\"1933\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#hits-rate-命中率\",\"1934\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/critic-model/#行动清单\",\"1935\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%B3%BB%E7%BB%9F%E5%88%86%E7%B1%BB/#定义-1\",\"1936\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#代码示例\",\"1937\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9B%BA%E5%AE%9A%E9%95%BF%E5%BA%A6%E5%88%86%E5%9D%97/#_1-chunk-size\",\"1938\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/AdaLoRA/#操作步骤\",\"1939\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#技术术语简化\",\"1940\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#few-shot-cot\",\"1941\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6%E5%8F%8A%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6/#传统推理方式\",\"1942\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax-improvement/#策略梯度与ppo回顾\",\"1943\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax/#内容摘要\",\"1944\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/DPO%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/#_5-kl散度最小化\",\"1945\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/DoRA/#常见错误\",\"1946\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/LoRA_/#常见错误\",\"1947\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E5%8E%9F%E7%90%86/#感官记忆\",\"1948\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#方法简介-1\",\"1949\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96%E4%B8%AD%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E9%98%B6%E6%AE%B5/#稀疏和稠密搜索权重\",\"1950\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#rag整体思路\",\"1951\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9F%BA%E4%BA%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%9D%97/#使用方法\",\"1952\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/RL%E5%9C%A8NLP%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E6%8B%93%E5%B1%95/#行动清单\",\"1953\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/LLaMA-Adapter/#行动清单\",\"1954\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#重点段落\",\"1955\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/VAPO/#核心观点总结\",\"1956\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/REINFORCE%E7%AE%97%E6%B3%95%E6%94%B9%E8%BF%9B%EF%BC%9ARLOO%E4%B8%8EREINFORCE__/#reinforce-概述\",\"1957\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/%E4%BB%8B%E7%BB%8D/#加速计算-fast\",\"1958\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/LLM%E5%AF%B9%E9%BD%90%E4%B8%8B%E7%9A%84RLHF_PPO/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Prompt%E5%88%B0Response%E7%9A%84MDP%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90/#操作步骤\",\"1959\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#具体方法\",\"1960\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/%E6%B7%B1%E5%BA%A6%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96%EF%BC%88DPO%EF%BC%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%A7%A3%E6%9E%90%E4%B8%8E%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B/#数据转换\",\"1961\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Reference-Model/#行动清单\",\"1962\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/LoRA/#_1-lora的实现\",\"1963\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6%E5%8F%8A%E4%BC%98%E5%8C%96/%E9%A6%96Token%E6%97%B6%E5%BB%B6%E4%BC%98%E5%8C%96/#首个token的推理延迟\",\"1964\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/QLoRA/#💡启发点\",\"1965\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/P-Tuning-V2/#常见错误\",\"1966\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96DPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DPOP/#操作步骤\",\"1967\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/P-Tuning/#💡启发点\",\"1968\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#self-evolution\",\"1969\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%88%86%E6%9E%90/%E6%A8%A1%E5%9E%8B%E6%98%BE%E5%AD%98%E6%80%BB%E4%BD%93%E5%88%86%E6%9E%90/#元数据\",\"1970\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E6%A1%86%E6%9E%B6%E5%92%8C%E5%BA%94%E7%94%A8/#ragen-推理驱动的交互优化框架\",\"1971\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/Instruct-GPT/#思考-板块\",\"1972\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%88%86%E6%9E%90/%E6%98%BE%E5%AD%98%E4%BC%98%E5%8C%96%E4%B8%8E%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%88%86%E6%9E%90/#内容总结\",\"1973\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/RLHF%E6%B5%81%E7%A8%8B/#思考\",\"1974\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/Prefix-Tuning/#防止训练不稳定\",\"1975\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/VeRA/#常见错误\",\"1976\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96DPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/Self-Reward/#指令遵循训练\",\"1977\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/%E8%AE%A1%E7%AE%97%E4%B8%8E%E5%86%85%E5%AD%98%E9%99%90%E5%88%B6/#计算带宽与内存带宽\",\"1978\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6/vLLM/#常规kv-cache分配\",\"1979\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/X-LoRA/#💡-启发点\",\"1980\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#引入额外的统计量\",\"1981\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/Prompt-Tuning/#hard-prompt-与-soft-prompt-的区别\",\"1982\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/#llm-int8\",\"1983\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/%E4%BB%8B%E7%BB%8D/#技术术语通俗解释\",\"1984\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#代码示例-计算-precision\",\"1985\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%B3%BB%E7%BB%9F%E5%88%86%E7%B1%BB/#_3-并行化-parallelization\",\"1986\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#💡启发点-1\",\"1987\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9B%BA%E5%AE%9A%E9%95%BF%E5%BA%A6%E5%88%86%E5%9D%97/#_2-chunk-overlap\",\"1988\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/AdaLoRA/#常见错误\",\"1989\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#操作步骤\",\"1990\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#cot-改进方法\",\"1991\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6%E5%8F%8A%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6/#过程建模两种方式\",\"1992\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax-improvement/#重点段落\",\"1993\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax/#策略梯度与ppo回顾\",\"1994\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/DPO%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/#_6-奖励函数反推\",\"1995\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%88%86%E6%9E%90/%E8%AE%AD%E7%BB%83%E9%98%B6%E6%AE%B5%E7%9A%84%E6%98%BE%E5%AD%98%E5%88%86%E6%9E%90/\",\"1996\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/DoRA/#💡启发点\",\"1997\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/LoRA_/#行动清单\",\"1998\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E5%8E%9F%E7%90%86/#短时记忆-stm-或工作记忆\",\"1999\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#可选的基座模型\",\"2000\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96%E4%B8%AD%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E9%98%B6%E6%AE%B5/#结果数量-topk\",\"2001\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#知识文档的准备\",\"2002\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9F%BA%E4%BA%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%9D%97/#提示\",\"2003\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/RL%E5%9C%A8NLP%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E6%8B%93%E5%B1%95/#后续追踪\",\"2004\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#技术术语转述\",\"2005\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/VAPO/#重点段落\",\"2006\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Accelerate/\",\"2007\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/REINFORCE%E7%AE%97%E6%B3%95%E6%94%B9%E8%BF%9B%EF%BC%9ARLOO%E4%B8%8EREINFORCE__/#操作步骤\",\"2008\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/%E4%BB%8B%E7%BB%8D/#显存节省-memory-efficient\",\"2009\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/LLM%E5%AF%B9%E9%BD%90%E4%B8%8B%E7%9A%84RLHF_PPO/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Prompt%E5%88%B0Response%E7%9A%84MDP%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90/#常见错误\",\"2010\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/DeepSpeed/\",\"2011\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#reasoning-and-acting\",\"2012\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/%E6%B7%B1%E5%BA%A6%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96%EF%BC%88DPO%EF%BC%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%A7%A3%E6%9E%90%E4%B8%8E%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B/#公式显示\",\"2013\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/LoRA/#_2-参数更新与内在秩\",\"2014\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6%E5%8F%8A%E4%BC%98%E5%8C%96/%E9%A6%96Token%E6%97%B6%E5%BB%B6%E4%BC%98%E5%8C%96/#后续每个token的推理延迟\",\"2015\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/QLoRA/#行动清单\",\"2016\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/\",\"2017\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/P-Tuning-V2/#行动清单\",\"2018\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96DPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DPOP/#常见错误\",\"2019\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/P-Tuning/#行动清单\",\"2020\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#关键段落\",\"2021\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%88%86%E6%9E%90/%E6%A8%A1%E5%9E%8B%E6%98%BE%E5%AD%98%E6%80%BB%E4%BD%93%E5%88%86%E6%9E%90/#核心观点总结\",\"2022\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E6%A1%86%E6%9E%B6%E5%92%8C%E5%BA%94%E7%94%A8/#一句话总结\",\"2023\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%88%86%E6%9E%90/%E6%98%BE%E5%AD%98%E4%BC%98%E5%8C%96%E4%B8%8E%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%88%86%E6%9E%90/#推理阶段显存分析\",\"2024\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/Prefix-Tuning/#技术术语通俗解释\",\"2025\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/VeRA/#💡启发点\",\"2026\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96DPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/Self-Reward/#迭代训练\",\"2027\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/%E8%AE%A1%E7%AE%97%E4%B8%8E%E5%86%85%E5%AD%98%E9%99%90%E5%88%B6/#性能受限类型\",\"2028\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/X-LoRA/#警告区块\",\"2029\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron%E5%92%8CDeepSpeed%E5%90%8E%E7%AB%AF%E5%AE%9E%E7%8E%B0%E7%9A%84%E5%8C%BA%E5%88%AB/\",\"2030\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#公式说明\",\"2031\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/X-ray/\",\"2032\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/Prompt-Tuning/#技术术语转述\",\"2033\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/#smoothquant\",\"2034\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/%E4%BB%8B%E7%BB%8D/#操作步骤\",\"2035\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#ndcg-归一化折损累计增益\",\"2036\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E9%9B%86/\",\"2037\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%B3%BB%E7%BB%9F%E5%88%86%E7%B1%BB/#定义-2\",\"2038\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#行动清单-1\",\"2039\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9B%BA%E5%AE%9A%E9%95%BF%E5%BA%A6%E5%88%86%E5%9D%97/#_3-length-function\",\"2040\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/AdaLoRA/#行动清单\",\"2041\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#常见错误\",\"2042\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#cot-sc-self-consistency\",\"2043\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6%E5%8F%8A%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6/#瓶颈分析-浮点运算的主要来源\",\"2044\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax-improvement/#ppo算法简化\",\"2045\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax/#重点段落\",\"2046\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/DPO%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/#_7-偏好概率模型\",\"2047\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%88%86%E6%9E%90/%E8%AE%AD%E7%BB%83%E9%98%B6%E6%AE%B5%E7%9A%84%E6%98%BE%E5%AD%98%E5%88%86%E6%9E%90/#元数据\",\"2048\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/DoRA/#行动清单\",\"2049\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E5%8E%9F%E7%90%86/#长时记忆-ltm\",\"2050\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#prompt示例\",\"2051\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96%E4%B8%AD%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E9%98%B6%E6%AE%B5/#相似度度量方法\",\"2052\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#转换为纯文本数据\",\"2053\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#操作步骤\",\"2054\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/VAPO/#value-model-based-v-s-value-model-free\",\"2055\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Accelerate/#accelerate\",\"2056\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/REINFORCE%E7%AE%97%E6%B3%95%E6%94%B9%E8%BF%9B%EF%BC%9ARLOO%E4%B8%8EREINFORCE__/#常见错误\",\"2057\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/%E4%BB%8B%E7%BB%8D/#精确注意力-exact-attention\",\"2058\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/LLM%E5%AF%B9%E9%BD%90%E4%B8%8B%E7%9A%84RLHF_PPO/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Prompt%E5%88%B0Response%E7%9A%84MDP%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90/#💡-启发点\",\"2059\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/DeepSpeed/#混合精度训练\",\"2060\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#流程及与cot和act-only方法的对比\",\"2061\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/%E6%B7%B1%E5%BA%A6%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96%EF%BC%88DPO%EF%BC%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%A7%A3%E6%9E%90%E4%B8%8E%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B/#来源标注\",\"2062\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/LoRA/#_3-矩阵初始化策略\",\"2063\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E5%A4%9A%E6%A0%B7%E6%80%A7%E6%8E%A2%E7%B4%A2/\",\"2064\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6%E5%8F%8A%E4%BC%98%E5%8C%96/%E9%A6%96Token%E6%97%B6%E5%BB%B6%E4%BC%98%E5%8C%96/#优化system-prompt\",\"2065\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/QLoRA/#数据转换\",\"2066\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#megatron-lm\",\"2067\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E7%94%9F%E4%BA%A7%E5%90%88%E6%88%90%E4%B8%8E%E8%B4%A8%E9%87%8F%E8%BF%87%E6%BB%A4/\",\"2068\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96DPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DPOP/#💡启发点\",\"2069\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/P-Tuning/#数据转换\",\"2070\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#自我进化过程\",\"2071\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%88%86%E6%9E%90/%E6%A8%A1%E5%9E%8B%E6%98%BE%E5%AD%98%E6%80%BB%E4%BD%93%E5%88%86%E6%9E%90/#重点段落与数据\",\"2072\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E6%A1%86%E6%9E%B6%E5%92%8C%E5%BA%94%E7%94%A8/#具体实现\",\"2073\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%88%86%E6%9E%90/%E6%98%BE%E5%AD%98%E4%BC%98%E5%8C%96%E4%B8%8E%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%88%86%E6%9E%90/#显存优化方法\",\"2074\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/Prefix-Tuning/#操作步骤\",\"2075\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/VeRA/#行动清单\",\"2076\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96DPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/Self-Reward/#实验结果与分析\",\"2077\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/%E8%AE%A1%E7%AE%97%E4%B8%8E%E5%86%85%E5%AD%98%E9%99%90%E5%88%B6/#gpu内存分级\",\"2078\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/X-LoRA/#行动清单\",\"2079\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron%E5%92%8CDeepSpeed%E5%90%8E%E7%AB%AF%E5%AE%9E%E7%8E%B0%E7%9A%84%E5%8C%BA%E5%88%AB/#deepspeed-后端\",\"2080\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#kernel融合\",\"2081\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/X-ray/#构建思想\",\"2082\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/Prompt-Tuning/#操作步骤\",\"2083\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E9%A3%9E%E8%BD%AE%E5%9C%A8SFT%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8%E4%B8%8E%E4%BC%98%E5%8C%96/\",\"2084\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B8%93%E9%A1%B9%E6%8F%90%E5%8D%87/\",\"2085\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/#gpt-q\",\"2086\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/%E4%BB%8B%E7%BB%8D/#常见错误\",\"2087\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#dcg-的思想\",\"2088\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E9%9B%86/#元数据\",\"2089\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%B3%BB%E7%BB%9F%E5%88%86%E7%B1%BB/#_4-协调者-工作者-orchestrator-workers\",\"2090\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#数据转换\",\"2091\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9B%BA%E5%AE%9A%E9%95%BF%E5%BA%A6%E5%88%86%E5%9D%97/#_4-separators\",\"2092\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/AdaLoRA/#数据转换\",\"2093\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#行动清单\",\"2094\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#tot-tree-of-thoughts\",\"2095\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6%E5%8F%8A%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6/#时延计算\",\"2096\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax-improvement/#操作步骤\",\"2097\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax/#ppo算法简化\",\"2098\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/DPO%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/#⚠-常见错误警示\",\"2099\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%88%86%E6%9E%90/%E8%AE%AD%E7%BB%83%E9%98%B6%E6%AE%B5%E7%9A%84%E6%98%BE%E5%AD%98%E5%88%86%E6%9E%90/#核心观点总结\",\"2100\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B8%93%E9%A1%B9%E6%8F%90%E5%8D%872/\",\"2101\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E5%90%AF%E5%8A%A8%E8%84%9A%E6%9C%AC/\",\"2102\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E5%8E%9F%E7%90%86/#最大内部产品搜索-maximum-inner-product-search-mips\",\"2103\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#优势与挑战\",\"2104\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96%E4%B8%AD%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E9%98%B6%E6%AE%B5/#_5-高级检索策略\",\"2105\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#文档切片\",\"2106\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#常见错误\",\"2107\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/VAPO/#value-model-的挑战\",\"2108\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Accelerate/#分布式推理\",\"2109\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/REINFORCE%E7%AE%97%E6%B3%95%E6%94%B9%E8%BF%9B%EF%BC%9ARLOO%E4%B8%8EREINFORCE__/#💡-启发点\",\"2110\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/%E4%BB%8B%E7%BB%8D/#技术术语通俗解释\",\"2111\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RLHF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/LLM%E5%AF%B9%E9%BD%90%E4%B8%8B%E7%9A%84RLHF_PPO/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Prompt%E5%88%B0Response%E7%9A%84MDP%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90/#行动清单\",\"2112\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/DeepSpeed/#zero-零冗余优化器\",\"2113\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#reflexion\",\"2114\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7%E5%92%8C%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5/\",\"2115\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/LoRA/#操作步骤\",\"2116\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E5%A4%9A%E6%A0%B7%E6%80%A7%E6%8E%A2%E7%B4%A2/#元数据\",\"2117\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6%E5%8F%8A%E4%BC%98%E5%8C%96/%E9%A6%96Token%E6%97%B6%E5%BB%B6%E4%BC%98%E5%8C%96/#第一种形式-prefix-sharing\",\"2118\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#megatron-lm-的优缺点\",\"2119\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E7%94%9F%E4%BA%A7%E5%90%88%E6%88%90%E4%B8%8E%E8%B4%A8%E9%87%8F%E8%BF%87%E6%BB%A4/#数据生产合成\",\"2120\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96DPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DPOP/#行动清单\",\"2121\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/P-Tuning/#公式显示\",\"2122\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#复杂行为表现\",\"2123\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%88%86%E6%9E%90/%E6%A8%A1%E5%9E%8B%E6%98%BE%E5%AD%98%E6%80%BB%E4%BD%93%E5%88%86%E6%9E%90/#显存消耗内容概述\",\"2124\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E6%A1%86%E6%9E%B6%E5%92%8C%E5%BA%94%E7%94%A8/#_1-使用-mdp-进行建模\",\"2125\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%88%86%E6%9E%90/%E6%98%BE%E5%AD%98%E4%BC%98%E5%8C%96%E4%B8%8E%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%88%86%E6%9E%90/#操作步骤\",\"2126\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/Prefix-Tuning/#常见错误\",\"2127\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96DPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/Self-Reward/#常见错误\",\"2128\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/%E8%AE%A1%E7%AE%97%E4%B8%8E%E5%86%85%E5%AD%98%E9%99%90%E5%88%B6/#gpu运行模式\",\"2129\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron%E5%92%8CDeepSpeed%E5%90%8E%E7%AB%AF%E5%AE%9E%E7%8E%B0%E7%9A%84%E5%8C%BA%E5%88%AB/#megatron-后端\",\"2130\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#一个分块计算softmax的例子\",\"2131\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E5%8F%8A%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE/\",\"2132\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/X-ray/#大模型并行训练\",\"2133\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/Prompt-Tuning/#常见错误\",\"2134\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E9%A3%9E%E8%BD%AE%E5%9C%A8SFT%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8%E4%B8%8E%E4%BC%98%E5%8C%96/#元数据\",\"2135\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B8%93%E9%A1%B9%E6%8F%90%E5%8D%87/#元数据\",\"2136\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/%E4%BB%8B%E7%BB%8D/#💡-启发点\",\"2137\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#dcg-公式\",\"2138\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E9%9B%86/#内容处理\",\"2139\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%B3%BB%E7%BB%9F%E5%88%86%E7%B1%BB/#适用场景-1\",\"2140\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#公式显示\",\"2141\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/%E5%9B%BA%E5%AE%9A%E9%95%BF%E5%BA%A6%E5%88%86%E5%9D%97/#工作原理\",\"2142\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/AdaLoRA/#公式显示\",\"2143\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#数据转换\",\"2144\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#got-graph-of-thoughts\",\"2145\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6%E5%8F%8A%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6/#计算一个-token-所需要的数据量\",\"2146\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax-improvement/#常见错误\",\"2147\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax/#操作步骤\",\"2148\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DPO%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/DPO%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/#💡-创新点解析\",\"2149\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%88%86%E6%9E%90/%E8%AE%AD%E7%BB%83%E9%98%B6%E6%AE%B5%E7%9A%84%E6%98%BE%E5%AD%98%E5%88%86%E6%9E%90/#重点段落\",\"2150\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B8%93%E9%A1%B9%E6%8F%90%E5%8D%872/#分类-机器学习\",\"2151\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E5%90%AF%E5%8A%A8%E8%84%9A%E6%9C%AC/#核心观点总结\",\"2152\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E5%8E%9F%E7%90%86/#lsh-局部敏感哈希\",\"2153\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#三、多级标题如何处理\",\"2154\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96%E4%B8%AD%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E9%98%B6%E6%AE%B5/#上下文压缩\",\"2155\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#embedding模型\",\"2156\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#💡启发点\",\"2157\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/VAPO/#蒙特卡洛估计与价值模型\",\"2158\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Accelerate/#分布式训练\",\"2159\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/REINFORCE%E7%AE%97%E6%B3%95%E6%94%B9%E8%BF%9B%EF%BC%9ARLOO%E4%B8%8EREINFORCE__/#行动清单\",\"2160\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/%E4%BB%8B%E7%BB%8D/#操作步骤\",\"2161\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/DeepSpeed/#zero的显存分类\",\"2162\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#流程图\",\"2163\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7%E5%92%8C%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5/#训练技巧\",\"2164\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/LoRA/#常见错误\",\"2165\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E5%A4%9A%E6%A0%B7%E6%80%A7%E6%8E%A2%E7%B4%A2/#核心观点总结\",\"2166\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6%E5%8F%8A%E4%BC%98%E5%8C%96/%E9%A6%96Token%E6%97%B6%E5%BB%B6%E4%BC%98%E5%8C%96/#第二种形式-prompt-cache\",\"2167\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#megatron-lm-的特点\",\"2168\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E7%94%9F%E4%BA%A7%E5%90%88%E6%88%90%E4%B8%8E%E8%B4%A8%E9%87%8F%E8%BF%87%E6%BB%A4/#生产合成-prompt\",\"2169\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#技术术语解释\",\"2170\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%88%86%E6%9E%90/%E6%A8%A1%E5%9E%8B%E6%98%BE%E5%AD%98%E6%80%BB%E4%BD%93%E5%88%86%E6%9E%90/#显存估算与实际测量差异\",\"2171\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E6%A1%86%E6%9E%B6%E5%92%8C%E5%BA%94%E7%94%A8/#_2-rico-算法-推理-交互链优化\",\"2172\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%88%86%E6%9E%90/%E6%98%BE%E5%AD%98%E4%BC%98%E5%8C%96%E4%B8%8E%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%88%86%E6%9E%90/#常见错误\",\"2173\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/Prefix-Tuning/#💡启发点\",\"2174\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96DPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/Self-Reward/#行动清单\",\"2175\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/%E8%AE%A1%E7%AE%97%E4%B8%8E%E5%86%85%E5%AD%98%E9%99%90%E5%88%B6/#kernel融合\",\"2176\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#计算block1\",\"2177\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E5%8F%8A%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE/#综述\",\"2178\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/X-ray/#数据并行-data-parallel-dp\",\"2179\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/Prompt-Tuning/#💡启发点\",\"2180\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E9%A3%9E%E8%BD%AE%E5%9C%A8SFT%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8%E4%B8%8E%E4%BC%98%E5%8C%96/#核心观点总结\",\"2181\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B8%93%E9%A1%B9%E6%8F%90%E5%8D%87/#核心观点总结\",\"2182\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/%E4%BB%8B%E7%BB%8D/#行动清单\",\"2183\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#idcg-和-ndcg\",\"2184\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E9%9B%86/#重点数据集\",\"2185\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%B3%BB%E7%BB%9F%E5%88%86%E7%B1%BB/#示例-1\",\"2186\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#moe推理优化\",\"2187\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#公式显示\",\"2188\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#got-的核心特点\",\"2189\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6%E5%8F%8A%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6/#推理-tps-计算\",\"2190\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax-improvement/#💡启发点\",\"2191\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax/#常见错误\",\"2192\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%88%86%E6%9E%90/%E8%AE%AD%E7%BB%83%E9%98%B6%E6%AE%B5%E7%9A%84%E6%98%BE%E5%AD%98%E5%88%86%E6%9E%90/#静态值分析\",\"2193\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B8%93%E9%A1%B9%E6%8F%90%E5%8D%872/#标签-多轮对话、损失函数优化、加速计算\",\"2194\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E5%90%AF%E5%8A%A8%E8%84%9A%E6%9C%AC/#重点段落\",\"2195\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E5%8E%9F%E7%90%86/#annoy-approximate-nearest-neighbors-oh-yeah\",\"2196\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#为什么要处理多级标题\",\"2197\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96%E4%B8%AD%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E9%98%B6%E6%AE%B5/#句子窗口搜索\",\"2198\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#向量数据库\",\"2199\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#行动清单\",\"2200\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/VAPO/#操作步骤\",\"2201\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Accelerate/#代码块\",\"2202\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/REINFORCE%E7%AE%97%E6%B3%95%E6%94%B9%E8%BF%9B%EF%BC%9ARLOO%E4%B8%8EREINFORCE__/#来源\",\"2203\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/%E4%BB%8B%E7%BB%8D/#常见错误\",\"2204\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/DeepSpeed/#zero-三个阶段以及显存占用分析\",\"2205\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#内部反馈与外部反馈\",\"2206\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7%E5%92%8C%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5/#关键步骤\",\"2207\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/LoRA/#💡-启发点\",\"2208\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E5%A4%9A%E6%A0%B7%E6%80%A7%E6%8E%A2%E7%B4%A2/#重点段落提取\",\"2209\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#提醒\",\"2210\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E7%94%9F%E4%BA%A7%E5%90%88%E6%88%90%E4%B8%8E%E8%B4%A8%E9%87%8F%E8%BF%87%E6%BB%A4/#生产合成-answer\",\"2211\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#💡启发点-1\",\"2212\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%88%86%E6%9E%90/%E6%A8%A1%E5%9E%8B%E6%98%BE%E5%AD%98%E6%80%BB%E4%BD%93%E5%88%86%E6%9E%90/#操作步骤\",\"2213\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E6%A1%86%E6%9E%B6%E5%92%8C%E5%BA%94%E7%94%A8/#_3-奖励归一化策略\",\"2214\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%88%86%E6%9E%90/%E6%98%BE%E5%AD%98%E4%BC%98%E5%8C%96%E4%B8%8E%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%88%86%E6%9E%90/#行动清单\",\"2215\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/Prefix-Tuning/#行动清单\",\"2216\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#计算block2\",\"2217\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E5%8F%8A%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE/#参数设置与注意事项\",\"2218\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/X-ray/#张量并行-tensor-parallel-tp\",\"2219\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/Prompt-Tuning/#行动清单\",\"2220\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E9%A3%9E%E8%BD%AE%E5%9C%A8SFT%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8%E4%B8%8E%E4%BC%98%E5%8C%96/#重点段落与数据\",\"2221\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B8%93%E9%A1%B9%E6%8F%90%E5%8D%87/#重点段落\",\"2222\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#针对生成环节的评估\",\"2223\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E9%9B%86/#数据集格式与内容\",\"2224\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%B3%BB%E7%BB%9F%E5%88%86%E7%B1%BB/#_5-工作流-评估-优化循环-evaluator-optimizer\",\"2225\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#元数据-1\",\"2226\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#clip-higher技术改进-提升低概率token探索能力\",\"2227\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#got-的模块组成\",\"2228\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6%E5%8F%8A%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6/#如何计算-tps\",\"2229\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax-improvement/#行动清单\",\"2230\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax/#💡启发点\",\"2231\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%88%86%E6%9E%90/%E8%AE%AD%E7%BB%83%E9%98%B6%E6%AE%B5%E7%9A%84%E6%98%BE%E5%AD%98%E5%88%86%E6%9E%90/#动态值分析\",\"2232\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B8%93%E9%A1%B9%E6%8F%90%E5%8D%872/#日期-2023年10月30日\",\"2233\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E5%90%AF%E5%8A%A8%E8%84%9A%E6%9C%AC/#操作步骤\",\"2234\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E5%8E%9F%E7%90%86/#hnsw-hierarchical-navigable-small-world\",\"2235\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#具体做法\",\"2236\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96%E4%B8%AD%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E9%98%B6%E6%AE%B5/#父文档搜索\",\"2237\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#优化存储与检索效率\",\"2238\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#grpo优势函数估计与奖励监督rl\",\"2239\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/VAPO/#常见错误\",\"2240\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/%E4%BB%8B%E7%BB%8D/#💡-启发点\",\"2241\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/DeepSpeed/#数据通信量分析\",\"2242\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#lifelong-learning-agents\",\"2243\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7%E5%92%8C%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5/#常见错误\",\"2244\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/LoRA/#行动清单\",\"2245\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E5%A4%9A%E6%A0%B7%E6%80%A7%E6%8E%A2%E7%B4%A2/#数据用途的多样化\",\"2246\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#大型模型训练的挑战\",\"2247\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E7%94%9F%E4%BA%A7%E5%90%88%E6%88%90%E4%B8%8E%E8%B4%A8%E9%87%8F%E8%BF%87%E6%BB%A4/#数据质量过滤\",\"2248\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#deepseek-r1-zero的aha-moment\",\"2249\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%88%86%E6%9E%90/%E6%A8%A1%E5%9E%8B%E6%98%BE%E5%AD%98%E6%80%BB%E4%BD%93%E5%88%86%E6%9E%90/#常见错误\",\"2250\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E6%A1%86%E6%9E%B6%E5%92%8C%E5%BA%94%E7%94%A8/#_4-模型评估与数据平衡\",\"2251\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#forward具体流程\",\"2252\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E5%8F%8A%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE/#技术细节\",\"2253\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/X-ray/#流水线并行-pipeline-parallel-pp\",\"2254\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/Prompt-Tuning/#数据转换\",\"2255\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E9%A3%9E%E8%BD%AE%E5%9C%A8SFT%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8%E4%B8%8E%E4%BC%98%E5%8C%96/#操作步骤\",\"2256\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B8%93%E9%A1%B9%E6%8F%90%E5%8D%87/#多轮对话数据判断\",\"2257\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#非量化评估\",\"2258\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E9%9B%86/#思考\",\"2259\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%B3%BB%E7%BB%9F%E5%88%86%E7%B1%BB/#适用场景-2\",\"2260\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#核心观点总结-1\",\"2261\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#元数据-1\",\"2262\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/Prompt-Tech-%E6%8F%90%E7%A4%BA%E6%8A%80%E6%9C%AF/#controller-的两个重要组件\",\"2263\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6%E5%8F%8A%E4%BC%98%E5%8C%96/%E6%8E%A8%E7%90%86%E8%80%97%E6%97%B6/#tps-估算方法\",\"2264\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax-improvement/#remax具体算法\",\"2265\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax/#行动清单\",\"2266\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%88%86%E6%9E%90/%E8%AE%AD%E7%BB%83%E9%98%B6%E6%AE%B5%E7%9A%84%E6%98%BE%E5%AD%98%E5%88%86%E6%9E%90/#操作步骤\",\"2267\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B8%93%E9%A1%B9%E6%8F%90%E5%8D%872/#核心观点总结\",\"2268\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E5%90%AF%E5%8A%A8%E8%84%9A%E6%9C%AC/#常见错误\",\"2269\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E5%8E%9F%E7%90%86/#工具使用-tool-use\",\"2270\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#四、好用的pdf文件解析工具推荐\",\"2271\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96%E4%B8%AD%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E9%98%B6%E6%AE%B5/#自动合并\",\"2272\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#查询检索\",\"2273\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#核心观点总结\",\"2274\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/VAPO/#💡启发点\",\"2275\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/%E4%BB%8B%E7%BB%8D/#行动清单\",\"2276\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/DeepSpeed/#传统数据并行\",\"2277\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#voyager\",\"2278\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7%E5%92%8C%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5/#sft阶段的packing策略\",\"2279\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/LoRA/#lora-微调的初始化影响与核心代码分析\",\"2280\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E5%A4%9A%E6%A0%B7%E6%80%A7%E6%8E%A2%E7%B4%A2/#数据形式的多样化\",\"2281\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#显存限制\",\"2282\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E7%94%9F%E4%BA%A7%E5%90%88%E6%88%90%E4%B8%8E%E8%B4%A8%E9%87%8F%E8%BF%87%E6%BB%A4/#ifd-过滤\",\"2283\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#强化学习的核心价值\",\"2284\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%88%86%E6%9E%90/%E6%A8%A1%E5%9E%8B%E6%98%BE%E5%AD%98%E6%80%BB%E4%BD%93%E5%88%86%E6%9E%90/#代码示例\",\"2285\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E6%A1%86%E6%9E%B6%E5%92%8C%E5%BA%94%E7%94%A8/#rl-agents-全面强化学习算法测试框架\",\"2286\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#flash-attention-具体做法\",\"2287\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E5%8F%8A%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE/#常见错误\",\"2288\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/X-ray/#zero-zero-redundancy-optimizer\",\"2289\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/PEFT%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/Prompt-Tuning/#公式显示\",\"2290\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E9%A3%9E%E8%BD%AE%E5%9C%A8SFT%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8%E4%B8%8E%E4%BC%98%E5%8C%96/#常见错误\",\"2291\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B8%93%E9%A1%B9%E6%8F%90%E5%8D%87/#多轮对话数据合成\",\"2292\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#量化评估\",\"2293\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E9%9B%86/#附加要求\",\"2294\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%B3%BB%E7%BB%9F%E5%88%86%E7%B1%BB/#示例-2\",\"2295\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#重点段落\",\"2296\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#内容处理\",\"2297\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax-improvement/#元数据\",\"2298\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax/#remax具体算法\",\"2299\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%88%86%E6%9E%90/%E8%AE%AD%E7%BB%83%E9%98%B6%E6%AE%B5%E7%9A%84%E6%98%BE%E5%AD%98%E5%88%86%E6%9E%90/#常见错误\",\"2300\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B8%93%E9%A1%B9%E6%8F%90%E5%8D%872/#重点段落\",\"2301\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E5%90%AF%E5%8A%A8%E8%84%9A%E6%9C%AC/#💡启发点\",\"2302\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E5%8E%9F%E7%90%86/#智能体与llm的区别\",\"2303\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#文本分块策略\",\"2304\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96%E4%B8%AD%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E9%98%B6%E6%AE%B5/#多向量检索\",\"2305\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#生成回答\",\"2306\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#重点段落-1\",\"2307\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/VAPO/#行动清单\",\"2308\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/DeepSpeed/#zero1、2阶段-优化器状态分区、梯度分区\",\"2309\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#流程图-1\",\"2310\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7%E5%92%8C%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5/#重点段落\",\"2311\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/LoRA/#核心观点总结\",\"2312\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E5%A4%9A%E6%A0%B7%E6%80%A7%E6%8E%A2%E7%B4%A2/#多轮聊天与答复分布\",\"2313\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#计算挑战\",\"2314\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E7%94%9F%E4%BA%A7%E5%90%88%E6%88%90%E4%B8%8E%E8%B4%A8%E9%87%8F%E8%BF%87%E6%BB%A4/#总体流程\",\"2315\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#deepseek-r1-zero的缺点与局限性\",\"2316\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%88%86%E6%9E%90/%E6%A8%A1%E5%9E%8B%E6%98%BE%E5%AD%98%E6%80%BB%E4%BD%93%E5%88%86%E6%9E%90/#💡启发点\",\"2317\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E6%A1%86%E6%9E%B6%E5%92%8C%E5%BA%94%E7%94%A8/#一句话总结-1\",\"2318\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#计算初始attention分数\",\"2319\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E5%8F%8A%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE/#💡启发点\",\"2320\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/X-ray/#megatron-lm、deepspeed-与-ray-分布式计算的利器\",\"2321\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E9%A3%9E%E8%BD%AE%E5%9C%A8SFT%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8%E4%B8%8E%E4%BC%98%E5%8C%96/#📈趋势预测\",\"2322\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B8%93%E9%A1%B9%E6%8F%90%E5%8D%87/#多轮计算loss\",\"2323\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#意图分流评估\",\"2324\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E9%9B%86/#操作步骤\",\"2325\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%B3%BB%E7%BB%9F%E5%88%86%E7%B1%BB/#总结\",\"2326\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#滑动窗口注意力机制\",\"2327\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#核心观点\",\"2328\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax-improvement/#核心观点总结\",\"2329\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax/#元数据\",\"2330\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%88%86%E6%9E%90/%E8%AE%AD%E7%BB%83%E9%98%B6%E6%AE%B5%E7%9A%84%E6%98%BE%E5%AD%98%E5%88%86%E6%9E%90/#💡-启发点\",\"2331\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B8%93%E9%A1%B9%E6%8F%90%E5%8D%872/#通俗解读\",\"2332\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E5%90%AF%E5%8A%A8%E8%84%9A%E6%9C%AC/#行动清单\",\"2333\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E5%8E%9F%E7%90%86/#与llm的交互方式\",\"2334\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#文本分块策略的意义\",\"2335\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96%E4%B8%AD%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E9%98%B6%E6%AE%B5/#多代理检索\",\"2336\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#rag分类\",\"2337\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#操作步骤-1\",\"2338\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/VAPO/#数据转换\",\"2339\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/DeepSpeed/#深入理解-zero3-与-cpu-卸载技术\",\"2340\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#实验结果\",\"2341\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7%E5%92%8C%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5/#训练策略\",\"2342\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/LoRA/#重点分析\",\"2343\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E5%A4%9A%E6%A0%B7%E6%80%A7%E6%8E%A2%E7%B4%A2/#常见错误警告\",\"2344\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#并行策略挑战\",\"2345\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E7%94%9F%E4%BA%A7%E5%90%88%E6%88%90%E4%B8%8E%E8%B4%A8%E9%87%8F%E8%BF%87%E6%BB%A4/#思考\",\"2346\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#操作步骤-如何优化deepseek-r1-zero的使用\",\"2347\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%88%86%E6%9E%90/%E6%A8%A1%E5%9E%8B%E6%98%BE%E5%AD%98%E6%80%BB%E4%BD%93%E5%88%86%E6%9E%90/#数据表格\",\"2348\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E6%A1%86%E6%9E%B6%E5%92%8C%E5%BA%94%E7%94%A8/#具体实现-1\",\"2349\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#afe-softmax-mask-dropout\",\"2350\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E5%8F%8A%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE/#思考-未来展望与问题\",\"2351\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/X-ray/#megatron-lm\",\"2352\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E9%A3%9E%E8%BD%AE%E5%9C%A8SFT%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8%E4%B8%8E%E4%BC%98%E5%8C%96/#💡启发点\",\"2353\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B8%93%E9%A1%B9%E6%8F%90%E5%8D%87/#常见错误\",\"2354\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#分类任务评估\",\"2355\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E9%9B%86/#常见错误\",\"2356\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#rolling-buffer-cache\",\"2357\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#技术术语转述\",\"2358\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax-improvement/#重点段落-1\",\"2359\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax/#核心观点总结\",\"2360\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%88%86%E6%9E%90/%E8%AE%AD%E7%BB%83%E9%98%B6%E6%AE%B5%E7%9A%84%E6%98%BE%E5%AD%98%E5%88%86%E6%9E%90/#行动清单\",\"2361\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B8%93%E9%A1%B9%E6%8F%90%E5%8D%872/#操作步骤\",\"2362\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E5%90%AF%E5%8A%A8%E8%84%9A%E6%9C%AC/#📈趋势预测\",\"2363\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E5%8E%9F%E7%90%86/#与agent的交互方式\",\"2364\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#理想文本块的特性\",\"2365\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96%E4%B8%AD%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E9%98%B6%E6%AE%B5/#self-rag\",\"2366\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#三个阶段-naive-rag、advanced-rag、modular-rag\",\"2367\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#常见错误-1\",\"2368\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/VAPO/#来源标注\",\"2369\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/DeepSpeed/#通信效率分析\",\"2370\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#ghost-in-the-minecraft-gitm\",\"2371\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7%E5%92%8C%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5/#多任务学习\",\"2372\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/LoRA/#初始化策略对比\",\"2373\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E5%A4%9A%E6%A0%B7%E6%80%A7%E6%8E%A2%E7%B4%A2/#💡启发点\",\"2374\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#数据并行\",\"2375\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E7%94%9F%E4%BA%A7%E5%90%88%E6%88%90%E4%B8%8E%E8%B4%A8%E9%87%8F%E8%BF%87%E6%BB%A4/#操作步骤\",\"2376\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#提高模型推理性能与用户友好性方法探讨\",\"2377\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%88%86%E6%9E%90/%E6%A8%A1%E5%9E%8B%E6%98%BE%E5%AD%98%E6%80%BB%E4%BD%93%E5%88%86%E6%9E%90/#行动清单\",\"2378\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E6%A1%86%E6%9E%B6%E5%92%8C%E5%BA%94%E7%94%A8/#_1-规划算法\",\"2379\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#计算output\",\"2380\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E5%8F%8A%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE/#行动清单\",\"2381\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/X-ray/#deepspeed\",\"2382\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E9%A3%9E%E8%BD%AE%E5%9C%A8SFT%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8%E4%B8%8E%E4%BC%98%E5%8C%96/#思考-板块\",\"2383\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B8%93%E9%A1%B9%E6%8F%90%E5%8D%87/#💡启发点\",\"2384\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#function-call-的评估\",\"2385\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E9%9B%86/#💡启发点\",\"2386\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#chunking方法\",\"2387\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#操作步骤-1\",\"2388\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax-improvement/#remax的基本概念\",\"2389\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax/#重点段落-1\",\"2390\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B8%93%E9%A1%B9%E6%8F%90%E5%8D%872/#常见错误\",\"2391\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E5%90%AF%E5%8A%A8%E8%84%9A%E6%9C%AC/#后续追踪\",\"2392\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E5%8E%9F%E7%90%86/#与强化学习智能体的区别\",\"2393\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#文本分块策略对大模型输出的影响\",\"2394\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96%E4%B8%AD%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E9%98%B6%E6%AE%B5/#重排模型\",\"2395\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#相关综述论文\",\"2396\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#💡-启发点\",\"2397\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/DeepSpeed/#cpu卸载策略\",\"2398\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#流程图-2\",\"2399\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7%E5%92%8C%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5/#顺序训练\",\"2400\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/LoRA/#lora-微调核心代码\",\"2401\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E5%A4%9A%E6%A0%B7%E6%80%A7%E6%8E%A2%E7%B4%A2/#行动清单\",\"2402\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#限制\",\"2403\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E7%94%9F%E4%BA%A7%E5%90%88%E6%88%90%E4%B8%8E%E8%B4%A8%E9%87%8F%E8%BF%87%E6%BB%A4/#常见错误\",\"2404\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#元数据-1\",\"2405\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E6%A1%86%E6%9E%B6%E5%92%8C%E5%BA%94%E7%94%A8/#_2-安全规划\",\"2406\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#计算的伪代码\",\"2407\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E5%8F%8A%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE/#📈趋势预测\",\"2408\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/X-ray/#ray\",\"2409\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E9%A3%9E%E8%BD%AE%E5%9C%A8SFT%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8%E4%B8%8E%E4%BC%98%E5%8C%96/#行动清单\",\"2410\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B8%93%E9%A1%B9%E6%8F%90%E5%8D%87/#行动清单\",\"2411\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#答案评估\",\"2412\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E9%9B%86/#行动清单\",\"2413\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#步骤流程\",\"2414\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#常见错误-1\",\"2415\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax-improvement/#reinforce方法的修正\",\"2416\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax/#remax的基本概念\",\"2417\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B8%93%E9%A1%B9%E6%8F%90%E5%8D%872/#代码示例\",\"2418\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E5%8E%9F%E7%90%86/#强化学习智能体\",\"2419\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#文本分块过长的影响\",\"2420\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#naive-rag\",\"2421\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#行动清单-1\",\"2422\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/DeepSpeed/#cpu卸载的优化目标\",\"2423\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#llm-planner-示例\",\"2424\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7%E5%92%8C%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5/#混合序列训练\",\"2425\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/LoRA/#lora-设置降维和升维矩阵\",\"2426\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E5%A4%9A%E6%A0%B7%E6%80%A7%E6%8E%A2%E7%B4%A2/#📈趋势预测\",\"2427\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#all-reduce-操作\",\"2428\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E7%94%9F%E4%BA%A7%E5%90%88%E6%88%90%E4%B8%8E%E8%B4%A8%E9%87%8F%E8%BF%87%E6%BB%A4/#💡-启发点\",\"2429\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#核心观点总结\",\"2430\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E6%A1%86%E6%9E%B6%E5%92%8C%E5%BA%94%E7%94%A8/#_3-基于值的算法\",\"2431\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#图例加深理解\",\"2432\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E5%8F%8A%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE/#后续追踪\",\"2433\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/X-ray/#代码示例\",\"2434\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E9%A3%9E%E8%BD%AE%E5%9C%A8SFT%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8%E4%B8%8E%E4%BC%98%E5%8C%96/#后续追踪\",\"2435\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B8%93%E9%A1%B9%E6%8F%90%E5%8D%87/#📈趋势预测\",\"2436\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#事实性\",\"2437\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E9%9B%86/#📈趋势预测\",\"2438\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#常见错误-2\",\"2439\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#💡启发点\",\"2440\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax-improvement/#基线计算的创新\",\"2441\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax/#reinforce方法的修正\",\"2442\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B8%93%E9%A1%B9%E6%8F%90%E5%8D%872/#💡启发点\",\"2443\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E5%8E%9F%E7%90%86/#基于大模型的智能体\",\"2444\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#_1-语义模糊\",\"2445\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#优点\",\"2446\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#数据转换\",\"2447\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/DeepSpeed/#数据卸载策略\",\"2448\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#rag-agent\",\"2449\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7%E5%92%8C%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5/#思考\",\"2450\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/LoRA/#常见错误-1\",\"2451\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E5%A4%9A%E6%A0%B7%E6%80%A7%E6%8E%A2%E7%B4%A2/#后续追踪\",\"2452\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#工作原理\",\"2453\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E7%94%9F%E4%BA%A7%E5%90%88%E6%88%90%E4%B8%8E%E8%B4%A8%E9%87%8F%E8%BF%87%E6%BB%A4/#行动清单\",\"2454\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#重点段落-1\",\"2455\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E6%A1%86%E6%9E%B6%E5%92%8C%E5%BA%94%E7%94%A8/#_4-安全基于值的方法\",\"2456\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#当-j-1-时\",\"2457\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B8%93%E9%A1%B9%E6%8F%90%E5%8D%87/#后续追踪\",\"2458\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#噪音评估\",\"2459\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E9%9B%86/#后续追踪\",\"2460\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#💡启发点-2\",\"2461\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#行动清单-1\",\"2462\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax-improvement/#操作步骤-1\",\"2463\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax/#基线计算的创新\",\"2464\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B8%93%E9%A1%B9%E6%8F%90%E5%8D%872/#行动清单\",\"2465\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#_2-降低召回精度\",\"2466\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#缺点\",\"2467\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#grpo策略更新与实现-深度学习中的强化学习优化\",\"2468\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/DeepSpeed/#计算卸载策略\",\"2469\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#从外部来源检索信息的范式\",\"2470\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7%E5%92%8C%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5/#行动清单\",\"2471\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/LoRA%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/LoRA/#行动清单-1\",\"2472\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#模型并行\",\"2473\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E7%94%9F%E4%BA%A7%E5%90%88%E6%88%90%E4%B8%8E%E8%B4%A8%E9%87%8F%E8%BF%87%E6%BB%A4/#📈-趋势预测\",\"2474\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#冷启动的作用\",\"2475\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#当-j-2-时\",\"2476\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B8%93%E9%A1%B9%E6%8F%90%E5%8D%87/#思考\",\"2477\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#分专项能力评估\",\"2478\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/MOE%E7%B3%BB%E5%88%97/Mistral/#行动清单-2\",\"2479\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#数据转换-1\",\"2480\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax-improvement/#常见错误-1\",\"2481\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax/#操作步骤-1\",\"2482\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B8%93%E9%A1%B9%E6%8F%90%E5%8D%872/#数据转换\",\"2483\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#_3-输入受限\",\"2484\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#advanced-rag\",\"2485\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#grpo策略更新公式\",\"2486\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/DeepSpeed/#通信量分析\",\"2487\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#具体方法-1\",\"2488\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7%E5%92%8C%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5/#📈趋势预测\",\"2489\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#model-parallelism-mp\",\"2490\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/SFT%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E7%94%9F%E4%BA%A7%E5%90%88%E6%88%90%E4%B8%8E%E8%B4%A8%E9%87%8F%E8%BF%87%E6%BB%A4/#后续追踪\",\"2491\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#推理过程中的语言一致性奖励\",\"2492\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#tilling-中的-safe-softmax\",\"2493\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#_1-易混淆实体\",\"2494\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#动态采样技术在机器学习中的应用与挑战\",\"2495\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax-improvement/#💡-启发点\",\"2496\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax/#常见错误-1\",\"2497\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B8%93%E9%A1%B9%E6%8F%90%E5%8D%872/#📈趋势预测\",\"2498\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#文本分块过短的影响\",\"2499\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#优点-1\",\"2500\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#代码实现\",\"2501\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#verify-and-edit\",\"2502\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7%E5%92%8C%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5/#后续追踪\",\"2503\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#activation-checkpointing-gradient-checkpointing\",\"2504\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#数据收集与处理\",\"2505\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#我们定义\",\"2506\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#_2-弱相关性\",\"2507\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#核心观点总结\",\"2508\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax-improvement/#行动清单-1\",\"2509\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax/#💡-启发点\",\"2510\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%90%8E%E8%AE%AD%E7%BB%83/SFT%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/STF%E8%AE%AD%E7%BB%83/%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B8%93%E9%A1%B9%E6%8F%90%E5%8D%872/#后续追踪\",\"2511\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#_1-上下文缺失\",\"2512\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#缺点-1\",\"2513\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#常见错误-2\",\"2514\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#方法简介\",\"2515\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#张量并行-intra-layer-tensor-parallelism\",\"2516\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#技术术语转述\",\"2517\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#思路转变\",\"2518\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#_3-function-call\",\"2519\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#动态采样的操作步骤\",\"2520\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax-improvement/#数据转换\",\"2521\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax/#行动清单-1\",\"2522\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#_2-主题信息丢失\",\"2523\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#modular-rag\",\"2524\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#行动清单-2\",\"2525\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#流程图-3\",\"2526\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#代码块\",\"2527\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#操作步骤-1\",\"2528\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#更新公式\",\"2529\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#_4-时效性\",\"2530\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#常见错误-2\",\"2531\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax-improvement/#公式显示\",\"2532\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax/#数据转换\",\"2533\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#_3-碎片化问题\",\"2534\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#优点-2\",\"2535\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#grpo代码优化与重要性采样分析\",\"2536\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#demonstrate-search-predict\",\"2537\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#gemms行并行\",\"2538\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#常见错误-1\",\"2539\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#forward计算代码解析\",\"2540\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#_5-拒答\",\"2541\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#💡-启发点\",\"2542\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/ReMax/#公式显示\",\"2543\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#如何制定合适的文本分块策略\",\"2544\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E6%B5%81%E7%A8%8B%E5%92%8C%E5%88%86%E7%B1%BB/#缺点-2\",\"2545\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#核心观点总结-1\",\"2546\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#方法简介-1\",\"2547\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#gemms列并行与transformer中的张量并行\",\"2548\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#💡启发点-2\",\"2549\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#数据块的拆分\",\"2550\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#开源rag评估框架\",\"2551\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#行动清单-2\",\"2552\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#常见文本分块策略\",\"2553\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#重点段落-2\",\"2554\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#示例流程\",\"2555\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#gemms列并行\",\"2556\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#行动清单-1\",\"2557\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#循环计算过程\",\"2558\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#_1-ragas\",\"2559\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#token-level-loss-优化策略-提升深度学习模型的训练效果\",\"2560\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#固定大小的分块\",\"2561\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#重要性采样的不足\",\"2562\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#iterative-retrieval-augmentation\",\"2563\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#transformer中的张量并行\",\"2564\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#数据转换\",\"2565\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#step-6-外层循环\",\"2566\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#_1-忠实性\",\"2567\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#元数据-2\",\"2568\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#优点-1\",\"2569\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#ppo的重要性采样处理\",\"2570\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#方法简介-2\",\"2571\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#masked-multi-head-self-attention\",\"2572\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#实验结果\",\"2573\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#step-8-内层循环\",\"2574\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#_2-答案相关性\",\"2575\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#核心观点总结-1\",\"2576\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#缺点-1\",\"2577\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#trl实现的简化\",\"2578\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#示例检索-query-生成\",\"2579\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#feed-forward-neural-network\",\"2580\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#deepseek-r1在chinese-simpleqa中的表现\",\"2581\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#step-10-相似度计算\",\"2582\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#_3-上下文相关性\",\"2583\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#重点段落\",\"2584\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#内容分块\",\"2585\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#操作步骤-2\",\"2586\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#流程图-4\",\"2587\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#切分mlp\",\"2588\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#总结生成的长度分析\",\"2589\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#step-11-掩码处理\",\"2590\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E8%AF%84%E4%BC%B0/#_2-langsmith\",\"2591\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#token-level-loss的优势\",\"2592\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#优点-2\",\"2593\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#常见错误-3\",\"2594\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#irp-说明性文本生成任务\",\"2595\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#对比按照行列切分权重的方法\",\"2596\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#蒸馏实验结果\",\"2597\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#step-12-权重计算\",\"2598\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#训练过程的稳定性\",\"2599\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#缺点-2\",\"2600\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#示例代码\",\"2601\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#方法简介-3\",\"2602\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#行并行\",\"2603\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#核心观点总结-1\",\"2604\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#step-13-更新最大值和权重\",\"2605\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#问题解决与策略调整\",\"2606\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#递归分块\",\"2607\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#行动清单-3\",\"2608\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#流程细节\",\"2609\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#列并行\",\"2610\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#重点段落与数据\",\"2611\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#step-14-dropout操作\",\"2612\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#操作步骤-2\",\"2613\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#优点-3\",\"2614\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/GRPO/#数据转换-1\",\"2615\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/LLM-based-Agent-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%88%86%E7%B1%BB/#流程图-5\",\"2616\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#gelu计算中的行列切割策略\",\"2617\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#_1-蒸馏模型的性能提升\",\"2618\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#step-15-更新输出块\",\"2619\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#常见错误-3\",\"2620\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#缺点-3\",\"2621\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#通信量分析\",\"2622\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#_2-大规模模型的对比结果\",\"2623\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#step-16-更新块信息\",\"2624\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#💡-启发点-1\",\"2625\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#从小到大分块\",\"2626\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#self-attention的切分策略\",\"2627\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#💡启发点-3\",\"2628\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#拼接结果\",\"2629\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#行动清单-3\",\"2630\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#优点-4\",\"2631\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#多头注意力并行切分\",\"2632\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#discussion\",\"2633\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#计算量和显存\",\"2634\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#token-level-loss-优化策略-提升深度学习模型的训练效果-1\",\"2635\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#缺点-4\",\"2636\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#当num-heads-2时的情况\",\"2637\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#核心观点总结-2\",\"2638\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#flashattention-计算流程\",\"2639\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#元数据-3\",\"2640\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#特殊结构分块\",\"2641\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#通信量分析-1\",\"2642\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#重点段落-2\",\"2643\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#计算量\",\"2644\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#核心观点总结-2\",\"2645\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#优点-5\",\"2646\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#embedding切分策略\",\"2647\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#技术术语解释-1\",\"2648\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#显存\",\"2649\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#重点段落-1\",\"2650\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#缺点-5\",\"2651\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#输入层embedding\",\"2652\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#操作步骤-2\",\"2653\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/FlashAttention/FlashAttention-Forword%E6%B5%81%E7%A8%8B/#io复杂度\",\"2654\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#token-level-loss的优势-1\",\"2655\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#分块大小的选择\",\"2656\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#输出层embedding\",\"2657\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#常见错误-2\",\"2658\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#训练过程的稳定性-1\",\"2659\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#embedding模型阶段\",\"2660\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#cross-entropy切分的基本流程\",\"2661\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/Common-Models%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/DeepSeek%E7%B3%BB%E5%88%97/DeepSeek-R1/#💡启发点-4\",\"2662\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#问题解决与策略调整-1\",\"2663\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#不同嵌入模型的效果差异\",\"2664\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#优化策略\",\"2665\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#操作步骤-3\",\"2666\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#向量数据库阶段\",\"2667\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#gpu上的局部计算\",\"2668\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#常见错误-4\",\"2669\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#元数据的作用\",\"2670\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#allreduce操作\",\"2671\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#💡-启发点-2\",\"2672\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#示例-日期作为元数据标签\",\"2673\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#计算局部cross-entropy\",\"2674\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#行动清单-4\",\"2675\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#其他元数据类型\",\"2676\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#汇总总loss\",\"2677\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#优化过长回答的奖励机制-提升模型性能\",\"2678\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#大语言模型学习-大模型应用-rag检索增强生成-rag优化中查询索引阶段-rag优化中查询索引阶段\",\"2679\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#transformerblock中的通信优化\",\"2680\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#分类-机器学习优化\",\"2681\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#生成回答阶段的设计与优化\",\"2682\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#张量并行与序列并行\",\"2683\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#标签-奖励机制-模型训练-性能提升\",\"2684\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#提示词设计的关键要点\",\"2685\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#流水线并行-inter-layer-pipeline-parallelism\",\"2686\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#日期-2025年4月12日\",\"2687\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#提示词对模型行为的影响\",\"2688\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#代码块-1\",\"2689\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#核心观点-1\",\"2690\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#减少主观性和幻觉的提示词策略\",\"2691\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#gpipe\",\"2692\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#重点内容\",\"2693\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#动态调整提示词以适应场景需求\",\"2694\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#pipedream\",\"2695\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#操作步骤-4\",\"2696\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#模型选择与开发框架\",\"2697\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#virtual-pipeline\",\"2698\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#常见错误-5\",\"2699\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#根据需求选择合适的-llm\",\"2700\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#_3d并行\",\"2701\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/RL%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96PPO%E6%96%B9%E5%90%91%E7%9A%84%E7%AE%97%E6%B3%95/DAPO/#行动清单-5\",\"2702\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/RAG%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/RAG%E4%BC%98%E5%8C%96/#使用开发框架搭建-rag-系统\",\"2703\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#数据并行-1\",\"2704\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#计算效率高-实现简单\",\"2705\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#张量并行\",\"2706\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#因模型结构而异-实现难度大\",\"2707\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#流水线并行\",\"2708\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#通信成本最低\",\"2709\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#显存和通信效率比较\",\"2710\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#_3d并行技术的混合应用\",\"2711\":\"/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/Megatron-LM/#_4d并行技术在llama3中的应用\"},\"fieldIds\":{\"title\":0,\"titles\":1,\"text\":2},\"fieldLength\":{\"0\":[2,1,1],\"1\":[1,1,1],\"2\":[1,1,1],\"3\":[2,1,1],\"4\":[1,1,8],\"5\":[1,1,186],\"6\":[2,3,1],\"7\":[1,1,9],\"8\":[2,1,1],\"9\":[2,4,1],\"10\":[4,1,58],\"11\":[1,1,57],\"12\":[5,2,56],\"13\":[2,5,1],\"14\":[1,1,6],\"15\":[4,1,43],\"16\":[1,1,10],\"17\":[1,1,11],\"18\":[2,6,118],\"19\":[1,1,3],\"20\":[1,1,29],\"21\":[1,1,9],\"22\":[4,1,31],\"23\":[1,1,2],\"24\":[1,1,8],\"25\":[1,1,2],\"26\":[1,1,1],\"27\":[4,1,42],\"28\":[1,1,4],\"29\":[2,1,1],\"30\":[1,1,4],\"31\":[1,1,4],\"32\":[1,1,32],\"33\":[1,1,1],\"34\":[3,3,56],\"35\":[1,1,4],\"36\":[1,1,1],\"37\":[1,1,5],\"38\":[1,1,4],\"39\":[1,1,161],\"40\":[2,3,78],\"41\":[1,1,4],\"42\":[2,1,7],\"43\":[1,1,1],\"44\":[1,1,5],\"45\":[1,1,4],\"46\":[1,1,5],\"47\":[1,1,43],\"48\":[1,1,27],\"49\":[2,3,69],\"50\":[1,1,4],\"51\":[2,1,9],\"52\":[4,1,1],\"53\":[1,1,3],\"54\":[1,1,4],\"55\":[1,1,5],\"56\":[5,1,44],\"57\":[2,3,33],\"58\":[2,1,1],\"59\":[2,5,20],\"60\":[1,1,4],\"61\":[1,1,1],\"62\":[1,1,4],\"63\":[1,1,18],\"64\":[6,1,1],\"65\":[2,3,32],\"66\":[2,3,8],\"67\":[2,5,35],\"68\":[3,1,1],\"69\":[1,1,4],\"70\":[1,1,1],\"71\":[1,1,9],\"72\":[1,1,4],\"73\":[4,1,19],\"74\":[1,6,12],\"75\":[5,1,1],\"76\":[2,3,25],\"77\":[2,1,1],\"78\":[4,3,1],\"79\":[1,1,4],\"80\":[1,1,11],\"81\":[1,1,1],\"82\":[2,1,1],\"83\":[1,1,1],\"84\":[2,1,19],\"85\":[1,1,10],\"86\":[2,6,10],\"87\":[1,5,11],\"88\":[1,1,9],\"89\":[5,1,1],\"90\":[2,3,24],\"91\":[2,3,13],\"92\":[1,3,11],\"93\":[1,1,14],\"94\":[1,1,12],\"95\":[7,1,1],\"96\":[1,2,10],\"97\":[2,2,11],\"98\":[5,1,15],\"99\":[1,1,9],\"100\":[1,6,1],\"101\":[1,5,22],\"102\":[1,1,8],\"103\":[3,1,1],\"104\":[1,5,12],\"105\":[2,3,14],\"106\":[2,3,28],\"107\":[2,3,17],\"108\":[1,1,1],\"109\":[1,1,8],\"110\":[1,7,11],\"111\":[1,2,18],\"112\":[2,2,12],\"113\":[3,1,19],\"114\":[2,1,1],\"115\":[1,1,28],\"116\":[2,6,18],\"117\":[1,5,1],\"118\":[1,2,17],\"119\":[1,3,11],\"120\":[5,1,1],\"121\":[1,5,27],\"122\":[2,1,1],\"123\":[2,3,13],\"124\":[2,1,1],\"125\":[2,3,22],\"126\":[3,2,4],\"127\":[1,1,1],\"128\":[1,7,12],\"129\":[1,2,1],\"130\":[4,2,25],\"131\":[1,1,11],\"132\":[1,2,10],\"133\":[1,1,10],\"134\":[1,1,1],\"135\":[2,6,39],\"136\":[5,6,11],\"137\":[1,1,5],\"138\":[1,3,13],\"139\":[1,5,11],\"140\":[1,1,1],\"141\":[1,5,1],\"142\":[1,2,11],\"143\":[2,3,7],\"144\":[2,3,17],\"145\":[4,3,2],\"146\":[2,5,5],\"147\":[2,2,11],\"148\":[1,7,1],\"149\":[6,3,9],\"150\":[2,2,8],\"151\":[1,1,68],\"152\":[1,2,7],\"153\":[1,1,26],\"154\":[1,1,10],\"155\":[2,6,17],\"156\":[2,6,18],\"157\":[1,2,8],\"158\":[1,3,1],\"159\":[1,5,15],\"160\":[1,1,10],\"161\":[1,1,1],\"162\":[4,6,31],\"163\":[1,2,16],\"164\":[2,1,32],\"165\":[2,3,27],\"166\":[2,6,19],\"167\":[2,5,9],\"168\":[3,2,17],\"169\":[2,8,30],\"170\":[6,3,8],\"171\":[1,1,1],\"172\":[2,1,35],\"173\":[1,2,3],\"174\":[1,1,10],\"175\":[1,6,7],\"176\":[1,5,1],\"177\":[2,1,1],\"178\":[2,4,16],\"179\":[1,5,1],\"180\":[1,1,12],\"181\":[1,1,9],\"182\":[2,1,10],\"183\":[4,6,18],\"184\":[1,3,37],\"185\":[2,1,15],\"186\":[2,1,1],\"187\":[2,6,22],\"188\":[3,2,16],\"189\":[3,2,53],\"190\":[2,8,39],\"191\":[6,3,7],\"192\":[2,2,10],\"193\":[1,1,24],\"194\":[1,3,25],\"195\":[1,1,1],\"196\":[1,6,11],\"197\":[3,6,16],\"198\":[1,3,11],\"199\":[5,4,42],\"200\":[3,6,1],\"201\":[1,1,1],\"202\":[1,1,9],\"203\":[1,2,12],\"204\":[4,1,1],\"205\":[5,6,28],\"206\":[1,2,1],\"207\":[2,3,13],\"208\":[1,3,19],\"209\":[2,2,11],\"210\":[1,1,8],\"211\":[1,8,17],\"212\":[7,3,9],\"213\":[4,1,43],\"214\":[1,1,11],\"215\":[1,3,21],\"216\":[3,2,18],\"217\":[3,6,10],\"218\":[2,6,25],\"219\":[3,1,9],\"220\":[2,4,21],\"221\":[1,9,33],\"222\":[1,2,33],\"223\":[2,2,27],\"224\":[1,2,1],\"225\":[1,4,10],\"226\":[5,1,10],\"227\":[6,6,23],\"228\":[3,3,37],\"229\":[4,1,10],\"230\":[2,3,32],\"231\":[1,3,11],\"232\":[2,2,7],\"233\":[1,1,9],\"234\":[1,7,11],\"235\":[1,2,1],\"236\":[3,1,11],\"237\":[1,1,21],\"238\":[1,3,24],\"239\":[2,2,20],\"240\":[1,6,29],\"241\":[2,5,8],\"242\":[1,1,4],\"243\":[2,4,9],\"244\":[1,9,7],\"245\":[1,2,19],\"246\":[2,2,31],\"247\":[3,3,52],\"248\":[1,4,10],\"249\":[2,5,6],\"250\":[2,1,1],\"251\":[1,5,18],\"252\":[3,3,15],\"253\":[1,4,15],\"254\":[2,1,1],\"255\":[1,3,7],\"256\":[1,1,12],\"257\":[3,1,11],\"258\":[3,7,9],\"259\":[1,3,22],\"260\":[2,1,7],\"261\":[2,3,28],\"262\":[1,1,1],\"263\":[3,2,22],\"264\":[2,5,8],\"265\":[1,1,5],\"266\":[1,3,38],\"267\":[4,6,1],\"268\":[1,2,27],\"269\":[1,1,6],\"270\":[9,2,1],\"271\":[1,4,1],\"272\":[3,5,1],\"273\":[1,2,12],\"274\":[5,1,1],\"275\":[2,5,15],\"276\":[3,3,36],\"277\":[1,4,1],\"278\":[2,3,13],\"279\":[3,3,9],\"280\":[1,1,1],\"281\":[1,1,11],\"282\":[1,7,10],\"283\":[1,3,19],\"284\":[2,1,6],\"285\":[1,3,28],\"286\":[1,1,11],\"287\":[2,2,14],\"288\":[1,5,5],\"289\":[3,3,12],\"290\":[1,9,31],\"291\":[1,2,24],\"292\":[1,1,20],\"293\":[3,11,35],\"294\":[3,5,16],\"295\":[2,6,15],\"296\":[2,2,11],\"297\":[1,5,11],\"298\":[4,1,1],\"299\":[3,5,17],\"300\":[1,2,9],\"301\":[2,5,12],\"302\":[2,3,28],\"303\":[1,3,12],\"304\":[3,2,9],\"305\":[1,1,17],\"306\":[2,3,3],\"307\":[1,3,25],\"308\":[1,1,23],\"309\":[1,1,12],\"310\":[2,5,1],\"311\":[1,3,8],\"312\":[1,9,8],\"313\":[1,1,7],\"314\":[2,1,6],\"315\":[2,11,18],\"316\":[3,5,8],\"317\":[3,5,1],\"318\":[1,3,22],\"319\":[1,5,19],\"320\":[1,4,11],\"321\":[1,1,1],\"322\":[1,2,6],\"323\":[1,1,1],\"324\":[2,5,62],\"325\":[2,1,1],\"326\":[3,1,13],\"327\":[1,1,19],\"328\":[1,1,10],\"329\":[1,2,1],\"330\":[1,2,34],\"331\":[1,1,1],\"332\":[1,1,37],\"333\":[1,7,6],\"334\":[1,3,12],\"335\":[1,6,12],\"336\":[1,1,5],\"337\":[3,1,9],\"338\":[1,2,12],\"339\":[3,5,11],\"340\":[2,6,10],\"341\":[1,3,10],\"342\":[1,5,1],\"343\":[1,4,9],\"344\":[1,1,11],\"345\":[1,1,11],\"346\":[1,2,28],\"347\":[1,1,12],\"348\":[1,4,10],\"349\":[2,3,10],\"350\":[1,1,8],\"351\":[1,1,13],\"352\":[1,1,1],\"353\":[2,3,8],\"354\":[1,2,8],\"355\":[1,2,20],\"356\":[3,1,7],\"357\":[1,1,1],\"358\":[1,5,5],\"359\":[6,5,26],\"360\":[1,1,6],\"361\":[1,1,9],\"362\":[1,2,9],\"363\":[4,5,11],\"364\":[2,6,21],\"365\":[1,3,24],\"366\":[2,6,7],\"367\":[1,4,1],\"368\":[2,1,14],\"369\":[1,1,18],\"370\":[1,1,1],\"371\":[1,1,1],\"372\":[1,2,4],\"373\":[1,1,21],\"374\":[1,4,1],\"375\":[2,3,10],\"376\":[1,2,7],\"377\":[1,1,11],\"378\":[2,3,4],\"379\":[1,1,1],\"380\":[1,2,8],\"381\":[1,2,30],\"382\":[1,1,11],\"383\":[1,1,8],\"384\":[1,1,12],\"385\":[2,5,6],\"386\":[1,5,7],\"387\":[1,1,6],\"388\":[1,2,7],\"389\":[3,4,1],\"390\":[2,5,1],\"391\":[1,3,43],\"392\":[2,6,15],\"393\":[2,5,27],\"394\":[2,1,1],\"395\":[1,1,1],\"396\":[1,1,12],\"397\":[1,1,10],\"398\":[1,1,11],\"399\":[1,1,1],\"400\":[1,5,13],\"401\":[2,1,1],\"402\":[1,1,1],\"403\":[1,1,8],\"404\":[2,2,4],\"405\":[1,1,13],\"406\":[1,2,11],\"407\":[1,2,15],\"408\":[2,1,10],\"409\":[1,1,7],\"410\":[1,1,1],\"411\":[1,1,18],\"412\":[1,5,7],\"413\":[3,1,11],\"414\":[1,2,11],\"415\":[3,6,9],\"416\":[2,7,16],\"417\":[1,3,9],\"418\":[3,6,2],\"419\":[2,5,14],\"420\":[2,3,21],\"421\":[3,2,10],\"422\":[1,1,18],\"423\":[1,1,7],\"424\":[1,1,14],\"425\":[1,1,7],\"426\":[3,2,34],\"427\":[1,5,14],\"428\":[2,3,4],\"429\":[1,2,8],\"430\":[1,1,1],\"431\":[1,1,9],\"432\":[3,2,14],\"433\":[1,1,15],\"434\":[1,1,14],\"435\":[1,1,46],\"436\":[1,1,12],\"437\":[1,1,12],\"438\":[1,1,1],\"439\":[1,5,11],\"440\":[1,6,16],\"441\":[2,5,1],\"442\":[1,3,8],\"443\":[3,8,12],\"444\":[2,5,27],\"445\":[2,3,18],\"446\":[4,2,10],\"447\":[1,1,1],\"448\":[1,1,1],\"449\":[1,1,12],\"450\":[3,1,1],\"451\":[1,1,1],\"452\":[2,2,3],\"453\":[3,4,9],\"454\":[2,3,18],\"455\":[2,2,9],\"456\":[2,2,11],\"457\":[1,1,6],\"458\":[2,1,1],\"459\":[1,1,1],\"460\":[1,1,1],\"461\":[1,1,13],\"462\":[1,1,17],\"463\":[1,1,1],\"464\":[1,1,10],\"465\":[2,2,18],\"466\":[3,5,13],\"467\":[1,6,10],\"468\":[2,7,12],\"469\":[3,2,30],\"470\":[1,8,21],\"471\":[2,5,16],\"472\":[2,3,5],\"473\":[2,2,13],\"474\":[1,2,31],\"475\":[3,2,22],\"476\":[1,1,1],\"477\":[1,3,12],\"478\":[1,1,10],\"479\":[2,2,10],\"480\":[4,4,33],\"481\":[1,4,17],\"482\":[2,1,1],\"483\":[1,2,13],\"484\":[1,1,10],\"485\":[1,2,27],\"486\":[1,1,1],\"487\":[1,2,10],\"488\":[1,2,23],\"489\":[1,1,8],\"490\":[1,1,10],\"491\":[1,1,1],\"492\":[1,2,7],\"493\":[1,1,1],\"494\":[2,2,12],\"495\":[1,6,12],\"496\":[1,5,1],\"497\":[2,8,26],\"498\":[2,5,12],\"499\":[2,1,14],\"500\":[1,1,2],\"501\":[1,2,21],\"502\":[2,2,28],\"503\":[2,2,45],\"504\":[1,3,1],\"505\":[1,1,9],\"506\":[3,1,1],\"507\":[2,2,13],\"508\":[5,4,29],\"509\":[1,1,1],\"510\":[1,4,4],\"511\":[2,3,4],\"512\":[1,1,1],\"513\":[1,1,12],\"514\":[1,1,15],\"515\":[1,2,33],\"516\":[3,2,13],\"517\":[1,1,1],\"518\":[1,2,12],\"519\":[1,1,1],\"520\":[3,2,1],\"521\":[1,1,15],\"522\":[1,1,5],\"523\":[2,2,11],\"524\":[1,2,8],\"525\":[4,2,20],\"526\":[4,2,35],\"527\":[1,4,7],\"528\":[3,6,10],\"529\":[2,6,14],\"530\":[1,4,7],\"531\":[2,1,6],\"532\":[1,2,21],\"533\":[1,2,21],\"534\":[2,2,9],\"535\":[2,2,36],\"536\":[1,4,6],\"537\":[4,2,46],\"538\":[1,3,2],\"539\":[2,1,10],\"540\":[1,1,10],\"541\":[1,1,1],\"542\":[2,4,8],\"543\":[1,1,11],\"544\":[2,3,20],\"545\":[1,1,10],\"546\":[1,1,6],\"547\":[1,1,1],\"548\":[1,2,25],\"549\":[1,2,18],\"550\":[1,1,10],\"551\":[1,2,1],\"552\":[1,1,11],\"553\":[2,5,27],\"554\":[1,1,1],\"555\":[1,1,12],\"556\":[2,2,11],\"557\":[1,1,1],\"558\":[3,2,42],\"559\":[2,2,28],\"560\":[1,4,28],\"561\":[2,6,3],\"562\":[1,5,18],\"563\":[3,4,10],\"564\":[3,1,10],\"565\":[1,1,7],\"566\":[1,1,8],\"567\":[2,2,21],\"568\":[2,2,23],\"569\":[1,4,3],\"570\":[5,2,7],\"571\":[1,3,6],\"572\":[1,2,14],\"573\":[1,1,11],\"574\":[1,1,13],\"575\":[2,2,21],\"576\":[2,2,7],\"577\":[1,1,11],\"578\":[1,1,11],\"579\":[1,1,1],\"580\":[1,1,4],\"581\":[1,2,22],\"582\":[1,1,9],\"583\":[1,2,7],\"584\":[1,1,1],\"585\":[1,1,7],\"586\":[1,3,26],\"587\":[1,1,7],\"588\":[1,1,10],\"589\":[2,5,30],\"590\":[1,2,50],\"591\":[1,1,16],\"592\":[1,2,3],\"593\":[4,2,23],\"594\":[2,1,12],\"595\":[1,4,32],\"596\":[2,6,4],\"597\":[1,5,9],\"598\":[2,1,7],\"599\":[1,1,7],\"600\":[1,1,4],\"601\":[1,1,7],\"602\":[1,4,4],\"603\":[3,2,5],\"604\":[1,3,2],\"605\":[1,3,6],\"606\":[1,1,9],\"607\":[1,1,1],\"608\":[1,1,35],\"609\":[1,1,1],\"610\":[3,1,16],\"611\":[1,1,31],\"612\":[1,2,10],\"613\":[1,1,4],\"614\":[1,2,30],\"615\":[1,1,4],\"616\":[1,1,7],\"617\":[1,1,11],\"618\":[1,2,33],\"619\":[2,3,80],\"620\":[1,1,1],\"621\":[1,1,9],\"622\":[4,2,36],\"623\":[1,2,20],\"624\":[1,1,1],\"625\":[1,1,6],\"626\":[1,2,8],\"627\":[1,1,6],\"628\":[3,1,9],\"629\":[2,4,9],\"630\":[2,5,10],\"631\":[3,5,38],\"632\":[1,1,23],\"633\":[1,1,7],\"634\":[1,1,7],\"635\":[3,1,10],\"636\":[1,3,1],\"637\":[1,1,7],\"638\":[1,3,6],\"639\":[1,2,18],\"640\":[2,1,122],\"641\":[1,1,9],\"642\":[1,1,9],\"643\":[1,1,6],\"644\":[2,2,21],\"645\":[1,1,10],\"646\":[1,2,64],\"647\":[1,2,138],\"648\":[1,1,4],\"649\":[1,2,9],\"650\":[2,1,9],\"651\":[1,1,9],\"652\":[1,1,7],\"653\":[1,2,19],\"654\":[1,3,16],\"655\":[2,2,36],\"656\":[1,1,119],\"657\":[1,2,14],\"658\":[1,2,6],\"659\":[1,1,11],\"660\":[2,1,19],\"661\":[1,1,1],\"662\":[1,1,9],\"663\":[1,1,8],\"664\":[2,4,10],\"665\":[1,5,8],\"666\":[1,1,4],\"667\":[1,1,8],\"668\":[1,1,5],\"669\":[1,1,13],\"670\":[1,4,11],\"671\":[1,1,4],\"672\":[2,4,36],\"673\":[1,2,5],\"674\":[1,1,1],\"675\":[1,1,10],\"676\":[2,1,21],\"677\":[3,1,19],\"678\":[1,1,5],\"679\":[1,1,1],\"680\":[2,1,4],\"681\":[1,2,9],\"682\":[4,1,6],\"683\":[1,1,9],\"684\":[1,1,4],\"685\":[3,1,18],\"686\":[1,1,4],\"687\":[1,1,1],\"688\":[1,2,10],\"689\":[1,2,5],\"690\":[2,2,10],\"691\":[1,1,4],\"692\":[1,1,7],\"693\":[1,1,8],\"694\":[3,1,9],\"695\":[1,1,21],\"696\":[1,1,5],\"697\":[1,1,1],\"698\":[1,1,19],\"699\":[1,2,5],\"700\":[2,1,4],\"701\":[1,1,10],\"702\":[3,4,10],\"703\":[1,5,5],\"704\":[1,1,16],\"705\":[3,1,10],\"706\":[1,1,7],\"707\":[1,1,6],\"708\":[1,4,8],\"709\":[1,1,8],\"710\":[2,4,26],\"711\":[2,2,4],\"712\":[4,2,10],\"713\":[1,1,5],\"714\":[2,1,1],\"715\":[1,3,25],\"716\":[1,1,1],\"717\":[1,1,3],\"718\":[2,2,10],\"719\":[3,1,13],\"720\":[1,2,6],\"721\":[1,1,5],\"722\":[1,1,2],\"723\":[1,2,30],\"724\":[1,2,8],\"725\":[1,2,3],\"726\":[2,2,8],\"727\":[3,1,5],\"728\":[1,1,16],\"729\":[1,1,16],\"730\":[1,1,20],\"731\":[1,1,5],\"732\":[1,2,44],\"733\":[1,1,14],\"734\":[1,1,11],\"735\":[1,2,5],\"736\":[3,1,11],\"737\":[1,1,7],\"738\":[1,4,17],\"739\":[1,5,10],\"740\":[1,1,26],\"741\":[1,1,26],\"742\":[1,4,6],\"743\":[1,1,1],\"744\":[1,4,1],\"745\":[2,2,7],\"746\":[4,2,5],\"747\":[1,1,13],\"748\":[1,3,36],\"749\":[1,1,11],\"750\":[1,1,55],\"751\":[1,1,6],\"752\":[1,1,4],\"753\":[2,1,6],\"754\":[1,1,11],\"755\":[1,1,4],\"756\":[1,1,3],\"757\":[1,2,39],\"758\":[1,1,5],\"759\":[1,2,3],\"760\":[2,2,8],\"761\":[1,1,4],\"762\":[1,1,34],\"763\":[1,1,40],\"764\":[1,1,3],\"765\":[1,1,13],\"766\":[1,1,73],\"767\":[1,2,44],\"768\":[1,1,41],\"769\":[1,1,35],\"770\":[1,1,7],\"771\":[3,5,14],\"772\":[1,1,4],\"773\":[1,3,40],\"774\":[1,1,3],\"775\":[3,5,32],\"776\":[3,2,10],\"777\":[1,1,5],\"778\":[1,1,56],\"779\":[1,3,40],\"780\":[1,1,10],\"781\":[1,1,6],\"782\":[1,1,9],\"783\":[1,1,43],\"784\":[1,1,4],\"785\":[3,1,5],\"786\":[1,1,4],\"787\":[1,1,4],\"788\":[1,1,4],\"789\":[1,2,15],\"790\":[1,1,4],\"791\":[1,2,6],\"792\":[1,1,9],\"793\":[1,1,3],\"794\":[1,1,9],\"795\":[4,2,14],\"796\":[1,1,4],\"797\":[1,1,6],\"798\":[1,1,1],\"799\":[1,1,23],\"800\":[1,1,7],\"801\":[1,1,1],\"802\":[1,1,1],\"803\":[1,2,11],\"804\":[1,3,14],\"805\":[1,1,5],\"806\":[1,4,5],\"807\":[1,2,8],\"808\":[1,1,4],\"809\":[1,1,5],\"810\":[1,3,31],\"811\":[3,2,11],\"812\":[1,2,7],\"813\":[1,1,16],\"814\":[1,1,1],\"815\":[1,1,5],\"816\":[1,1,4],\"817\":[1,1,5],\"818\":[1,1,5],\"819\":[1,1,8],\"820\":[1,1,82],\"821\":[1,1,8],\"822\":[1,2,6],\"823\":[1,1,4],\"824\":[1,1,5],\"825\":[1,1,9],\"826\":[3,2,13],\"827\":[1,1,1],\"828\":[1,1,1],\"829\":[1,1,4],\"830\":[1,1,1],\"831\":[1,1,7],\"832\":[1,1,11],\"833\":[1,1,1],\"834\":[1,1,5],\"835\":[1,1,12],\"836\":[1,1,11],\"837\":[1,2,20],\"838\":[1,4,1],\"839\":[1,1,2],\"840\":[1,4,43],\"841\":[1,2,5],\"842\":[1,1,6],\"843\":[1,1,23],\"844\":[2,1,10],\"845\":[3,2,24],\"846\":[1,2,16],\"847\":[4,2,33],\"848\":[1,1,11],\"849\":[1,1,1],\"850\":[3,1,7],\"851\":[1,1,8],\"852\":[1,1,5],\"853\":[1,1,1],\"854\":[1,1,11],\"855\":[1,1,1],\"856\":[1,1,8],\"857\":[1,1,5],\"858\":[1,1,15],\"859\":[1,1,12],\"860\":[3,2,8],\"861\":[1,1,11],\"862\":[1,1,11],\"863\":[2,1,1],\"864\":[1,1,5],\"865\":[1,1,9],\"866\":[1,1,4],\"867\":[1,1,20],\"868\":[2,1,42],\"869\":[1,1,3],\"870\":[2,1,17],\"871\":[4,1,7],\"872\":[2,1,1],\"873\":[1,2,16],\"874\":[1,5,1],\"875\":[1,1,20],\"876\":[1,3,11],\"877\":[1,1,4],\"878\":[1,1,3],\"879\":[2,1,6],\"880\":[3,2,18],\"881\":[4,2,31],\"882\":[4,1,18],\"883\":[1,1,10],\"884\":[2,1,1],\"885\":[2,1,1],\"886\":[1,1,3],\"887\":[1,1,10],\"888\":[2,1,1],\"889\":[1,1,33],\"890\":[1,1,9],\"891\":[1,1,3],\"892\":[1,1,7],\"893\":[1,1,7],\"894\":[1,1,13],\"895\":[2,1,1],\"896\":[4,1,4],\"897\":[1,1,5],\"898\":[1,1,10],\"899\":[1,2,11],\"900\":[2,1,1],\"901\":[1,1,16],\"902\":[1,1,4],\"903\":[1,1,1],\"904\":[6,1,1],\"905\":[1,1,3],\"906\":[1,1,1],\"907\":[1,1,1],\"908\":[1,2,11],\"909\":[1,2,20],\"910\":[1,6,15],\"911\":[1,1,12],\"912\":[1,3,11],\"913\":[1,1,10],\"914\":[1,1,4],\"915\":[2,1,3],\"916\":[1,1,8],\"917\":[4,1,89],\"918\":[1,5,11],\"919\":[1,1,20],\"920\":[1,2,11],\"921\":[2,1,1],\"922\":[1,2,10],\"923\":[1,1,6],\"924\":[2,2,1],\"925\":[1,1,11],\"926\":[1,1,13],\"927\":[1,1,4],\"928\":[1,1,10],\"929\":[1,1,21],\"930\":[1,2,10],\"931\":[1,5,12],\"932\":[1,2,28],\"933\":[1,1,22],\"934\":[1,2,19],\"935\":[1,2,13],\"936\":[1,1,1],\"937\":[1,1,4],\"938\":[2,2,20],\"939\":[3,7,4],\"940\":[1,1,2],\"941\":[4,2,20],\"942\":[1,1,1],\"943\":[2,2,10],\"944\":[2,1,1],\"945\":[2,1,1],\"946\":[1,1,1],\"947\":[1,2,1],\"948\":[1,1,1],\"949\":[1,5,20],\"950\":[1,1,1],\"951\":[1,3,5],\"952\":[1,1,3],\"953\":[2,1,5],\"954\":[3,2,19],\"955\":[3,1,1],\"956\":[2,2,16],\"957\":[1,2,1],\"958\":[1,2,2],\"959\":[2,1,1],\"960\":[1,2,6],\"961\":[1,2,18],\"962\":[5,2,1],\"963\":[1,1,1],\"964\":[1,1,1],\"965\":[2,1,9],\"966\":[3,1,7],\"967\":[1,1,17],\"968\":[1,2,5],\"969\":[1,6,3],\"970\":[1,2,12],\"971\":[1,1,1],\"972\":[1,2,1],\"973\":[1,1,1],\"974\":[1,1,1],\"975\":[1,2,8],\"976\":[1,1,1],\"977\":[2,1,1],\"978\":[1,2,7],\"979\":[1,1,3],\"980\":[2,2,20],\"981\":[5,7,20],\"982\":[1,1,3],\"983\":[4,2,15],\"984\":[2,1,1],\"985\":[2,2,16],\"986\":[1,2,12],\"987\":[1,2,10],\"988\":[1,1,11],\"989\":[1,3,6],\"990\":[1,1,11],\"991\":[2,5,1],\"992\":[2,2,7],\"993\":[1,1,5],\"994\":[3,1,7],\"995\":[3,2,14],\"996\":[4,4,42],\"997\":[4,2,16],\"998\":[1,3,30],\"999\":[1,2,10],\"1000\":[1,2,11],\"1001\":[1,1,10],\"1002\":[1,2,15],\"1003\":[1,1,1],\"1004\":[1,2,9],\"1005\":[2,2,1],\"1006\":[5,2,17],\"1007\":[1,2,13],\"1008\":[1,1,39],\"1009\":[1,2,14],\"1010\":[1,6,4],\"1011\":[1,1,10],\"1012\":[1,2,6],\"1013\":[1,3,14],\"1014\":[1,1,3],\"1015\":[1,1,12],\"1016\":[1,2,1],\"1017\":[1,1,10],\"1018\":[1,2,10],\"1019\":[1,2,14],\"1020\":[1,1,1],\"1021\":[3,2,17],\"1022\":[3,7,29],\"1023\":[1,1,14],\"1024\":[6,1,1],\"1025\":[3,1,40],\"1026\":[1,2,8],\"1027\":[2,1,1],\"1028\":[1,2,10],\"1029\":[1,1,1],\"1030\":[1,3,17],\"1031\":[1,1,9],\"1032\":[1,7,7],\"1033\":[2,2,11],\"1034\":[1,1,4],\"1035\":[3,2,11],\"1036\":[3,4,15],\"1037\":[5,2,7],\"1038\":[1,3,4],\"1039\":[1,2,2],\"1040\":[1,2,12],\"1041\":[1,1,18],\"1042\":[1,1,1],\"1043\":[1,2,1],\"1044\":[1,1,11],\"1045\":[1,2,9],\"1046\":[1,2,8],\"1047\":[1,2,25],\"1048\":[1,2,6],\"1049\":[1,2,1],\"1050\":[1,6,31],\"1051\":[1,1,6],\"1052\":[1,2,7],\"1053\":[1,3,11],\"1054\":[1,1,1],\"1055\":[1,1,6],\"1056\":[1,1,1],\"1057\":[1,1,11],\"1058\":[1,1,1],\"1059\":[1,3,13],\"1060\":[1,1,8],\"1061\":[1,2,12],\"1062\":[1,2,7],\"1063\":[1,1,10],\"1064\":[1,1,1],\"1065\":[8,1,14],\"1066\":[2,1,11],\"1067\":[2,1,7],\"1068\":[2,1,9],\"1069\":[1,2,27],\"1070\":[1,2,11],\"1071\":[1,2,16],\"1072\":[1,2,12],\"1073\":[1,3,11],\"1074\":[1,1,1],\"1075\":[1,7,29],\"1076\":[2,2,13],\"1077\":[1,1,3],\"1078\":[1,1,1],\"1079\":[2,1,12],\"1080\":[1,1,5],\"1081\":[1,2,1],\"1082\":[1,2,14],\"1083\":[1,2,11],\"1084\":[1,1,3],\"1085\":[1,1,11],\"1086\":[2,1,11],\"1087\":[1,3,8],\"1088\":[1,1,20],\"1089\":[1,1,13],\"1090\":[1,2,1],\"1091\":[1,1,7],\"1092\":[1,2,11],\"1093\":[1,3,25],\"1094\":[1,5,8],\"1095\":[1,1,2],\"1096\":[1,2,8],\"1097\":[1,2,1],\"1098\":[1,1,10],\"1099\":[1,1,1],\"1100\":[1,1,2],\"1101\":[1,1,10],\"1102\":[1,2,14],\"1103\":[1,1,12],\"1104\":[1,3,7],\"1105\":[1,1,1],\"1106\":[1,2,1],\"1107\":[1,1,7],\"1108\":[1,1,9],\"1109\":[3,2,10],\"1110\":[1,1,12],\"1111\":[1,1,32],\"1112\":[1,1,21],\"1113\":[1,1,9],\"1114\":[1,2,14],\"1115\":[1,1,1],\"1116\":[1,2,1],\"1117\":[1,2,12],\"1118\":[1,1,15],\"1119\":[1,2,29],\"1120\":[1,2,7],\"1121\":[1,2,11],\"1122\":[2,5,1],\"1123\":[1,1,16],\"1124\":[1,1,25],\"1125\":[2,1,14],\"1126\":[1,1,3],\"1127\":[3,3,43],\"1128\":[1,2,1],\"1129\":[1,2,7],\"1130\":[1,2,10],\"1131\":[1,1,8],\"1132\":[1,2,9],\"1133\":[1,1,1],\"1134\":[1,3,8],\"1135\":[1,1,1],\"1136\":[1,1,18],\"1137\":[1,1,8],\"1138\":[1,3,17],\"1139\":[1,1,14],\"1140\":[1,1,12],\"1141\":[1,1,10],\"1142\":[1,3,37],\"1143\":[1,6,12],\"1144\":[1,1,7],\"1145\":[1,1,10],\"1146\":[1,3,9],\"1147\":[1,1,6],\"1148\":[1,1,9],\"1149\":[1,1,9],\"1150\":[1,1,13],\"1151\":[1,1,9],\"1152\":[3,2,12],\"1153\":[1,1,8],\"1154\":[2,3,12],\"1155\":[1,2,13],\"1156\":[1,3,20],\"1157\":[1,1,7],\"1158\":[1,1,1],\"1159\":[2,2,5],\"1160\":[6,1,14],\"1161\":[2,1,9],\"1162\":[1,1,26],\"1163\":[3,1,12],\"1164\":[1,2,14],\"1165\":[1,1,1],\"1166\":[1,3,5],\"1167\":[1,3,6],\"1168\":[1,1,1],\"1169\":[1,1,1],\"1170\":[1,2,17],\"1171\":[1,2,5],\"1172\":[1,1,1],\"1173\":[1,7,5],\"1174\":[1,1,5],\"1175\":[2,1,16],\"1176\":[3,1,10],\"1177\":[1,1,4],\"1178\":[1,2,23],\"1179\":[2,3,21],\"1180\":[1,2,1],\"1181\":[1,2,9],\"1182\":[1,1,1],\"1183\":[1,2,1],\"1184\":[3,1,16],\"1185\":[1,1,14],\"1186\":[1,2,13],\"1187\":[1,2,39],\"1188\":[6,1,5],\"1189\":[1,1,5],\"1190\":[1,3,7],\"1191\":[1,1,1],\"1192\":[1,1,3],\"1193\":[1,3,9],\"1194\":[1,1,4],\"1195\":[1,3,3],\"1196\":[1,1,1],\"1197\":[1,1,12],\"1198\":[1,1,18],\"1199\":[1,2,14],\"1200\":[1,1,4],\"1201\":[2,5,11],\"1202\":[1,1,1],\"1203\":[1,2,12],\"1204\":[1,2,24],\"1205\":[1,3,9],\"1206\":[1,1,4],\"1207\":[1,2,31],\"1208\":[1,1,27],\"1209\":[7,1,14],\"1210\":[3,1,5],\"1211\":[1,1,19],\"1212\":[1,1,9],\"1213\":[1,2,11],\"1214\":[12,1,1],\"1215\":[1,3,8],\"1216\":[1,2,7],\"1217\":[1,2,16],\"1218\":[5,1,1],\"1219\":[1,1,11],\"1220\":[1,2,3],\"1221\":[1,1,2],\"1222\":[1,7,36],\"1223\":[1,1,4],\"1224\":[2,1,44],\"1225\":[2,1,47],\"1226\":[1,1,9],\"1227\":[1,2,14],\"1228\":[1,3,11],\"1229\":[1,3,27],\"1230\":[1,1,6],\"1231\":[2,2,4],\"1232\":[2,3,37],\"1233\":[2,4,19],\"1234\":[1,1,5],\"1235\":[1,1,9],\"1236\":[1,2,5],\"1237\":[2,2,18],\"1238\":[4,7,14],\"1239\":[1,1,16],\"1240\":[1,3,6],\"1241\":[2,2,22],\"1242\":[1,1,4],\"1243\":[1,2,12],\"1244\":[1,1,3],\"1245\":[1,2,9],\"1246\":[2,2,40],\"1247\":[1,1,1],\"1248\":[1,1,16],\"1249\":[1,1,10],\"1250\":[1,2,16],\"1251\":[1,1,1],\"1252\":[2,2,7],\"1253\":[1,2,6],\"1254\":[1,2,6],\"1255\":[1,2,11],\"1256\":[1,3,13],\"1257\":[1,1,7],\"1258\":[3,2,32],\"1259\":[3,1,16],\"1260\":[6,1,18],\"1261\":[2,1,19],\"1262\":[2,1,8],\"1263\":[1,1,13],\"1264\":[1,2,12],\"1265\":[1,1,15],\"1266\":[2,4,53],\"1267\":[1,3,12],\"1268\":[1,2,16],\"1269\":[3,6,7],\"1270\":[1,1,5],\"1271\":[1,2,4],\"1272\":[1,1,5],\"1273\":[2,5,10],\"1274\":[1,1,4],\"1275\":[2,1,20],\"1276\":[1,1,3],\"1277\":[1,2,10],\"1278\":[2,3,18],\"1279\":[1,3,31],\"1280\":[1,1,5],\"1281\":[1,2,22],\"1282\":[2,3,20],\"1283\":[3,1,1],\"1284\":[2,2,13],\"1285\":[1,1,27],\"1286\":[1,1,1],\"1287\":[1,2,23],\"1288\":[1,2,16],\"1289\":[3,7,12],\"1290\":[1,2,14],\"1291\":[2,2,9],\"1292\":[1,1,13],\"1293\":[1,2,4],\"1294\":[1,1,4],\"1295\":[1,2,5],\"1296\":[2,2,17],\"1297\":[4,2,25],\"1298\":[1,1,14],\"1299\":[1,1,9],\"1300\":[1,2,19],\"1301\":[1,1,5],\"1302\":[3,3,22],\"1303\":[2,2,5],\"1304\":[1,1,8],\"1305\":[1,2,11],\"1306\":[1,2,20],\"1307\":[2,1,8],\"1308\":[2,1,13],\"1309\":[1,1,16],\"1310\":[1,1,12],\"1311\":[1,2,3],\"1312\":[1,1,1],\"1313\":[1,3,8],\"1314\":[1,2,7],\"1315\":[1,1,1],\"1316\":[4,6,7],\"1317\":[1,1,4],\"1318\":[1,2,12],\"1319\":[1,1,2],\"1320\":[1,1,1],\"1321\":[1,1,21],\"1322\":[1,7,4],\"1323\":[1,1,15],\"1324\":[1,2,55],\"1325\":[1,2,5],\"1326\":[1,3,16],\"1327\":[1,1,6],\"1328\":[1,2,15],\"1329\":[3,3,51],\"1330\":[1,4,5],\"1331\":[2,2,12],\"1332\":[1,1,21],\"1333\":[2,1,31],\"1334\":[1,1,9],\"1335\":[1,1,8],\"1336\":[3,7,13],\"1337\":[1,2,12],\"1338\":[1,4,21],\"1339\":[1,1,6],\"1340\":[1,2,4],\"1341\":[1,1,13],\"1342\":[1,2,4],\"1343\":[2,2,31],\"1344\":[2,2,52],\"1345\":[1,1,3],\"1346\":[1,1,3],\"1347\":[1,2,31],\"1348\":[2,1,6],\"1349\":[1,2,5],\"1350\":[1,2,7],\"1351\":[1,1,5],\"1352\":[1,2,5],\"1353\":[1,1,28],\"1354\":[3,1,15],\"1355\":[1,2,17],\"1356\":[1,1,9],\"1357\":[2,2,3],\"1358\":[1,2,16],\"1359\":[2,4,32],\"1360\":[1,2,12],\"1361\":[1,2,8],\"1362\":[3,6,5],\"1363\":[1,1,4],\"1364\":[1,2,71],\"1365\":[1,1,10],\"1366\":[1,1,6],\"1367\":[4,1,21],\"1368\":[8,7,48],\"1369\":[1,1,4],\"1370\":[1,2,10],\"1371\":[1,2,5],\"1372\":[2,1,8],\"1373\":[1,1,12],\"1374\":[1,2,13],\"1375\":[1,4,13],\"1376\":[2,2,14],\"1377\":[2,1,32],\"1378\":[1,1,6],\"1379\":[1,1,7],\"1380\":[1,1,1],\"1381\":[1,1,8],\"1382\":[3,7,13],\"1383\":[1,2,4],\"1384\":[1,4,11],\"1385\":[1,2,12],\"1386\":[1,1,5],\"1387\":[1,2,7],\"1388\":[2,2,7],\"1389\":[1,2,14],\"1390\":[1,1,1],\"1391\":[1,1,3],\"1392\":[1,1,25],\"1393\":[1,1,8],\"1394\":[3,3,9],\"1395\":[1,2,18],\"1396\":[1,1,1],\"1397\":[2,1,3],\"1398\":[1,2,14],\"1399\":[1,1,11],\"1400\":[1,2,1],\"1401\":[2,1,1],\"1402\":[1,1,1],\"1403\":[1,2,16],\"1404\":[1,2,19],\"1405\":[1,3,26],\"1406\":[1,2,12],\"1407\":[1,2,13],\"1408\":[4,1,11],\"1409\":[1,1,9],\"1410\":[1,1,7],\"1411\":[1,1,1],\"1412\":[2,5,16],\"1413\":[1,7,15],\"1414\":[1,1,12],\"1415\":[1,1,1],\"1416\":[1,2,11],\"1417\":[1,2,8],\"1418\":[1,1,10],\"1419\":[1,2,25],\"1420\":[1,4,37],\"1421\":[1,1,12],\"1422\":[1,3,3],\"1423\":[2,2,9],\"1424\":[1,2,8],\"1425\":[2,1,9],\"1426\":[1,1,1],\"1427\":[2,1,7],\"1428\":[1,1,1],\"1429\":[3,7,12],\"1430\":[1,2,3],\"1431\":[1,4,8],\"1432\":[3,1,1],\"1433\":[2,1,1],\"1434\":[1,1,1],\"1435\":[1,1,37],\"1436\":[2,1,24],\"1437\":[1,2,16],\"1438\":[1,1,3],\"1439\":[1,1,29],\"1440\":[2,1,1],\"1441\":[1,1,19],\"1442\":[1,2,9],\"1443\":[1,1,1],\"1444\":[1,1,4],\"1445\":[1,1,10],\"1446\":[1,2,5],\"1447\":[3,1,10],\"1448\":[2,3,12],\"1449\":[1,2,10],\"1450\":[2,2,23],\"1451\":[2,2,33],\"1452\":[1,3,12],\"1453\":[2,1,26],\"1454\":[2,5,7],\"1455\":[1,1,35],\"1456\":[1,1,14],\"1457\":[1,2,5],\"1458\":[2,1,191],\"1459\":[2,4,3],\"1460\":[1,1,16],\"1461\":[1,1,12],\"1462\":[1,2,14],\"1463\":[1,1,15],\"1464\":[2,2,11],\"1465\":[1,4,26],\"1466\":[1,1,10],\"1467\":[5,4,8],\"1468\":[2,2,12],\"1469\":[1,2,6],\"1470\":[1,3,17],\"1471\":[1,1,10],\"1472\":[3,1,8],\"1473\":[1,1,10],\"1474\":[1,1,12],\"1475\":[1,2,8],\"1476\":[1,1,1],\"1477\":[1,3,2],\"1478\":[2,1,9],\"1479\":[1,2,9],\"1480\":[1,1,1],\"1481\":[3,1,10],\"1482\":[2,1,9],\"1483\":[1,2,7],\"1484\":[1,1,4],\"1485\":[1,1,22],\"1486\":[1,2,11],\"1487\":[3,3,15],\"1488\":[1,1,2],\"1489\":[2,1,11],\"1490\":[1,1,10],\"1491\":[1,1,11],\"1492\":[1,2,16],\"1493\":[1,1,18],\"1494\":[2,1,6],\"1495\":[1,2,14],\"1496\":[2,2,15],\"1497\":[2,1,12],\"1498\":[1,1,1],\"1499\":[2,3,15],\"1500\":[2,1,8],\"1501\":[2,5,5],\"1502\":[1,2,10],\"1503\":[1,2,4],\"1504\":[2,6,6],\"1505\":[1,1,19],\"1506\":[1,1,1],\"1507\":[1,1,10],\"1508\":[3,2,11],\"1509\":[1,1,1],\"1510\":[1,1,11],\"1511\":[2,4,1],\"1512\":[2,2,6],\"1513\":[1,1,15],\"1514\":[1,3,12],\"1515\":[1,1,14],\"1516\":[1,1,11],\"1517\":[1,1,17],\"1518\":[4,2,10],\"1519\":[1,1,1],\"1520\":[3,2,1],\"1521\":[1,3,6],\"1522\":[1,2,10],\"1523\":[1,2,9],\"1524\":[1,1,1],\"1525\":[1,1,1],\"1526\":[2,1,9],\"1527\":[1,1,11],\"1528\":[1,1,5],\"1529\":[2,1,1],\"1530\":[1,2,10],\"1531\":[1,1,14],\"1532\":[1,1,4],\"1533\":[1,2,14],\"1534\":[2,1,1],\"1535\":[1,1,24],\"1536\":[1,1,82],\"1537\":[2,1,9],\"1538\":[1,2,1],\"1539\":[1,2,19],\"1540\":[2,2,6],\"1541\":[1,2,9],\"1542\":[1,2,31],\"1543\":[2,2,9],\"1544\":[5,3,16],\"1545\":[2,5,7],\"1546\":[1,1,12],\"1547\":[1,1,3],\"1548\":[1,1,3],\"1549\":[1,1,1],\"1550\":[2,6,9],\"1551\":[1,1,9],\"1552\":[2,2,40],\"1553\":[1,1,1],\"1554\":[1,1,1],\"1555\":[1,1,13],\"1556\":[1,2,5],\"1557\":[1,2,13],\"1558\":[1,1,11],\"1559\":[1,6,27],\"1560\":[1,1,6],\"1561\":[2,2,16],\"1562\":[1,3,11],\"1563\":[1,1,1],\"1564\":[1,1,13],\"1565\":[2,1,1],\"1566\":[1,1,31],\"1567\":[4,2,8],\"1568\":[1,1,9],\"1569\":[7,5,30],\"1570\":[1,3,2],\"1571\":[1,2,1],\"1572\":[1,3,12],\"1573\":[1,1,1],\"1574\":[1,1,1],\"1575\":[1,1,10],\"1576\":[1,2,11],\"1577\":[3,1,11],\"1578\":[5,3,35],\"1579\":[1,2,1],\"1580\":[3,1,7],\"1581\":[1,1,2],\"1582\":[1,2,81],\"1583\":[1,1,11],\"1584\":[2,2,1],\"1585\":[2,1,1],\"1586\":[1,1,8],\"1587\":[1,1,14],\"1588\":[16,3,12],\"1589\":[1,2,11],\"1590\":[1,1,11],\"1591\":[1,2,35],\"1592\":[1,1,22],\"1593\":[3,2,9],\"1594\":[3,3,28],\"1595\":[3,1,6],\"1596\":[1,1,18],\"1597\":[1,1,3],\"1598\":[2,2,12],\"1599\":[1,1,11],\"1600\":[2,6,5],\"1601\":[1,1,3],\"1602\":[2,2,1],\"1603\":[1,1,1],\"1604\":[1,1,10],\"1605\":[1,1,11],\"1606\":[2,1,20],\"1607\":[1,2,4],\"1608\":[2,1,20],\"1609\":[1,1,11],\"1610\":[2,4,14],\"1611\":[2,2,10],\"1612\":[2,1,13],\"1613\":[2,2,26],\"1614\":[3,2,10],\"1615\":[2,1,12],\"1616\":[1,1,1],\"1617\":[4,1,36],\"1618\":[1,1,9],\"1619\":[7,5,20],\"1620\":[1,3,8],\"1621\":[1,3,7],\"1622\":[1,3,89],\"1623\":[2,1,1],\"1624\":[1,1,11],\"1625\":[3,1,12],\"1626\":[1,1,8],\"1627\":[2,1,1],\"1628\":[1,2,54],\"1629\":[1,1,9],\"1630\":[3,1,1],\"1631\":[1,3,19],\"1632\":[1,1,7],\"1633\":[1,1,24],\"1634\":[1,2,51],\"1635\":[2,1,1],\"1636\":[1,1,17],\"1637\":[5,2,1],\"1638\":[1,2,11],\"1639\":[1,1,5],\"1640\":[2,1,1],\"1641\":[1,3,5],\"1642\":[1,2,11],\"1643\":[1,1,1],\"1644\":[1,2,39],\"1645\":[1,2,12],\"1646\":[1,1,21],\"1647\":[1,2,15],\"1648\":[2,3,6],\"1649\":[5,4,1],\"1650\":[1,1,14],\"1651\":[1,1,6],\"1652\":[2,2,6],\"1653\":[1,1,12],\"1654\":[1,1,1],\"1655\":[4,1,1],\"1656\":[2,1,5],\"1657\":[2,4,34],\"1658\":[1,1,52],\"1659\":[1,1,5],\"1660\":[1,1,7],\"1661\":[3,1,1],\"1662\":[2,1,1],\"1663\":[1,6,14],\"1664\":[2,2,10],\"1665\":[1,3,16],\"1666\":[1,2,18],\"1667\":[3,2,12],\"1668\":[1,2,13],\"1669\":[1,1,1],\"1670\":[2,1,1],\"1671\":[1,2,36],\"1672\":[4,4,14],\"1673\":[1,1,20],\"1674\":[3,2,7],\"1675\":[1,3,9],\"1676\":[1,3,15],\"1677\":[1,3,7],\"1678\":[5,1,1],\"1679\":[1,1,10],\"1680\":[1,3,12],\"1681\":[1,1,10],\"1682\":[1,2,12],\"1683\":[1,2,24],\"1684\":[1,4,12],\"1685\":[1,3,45],\"1686\":[1,1,5],\"1687\":[1,1,13],\"1688\":[1,2,7],\"1689\":[1,2,11],\"1690\":[1,1,1],\"1691\":[2,2,1],\"1692\":[1,2,6],\"1693\":[2,1,3],\"1694\":[1,2,10],\"1695\":[2,2,9],\"1696\":[1,2,5],\"1697\":[2,1,1],\"1698\":[1,2,14],\"1699\":[1,2,12],\"1700\":[1,1,12],\"1701\":[2,3,14],\"1702\":[1,8,12],\"1703\":[1,1,28],\"1704\":[1,2,7],\"1705\":[2,1,1],\"1706\":[1,1,1],\"1707\":[1,1,9],\"1708\":[2,4,44],\"1709\":[1,1,6],\"1710\":[2,1,1],\"1711\":[1,1,1],\"1712\":[2,4,34],\"1713\":[1,1,1],\"1714\":[1,1,1],\"1715\":[1,3,1],\"1716\":[1,3,7],\"1717\":[3,6,12],\"1718\":[2,2,8],\"1719\":[1,3,8],\"1720\":[1,2,28],\"1721\":[1,1,10],\"1722\":[1,2,16],\"1723\":[2,1,1],\"1724\":[1,1,1],\"1725\":[2,1,1],\"1726\":[1,2,12],\"1727\":[1,2,27],\"1728\":[6,7,18],\"1729\":[1,1,1],\"1730\":[3,5,7],\"1731\":[1,3,48],\"1732\":[1,3,36],\"1733\":[1,3,6],\"1734\":[2,1,1],\"1735\":[1,1,8],\"1736\":[1,3,14],\"1737\":[1,1,1],\"1738\":[1,2,6],\"1739\":[1,1,1],\"1740\":[1,4,34],\"1741\":[1,2,6],\"1742\":[1,1,6],\"1743\":[1,1,4],\"1744\":[1,2,9],\"1745\":[1,2,8],\"1746\":[2,2,5],\"1747\":[1,2,12],\"1748\":[1,1,1],\"1749\":[1,2,1],\"1750\":[2,1,7],\"1751\":[1,1,3],\"1752\":[1,2,16],\"1753\":[2,1,11],\"1754\":[1,2,3],\"1755\":[5,3,1],\"1756\":[1,2,39],\"1757\":[1,2,4],\"1758\":[3,1,11],\"1759\":[2,3,12],\"1760\":[1,8,7],\"1761\":[1,2,8],\"1762\":[1,2,8],\"1763\":[1,3,27],\"1764\":[1,2,4],\"1765\":[1,1,8],\"1766\":[2,4,22],\"1767\":[1,2,5],\"1768\":[1,1,2],\"1769\":[5,2,1],\"1770\":[1,2,10],\"1771\":[1,2,32],\"1772\":[2,3,6],\"1773\":[1,3,5],\"1774\":[5,6,14],\"1775\":[2,2,9],\"1776\":[3,1,7],\"1777\":[1,1,4],\"1778\":[1,1,6],\"1779\":[1,2,8],\"1780\":[7,1,1],\"1781\":[2,1,1],\"1782\":[1,2,69],\"1783\":[1,2,10],\"1784\":[1,1,15],\"1785\":[1,1,12],\"1786\":[3,7,19],\"1787\":[1,2,27],\"1788\":[4,5,20],\"1789\":[1,3,12],\"1790\":[1,2,8],\"1791\":[1,3,4],\"1792\":[1,1,11],\"1793\":[1,1,13],\"1794\":[1,3,10],\"1795\":[1,2,65],\"1796\":[1,2,20],\"1797\":[1,1,18],\"1798\":[3,1,1],\"1799\":[1,2,3],\"1800\":[1,1,4],\"1801\":[1,1,4],\"1802\":[1,2,3],\"1803\":[1,2,1],\"1804\":[2,2,5],\"1805\":[1,2,1],\"1806\":[2,1,1],\"1807\":[1,1,12],\"1808\":[1,1,6],\"1809\":[1,3,14],\"1810\":[2,2,12],\"1811\":[1,1,8],\"1812\":[1,2,1],\"1813\":[4,2,29],\"1814\":[1,2,15],\"1815\":[2,3,1],\"1816\":[1,2,31],\"1817\":[1,2,43],\"1818\":[1,1,9],\"1819\":[2,3,17],\"1820\":[1,8,8],\"1821\":[1,1,6],\"1822\":[1,1,8],\"1823\":[1,1,28],\"1824\":[1,2,5],\"1825\":[1,2,5],\"1826\":[5,4,10],\"1827\":[1,1,1],\"1828\":[1,2,2],\"1829\":[1,1,5],\"1830\":[2,7,43],\"1831\":[1,2,40],\"1832\":[1,2,47],\"1833\":[1,3,7],\"1834\":[1,3,7],\"1835\":[6,6,7],\"1836\":[1,1,1],\"1837\":[1,4,15],\"1838\":[1,1,3],\"1839\":[1,1,6],\"1840\":[1,2,4],\"1841\":[2,1,14],\"1842\":[4,1,1],\"1843\":[1,2,37],\"1844\":[1,2,1],\"1845\":[1,1,5],\"1846\":[1,1,8],\"1847\":[5,7,19],\"1848\":[1,2,8],\"1849\":[1,5,7],\"1850\":[1,3,4],\"1851\":[1,2,4],\"1852\":[1,3,7],\"1853\":[1,1,13],\"1854\":[1,1,1],\"1855\":[1,1,9],\"1856\":[1,3,11],\"1857\":[1,2,7],\"1858\":[1,2,9],\"1859\":[1,1,7],\"1860\":[1,4,10],\"1861\":[1,2,4],\"1862\":[1,1,1],\"1863\":[1,1,4],\"1864\":[1,2,6],\"1865\":[2,3,10],\"1866\":[2,2,10],\"1867\":[1,3,16],\"1868\":[1,2,30],\"1869\":[1,1,12],\"1870\":[1,1,26],\"1871\":[1,3,8],\"1872\":[1,2,12],\"1873\":[3,3,12],\"1874\":[3,2,8],\"1875\":[1,1,8],\"1876\":[2,2,7],\"1877\":[1,2,3],\"1878\":[1,1,17],\"1879\":[4,4,1],\"1880\":[1,1,10],\"1881\":[1,1,4],\"1882\":[1,1,1],\"1883\":[1,2,49],\"1884\":[1,3,15],\"1885\":[3,9,47],\"1886\":[1,1,1],\"1887\":[1,2,6],\"1888\":[1,1,2],\"1889\":[4,2,34],\"1890\":[1,2,10],\"1891\":[1,2,18],\"1892\":[1,3,6],\"1893\":[2,1,1],\"1894\":[2,4,4],\"1895\":[1,1,7],\"1896\":[4,1,7],\"1897\":[1,1,5],\"1898\":[1,2,3],\"1899\":[1,1,8],\"1900\":[2,1,1],\"1901\":[1,3,58],\"1902\":[1,1,46],\"1903\":[1,1,1],\"1904\":[5,7,17],\"1905\":[1,2,5],\"1906\":[3,2,1],\"1907\":[1,3,7],\"1908\":[2,2,4],\"1909\":[1,1,1],\"1910\":[1,1,16],\"1911\":[1,1,5],\"1912\":[1,3,76],\"1913\":[1,2,4],\"1914\":[1,2,5],\"1915\":[1,1,8],\"1916\":[1,1,1],\"1917\":[1,4,54],\"1918\":[1,2,3],\"1919\":[1,1,9],\"1920\":[1,1,16],\"1921\":[1,2,6],\"1922\":[1,3,16],\"1923\":[1,1,9],\"1924\":[1,3,13],\"1925\":[2,2,53],\"1926\":[1,2,9],\"1927\":[1,1,9],\"1928\":[1,3,41],\"1929\":[1,2,1],\"1930\":[3,3,9],\"1931\":[1,3,1],\"1932\":[1,1,17],\"1933\":[3,2,6],\"1934\":[1,2,6],\"1935\":[1,7,9],\"1936\":[1,1,25],\"1937\":[3,2,10],\"1938\":[1,1,7],\"1939\":[1,1,10],\"1940\":[3,9,13],\"1941\":[2,2,5],\"1942\":[1,2,41],\"1943\":[1,1,6],\"1944\":[2,2,30],\"1945\":[1,1,6],\"1946\":[1,1,4],\"1947\":[1,3,14],\"1948\":[1,3,9],\"1949\":[1,6,28],\"1950\":[1,1,9],\"1951\":[1,5,19],\"1952\":[1,1,4],\"1953\":[1,2,9],\"1954\":[1,2,36],\"1955\":[1,1,21],\"1956\":[1,3,6],\"1957\":[3,2,7],\"1958\":[1,1,12],\"1959\":[1,2,1],\"1960\":[1,3,8],\"1961\":[1,2,7],\"1962\":[2,2,8],\"1963\":[1,2,12],\"1964\":[1,1,3],\"1965\":[1,3,4],\"1966\":[1,1,9],\"1967\":[1,2,5],\"1968\":[2,1,1],\"1969\":[1,1,10],\"1970\":[2,4,1],\"1971\":[3,2,18],\"1972\":[1,1,10],\"1973\":[2,1,5],\"1974\":[1,3,9],\"1975\":[1,1,6],\"1976\":[1,3,14],\"1977\":[1,1,14],\"1978\":[2,1,16],\"1979\":[2,3,4],\"1980\":[1,3,12],\"1981\":[5,3,7],\"1982\":[3,3,28],\"1983\":[1,1,9],\"1984\":[3,2,23],\"1985\":[4,4,1],\"1986\":[1,1,5],\"1987\":[3,2,10],\"1988\":[1,1,5],\"1989\":[1,1,11],\"1990\":[2,4,24],\"1991\":[2,2,16],\"1992\":[1,3,19],\"1993\":[1,1,41],\"1994\":[2,2,26],\"1995\":[1,1,1],\"1996\":[1,1,4],\"1997\":[1,1,10],\"1998\":[3,3,12],\"1999\":[1,3,4],\"2000\":[3,6,25],\"2001\":[1,1,11],\"2002\":[1,5,9],\"2003\":[1,1,5],\"2004\":[1,2,14],\"2005\":[1,1,1],\"2006\":[1,1,1],\"2007\":[1,2,14],\"2008\":[4,2,10],\"2009\":[1,1,4],\"2010\":[1,1,1],\"2011\":[3,3,27],\"2012\":[1,3,13],\"2013\":[2,2,31],\"2014\":[1,2,15],\"2015\":[1,1,6],\"2016\":[2,1,1],\"2017\":[1,3,10],\"2018\":[1,1,4],\"2019\":[1,2,5],\"2020\":[1,1,1],\"2021\":[1,1,13],\"2022\":[1,6,10],\"2023\":[1,2,11],\"2024\":[1,2,10],\"2025\":[1,1,4],\"2026\":[1,3,8],\"2027\":[1,2,21],\"2028\":[1,2,6],\"2029\":[1,1,1],\"2030\":[1,3,30],\"2031\":[2,1,1],\"2032\":[1,2,11],\"2033\":[1,3,56],\"2034\":[1,1,11],\"2035\":[2,2,7],\"2036\":[1,1,1],\"2037\":[1,7,45],\"2038\":[1,1,4],\"2039\":[3,2,6],\"2040\":[1,1,4],\"2041\":[1,1,5],\"2042\":[4,6,25],\"2043\":[2,2,10],\"2044\":[1,3,44],\"2045\":[1,2,19],\"2046\":[2,2,56],\"2047\":[1,1,10],\"2048\":[1,1,14],\"2049\":[3,3,19],\"2050\":[1,3,71],\"2051\":[1,6,21],\"2052\":[1,2,10],\"2053\":[1,1,16],\"2054\":[6,2,9],\"2055\":[1,1,29],\"2056\":[1,2,5],\"2057\":[4,2,5],\"2058\":[2,1,4],\"2059\":[1,1,24],\"2060\":[2,3,1],\"2061\":[1,3,3],\"2062\":[2,2,9],\"2063\":[1,1,1],\"2064\":[2,1,15],\"2065\":[1,1,11],\"2066\":[2,2,14],\"2067\":[1,1,9],\"2068\":[1,1,4],\"2069\":[1,2,11],\"2070\":[1,2,8],\"2071\":[1,1,1],\"2072\":[1,6,1],\"2073\":[1,2,18],\"2074\":[1,2,8],\"2075\":[1,1,6],\"2076\":[1,2,14],\"2077\":[1,1,33],\"2078\":[1,2,15],\"2079\":[2,1,35],\"2080\":[1,2,53],\"2081\":[1,2,72],\"2082\":[1,2,14],\"2083\":[1,1,1],\"2084\":[1,1,1],\"2085\":[2,3,50],\"2086\":[1,1,5],\"2087\":[2,4,17],\"2088\":[1,1,10],\"2089\":[6,4,24],\"2090\":[1,1,9],\"2091\":[2,2,10],\"2092\":[1,1,8],\"2093\":[1,1,5],\"2094\":[4,6,20],\"2095\":[1,1,1],\"2096\":[1,2,7],\"2097\":[1,2,44],\"2098\":[2,1,9],\"2099\":[1,1,7],\"2100\":[1,1,1],\"2101\":[1,1,9],\"2102\":[7,3,14],\"2103\":[1,3,8],\"2104\":[2,4,5],\"2105\":[1,2,7],\"2106\":[1,1,5],\"2107\":[3,2,4],\"2108\":[1,1,36],\"2109\":[2,2,3],\"2110\":[1,1,13],\"2111\":[1,1,5],\"2112\":[2,1,1],\"2113\":[1,2,22],\"2114\":[1,1,10],\"2115\":[1,1,22],\"2116\":[1,1,9],\"2117\":[3,3,11],\"2118\":[3,2,50],\"2119\":[1,1,6],\"2120\":[1,1,6],\"2121\":[1,2,19],\"2122\":[1,2,8],\"2123\":[1,2,14],\"2124\":[4,7,28],\"2125\":[1,1,7],\"2126\":[1,2,4],\"2127\":[1,2,6],\"2128\":[1,1,7],\"2129\":[2,1,48],\"2130\":[1,2,12],\"2131\":[1,1,9],\"2132\":[1,2,4],\"2133\":[1,2,6],\"2134\":[1,1,10],\"2135\":[1,1,10],\"2136\":[2,1,3],\"2137\":[2,4,24],\"2138\":[1,1,7],\"2139\":[1,4,18],\"2140\":[1,1,34],\"2141\":[1,1,31],\"2142\":[1,1,16],\"2143\":[1,1,9],\"2144\":[4,6,16],\"2145\":[3,2,81],\"2146\":[1,2,4],\"2147\":[1,1,7],\"2148\":[2,1,16],\"2149\":[1,1,1],\"2150\":[2,1,1],\"2151\":[1,1,11],\"2152\":[3,9,6],\"2153\":[2,1,1],\"2154\":[1,6,15],\"2155\":[1,1,15],\"2156\":[1,1,4],\"2157\":[1,2,6],\"2158\":[1,1,3],\"2159\":[1,2,3],\"2160\":[1,1,7],\"2161\":[1,3,52],\"2162\":[1,3,1],\"2163\":[1,1,19],\"2164\":[1,1,9],\"2165\":[1,1,6],\"2166\":[3,3,27],\"2167\":[3,2,9],\"2168\":[2,2,17],\"2169\":[1,2,7],\"2170\":[1,2,6],\"2171\":[5,7,16],\"2172\":[1,1,3],\"2173\":[1,2,5],\"2174\":[1,2,11],\"2175\":[1,1,14],\"2176\":[2,3,27],\"2177\":[1,1,21],\"2178\":[5,3,7],\"2179\":[1,2,6],\"2180\":[1,1,9],\"2181\":[1,1,6],\"2182\":[1,1,9],\"2183\":[3,4,14],\"2184\":[1,2,16],\"2185\":[1,4,16],\"2186\":[1,1,1],\"2187\":[1,1,16],\"2188\":[2,9,26],\"2189\":[3,1,1],\"2190\":[1,2,3],\"2191\":[1,1,4],\"2192\":[1,2,47],\"2193\":[4,1,1],\"2194\":[1,1,23],\"2195\":[7,9,16],\"2196\":[2,3,5],\"2197\":[1,6,13],\"2198\":[1,1,4],\"2199\":[1,1,16],\"2200\":[1,1,10],\"2201\":[1,2,62],\"2202\":[1,2,32],\"2203\":[1,1,3],\"2204\":[2,3,1],\"2205\":[1,3,3],\"2206\":[1,2,12],\"2207\":[2,1,4],\"2208\":[1,1,1],\"2209\":[1,2,2],\"2210\":[2,2,9],\"2211\":[1,2,4],\"2212\":[1,1,8],\"2213\":[2,7,17],\"2214\":[1,1,8],\"2215\":[1,2,21],\"2216\":[2,3,5],\"2217\":[1,1,35],\"2218\":[5,3,31],\"2219\":[1,2,10],\"2220\":[1,1,22],\"2221\":[1,1,1],\"2222\":[1,1,7],\"2223\":[1,2,25],\"2224\":[6,4,16],\"2225\":[1,1,10],\"2226\":[3,1,1],\"2227\":[2,9,19],\"2228\":[3,4,56],\"2229\":[1,2,19],\"2230\":[1,1,3],\"2231\":[1,2,7],\"2232\":[2,1,1],\"2233\":[1,1,62],\"2234\":[6,9,15],\"2235\":[1,3,25],\"2236\":[1,6,11],\"2237\":[1,2,4],\"2238\":[1,1,11],\"2239\":[1,1,4],\"2240\":[2,1,4],\"2241\":[1,4,4],\"2242\":[3,2,5],\"2243\":[1,2,5],\"2244\":[1,1,8],\"2245\":[1,2,18],\"2246\":[1,2,3],\"2247\":[1,1,1],\"2248\":[4,1,9],\"2249\":[1,1,4],\"2250\":[2,7,6],\"2251\":[1,1,1],\"2252\":[1,1,26],\"2253\":[5,3,25],\"2254\":[1,2,10],\"2255\":[1,1,14],\"2256\":[1,2,9],\"2257\":[1,2,16],\"2258\":[1,1,12],\"2259\":[1,4,14],\"2260\":[1,1,7],\"2261\":[1,3,11],\"2262\":[2,10,15],\"2263\":[2,1,33],\"2264\":[1,1,1],\"2265\":[1,1,19],\"2266\":[1,1,15],\"2267\":[1,1,7],\"2268\":[1,1,5],\"2269\":[4,1,14],\"2270\":[2,1,15],\"2271\":[1,6,10],\"2272\":[1,1,8],\"2273\":[1,1,15],\"2274\":[1,1,4],\"2275\":[1,1,25],\"2276\":[1,5,21],\"2277\":[1,5,16],\"2278\":[1,1,13],\"2279\":[2,1,11],\"2280\":[1,2,15],\"2281\":[1,3,19],\"2282\":[2,2,4],\"2283\":[1,5,8],\"2284\":[1,1,9],\"2285\":[3,4,1],\"2286\":[3,1,54],\"2287\":[1,1,6],\"2288\":[5,3,13],\"2289\":[1,2,15],\"2290\":[1,1,4],\"2291\":[1,2,8],\"2292\":[1,2,11],\"2293\":[1,1,1],\"2294\":[1,4,17],\"2295\":[1,1,1],\"2296\":[1,3,8],\"2297\":[1,1,10],\"2298\":[1,1,1],\"2299\":[1,1,5],\"2300\":[1,1,17],\"2301\":[1,1,4],\"2302\":[1,1,1],\"2303\":[1,1,12],\"2304\":[1,6,13],\"2305\":[1,1,9],\"2306\":[1,1,51],\"2307\":[1,1,4],\"2308\":[5,5,57],\"2309\":[1,5,1],\"2310\":[1,2,8],\"2311\":[1,2,7],\"2312\":[1,2,12],\"2313\":[1,3,18],\"2314\":[1,2,10],\"2315\":[3,5,11],\"2316\":[1,1,4],\"2317\":[1,6,9],\"2318\":[1,4,12],\"2319\":[1,1,11],\"2320\":[6,1,10],\"2321\":[1,1,6],\"2322\":[1,2,30],\"2323\":[1,1,18],\"2324\":[1,2,4],\"2325\":[1,1,17],\"2326\":[1,2,6],\"2327\":[1,4,24],\"2328\":[1,1,5],\"2329\":[1,1,10],\"2330\":[2,1,3],\"2331\":[1,1,14],\"2332\":[1,1,4],\"2333\":[1,1,11],\"2334\":[1,1,12],\"2335\":[1,6,19],\"2336\":[1,1,1],\"2337\":[1,1,8],\"2338\":[1,1,16],\"2339\":[5,5,8],\"2340\":[1,5,1],\"2341\":[1,1,1],\"2342\":[1,2,1],\"2343\":[1,1,7],\"2344\":[1,3,12],\"2345\":[1,1,19],\"2346\":[4,5,13],\"2347\":[1,1,31],\"2348\":[1,6,1],\"2349\":[5,4,25],\"2350\":[3,1,7],\"2351\":[2,6,14],\"2352\":[1,1,4],\"2353\":[1,1,6],\"2354\":[1,2,14],\"2355\":[1,2,5],\"2356\":[3,2,10],\"2357\":[1,4,24],\"2358\":[1,1,1],\"2359\":[1,1,5],\"2360\":[1,1,6],\"2361\":[1,1,7],\"2362\":[1,1,4],\"2363\":[1,1,23],\"2364\":[1,2,11],\"2365\":[2,6,14],\"2366\":[5,2,19],\"2367\":[1,1,4],\"2368\":[1,1,18],\"2369\":[1,10,12],\"2370\":[6,2,11],\"2371\":[1,2,3],\"2372\":[1,3,12],\"2373\":[1,1,5],\"2374\":[1,2,38],\"2375\":[1,1,7],\"2376\":[1,1,1],\"2377\":[1,1,9],\"2378\":[2,7,26],\"2379\":[1,4,30],\"2380\":[1,1,4],\"2381\":[1,6,12],\"2382\":[3,1,4],\"2383\":[1,1,3],\"2384\":[3,2,12],\"2385\":[1,2,2],\"2386\":[1,2,11],\"2387\":[1,3,8],\"2388\":[1,2,7],\"2389\":[1,1,1],\"2390\":[1,1,5],\"2391\":[1,1,5],\"2392\":[1,1,1],\"2393\":[1,1,8],\"2394\":[1,6,12],\"2395\":[1,2,11],\"2396\":[2,1,4],\"2397\":[1,10,7],\"2398\":[1,8,1],\"2399\":[1,2,4],\"2400\":[2,3,47],\"2401\":[1,1,9],\"2402\":[1,3,14],\"2403\":[1,1,4],\"2404\":[1,1,11],\"2405\":[2,7,18],\"2406\":[1,4,13],\"2407\":[1,1,4],\"2408\":[1,6,40],\"2409\":[1,1,7],\"2410\":[1,1,4],\"2411\":[1,1,3],\"2412\":[1,2,3],\"2413\":[1,1,6],\"2414\":[1,3,4],\"2415\":[1,2,8],\"2416\":[1,2,7],\"2417\":[1,1,20],\"2418\":[1,1,20],\"2419\":[1,2,5],\"2420\":[2,1,14],\"2421\":[1,1,4],\"2422\":[1,10,11],\"2423\":[3,2,1],\"2424\":[1,2,6],\"2425\":[2,3,24],\"2426\":[1,1,4],\"2427\":[3,2,10],\"2428\":[2,1,3],\"2429\":[1,1,4],\"2430\":[2,7,25],\"2431\":[1,4,10],\"2432\":[1,1,3],\"2433\":[1,6,78],\"2434\":[1,1,28],\"2435\":[1,1,3],\"2436\":[1,2,20],\"2437\":[1,2,4],\"2438\":[1,1,4],\"2439\":[1,3,5],\"2440\":[1,2,4],\"2441\":[1,2,8],\"2442\":[1,1,5],\"2443\":[1,1,26],\"2444\":[2,3,8],\"2445\":[1,3,7],\"2446\":[1,1,26],\"2447\":[1,10,10],\"2448\":[2,2,1],\"2449\":[1,1,21],\"2450\":[1,2,5],\"2451\":[1,1,7],\"2452\":[1,5,20],\"2453\":[1,1,6],\"2454\":[1,1,1],\"2455\":[2,7,11],\"2456\":[3,4,1],\"2457\":[1,1,3],\"2458\":[1,1,10],\"2459\":[1,2,3],\"2460\":[1,1,4],\"2461\":[1,3,5],\"2462\":[1,1,9],\"2463\":[1,2,4],\"2464\":[1,1,4],\"2465\":[2,3,8],\"2466\":[1,3,11],\"2467\":[2,1,19],\"2468\":[1,10,8],\"2469\":[1,2,16],\"2470\":[1,1,4],\"2471\":[1,2,16],\"2472\":[1,2,1],\"2473\":[2,1,5],\"2474\":[1,2,8],\"2475\":[3,4,1],\"2476\":[2,1,12],\"2477\":[1,1,3],\"2478\":[1,1,6],\"2479\":[1,3,12],\"2480\":[1,1,6],\"2481\":[1,1,9],\"2482\":[1,1,14],\"2483\":[2,3,8],\"2484\":[2,1,27],\"2485\":[1,2,66],\"2486\":[1,10,11],\"2487\":[1,1,1],\"2488\":[1,1,4],\"2489\":[3,2,6],\"2490\":[1,1,3],\"2491\":[1,2,4],\"2492\":[4,1,25],\"2493\":[2,2,8],\"2494\":[1,1,9],\"2495\":[2,1,4],\"2496\":[1,1,6],\"2497\":[1,1,4],\"2498\":[1,2,4],\"2499\":[1,3,7],\"2500\":[1,2,77],\"2501\":[3,3,1],\"2502\":[1,1,4],\"2503\":[5,5,11],\"2504\":[1,2,7],\"2505\":[2,5,26],\"2506\":[2,2,7],\"2507\":[1,1,8],\"2508\":[1,1,4],\"2509\":[2,1,4],\"2510\":[1,1,5],\"2511\":[2,3,5],\"2512\":[1,3,4],\"2513\":[1,2,6],\"2514\":[1,6,17],\"2515\":[5,2,8],\"2516\":[1,1,9],\"2517\":[2,5,24],\"2518\":[3,2,10],\"2519\":[1,1,14],\"2520\":[1,1,14],\"2521\":[1,1,4],\"2522\":[2,3,5],\"2523\":[2,1,16],\"2524\":[1,2,16],\"2525\":[1,6,1],\"2526\":[1,7,49],\"2527\":[1,1,7],\"2528\":[2,5,64],\"2529\":[2,2,7],\"2530\":[1,1,5],\"2531\":[1,1,44],\"2532\":[1,1,14],\"2533\":[2,3,8],\"2534\":[1,3,7],\"2535\":[1,1,10],\"2536\":[3,3,1],\"2537\":[1,7,38],\"2538\":[1,1,2],\"2539\":[1,5,87],\"2540\":[2,2,8],\"2541\":[2,1,3],\"2542\":[1,1,44],\"2543\":[2,1,15],\"2544\":[1,3,3],\"2545\":[1,1,18],\"2546\":[1,6,25],\"2547\":[1,2,5],\"2548\":[1,1,2],\"2549\":[1,5,23],\"2550\":[1,1,9],\"2551\":[1,1,7],\"2552\":[1,1,10],\"2553\":[1,1,1],\"2554\":[1,6,10],\"2555\":[1,2,6],\"2556\":[1,1,4],\"2557\":[1,1,1],\"2558\":[2,2,5],\"2559\":[5,1,1],\"2560\":[1,1,8],\"2561\":[1,2,14],\"2562\":[3,3,1],\"2563\":[1,2,8],\"2564\":[1,1,10],\"2565\":[3,2,21],\"2566\":[3,4,13],\"2567\":[1,5,12],\"2568\":[1,2,3],\"2569\":[1,2,6],\"2570\":[1,6,21],\"2571\":[5,3,8],\"2572\":[1,1,1],\"2573\":[3,2,30],\"2574\":[3,4,3],\"2575\":[1,5,9],\"2576\":[1,2,10],\"2577\":[1,2,42],\"2578\":[3,6,22],\"2579\":[4,3,37],\"2580\":[3,1,13],\"2581\":[3,2,21],\"2582\":[3,4,9],\"2583\":[1,5,1],\"2584\":[1,1,13],\"2585\":[1,1,7],\"2586\":[1,6,1],\"2587\":[1,2,12],\"2588\":[1,1,10],\"2589\":[3,2,17],\"2590\":[2,2,10],\"2591\":[3,6,7],\"2592\":[1,2,3],\"2593\":[1,1,4],\"2594\":[2,3,1],\"2595\":[1,3,1],\"2596\":[1,1,1],\"2597\":[3,2,46],\"2598\":[1,6,8],\"2599\":[1,2,10],\"2600\":[1,1,28],\"2601\":[1,5,24],\"2602\":[1,4,26],\"2603\":[1,1,30],\"2604\":[3,2,33],\"2605\":[1,6,12],\"2606\":[1,1,22],\"2607\":[1,1,4],\"2608\":[1,5,21],\"2609\":[1,4,47],\"2610\":[1,1,1],\"2611\":[3,2,16],\"2612\":[1,5,13],\"2613\":[1,2,9],\"2614\":[1,1,4],\"2615\":[1,5,1],\"2616\":[1,2,25],\"2617\":[2,2,10],\"2618\":[3,2,46],\"2619\":[1,5,7],\"2620\":[1,2,5],\"2621\":[1,2,24],\"2622\":[2,2,15],\"2623\":[3,2,16],\"2624\":[2,5,6],\"2625\":[1,1,7],\"2626\":[2,2,1],\"2627\":[1,1,4],\"2628\":[1,2,11],\"2629\":[1,5,9],\"2630\":[1,2,4],\"2631\":[1,4,7],\"2632\":[1,1,1],\"2633\":[1,2,1],\"2634\":[5,1,1],\"2635\":[1,2,5],\"2636\":[4,4,31],\"2637\":[1,1,11],\"2638\":[2,1,1],\"2639\":[1,5,12],\"2640\":[1,1,18],\"2641\":[1,4,26],\"2642\":[1,1,21],\"2643\":[1,3,63],\"2644\":[1,5,9],\"2645\":[1,2,4],\"2646\":[1,2,1],\"2647\":[1,1,15],\"2648\":[1,3,20],\"2649\":[1,5,1],\"2650\":[1,2,7],\"2651\":[1,3,17],\"2652\":[1,1,8],\"2653\":[1,3,84],\"2654\":[3,6,7],\"2655\":[1,1,34],\"2656\":[1,3,11],\"2657\":[1,1,5],\"2658\":[1,6,8],\"2659\":[1,1,8],\"2660\":[2,2,23],\"2661\":[1,1,3],\"2662\":[1,6,12],\"2663\":[1,2,10],\"2664\":[1,2,3],\"2665\":[1,5,13],\"2666\":[1,1,8],\"2667\":[1,3,7],\"2668\":[1,5,7],\"2669\":[1,2,6],\"2670\":[1,3,12],\"2671\":[2,5,6],\"2672\":[2,3,15],\"2673\":[2,3,15],\"2674\":[1,5,9],\"2675\":[1,3,17],\"2676\":[1,3,19],\"2677\":[2,1,1],\"2678\":[5,1,1],\"2679\":[1,2,3],\"2680\":[2,2,1],\"2681\":[1,5,12],\"2682\":[1,2,5],\"2683\":[4,4,1],\"2684\":[1,6,1],\"2685\":[5,1,9],\"2686\":[2,4,7],\"2687\":[1,7,16],\"2688\":[1,5,47],\"2689\":[1,2,12],\"2690\":[1,7,25],\"2691\":[1,6,13],\"2692\":[1,2,29],\"2693\":[1,7,16],\"2694\":[1,6,12],\"2695\":[1,2,10],\"2696\":[1,6,1],\"2697\":[2,6,44],\"2698\":[1,2,5],\"2699\":[2,7,22],\"2700\":[1,5,1],\"2701\":[1,2,7],\"2702\":[3,7,20],\"2703\":[1,5,1],\"2704\":[2,6,12],\"2705\":[1,5,1],\"2706\":[2,6,9],\"2707\":[1,5,1],\"2708\":[1,5,8],\"2709\":[1,5,7],\"2710\":[1,5,12],\"2711\":[1,5,9]},\"averageFieldLength\":[1.5294985250737456,2.147492625368729,12.453908554572271],\"storedFields\":{\"0\":{\"title\":\"Custom Component\",\"titles\":[]},\"1\":{\"title\":\"Markdown\",\"titles\":[]},\"2\":{\"title\":\"Welcome🎉\",\"titles\":[]},\"3\":{\"title\":\"Heading 2\",\"titles\":[\"Markdown\"]},\"4\":{\"title\":\"毕业设计导航\",\"titles\":[]},\"5\":{\"title\":\"关于大语言模型学习导航\",\"titles\":[\"Welcome🎉\"]},\"6\":{\"title\":\"Heading 3\",\"titles\":[\"Markdown\",\"Heading 2\"]},\"7\":{\"title\":\"using和namespace\",\"titles\":[]},\"8\":{\"title\":\"关于过程编程,面向对象编程和泛型编程\",\"titles\":[]},\"9\":{\"title\":\"Heading 4\",\"titles\":[\"Markdown\",\"Heading 2\",\"Heading 3\"]},\"10\":{\"title\":\"1. namespace（名称空间）\",\"titles\":[\"using和namespace\"]},\"11\":{\"title\":\"函数声明\",\"titles\":[]},\"12\":{\"title\":\"1. 过程编程（Procedural Programming）\",\"titles\":[\"关于过程编程,面向对象编程和泛型编程\"]},\"13\":{\"title\":\"Heading 5\",\"titles\":[\"Markdown\",\"Heading 2\",\"Heading 3\",\"Heading 4\"]},\"14\":{\"title\":\"初始化\",\"titles\":[]},\"15\":{\"title\":\"泛型编程（Generic Programming）\",\"titles\":[]},\"16\":{\"title\":\"导航\",\"titles\":[]},\"17\":{\"title\":\"局部和全局的命名空间引入\",\"titles\":[]},\"18\":{\"title\":\"Heading 6\",\"titles\":[\"Markdown\",\"Heading 2\",\"Heading 3\",\"Heading 4\",\"Heading 5\"]},\"19\":{\"title\":\"Demo\",\"titles\":[]},\"20\":{\"title\":\"区别与联系\",\"titles\":[]},\"21\":{\"title\":\"C++核心\",\"titles\":[]},\"22\":{\"title\":\"1. using std::cout\",\"titles\":[]},\"23\":{\"title\":\"bar\",\"titles\":[]},\"24\":{\"title\":\"高级特性\",\"titles\":[]},\"25\":{\"title\":\"foo\",\"titles\":[]},\"26\":{\"title\":\"什么是transformer\",\"titles\":[]},\"27\":{\"title\":\"2. using namespace std\",\"titles\":[]},\"28\":{\"title\":\"导航\",\"titles\":[]},\"29\":{\"title\":\"Transformer 模型与迁移学习整合解析\",\"titles\":[\"什么是transformer\"]},\"30\":{\"title\":\"导航\",\"titles\":[]},\"31\":{\"title\":\"模型变体\",\"titles\":[]},\"32\":{\"title\":\"单变量线性回归\",\"titles\":[]},\"33\":{\"title\":\"关于逻辑回归中的代价函数\",\"titles\":[]},\"34\":{\"title\":\"一、Transformer 模型的核心结构与工作原理\",\"titles\":[\"什么是transformer\",\"Transformer 模型与迁移学习整合解析\"]},\"35\":{\"title\":\"链表\",\"titles\":[]},\"36\":{\"title\":\"关于逻辑回归的思考\",\"titles\":[]},\"37\":{\"title\":\"导航\",\"titles\":[]},\"38\":{\"title\":\"应用实践\",\"titles\":[]},\"39\":{\"title\":\"机器学习引言\",\"titles\":[]},\"40\":{\"title\":\"二、迁移学习的定义与实施流程\",\"titles\":[\"什么是transformer\",\"Transformer 模型与迁移学习整合解析\"]},\"41\":{\"title\":\"树\",\"titles\":[]},\"42\":{\"title\":\"1. 问题背景\",\"titles\":[\"关于逻辑回归的思考\"]},\"43\":{\"title\":\"学习资料\",\"titles\":[]},\"44\":{\"title\":\"深度学习\",\"titles\":[]},\"45\":{\"title\":\"导航\",\"titles\":[]},\"46\":{\"title\":\"导航\",\"titles\":[]},\"47\":{\"title\":\"分隔链表\",\"titles\":[]},\"48\":{\"title\":\"合并零之间的节点\",\"titles\":[]},\"49\":{\"title\":\"三、整合应用案例与最佳实践\",\"titles\":[\"什么是transformer\",\"Transformer 模型与迁移学习整合解析\"]},\"50\":{\"title\":\"动态规划\",\"titles\":[]},\"51\":{\"title\":\"2. 逻辑回归的核心思想\",\"titles\":[\"关于逻辑回归的思考\"]},\"52\":{\"title\":\"1. 自然语言处理（NLP）基础\",\"titles\":[\"学习资料\"]},\"53\":{\"title\":\"实践项目\",\"titles\":[]},\"54\":{\"title\":\"系统设计\",\"titles\":[]},\"55\":{\"title\":\"词嵌入\",\"titles\":[]},\"56\":{\"title\":\"2024-12-25T00:00:00.000Z\",\"titles\":[]},\"57\":{\"title\":\"四、挑战与前沿技术\",\"titles\":[\"什么是transformer\",\"Transformer 模型与迁移学习整合解析\"]},\"58\":{\"title\":\"3. 逻辑回归的全流程\",\"titles\":[\"关于逻辑回归的思考\"]},\"59\":{\"title\":\"需要学习的知识：\",\"titles\":[\"学习资料\",\"1. 自然语言处理（NLP）基础\"]},\"60\":{\"title\":\"导航\",\"titles\":[]},\"61\":{\"title\":\"Attention机制详解与应用\",\"titles\":[]},\"62\":{\"title\":\"实现过程\",\"titles\":[]},\"63\":{\"title\":\"Attention\",\"titles\":[]},\"64\":{\"title\":\"DCA：长文本处理的新突破（Dual Chunk Attention）\",\"titles\":[]},\"65\":{\"title\":\"五、工具与资源推荐\",\"titles\":[\"什么是transformer\",\"Transformer 模型与迁移学习整合解析\"]},\"66\":{\"title\":\"第一步：输入数据\",\"titles\":[\"关于逻辑回归的思考\",\"3. 逻辑回归的全流程\"]},\"67\":{\"title\":\"学习资源：\",\"titles\":[\"学习资料\",\"1. 自然语言处理（NLP）基础\"]},\"68\":{\"title\":\"KV Cache技术详解：优化Transformer自回归生成效率\",\"titles\":[]},\"69\":{\"title\":\"开发文档\",\"titles\":[]},\"70\":{\"title\":\"Transformer中的Attention详解与应用指南\",\"titles\":[]},\"71\":{\"title\":\"元数据\",\"titles\":[\"Attention机制详解与应用\"]},\"72\":{\"title\":\"论文撰写\",\"titles\":[]},\"73\":{\"title\":\"FFN,Add&amp;LN\",\"titles\":[]},\"74\":{\"title\":\"元数据\",\"titles\":[\"DCA：长文本处理的新突破（Dual Chunk Attention）\"]},\"75\":{\"title\":\"【长上下文模型优化】基于Shifted Sparse Attention的创新方法\",\"titles\":[]},\"76\":{\"title\":\"第二步：线性回归部分\",\"titles\":[\"关于逻辑回归的思考\",\"3. 逻辑回归的全流程\"]},\"77\":{\"title\":\"2. 机器学习基础\",\"titles\":[\"学习资料\"]},\"78\":{\"title\":\"博客标题：KV Cache技术详解：优化Transformer自回归生成效率\",\"titles\":[\"KV Cache技术详解：优化Transformer自回归生成效率\"]},\"79\":{\"title\":\"部署文档\",\"titles\":[]},\"80\":{\"title\":\"元数据\",\"titles\":[\"Transformer中的Attention详解与应用指南\"]},\"81\":{\"title\":\"优化Attention计算复杂度的技术探讨\",\"titles\":[]},\"82\":{\"title\":\"深度学习中的注意力机制优化：从MHA到MLA\",\"titles\":[]},\"83\":{\"title\":\"Attention机制的核心思想与计算方法\",\"titles\":[\"Attention机制详解与应用\"]},\"84\":{\"title\":\"Positional-Encoding\",\"titles\":[]},\"85\":{\"title\":\"发展历史\",\"titles\":[]},\"86\":{\"title\":\"什么是DCA？\",\"titles\":[\"DCA：长文本处理的新突破（Dual Chunk Attention）\"]},\"87\":{\"title\":\"元数据\",\"titles\":[\"【长上下文模型优化】基于Shifted Sparse Attention的创新方法\"]},\"88\":{\"title\":\"介绍\",\"titles\":[]},\"89\":{\"title\":\"Transformer核心模块解析：FFN、Add & LN 的作用与应用\",\"titles\":[]},\"90\":{\"title\":\"第三步：通过S型函数转换概率\",\"titles\":[\"关于逻辑回归的思考\",\"3. 逻辑回归的全流程\"]},\"91\":{\"title\":\"需要学习的知识：\",\"titles\":[\"学习资料\",\"2. 机器学习基础\"]},\"92\":{\"title\":\"元数据\",\"titles\":[\"KV Cache技术详解：优化Transformer自回归生成效率\"]},\"93\":{\"title\":\"内容概述\",\"titles\":[\"Transformer中的Attention详解与应用指南\"]},\"94\":{\"title\":\"元数据\",\"titles\":[\"优化Attention计算复杂度的技术探讨\"]},\"95\":{\"title\":\"深度学习中的Layer Norm设计：Post-Norm、Pre-Norm与Sandwich-Norm比较\",\"titles\":[]},\"96\":{\"title\":\"元数据\",\"titles\":[\"深度学习中的注意力机制优化：从MHA到MLA\"]},\"97\":{\"title\":\"💡 核心思想\",\"titles\":[\"Attention机制详解与应用\",\"Attention机制的核心思想与计算方法\"]},\"98\":{\"title\":\"Structure-&amp;-Decoding-Policy-结构和解码策略\",\"titles\":[]},\"99\":{\"title\":\"核心观点总结\",\"titles\":[\"发展历史\"]},\"100\":{\"title\":\"核心思想与实现\",\"titles\":[\"DCA：长文本处理的新突破（Dual Chunk Attention）\"]},\"101\":{\"title\":\"核心观点总结\",\"titles\":[\"【长上下文模型优化】基于Shifted Sparse Attention的创新方法\"]},\"102\":{\"title\":\"MCP架构概览\",\"titles\":[\"介绍\"]},\"103\":{\"title\":\"激活函数与FFN结构优化：SwiGLU、GeGLU及其应用解析\",\"titles\":[]},\"104\":{\"title\":\"元数据\",\"titles\":[\"Transformer核心模块解析：FFN、Add & LN 的作用与应用\"]},\"105\":{\"title\":\"第四步：设定阈值进行分类\",\"titles\":[\"关于逻辑回归的思考\",\"3. 逻辑回归的全流程\"]},\"106\":{\"title\":\"学习资源：\",\"titles\":[\"学习资料\",\"2. 机器学习基础\"]},\"107\":{\"title\":\"KV Cache技术简介\",\"titles\":[\"KV Cache技术详解：优化Transformer自回归生成效率\"]},\"108\":{\"title\":\"核心内容\",\"titles\":[\"Transformer中的Attention详解与应用指南\"]},\"109\":{\"title\":\"内容概述\",\"titles\":[\"优化Attention计算复杂度的技术探讨\"]},\"110\":{\"title\":\"元数据\",\"titles\":[\"深度学习中的Layer Norm设计：Post-Norm、Pre-Norm与Sandwich-Norm比较\"]},\"111\":{\"title\":\"简介\",\"titles\":[\"深度学习中的注意力机制优化：从MHA到MLA\"]},\"112\":{\"title\":\"✅ Attention的基本概念\",\"titles\":[\"Attention机制详解与应用\",\"Attention机制的核心思想与计算方法\"]},\"113\":{\"title\":\"Pre-training-预训练\",\"titles\":[]},\"114\":{\"title\":\"激活函数详解与比较：从Sigmoid到Swish\",\"titles\":[]},\"115\":{\"title\":\"重点段落\",\"titles\":[\"发展历史\"]},\"116\":{\"title\":\"1️⃣ DCA的工作流程\",\"titles\":[\"DCA：长文本处理的新突破（Dual Chunk Attention）\",\"核心思想与实现\"]},\"117\":{\"title\":\"技术解析\",\"titles\":[\"【长上下文模型优化】基于Shifted Sparse Attention的创新方法\"]},\"118\":{\"title\":\"MCP系统组成\",\"titles\":[\"介绍\",\"MCP架构概览\"]},\"119\":{\"title\":\"元数据\",\"titles\":[\"激活函数与FFN结构优化：SwiGLU、GeGLU及其应用解析\"]},\"120\":{\"title\":\"NTK插值方法解析与优化：从NTK-aware到NTK-by-parts\",\"titles\":[]},\"121\":{\"title\":\"核心内容总结\",\"titles\":[\"Transformer核心模块解析：FFN、Add & LN 的作用与应用\"]},\"122\":{\"title\":\"YaRN方法解析：扩展RoPE嵌入与注意力优化的实践\",\"titles\":[]},\"123\":{\"title\":\"第五步：训练模型\",\"titles\":[\"关于逻辑回归的思考\",\"3. 逻辑回归的全流程\"]},\"124\":{\"title\":\"3. 深度学习基础\",\"titles\":[\"学习资料\"]},\"125\":{\"title\":\"KV Cache工作原理\",\"titles\":[\"KV Cache技术详解：优化Transformer自回归生成效率\"]},\"126\":{\"title\":\"✅ Self-Attention机制\",\"titles\":[\"Transformer中的Attention详解与应用指南\",\"核心内容\"]},\"127\":{\"title\":\"核心内容\",\"titles\":[\"优化Attention计算复杂度的技术探讨\"]},\"128\":{\"title\":\"内容摘要\",\"titles\":[\"深度学习中的Layer Norm设计：Post-Norm、Pre-Norm与Sandwich-Norm比较\"]},\"129\":{\"title\":\"核心观点总结\",\"titles\":[\"深度学习中的注意力机制优化：从MHA到MLA\"]},\"130\":{\"title\":\"⚠️ Scaled Dot-Product的计算公式\",\"titles\":[\"Attention机制详解与应用\",\"Attention机制的核心思想与计算方法\"]},\"131\":{\"title\":\"后训练\",\"titles\":[]},\"132\":{\"title\":\"元数据\",\"titles\":[\"激活函数详解与比较：从Sigmoid到Swish\"]},\"133\":{\"title\":\"操作步骤\",\"titles\":[\"发展历史\"]},\"134\":{\"title\":\"介绍\",\"titles\":[]},\"135\":{\"title\":\"2️⃣ DCA代码实现\",\"titles\":[\"DCA：长文本处理的新突破（Dual Chunk Attention）\",\"核心思想与实现\"]},\"136\":{\"title\":\"✅ 核心原理：Shifted Sparse Attention\",\"titles\":[\"【长上下文模型优化】基于Shifted Sparse Attention的创新方法\",\"技术解析\"]},\"137\":{\"title\":\"API集成的挑战\",\"titles\":[\"介绍\"]},\"138\":{\"title\":\"核心内容概述\",\"titles\":[\"激活函数与FFN结构优化：SwiGLU、GeGLU及其应用解析\"]},\"139\":{\"title\":\"元数据\",\"titles\":[\"NTK插值方法解析与优化：从NTK-aware到NTK-by-parts\"]},\"140\":{\"title\":\"位置内插法扩展语言模型上下文长度\",\"titles\":[]},\"141\":{\"title\":\"详细解析\",\"titles\":[\"Transformer核心模块解析：FFN、Add & LN 的作用与应用\"]},\"142\":{\"title\":\"元数据\",\"titles\":[\"YaRN方法解析：扩展RoPE嵌入与注意力优化的实践\"]},\"143\":{\"title\":\"第六步：预测新数据\",\"titles\":[\"关于逻辑回归的思考\",\"3. 逻辑回归的全流程\"]},\"144\":{\"title\":\"需要学习的知识：\",\"titles\":[\"学习资料\",\"3. 深度学习基础\"]},\"145\":{\"title\":\"KV Cache vs 不使用缓存\",\"titles\":[\"KV Cache技术详解：优化Transformer自回归生成效率\"]},\"146\":{\"title\":\"Encoder中的Self-Attention\",\"titles\":[\"Transformer中的Attention详解与应用指南\",\"核心内容\",\"✅ Self-Attention机制\"]},\"147\":{\"title\":\"Self Attention的计算复杂度问题\",\"titles\":[\"优化Attention计算复杂度的技术探讨\",\"核心内容\"]},\"148\":{\"title\":\"核心内容\",\"titles\":[\"深度学习中的Layer Norm设计：Post-Norm、Pre-Norm与Sandwich-Norm比较\"]},\"149\":{\"title\":\"✅ MHA（Multi-head Attention）\",\"titles\":[\"深度学习中的注意力机制优化：从MHA到MLA\",\"核心观点总结\"]},\"150\":{\"title\":\"📈 技术趋势与优化点\",\"titles\":[\"Attention机制详解与应用\",\"Attention机制的核心思想与计算方法\"]},\"151\":{\"title\":\"强化学习基础\",\"titles\":[]},\"152\":{\"title\":\"内容摘要\",\"titles\":[\"激活函数详解与比较：从Sigmoid到Swish\"]},\"153\":{\"title\":\"行动清单\",\"titles\":[\"发展历史\"]},\"154\":{\"title\":\"元数据\",\"titles\":[\"介绍\"]},\"155\":{\"title\":\"📈 数据总结与优势\",\"titles\":[\"DCA：长文本处理的新突破（Dual Chunk Attention）\",\"核心思想与实现\"]},\"156\":{\"title\":\"⚠️ 操作步骤\",\"titles\":[\"【长上下文模型优化】基于Shifted Sparse Attention的创新方法\",\"技术解析\"]},\"157\":{\"title\":\"认证与集成复杂性\",\"titles\":[\"介绍\",\"API集成的挑战\"]},\"158\":{\"title\":\"关键内容解析\",\"titles\":[\"激活函数与FFN结构优化：SwiGLU、GeGLU及其应用解析\"]},\"159\":{\"title\":\"核心观点总结\",\"titles\":[\"NTK插值方法解析与优化：从NTK-aware到NTK-by-parts\"]},\"160\":{\"title\":\"元数据\",\"titles\":[\"位置内插法扩展语言模型上下文长度\"]},\"161\":{\"title\":\"数字输入优化与外推方法解析\",\"titles\":[]},\"162\":{\"title\":\"✅ FFN 前馈网络：独立计算的核心\",\"titles\":[\"Transformer核心模块解析：FFN、Add & LN 的作用与应用\",\"详细解析\"]},\"163\":{\"title\":\"内容概要\",\"titles\":[\"YaRN方法解析：扩展RoPE嵌入与注意力优化的实践\"]},\"164\":{\"title\":\"4. 举个例子\",\"titles\":[\"关于逻辑回归的思考\"]},\"165\":{\"title\":\"学习资源：\",\"titles\":[\"学习资料\",\"3. 深度学习基础\"]},\"166\":{\"title\":\"不使用KV Cache的流程\",\"titles\":[\"KV Cache技术详解：优化Transformer自回归生成效率\",\"KV Cache vs 不使用缓存\"]},\"167\":{\"title\":\"Decoder中的Self-Attention\",\"titles\":[\"Transformer中的Attention详解与应用指南\",\"核心内容\",\"✅ Self-Attention机制\"]},\"168\":{\"title\":\"Sparse Attention：局部与远程稀疏相关\",\"titles\":[\"优化Attention计算复杂度的技术探讨\",\"核心内容\"]},\"169\":{\"title\":\"Layer Norm的位置对模型的影响\",\"titles\":[\"深度学习中的Layer Norm设计：Post-Norm、Pre-Norm与Sandwich-Norm比较\",\"核心内容\"]},\"170\":{\"title\":\"⚠️ MQA（Multi-query Attention）\",\"titles\":[\"深度学习中的注意力机制优化：从MHA到MLA\",\"核心观点总结\"]},\"171\":{\"title\":\"常见错误与注意事项\",\"titles\":[\"Attention机制详解与应用\"]},\"172\":{\"title\":\"Common-Models\",\"titles\":[]},\"173\":{\"title\":\"常见激活函数解析\",\"titles\":[\"激活函数详解与比较：从Sigmoid到Swish\"]},\"174\":{\"title\":\"核心内容总结\",\"titles\":[\"介绍\"]},\"175\":{\"title\":\"常见错误\",\"titles\":[\"DCA：长文本处理的新突破（Dual Chunk Attention）\"]},\"176\":{\"title\":\"数据与示例\",\"titles\":[\"【长上下文模型优化】基于Shifted Sparse Attention的创新方法\"]},\"177\":{\"title\":\"如何应对这些挑战？\",\"titles\":[\"介绍\"]},\"178\":{\"title\":\"1. FFN结构与激活函数基础\",\"titles\":[\"激活函数与FFN结构优化：SwiGLU、GeGLU及其应用解析\",\"关键内容解析\"]},\"179\":{\"title\":\"关键内容解析\",\"titles\":[\"NTK插值方法解析与优化：从NTK-aware到NTK-by-parts\"]},\"180\":{\"title\":\"核心观点\",\"titles\":[\"位置内插法扩展语言模型上下文长度\"]},\"181\":{\"title\":\"元数据\",\"titles\":[\"数字输入优化与外推方法解析\"]},\"182\":{\"title\":\"旋转位置编码与ALiBi：深度学习中的位置嵌入优化\",\"titles\":[]},\"183\":{\"title\":\"⚠️ Add 残差连接：优化深层网络的梯度回传\",\"titles\":[\"Transformer核心模块解析：FFN、Add & LN 的作用与应用\",\"详细解析\"]},\"184\":{\"title\":\"核心观点\",\"titles\":[\"YaRN方法解析：扩展RoPE嵌入与注意力优化的实践\",\"内容概要\"]},\"185\":{\"title\":\"5. 总结\",\"titles\":[\"关于逻辑回归的思考\"]},\"186\":{\"title\":\"4. 智能阅读模型相关技术\",\"titles\":[\"学习资料\"]},\"187\":{\"title\":\"使用KV Cache的流程\",\"titles\":[\"KV Cache技术详解：优化Transformer自回归生成效率\",\"KV Cache vs 不使用缓存\"]},\"188\":{\"title\":\"✅ Cross-Attention机制\",\"titles\":[\"Transformer中的Attention详解与应用指南\",\"核心内容\"]},\"189\":{\"title\":\"Linear Attention：从平方复杂度到线性复杂度\",\"titles\":[\"优化Attention计算复杂度的技术探讨\",\"核心内容\"]},\"190\":{\"title\":\"Layer Norm的计算公式\",\"titles\":[\"深度学习中的Layer Norm设计：Post-Norm、Pre-Norm与Sandwich-Norm比较\",\"核心内容\"]},\"191\":{\"title\":\"❗️ GQA（Grouped-query Attention）\",\"titles\":[\"深度学习中的注意力机制优化：从MHA到MLA\",\"核心观点总结\"]},\"192\":{\"title\":\"❗️ 常见错误\",\"titles\":[\"Attention机制详解与应用\",\"常见错误与注意事项\"]},\"193\":{\"title\":\"训练推理优化\",\"titles\":[]},\"194\":{\"title\":\"Sigmoid\",\"titles\":[\"激活函数详解与比较：从Sigmoid到Swish\",\"常见激活函数解析\"]},\"195\":{\"title\":\"关键内容解析\",\"titles\":[\"介绍\"]},\"196\":{\"title\":\"行动清单\",\"titles\":[\"DCA：长文本处理的新突破（Dual Chunk Attention）\"]},\"197\":{\"title\":\"📊 数据表格：上下文长度分组与注意力计算\",\"titles\":[\"【长上下文模型优化】基于Shifted Sparse Attention的创新方法\",\"数据与示例\"]},\"198\":{\"title\":\"解决方案\",\"titles\":[\"介绍\",\"如何应对这些挑战？\"]},\"199\":{\"title\":\"2. GLU与其变种（SwiGLU、GeGLU）的改进\",\"titles\":[\"激活函数与FFN结构优化：SwiGLU、GeGLU及其应用解析\",\"关键内容解析\"]},\"200\":{\"title\":\"NTK-aware插值：高频外推与低频内插\",\"titles\":[\"NTK插值方法解析与优化：从NTK-aware到NTK-by-parts\",\"关键内容解析\"]},\"201\":{\"title\":\"重点内容\",\"titles\":[\"位置内插法扩展语言模型上下文长度\"]},\"202\":{\"title\":\"数字输入优化的核心方法\",\"titles\":[\"数字输入优化与外推方法解析\"]},\"203\":{\"title\":\"概述\",\"titles\":[\"旋转位置编码与ALiBi：深度学习中的位置嵌入优化\"]},\"204\":{\"title\":\"大模型结构与混合专家（LLM & MoE）解析\",\"titles\":[]},\"205\":{\"title\":\"❗️ LN 层归一化：NLP 中的收敛加速器\",\"titles\":[\"Transformer核心模块解析：FFN、Add & LN 的作用与应用\",\"详细解析\"]},\"206\":{\"title\":\"技术细节\",\"titles\":[\"YaRN方法解析：扩展RoPE嵌入与注意力优化的实践\"]},\"207\":{\"title\":\"需要学习的知识：\",\"titles\":[\"学习资料\",\"4. 智能阅读模型相关技术\"]},\"208\":{\"title\":\"技术实现示例\",\"titles\":[\"KV Cache技术详解：优化Transformer自回归生成效率\"]},\"209\":{\"title\":\"⚠️ 常见错误\",\"titles\":[\"Transformer中的Attention详解与应用指南\",\"核心内容\"]},\"210\":{\"title\":\"常见错误\",\"titles\":[\"优化Attention计算复杂度的技术探讨\"]},\"211\":{\"title\":\"技术术语通俗解释\",\"titles\":[\"深度学习中的Layer Norm设计：Post-Norm、Pre-Norm与Sandwich-Norm比较\",\"核心内容\"]},\"212\":{\"title\":\"📈 MLA（Multi-head Latent Attention）\",\"titles\":[\"深度学习中的注意力机制优化：从MHA到MLA\",\"核心观点总结\"]},\"213\":{\"title\":\"代码示例：Scaled Dot-Product计算\",\"titles\":[\"Attention机制详解与应用\"]},\"214\":{\"title\":\"模型压缩\",\"titles\":[]},\"215\":{\"title\":\"Tanh\",\"titles\":[\"激活函数详解与比较：从Sigmoid到Swish\",\"常见激活函数解析\"]},\"216\":{\"title\":\"1. 为什么需要位置编码？\",\"titles\":[\"介绍\",\"关键内容解析\"]},\"217\":{\"title\":\"[思考] 延伸问题\",\"titles\":[\"DCA：长文本处理的新突破（Dual Chunk Attention）\"]},\"218\":{\"title\":\"示例代码：分组与移位处理\",\"titles\":[\"【长上下文模型优化】基于Shifted Sparse Attention的创新方法\",\"数据与示例\"]},\"219\":{\"title\":\"[思考] 延伸问题\",\"titles\":[\"介绍\"]},\"220\":{\"title\":\"3. LLaMA2中的参数优化\",\"titles\":[\"激活函数与FFN结构优化：SwiGLU、GeGLU及其应用解析\",\"关键内容解析\"]},\"221\":{\"title\":\"核心思想\",\"titles\":[\"NTK插值方法解析与优化：从NTK-aware到NTK-by-parts\",\"关键内容解析\",\"NTK-aware插值：高频外推与低频内插\"]},\"222\":{\"title\":\"RoPE的问题与位置内插法的解决方案\",\"titles\":[\"位置内插法扩展语言模型上下文长度\",\"重点内容\"]},\"223\":{\"title\":\"✅ 数字输入的进制表示与直接外推\",\"titles\":[\"数字输入优化与外推方法解析\",\"数字输入优化的核心方法\"]},\"224\":{\"title\":\"核心内容\",\"titles\":[\"旋转位置编码与ALiBi：深度学习中的位置嵌入优化\"]},\"225\":{\"title\":\"元数据\",\"titles\":[\"大模型结构与混合专家（LLM & MoE）解析\"]},\"226\":{\"title\":\"深度解析语言模型采样方法：Top-K、Top-P、Temperature及综合策略\",\"titles\":[]},\"227\":{\"title\":\"📈 数据对比表：Batch Norm vs Layer Norm\",\"titles\":[\"Transformer核心模块解析：FFN、Add & LN 的作用与应用\",\"详细解析\"]},\"228\":{\"title\":\"## 1. 温度参数对注意力机制的优化\",\"titles\":[\"YaRN方法解析：扩展RoPE嵌入与注意力优化的实践\",\"技术细节\"]},\"229\":{\"title\":\"解码采样策略：Greedy Search与Beam Search的实现与优化\",\"titles\":[]},\"230\":{\"title\":\"学习资源：\",\"titles\":[\"学习资料\",\"4. 智能阅读模型相关技术\"]},\"231\":{\"title\":\"常见错误及警告\",\"titles\":[\"KV Cache技术详解：优化Transformer自回归生成效率\"]},\"232\":{\"title\":\"💡 启发点\",\"titles\":[\"Transformer中的Attention详解与应用指南\",\"核心内容\"]},\"233\":{\"title\":\"思考与延伸问题\",\"titles\":[\"优化Attention计算复杂度的技术探讨\"]},\"234\":{\"title\":\"行动清单\",\"titles\":[\"深度学习中的Layer Norm设计：Post-Norm、Pre-Norm与Sandwich-Norm比较\"]},\"235\":{\"title\":\"数据与公式解读\",\"titles\":[\"深度学习中的注意力机制优化：从MHA到MLA\"]},\"236\":{\"title\":\"作者观点 vs 个人观点\",\"titles\":[\"Attention机制详解与应用\"]},\"237\":{\"title\":\"大模型应用\",\"titles\":[]},\"238\":{\"title\":\"ReLU\",\"titles\":[\"激活函数详解与比较：从Sigmoid到Swish\",\"常见激活函数解析\"]},\"239\":{\"title\":\"2. 位置编码的设计要求\",\"titles\":[\"介绍\",\"关键内容解析\"]},\"240\":{\"title\":\"后续追踪研究计划\",\"titles\":[\"DCA：长文本处理的新突破（Dual Chunk Attention）\"]},\"241\":{\"title\":\"常见错误警告 ⚠️\",\"titles\":[\"【长上下文模型优化】基于Shifted Sparse Attention的创新方法\"]},\"242\":{\"title\":\"行动清单\",\"titles\":[\"介绍\"]},\"243\":{\"title\":\"4. 常见错误与注意事项\",\"titles\":[\"激活函数与FFN结构优化：SwiGLU、GeGLU及其应用解析\",\"关键内容解析\"]},\"244\":{\"title\":\"缺点\",\"titles\":[\"NTK插值方法解析与优化：从NTK-aware到NTK-by-parts\",\"关键内容解析\",\"NTK-aware插值：高频外推与低频内插\"]},\"245\":{\"title\":\"微调对效果的影响\",\"titles\":[\"位置内插法扩展语言模型上下文长度\",\"重点内容\"]},\"246\":{\"title\":\"⚠ 线性内插与进制转换的优化策略\",\"titles\":[\"数字输入优化与外推方法解析\",\"数字输入优化的核心方法\"]},\"247\":{\"title\":\"1. 什么是RoPE？\",\"titles\":[\"旋转位置编码与ALiBi：深度学习中的位置嵌入优化\",\"核心内容\"]},\"248\":{\"title\":\"核心内容总结\",\"titles\":[\"大模型结构与混合专家（LLM & MoE）解析\"]},\"249\":{\"title\":\"什么是语言模型采样方法？\",\"titles\":[\"深度解析语言模型采样方法：Top-K、Top-P、Temperature及综合策略\"]},\"250\":{\"title\":\"BBPE：字节级别的BPE分词技术解析与应用\",\"titles\":[]},\"251\":{\"title\":\"常见错误警告区块\",\"titles\":[\"Transformer核心模块解析：FFN、Add & LN 的作用与应用\"]},\"252\":{\"title\":\"## 2. RoPE嵌入的比例缩放\",\"titles\":[\"YaRN方法解析：扩展RoPE嵌入与注意力优化的实践\",\"技术细节\"]},\"253\":{\"title\":\"核心观点总结\",\"titles\":[\"解码采样策略：Greedy Search与Beam Search的实现与优化\"]},\"254\":{\"title\":\"5. 编程与工具\",\"titles\":[\"学习资料\"]},\"255\":{\"title\":\"💡启发点\",\"titles\":[\"KV Cache技术详解：优化Transformer自回归生成效率\"]},\"256\":{\"title\":\"行动清单\",\"titles\":[\"Transformer中的Attention详解与应用指南\"]},\"257\":{\"title\":\"作者观点 vs 个人观点\",\"titles\":[\"优化Attention计算复杂度的技术探讨\"]},\"258\":{\"title\":\"[思考]板块\",\"titles\":[\"深度学习中的Layer Norm设计：Post-Norm、Pre-Norm与Sandwich-Norm比较\"]},\"259\":{\"title\":\"KV缓存需求对比\",\"titles\":[\"深度学习中的注意力机制优化：从MHA到MLA\",\"数据与公式解读\"]},\"260\":{\"title\":\"思考 💭\",\"titles\":[\"Attention机制详解与应用\"]},\"261\":{\"title\":\"Leaky ReLU\",\"titles\":[\"激活函数详解与比较：从Sigmoid到Swish\",\"常见激活函数解析\"]},\"262\":{\"title\":\"WordPiece分词算法解析与实践\",\"titles\":[]},\"263\":{\"title\":\"3. 数学实现：正弦函数的应用\",\"titles\":[\"介绍\",\"关键内容解析\"]},\"264\":{\"title\":\"💡 启发点\",\"titles\":[\"【长上下文模型优化】基于Shifted Sparse Attention的创新方法\"]},\"265\":{\"title\":\"后续追踪\",\"titles\":[\"介绍\"]},\"266\":{\"title\":\"代码示例\",\"titles\":[\"激活函数与FFN结构优化：SwiGLU、GeGLU及其应用解析\"]},\"267\":{\"title\":\"NTK-by-parts插值：波长与上下文长度的关系\",\"titles\":[\"NTK插值方法解析与优化：从NTK-aware到NTK-by-parts\",\"关键内容解析\"]},\"268\":{\"title\":\"困惑度指标的重要性\",\"titles\":[\"位置内插法扩展语言模型上下文长度\",\"重点内容\"]},\"269\":{\"title\":\"常见错误提醒\",\"titles\":[\"数字输入优化与外推方法解析\"]},\"270\":{\"title\":\"💡 启发点：\\n由于旋转矩阵 $$R_m$$ 是正交矩阵，不改变向量模长，因此RoPE不会破坏模型的稳定性。\",\"titles\":[\"旋转位置编码与ALiBi：深度学习中的位置嵌入优化\"]},\"271\":{\"title\":\"模型结构分类\",\"titles\":[\"大模型结构与混合专家（LLM & MoE）解析\"]},\"272\":{\"title\":\"Top-K Sampling\",\"titles\":[\"深度解析语言模型采样方法：Top-K、Top-P、Temperature及综合策略\"]},\"273\":{\"title\":\"元数据\",\"titles\":[\"BBPE：字节级别的BPE分词技术解析与应用\"]},\"274\":{\"title\":\"使用Byte Pair Encoding (BPE)优化子词分词的技巧与实践\",\"titles\":[]},\"275\":{\"title\":\"行动清单 📋\",\"titles\":[\"Transformer核心模块解析：FFN、Add & LN 的作用与应用\"]},\"276\":{\"title\":\"## 3. LLaMA模型的推荐公式\",\"titles\":[\"YaRN方法解析：扩展RoPE嵌入与注意力优化的实践\",\"技术细节\"]},\"277\":{\"title\":\"解码策略详解\",\"titles\":[\"解码采样策略：Greedy Search与Beam Search的实现与优化\"]},\"278\":{\"title\":\"需要学习的知识：\",\"titles\":[\"学习资料\",\"5. 编程与工具\"]},\"279\":{\"title\":\"[思考]板块\",\"titles\":[\"KV Cache技术详解：优化Transformer自回归生成效率\"]},\"280\":{\"title\":\"个人见解\",\"titles\":[\"Transformer中的Attention详解与应用指南\"]},\"281\":{\"title\":\"行动清单\",\"titles\":[\"优化Attention计算复杂度的技术探讨\"]},\"282\":{\"title\":\"后续追踪计划\",\"titles\":[\"深度学习中的Layer Norm设计：Post-Norm、Pre-Norm与Sandwich-Norm比较\"]},\"283\":{\"title\":\"MLA核心公式\",\"titles\":[\"深度学习中的注意力机制优化：从MHA到MLA\",\"数据与公式解读\"]},\"284\":{\"title\":\"行动清单 ✅\",\"titles\":[\"Attention机制详解与应用\"]},\"285\":{\"title\":\"ELU\",\"titles\":[\"激活函数详解与比较：从Sigmoid到Swish\",\"常见激活函数解析\"]},\"286\":{\"title\":\"元数据\",\"titles\":[\"WordPiece分词算法解析与实践\"]},\"287\":{\"title\":\"4. 技术实现步骤\",\"titles\":[\"介绍\",\"关键内容解析\"]},\"288\":{\"title\":\"行动清单\",\"titles\":[\"【长上下文模型优化】基于Shifted Sparse Attention的创新方法\"]},\"289\":{\"title\":\"个人见解 [思考]\",\"titles\":[\"激活函数与FFN结构优化：SwiGLU、GeGLU及其应用解析\"]},\"290\":{\"title\":\"核心思想\",\"titles\":[\"NTK插值方法解析与优化：从NTK-aware到NTK-by-parts\",\"关键内容解析\",\"NTK-by-parts插值：波长与上下文长度的关系\"]},\"291\":{\"title\":\"应用位置内插的操作步骤\",\"titles\":[\"位置内插法扩展语言模型上下文长度\",\"重点内容\"]},\"292\":{\"title\":\"表格数据整理\",\"titles\":[\"数字输入优化与外推方法解析\"]},\"293\":{\"title\":\"2. 什么是ALiBi？\",\"titles\":[\"旋转位置编码与ALiBi：深度学习中的位置嵌入优化\",\"💡 启发点：\\n由于旋转矩阵 $$R_m$$ 是正交矩阵，不改变向量模长，因此RoPE不会破坏模型的稳定性。\"]},\"294\":{\"title\":\"Decoder-only 模型\",\"titles\":[\"大模型结构与混合专家（LLM & MoE）解析\",\"模型结构分类\"]},\"295\":{\"title\":\"核心概念：\",\"titles\":[\"深度解析语言模型采样方法：Top-K、Top-P、Temperature及综合策略\",\"Top-K Sampling\"]},\"296\":{\"title\":\"BBPE：字节级别的BPE分词技术\",\"titles\":[\"BBPE：字节级别的BPE分词技术解析与应用\"]},\"297\":{\"title\":\"元数据\",\"titles\":[\"使用Byte Pair Encoding (BPE)优化子词分词的技巧与实践\"]},\"298\":{\"title\":\"使用Unigram语言模型（ULM）优化分词算法：核心思路与实践\",\"titles\":[]},\"299\":{\"title\":\"[思考] 延伸问题\",\"titles\":[\"Transformer核心模块解析：FFN、Add & LN 的作用与应用\"]},\"300\":{\"title\":\"思考板块\",\"titles\":[\"YaRN方法解析：扩展RoPE嵌入与注意力优化的实践\"]},\"301\":{\"title\":\"Greedy Search\",\"titles\":[\"解码采样策略：Greedy Search与Beam Search的实现与优化\",\"解码策略详解\"]},\"302\":{\"title\":\"学习资源：\",\"titles\":[\"学习资料\",\"5. 编程与工具\"]},\"303\":{\"title\":\"行动清单\",\"titles\":[\"KV Cache技术详解：优化Transformer自回归生成效率\"]},\"304\":{\"title\":\"[思考]板块\",\"titles\":[\"Transformer中的Attention详解与应用指南\",\"个人见解\"]},\"305\":{\"title\":\"数据表格\",\"titles\":[\"优化Attention计算复杂度的技术探讨\"]},\"306\":{\"title\":\"📈 趋势预测\",\"titles\":[\"深度学习中的注意力机制优化：从MHA到MLA\",\"数据与公式解读\"]},\"307\":{\"title\":\"Swish\",\"titles\":[\"激活函数详解与比较：从Sigmoid到Swish\",\"常见激活函数解析\"]},\"308\":{\"title\":\"WordPiece分词算法简介\",\"titles\":[\"WordPiece分词算法解析与实践\"]},\"309\":{\"title\":\"常见错误与警告\",\"titles\":[\"介绍\"]},\"310\":{\"title\":\"思考 🤔\",\"titles\":[\"【长上下文模型优化】基于Shifted Sparse Attention的创新方法\"]},\"311\":{\"title\":\"行动清单\",\"titles\":[\"激活函数与FFN结构优化：SwiGLU、GeGLU及其应用解析\"]},\"312\":{\"title\":\"缺点\",\"titles\":[\"NTK插值方法解析与优化：从NTK-aware到NTK-by-parts\",\"关键内容解析\",\"NTK-by-parts插值：波长与上下文长度的关系\"]},\"313\":{\"title\":\"常见错误与警告\",\"titles\":[\"位置内插法扩展语言模型上下文长度\"]},\"314\":{\"title\":\"📈 趋势预测\",\"titles\":[\"数字输入优化与外推方法解析\"]},\"315\":{\"title\":\"3. RoPE与ALiBi的对比\",\"titles\":[\"旋转位置编码与ALiBi：深度学习中的位置嵌入优化\",\"💡 启发点：\\n由于旋转矩阵 $$R_m$$ 是正交矩阵，不改变向量模长，因此RoPE不会破坏模型的稳定性。\"]},\"316\":{\"title\":\"Encoder-only 模型\",\"titles\":[\"大模型结构与混合专家（LLM & MoE）解析\",\"模型结构分类\"]},\"317\":{\"title\":\"Top-P Sampling\",\"titles\":[\"深度解析语言模型采样方法：Top-K、Top-P、Temperature及综合策略\"]},\"318\":{\"title\":\"BBPE的核心特点与优势\",\"titles\":[\"BBPE：字节级别的BPE分词技术解析与应用\",\"BBPE：字节级别的BPE分词技术\"]},\"319\":{\"title\":\"核心观点概述\",\"titles\":[\"使用Byte Pair Encoding (BPE)优化子词分词的技巧与实践\"]},\"320\":{\"title\":\"元数据\",\"titles\":[\"使用Unigram语言模型（ULM）优化分词算法：核心思路与实践\"]},\"321\":{\"title\":\"分词算法的比较\",\"titles\":[]},\"322\":{\"title\":\"行动清单\",\"titles\":[\"YaRN方法解析：扩展RoPE嵌入与注意力优化的实践\"]},\"323\":{\"title\":\"常用分词库\",\"titles\":[]},\"324\":{\"title\":\"Beam Search\",\"titles\":[\"解码采样策略：Greedy Search与Beam Search的实现与优化\",\"解码策略详解\"]},\"325\":{\"title\":\"6. 数据集与实验设计\",\"titles\":[\"学习资料\"]},\"326\":{\"title\":\"作者观点 vs 个人观点对比\",\"titles\":[\"Transformer中的Attention详解与应用指南\"]},\"327\":{\"title\":\"后续追踪研究计划\",\"titles\":[\"优化Attention计算复杂度的技术探讨\"]},\"328\":{\"title\":\"推理耗时\",\"titles\":[]},\"329\":{\"title\":\"行动清单\",\"titles\":[\"深度学习中的注意力机制优化：从MHA到MLA\"]},\"330\":{\"title\":\"激活函数优缺点对比表\",\"titles\":[\"激活函数详解与比较：从Sigmoid到Swish\"]},\"331\":{\"title\":\"核心观点与实现步骤\",\"titles\":[\"WordPiece分词算法解析与实践\"]},\"332\":{\"title\":\"示例代码\",\"titles\":[\"介绍\"]},\"333\":{\"title\":\"延伸问题\",\"titles\":[\"【长上下文模型优化】基于Shifted Sparse Attention的创新方法\",\"思考 🤔\"]},\"334\":{\"title\":\"后续追踪研究计划\",\"titles\":[\"激活函数与FFN结构优化：SwiGLU、GeGLU及其应用解析\"]},\"335\":{\"title\":\"常见错误与注意事项\",\"titles\":[\"NTK插值方法解析与优化：从NTK-aware到NTK-by-parts\",\"关键内容解析\"]},\"336\":{\"title\":\"💡启发点\",\"titles\":[\"位置内插法扩展语言模型上下文长度\"]},\"337\":{\"title\":\"[思考]板块\",\"titles\":[\"数字输入优化与外推方法解析\"]},\"338\":{\"title\":\"常见错误\",\"titles\":[\"旋转位置编码与ALiBi：深度学习中的位置嵌入优化\"]},\"339\":{\"title\":\"Encoder-Decoder 模型\",\"titles\":[\"大模型结构与混合专家（LLM & MoE）解析\",\"模型结构分类\"]},\"340\":{\"title\":\"核心概念：\",\"titles\":[\"深度解析语言模型采样方法：Top-K、Top-P、Temperature及综合策略\",\"Top-P Sampling\"]},\"341\":{\"title\":\"BBPE的局限性与挑战\",\"titles\":[\"BBPE：字节级别的BPE分词技术解析与应用\",\"BBPE：字节级别的BPE分词技术\"]},\"342\":{\"title\":\"重点内容提取\",\"titles\":[\"使用Byte Pair Encoding (BPE)优化子词分词的技巧与实践\"]},\"343\":{\"title\":\"核心观点总结\",\"titles\":[\"使用Unigram语言模型（ULM）优化分词算法：核心思路与实践\"]},\"344\":{\"title\":\"元数据\",\"titles\":[\"分词算法的比较\"]},\"345\":{\"title\":\"数据多样性与模型优化探索\",\"titles\":[]},\"346\":{\"title\":\"数据表格示例\",\"titles\":[\"YaRN方法解析：扩展RoPE嵌入与注意力优化的实践\"]},\"347\":{\"title\":\"元数据\",\"titles\":[\"常用分词库\"]},\"348\":{\"title\":\"常见错误警告\",\"titles\":[\"解码采样策略：Greedy Search与Beam Search的实现与优化\"]},\"349\":{\"title\":\"需要学习的知识：\",\"titles\":[\"学习资料\",\"6. 数据集与实验设计\"]},\"350\":{\"title\":\"后续追踪研究计划\",\"titles\":[\"Transformer中的Attention详解与应用指南\"]},\"351\":{\"title\":\"推理机制概述\",\"titles\":[\"推理耗时\"]},\"352\":{\"title\":\"数据清洗\",\"titles\":[]},\"353\":{\"title\":\"✅ 工程实践建议\",\"titles\":[\"深度学习中的注意力机制优化：从MHA到MLA\",\"行动清单\"]},\"354\":{\"title\":\"常见错误与警示区块\",\"titles\":[\"激活函数详解与比较：从Sigmoid到Swish\"]},\"355\":{\"title\":\"WordPiece的核心思想\",\"titles\":[\"WordPiece分词算法解析与实践\",\"核心观点与实现步骤\"]},\"356\":{\"title\":\"[思考] 延伸问题\",\"titles\":[\"介绍\"]},\"357\":{\"title\":\"数据爬取\",\"titles\":[]},\"358\":{\"title\":\"来源标注\",\"titles\":[\"【长上下文模型优化】基于Shifted Sparse Attention的创新方法\"]},\"359\":{\"title\":\"操作步骤：如何应用NTK-aware和NTK-by-parts插值？\",\"titles\":[\"NTK插值方法解析与优化：从NTK-aware到NTK-by-parts\"]},\"360\":{\"title\":\"📈趋势预测\",\"titles\":[\"位置内插法扩展语言模型上下文长度\"]},\"361\":{\"title\":\"行动清单\",\"titles\":[\"数字输入优化与外推方法解析\"]},\"362\":{\"title\":\"思考\",\"titles\":[\"旋转位置编码与ALiBi：深度学习中的位置嵌入优化\"]},\"363\":{\"title\":\"Prefix LM（前缀语言模型）\",\"titles\":[\"大模型结构与混合专家（LLM & MoE）解析\",\"模型结构分类\"]},\"364\":{\"title\":\"代码实现：\",\"titles\":[\"深度解析语言模型采样方法：Top-K、Top-P、Temperature及综合策略\",\"Top-P Sampling\"]},\"365\":{\"title\":\"BBPE与BPE的对比\",\"titles\":[\"BBPE：字节级别的BPE分词技术解析与应用\",\"BBPE：字节级别的BPE分词技术\"]},\"366\":{\"title\":\"## BPE的核心思想\",\"titles\":[\"使用Byte Pair Encoding (BPE)优化子词分词的技巧与实践\",\"重点内容提取\"]},\"367\":{\"title\":\"重点内容解析\",\"titles\":[\"使用Unigram语言模型（ULM）优化分词算法：核心思路与实践\"]},\"368\":{\"title\":\"1️⃣ 核心观点总结\",\"titles\":[\"分词算法的比较\"]},\"369\":{\"title\":\"数据多样性的核心价值\",\"titles\":[\"数据多样性与模型优化探索\"]},\"370\":{\"title\":\"数据配比与训练顺序优化指南\",\"titles\":[]},\"371\":{\"title\":\"模型打分与数据去重\",\"titles\":[]},\"372\":{\"title\":\"后续追踪\",\"titles\":[\"YaRN方法解析：扩展RoPE嵌入与注意力优化的实践\"]},\"373\":{\"title\":\"核心内容总结\",\"titles\":[\"常用分词库\"]},\"374\":{\"title\":\"数据与公式\",\"titles\":[\"解码采样策略：Greedy Search与Beam Search的实现与优化\"]},\"375\":{\"title\":\"学习资源：\",\"titles\":[\"学习资料\",\"6. 数据集与实验设计\"]},\"376\":{\"title\":\"关键瓶颈\",\"titles\":[\"推理耗时\",\"推理机制概述\"]},\"377\":{\"title\":\"元数据\",\"titles\":[\"数据清洗\"]},\"378\":{\"title\":\"⚠️ 常见错误\",\"titles\":[\"深度学习中的注意力机制优化：从MHA到MLA\",\"行动清单\"]},\"379\":{\"title\":\"深度学习中的显存优化与梯度处理方法\",\"titles\":[]},\"380\":{\"title\":\"行动清单\",\"titles\":[\"激活函数详解与比较：从Sigmoid到Swish\"]},\"381\":{\"title\":\"WordPiece的实现步骤\",\"titles\":[\"WordPiece分词算法解析与实践\",\"核心观点与实现步骤\"]},\"382\":{\"title\":\"混合精度训练\",\"titles\":[]},\"383\":{\"title\":\"行动清单\",\"titles\":[\"介绍\"]},\"384\":{\"title\":\"元数据\",\"titles\":[\"数据爬取\"]},\"385\":{\"title\":\"后续追踪 📈\",\"titles\":[\"【长上下文模型优化】基于Shifted Sparse Attention的创新方法\"]},\"386\":{\"title\":\"💡启发点\",\"titles\":[\"NTK插值方法解析与优化：从NTK-aware到NTK-by-parts\"]},\"387\":{\"title\":\"行动清单\",\"titles\":[\"位置内插法扩展语言模型上下文长度\"]},\"388\":{\"title\":\"行动清单\",\"titles\":[\"旋转位置编码与ALiBi：深度学习中的位置嵌入优化\"]},\"389\":{\"title\":\"混合专家（MoE）架构\",\"titles\":[\"大模型结构与混合专家（LLM & MoE）解析\"]},\"390\":{\"title\":\"Temperature Sampling\",\"titles\":[\"深度解析语言模型采样方法：Top-K、Top-P、Temperature及综合策略\"]},\"391\":{\"title\":\"BBPE代码实现示例\",\"titles\":[\"BBPE：字节级别的BPE分词技术解析与应用\",\"BBPE：字节级别的BPE分词技术\"]},\"392\":{\"title\":\"## BPE的操作步骤\",\"titles\":[\"使用Byte Pair Encoding (BPE)优化子词分词的技巧与实践\",\"重点内容提取\"]},\"393\":{\"title\":\"1. ULM的核心思路\",\"titles\":[\"使用Unigram语言模型（ULM）优化分词算法：核心思路与实践\",\"重点内容解析\"]},\"394\":{\"title\":\"2️⃣ 重点内容解析\",\"titles\":[\"分词算法的比较\"]},\"395\":{\"title\":\"核心数据筛选方法\",\"titles\":[\"数据多样性与模型优化探索\"]},\"396\":{\"title\":\"元数据\",\"titles\":[\"数据配比与训练顺序优化指南\"]},\"397\":{\"title\":\"继续预训练\",\"titles\":[]},\"398\":{\"title\":\"元数据\",\"titles\":[\"模型打分与数据去重\"]},\"399\":{\"title\":\"重点内容\",\"titles\":[\"常用分词库\"]},\"400\":{\"title\":\"数据表格示例\",\"titles\":[\"解码采样策略：Greedy Search与Beam Search的实现与优化\",\"数据与公式\"]},\"401\":{\"title\":\"7. 论文写作与学术规范\",\"titles\":[\"学习资料\"]},\"402\":{\"title\":\"时延计算\",\"titles\":[\"推理耗时\"]},\"403\":{\"title\":\"核心观点总结\",\"titles\":[\"数据清洗\"]},\"404\":{\"title\":\"💡 启发点\",\"titles\":[\"深度学习中的注意力机制优化：从MHA到MLA\"]},\"405\":{\"title\":\"元数据\",\"titles\":[\"深度学习中的显存优化与梯度处理方法\"]},\"406\":{\"title\":\"思考与启发\",\"titles\":[\"激活函数详解与比较：从Sigmoid到Swish\"]},\"407\":{\"title\":\"实现代码片段\",\"titles\":[\"WordPiece分词算法解析与实践\",\"核心观点与实现步骤\"]},\"408\":{\"title\":\"什么是混合精度训练？\",\"titles\":[\"混合精度训练\"]},\"409\":{\"title\":\"后续追踪\",\"titles\":[\"介绍\"]},\"410\":{\"title\":\"训练容灾及训练监控\",\"titles\":[]},\"411\":{\"title\":\"核心观点总结\",\"titles\":[\"数据爬取\"]},\"412\":{\"title\":\"📈趋势预测\",\"titles\":[\"NTK插值方法解析与优化：从NTK-aware到NTK-by-parts\"]},\"413\":{\"title\":\"[思考]板块\",\"titles\":[\"位置内插法扩展语言模型上下文长度\"]},\"414\":{\"title\":\"后续追踪\",\"titles\":[\"旋转位置编码与ALiBi：深度学习中的位置嵌入优化\"]},\"415\":{\"title\":\"什么是 MoE？\",\"titles\":[\"大模型结构与混合专家（LLM & MoE）解析\",\"混合专家（MoE）架构\"]},\"416\":{\"title\":\"核心概念：\",\"titles\":[\"深度解析语言模型采样方法：Top-K、Top-P、Temperature及综合策略\",\"Temperature Sampling\"]},\"417\":{\"title\":\"常见错误提示\",\"titles\":[\"BBPE：字节级别的BPE分词技术解析与应用\",\"BBPE：字节级别的BPE分词技术\"]},\"418\":{\"title\":\"## 示例：从语料库中生成子词表\",\"titles\":[\"使用Byte Pair Encoding (BPE)优化子词分词的技巧与实践\",\"重点内容提取\"]},\"419\":{\"title\":\"2. ULM的优势与挑战\",\"titles\":[\"使用Unigram语言模型（ULM）优化分词算法：核心思路与实践\",\"重点内容解析\"]},\"420\":{\"title\":\"💡 WordPiece与BPE的对比\",\"titles\":[\"分词算法的比较\",\"2️⃣ 重点内容解析\"]},\"421\":{\"title\":\"方法1：基于K-means聚类的多样性采样\",\"titles\":[\"数据多样性与模型优化探索\",\"核心数据筛选方法\"]},\"422\":{\"title\":\"核心观点总结\",\"titles\":[\"数据配比与训练顺序优化指南\"]},\"423\":{\"title\":\"核心观点总结\",\"titles\":[\"继续预训练\"]},\"424\":{\"title\":\"预训练定义以及数据来源\",\"titles\":[]},\"425\":{\"title\":\"核心观点总结\",\"titles\":[\"模型打分与数据去重\"]},\"426\":{\"title\":\"1. SentencePiece 的核心特点\",\"titles\":[\"常用分词库\",\"重点内容\"]},\"427\":{\"title\":\"公式示例\",\"titles\":[\"解码采样策略：Greedy Search与Beam Search的实现与优化\",\"数据与公式\"]},\"428\":{\"title\":\"需要学习的知识：\",\"titles\":[\"学习资料\",\"7. 论文写作与学术规范\"]},\"429\":{\"title\":\"数据量分析\",\"titles\":[\"推理耗时\",\"时延计算\"]},\"430\":{\"title\":\"重点内容提取\",\"titles\":[\"数据清洗\"]},\"431\":{\"title\":\"预训练评估\",\"titles\":[]},\"432\":{\"title\":\"[思考]板块\",\"titles\":[\"深度学习中的注意力机制优化：从MHA到MLA\"]},\"433\":{\"title\":\"核心内容总结\",\"titles\":[\"深度学习中的显存优化与梯度处理方法\"]},\"434\":{\"title\":\"优缺点分析\",\"titles\":[\"WordPiece分词算法解析与实践\"]},\"435\":{\"title\":\"混合精度训练的核心流程\",\"titles\":[\"混合精度训练\"]},\"436\":{\"title\":\"预训练评估2\",\"titles\":[]},\"437\":{\"title\":\"元数据\",\"titles\":[\"训练容灾及训练监控\"]},\"438\":{\"title\":\"重点内容解析\",\"titles\":[\"数据爬取\"]},\"439\":{\"title\":\"行动清单\",\"titles\":[\"NTK插值方法解析与优化：从NTK-aware到NTK-by-parts\"]},\"440\":{\"title\":\"构成要素\",\"titles\":[\"大模型结构与混合专家（LLM & MoE）解析\",\"混合专家（MoE）架构\"]},\"441\":{\"title\":\"综合采样策略：KPT\",\"titles\":[\"深度解析语言模型采样方法：Top-K、Top-P、Temperature及综合策略\"]},\"442\":{\"title\":\"行动清单\",\"titles\":[\"BBPE：字节级别的BPE分词技术解析与应用\",\"BBPE：字节级别的BPE分词技术\"]},\"443\":{\"title\":\"初始语料库（带频次）\",\"titles\":[\"使用Byte Pair Encoding (BPE)优化子词分词的技巧与实践\",\"重点内容提取\",\"## 示例：从语料库中生成子词表\"]},\"444\":{\"title\":\"3. ULM操作流程示例\",\"titles\":[\"使用Unigram语言模型（ULM）优化分词算法：核心思路与实践\",\"重点内容解析\"]},\"445\":{\"title\":\"💡 WordPiece与ULM的对比\",\"titles\":[\"分词算法的比较\",\"2️⃣ 重点内容解析\"]},\"446\":{\"title\":\"方法2：加权采样（基于聚类簇的多样性权重和质量权重）\",\"titles\":[\"数据多样性与模型优化探索\",\"核心数据筛选方法\"]},\"447\":{\"title\":\"重点内容提取\",\"titles\":[\"数据配比与训练顺序优化指南\"]},\"448\":{\"title\":\"重点内容\",\"titles\":[\"继续预训练\"]},\"449\":{\"title\":\"核心观点总结\",\"titles\":[\"预训练定义以及数据来源\"]},\"450\":{\"title\":\"Prompt Tech 提示技术\",\"titles\":[]},\"451\":{\"title\":\"数据质量评估与打分\",\"titles\":[\"模型打分与数据去重\"]},\"452\":{\"title\":\"2. Tokenizers库的编码流程\",\"titles\":[\"常用分词库\",\"重点内容\"]},\"453\":{\"title\":\"[思考] 延伸问题\",\"titles\":[\"解码采样策略：Greedy Search与Beam Search的实现与优化\"]},\"454\":{\"title\":\"学习资源：\",\"titles\":[\"学习资料\",\"7. 论文写作与学术规范\"]},\"455\":{\"title\":\"KV-cache读取\",\"titles\":[\"推理耗时\",\"时延计算\"]},\"456\":{\"title\":\"URL 过滤\",\"titles\":[\"数据清洗\",\"重点内容提取\"]},\"457\":{\"title\":\"预训练评估的核心观点\",\"titles\":[\"预训练评估\"]},\"458\":{\"title\":\"Actor-Critic算法\",\"titles\":[]},\"459\":{\"title\":\"主要内容\",\"titles\":[\"深度学习中的显存优化与梯度处理方法\"]},\"460\":{\"title\":\"PPO算法\",\"titles\":[]},\"461\":{\"title\":\"常见错误与注意事项\",\"titles\":[\"WordPiece分词算法解析与实践\"]},\"462\":{\"title\":\"混合精度训练的优势\",\"titles\":[\"混合精度训练\"]},\"463\":{\"title\":\"大海捞针测试\",\"titles\":[\"预训练评估2\"]},\"464\":{\"title\":\"核心观点总结\",\"titles\":[\"训练容灾及训练监控\"]},\"465\":{\"title\":\"✅ 高质量PDF数据解析方法\",\"titles\":[\"数据爬取\",\"重点内容解析\"]},\"466\":{\"title\":\"[思考]板块\",\"titles\":[\"NTK插值方法解析与优化：从NTK-aware到NTK-by-parts\"]},\"467\":{\"title\":\"放置位置\",\"titles\":[\"大模型结构与混合专家（LLM & MoE）解析\",\"混合专家（MoE）架构\"]},\"468\":{\"title\":\"核心概念：\",\"titles\":[\"深度解析语言模型采样方法：Top-K、Top-P、Temperature及综合策略\",\"综合采样策略：KPT\"]},\"469\":{\"title\":\"[思考] 板块\",\"titles\":[\"BBPE：字节级别的BPE分词技术解析与应用\"]},\"470\":{\"title\":\"基础字符频次统计\",\"titles\":[\"使用Byte Pair Encoding (BPE)优化子词分词的技巧与实践\",\"重点内容提取\",\"## 示例：从语料库中生成子词表\"]},\"471\":{\"title\":\"4. 数据与趋势📈\",\"titles\":[\"使用Unigram语言模型（ULM）优化分词算法：核心思路与实践\",\"重点内容解析\"]},\"472\":{\"title\":\"⚠️ 常见错误\",\"titles\":[\"分词算法的比较\",\"2️⃣ 重点内容解析\"]},\"473\":{\"title\":\"方法3：基于KNN聚类的权重采样\",\"titles\":[\"数据多样性与模型优化探索\",\"核心数据筛选方法\"]},\"474\":{\"title\":\"数据分类与配比方法\",\"titles\":[\"数据配比与训练顺序优化指南\",\"重点内容提取\"]},\"475\":{\"title\":\"1. 什么是继续预训练？\",\"titles\":[\"继续预训练\",\"重点内容\"]},\"476\":{\"title\":\"重点内容解析\",\"titles\":[\"预训练定义以及数据来源\"]},\"477\":{\"title\":\"ICL概念原理\",\"titles\":[\"Prompt Tech 提示技术\"]},\"478\":{\"title\":\"PPO训练的trick和问题\",\"titles\":[]},\"479\":{\"title\":\"✅ 模型打分器的选择\",\"titles\":[\"模型打分与数据去重\",\"数据质量评估与打分\"]},\"480\":{\"title\":\"✅ Normalization（标准化）\",\"titles\":[\"常用分词库\",\"重点内容\",\"2. Tokenizers库的编码流程\"]},\"481\":{\"title\":\"行动清单\",\"titles\":[\"解码采样策略：Greedy Search与Beam Search的实现与优化\"]},\"482\":{\"title\":\"8. 实践与项目\",\"titles\":[\"学习资料\"]},\"483\":{\"title\":\"计算时延\",\"titles\":[\"推理耗时\",\"时延计算\"]},\"484\":{\"title\":\"RL在NLP场景下的拓展\",\"titles\":[]},\"485\":{\"title\":\"内容提取\",\"titles\":[\"数据清洗\",\"重点内容提取\"]},\"486\":{\"title\":\"重点内容\",\"titles\":[\"预训练评估\"]},\"487\":{\"title\":\"元数据\",\"titles\":[\"Actor-Critic算法\"]},\"488\":{\"title\":\"显存占用与数据类型的影响\",\"titles\":[\"深度学习中的显存优化与梯度处理方法\",\"主要内容\"]},\"489\":{\"title\":\"元数据\",\"titles\":[\"PPO算法\"]},\"490\":{\"title\":\"思考与延伸问题\",\"titles\":[\"WordPiece分词算法解析与实践\"]},\"491\":{\"title\":\"常见问题与解决方法\",\"titles\":[\"混合精度训练\"]},\"492\":{\"title\":\"核心观点\",\"titles\":[\"预训练评估2\",\"大海捞针测试\"]},\"493\":{\"title\":\"核心内容解析\",\"titles\":[\"训练容灾及训练监控\"]},\"494\":{\"title\":\"✅ 爬虫分类与实现方式\",\"titles\":[\"数据爬取\",\"重点内容解析\"]},\"495\":{\"title\":\"应用场景\",\"titles\":[\"大模型结构与混合专家（LLM & MoE）解析\",\"混合专家（MoE）架构\"]},\"496\":{\"title\":\"多答案选择策略\",\"titles\":[\"深度解析语言模型采样方法：Top-K、Top-P、Temperature及综合策略\"]},\"497\":{\"title\":\"第一次迭代：合并频率最高的字符对\",\"titles\":[\"使用Byte Pair Encoding (BPE)优化子词分词的技巧与实践\",\"重点内容提取\",\"## 示例：从语料库中生成子词表\"]},\"498\":{\"title\":\"5. 常见错误⚠️\",\"titles\":[\"使用Unigram语言模型（ULM）优化分词算法：核心思路与实践\",\"重点内容解析\"]},\"499\":{\"title\":\"3️⃣ 技术术语通俗解读\",\"titles\":[\"分词算法的比较\"]},\"500\":{\"title\":\"垂域数据扩充流程\",\"titles\":[\"数据多样性与模型优化探索\"]},\"501\":{\"title\":\"领域数据的使用策略\",\"titles\":[\"数据配比与训练顺序优化指南\",\"重点内容提取\"]},\"502\":{\"title\":\"2. 长文本预训练的技术细节\",\"titles\":[\"继续预训练\",\"重点内容\"]},\"503\":{\"title\":\"1. 预训练的定义与目标\",\"titles\":[\"预训练定义以及数据来源\",\"重点内容解析\"]},\"504\":{\"title\":\"核心概念\",\"titles\":[\"Prompt Tech 提示技术\"]},\"505\":{\"title\":\"PPO训练中的关键技巧\",\"titles\":[\"PPO训练的trick和问题\"]},\"506\":{\"title\":\"SARSA-λ与Q-learning对比\",\"titles\":[]},\"507\":{\"title\":\"⚠ 训练打分器的注意事项\",\"titles\":[\"模型打分与数据去重\",\"数据质量评估与打分\"]},\"508\":{\"title\":\"⚠️ Pre-tokenization（预分词）\",\"titles\":[\"常用分词库\",\"重点内容\",\"2. Tokenizers库的编码流程\"]},\"509\":{\"title\":\"SARSA算法\",\"titles\":[]},\"510\":{\"title\":\"后续追踪\",\"titles\":[\"解码采样策略：Greedy Search与Beam Search的实现与优化\"]},\"511\":{\"title\":\"需要学习的知识：\",\"titles\":[\"学习资料\",\"8. 实践与项目\"]},\"512\":{\"title\":\"价值迭代算法\",\"titles\":[]},\"513\":{\"title\":\"公式总结\",\"titles\":[\"推理耗时\"]},\"514\":{\"title\":\"核心观点总结\",\"titles\":[\"RL在NLP场景下的拓展\"]},\"515\":{\"title\":\"语言识别\",\"titles\":[\"数据清洗\",\"重点内容提取\"]},\"516\":{\"title\":\"困惑度（PPL）测量\",\"titles\":[\"预训练评估\",\"重点内容\"]},\"517\":{\"title\":\"强化学习分类\",\"titles\":[]},\"518\":{\"title\":\"核心观点总结\",\"titles\":[\"Actor-Critic算法\"]},\"519\":{\"title\":\"强化学习的独特性\",\"titles\":[]},\"520\":{\"title\":\"Loss Scale 的两种策略\",\"titles\":[\"深度学习中的显存优化与梯度处理方法\",\"主要内容\"]},\"521\":{\"title\":\"核心观点\",\"titles\":[\"PPO算法\"]},\"522\":{\"title\":\"行动清单\",\"titles\":[\"WordPiece分词算法解析与实践\"]},\"523\":{\"title\":\"⚠ 舍入误差\",\"titles\":[\"混合精度训练\",\"常见问题与解决方法\"]},\"524\":{\"title\":\"重点段落\",\"titles\":[\"预训练评估2\",\"大海捞针测试\"]},\"525\":{\"title\":\"监控 Loss 和 Spike\",\"titles\":[\"训练容灾及训练监控\",\"核心内容解析\"]},\"526\":{\"title\":\"⚙ 基本配置建议（代码片段）\",\"titles\":[\"数据爬取\",\"重点内容解析\"]},\"527\":{\"title\":\"常见错误\",\"titles\":[\"大模型结构与混合专家（LLM & MoE）解析\"]},\"528\":{\"title\":\"Best-of-N\",\"titles\":[\"深度解析语言模型采样方法：Top-K、Top-P、Temperature及综合策略\",\"多答案选择策略\"]},\"529\":{\"title\":\"## 优缺点分析\",\"titles\":[\"使用Byte Pair Encoding (BPE)优化子词分词的技巧与实践\",\"重点内容提取\"]},\"530\":{\"title\":\"行动清单\",\"titles\":[\"使用Unigram语言模型（ULM）优化分词算法：核心思路与实践\"]},\"531\":{\"title\":\"4️⃣ 行动清单\",\"titles\":[\"分词算法的比较\"]},\"532\":{\"title\":\"数据处理与筛选流程\",\"titles\":[\"数据多样性与模型优化探索\",\"垂域数据扩充流程\"]},\"533\":{\"title\":\"数据训练顺序与课程学习\",\"titles\":[\"数据配比与训练顺序优化指南\",\"重点内容提取\"]},\"534\":{\"title\":\"3. 数据与采样\",\"titles\":[\"继续预训练\",\"重点内容\"]},\"535\":{\"title\":\"2. 预训练数据的来源与规模\",\"titles\":[\"预训练定义以及数据来源\",\"重点内容解析\"]},\"536\":{\"title\":\"上下文依赖\",\"titles\":[\"Prompt Tech 提示技术\",\"核心概念\"]},\"537\":{\"title\":\"Token Level KL-Penalty\",\"titles\":[\"PPO训练的trick和问题\",\"PPO训练中的关键技巧\"]},\"538\":{\"title\":\"分类\",\"titles\":[\"SARSA-λ与Q-learning对比\"]},\"539\":{\"title\":\"强化学习问题,流程\",\"titles\":[]},\"540\":{\"title\":\"时序差分算法\",\"titles\":[]},\"541\":{\"title\":\"数据去重的三大类别\",\"titles\":[\"模型打分与数据去重\"]},\"542\":{\"title\":\"❗️ 模型分词与后处理\",\"titles\":[\"常用分词库\",\"重点内容\",\"2. Tokenizers库的编码流程\"]},\"543\":{\"title\":\"元数据\",\"titles\":[\"SARSA算法\"]},\"544\":{\"title\":\"学习资源：\",\"titles\":[\"学习资料\",\"8. 实践与项目\"]},\"545\":{\"title\":\"元数据\",\"titles\":[\"价值迭代算法\"]},\"546\":{\"title\":\"常见错误\",\"titles\":[\"推理耗时\"]},\"547\":{\"title\":\"重点段落\",\"titles\":[\"RL在NLP场景下的拓展\"]},\"548\":{\"title\":\"低质内容过滤\",\"titles\":[\"数据清洗\",\"重点内容提取\"]},\"549\":{\"title\":\"Benchmark评估\",\"titles\":[\"预训练评估\",\"重点内容\"]},\"550\":{\"title\":\"元数据\",\"titles\":[\"强化学习分类\"]},\"551\":{\"title\":\"重点内容\",\"titles\":[\"Actor-Critic算法\"]},\"552\":{\"title\":\"元数据\",\"titles\":[\"强化学习的独特性\"]},\"553\":{\"title\":\"1. 常量损失放大\",\"titles\":[\"深度学习中的显存优化与梯度处理方法\",\"主要内容\",\"Loss Scale 的两种策略\"]},\"554\":{\"title\":\"重点段落\",\"titles\":[\"PPO算法\"]},\"555\":{\"title\":\"后续追踪计划\",\"titles\":[\"WordPiece分词算法解析与实践\"]},\"556\":{\"title\":\"⚠ 梯度下溢\",\"titles\":[\"混合精度训练\",\"常见问题与解决方法\"]},\"557\":{\"title\":\"概率探针\",\"titles\":[\"预训练评估2\"]},\"558\":{\"title\":\"困惑度（Perplexity）分析\",\"titles\":[\"训练容灾及训练监控\",\"核心内容解析\"]},\"559\":{\"title\":\"📋 指定平台爬虫ID列表示例\",\"titles\":[\"数据爬取\",\"重点内容解析\"]},\"560\":{\"title\":\"操作步骤\",\"titles\":[\"大模型结构与混合专家（LLM & MoE）解析\"]},\"561\":{\"title\":\"Majority Vote\",\"titles\":[\"深度解析语言模型采样方法：Top-K、Top-P、Temperature及综合策略\",\"多答案选择策略\"]},\"562\":{\"title\":\"常见错误与注意事项\",\"titles\":[\"使用Byte Pair Encoding (BPE)优化子词分词的技巧与实践\"]},\"563\":{\"title\":\"[思考] 延伸问题\",\"titles\":[\"使用Unigram语言模型（ULM）优化分词算法：核心思路与实践\"]},\"564\":{\"title\":\"[思考] 板块\",\"titles\":[\"分词算法的比较\"]},\"565\":{\"title\":\"常见错误与注意事项\",\"titles\":[\"数据多样性与模型优化探索\"]},\"566\":{\"title\":\"警告区块\",\"titles\":[\"数据配比与训练顺序优化指南\"]},\"567\":{\"title\":\"4. 主要步骤\",\"titles\":[\"继续预训练\",\"重点内容\"]},\"568\":{\"title\":\"3. 数据处理的挑战\",\"titles\":[\"预训练定义以及数据来源\",\"重点内容解析\"]},\"569\":{\"title\":\"无参数更新\",\"titles\":[\"Prompt Tech 提示技术\",\"核心概念\"]},\"570\":{\"title\":\"Generalized Advantage Estimation (GAE)\",\"titles\":[\"PPO训练的trick和问题\",\"PPO训练中的关键技巧\"]},\"571\":{\"title\":\"标签\",\"titles\":[\"SARSA-λ与Q-learning对比\"]},\"572\":{\"title\":\"强化学习问题与流程\",\"titles\":[\"强化学习问题,流程\"]},\"573\":{\"title\":\"深度Q网络\",\"titles\":[]},\"574\":{\"title\":\"核心观点\",\"titles\":[\"时序差分算法\"]},\"575\":{\"title\":\"❗ 数据重复类型\",\"titles\":[\"模型打分与数据去重\",\"数据去重的三大类别\"]},\"576\":{\"title\":\"3. 常见错误与注意事项\",\"titles\":[\"常用分词库\",\"重点内容\"]},\"577\":{\"title\":\"内容概述\",\"titles\":[\"SARSA算法\"]},\"578\":{\"title\":\"总结\",\"titles\":[\"学习资料\"]},\"579\":{\"title\":\"内容处理\",\"titles\":[\"价值迭代算法\"]},\"580\":{\"title\":\"💡启发点\",\"titles\":[\"推理耗时\"]},\"581\":{\"title\":\"NLP中的MDP建模\",\"titles\":[\"RL在NLP场景下的拓展\",\"重点段落\"]},\"582\":{\"title\":\"常见错误警告\",\"titles\":[\"数据清洗\"]},\"583\":{\"title\":\"技术术语解释\",\"titles\":[\"预训练评估\",\"重点内容\"]},\"584\":{\"title\":\"策略梯度算法\",\"titles\":[]},\"585\":{\"title\":\"内容概要\",\"titles\":[\"强化学习分类\"]},\"586\":{\"title\":\"策略梯度与Q值函数\",\"titles\":[\"Actor-Critic算法\",\"重点内容\"]},\"587\":{\"title\":\"核心观点总结\",\"titles\":[\"强化学习的独特性\"]},\"588\":{\"title\":\"策略迭代算法\",\"titles\":[]},\"589\":{\"title\":\"2. 动量损失放大\",\"titles\":[\"深度学习中的显存优化与梯度处理方法\",\"主要内容\",\"Loss Scale 的两种策略\"]},\"590\":{\"title\":\"PPO算法的基本原理\",\"titles\":[\"PPO算法\",\"重点段落\"]},\"591\":{\"title\":\"数据支持\",\"titles\":[\"混合精度训练\"]},\"592\":{\"title\":\"核心观点\",\"titles\":[\"预训练评估2\",\"概率探针\"]},\"593\":{\"title\":\"解决 Loss Spike 的方法\",\"titles\":[\"训练容灾及训练监控\",\"核心内容解析\"]},\"594\":{\"title\":\"常见错误警告 ⚠️\",\"titles\":[\"数据爬取\"]},\"595\":{\"title\":\"数据表格示例\",\"titles\":[\"大模型结构与混合专家（LLM & MoE）解析\"]},\"596\":{\"title\":\"Self-consistency\",\"titles\":[\"深度解析语言模型采样方法：Top-K、Top-P、Temperature及综合策略\",\"多答案选择策略\"]},\"597\":{\"title\":\"行动清单\",\"titles\":[\"使用Byte Pair Encoding (BPE)优化子词分词的技巧与实践\"]},\"598\":{\"title\":\"📈 未来趋势预测\",\"titles\":[\"数据多样性与模型优化探索\"]},\"599\":{\"title\":\"行动清单\",\"titles\":[\"数据配比与训练顺序优化指南\"]},\"600\":{\"title\":\"常见错误\",\"titles\":[\"继续预训练\"]},\"601\":{\"title\":\"常见错误与注意事项\",\"titles\":[\"预训练定义以及数据来源\"]},\"602\":{\"title\":\"动态适应\",\"titles\":[\"Prompt Tech 提示技术\",\"核心概念\"]},\"603\":{\"title\":\"Adding SFT Loss\",\"titles\":[\"PPO训练的trick和问题\",\"PPO训练中的关键技巧\"]},\"604\":{\"title\":\"日期\",\"titles\":[\"SARSA-λ与Q-learning对比\"]},\"605\":{\"title\":\"应用场景\",\"titles\":[\"强化学习问题,流程\",\"强化学习问题与流程\"]},\"606\":{\"title\":\"DQN简介\",\"titles\":[\"深度Q网络\"]},\"607\":{\"title\":\"蒙特卡洛方法\",\"titles\":[]},\"608\":{\"title\":\"重点段落\",\"titles\":[\"时序差分算法\"]},\"609\":{\"title\":\"数据去重流程\",\"titles\":[\"模型打分与数据去重\"]},\"610\":{\"title\":\"作者观点 vs 个人观点\",\"titles\":[\"常用分词库\"]},\"611\":{\"title\":\"核心观点\",\"titles\":[\"SARSA算法\"]},\"612\":{\"title\":\"核心观点\",\"titles\":[\"价值迭代算法\",\"内容处理\"]},\"613\":{\"title\":\"行动清单\",\"titles\":[\"推理耗时\"]},\"614\":{\"title\":\"强化学习优化目标\",\"titles\":[\"RL在NLP场景下的拓展\",\"重点段落\"]},\"615\":{\"title\":\"行动清单\",\"titles\":[\"数据清洗\"]},\"616\":{\"title\":\"思考\",\"titles\":[\"预训练评估\"]},\"617\":{\"title\":\"元数据\",\"titles\":[\"策略梯度算法\"]},\"618\":{\"title\":\"以数据来源划分\",\"titles\":[\"强化学习分类\",\"内容概要\"]},\"619\":{\"title\":\"Actor-Critic算法简介\",\"titles\":[\"Actor-Critic算法\",\"重点内容\"]},\"620\":{\"title\":\"重点内容提取\",\"titles\":[\"强化学习的独特性\"]},\"621\":{\"title\":\"核心观点总结\",\"titles\":[\"策略迭代算法\"]},\"622\":{\"title\":\"梯度裁剪（Clip Gradients）\",\"titles\":[\"深度学习中的显存优化与梯度处理方法\",\"主要内容\"]},\"623\":{\"title\":\"重要性采样技术\",\"titles\":[\"PPO算法\",\"重点段落\"]},\"624\":{\"title\":\"贝尔曼方程\",\"titles\":[]},\"625\":{\"title\":\"💡启发点\",\"titles\":[\"混合精度训练\"]},\"626\":{\"title\":\"重点段落\",\"titles\":[\"预训练评估2\",\"概率探针\"]},\"627\":{\"title\":\"常见错误警告\",\"titles\":[\"训练容灾及训练监控\"]},\"628\":{\"title\":\"思考板块 [思考]\",\"titles\":[\"数据爬取\"]},\"629\":{\"title\":\"📈 趋势预测\",\"titles\":[\"大模型结构与混合专家（LLM & MoE）解析\"]},\"630\":{\"title\":\"常见错误 ⚠️\",\"titles\":[\"深度解析语言模型采样方法：Top-K、Top-P、Temperature及综合策略\"]},\"631\":{\"title\":\"[思考] 延伸问题\",\"titles\":[\"使用Byte Pair Encoding (BPE)优化子词分词的技巧与实践\"]},\"632\":{\"title\":\"思考板块\",\"titles\":[\"数据多样性与模型优化探索\"]},\"633\":{\"title\":\"📈趋势预测\",\"titles\":[\"数据配比与训练顺序优化指南\"]},\"634\":{\"title\":\"💡启发点\",\"titles\":[\"继续预训练\"]},\"635\":{\"title\":\"[思考] 延伸问题\",\"titles\":[\"预训练定义以及数据来源\"]},\"636\":{\"title\":\"工作原理\",\"titles\":[\"Prompt Tech 提示技术\"]},\"637\":{\"title\":\"操作步骤\",\"titles\":[\"PPO训练的trick和问题\"]},\"638\":{\"title\":\"内容概述\",\"titles\":[\"SARSA-λ与Q-learning对比\"]},\"639\":{\"title\":\"强化学习的流程\",\"titles\":[\"强化学习问题,流程\"]},\"640\":{\"title\":\"Q-learning的更新方式\",\"titles\":[\"深度Q网络\"]},\"641\":{\"title\":\"元数据\",\"titles\":[\"蒙特卡洛方法\"]},\"642\":{\"title\":\"马尔可夫决策过程\",\"titles\":[]},\"643\":{\"title\":\"技术术语转述\",\"titles\":[\"时序差分算法\"]},\"644\":{\"title\":\"✅ 操作步骤\",\"titles\":[\"模型打分与数据去重\",\"数据去重流程\"]},\"645\":{\"title\":\"行动清单\",\"titles\":[\"常用分词库\"]},\"646\":{\"title\":\"重点段落\",\"titles\":[\"SARSA算法\",\"核心观点\"]},\"647\":{\"title\":\"重点段落\",\"titles\":[\"价值迭代算法\",\"内容处理\"]},\"648\":{\"title\":\"📈趋势预测\",\"titles\":[\"推理耗时\"]},\"649\":{\"title\":\"关键步骤\",\"titles\":[\"RL在NLP场景下的拓展\",\"重点段落\"]},\"650\":{\"title\":\"📈 趋势预测\",\"titles\":[\"数据清洗\"]},\"651\":{\"title\":\"操作步骤\",\"titles\":[\"预训练评估\"]},\"652\":{\"title\":\"核心观点\",\"titles\":[\"策略梯度算法\"]},\"653\":{\"title\":\"以采样策略和更新策略划分\",\"titles\":[\"强化学习分类\",\"内容概要\"]},\"654\":{\"title\":\"其他指导策略更新的方法\",\"titles\":[\"Actor-Critic算法\",\"重点内容\"]},\"655\":{\"title\":\"1. 优化目标的核心区别\",\"titles\":[\"强化学习的独特性\",\"重点内容提取\"]},\"656\":{\"title\":\"重点段落\",\"titles\":[\"策略迭代算法\"]},\"657\":{\"title\":\"常见错误与注意事项\",\"titles\":[\"深度学习中的显存优化与梯度处理方法\",\"主要内容\"]},\"658\":{\"title\":\"策略截断与稳定性\",\"titles\":[\"PPO算法\",\"重点段落\"]},\"659\":{\"title\":\"元数据\",\"titles\":[\"贝尔曼方程\"]},\"660\":{\"title\":\"[思考]\",\"titles\":[\"混合精度训练\"]},\"661\":{\"title\":\"续写能力\",\"titles\":[\"预训练评估2\"]},\"662\":{\"title\":\"行动清单\",\"titles\":[\"训练容灾及训练监控\"]},\"663\":{\"title\":\"行动清单\",\"titles\":[\"数据爬取\"]},\"664\":{\"title\":\"💡 启发点\",\"titles\":[\"大模型结构与混合专家（LLM & MoE）解析\"]},\"665\":{\"title\":\"💡启发点\",\"titles\":[\"深度解析语言模型采样方法：Top-K、Top-P、Temperature及综合策略\"]},\"666\":{\"title\":\"行动清单\",\"titles\":[\"数据多样性与模型优化探索\"]},\"667\":{\"title\":\"后续追踪\",\"titles\":[\"数据配比与训练顺序优化指南\"]},\"668\":{\"title\":\"行动清单\",\"titles\":[\"继续预训练\"]},\"669\":{\"title\":\"行动清单\",\"titles\":[\"预训练定义以及数据来源\"]},\"670\":{\"title\":\"提示词和示例\",\"titles\":[\"Prompt Tech 提示技术\",\"工作原理\"]},\"671\":{\"title\":\"常见错误\",\"titles\":[\"PPO训练的trick和问题\"]},\"672\":{\"title\":\"SARSA-λ算法\",\"titles\":[\"SARSA-λ与Q-learning对比\",\"内容概述\"]},\"673\":{\"title\":\"常见错误\",\"titles\":[\"强化学习问题,流程\"]},\"674\":{\"title\":\"DQN的重要改进\",\"titles\":[\"深度Q网络\"]},\"675\":{\"title\":\"内容概述\",\"titles\":[\"蒙特卡洛方法\"]},\"676\":{\"title\":\"🚀 核心观点\",\"titles\":[\"马尔可夫决策过程\"]},\"677\":{\"title\":\"Knowledge Distillation 知识蒸馏\",\"titles\":[]},\"678\":{\"title\":\"常见错误警告\",\"titles\":[\"时序差分算法\"]},\"679\":{\"title\":\"常见错误与注意事项\",\"titles\":[\"模型打分与数据去重\"]},\"680\":{\"title\":\"📈 趋势预测\",\"titles\":[\"常用分词库\"]},\"681\":{\"title\":\"操作步骤\",\"titles\":[\"SARSA算法\",\"核心观点\"]},\"682\":{\"title\":\"Low-Rank Factorization 低秩分解\",\"titles\":[]},\"683\":{\"title\":\"后续追踪\",\"titles\":[\"推理耗时\"]},\"684\":{\"title\":\"常见错误\",\"titles\":[\"RL在NLP场景下的拓展\"]},\"685\":{\"title\":\"[思考]板块\",\"titles\":[\"数据清洗\"]},\"686\":{\"title\":\"常见错误\",\"titles\":[\"预训练评估\"]},\"687\":{\"title\":\"重点段落\",\"titles\":[\"策略梯度算法\"]},\"688\":{\"title\":\"以需不需要环境动态划分\",\"titles\":[\"强化学习分类\",\"内容概要\"]},\"689\":{\"title\":\"常见错误\",\"titles\":[\"Actor-Critic算法\"]},\"690\":{\"title\":\"2. 数据类型与来源\",\"titles\":[\"强化学习的独特性\",\"重点内容提取\"]},\"691\":{\"title\":\"常见错误\",\"titles\":[\"策略迭代算法\"]},\"692\":{\"title\":\"介绍\",\"titles\":[]},\"693\":{\"title\":\"模型剪枝\",\"titles\":[]},\"694\":{\"title\":\"[思考] 板块\",\"titles\":[\"深度学习中的显存优化与梯度处理方法\"]},\"695\":{\"title\":\"操作步骤\",\"titles\":[\"PPO算法\"]},\"696\":{\"title\":\"内容处理\",\"titles\":[\"贝尔曼方程\"]},\"697\":{\"title\":\"模型量化\",\"titles\":[]},\"698\":{\"title\":\"行动清单\",\"titles\":[\"混合精度训练\"]},\"699\":{\"title\":\"核心观点\",\"titles\":[\"预训练评估2\",\"续写能力\"]},\"700\":{\"title\":\"📈 趋势预测\",\"titles\":[\"训练容灾及训练监控\"]},\"701\":{\"title\":\"📈趋势预测\",\"titles\":[\"数据爬取\"]},\"702\":{\"title\":\"[思考] 延伸问题\",\"titles\":[\"大模型结构与混合专家（LLM & MoE）解析\"]},\"703\":{\"title\":\"📈趋势预测\",\"titles\":[\"深度解析语言模型采样方法：Top-K、Top-P、Temperature及综合策略\"]},\"704\":{\"title\":\"后续追踪计划\",\"titles\":[\"数据多样性与模型优化探索\"]},\"705\":{\"title\":\"[思考]板块\",\"titles\":[\"数据配比与训练顺序优化指南\"]},\"706\":{\"title\":\"📈趋势预测\",\"titles\":[\"继续预训练\"]},\"707\":{\"title\":\"后续追踪\",\"titles\":[\"预训练定义以及数据来源\"]},\"708\":{\"title\":\"上下文提供\",\"titles\":[\"Prompt Tech 提示技术\",\"工作原理\"]},\"709\":{\"title\":\"行动清单\",\"titles\":[\"PPO训练的trick和问题\"]},\"710\":{\"title\":\"Q-learning算法\",\"titles\":[\"SARSA-λ与Q-learning对比\",\"内容概述\"]},\"711\":{\"title\":\"💡 启发点\",\"titles\":[\"强化学习问题,流程\"]},\"712\":{\"title\":\"Repaly Buffer（经验回放）\",\"titles\":[\"深度Q网络\",\"DQN的重要改进\"]},\"713\":{\"title\":\"核心观点\",\"titles\":[\"蒙特卡洛方法\"]},\"714\":{\"title\":\"📊 重点段落\",\"titles\":[\"马尔可夫决策过程\"]},\"715\":{\"title\":\"知识蒸馏的基本组成部分\",\"titles\":[\"Knowledge Distillation 知识蒸馏\"]},\"716\":{\"title\":\"PageAttention原理\",\"titles\":[]},\"717\":{\"title\":\"💡启发点\",\"titles\":[\"时序差分算法\"]},\"718\":{\"title\":\"⚠ 警告区块\",\"titles\":[\"模型打分与数据去重\",\"常见错误与注意事项\"]},\"719\":{\"title\":\"[思考] 延伸问题\",\"titles\":[\"常用分词库\"]},\"720\":{\"title\":\"常见错误\",\"titles\":[\"SARSA算法\",\"核心观点\"]},\"721\":{\"title\":\"💡启发点\",\"titles\":[\"RL在NLP场景下的拓展\"]},\"722\":{\"title\":\"💡启发点\",\"titles\":[\"预训练评估\"]},\"723\":{\"title\":\"策略梯度算法\",\"titles\":[\"策略梯度算法\",\"重点段落\"]},\"724\":{\"title\":\"以如何学习策略划分\",\"titles\":[\"强化学习分类\",\"内容概要\"]},\"725\":{\"title\":\"💡启发点\",\"titles\":[\"Actor-Critic算法\"]},\"726\":{\"title\":\"3. 学习方式的差异\",\"titles\":[\"强化学习的独特性\",\"重点内容提取\"]},\"727\":{\"title\":\"个人见解 [思考]\",\"titles\":[\"策略迭代算法\"]},\"728\":{\"title\":\"模型变得越来越大\",\"titles\":[\"介绍\"]},\"729\":{\"title\":\"模型量化与剪枝的区别\",\"titles\":[\"模型剪枝\"]},\"730\":{\"title\":\"行动清单\",\"titles\":[\"深度学习中的显存优化与梯度处理方法\"]},\"731\":{\"title\":\"常见错误\",\"titles\":[\"PPO算法\"]},\"732\":{\"title\":\"贝尔曼期望方程\",\"titles\":[\"贝尔曼方程\",\"内容处理\"]},\"733\":{\"title\":\"模型量化\",\"titles\":[\"模型量化\"]},\"734\":{\"title\":\"后续追踪\",\"titles\":[\"混合精度训练\"]},\"735\":{\"title\":\"重点段落\",\"titles\":[\"预训练评估2\",\"续写能力\"]},\"736\":{\"title\":\"[思考] 延伸问题\",\"titles\":[\"训练容灾及训练监控\"]},\"737\":{\"title\":\"后续追踪\",\"titles\":[\"数据爬取\"]},\"738\":{\"title\":\"行动清单\",\"titles\":[\"大模型结构与混合专家（LLM & MoE）解析\"]},\"739\":{\"title\":\"行动清单\",\"titles\":[\"深度解析语言模型采样方法：Top-K、Top-P、Temperature及综合策略\"]},\"740\":{\"title\":\"后续追踪\",\"titles\":[\"继续预训练\"]},\"741\":{\"title\":\"数据资源概览\",\"titles\":[\"预训练定义以及数据来源\"]},\"742\":{\"title\":\"推理和生成\",\"titles\":[\"Prompt Tech 提示技术\",\"工作原理\"]},\"743\":{\"title\":\"PPO优化与对齐税影响分析\",\"titles\":[]},\"744\":{\"title\":\"算法流程\",\"titles\":[\"SARSA-λ与Q-learning对比\",\"内容概述\"]},\"745\":{\"title\":\"📈 趋势预测\",\"titles\":[\"强化学习问题,流程\"]},\"746\":{\"title\":\"Target Network（目标网络）\",\"titles\":[\"深度Q网络\",\"DQN的重要改进\"]},\"747\":{\"title\":\"重点段落\",\"titles\":[\"蒙特卡洛方法\"]},\"748\":{\"title\":\"状态价值函数\",\"titles\":[\"马尔可夫决策过程\",\"📊 重点段落\"]},\"749\":{\"title\":\"白盒知识蒸馏\",\"titles\":[]},\"750\":{\"title\":\"核心机制\",\"titles\":[\"PageAttention原理\"]},\"751\":{\"title\":\"大模型的packing技巧\",\"titles\":[]},\"752\":{\"title\":\"行动清单\",\"titles\":[\"时序差分算法\"]},\"753\":{\"title\":\"📈 趋势预测\",\"titles\":[\"模型打分与数据去重\"]},\"754\":{\"title\":\"思考\",\"titles\":[\"SARSA算法\"]},\"755\":{\"title\":\"行动清单\",\"titles\":[\"RL在NLP场景下的拓展\"]},\"756\":{\"title\":\"行动清单\",\"titles\":[\"预训练评估\"]},\"757\":{\"title\":\"REINFORCE算法\",\"titles\":[\"策略梯度算法\",\"重点段落\"]},\"758\":{\"title\":\"常见错误\",\"titles\":[\"强化学习分类\"]},\"759\":{\"title\":\"行动清单\",\"titles\":[\"Actor-Critic算法\"]},\"760\":{\"title\":\"4. 智能体的作用\",\"titles\":[\"强化学习的独特性\",\"重点内容提取\"]},\"761\":{\"title\":\"行动清单\",\"titles\":[\"策略迭代算法\"]},\"762\":{\"title\":\"半径为k的子数组平均值\",\"titles\":[]},\"763\":{\"title\":\"需要一些大模型压缩技术\",\"titles\":[\"介绍\"]},\"764\":{\"title\":\"剪枝流程\",\"titles\":[\"模型剪枝\"]},\"765\":{\"title\":\"后续追踪\",\"titles\":[\"深度学习中的显存优化与梯度处理方法\"]},\"766\":{\"title\":\"💡启发点\",\"titles\":[\"PPO算法\"]},\"767\":{\"title\":\"最优策略与贝尔曼最优方程\",\"titles\":[\"贝尔曼方程\",\"内容处理\"]},\"768\":{\"title\":\"常用的数据类型\",\"titles\":[\"模型量化\"]},\"769\":{\"title\":\"大小为k平均值大于等于阈值的子数组个数\",\"titles\":[]},\"770\":{\"title\":\"思考\",\"titles\":[\"预训练评估2\"]},\"771\":{\"title\":\"[思考]延伸问题\",\"titles\":[\"深度解析语言模型采样方法：Top-K、Top-P、Temperature及综合策略\"]},\"772\":{\"title\":\"数据采样与分布策略\",\"titles\":[\"预训练定义以及数据来源\"]},\"773\":{\"title\":\"ICL形式化定义\",\"titles\":[\"Prompt Tech 提示技术\"]},\"774\":{\"title\":\"分类\",\"titles\":[\"PPO优化与对齐税影响分析\"]},\"775\":{\"title\":\"Q-learning算法流程：\",\"titles\":[\"SARSA-λ与Q-learning对比\",\"内容概述\",\"算法流程\"]},\"776\":{\"title\":\"[思考]板块\",\"titles\":[\"强化学习问题,流程\"]},\"777\":{\"title\":\"常见错误\",\"titles\":[\"深度Q网络\"]},\"778\":{\"title\":\"操作步骤\",\"titles\":[\"蒙特卡洛方法\"]},\"779\":{\"title\":\"动作价值函数\",\"titles\":[\"马尔可夫决策过程\",\"📊 重点段落\"]},\"780\":{\"title\":\"知识的类型\",\"titles\":[\"白盒知识蒸馏\"]},\"781\":{\"title\":\"不同解码策略下的用法\",\"titles\":[\"PageAttention原理\"]},\"782\":{\"title\":\"Why\",\"titles\":[\"大模型的packing技巧\"]},\"783\":{\"title\":\"定长子串中元音的最大数目\",\"titles\":[]},\"784\":{\"title\":\"📈趋势预测\",\"titles\":[\"时序差分算法\"]},\"785\":{\"title\":\"[思考] 延伸问题\",\"titles\":[\"模型打分与数据去重\"]},\"786\":{\"title\":\"💡启发点\",\"titles\":[\"SARSA算法\"]},\"787\":{\"title\":\"📈趋势预测\",\"titles\":[\"RL在NLP场景下的拓展\"]},\"788\":{\"title\":\"📈趋势预测\",\"titles\":[\"预训练评估\"]},\"789\":{\"title\":\"算法流程\",\"titles\":[\"策略梯度算法\",\"重点段落\"]},\"790\":{\"title\":\"💡启发点\",\"titles\":[\"强化学习分类\"]},\"791\":{\"title\":\"📈趋势预测\",\"titles\":[\"Actor-Critic算法\"]},\"792\":{\"title\":\"常见错误\",\"titles\":[\"强化学习的独特性\"]},\"793\":{\"title\":\"📈趋势预测\",\"titles\":[\"策略迭代算法\"]},\"794\":{\"title\":\"降低模型部署的成本\",\"titles\":[\"介绍\"]},\"795\":{\"title\":\"1. 先训练模型，然后剪枝，最后微调\",\"titles\":[\"模型剪枝\",\"剪枝流程\"]},\"796\":{\"title\":\"行动清单\",\"titles\":[\"PPO算法\"]},\"797\":{\"title\":\"思考\",\"titles\":[\"贝尔曼方程\"]},\"798\":{\"title\":\"FastText\",\"titles\":[]},\"799\":{\"title\":\"量化对象\",\"titles\":[\"模型量化\"]},\"800\":{\"title\":\"操作步骤\",\"titles\":[\"预训练评估2\"]},\"801\":{\"title\":\"Word2Vec\",\"titles\":[]},\"802\":{\"title\":\"oneHot\",\"titles\":[]},\"803\":{\"title\":\"数据分布比例\",\"titles\":[\"预训练定义以及数据来源\",\"数据采样与分布策略\"]},\"804\":{\"title\":\"ICL示例设计\",\"titles\":[\"Prompt Tech 提示技术\"]},\"805\":{\"title\":\"标签\",\"titles\":[\"PPO优化与对齐税影响分析\"]},\"806\":{\"title\":\"常见错误\",\"titles\":[\"SARSA-λ与Q-learning对比\",\"内容概述\"]},\"807\":{\"title\":\"行动清单\",\"titles\":[\"强化学习问题,流程\"]},\"808\":{\"title\":\"💡启发点\",\"titles\":[\"深度Q网络\"]},\"809\":{\"title\":\"常见错误\",\"titles\":[\"蒙特卡洛方法\"]},\"810\":{\"title\":\"策略与价值函数的关系\",\"titles\":[\"马尔可夫决策过程\",\"📊 重点段落\"]},\"811\":{\"title\":\"1. Response-based\",\"titles\":[\"白盒知识蒸馏\",\"知识的类型\"]},\"812\":{\"title\":\"prefill阶段\",\"titles\":[\"PageAttention原理\",\"不同解码策略下的用法\"]},\"813\":{\"title\":\"What\",\"titles\":[\"大模型的packing技巧\"]},\"814\":{\"title\":\"介绍\",\"titles\":[]},\"815\":{\"title\":\"后续追踪\",\"titles\":[\"时序差分算法\"]},\"816\":{\"title\":\"行动清单\",\"titles\":[\"模型打分与数据去重\"]},\"817\":{\"title\":\"行动清单\",\"titles\":[\"SARSA算法\"]},\"818\":{\"title\":\"后续追踪\",\"titles\":[\"RL在NLP场景下的拓展\"]},\"819\":{\"title\":\"后续追踪\",\"titles\":[\"预训练评估\"]},\"820\":{\"title\":\"代码示例\",\"titles\":[\"策略梯度算法\"]},\"821\":{\"title\":\"行动清单\",\"titles\":[\"强化学习分类\"]},\"822\":{\"title\":\"后续追踪\",\"titles\":[\"Actor-Critic算法\"]},\"823\":{\"title\":\"💡启发点\",\"titles\":[\"强化学习的独特性\"]},\"824\":{\"title\":\"后续追踪\",\"titles\":[\"策略迭代算法\"]},\"825\":{\"title\":\"提升模型的推理性能\",\"titles\":[\"介绍\"]},\"826\":{\"title\":\"2. 模型训练的过程中剪枝，然后微调\",\"titles\":[\"模型剪枝\",\"剪枝流程\"]},\"827\":{\"title\":\"BART\",\"titles\":[]},\"828\":{\"title\":\"RoBERTa\",\"titles\":[]},\"829\":{\"title\":\"📈趋势预测\",\"titles\":[\"PPO算法\"]},\"830\":{\"title\":\"T5\",\"titles\":[]},\"831\":{\"title\":\"操作步骤\",\"titles\":[\"贝尔曼方程\"]},\"832\":{\"title\":\"元数据\",\"titles\":[\"FastText\"]},\"833\":{\"title\":\"量化形式\",\"titles\":[]},\"834\":{\"title\":\"常见错误\",\"titles\":[\"预训练评估2\"]},\"835\":{\"title\":\"元数据\",\"titles\":[\"Word2Vec\"]},\"836\":{\"title\":\"元数据\",\"titles\":[\"oneHot\"]},\"837\":{\"title\":\"中文语料采样\",\"titles\":[\"预训练定义以及数据来源\",\"数据采样与分布策略\"]},\"838\":{\"title\":\"示例选择\",\"titles\":[\"Prompt Tech 提示技术\",\"ICL示例设计\"]},\"839\":{\"title\":\"日期\",\"titles\":[\"PPO优化与对齐税影响分析\"]},\"840\":{\"title\":\"代码示例\",\"titles\":[\"SARSA-λ与Q-learning对比\",\"内容概述\"]},\"841\":{\"title\":\"后续追踪\",\"titles\":[\"强化学习问题,流程\"]},\"842\":{\"title\":\"行动清单\",\"titles\":[\"深度Q网络\"]},\"843\":{\"title\":\"代码示例\",\"titles\":[\"蒙特卡洛方法\"]},\"844\":{\"title\":\"✅ 操作步骤\",\"titles\":[\"马尔可夫决策过程\"]},\"845\":{\"title\":\"2. Feature-based\",\"titles\":[\"白盒知识蒸馏\",\"知识的类型\"]},\"846\":{\"title\":\"decode阶段\",\"titles\":[\"PageAttention原理\",\"不同解码策略下的用法\"]},\"847\":{\"title\":\"5.7.1 预训练阶段\",\"titles\":[\"大模型的packing技巧\",\"What\"]},\"848\":{\"title\":\"元数据\",\"titles\":[\"介绍\"]},\"849\":{\"title\":\"介绍\",\"titles\":[]},\"850\":{\"title\":\"[思考]板块\",\"titles\":[\"时序差分算法\"]},\"851\":{\"title\":\"后续追踪\",\"titles\":[\"模型打分与数据去重\"]},\"852\":{\"title\":\"📈趋势预测\",\"titles\":[\"SARSA算法\"]},\"853\":{\"title\":\"GLM1\",\"titles\":[]},\"854\":{\"title\":\"GLM2\",\"titles\":[]},\"855\":{\"title\":\"GLM3\",\"titles\":[]},\"856\":{\"title\":\"常见错误\",\"titles\":[\"策略梯度算法\"]},\"857\":{\"title\":\"📈趋势预测\",\"titles\":[\"强化学习分类\"]},\"858\":{\"title\":\"操作步骤\",\"titles\":[\"强化学习的独特性\"]},\"859\":{\"title\":\"GLM4\",\"titles\":[]},\"860\":{\"title\":\"3. 进行剪枝，然后从头训练剪枝的模型\",\"titles\":[\"模型剪枝\",\"剪枝流程\"]},\"861\":{\"title\":\"元数据\",\"titles\":[\"BART\"]},\"862\":{\"title\":\"元数据\",\"titles\":[\"RoBERTa\"]},\"863\":{\"title\":\"DeepSeek-R1\",\"titles\":[]},\"864\":{\"title\":\"后续追踪\",\"titles\":[\"PPO算法\"]},\"865\":{\"title\":\"元数据\",\"titles\":[\"T5\"]},\"866\":{\"title\":\"常见错误\",\"titles\":[\"贝尔曼方程\"]},\"867\":{\"title\":\"FastText算法核心概述\",\"titles\":[\"FastText\"]},\"868\":{\"title\":\"根据量化数据表示的原始数据范围是否均匀，可以将量化方法分为线性量化和非线性量化\",\"titles\":[\"量化形式\"]},\"869\":{\"title\":\"💡启发点\",\"titles\":[\"预训练评估2\"]},\"870\":{\"title\":\"什么是Word2Vec？\",\"titles\":[\"Word2Vec\"]},\"871\":{\"title\":\"什么是独热编码（OneHot Encoding）？\",\"titles\":[\"oneHot\"]},\"872\":{\"title\":\"DeepSeek-V2\",\"titles\":[]},\"873\":{\"title\":\"英文语料采样\",\"titles\":[\"预训练定义以及数据来源\",\"数据采样与分布策略\"]},\"874\":{\"title\":\"启发式方法\",\"titles\":[\"Prompt Tech 提示技术\",\"ICL示例设计\",\"示例选择\"]},\"875\":{\"title\":\"内容概述\",\"titles\":[\"PPO优化与对齐税影响分析\"]},\"876\":{\"title\":\"思考\",\"titles\":[\"SARSA-λ与Q-learning对比\"]},\"877\":{\"title\":\"📈趋势预测\",\"titles\":[\"深度Q网络\"]},\"878\":{\"title\":\"💡启发点\",\"titles\":[\"蒙特卡洛方法\"]},\"879\":{\"title\":\"⚠ 常见错误\",\"titles\":[\"马尔可夫决策过程\"]},\"880\":{\"title\":\"3. Relation-based\",\"titles\":[\"白盒知识蒸馏\",\"知识的类型\"]},\"881\":{\"title\":\"5.7.2 微调阶段\",\"titles\":[\"大模型的packing技巧\",\"What\"]},\"882\":{\"title\":\"1. 什么是词嵌入（Embedding）？\",\"titles\":[\"介绍\"]},\"883\":{\"title\":\"元数据\",\"titles\":[\"介绍\"]},\"884\":{\"title\":\"DeepSeek-V3\",\"titles\":[]},\"885\":{\"title\":\"Deepseek-V1\",\"titles\":[]},\"886\":{\"title\":\"后续追踪\",\"titles\":[\"SARSA算法\"]},\"887\":{\"title\":\"元数据\",\"titles\":[\"GLM1\"]},\"888\":{\"title\":\"Deepseek-math\",\"titles\":[]},\"889\":{\"title\":\"模型结构概述\",\"titles\":[\"GLM2\"]},\"890\":{\"title\":\"元数据\",\"titles\":[\"GLM3\"]},\"891\":{\"title\":\"💡启发点\",\"titles\":[\"策略梯度算法\"]},\"892\":{\"title\":\"后续追踪\",\"titles\":[\"强化学习分类\"]},\"893\":{\"title\":\"📈趋势预测\",\"titles\":[\"强化学习的独特性\"]},\"894\":{\"title\":\"模型结构\",\"titles\":[\"GLM4\"]},\"895\":{\"title\":\"GPT-1\",\"titles\":[]},\"896\":{\"title\":\"7.2.3 剪枝分类\",\"titles\":[\"模型剪枝\"]},\"897\":{\"title\":\"内容概述\",\"titles\":[\"BART\"]},\"898\":{\"title\":\"内容简介\",\"titles\":[\"RoBERTa\"]},\"899\":{\"title\":\"元数据\",\"titles\":[\"DeepSeek-R1\"]},\"900\":{\"title\":\"GPT-2\",\"titles\":[]},\"901\":{\"title\":\"内容概述\",\"titles\":[\"T5\"]},\"902\":{\"title\":\"行动清单\",\"titles\":[\"贝尔曼方程\"]},\"903\":{\"title\":\"技术细节与优化点\",\"titles\":[\"FastText\"]},\"904\":{\"title\":\"根据 sss 和 zzz 的共享范围即量化粒度，量化方法可以进行以下分类\",\"titles\":[\"量化形式\"]},\"905\":{\"title\":\"行动清单\",\"titles\":[\"预训练评估2\"]},\"906\":{\"title\":\"Word2Vec的加速方法\",\"titles\":[\"Word2Vec\"]},\"907\":{\"title\":\"优缺点分析\",\"titles\":[\"oneHot\"]},\"908\":{\"title\":\"元数据\",\"titles\":[\"DeepSeek-V2\"]},\"909\":{\"title\":\"Code语料采样\",\"titles\":[\"预训练定义以及数据来源\",\"数据采样与分布策略\"]},\"910\":{\"title\":\"基于语义相似度\",\"titles\":[\"Prompt Tech 提示技术\",\"ICL示例设计\",\"示例选择\",\"启发式方法\"]},\"911\":{\"title\":\"核心观点\",\"titles\":[\"PPO优化与对齐税影响分析\"]},\"912\":{\"title\":\"行动清单\",\"titles\":[\"SARSA-λ与Q-learning对比\"]},\"913\":{\"title\":\"后续追踪\",\"titles\":[\"深度Q网络\"]},\"914\":{\"title\":\"行动清单\",\"titles\":[\"蒙特卡洛方法\"]},\"915\":{\"title\":\"💡 启发点\",\"titles\":[\"马尔可夫决策过程\"]},\"916\":{\"title\":\"蒸馏的方法\",\"titles\":[\"白盒知识蒸馏\"]},\"917\":{\"title\":\"咱们来看看 Llama Factory 是如何优化的\",\"titles\":[\"大模型的packing技巧\"]},\"918\":{\"title\":\"核心特性\",\"titles\":[\"介绍\",\"1. 什么是词嵌入（Embedding）？\"]},\"919\":{\"title\":\"内容处理\",\"titles\":[\"介绍\"]},\"920\":{\"title\":\"元数据\",\"titles\":[\"DeepSeek-V3\"]},\"921\":{\"title\":\"GPT-3\",\"titles\":[]},\"922\":{\"title\":\"元数据\",\"titles\":[\"Deepseek-V1\"]},\"923\":{\"title\":\"内容概述\",\"titles\":[\"GLM1\"]},\"924\":{\"title\":\"分类：自动推断\",\"titles\":[\"Deepseek-math\"]},\"925\":{\"title\":\"训练目标\",\"titles\":[\"GLM2\"]},\"926\":{\"title\":\"内容概述\",\"titles\":[\"GLM3\"]},\"927\":{\"title\":\"📈趋势预测\",\"titles\":[\"策略梯度算法\"]},\"928\":{\"title\":\"行动清单\",\"titles\":[\"强化学习的独特性\"]},\"929\":{\"title\":\"预训练数据处理\",\"titles\":[\"GLM4\"]},\"930\":{\"title\":\"元数据\",\"titles\":[\"GPT-1\"]},\"931\":{\"title\":\"非结构化剪枝\",\"titles\":[\"模型剪枝\",\"7.2.3 剪枝分类\"]},\"932\":{\"title\":\"核心观点\",\"titles\":[\"BART\",\"内容概述\"]},\"933\":{\"title\":\"核心观点\",\"titles\":[\"RoBERTa\"]},\"934\":{\"title\":\"内容概述\",\"titles\":[\"DeepSeek-R1\"]},\"935\":{\"title\":\"元数据\",\"titles\":[\"GPT-2\"]},\"936\":{\"title\":\"关键点\",\"titles\":[\"T5\"]},\"937\":{\"title\":\"📈趋势预测\",\"titles\":[\"贝尔曼方程\"]},\"938\":{\"title\":\"✅ 模型结构与输入输出\",\"titles\":[\"FastText\",\"技术细节与优化点\"]},\"939\":{\"title\":\"逐层量化 per-tensor\",\"titles\":[\"量化形式\",\"根据 sss 和 zzz 的共享范围即量化粒度，量化方法可以进行以下分类\"]},\"940\":{\"title\":\"📈趋势预测\",\"titles\":[\"预训练评估2\"]},\"941\":{\"title\":\"Hierarchical Softmax（霍夫曼树）\",\"titles\":[\"Word2Vec\",\"Word2Vec的加速方法\"]},\"942\":{\"title\":\"LLaMA1\",\"titles\":[]},\"943\":{\"title\":\"✅ 优点\",\"titles\":[\"oneHot\",\"优缺点分析\"]},\"944\":{\"title\":\"LLama 2\",\"titles\":[]},\"945\":{\"title\":\"LLama 3\",\"titles\":[]},\"946\":{\"title\":\"GShard\",\"titles\":[]},\"947\":{\"title\":\"内容处理\",\"titles\":[\"DeepSeek-V2\"]},\"948\":{\"title\":\"Mistral\",\"titles\":[]},\"949\":{\"title\":\"基于多样性\",\"titles\":[\"Prompt Tech 提示技术\",\"ICL示例设计\",\"示例选择\"]},\"950\":{\"title\":\"重点段落\",\"titles\":[\"PPO优化与对齐税影响分析\"]},\"951\":{\"title\":\"后续追踪\",\"titles\":[\"SARSA-λ与Q-learning对比\"]},\"952\":{\"title\":\"📈趋势预测\",\"titles\":[\"蒙特卡洛方法\"]},\"953\":{\"title\":\"📈 趋势预测\",\"titles\":[\"马尔可夫决策过程\"]},\"954\":{\"title\":\"1. Offline distillation\",\"titles\":[\"白盒知识蒸馏\",\"蒸馏的方法\"]},\"955\":{\"title\":\"2. Embedding 的实现与工作机制\",\"titles\":[\"介绍\"]},\"956\":{\"title\":\"BERT Embedding\",\"titles\":[\"介绍\",\"内容处理\"]},\"957\":{\"title\":\"核心架构演进\",\"titles\":[\"DeepSeek-V3\"]},\"958\":{\"title\":\"分类\",\"titles\":[\"GPT-3\"]},\"959\":{\"title\":\"Switch Transformer\",\"titles\":[]},\"960\":{\"title\":\"内容概述\",\"titles\":[\"Deepseek-V1\"]},\"961\":{\"title\":\"模型结构与创新点\",\"titles\":[\"GLM1\",\"内容概述\"]},\"962\":{\"title\":\"标签：数学预训练、强化学习、数据处理、DeepSeek\",\"titles\":[\"Deepseek-math\"]},\"963\":{\"title\":\"解码器架构的选择\",\"titles\":[\"GLM2\"]},\"964\":{\"title\":\"主要优化点\",\"titles\":[\"GLM3\"]},\"965\":{\"title\":\"[思考]\",\"titles\":[\"策略梯度算法\"]},\"966\":{\"title\":\"[思考]板块\",\"titles\":[\"强化学习的独特性\"]},\"967\":{\"title\":\"对齐训练技术\",\"titles\":[\"GLM4\"]},\"968\":{\"title\":\"内容摘要\",\"titles\":[\"GPT-1\"]},\"969\":{\"title\":\"优点\",\"titles\":[\"模型剪枝\",\"7.2.3 剪枝分类\",\"非结构化剪枝\"]},\"970\":{\"title\":\"技术术语简化\",\"titles\":[\"BART\",\"内容概述\"]},\"971\":{\"title\":\"重点段落\",\"titles\":[\"RoBERTa\"]},\"972\":{\"title\":\"研究背景与内容\",\"titles\":[\"DeepSeek-R1\"]},\"973\":{\"title\":\"PLaM\",\"titles\":[]},\"974\":{\"title\":\"PLaM2\",\"titles\":[]},\"975\":{\"title\":\"内容概述\",\"titles\":[\"GPT-2\"]},\"976\":{\"title\":\"Qwen1\",\"titles\":[]},\"977\":{\"title\":\"Qwen2.5\",\"titles\":[]},\"978\":{\"title\":\"T5模型的核心思想\",\"titles\":[\"T5\",\"关键点\"]},\"979\":{\"title\":\"后续追踪\",\"titles\":[\"贝尔曼方程\"]},\"980\":{\"title\":\"✅ 损失函数与分层Softmax\",\"titles\":[\"FastText\",\"技术细节与优化点\"]},\"981\":{\"title\":\"逐通道量化 per-token &amp; per-channel\",\"titles\":[\"量化形式\",\"根据 sss 和 zzz 的共享范围即量化粒度，量化方法可以进行以下分类\"]},\"982\":{\"title\":\"后续追踪\",\"titles\":[\"预训练评估2\"]},\"983\":{\"title\":\"Negative Sampling（负采样）\",\"titles\":[\"Word2Vec\",\"Word2Vec的加速方法\"]},\"984\":{\"title\":\"分类：机器学习模型\",\"titles\":[\"LLaMA1\"]},\"985\":{\"title\":\"⚠️ 缺点\",\"titles\":[\"oneHot\",\"优缺点分析\"]},\"986\":{\"title\":\"元数据\",\"titles\":[\"LLama 2\"]},\"987\":{\"title\":\"元数据\",\"titles\":[\"LLama 3\"]},\"988\":{\"title\":\"元数据\",\"titles\":[\"GShard\"]},\"989\":{\"title\":\"核心观点总结\",\"titles\":[\"DeepSeek-V2\",\"内容处理\"]},\"990\":{\"title\":\"元数据\",\"titles\":[\"Mistral\"]},\"991\":{\"title\":\"LLM-based方法\",\"titles\":[\"Prompt Tech 提示技术\",\"ICL示例设计\",\"示例选择\"]},\"992\":{\"title\":\"PPO-ptx优化目标\",\"titles\":[\"PPO优化与对齐税影响分析\",\"重点段落\"]},\"993\":{\"title\":\"后续追踪\",\"titles\":[\"蒙特卡洛方法\"]},\"994\":{\"title\":\"[思考] 板块\",\"titles\":[\"马尔可夫决策过程\"]},\"995\":{\"title\":\"2. Online distillation\",\"titles\":[\"白盒知识蒸馏\",\"蒸馏的方法\"]},\"996\":{\"title\":\"2.1 PyTorch 实现\",\"titles\":[\"介绍\",\"2. Embedding 的实现与工作机制\"]},\"997\":{\"title\":\"Masked LM (MLM)\",\"titles\":[\"介绍\",\"内容处理\"]},\"998\":{\"title\":\"混合专家系统革新\",\"titles\":[\"DeepSeek-V3\",\"核心架构演进\"]},\"999\":{\"title\":\"标签\",\"titles\":[\"GPT-3\"]},\"1000\":{\"title\":\"元数据\",\"titles\":[\"Switch Transformer\"]},\"1001\":{\"title\":\"Qwen2\",\"titles\":[]},\"1002\":{\"title\":\"模型结构\",\"titles\":[\"Deepseek-V1\"]},\"1003\":{\"title\":\"DeBERTa的相对位置编码与绝对位置编码解析\",\"titles\":[]},\"1004\":{\"title\":\"自回归填空任务\",\"titles\":[\"GLM1\",\"内容概述\"]},\"1005\":{\"title\":\"日期：2025年4月12日\",\"titles\":[\"Deepseek-math\"]},\"1006\":{\"title\":\"为什么选择 Decoder-only 架构？\",\"titles\":[\"GLM2\",\"解码器架构的选择\"]},\"1007\":{\"title\":\"词表大小调整\",\"titles\":[\"GLM3\",\"主要优化点\"]},\"1008\":{\"title\":\"ChatGLM技术创新\",\"titles\":[\"GLM4\"]},\"1009\":{\"title\":\"模型结构\",\"titles\":[\"GPT-1\"]},\"1010\":{\"title\":\"缺点\",\"titles\":[\"模型剪枝\",\"7.2.3 剪枝分类\",\"非结构化剪枝\"]},\"1011\":{\"title\":\"操作步骤\",\"titles\":[\"BART\"]},\"1012\":{\"title\":\"模型规模与算力\",\"titles\":[\"RoBERTa\",\"重点段落\"]},\"1013\":{\"title\":\"研究背景\",\"titles\":[\"DeepSeek-R1\",\"研究背景与内容\"]},\"1014\":{\"title\":\"分类\",\"titles\":[\"PLaM\"]},\"1015\":{\"title\":\"元数据\",\"titles\":[\"PLaM2\"]},\"1016\":{\"title\":\"重点内容\",\"titles\":[\"GPT-2\"]},\"1017\":{\"title\":\"元数据\",\"titles\":[\"Qwen1\"]},\"1018\":{\"title\":\"元数据\",\"titles\":[\"Qwen2.5\"]},\"1019\":{\"title\":\"任务与数据集\",\"titles\":[\"T5\",\"关键点\"]},\"1020\":{\"title\":\"T5模型与相对位置编码优化解析\",\"titles\":[]},\"1021\":{\"title\":\"✅ N-gram特征与优化点\",\"titles\":[\"FastText\",\"技术细节与优化点\"]},\"1022\":{\"title\":\"逐组量化 per-group\",\"titles\":[\"量化形式\",\"根据 sss 和 zzz 的共享范围即量化粒度，量化方法可以进行以下分类\"]},\"1023\":{\"title\":\"技术对比表格\",\"titles\":[\"Word2Vec\"]},\"1024\":{\"title\":\"标签：LLaMA1, 自监督学习, 机器学习, GPT, AdamW\",\"titles\":[\"LLaMA1\"]},\"1025\":{\"title\":\"示例代码：如何实现独热编码？\",\"titles\":[\"oneHot\"]},\"1026\":{\"title\":\"内容概要\",\"titles\":[\"LLama 2\"]},\"1027\":{\"title\":\"相对位置编码与XLNet位置编码详解 深入理解Transformer机制\",\"titles\":[]},\"1028\":{\"title\":\"内容概述\",\"titles\":[\"LLama 3\"]},\"1029\":{\"title\":\"内容处理\",\"titles\":[\"GShard\"]},\"1030\":{\"title\":\"重点段落提取\",\"titles\":[\"DeepSeek-V2\",\"内容处理\"]},\"1031\":{\"title\":\"核心观点总结\",\"titles\":[\"Mistral\"]},\"1032\":{\"title\":\"直接用LLM生成Demonstration\",\"titles\":[\"Prompt Tech 提示技术\",\"ICL示例设计\",\"示例选择\",\"LLM-based方法\"]},\"1033\":{\"title\":\"KL Reward系数设置\",\"titles\":[\"PPO优化与对齐税影响分析\",\"重点段落\"]},\"1034\":{\"title\":\"行动清单\",\"titles\":[\"马尔可夫决策过程\"]},\"1035\":{\"title\":\"3. Self-distillation\",\"titles\":[\"白盒知识蒸馏\",\"蒸馏的方法\"]},\"1036\":{\"title\":\"2.2 Embedding 的物理意义\",\"titles\":[\"介绍\",\"2. Embedding 的实现与工作机制\"]},\"1037\":{\"title\":\"Next Sentence Prediction (NSP)\",\"titles\":[\"介绍\",\"内容处理\"]},\"1038\":{\"title\":\"通信优化机制\",\"titles\":[\"DeepSeek-V3\",\"核心架构演进\"]},\"1039\":{\"title\":\"日期\",\"titles\":[\"GPT-3\"]},\"1040\":{\"title\":\"模型特点\",\"titles\":[\"Switch Transformer\"]},\"1041\":{\"title\":\"模型结构与创新\",\"titles\":[\"Qwen2\"]},\"1042\":{\"title\":\"BERT与RNN位置编码的对比与应用\",\"titles\":[]},\"1043\":{\"title\":\"训练过程\",\"titles\":[\"Deepseek-V1\"]},\"1044\":{\"title\":\"元数据\",\"titles\":[\"DeBERTa的相对位置编码与绝对位置编码解析\"]},\"1045\":{\"title\":\"二维位置编码技术\",\"titles\":[\"GLM1\",\"内容概述\"]},\"1046\":{\"title\":\"核心观点总结\",\"titles\":[\"Deepseek-math\"]},\"1047\":{\"title\":\"样本构建与损失计算\",\"titles\":[\"GLM2\",\"解码器架构的选择\"]},\"1048\":{\"title\":\"位置编码改进\",\"titles\":[\"GLM3\",\"主要优化点\"]},\"1049\":{\"title\":\"训练范式\",\"titles\":[\"GPT-1\"]},\"1050\":{\"title\":\"非结构化剪枝方法\",\"titles\":[\"模型剪枝\",\"7.2.3 剪枝分类\",\"非结构化剪枝\"]},\"1051\":{\"title\":\"常见错误\",\"titles\":[\"BART\"]},\"1052\":{\"title\":\"训练数据与方法\",\"titles\":[\"RoBERTa\",\"重点段落\"]},\"1053\":{\"title\":\"研究内容\",\"titles\":[\"DeepSeek-R1\",\"研究背景与内容\"]},\"1054\":{\"title\":\"Transformer绝对位置编码详解与改进分析\",\"titles\":[]},\"1055\":{\"title\":\"标签\",\"titles\":[\"PLaM\"]},\"1056\":{\"title\":\"监督微调与预训练的区别\",\"titles\":[]},\"1057\":{\"title\":\"内容概述\",\"titles\":[\"PLaM2\"]},\"1058\":{\"title\":\"训练Tokenizer\",\"titles\":[]},\"1059\":{\"title\":\"模型结构与训练范式\",\"titles\":[\"GPT-2\",\"重点内容\"]},\"1060\":{\"title\":\"核心观点总结\",\"titles\":[\"Qwen1\"]},\"1061\":{\"title\":\"核心观点总结\",\"titles\":[\"Qwen2.5\"]},\"1062\":{\"title\":\"模型训练方式\",\"titles\":[\"T5\",\"关键点\"]},\"1063\":{\"title\":\"元数据\",\"titles\":[\"T5模型与相对位置编码优化解析\"]},\"1064\":{\"title\":\"常见错误与解决方法\",\"titles\":[\"FastText\"]},\"1065\":{\"title\":\"Llama3 技术报告中提供的 tensor-wise 和 row-wise FP8 量化示意图\",\"titles\":[\"量化形式\"]},\"1066\":{\"title\":\"常见错误警告 ⚠️\",\"titles\":[\"Word2Vec\"]},\"1067\":{\"title\":\"日期：2025年4月12日\",\"titles\":[\"LLaMA1\"]},\"1068\":{\"title\":\"为什么需要独热编码？\",\"titles\":[\"oneHot\"]},\"1069\":{\"title\":\"模型结构改进\",\"titles\":[\"LLama 2\"]},\"1070\":{\"title\":\"元数据\",\"titles\":[\"相对位置编码与XLNet位置编码详解 深入理解Transformer机制\"]},\"1071\":{\"title\":\"模型结构\",\"titles\":[\"LLama 3\"]},\"1072\":{\"title\":\"核心观点总结\",\"titles\":[\"GShard\",\"内容处理\"]},\"1073\":{\"title\":\"通俗语言转述\",\"titles\":[\"DeepSeek-V2\",\"内容处理\"]},\"1074\":{\"title\":\"重点段落与数据\",\"titles\":[\"Mistral\"]},\"1075\":{\"title\":\"基于Prompt召回\",\"titles\":[\"Prompt Tech 提示技术\",\"ICL示例设计\",\"示例选择\",\"LLM-based方法\"]},\"1076\":{\"title\":\"预训练损失PTX Loss\",\"titles\":[\"PPO优化与对齐税影响分析\",\"重点段落\"]},\"1077\":{\"title\":\"后续追踪\",\"titles\":[\"马尔可夫决策过程\"]},\"1078\":{\"title\":\"黑盒知识蒸馏\",\"titles\":[]},\"1079\":{\"title\":\"3. 常见错误与注意事项\",\"titles\":[\"介绍\"]},\"1080\":{\"title\":\"常见错误\",\"titles\":[\"介绍\"]},\"1081\":{\"title\":\"多目标训练体系\",\"titles\":[\"DeepSeek-V3\"]},\"1082\":{\"title\":\"内容概述\",\"titles\":[\"GPT-3\"]},\"1083\":{\"title\":\"创新点\",\"titles\":[\"Switch Transformer\"]},\"1084\":{\"title\":\"模型训练与数据处理\",\"titles\":[\"Qwen2\"]},\"1085\":{\"title\":\"元数据\",\"titles\":[\"BERT与RNN位置编码的对比与应用\"]},\"1086\":{\"title\":\"预训练的Scaling Law\",\"titles\":[]},\"1087\":{\"title\":\"SFT训练\",\"titles\":[\"Deepseek-V1\",\"训练过程\"]},\"1088\":{\"title\":\"核心观点总结\",\"titles\":[\"DeBERTa的相对位置编码与绝对位置编码解析\"]},\"1089\":{\"title\":\"多任务预训练策略\",\"titles\":[\"GLM1\"]},\"1090\":{\"title\":\"重点段落与数据\",\"titles\":[\"Deepseek-math\"]},\"1091\":{\"title\":\"常见错误\",\"titles\":[\"GLM2\"]},\"1092\":{\"title\":\"前馈网络激活函数更改\",\"titles\":[\"GLM3\",\"主要优化点\"]},\"1093\":{\"title\":\"预训练\",\"titles\":[\"GPT-1\",\"训练范式\"]},\"1094\":{\"title\":\"结构化剪枝\",\"titles\":[\"模型剪枝\",\"7.2.3 剪枝分类\"]},\"1095\":{\"title\":\"💡启发点\",\"titles\":[\"BART\"]},\"1096\":{\"title\":\"文本编码与词汇表\",\"titles\":[\"RoBERTa\",\"重点段落\"]},\"1097\":{\"title\":\"研究贡献\",\"titles\":[\"DeepSeek-R1\"]},\"1098\":{\"title\":\"元数据\",\"titles\":[\"Transformer绝对位置编码详解与改进分析\"]},\"1099\":{\"title\":\"预训练策略\",\"titles\":[]},\"1100\":{\"title\":\"日期\",\"titles\":[\"PLaM\"]},\"1101\":{\"title\":\"元数据\",\"titles\":[\"监督微调与预训练的区别\"]},\"1102\":{\"title\":\"模型结构与预训练\",\"titles\":[\"PLaM2\",\"内容概述\"]},\"1103\":{\"title\":\"元数据\",\"titles\":[\"训练Tokenizer\"]},\"1104\":{\"title\":\"数据与实验\",\"titles\":[\"GPT-2\",\"重点内容\"]},\"1105\":{\"title\":\"重点段落\",\"titles\":[\"Qwen1\"]},\"1106\":{\"title\":\"重点段落\",\"titles\":[\"Qwen2.5\"]},\"1107\":{\"title\":\"操作步骤\",\"titles\":[\"T5\"]},\"1108\":{\"title\":\"核心观点总结\",\"titles\":[\"T5模型与相对位置编码优化解析\"]},\"1109\":{\"title\":\"⚠️ 常见错误：\",\"titles\":[\"FastText\",\"常见错误与解决方法\"]},\"1110\":{\"title\":\"量化分类\",\"titles\":[]},\"1111\":{\"title\":\"示例代码\",\"titles\":[\"Word2Vec\"]},\"1112\":{\"title\":\"模型结构改进\",\"titles\":[\"LLaMA1\"]},\"1113\":{\"title\":\"常见错误警告区块\",\"titles\":[\"oneHot\"]},\"1114\":{\"title\":\"训练数据策略\",\"titles\":[\"LLama 2\"]},\"1115\":{\"title\":\"高效深度学习模型训练框架选择与优化指南\",\"titles\":[]},\"1116\":{\"title\":\"内容处理\",\"titles\":[\"相对位置编码与XLNet位置编码详解 深入理解Transformer机制\"]},\"1117\":{\"title\":\"训练数据\",\"titles\":[\"LLama 3\"]},\"1118\":{\"title\":\"Agent评估框架汇总\",\"titles\":[]},\"1119\":{\"title\":\"重点段落提取\",\"titles\":[\"GShard\",\"内容处理\"]},\"1120\":{\"title\":\"操作步骤\",\"titles\":[\"DeepSeek-V2\"]},\"1121\":{\"title\":\"模型结构与工作原理\",\"titles\":[\"Mistral\",\"重点段落与数据\"]},\"1122\":{\"title\":\"基于主动学习/强化学习\",\"titles\":[\"Prompt Tech 提示技术\",\"ICL示例设计\",\"示例选择\"]},\"1123\":{\"title\":\"操作步骤\",\"titles\":[\"PPO优化与对齐税影响分析\"]},\"1124\":{\"title\":\"白盒知识蒸馏与黑盒知识蒸馏的区别\",\"titles\":[\"黑盒知识蒸馏\"]},\"1125\":{\"title\":\"5. 行动清单\",\"titles\":[\"介绍\"]},\"1126\":{\"title\":\"💡启发点\",\"titles\":[\"介绍\"]},\"1127\":{\"title\":\"多token预测(MTP)\",\"titles\":[\"DeepSeek-V3\",\"多目标训练体系\"]},\"1128\":{\"title\":\"模型结构与技术创新\",\"titles\":[\"GPT-3\"]},\"1129\":{\"title\":\"模型结构设计\",\"titles\":[\"Switch Transformer\"]},\"1130\":{\"title\":\"预训练阶段\",\"titles\":[\"Qwen2\",\"模型训练与数据处理\"]},\"1131\":{\"title\":\"核心观点总结\",\"titles\":[\"BERT与RNN位置编码的对比与应用\"]},\"1132\":{\"title\":\"核心观点总结\",\"titles\":[\"预训练的Scaling Law\"]},\"1133\":{\"title\":\"基于大模型的智能体原理\",\"titles\":[]},\"1134\":{\"title\":\"DPO训练\",\"titles\":[\"Deepseek-V1\",\"训练过程\"]},\"1135\":{\"title\":\"重点内容解析\",\"titles\":[\"DeBERTa的相对位置编码与绝对位置编码解析\"]},\"1136\":{\"title\":\"定义以及历史发展\",\"titles\":[]},\"1137\":{\"title\":\"操作步骤\",\"titles\":[\"GLM1\"]},\"1138\":{\"title\":\"训练数据与来源\",\"titles\":[\"Deepseek-math\",\"重点段落与数据\"]},\"1139\":{\"title\":\"智能体的分类\",\"titles\":[]},\"1140\":{\"title\":\"行动清单\",\"titles\":[\"GLM2\"]},\"1141\":{\"title\":\"操作步骤\",\"titles\":[\"GLM3\"]},\"1142\":{\"title\":\"微调\",\"titles\":[\"GPT-1\",\"训练范式\"]},\"1143\":{\"title\":\"结构化剪枝方法\",\"titles\":[\"模型剪枝\",\"7.2.3 剪枝分类\",\"结构化剪枝\"]},\"1144\":{\"title\":\"行动清单\",\"titles\":[\"BART\"]},\"1145\":{\"title\":\"操作步骤\",\"titles\":[\"RoBERTa\"]},\"1146\":{\"title\":\"强化学习在大模型上的应用\",\"titles\":[\"DeepSeek-R1\",\"研究贡献\"]},\"1147\":{\"title\":\"核心内容总结\",\"titles\":[\"Transformer绝对位置编码详解与改进分析\"]},\"1148\":{\"title\":\"元数据\",\"titles\":[\"预训练策略\"]},\"1149\":{\"title\":\"内容概述\",\"titles\":[\"PLaM\"]},\"1150\":{\"title\":\"核心观点总结\",\"titles\":[\"监督微调与预训练的区别\"]},\"1151\":{\"title\":\"智能体的框架和应用\",\"titles\":[]},\"1152\":{\"title\":\"Scaling Law 与优化\",\"titles\":[\"PLaM2\",\"内容概述\"]},\"1153\":{\"title\":\"核心内容总结\",\"titles\":[\"训练Tokenizer\"]},\"1154\":{\"title\":\"Zero-shot学习\",\"titles\":[\"GPT-2\",\"重点内容\"]},\"1155\":{\"title\":\"模型结构与创新之处\",\"titles\":[\"Qwen1\",\"重点段落\"]},\"1156\":{\"title\":\"模型系列与结构\",\"titles\":[\"Qwen2.5\",\"重点段落\"]},\"1157\":{\"title\":\"常见错误\",\"titles\":[\"T5\"]},\"1158\":{\"title\":\"重点内容提取\",\"titles\":[\"T5模型与相对位置编码优化解析\"]},\"1159\":{\"title\":\"❗️解决方法：\",\"titles\":[\"FastText\",\"常见错误与解决方法\"]},\"1160\":{\"title\":\"量化感知训练 Quantization Aware Training (QAT)\",\"titles\":[\"量化分类\"]},\"1161\":{\"title\":\"行动清单 ✅\",\"titles\":[\"Word2Vec\"]},\"1162\":{\"title\":\"训练方式\",\"titles\":[\"LLaMA1\"]},\"1163\":{\"title\":\"作者观点 vs 个人观点\",\"titles\":[\"oneHot\"]},\"1164\":{\"title\":\"拒绝采样方法\",\"titles\":[\"LLama 2\"]},\"1165\":{\"title\":\"元数据\",\"titles\":[\"高效深度学习模型训练框架选择与优化指南\"]},\"1166\":{\"title\":\"核心观点概述\",\"titles\":[\"相对位置编码与XLNet位置编码详解 深入理解Transformer机制\",\"内容处理\"]},\"1167\":{\"title\":\"数据过滤流程\",\"titles\":[\"LLama 3\",\"训练数据\"]},\"1168\":{\"title\":\"AgentBench\",\"titles\":[\"Agent评估框架汇总\"]},\"1169\":{\"title\":\"智能体系统分类\",\"titles\":[]},\"1170\":{\"title\":\"技术术语转述\",\"titles\":[\"GShard\",\"内容处理\"]},\"1171\":{\"title\":\"常见错误\",\"titles\":[\"DeepSeek-V2\"]},\"1172\":{\"title\":\"MOE并行训练\",\"titles\":[]},\"1173\":{\"title\":\"主动学习思路\",\"titles\":[\"Prompt Tech 提示技术\",\"ICL示例设计\",\"示例选择\",\"基于主动学习/强化学习\"]},\"1174\":{\"title\":\"常见错误\",\"titles\":[\"PPO优化与对齐税影响分析\"]},\"1175\":{\"title\":\"ICL：上下文少样本学习蒸馏\",\"titles\":[\"黑盒知识蒸馏\"]},\"1176\":{\"title\":\"6. [思考] 延伸问题\",\"titles\":[\"介绍\"]},\"1177\":{\"title\":\"行动清单\",\"titles\":[\"介绍\"]},\"1178\":{\"title\":\"性能对比\",\"titles\":[\"DeepSeek-V3\"]},\"1179\":{\"title\":\"Sparse Attention\",\"titles\":[\"GPT-3\",\"模型结构与技术创新\"]},\"1180\":{\"title\":\"负载均衡\",\"titles\":[\"Switch Transformer\"]},\"1181\":{\"title\":\"后训练数据合成\",\"titles\":[\"Qwen2\",\"模型训练与数据处理\"]},\"1182\":{\"title\":\"内容详解\",\"titles\":[\"BERT与RNN位置编码的对比与应用\"]},\"1183\":{\"title\":\"核心内容\",\"titles\":[\"预训练的Scaling Law\"]},\"1184\":{\"title\":\"什么是LLM Agent？\",\"titles\":[\"基于大模型的智能体原理\"]},\"1185\":{\"title\":\"RAG优化\",\"titles\":[]},\"1186\":{\"title\":\"数据表格\",\"titles\":[\"Deepseek-V1\"]},\"1187\":{\"title\":\"DeBERTa位置编码的公式解析\",\"titles\":[\"DeBERTa的相对位置编码与绝对位置编码解析\",\"重点内容解析\"]},\"1188\":{\"title\":\"OpenAI 在 AGI 五级分类中对于 Agent 的定义\",\"titles\":[\"定义以及历史发展\"]},\"1189\":{\"title\":\"常见错误\",\"titles\":[\"GLM1\"]},\"1190\":{\"title\":\"数据集收集和清洗过程\",\"titles\":[\"Deepseek-math\",\"重点段落与数据\"]},\"1191\":{\"title\":\"按照数量分类\",\"titles\":[\"智能体的分类\"]},\"1192\":{\"title\":\"常见错误\",\"titles\":[\"GLM3\"]},\"1193\":{\"title\":\"输入形式的改变\",\"titles\":[\"GPT-1\",\"训练范式\"]},\"1194\":{\"title\":\"常见错误\",\"titles\":[\"RoBERTa\"]},\"1195\":{\"title\":\"蒸馏技术的应用\",\"titles\":[\"DeepSeek-R1\",\"研究贡献\"]},\"1196\":{\"title\":\"重点内容解析\",\"titles\":[\"Transformer绝对位置编码详解与改进分析\"]},\"1197\":{\"title\":\"核心观点总结\",\"titles\":[\"预训练策略\"]},\"1198\":{\"title\":\"模型结构\",\"titles\":[\"PLaM\"]},\"1199\":{\"title\":\"重点段落\",\"titles\":[\"监督微调与预训练的区别\",\"核心观点总结\"]},\"1200\":{\"title\":\"智能体框架\",\"titles\":[\"智能体的框架和应用\"]},\"1201\":{\"title\":\"FLOPs 计算成本\",\"titles\":[\"PLaM2\",\"内容概述\",\"Scaling Law 与优化\"]},\"1202\":{\"title\":\"重点内容解析\",\"titles\":[\"训练Tokenizer\"]},\"1203\":{\"title\":\"操作步骤\",\"titles\":[\"GPT-2\"]},\"1204\":{\"title\":\"模型训练方法\",\"titles\":[\"Qwen1\",\"重点段落\"]},\"1205\":{\"title\":\"预训练数据与方法\",\"titles\":[\"Qwen2.5\",\"重点段落\"]},\"1206\":{\"title\":\"💡启发点\",\"titles\":[\"T5\"]},\"1207\":{\"title\":\"相对位置编码的简化\",\"titles\":[\"T5模型与相对位置编码优化解析\",\"重点内容提取\"]},\"1208\":{\"title\":\"示例代码\",\"titles\":[\"FastText\"]},\"1209\":{\"title\":\"量化感知微调 Quantization-Aware Fine-tuning (QAF)\",\"titles\":[\"量化分类\"]},\"1210\":{\"title\":\"[思考] 延伸问题\",\"titles\":[\"Word2Vec\"]},\"1211\":{\"title\":\"训练数据\",\"titles\":[\"LLaMA1\"]},\"1212\":{\"title\":\"行动清单\",\"titles\":[\"oneHot\"]},\"1213\":{\"title\":\"后训练总结\",\"titles\":[\"LLama 2\"]},\"1214\":{\"title\":\"分类：深度学习/模型训练\\n标签：Llama架构、Megatron-LM、预训练、模型优化、深度学习框架\\n日期：2023年10月XX日\",\"titles\":[\"高效深度学习模型训练框架选择与优化指南\"]},\"1215\":{\"title\":\"相对位置编码的基础原理\",\"titles\":[\"相对位置编码与XLNet位置编码详解 深入理解Transformer机制\",\"内容处理\"]},\"1216\":{\"title\":\"训练流程\",\"titles\":[\"LLama 3\"]},\"1217\":{\"title\":\"核心思想\",\"titles\":[\"Agent评估框架汇总\",\"AgentBench\"]},\"1218\":{\"title\":\"从架构上看，Agentic system 可以分为两大类系统：\",\"titles\":[\"智能体系统分类\"]},\"1219\":{\"title\":\"操作步骤\",\"titles\":[\"GShard\"]},\"1220\":{\"title\":\"💡启发点\",\"titles\":[\"DeepSeek-V2\"]},\"1221\":{\"title\":\"分类\",\"titles\":[\"MOE并行训练\"]},\"1222\":{\"title\":\"强化学习方法\",\"titles\":[\"Prompt Tech 提示技术\",\"ICL示例设计\",\"示例选择\",\"基于主动学习/强化学习\"]},\"1223\":{\"title\":\"💡启发点\",\"titles\":[\"PPO优化与对齐税影响分析\"]},\"1224\":{\"title\":\"CoT：中间推理步骤蒸馏\",\"titles\":[\"黑盒知识蒸馏\"]},\"1225\":{\"title\":\"7. 后续追踪研究计划\",\"titles\":[\"介绍\"]},\"1226\":{\"title\":\"数据转换\",\"titles\":[\"介绍\"]},\"1227\":{\"title\":\"实现规范\",\"titles\":[\"DeepSeek-V3\"]},\"1228\":{\"title\":\"训练范式\",\"titles\":[\"GPT-3\",\"模型结构与技术创新\"]},\"1229\":{\"title\":\"公式与设定\",\"titles\":[\"Switch Transformer\",\"负载均衡\"]},\"1230\":{\"title\":\"训练过程的阶段划分\",\"titles\":[\"Qwen2\"]},\"1231\":{\"title\":\"什么是位置编码？\",\"titles\":[\"BERT与RNN位置编码的对比与应用\",\"内容详解\"]},\"1232\":{\"title\":\"1. 计算预算公式及其意义\",\"titles\":[\"预训练的Scaling Law\",\"核心内容\"]},\"1233\":{\"title\":\"LLM Agent的核心组成\",\"titles\":[\"基于大模型的智能体原理\",\"什么是LLM Agent？\"]},\"1234\":{\"title\":\"数据清洗\",\"titles\":[\"RAG优化\"]},\"1235\":{\"title\":\"RAG优化中查询索引阶段\",\"titles\":[]},\"1236\":{\"title\":\"警告区块\",\"titles\":[\"Deepseek-V1\"]},\"1237\":{\"title\":\"模型结构：Encoder与Decoder的分工\",\"titles\":[\"DeBERTa的相对位置编码与绝对位置编码解析\",\"重点内容解析\"]},\"1238\":{\"title\":\"Level 1: Conversational AI\",\"titles\":[\"定义以及历史发展\",\"OpenAI 在 AGI 五级分类中对于 Agent 的定义\"]},\"1239\":{\"title\":\"行动清单\",\"titles\":[\"GLM1\"]},\"1240\":{\"title\":\"指令微调与强化学习\",\"titles\":[\"Deepseek-math\",\"重点段落与数据\"]},\"1241\":{\"title\":\"SingleAgent：单个智能体进行任务规划与行动\",\"titles\":[\"智能体的分类\",\"按照数量分类\"]},\"1242\":{\"title\":\"💡启发点\",\"titles\":[\"GLM3\"]},\"1243\":{\"title\":\"操作步骤\",\"titles\":[\"GPT-1\"]},\"1244\":{\"title\":\"💡启发点\",\"titles\":[\"RoBERTa\"]},\"1245\":{\"title\":\"操作步骤\",\"titles\":[\"DeepSeek-R1\"]},\"1246\":{\"title\":\"1. 位置编码的定义与公式\",\"titles\":[\"Transformer绝对位置编码详解与改进分析\",\"重点内容解析\"]},\"1247\":{\"title\":\"重点内容\",\"titles\":[\"预训练策略\"]},\"1248\":{\"title\":\"训练设置\",\"titles\":[\"PLaM\"]},\"1249\":{\"title\":\"技术术语通俗解释\",\"titles\":[\"监督微调与预训练的区别\"]},\"1250\":{\"title\":\"全代码框架\",\"titles\":[\"智能体的框架和应用\",\"智能体框架\"]},\"1251\":{\"title\":\"RAG方向\",\"titles\":[]},\"1252\":{\"title\":\"Reasoning 能力优化\",\"titles\":[\"PLaM2\",\"内容概述\"]},\"1253\":{\"title\":\"Tokenizer的作用与训练方法\",\"titles\":[\"训练Tokenizer\",\"重点内容解析\"]},\"1254\":{\"title\":\"常见错误\",\"titles\":[\"GPT-2\"]},\"1255\":{\"title\":\"外推能力扩展技术\",\"titles\":[\"Qwen1\",\"重点段落\"]},\"1256\":{\"title\":\"长文本预训练\",\"titles\":[\"Qwen2.5\",\"重点段落\"]},\"1257\":{\"title\":\"行动清单\",\"titles\":[\"T5\"]},\"1258\":{\"title\":\"“分桶”处理机制\",\"titles\":[\"T5模型与相对位置编码优化解析\",\"重点内容提取\"]},\"1259\":{\"title\":\"作者观点 vs 个人观点对比表格\",\"titles\":[\"FastText\"]},\"1260\":{\"title\":\"训练后量化 Post Training Quantization (PTQ)\",\"titles\":[\"量化分类\"]},\"1261\":{\"title\":\"后续追踪 📈\",\"titles\":[\"Word2Vec\"]},\"1262\":{\"title\":\"⚠️ 常见错误\",\"titles\":[\"LLaMA1\"]},\"1263\":{\"title\":\"后续追踪研究计划\",\"titles\":[\"oneHot\"]},\"1264\":{\"title\":\"操作步骤\",\"titles\":[\"LLama 2\"]},\"1265\":{\"title\":\"核心内容总结\",\"titles\":[\"高效深度学习模型训练框架选择与优化指南\"]},\"1266\":{\"title\":\"改进点：\",\"titles\":[\"相对位置编码与XLNet位置编码详解 深入理解Transformer机制\",\"内容处理\",\"相对位置编码的基础原理\"]},\"1267\":{\"title\":\"整体流程\",\"titles\":[\"LLama 3\",\"训练流程\"]},\"1268\":{\"title\":\"评估方式\",\"titles\":[\"Agent评估框架汇总\",\"AgentBench\"]},\"1269\":{\"title\":\"工作流（Workflow）\",\"titles\":[\"智能体系统分类\",\"从架构上看，Agentic system 可以分为两大类系统：\"]},\"1270\":{\"title\":\"常见错误\",\"titles\":[\"GShard\"]},\"1271\":{\"title\":\"行动清单\",\"titles\":[\"DeepSeek-V2\"]},\"1272\":{\"title\":\"标签\",\"titles\":[\"MOE并行训练\"]},\"1273\":{\"title\":\"基于自生成的：\",\"titles\":[\"Prompt Tech 提示技术\",\"ICL示例设计\",\"示例选择\"]},\"1274\":{\"title\":\"行动清单\",\"titles\":[\"PPO优化与对齐税影响分析\"]},\"1275\":{\"title\":\"IF：基于指令跟随的蒸馏\",\"titles\":[\"黑盒知识蒸馏\"]},\"1276\":{\"title\":\"来源标注\",\"titles\":[\"介绍\"]},\"1277\":{\"title\":\"创新启示\",\"titles\":[\"DeepSeek-V3\"]},\"1278\":{\"title\":\"与GPT-2区别\",\"titles\":[\"GPT-3\",\"模型结构与技术创新\"]},\"1279\":{\"title\":\"负载均衡损失设计\",\"titles\":[\"Switch Transformer\",\"负载均衡\"]},\"1280\":{\"title\":\"常见错误警告\",\"titles\":[\"Qwen2\"]},\"1281\":{\"title\":\"BERT的可学习位置编码\",\"titles\":[\"BERT与RNN位置编码的对比与应用\",\"内容详解\"]},\"1282\":{\"title\":\"2. 数据与模型尺寸的平衡\",\"titles\":[\"预训练的Scaling Law\",\"核心内容\"]},\"1283\":{\"title\":\"规划（Planning）\",\"titles\":[\"基于大模型的智能体原理\"]},\"1284\":{\"title\":\"1. 确保数据的准确性\",\"titles\":[\"RAG优化\",\"数据清洗\"]},\"1285\":{\"title\":\"多级索引\",\"titles\":[\"RAG优化中查询索引阶段\"]},\"1286\":{\"title\":\"RAG流程和分类\",\"titles\":[]},\"1287\":{\"title\":\"行动清单\",\"titles\":[\"Deepseek-V1\"]},\"1288\":{\"title\":\"下游任务微调方式\",\"titles\":[\"DeBERTa的相对位置编码与绝对位置编码解析\",\"重点内容解析\"]},\"1289\":{\"title\":\"Level 2: Reasoners\",\"titles\":[\"定义以及历史发展\",\"OpenAI 在 AGI 五级分类中对于 Agent 的定义\"]},\"1290\":{\"title\":\"数据表格\",\"titles\":[\"Deepseek-math\"]},\"1291\":{\"title\":\"MultiAgent：多样化的智能体协作与集体决策\",\"titles\":[\"智能体的分类\",\"按照数量分类\"]},\"1292\":{\"title\":\"数据表格\",\"titles\":[\"GLM3\"]},\"1293\":{\"title\":\"常见错误\",\"titles\":[\"GPT-1\"]},\"1294\":{\"title\":\"行动清单\",\"titles\":[\"RoBERTa\"]},\"1295\":{\"title\":\"常见错误\",\"titles\":[\"DeepSeek-R1\"]},\"1296\":{\"title\":\"2. 编码可视化特点\",\"titles\":[\"Transformer绝对位置编码详解与改进分析\",\"重点内容解析\"]},\"1297\":{\"title\":\"最优 Batch Size 的选择\",\"titles\":[\"预训练策略\",\"重点内容\"]},\"1298\":{\"title\":\"操作步骤\",\"titles\":[\"PLaM\"]},\"1299\":{\"title\":\"重点步骤\",\"titles\":[\"监督微调与预训练的区别\"]},\"1300\":{\"title\":\"多智能体协作框架\",\"titles\":[\"智能体的框架和应用\",\"智能体框架\"]},\"1301\":{\"title\":\"常见错误\",\"titles\":[\"PLaM2\"]},\"1302\":{\"title\":\"✅ Tokenizer训练步骤：\",\"titles\":[\"训练Tokenizer\",\"重点内容解析\",\"Tokenizer的作用与训练方法\"]},\"1303\":{\"title\":\"💡 启发点\",\"titles\":[\"GPT-2\"]},\"1304\":{\"title\":\"操作步骤\",\"titles\":[\"Qwen1\"]},\"1305\":{\"title\":\"操作步骤\",\"titles\":[\"Qwen2.5\"]},\"1306\":{\"title\":\"设计思想的直观性\",\"titles\":[\"T5模型与相对位置编码优化解析\",\"重点内容提取\"]},\"1307\":{\"title\":\"行动清单 📋\",\"titles\":[\"FastText\"]},\"1308\":{\"title\":\"QAT 量化感知训练\",\"titles\":[]},\"1309\":{\"title\":\"RAG评估\",\"titles\":[]},\"1310\":{\"title\":\"行动清单\",\"titles\":[\"LLaMA1\"]},\"1311\":{\"title\":\"常见错误\",\"titles\":[\"LLama 2\"]},\"1312\":{\"title\":\"主要内容\",\"titles\":[\"高效深度学习模型训练框架选择与优化指南\"]},\"1313\":{\"title\":\"XLNet中的位置编码\",\"titles\":[\"相对位置编码与XLNet位置编码详解 深入理解Transformer机制\",\"内容处理\"]},\"1314\":{\"title\":\"常见错误\",\"titles\":[\"LLama 3\"]},\"1315\":{\"title\":\"ToolEmu\",\"titles\":[\"Agent评估框架汇总\"]},\"1316\":{\"title\":\"自主智能体（Autonomous Agent）\",\"titles\":[\"智能体系统分类\",\"从架构上看，Agentic system 可以分为两大类系统：\"]},\"1317\":{\"title\":\"💡启发点\",\"titles\":[\"GShard\"]},\"1318\":{\"title\":\"数据转换\",\"titles\":[\"DeepSeek-V2\"]},\"1319\":{\"title\":\"日期\",\"titles\":[\"MOE并行训练\"]},\"1320\":{\"title\":\"固定长度分块\",\"titles\":[]},\"1321\":{\"title\":\"基于大模型的分块\",\"titles\":[]},\"1322\":{\"title\":\"示例格式\",\"titles\":[\"Prompt Tech 提示技术\",\"ICL示例设计\",\"示例选择\",\"基于自生成的：\"]},\"1323\":{\"title\":\"数据表格示例\",\"titles\":[\"PPO优化与对齐税影响分析\"]},\"1324\":{\"title\":\"应用路线图\",\"titles\":[\"DeepSeek-V3\"]},\"1325\":{\"title\":\"常见错误\",\"titles\":[\"GPT-3\"]},\"1326\":{\"title\":\"数据表格\",\"titles\":[\"Switch Transformer\",\"负载均衡\"]},\"1327\":{\"title\":\"行动清单\",\"titles\":[\"Qwen2\"]},\"1328\":{\"title\":\"RNN位置编码\",\"titles\":[\"BERT与RNN位置编码的对比与应用\",\"内容详解\"]},\"1329\":{\"title\":\"3. Scaling Law实验结果\",\"titles\":[\"预训练的Scaling Law\",\"核心内容\"]},\"1330\":{\"title\":\"子目标分解\",\"titles\":[\"基于大模型的智能体原理\",\"规划（Planning）\"]},\"1331\":{\"title\":\"2. 基本数据清理\",\"titles\":[\"RAG优化\",\"数据清洗\"]},\"1332\":{\"title\":\"多级路由机制\",\"titles\":[\"RAG优化中查询索引阶段\"]},\"1333\":{\"title\":\"什么是RAG？\",\"titles\":[\"RAG流程和分类\"]},\"1334\":{\"title\":\"基于文档结构分块\",\"titles\":[]},\"1335\":{\"title\":\"常见错误\",\"titles\":[\"DeBERTa的相对位置编码与绝对位置编码解析\"]},\"1336\":{\"title\":\"Level 3: Agents\",\"titles\":[\"定义以及历史发展\",\"OpenAI 在 AGI 五级分类中对于 Agent 的定义\"]},\"1337\":{\"title\":\"操作步骤\",\"titles\":[\"Deepseek-math\"]},\"1338\":{\"title\":\"多个智能体系统的核心特征\",\"titles\":[\"智能体的分类\",\"按照数量分类\",\"MultiAgent：多样化的智能体协作与集体决策\"]},\"1339\":{\"title\":\"行动清单\",\"titles\":[\"GLM3\"]},\"1340\":{\"title\":\"💡启发点\",\"titles\":[\"GPT-1\"]},\"1341\":{\"title\":\"数据表格\",\"titles\":[\"RoBERTa\"]},\"1342\":{\"title\":\"💡启发点\",\"titles\":[\"DeepSeek-R1\"]},\"1343\":{\"title\":\"3. 缺点与局限性\",\"titles\":[\"Transformer绝对位置编码详解与改进分析\",\"重点内容解析\"]},\"1344\":{\"title\":\"WSD 调度器的三阶段学习率策略\",\"titles\":[\"预训练策略\",\"重点内容\"]},\"1345\":{\"title\":\"常见错误\",\"titles\":[\"PLaM\"]},\"1346\":{\"title\":\"常见错误\",\"titles\":[\"监督微调与预训练的区别\"]},\"1347\":{\"title\":\"可视化低代码平台\",\"titles\":[\"智能体的框架和应用\",\"智能体框架\"]},\"1348\":{\"title\":\"💡 启发点\",\"titles\":[\"PLaM2\"]},\"1349\":{\"title\":\"中文预训练的独特挑战\",\"titles\":[\"训练Tokenizer\",\"重点内容解析\"]},\"1350\":{\"title\":\"行动清单\",\"titles\":[\"GPT-2\"]},\"1351\":{\"title\":\"常见错误\",\"titles\":[\"Qwen1\"]},\"1352\":{\"title\":\"常见错误\",\"titles\":[\"Qwen2.5\"]},\"1353\":{\"title\":\"操作步骤\",\"titles\":[\"T5模型与相对位置编码优化解析\"]},\"1354\":{\"title\":\"[思考] 延伸问题\",\"titles\":[\"FastText\"]},\"1355\":{\"title\":\"量化感知训练的基本原理\",\"titles\":[\"QAT 量化感知训练\"]},\"1356\":{\"title\":\"RAG评估的核心维度\",\"titles\":[\"RAG评估\"]},\"1357\":{\"title\":\"💡 启发点\",\"titles\":[\"LLama 2\"]},\"1358\":{\"title\":\"模型结构与参数选择\",\"titles\":[\"高效深度学习模型训练框架选择与优化指南\",\"主要内容\"]},\"1359\":{\"title\":\"核心公式展开：\",\"titles\":[\"相对位置编码与XLNet位置编码详解 深入理解Transformer机制\",\"内容处理\",\"XLNet中的位置编码\"]},\"1360\":{\"title\":\"数据表格\",\"titles\":[\"LLama 3\"]},\"1361\":{\"title\":\"核心目标\",\"titles\":[\"Agent评估框架汇总\",\"ToolEmu\"]},\"1362\":{\"title\":\"基础构建模块：增强型 LLM\",\"titles\":[\"智能体系统分类\",\"从架构上看，Agentic system 可以分为两大类系统：\"]},\"1363\":{\"title\":\"行动清单\",\"titles\":[\"GShard\"]},\"1364\":{\"title\":\"公式显示\",\"titles\":[\"DeepSeek-V2\"]},\"1365\":{\"title\":\"内容概述\",\"titles\":[\"MOE并行训练\"]},\"1366\":{\"title\":\"最简单直观的文本分块方法\",\"titles\":[\"固定长度分块\"]},\"1367\":{\"title\":\"Dense X Retrieval: 检索粒度的选择\",\"titles\":[\"基于大模型的分块\"]},\"1368\":{\"title\":\"Cross-task generalization via natural language crowdsourcing instructions\",\"titles\":[\"Prompt Tech 提示技术\",\"ICL示例设计\",\"示例选择\",\"基于自生成的：\"]},\"1369\":{\"title\":\"来源标注\",\"titles\":[\"PPO优化与对齐税影响分析\"]},\"1370\":{\"title\":\"行动清单\",\"titles\":[\"GPT-3\"]},\"1371\":{\"title\":\"常见错误\",\"titles\":[\"Switch Transformer\"]},\"1372\":{\"title\":\"💡 启发点\",\"titles\":[\"Qwen2\"]},\"1373\":{\"title\":\"数据呈现\",\"titles\":[\"BERT与RNN位置编码的对比与应用\"]},\"1374\":{\"title\":\"操作步骤\",\"titles\":[\"预训练的Scaling Law\"]},\"1375\":{\"title\":\"目的\",\"titles\":[\"基于大模型的智能体原理\",\"规划（Planning）\",\"子目标分解\"]},\"1376\":{\"title\":\"3. 实体解析\",\"titles\":[\"RAG优化\",\"数据清洗\"]},\"1377\":{\"title\":\"索引/查询算法\",\"titles\":[\"RAG优化中查询索引阶段\"]},\"1378\":{\"title\":\"LLM本身的局限性\",\"titles\":[\"RAG流程和分类\"]},\"1379\":{\"title\":\"利用文档内部结构进行分块\",\"titles\":[\"基于文档结构分块\"]},\"1380\":{\"title\":\"基于语义分块\",\"titles\":[]},\"1381\":{\"title\":\"行动清单\",\"titles\":[\"DeBERTa的相对位置编码与绝对位置编码解析\"]},\"1382\":{\"title\":\"Level 4: Innovators\",\"titles\":[\"定义以及历史发展\",\"OpenAI 在 AGI 五级分类中对于 Agent 的定义\"]},\"1383\":{\"title\":\"常见错误\",\"titles\":[\"Deepseek-math\"]},\"1384\":{\"title\":\"多个智能体系统的优势\",\"titles\":[\"智能体的分类\",\"按照数量分类\",\"MultiAgent：多样化的智能体协作与集体决策\"]},\"1385\":{\"title\":\"行动清单\",\"titles\":[\"GPT-1\"]},\"1386\":{\"title\":\"来源标注\",\"titles\":[\"RoBERTa\"]},\"1387\":{\"title\":\"行动清单\",\"titles\":[\"DeepSeek-R1\"]},\"1388\":{\"title\":\"4. 改进方向\",\"titles\":[\"Transformer绝对位置编码详解与改进分析\",\"重点内容解析\"]},\"1389\":{\"title\":\"提高效率的预训练技巧\",\"titles\":[\"预训练策略\",\"重点内容\"]},\"1390\":{\"title\":\"数据与公式\",\"titles\":[\"PLaM\"]},\"1391\":{\"title\":\"💡启发点\",\"titles\":[\"监督微调与预训练的区别\"]},\"1392\":{\"title\":\"使用这些框架时的注意事项\",\"titles\":[\"智能体的框架和应用\"]},\"1393\":{\"title\":\"数据表格\",\"titles\":[\"PLaM2\"]},\"1394\":{\"title\":\"⚠ 常见问题：\",\"titles\":[\"训练Tokenizer\",\"重点内容解析\",\"中文预训练的独特挑战\"]},\"1395\":{\"title\":\"数据转换\",\"titles\":[\"GPT-2\"]},\"1396\":{\"title\":\"常见索引优化算法实现\",\"titles\":[]},\"1397\":{\"title\":\"💡 启发点\",\"titles\":[\"Qwen1\"]},\"1398\":{\"title\":\"数据表格\",\"titles\":[\"Qwen2.5\"]},\"1399\":{\"title\":\"常见错误\",\"titles\":[\"T5模型与相对位置编码优化解析\"]},\"1400\":{\"title\":\"QAT方法\",\"titles\":[\"QAT 量化感知训练\"]},\"1401\":{\"title\":\"DPO介绍及RLHF-PPO缺点\",\"titles\":[]},\"1402\":{\"title\":\"RAG的难点\",\"titles\":[\"RAG评估\"]},\"1403\":{\"title\":\"行动清单\",\"titles\":[\"LLama 2\"]},\"1404\":{\"title\":\"训练框架推荐\",\"titles\":[\"高效深度学习模型训练框架选择与优化指南\",\"主要内容\"]},\"1405\":{\"title\":\"操作步骤\",\"titles\":[\"相对位置编码与XLNet位置编码详解 深入理解Transformer机制\",\"内容处理\"]},\"1406\":{\"title\":\"行动清单\",\"titles\":[\"LLama 3\"]},\"1407\":{\"title\":\"评估方式\",\"titles\":[\"Agent评估框架汇总\",\"ToolEmu\"]},\"1408\":{\"title\":\"自主智能体（Autonomous Agent）\",\"titles\":[\"智能体系统分类\"]},\"1409\":{\"title\":\"数据转换\",\"titles\":[\"GShard\"]},\"1410\":{\"title\":\"分布式初始化\",\"titles\":[\"MOE并行训练\"]},\"1411\":{\"title\":\"问题与挑战\",\"titles\":[\"固定长度分块\"]},\"1412\":{\"title\":\"Proposition 的特点\",\"titles\":[\"基于大模型的分块\",\"Dense X Retrieval: 检索粒度的选择\"]},\"1413\":{\"title\":\"示例顺序\",\"titles\":[\"Prompt Tech 提示技术\",\"ICL示例设计\",\"示例选择\",\"基于自生成的：\"]},\"1414\":{\"title\":\"强化学习中的奖励利用与泛化问题\",\"titles\":[]},\"1415\":{\"title\":\"DPO公式推导\",\"titles\":[]},\"1416\":{\"title\":\"数据表格\",\"titles\":[\"GPT-3\"]},\"1417\":{\"title\":\"行动清单\",\"titles\":[\"Switch Transformer\"]},\"1418\":{\"title\":\"通俗化说明\",\"titles\":[\"BERT与RNN位置编码的对比与应用\"]},\"1419\":{\"title\":\"数据表格\",\"titles\":[\"预训练的Scaling Law\"]},\"1420\":{\"title\":\"任务分解的实现方式\",\"titles\":[\"基于大模型的智能体原理\",\"规划（Planning）\",\"子目标分解\"]},\"1421\":{\"title\":\"文档划分\",\"titles\":[\"RAG优化\"]},\"1422\":{\"title\":\"常见的向量搜索算法\",\"titles\":[\"RAG优化中查询索引阶段\",\"索引/查询算法\"]},\"1423\":{\"title\":\"1. 知识的局限性\",\"titles\":[\"RAG流程和分类\",\"LLM本身的局限性\"]},\"1424\":{\"title\":\"优点\",\"titles\":[\"基于文档结构分块\",\"利用文档内部结构进行分块\"]},\"1425\":{\"title\":\"什么是基于语义分块？\",\"titles\":[\"基于语义分块\"]},\"1426\":{\"title\":\"人类建模偏好角度理解DPO\",\"titles\":[]},\"1427\":{\"title\":\"📈 趋势预测\",\"titles\":[\"DeBERTa的相对位置编码与绝对位置编码解析\"]},\"1428\":{\"title\":\"对比学习角度理解DPO\",\"titles\":[]},\"1429\":{\"title\":\"Level 5: Organizers\",\"titles\":[\"定义以及历史发展\",\"OpenAI 在 AGI 五级分类中对于 Agent 的定义\"]},\"1430\":{\"title\":\"💡启发点\",\"titles\":[\"Deepseek-math\"]},\"1431\":{\"title\":\"应用场景\",\"titles\":[\"智能体的分类\",\"按照数量分类\",\"MultiAgent：多样化的智能体协作与集体决策\"]},\"1432\":{\"title\":\"深度偏好优化（DPO）损失函数解析与代码示例\",\"titles\":[]},\"1433\":{\"title\":\"Actor-Model\",\"titles\":[]},\"1434\":{\"title\":\"Method\",\"titles\":[]},\"1435\":{\"title\":\"示例代码\",\"titles\":[\"Transformer绝对位置编码详解与改进分析\"]},\"1436\":{\"title\":\"✅ 四阶段预训练设置流程\",\"titles\":[\"预训练策略\"]},\"1437\":{\"title\":\"公式\",\"titles\":[\"PLaM\",\"数据与公式\"]},\"1438\":{\"title\":\"行动清单\",\"titles\":[\"监督微调与预训练的区别\"]},\"1439\":{\"title\":\"单智能体应用\",\"titles\":[\"智能体的框架和应用\"]},\"1440\":{\"title\":\"Instruct-GPT\",\"titles\":[]},\"1441\":{\"title\":\"行动清单\",\"titles\":[\"PLaM2\"]},\"1442\":{\"title\":\"词表扩充实例对比\",\"titles\":[\"训练Tokenizer\",\"重点内容解析\"]},\"1443\":{\"title\":\"RLHF流程\",\"titles\":[]},\"1444\":{\"title\":\"行动清单\",\"titles\":[\"Qwen1\"]},\"1445\":{\"title\":\"RLHF研究方法及研究总结\",\"titles\":[]},\"1446\":{\"title\":\"💡启发点\",\"titles\":[\"Qwen2.5\"]},\"1447\":{\"title\":\"[思考] 延伸问题\",\"titles\":[\"T5模型与相对位置编码优化解析\"]},\"1448\":{\"title\":\"LLM-QAT\",\"titles\":[\"QAT 量化感知训练\",\"QAT方法\"]},\"1449\":{\"title\":\"元数据\",\"titles\":[\"DPO介绍及RLHF-PPO缺点\"]},\"1450\":{\"title\":\"1. 如何建立知识向量库\",\"titles\":[\"RAG评估\",\"RAG的难点\"]},\"1451\":{\"title\":\"选择Megatron-LM的原因\",\"titles\":[\"高效深度学习模型训练框架选择与优化指南\",\"主要内容\"]},\"1452\":{\"title\":\"常见错误\",\"titles\":[\"相对位置编码与XLNet位置编码详解 深入理解Transformer机制\",\"内容处理\"]},\"1453\":{\"title\":\"AgentBoard 的核心目标\",\"titles\":[\"Agent评估框架汇总\"]},\"1454\":{\"title\":\"1. 执行过程中获取环境真实反馈\",\"titles\":[\"智能体系统分类\",\"自主智能体（Autonomous Agent）\"]},\"1455\":{\"title\":\"公式显示\",\"titles\":[\"GShard\"]},\"1456\":{\"title\":\"FWD与BWD过程\",\"titles\":[\"MOE并行训练\"]},\"1457\":{\"title\":\"上下文割裂\",\"titles\":[\"固定长度分块\",\"问题与挑战\"]},\"1458\":{\"title\":\"LlamaIndex 的实现方案\",\"titles\":[\"基于大模型的分块\"]},\"1459\":{\"title\":\"ICL 的挑战\",\"titles\":[\"Prompt Tech 提示技术\",\"ICL示例设计\"]},\"1460\":{\"title\":\"核心观点\",\"titles\":[\"强化学习中的奖励利用与泛化问题\"]},\"1461\":{\"title\":\"元数据\",\"titles\":[\"DPO公式推导\"]},\"1462\":{\"title\":\"来源标注\",\"titles\":[\"GPT-3\"]},\"1463\":{\"title\":\"常见错误提示\",\"titles\":[\"BERT与RNN位置编码的对比与应用\"]},\"1464\":{\"title\":\"📈 趋势预测\",\"titles\":[\"预训练的Scaling Law\"]},\"1465\":{\"title\":\"LLM与PDDL结合的规划方法\",\"titles\":[\"基于大模型的智能体原理\",\"规划（Planning）\"]},\"1466\":{\"title\":\"数据增强\",\"titles\":[\"RAG优化\"]},\"1467\":{\"title\":\"1. 聚类算法：K-means 等\",\"titles\":[\"RAG优化中查询索引阶段\",\"索引/查询算法\",\"常见的向量搜索算法\"]},\"1468\":{\"title\":\"2. 幻觉问题\",\"titles\":[\"RAG流程和分类\",\"LLM本身的局限性\"]},\"1469\":{\"title\":\"前提条件\",\"titles\":[\"基于文档结构分块\",\"利用文档内部结构进行分块\"]},\"1470\":{\"title\":\"做法\",\"titles\":[\"基于语义分块\",\"什么是基于语义分块？\"]},\"1471\":{\"title\":\"RL在NLP场景下的拓展\",\"titles\":[]},\"1472\":{\"title\":\"[思考]板块\",\"titles\":[\"DeBERTa的相对位置编码与绝对位置编码解析\"]},\"1473\":{\"title\":\"元数据\",\"titles\":[\"对比学习角度理解DPO\"]},\"1474\":{\"title\":\"智能体的核心定义\",\"titles\":[\"定义以及历史发展\"]},\"1475\":{\"title\":\"行动清单\",\"titles\":[\"Deepseek-math\"]},\"1476\":{\"title\":\"按行为模式分类\",\"titles\":[\"智能体的分类\"]},\"1477\":{\"title\":\"分类\",\"titles\":[\"深度偏好优化（DPO）损失函数解析与代码示例\"]},\"1478\":{\"title\":\"Reference-Model\",\"titles\":[]},\"1479\":{\"title\":\"元数据\",\"titles\":[\"Actor-Model\"]},\"1480\":{\"title\":\"强化学习算法\",\"titles\":[\"Method\"]},\"1481\":{\"title\":\"[思考] 延伸问题\",\"titles\":[\"Transformer绝对位置编码详解与改进分析\"]},\"1482\":{\"title\":\"⚠ 常见错误与注意事项\",\"titles\":[\"预训练策略\"]},\"1483\":{\"title\":\"数据表格\",\"titles\":[\"PLaM\",\"数据与公式\"]},\"1484\":{\"title\":\"📈趋势预测\",\"titles\":[\"监督微调与预训练的区别\"]},\"1485\":{\"title\":\"多智能体应用\",\"titles\":[\"智能体的框架和应用\"]},\"1486\":{\"title\":\"元数据\",\"titles\":[\"Instruct-GPT\"]},\"1487\":{\"title\":\"📊 数据表格示例：\",\"titles\":[\"训练Tokenizer\",\"重点内容解析\",\"词表扩充实例对比\"]},\"1488\":{\"title\":\"分类\",\"titles\":[\"RLHF流程\"]},\"1489\":{\"title\":\"Reward-Model\",\"titles\":[]},\"1490\":{\"title\":\"数据转换\",\"titles\":[\"Qwen1\"]},\"1491\":{\"title\":\"核心观点总结\",\"titles\":[\"RLHF研究方法及研究总结\"]},\"1492\":{\"title\":\"行动清单\",\"titles\":[\"Qwen2.5\"]},\"1493\":{\"title\":\"行动清单\",\"titles\":[\"T5模型与相对位置编码优化解析\"]},\"1494\":{\"title\":\"QAF 量化感知微调\",\"titles\":[]},\"1495\":{\"title\":\"内容概述\",\"titles\":[\"DPO介绍及RLHF-PPO缺点\"]},\"1496\":{\"title\":\"2. 检索优化\",\"titles\":[\"RAG评估\",\"RAG的难点\"]},\"1497\":{\"title\":\"critic-model\",\"titles\":[]},\"1498\":{\"title\":\"操作步骤\",\"titles\":[\"高效深度学习模型训练框架选择与优化指南\"]},\"1499\":{\"title\":\"数据表格：截断范围示例\",\"titles\":[\"相对位置编码与XLNet位置编码详解 深入理解Transformer机制\",\"内容处理\"]},\"1500\":{\"title\":\"AgentBoard 的评估方法与指标\",\"titles\":[\"Agent评估框架汇总\"]},\"1501\":{\"title\":\"2. 支持人工检查点干预\",\"titles\":[\"智能体系统分类\",\"自主智能体（Autonomous Agent）\"]},\"1502\":{\"title\":\"关键步骤\",\"titles\":[\"MOE并行训练\",\"FWD与BWD过程\"]},\"1503\":{\"title\":\"语义完整性受损\",\"titles\":[\"固定长度分块\",\"问题与挑战\"]},\"1504\":{\"title\":\"1. 长上下文问题\",\"titles\":[\"Prompt Tech 提示技术\",\"ICL示例设计\",\"ICL 的挑战\"]},\"1505\":{\"title\":\"重点段落\",\"titles\":[\"强化学习中的奖励利用与泛化问题\"]},\"1506\":{\"title\":\"核心目标函数推导\",\"titles\":[\"DPO公式推导\"]},\"1507\":{\"title\":\"启发标注\",\"titles\":[\"BERT与RNN位置编码的对比与应用\"]},\"1508\":{\"title\":\"[思考]板块\",\"titles\":[\"预训练的Scaling Law\"]},\"1509\":{\"title\":\"反思与完善\",\"titles\":[\"基于大模型的智能体原理\"]},\"1510\":{\"title\":\"用户反馈循环\",\"titles\":[\"RAG优化\"]},\"1511\":{\"title\":\"2. 位置敏感哈希\",\"titles\":[\"RAG优化中查询索引阶段\",\"索引/查询算法\",\"常见的向量搜索算法\"]},\"1512\":{\"title\":\"3. 数据安全性\",\"titles\":[\"RAG流程和分类\",\"LLM本身的局限性\"]},\"1513\":{\"title\":\"不同长度的问题\",\"titles\":[\"基于文档结构分块\"]},\"1514\":{\"title\":\"优势\",\"titles\":[\"基于语义分块\",\"什么是基于语义分块？\"]},\"1515\":{\"title\":\"核心观点总结\",\"titles\":[\"RL在NLP场景下的拓展\"]},\"1516\":{\"title\":\"在线与离线RLHF的比较与应用\",\"titles\":[]},\"1517\":{\"title\":\"内容概述\",\"titles\":[\"对比学习角度理解DPO\"]},\"1518\":{\"title\":\"感知：智能体的“眼睛”\",\"titles\":[\"定义以及历史发展\",\"智能体的核心定义\"]},\"1519\":{\"title\":\"深入理解Prompt到Response的MDP模型分析\",\"titles\":[]},\"1520\":{\"title\":\"Tool Use Agent\",\"titles\":[\"智能体的分类\",\"按行为模式分类\"]},\"1521\":{\"title\":\"标签\",\"titles\":[\"深度偏好优化（DPO）损失函数解析与代码示例\"]},\"1522\":{\"title\":\"核心观点总结\",\"titles\":[\"Reference-Model\"]},\"1523\":{\"title\":\"文章内容\",\"titles\":[\"Actor-Model\"]},\"1524\":{\"title\":\"DPOP\",\"titles\":[]},\"1525\":{\"title\":\"重点段落\",\"titles\":[\"Method\"]},\"1526\":{\"title\":\"📈 趋势预测\",\"titles\":[\"预训练策略\"]},\"1527\":{\"title\":\"行动清单\",\"titles\":[\"PLaM\"]},\"1528\":{\"title\":\"后续追踪\",\"titles\":[\"监督微调与预训练的区别\"]},\"1529\":{\"title\":\"Agent+RL 框架\",\"titles\":[\"智能体的框架和应用\"]},\"1530\":{\"title\":\"内容概述\",\"titles\":[\"Instruct-GPT\"]},\"1531\":{\"title\":\"技术术语通俗解释\",\"titles\":[\"训练Tokenizer\"]},\"1532\":{\"title\":\"标签\",\"titles\":[\"RLHF流程\"]},\"1533\":{\"title\":\"核心观点总结\",\"titles\":[\"Reward-Model\"]},\"1534\":{\"title\":\"Self-Reward\",\"titles\":[]},\"1535\":{\"title\":\"公式显示\",\"titles\":[\"Qwen1\"]},\"1536\":{\"title\":\"重点段落\",\"titles\":[\"RLHF研究方法及研究总结\"]},\"1537\":{\"title\":\"📈 趋势预测\",\"titles\":[\"T5模型与相对位置编码优化解析\"]},\"1538\":{\"title\":\"QAF方法\",\"titles\":[\"QAF 量化感知微调\"]},\"1539\":{\"title\":\"核心观点\",\"titles\":[\"DPO介绍及RLHF-PPO缺点\"]},\"1540\":{\"title\":\"3. 归纳总结\",\"titles\":[\"RAG评估\",\"RAG的难点\"]},\"1541\":{\"title\":\"核心观点总结\",\"titles\":[\"critic-model\"]},\"1542\":{\"title\":\"如何选择与配置训练框架\",\"titles\":[\"高效深度学习模型训练框架选择与优化指南\",\"操作步骤\"]},\"1543\":{\"title\":\"📈 趋势预测\",\"titles\":[\"相对位置编码与XLNet位置编码详解 深入理解Transformer机制\"]},\"1544\":{\"title\":\"1. 处理率（Process Rate）\",\"titles\":[\"Agent评估框架汇总\",\"AgentBoard 的评估方法与指标\"]},\"1545\":{\"title\":\"3. 设置终止条件\",\"titles\":[\"智能体系统分类\",\"自主智能体（Autonomous Agent）\"]},\"1546\":{\"title\":\"TDPO\",\"titles\":[]},\"1547\":{\"title\":\"常见错误\",\"titles\":[\"MOE并行训练\"]},\"1548\":{\"title\":\"改进方法\",\"titles\":[\"固定长度分块\"]},\"1549\":{\"title\":\"AdaLoRA\",\"titles\":[]},\"1550\":{\"title\":\"2. 选择适当的上下文\",\"titles\":[\"Prompt Tech 提示技术\",\"ICL示例设计\",\"ICL 的挑战\"]},\"1551\":{\"title\":\"操作步骤\",\"titles\":[\"强化学习中的奖励利用与泛化问题\"]},\"1552\":{\"title\":\"1. 原始约束目标\",\"titles\":[\"DPO公式推导\",\"核心目标函数推导\"]},\"1553\":{\"title\":\"DoRA\",\"titles\":[]},\"1554\":{\"title\":\"LoRA+\",\"titles\":[]},\"1555\":{\"title\":\"行动清单\",\"titles\":[\"BERT与RNN位置编码的对比与应用\"]},\"1556\":{\"title\":\"行动清单\",\"titles\":[\"预训练的Scaling Law\"]},\"1557\":{\"title\":\"自我批评与反思\",\"titles\":[\"基于大模型的智能体原理\",\"反思与完善\"]},\"1558\":{\"title\":\"时间敏感数据处理\",\"titles\":[\"RAG优化\"]},\"1559\":{\"title\":\"核心思想\",\"titles\":[\"RAG优化中查询索引阶段\",\"索引/查询算法\",\"常见的向量搜索算法\",\"2. 位置敏感哈希\"]},\"1560\":{\"title\":\"RAG的特点\",\"titles\":[\"RAG流程和分类\"]},\"1561\":{\"title\":\"解决方案：结合递归式分块\",\"titles\":[\"基于文档结构分块\",\"不同长度的问题\"]},\"1562\":{\"title\":\"局限性\",\"titles\":[\"基于语义分块\",\"什么是基于语义分块？\"]},\"1563\":{\"title\":\"重点段落\",\"titles\":[\"RL在NLP场景下的拓展\"]},\"1564\":{\"title\":\"在线与离线RLHF的核心思想\",\"titles\":[\"在线与离线RLHF的比较与应用\"]},\"1565\":{\"title\":\"LoRA-FA\",\"titles\":[]},\"1566\":{\"title\":\"核心观点\",\"titles\":[\"对比学习角度理解DPO\"]},\"1567\":{\"title\":\"决策：智能体的“大脑”\",\"titles\":[\"定义以及历史发展\",\"智能体的核心定义\"]},\"1568\":{\"title\":\"元数据\",\"titles\":[\"深入理解Prompt到Response的MDP模型分析\"]},\"1569\":{\"title\":\"MRKL System：Modular Reasoning, Knowledge, and Language\",\"titles\":[\"智能体的分类\",\"按行为模式分类\",\"Tool Use Agent\"]},\"1570\":{\"title\":\"日期\",\"titles\":[\"深度偏好优化（DPO）损失函数解析与代码示例\"]},\"1571\":{\"title\":\"重点内容\",\"titles\":[\"Reference-Model\"]},\"1572\":{\"title\":\"核心观点\",\"titles\":[\"Actor-Model\",\"文章内容\"]},\"1573\":{\"title\":\"LoRA\",\"titles\":[]},\"1574\":{\"title\":\"QLoRA\",\"titles\":[]},\"1575\":{\"title\":\"元数据\",\"titles\":[\"DPOP\"]},\"1576\":{\"title\":\"强化学习算法的优化\",\"titles\":[\"Method\",\"重点段落\"]},\"1577\":{\"title\":\"[思考] 延伸问题\",\"titles\":[\"预训练策略\"]},\"1578\":{\"title\":\"结合 LLM 与 RL 的双向优势\",\"titles\":[\"智能体的框架和应用\",\"Agent+RL 框架\"]},\"1579\":{\"title\":\"关键流程与技术\",\"titles\":[\"Instruct-GPT\"]},\"1580\":{\"title\":\"[思考]板块\",\"titles\":[\"训练Tokenizer\"]},\"1581\":{\"title\":\"日期\",\"titles\":[\"RLHF流程\"]},\"1582\":{\"title\":\"奖励模型训练\",\"titles\":[\"Reward-Model\"]},\"1583\":{\"title\":\"VeRA\",\"titles\":[]},\"1584\":{\"title\":\"分类：机器学习\",\"titles\":[\"Self-Reward\"]},\"1585\":{\"title\":\"X-LoRA\",\"titles\":[]},\"1586\":{\"title\":\"操作步骤\",\"titles\":[\"RLHF研究方法及研究总结\"]},\"1587\":{\"title\":\"后续追踪\",\"titles\":[\"T5模型与相对位置编码优化解析\"]},\"1588\":{\"title\":\"PEQA：Memory-Efficient Fine-Tuning of Compressed Large Language Models via sub-4-bit Integer Quantization\",\"titles\":[\"QAF 量化感知微调\",\"QAF方法\"]},\"1589\":{\"title\":\"技术术语通俗解释\",\"titles\":[\"DPO介绍及RLHF-PPO缺点\"]},\"1590\":{\"title\":\"针对检索环节的评估\",\"titles\":[\"RAG评估\"]},\"1591\":{\"title\":\"重点段落\",\"titles\":[\"critic-model\"]},\"1592\":{\"title\":\"常见错误\",\"titles\":[\"高效深度学习模型训练框架选择与优化指南\"]},\"1593\":{\"title\":\"[思考] 延伸问题\",\"titles\":[\"相对位置编码与XLNet位置编码详解 深入理解Transformer机制\"]},\"1594\":{\"title\":\"2. Grounding 精度\",\"titles\":[\"Agent评估框架汇总\",\"AgentBoard 的评估方法与指标\"]},\"1595\":{\"title\":\"工作流（Workflow）\",\"titles\":[\"智能体系统分类\"]},\"1596\":{\"title\":\"TDPO与PPO中的KL约束\",\"titles\":[\"TDPO\"]},\"1597\":{\"title\":\"💡启发点\",\"titles\":[\"MOE并行训练\"]},\"1598\":{\"title\":\"1. 引入重叠\",\"titles\":[\"固定长度分块\",\"改进方法\"]},\"1599\":{\"title\":\"元数据\",\"titles\":[\"AdaLoRA\"]},\"1600\":{\"title\":\"3. 输出一致性\",\"titles\":[\"Prompt Tech 提示技术\",\"ICL示例设计\",\"ICL 的挑战\"]},\"1601\":{\"title\":\"常见错误\",\"titles\":[\"强化学习中的奖励利用与泛化问题\"]},\"1602\":{\"title\":\"2. 目标函数变形\",\"titles\":[\"DPO公式推导\",\"核心目标函数推导\"]},\"1603\":{\"title\":\"参考文献\",\"titles\":[]},\"1604\":{\"title\":\"元数据\",\"titles\":[\"DoRA\"]},\"1605\":{\"title\":\"元数据\",\"titles\":[\"LoRA+\"]},\"1606\":{\"title\":\"[思考]\",\"titles\":[\"BERT与RNN位置编码的对比与应用\"]},\"1607\":{\"title\":\"后续追踪\",\"titles\":[\"预训练的Scaling Law\"]},\"1608\":{\"title\":\"ReAct：结合推理与行动\",\"titles\":[\"基于大模型的智能体原理\"]},\"1609\":{\"title\":\"解析PDF文件的主流方法详解\",\"titles\":[\"RAG优化\"]},\"1610\":{\"title\":\"3.查询转换\",\"titles\":[\"RAG优化中查询索引阶段\",\"索引/查询算法\",\"常见的向量搜索算法\"]},\"1611\":{\"title\":\"1. 依赖LLM来强化信息检索和输出\",\"titles\":[\"RAG流程和分类\",\"RAG的特点\"]},\"1612\":{\"title\":\"NLTK 的文本切分功能\",\"titles\":[\"基于语义分块\"]},\"1613\":{\"title\":\"NLP MDP建模\",\"titles\":[\"RL在NLP场景下的拓展\",\"重点段落\"]},\"1614\":{\"title\":\"在线（Online）RLHF\",\"titles\":[\"在线与离线RLHF的比较与应用\",\"在线与离线RLHF的核心思想\"]},\"1615\":{\"title\":\"LLaMA-Adapter\",\"titles\":[]},\"1616\":{\"title\":\"重点段落\",\"titles\":[\"对比学习角度理解DPO\"]},\"1617\":{\"title\":\"与其讨论 Agent，不如讨论 Agentic\",\"titles\":[]},\"1618\":{\"title\":\"内容概述\",\"titles\":[\"深入理解Prompt到Response的MDP模型分析\"]},\"1619\":{\"title\":\"CRITIC：Self-Correcting with Tool-Interactive Critiquing\",\"titles\":[\"智能体的分类\",\"按行为模式分类\",\"Tool Use Agent\"]},\"1620\":{\"title\":\"内容概要\",\"titles\":[\"深度偏好优化（DPO）损失函数解析与代码示例\"]},\"1621\":{\"title\":\"KL约束在PPO训练中的应用\",\"titles\":[\"Reference-Model\",\"重点内容\"]},\"1622\":{\"title\":\"重点段落\",\"titles\":[\"Actor-Model\",\"文章内容\"]},\"1623\":{\"title\":\"分类：机器学习\",\"titles\":[\"LoRA\"]},\"1624\":{\"title\":\"元数据\",\"titles\":[\"QLoRA\"]},\"1625\":{\"title\":\"P-Tuning V2\",\"titles\":[]},\"1626\":{\"title\":\"内容概述\",\"titles\":[\"DPOP\"]},\"1627\":{\"title\":\"P-Tuning\",\"titles\":[]},\"1628\":{\"title\":\"优化公式\",\"titles\":[\"Method\",\"重点段落\"]},\"1629\":{\"title\":\"行动清单\",\"titles\":[\"预训练策略\"]},\"1630\":{\"title\":\"GAIR/ToRL 框架\",\"titles\":[\"智能体的框架和应用\"]},\"1631\":{\"title\":\"InstructGPT的训练流程\",\"titles\":[\"Instruct-GPT\",\"关键流程与技术\"]},\"1632\":{\"title\":\"常见错误警告区块\",\"titles\":[\"训练Tokenizer\"]},\"1633\":{\"title\":\"研究背景\",\"titles\":[\"RLHF流程\"]},\"1634\":{\"title\":\"与传统强化学习的对比\",\"titles\":[\"Reward-Model\"]},\"1635\":{\"title\":\"Prefix-Tuning\",\"titles\":[]},\"1636\":{\"title\":\"核心观点\",\"titles\":[\"VeRA\"]},\"1637\":{\"title\":\"标签：语言模型、指令遵循、奖励评估、自我训练\",\"titles\":[\"Self-Reward\"]},\"1638\":{\"title\":\"元数据\",\"titles\":[\"X-LoRA\"]},\"1639\":{\"title\":\"常见错误\",\"titles\":[\"RLHF研究方法及研究总结\"]},\"1640\":{\"title\":\"Prompt Tuning\",\"titles\":[]},\"1641\":{\"title\":\"QLoRA\",\"titles\":[\"QAF 量化感知微调\",\"QAF方法\"]},\"1642\":{\"title\":\"操作步骤\",\"titles\":[\"DPO介绍及RLHF-PPO缺点\"]},\"1643\":{\"title\":\"介绍\",\"titles\":[]},\"1644\":{\"title\":\"MRR计算方法\",\"titles\":[\"RAG评估\",\"针对检索环节的评估\"]},\"1645\":{\"title\":\"技术术语转述\",\"titles\":[\"critic-model\"]},\"1646\":{\"title\":\"示例代码\",\"titles\":[\"高效深度学习模型训练框架选择与优化指南\"]},\"1647\":{\"title\":\"行动清单\",\"titles\":[\"相对位置编码与XLNet位置编码详解 深入理解Transformer机制\"]},\"1648\":{\"title\":\"3. 简单和困难任务区分\",\"titles\":[\"Agent评估框架汇总\",\"AgentBoard 的评估方法与指标\"]},\"1649\":{\"title\":\"1. 提示链（Prompt Chaining）\",\"titles\":[\"智能体系统分类\",\"工作流（Workflow）\"]},\"1650\":{\"title\":\"TDPO的优势\",\"titles\":[\"TDPO\"]},\"1651\":{\"title\":\"行动清单\",\"titles\":[\"MOE并行训练\"]},\"1652\":{\"title\":\"2. 智能截断\",\"titles\":[\"固定长度分块\",\"改进方法\"]},\"1653\":{\"title\":\"核心观点\",\"titles\":[\"AdaLoRA\"]},\"1654\":{\"title\":\"DAPO\",\"titles\":[]},\"1655\":{\"title\":\"Chain-of-Thought 思维链\",\"titles\":[]},\"1656\":{\"title\":\"💡 启发点\",\"titles\":[\"强化学习中的奖励利用与泛化问题\"]},\"1657\":{\"title\":\"步骤1：展开KL散度\",\"titles\":[\"DPO公式推导\",\"核心目标函数推导\",\"2. 目标函数变形\"]},\"1658\":{\"title\":\"参考文献\",\"titles\":[\"参考文献\"]},\"1659\":{\"title\":\"核心观点\",\"titles\":[\"DoRA\"]},\"1660\":{\"title\":\"内容摘要\",\"titles\":[\"LoRA+\"]},\"1661\":{\"title\":\"记忆（Memory）\",\"titles\":[]},\"1662\":{\"title\":\"一、基于规则的解析算法\",\"titles\":[\"RAG优化\"]},\"1663\":{\"title\":\"结合历史对话的重新表述\",\"titles\":[\"RAG优化中查询索引阶段\",\"索引/查询算法\",\"常见的向量搜索算法\",\"3.查询转换\"]},\"1664\":{\"title\":\"2. 能与外部数据有效集成\",\"titles\":[\"RAG流程和分类\",\"RAG的特点\"]},\"1665\":{\"title\":\"原理\",\"titles\":[\"基于语义分块\",\"NLTK 的文本切分功能\"]},\"1666\":{\"title\":\"强化学习优化目标\",\"titles\":[\"RL在NLP场景下的拓展\",\"重点段落\"]},\"1667\":{\"title\":\"离线（Offline）RLHF\",\"titles\":[\"在线与离线RLHF的比较与应用\",\"在线与离线RLHF的核心思想\"]},\"1668\":{\"title\":\"核心观点总结\",\"titles\":[\"LLaMA-Adapter\"]},\"1669\":{\"title\":\"GRPO\",\"titles\":[]},\"1670\":{\"title\":\"REINFORCE算法改进：RLOO与REINFORCE++\",\"titles\":[]},\"1671\":{\"title\":\"对比学习的损失函数\",\"titles\":[\"对比学习角度理解DPO\",\"重点段落\"]},\"1672\":{\"title\":\"系统的 Agentic 程度由什么决定？\",\"titles\":[\"与其讨论 Agent，不如讨论 Agentic\"]},\"1673\":{\"title\":\"核心观点总结\",\"titles\":[\"深入理解Prompt到Response的MDP模型分析\"]},\"1674\":{\"title\":\"Code Generation Agent\",\"titles\":[\"智能体的分类\",\"按行为模式分类\"]},\"1675\":{\"title\":\"理解DPO损失函数\",\"titles\":[\"深度偏好优化（DPO）损失函数解析与代码示例\"]},\"1676\":{\"title\":\"奖励机制的调整\",\"titles\":[\"Reference-Model\",\"重点内容\"]},\"1677\":{\"title\":\"操作步骤\",\"titles\":[\"Actor-Model\",\"文章内容\"]},\"1678\":{\"title\":\"标签：LoRA, 微调, 低秩矩阵, 大语言模型\",\"titles\":[\"LoRA\"]},\"1679\":{\"title\":\"内容摘要\",\"titles\":[\"QLoRA\"]},\"1680\":{\"title\":\"核心观点总结\",\"titles\":[\"P-Tuning V2\"]},\"1681\":{\"title\":\"核心观点\",\"titles\":[\"DPOP\"]},\"1682\":{\"title\":\"元数据\",\"titles\":[\"P-Tuning\"]},\"1683\":{\"title\":\"优势函数计算\",\"titles\":[\"Method\",\"重点段落\"]},\"1684\":{\"title\":\"核心理念\",\"titles\":[\"智能体的框架和应用\",\"GAIR/ToRL 框架\"]},\"1685\":{\"title\":\"强化学习目标修改\",\"titles\":[\"Instruct-GPT\",\"关键流程与技术\"]},\"1686\":{\"title\":\"行动清单\",\"titles\":[\"训练Tokenizer\"]},\"1687\":{\"title\":\"研究目标\",\"titles\":[\"RLHF流程\"]},\"1688\":{\"title\":\"聚合操作\",\"titles\":[\"Reward-Model\"]},\"1689\":{\"title\":\"元数据\",\"titles\":[\"Prefix-Tuning\"]},\"1690\":{\"title\":\"重点段落\",\"titles\":[\"VeRA\"]},\"1691\":{\"title\":\"日期：2025年4月12日\",\"titles\":[\"Self-Reward\"]},\"1692\":{\"title\":\"核心观点\",\"titles\":[\"X-LoRA\"]},\"1693\":{\"title\":\"💡 启发点\",\"titles\":[\"RLHF研究方法及研究总结\"]},\"1694\":{\"title\":\"元数据\",\"titles\":[\"Prompt Tuning\"]},\"1695\":{\"title\":\"PEFT 参数高效微调\",\"titles\":[\"QAF 量化感知微调\"]},\"1696\":{\"title\":\"常见错误\",\"titles\":[\"DPO介绍及RLHF-PPO缺点\"]},\"1697\":{\"title\":\"分类：机器学习技术\",\"titles\":[\"介绍\"]},\"1698\":{\"title\":\"MRR的意义\",\"titles\":[\"RAG评估\",\"针对检索环节的评估\"]},\"1699\":{\"title\":\"操作步骤\",\"titles\":[\"critic-model\"]},\"1700\":{\"title\":\"📈趋势预测\",\"titles\":[\"高效深度学习模型训练框架选择与优化指南\"]},\"1701\":{\"title\":\"4. 多回合交互\",\"titles\":[\"Agent评估框架汇总\",\"AgentBoard 的评估方法与指标\"]},\"1702\":{\"title\":\"定义\",\"titles\":[\"智能体系统分类\",\"工作流（Workflow）\",\"1. 提示链（Prompt Chaining）\"]},\"1703\":{\"title\":\"代码示例与计算步骤\",\"titles\":[\"TDPO\"]},\"1704\":{\"title\":\"路由与门控机制\",\"titles\":[\"MOE并行训练\",\"行动清单\"]},\"1705\":{\"title\":\"LangChain 的优化方案\",\"titles\":[\"固定长度分块\"]},\"1706\":{\"title\":\"重点段落\",\"titles\":[\"AdaLoRA\"]},\"1707\":{\"title\":\"元数据\",\"titles\":[\"DAPO\"]},\"1708\":{\"title\":\"CoT 概念原理\",\"titles\":[\"Chain-of-Thought 思维链\"]},\"1709\":{\"title\":\"行动清单\",\"titles\":[\"强化学习中的奖励利用与泛化问题\"]},\"1710\":{\"title\":\"ReMax-improvement\",\"titles\":[]},\"1711\":{\"title\":\"ReMax\",\"titles\":[]},\"1712\":{\"title\":\"步骤2：转换为最小化问题\",\"titles\":[\"DPO公式推导\",\"核心目标函数推导\",\"2. 目标函数变形\"]},\"1713\":{\"title\":\"重点段落\",\"titles\":[\"DoRA\"]},\"1714\":{\"title\":\"核心内容\",\"titles\":[\"LoRA+\"]},\"1715\":{\"title\":\"短期记忆与长期记忆\",\"titles\":[\"记忆（Memory）\"]},\"1716\":{\"title\":\"方法简介\",\"titles\":[\"RAG优化\",\"一、基于规则的解析算法\"]},\"1717\":{\"title\":\"假设文档嵌入（HyDE）\",\"titles\":[\"RAG优化中查询索引阶段\",\"索引/查询算法\",\"常见的向量搜索算法\",\"3.查询转换\"]},\"1718\":{\"title\":\"3. 数据隐私和安全保障\",\"titles\":[\"RAG流程和分类\",\"RAG的特点\"]},\"1719\":{\"title\":\"中文支持现状\",\"titles\":[\"基于语义分块\",\"NLTK 的文本切分功能\"]},\"1720\":{\"title\":\"行为约束优化目标\",\"titles\":[\"RL在NLP场景下的拓展\",\"重点段落\"]},\"1721\":{\"title\":\"关键步骤\",\"titles\":[\"在线与离线RLHF的比较与应用\"]},\"1722\":{\"title\":\"重点段落与数据\",\"titles\":[\"LLaMA-Adapter\"]},\"1723\":{\"title\":\"分类：自动推断为机器学习与强化学习\",\"titles\":[\"GRPO\"]},\"1724\":{\"title\":\"VAPO\",\"titles\":[]},\"1725\":{\"title\":\"HuggingFace TGI\",\"titles\":[]},\"1726\":{\"title\":\"元数据\",\"titles\":[\"REINFORCE算法改进：RLOO与REINFORCE++\"]},\"1727\":{\"title\":\"DPO中的损失函数\",\"titles\":[\"对比学习角度理解DPO\",\"重点段落\"]},\"1728\":{\"title\":\"1. 初步的 Agentic：路由器（Router）\",\"titles\":[\"与其讨论 Agent，不如讨论 Agentic\",\"系统的 Agentic 程度由什么决定？\"]},\"1729\":{\"title\":\"重点段落\",\"titles\":[\"深入理解Prompt到Response的MDP模型分析\"]},\"1730\":{\"title\":\"Program-aided LM\",\"titles\":[\"智能体的分类\",\"按行为模式分类\",\"Code Generation Agent\"]},\"1731\":{\"title\":\"核心代码解析\",\"titles\":[\"深度偏好优化（DPO）损失函数解析与代码示例\"]},\"1732\":{\"title\":\"奖励公式的具体表达\",\"titles\":[\"Reference-Model\",\"重点内容\"]},\"1733\":{\"title\":\"常见错误\",\"titles\":[\"Actor-Model\",\"文章内容\"]},\"1734\":{\"title\":\"日期：2025年4月12日\",\"titles\":[\"LoRA\"]},\"1735\":{\"title\":\"核心观点\",\"titles\":[\"QLoRA\"]},\"1736\":{\"title\":\"重点段落\",\"titles\":[\"P-Tuning V2\"]},\"1737\":{\"title\":\"重点段落\",\"titles\":[\"DPOP\"]},\"1738\":{\"title\":\"内容概述\",\"titles\":[\"P-Tuning\"]},\"1739\":{\"title\":\"奖励建模\",\"titles\":[\"Method\"]},\"1740\":{\"title\":\"具体做法\",\"titles\":[\"智能体的框架和应用\",\"GAIR/ToRL 框架\"]},\"1741\":{\"title\":\"警告区块\",\"titles\":[\"Instruct-GPT\"]},\"1742\":{\"title\":\"📈趋势预测\",\"titles\":[\"训练Tokenizer\"]},\"1743\":{\"title\":\"常见错误\",\"titles\":[\"RLHF流程\"]},\"1744\":{\"title\":\"操作步骤\",\"titles\":[\"Reward-Model\"]},\"1745\":{\"title\":\"核心观点总结\",\"titles\":[\"Prefix-Tuning\"]},\"1746\":{\"title\":\"1. VeRA的创新机制\",\"titles\":[\"VeRA\",\"重点段落\"]},\"1747\":{\"title\":\"核心观点总结\",\"titles\":[\"Self-Reward\"]},\"1748\":{\"title\":\"vLLM\",\"titles\":[]},\"1749\":{\"title\":\"重点内容\",\"titles\":[\"X-LoRA\"]},\"1750\":{\"title\":\"FlashAttention Forword流程\",\"titles\":[]},\"1751\":{\"title\":\"行动清单\",\"titles\":[\"RLHF研究方法及研究总结\"]},\"1752\":{\"title\":\"核心观点总结\",\"titles\":[\"Prompt Tuning\"]},\"1753\":{\"title\":\"PTQ 训练后量化\",\"titles\":[]},\"1754\":{\"title\":\"💡启发点\",\"titles\":[\"DPO介绍及RLHF-PPO缺点\"]},\"1755\":{\"title\":\"标签：PEFT, 微调, 大模型, 参数优化\",\"titles\":[\"介绍\",\"分类：机器学习技术\"]},\"1756\":{\"title\":\"示例计算\",\"titles\":[\"RAG评估\",\"针对检索环节的评估\"]},\"1757\":{\"title\":\"常见错误\",\"titles\":[\"critic-model\"]},\"1758\":{\"title\":\"[思考] 延伸问题\",\"titles\":[\"高效深度学习模型训练框架选择与优化指南\"]},\"1759\":{\"title\":\"5. 各项子能力分析\",\"titles\":[\"Agent评估框架汇总\",\"AgentBoard 的评估方法与指标\"]},\"1760\":{\"title\":\"适用场景\",\"titles\":[\"智能体系统分类\",\"工作流（Workflow）\",\"1. 提示链（Prompt Chaining）\"]},\"1761\":{\"title\":\"操作步骤\",\"titles\":[\"TDPO\",\"代码示例与计算步骤\"]},\"1762\":{\"title\":\"优化细节\",\"titles\":[\"MOE并行训练\",\"行动清单\"]},\"1763\":{\"title\":\"RecursiveCharacterTextSplitter\",\"titles\":[\"固定长度分块\",\"LangChain 的优化方案\"]},\"1764\":{\"title\":\"动态秩分配\",\"titles\":[\"AdaLoRA\",\"重点段落\"]},\"1765\":{\"title\":\"内容概述\",\"titles\":[\"DAPO\"]},\"1766\":{\"title\":\"CoT 和普通提示的区别\",\"titles\":[\"Chain-of-Thought 思维链\"]},\"1767\":{\"title\":\"标签\",\"titles\":[\"ReMax-improvement\"]},\"1768\":{\"title\":\"分类\",\"titles\":[\"ReMax\"]},\"1769\":{\"title\":\"3. 引入配分函数 Z(x)Z(x)Z(x)\",\"titles\":[\"DPO公式推导\",\"核心目标函数推导\"]},\"1770\":{\"title\":\"DoRA的基本步骤\",\"titles\":[\"DoRA\",\"重点段落\"]},\"1771\":{\"title\":\"LoRA+优化器创建\",\"titles\":[\"LoRA+\",\"核心内容\"]},\"1772\":{\"title\":\"短期记忆：上下文学习\",\"titles\":[\"记忆（Memory）\",\"短期记忆与长期记忆\"]},\"1773\":{\"title\":\"优点\",\"titles\":[\"RAG优化\",\"一、基于规则的解析算法\"]},\"1774\":{\"title\":\"退后提示（Step Back Prompting）\",\"titles\":[\"RAG优化中查询索引阶段\",\"索引/查询算法\",\"常见的向量搜索算法\",\"3.查询转换\"]},\"1775\":{\"title\":\"4. 表现效果因多方面因素而异\",\"titles\":[\"RAG流程和分类\",\"RAG的特点\"]},\"1776\":{\"title\":\"在 LangChain 中的应用\",\"titles\":[\"基于语义分块\"]},\"1777\":{\"title\":\"常见错误\",\"titles\":[\"RL在NLP场景下的拓展\"]},\"1778\":{\"title\":\"常见错误\",\"titles\":[\"在线与离线RLHF的比较与应用\"]},\"1779\":{\"title\":\"操作步骤\",\"titles\":[\"LLaMA-Adapter\"]},\"1780\":{\"title\":\"标签：PPO优化、GRPO、强化学习、Actor-Critic、LLM\",\"titles\":[\"GRPO\"]},\"1781\":{\"title\":\"分类：自动推断\",\"titles\":[\"VAPO\"]},\"1782\":{\"title\":\"Prefill和Decode\",\"titles\":[\"HuggingFace TGI\"]},\"1783\":{\"title\":\"核心观点总结\",\"titles\":[\"REINFORCE算法改进：RLOO与REINFORCE++\"]},\"1784\":{\"title\":\"操作步骤\",\"titles\":[\"对比学习角度理解DPO\"]},\"1785\":{\"title\":\"介绍\",\"titles\":[]},\"1786\":{\"title\":\"2. 多级路由决策：介于路由器与状态机之间\",\"titles\":[\"与其讨论 Agent，不如讨论 Agentic\",\"系统的 Agentic 程度由什么决定？\"]},\"1787\":{\"title\":\"单步MDP模型\",\"titles\":[\"深入理解Prompt到Response的MDP模型分析\",\"重点段落\"]},\"1788\":{\"title\":\"Tool-Integrated Reasoning Agent\",\"titles\":[\"智能体的分类\",\"按行为模式分类\",\"Code Generation Agent\"]},\"1789\":{\"title\":\"操作步骤\",\"titles\":[\"深度偏好优化（DPO）损失函数解析与代码示例\"]},\"1790\":{\"title\":\"操作步骤\",\"titles\":[\"Reference-Model\"]},\"1791\":{\"title\":\"💡启发点\",\"titles\":[\"Actor-Model\",\"文章内容\"]},\"1792\":{\"title\":\"文章概述\",\"titles\":[\"LoRA\"]},\"1793\":{\"title\":\"技术术语通俗解释\",\"titles\":[\"QLoRA\"]},\"1794\":{\"title\":\"技术术语通俗转述\",\"titles\":[\"P-Tuning V2\"]},\"1795\":{\"title\":\"DPOP算法的痛点解决\",\"titles\":[\"DPOP\",\"重点段落\"]},\"1796\":{\"title\":\"主要观点\",\"titles\":[\"P-Tuning\"]},\"1797\":{\"title\":\"奖励建模核心观点\",\"titles\":[\"Method\"]},\"1798\":{\"title\":\"OpenManus/OpenManus-RL 框架\",\"titles\":[\"智能体的框架和应用\"]},\"1799\":{\"title\":\"💡启发点\",\"titles\":[\"Instruct-GPT\"]},\"1800\":{\"title\":\"后续追踪方向\",\"titles\":[\"训练Tokenizer\"]},\"1801\":{\"title\":\"💡启发点\",\"titles\":[\"RLHF流程\"]},\"1802\":{\"title\":\"常见错误\",\"titles\":[\"Reward-Model\"]},\"1803\":{\"title\":\"重点段落\",\"titles\":[\"Prefix-Tuning\"]},\"1804\":{\"title\":\"2. 微调过程\",\"titles\":[\"VeRA\",\"重点段落\"]},\"1805\":{\"title\":\"实现方法\",\"titles\":[\"Self-Reward\"]},\"1806\":{\"title\":\"标准Attention与Safe softmax\",\"titles\":[]},\"1807\":{\"title\":\"计算与内存限制\",\"titles\":[]},\"1808\":{\"title\":\"vLLM\",\"titles\":[\"vLLM\"]},\"1809\":{\"title\":\"动态缩放机制\",\"titles\":[\"X-LoRA\",\"重点内容\"]},\"1810\":{\"title\":\"Tiling 分块计算\",\"titles\":[\"FlashAttention Forword流程\"]},\"1811\":{\"title\":\"后续追踪\",\"titles\":[\"RLHF研究方法及研究总结\"]},\"1812\":{\"title\":\"重点段落\",\"titles\":[\"Prompt Tuning\"]},\"1813\":{\"title\":\"QAT 插入“伪量化节点”后微调\",\"titles\":[\"PTQ 训练后量化\"]},\"1814\":{\"title\":\"行动清单\",\"titles\":[\"DPO介绍及RLHF-PPO缺点\"]},\"1815\":{\"title\":\"日期：2025年4月12日\",\"titles\":[\"介绍\",\"分类：机器学习技术\"]},\"1816\":{\"title\":\"MRR代码实现\",\"titles\":[\"RAG评估\",\"针对检索环节的评估\"]},\"1817\":{\"title\":\"代码示例\",\"titles\":[\"critic-model\"]},\"1818\":{\"title\":\"行动清单\",\"titles\":[\"高效深度学习模型训练框架选择与优化指南\"]},\"1819\":{\"title\":\"6. 探索能力\",\"titles\":[\"Agent评估框架汇总\",\"AgentBoard 的评估方法与指标\"]},\"1820\":{\"title\":\"示例\",\"titles\":[\"智能体系统分类\",\"工作流（Workflow）\",\"1. 提示链（Prompt Chaining）\"]},\"1821\":{\"title\":\"常见错误\",\"titles\":[\"TDPO\"]},\"1822\":{\"title\":\"操作步骤\",\"titles\":[\"MOE并行训练\"]},\"1823\":{\"title\":\"使用示例\",\"titles\":[\"固定长度分块\"]},\"1824\":{\"title\":\"SVD参数化增量更新\",\"titles\":[\"AdaLoRA\",\"重点段落\"]},\"1825\":{\"title\":\"DAPO算法的核心改进\",\"titles\":[\"DAPO\",\"内容概述\"]},\"1826\":{\"title\":\"Zero-Shot-CoT 与 Few-Shot-CoT\",\"titles\":[\"Chain-of-Thought 思维链\"]},\"1827\":{\"title\":\"推理耗时\",\"titles\":[]},\"1828\":{\"title\":\"日期\",\"titles\":[\"ReMax-improvement\"]},\"1829\":{\"title\":\"标签\",\"titles\":[\"ReMax\"]},\"1830\":{\"title\":\"关键操作：构造指数形式\",\"titles\":[\"DPO公式推导\",\"核心目标函数推导\",\"3. 引入配分函数 Z(x)Z(x)Z(x)\"]},\"1831\":{\"title\":\"代码示例\",\"titles\":[\"DoRA\",\"重点段落\"]},\"1832\":{\"title\":\"调整Trainer类方法\",\"titles\":[\"LoRA+\",\"核心内容\"]},\"1833\":{\"title\":\"长期记忆\",\"titles\":[\"记忆（Memory）\",\"短期记忆与长期记忆\"]},\"1834\":{\"title\":\"缺点\",\"titles\":[\"RAG优化\",\"一、基于规则的解析算法\"]},\"1835\":{\"title\":\"多查询检索/多路召回（Multi Query Retrieval）\",\"titles\":[\"RAG优化中查询索引阶段\",\"索引/查询算法\",\"常见的向量搜索算法\",\"3.查询转换\"]},\"1836\":{\"title\":\"RAG流程与分类\",\"titles\":[]},\"1837\":{\"title\":\"使用示例\",\"titles\":[\"基于语义分块\",\"在 LangChain 中的应用\"]},\"1838\":{\"title\":\"💡启发点\",\"titles\":[\"RL在NLP场景下的拓展\"]},\"1839\":{\"title\":\"行动清单\",\"titles\":[\"在线与离线RLHF的比较与应用\"]},\"1840\":{\"title\":\"常见错误\",\"titles\":[\"LLaMA-Adapter\"]},\"1841\":{\"title\":\"日期：2025年4月12日\",\"titles\":[\"GRPO\"]},\"1842\":{\"title\":\"标签：强化学习、VAPO算法、推理任务\",\"titles\":[\"VAPO\"]},\"1843\":{\"title\":\"Concatenate和Filter\",\"titles\":[\"HuggingFace TGI\"]},\"1844\":{\"title\":\"重点段落\",\"titles\":[\"REINFORCE算法改进：RLOO与REINFORCE++\"]},\"1845\":{\"title\":\"常见错误\",\"titles\":[\"对比学习角度理解DPO\"]},\"1846\":{\"title\":\"核心观点总结\",\"titles\":[\"介绍\"]},\"1847\":{\"title\":\"3. 状态机（State Machine）：允许循环运行\",\"titles\":[\"与其讨论 Agent，不如讨论 Agentic\",\"系统的 Agentic 程度由什么决定？\"]},\"1848\":{\"title\":\"多步MDP模型\",\"titles\":[\"深入理解Prompt到Response的MDP模型分析\",\"重点段落\"]},\"1849\":{\"title\":\"TaskWeaver\",\"titles\":[\"智能体的分类\",\"按行为模式分类\",\"Code Generation Agent\"]},\"1850\":{\"title\":\"常见错误\",\"titles\":[\"深度偏好优化（DPO）损失函数解析与代码示例\"]},\"1851\":{\"title\":\"常见错误\",\"titles\":[\"Reference-Model\"]},\"1852\":{\"title\":\"行动清单\",\"titles\":[\"Actor-Model\",\"文章内容\"]},\"1853\":{\"title\":\"核心观点\",\"titles\":[\"LoRA\"]},\"1854\":{\"title\":\"首Token时延优化\",\"titles\":[]},\"1855\":{\"title\":\"操作步骤\",\"titles\":[\"QLoRA\"]},\"1856\":{\"title\":\"实施步骤\",\"titles\":[\"P-Tuning V2\"]},\"1857\":{\"title\":\"正则化系数的应用\",\"titles\":[\"DPOP\",\"重点段落\"]},\"1858\":{\"title\":\"操作步骤\",\"titles\":[\"P-Tuning\"]},\"1859\":{\"title\":\"训练模板设计\",\"titles\":[\"Method\"]},\"1860\":{\"title\":\"核心理念\",\"titles\":[\"智能体的框架和应用\",\"OpenManus/OpenManus-RL 框架\"]},\"1861\":{\"title\":\"行动清单\",\"titles\":[\"Instruct-GPT\"]},\"1862\":{\"title\":\"显存优化与推理显存分析\",\"titles\":[]},\"1863\":{\"title\":\"行动清单\",\"titles\":[\"RLHF流程\"]},\"1864\":{\"title\":\"💡启发点\",\"titles\":[\"Reward-Model\"]},\"1865\":{\"title\":\"Prefix Tuning的实现\",\"titles\":[\"Prefix-Tuning\",\"重点段落\"]},\"1866\":{\"title\":\"3. 技术术语解释\",\"titles\":[\"VeRA\",\"重点段落\"]},\"1867\":{\"title\":\"初始化与种子数据\",\"titles\":[\"Self-Reward\",\"实现方法\"]},\"1868\":{\"title\":\"标准Attention\",\"titles\":[\"标准Attention与Safe softmax\"]},\"1869\":{\"title\":\"近似注意力方法\",\"titles\":[\"计算与内存限制\"]},\"1870\":{\"title\":\"Prefill\",\"titles\":[\"vLLM\",\"vLLM\"]},\"1871\":{\"title\":\"XLoraLinearLayer的前向传播\",\"titles\":[\"X-LoRA\",\"重点内容\"]},\"1872\":{\"title\":\"分块计算的难点\",\"titles\":[\"FlashAttention Forword流程\"]},\"1873\":{\"title\":\"Prompt Tuning 的基本原理\",\"titles\":[\"Prompt Tuning\",\"重点段落\"]},\"1874\":{\"title\":\"训练后量化（PTQ）\",\"titles\":[\"PTQ 训练后量化\"]},\"1875\":{\"title\":\"核心观点总结\",\"titles\":[\"介绍\"]},\"1876\":{\"title\":\"MRR 衡量标准\",\"titles\":[\"RAG评估\",\"针对检索环节的评估\"]},\"1877\":{\"title\":\"💡启发点\",\"titles\":[\"critic-model\"]},\"1878\":{\"title\":\"后续追踪\",\"titles\":[\"高效深度学习模型训练框架选择与优化指南\"]},\"1879\":{\"title\":\"2. 路由（Routing）\",\"titles\":[\"智能体系统分类\",\"工作流（Workflow）\"]},\"1880\":{\"title\":\"行动清单\",\"titles\":[\"TDPO\"]},\"1881\":{\"title\":\"常见错误\",\"titles\":[\"MOE并行训练\"]},\"1882\":{\"title\":\"参数说明\",\"titles\":[\"固定长度分块\"]},\"1883\":{\"title\":\"核心代码解析\",\"titles\":[\"AdaLoRA\",\"重点段落\"]},\"1884\":{\"title\":\"关键技术改进\",\"titles\":[\"DAPO\",\"内容概述\",\"DAPO算法的核心改进\"]},\"1885\":{\"title\":\"Zero-Shot-CoT\",\"titles\":[\"Chain-of-Thought 思维链\",\"Zero-Shot-CoT 与 Few-Shot-CoT\"]},\"1886\":{\"title\":\"推理机制\",\"titles\":[\"推理耗时\"]},\"1887\":{\"title\":\"内容摘要\",\"titles\":[\"ReMax-improvement\"]},\"1888\":{\"title\":\"日期\",\"titles\":[\"ReMax\"]},\"1889\":{\"title\":\"4. 定义最优策略 π∗\\\\pi^*π∗\",\"titles\":[\"DPO公式推导\",\"核心目标函数推导\"]},\"1890\":{\"title\":\"操作步骤\",\"titles\":[\"DoRA\",\"重点段落\"]},\"1891\":{\"title\":\"公式调整\",\"titles\":[\"LoRA+\",\"核心内容\"]},\"1892\":{\"title\":\"记忆的定义与分类\",\"titles\":[\"记忆（Memory）\"]},\"1893\":{\"title\":\"二、基于多模态大模型的解析技术\",\"titles\":[\"RAG优化\"]},\"1894\":{\"title\":\"4.检索参数\",\"titles\":[\"RAG优化中查询索引阶段\",\"索引/查询算法\",\"常见的向量搜索算法\"]},\"1895\":{\"title\":\"表现效果因多方面因素而异\",\"titles\":[\"RAG流程与分类\"]},\"1896\":{\"title\":\"扩展：基于 spaCy 的文本切块\",\"titles\":[\"基于语义分块\"]},\"1897\":{\"title\":\"思考\",\"titles\":[\"RL在NLP场景下的拓展\"]},\"1898\":{\"title\":\"💡启发点\",\"titles\":[\"LLaMA-Adapter\"]},\"1899\":{\"title\":\"核心观点\",\"titles\":[\"GRPO\"]},\"1900\":{\"title\":\"日期：2025年4月12日\",\"titles\":[\"VAPO\"]},\"1901\":{\"title\":\"RLOO的分析\",\"titles\":[\"REINFORCE算法改进：RLOO与REINFORCE++\",\"重点段落\"]},\"1902\":{\"title\":\"行动清单\",\"titles\":[\"对比学习角度理解DPO\"]},\"1903\":{\"title\":\"重点段落与数据\",\"titles\":[\"介绍\"]},\"1904\":{\"title\":\"4. 自主 Agent（Autonomous Agent）：顶层智能体\",\"titles\":[\"与其讨论 Agent，不如讨论 Agentic\",\"系统的 Agentic 程度由什么决定？\"]},\"1905\":{\"title\":\"奖励机制设计\",\"titles\":[\"深入理解Prompt到Response的MDP模型分析\",\"重点段落\"]},\"1906\":{\"title\":\"Observation-based Agent\",\"titles\":[\"智能体的分类\",\"按行为模式分类\"]},\"1907\":{\"title\":\"行动清单\",\"titles\":[\"深度偏好优化（DPO）损失函数解析与代码示例\"]},\"1908\":{\"title\":\"💡 启发点\",\"titles\":[\"Reference-Model\"]},\"1909\":{\"title\":\"重点段落\",\"titles\":[\"LoRA\"]},\"1910\":{\"title\":\"首Token时延\",\"titles\":[\"首Token时延优化\"]},\"1911\":{\"title\":\"常见错误\",\"titles\":[\"QLoRA\"]},\"1912\":{\"title\":\"代码实现\",\"titles\":[\"P-Tuning V2\"]},\"1913\":{\"title\":\"策略模型的拟合\",\"titles\":[\"DPOP\",\"重点段落\"]},\"1914\":{\"title\":\"常见错误\",\"titles\":[\"P-Tuning\"]},\"1915\":{\"title\":\"性能\",\"titles\":[\"Method\"]},\"1916\":{\"title\":\"模型显存总体分析\",\"titles\":[]},\"1917\":{\"title\":\"具体总结\",\"titles\":[\"智能体的框架和应用\",\"OpenManus/OpenManus-RL 框架\"]},\"1918\":{\"title\":\"后续追踪\",\"titles\":[\"Instruct-GPT\"]},\"1919\":{\"title\":\"元数据\",\"titles\":[\"显存优化与推理显存分析\"]},\"1920\":{\"title\":\"后续追踪\",\"titles\":[\"RLHF流程\"]},\"1921\":{\"title\":\"行动清单\",\"titles\":[\"Reward-Model\"]},\"1922\":{\"title\":\"应用于不同模型结构\",\"titles\":[\"Prefix-Tuning\",\"重点段落\"]},\"1923\":{\"title\":\"操作步骤\",\"titles\":[\"VeRA\"]},\"1924\":{\"title\":\"自我指令创建\",\"titles\":[\"Self-Reward\",\"实现方法\"]},\"1925\":{\"title\":\"标准Safe softmax\",\"titles\":[\"标准Attention与Safe softmax\"]},\"1926\":{\"title\":\"注意区分FLOPS和FLOPs\",\"titles\":[\"计算与内存限制\",\"近似注意力方法\"]},\"1927\":{\"title\":\"Decode\",\"titles\":[\"vLLM\",\"vLLM\"]},\"1928\":{\"title\":\"代码示例\",\"titles\":[\"X-LoRA\",\"重点内容\"]},\"1929\":{\"title\":\"FlashAttention的做法\",\"titles\":[\"FlashAttention Forword流程\"]},\"1930\":{\"title\":\"Prompt Ensembling 方法\",\"titles\":[\"Prompt Tuning\",\"重点段落\"]},\"1931\":{\"title\":\"PTQ方法\",\"titles\":[\"PTQ 训练后量化\",\"训练后量化（PTQ）\"]},\"1932\":{\"title\":\"重点段落\",\"titles\":[\"介绍\"]},\"1933\":{\"title\":\"Hits Rate 命中率\",\"titles\":[\"RAG评估\",\"针对检索环节的评估\"]},\"1934\":{\"title\":\"行动清单\",\"titles\":[\"critic-model\"]},\"1935\":{\"title\":\"定义\",\"titles\":[\"智能体系统分类\",\"工作流（Workflow）\",\"2. 路由（Routing）\"]},\"1936\":{\"title\":\"代码示例\",\"titles\":[\"MOE并行训练\"]},\"1937\":{\"title\":\"1. chunk_size\",\"titles\":[\"固定长度分块\",\"参数说明\"]},\"1938\":{\"title\":\"操作步骤\",\"titles\":[\"AdaLoRA\"]},\"1939\":{\"title\":\"技术术语简化\",\"titles\":[\"DAPO\"]},\"1940\":{\"title\":\"Few-Shot-CoT\",\"titles\":[\"Chain-of-Thought 思维链\",\"Zero-Shot-CoT 与 Few-Shot-CoT\"]},\"1941\":{\"title\":\"传统推理方式：\",\"titles\":[\"推理耗时\",\"推理机制\"]},\"1942\":{\"title\":\"策略梯度与PPO回顾\",\"titles\":[\"ReMax-improvement\"]},\"1943\":{\"title\":\"内容摘要\",\"titles\":[\"ReMax\"]},\"1944\":{\"title\":\"5. KL散度最小化\",\"titles\":[\"DPO公式推导\",\"核心目标函数推导\"]},\"1945\":{\"title\":\"常见错误\",\"titles\":[\"DoRA\"]},\"1946\":{\"title\":\"常见错误\",\"titles\":[\"LoRA+\"]},\"1947\":{\"title\":\"感官记忆\",\"titles\":[\"记忆（Memory）\",\"记忆的定义与分类\"]},\"1948\":{\"title\":\"方法简介\",\"titles\":[\"RAG优化\",\"二、基于多模态大模型的解析技术\"]},\"1949\":{\"title\":\"稀疏和稠密搜索权重\",\"titles\":[\"RAG优化中查询索引阶段\",\"索引/查询算法\",\"常见的向量搜索算法\",\"4.检索参数\"]},\"1950\":{\"title\":\"RAG整体思路\",\"titles\":[\"RAG流程与分类\"]},\"1951\":{\"title\":\"使用方法\",\"titles\":[\"基于语义分块\",\"扩展：基于 spaCy 的文本切块\"]},\"1952\":{\"title\":\"行动清单\",\"titles\":[\"RL在NLP场景下的拓展\"]},\"1953\":{\"title\":\"行动清单\",\"titles\":[\"LLaMA-Adapter\"]},\"1954\":{\"title\":\"重点段落\",\"titles\":[\"GRPO\",\"核心观点\"]},\"1955\":{\"title\":\"核心观点总结\",\"titles\":[\"VAPO\"]},\"1956\":{\"title\":\"REINFORCE++概述\",\"titles\":[\"REINFORCE算法改进：RLOO与REINFORCE++\",\"重点段落\"]},\"1957\":{\"title\":\"加速计算（Fast）\",\"titles\":[\"介绍\",\"重点段落与数据\"]},\"1958\":{\"title\":\"操作步骤\",\"titles\":[\"深入理解Prompt到Response的MDP模型分析\"]},\"1959\":{\"title\":\"具体方法\",\"titles\":[\"智能体的分类\",\"按行为模式分类\"]},\"1960\":{\"title\":\"数据转换\",\"titles\":[\"深度偏好优化（DPO）损失函数解析与代码示例\"]},\"1961\":{\"title\":\"行动清单\",\"titles\":[\"Reference-Model\"]},\"1962\":{\"title\":\"1. LoRA的实现\",\"titles\":[\"LoRA\",\"重点段落\"]},\"1963\":{\"title\":\"首个token的推理延迟\",\"titles\":[\"首Token时延优化\",\"首Token时延\"]},\"1964\":{\"title\":\"💡启发点\",\"titles\":[\"QLoRA\"]},\"1965\":{\"title\":\"常见错误\",\"titles\":[\"P-Tuning V2\"]},\"1966\":{\"title\":\"操作步骤\",\"titles\":[\"DPOP\"]},\"1967\":{\"title\":\"💡启发点\",\"titles\":[\"P-Tuning\"]},\"1968\":{\"title\":\"self-evolution\",\"titles\":[\"Method\"]},\"1969\":{\"title\":\"元数据\",\"titles\":[\"模型显存总体分析\"]},\"1970\":{\"title\":\"RAGEN：推理驱动的交互优化框架\",\"titles\":[\"智能体的框架和应用\",\"OpenManus/OpenManus-RL 框架\"]},\"1971\":{\"title\":\"[思考]板块\",\"titles\":[\"Instruct-GPT\"]},\"1972\":{\"title\":\"内容总结\",\"titles\":[\"显存优化与推理显存分析\"]},\"1973\":{\"title\":\"[思考]\",\"titles\":[\"RLHF流程\"]},\"1974\":{\"title\":\"防止训练不稳定\",\"titles\":[\"Prefix-Tuning\",\"重点段落\"]},\"1975\":{\"title\":\"常见错误\",\"titles\":[\"VeRA\"]},\"1976\":{\"title\":\"指令遵循训练\",\"titles\":[\"Self-Reward\",\"实现方法\"]},\"1977\":{\"title\":\"计算带宽与内存带宽\",\"titles\":[\"计算与内存限制\"]},\"1978\":{\"title\":\"常规KV cache分配\",\"titles\":[\"vLLM\",\"vLLM\"]},\"1979\":{\"title\":\"💡 启发点\",\"titles\":[\"X-LoRA\",\"重点内容\"]},\"1980\":{\"title\":\"引入额外的统计量\",\"titles\":[\"FlashAttention Forword流程\",\"FlashAttention的做法\"]},\"1981\":{\"title\":\"Hard Prompt 与 Soft Prompt 的区别\",\"titles\":[\"Prompt Tuning\",\"重点段落\"]},\"1982\":{\"title\":\"LLM.int8()\",\"titles\":[\"PTQ 训练后量化\",\"训练后量化（PTQ）\",\"PTQ方法\"]},\"1983\":{\"title\":\"技术术语通俗解释\",\"titles\":[\"介绍\"]},\"1984\":{\"title\":\"代码示例：计算 Precision\",\"titles\":[\"RAG评估\",\"针对检索环节的评估\"]},\"1985\":{\"title\":\"3. 并行化（Parallelization）\",\"titles\":[\"智能体系统分类\",\"工作流（Workflow）\"]},\"1986\":{\"title\":\"💡启发点\",\"titles\":[\"MOE并行训练\"]},\"1987\":{\"title\":\"2. chunk_overlap\",\"titles\":[\"固定长度分块\",\"参数说明\"]},\"1988\":{\"title\":\"常见错误\",\"titles\":[\"AdaLoRA\"]},\"1989\":{\"title\":\"操作步骤\",\"titles\":[\"DAPO\"]},\"1990\":{\"title\":\"CoT 改进方法\",\"titles\":[\"Chain-of-Thought 思维链\"]},\"1991\":{\"title\":\"过程建模两种方式：\",\"titles\":[\"推理耗时\",\"推理机制\"]},\"1992\":{\"title\":\"重点段落\",\"titles\":[\"ReMax-improvement\",\"策略梯度与PPO回顾\"]},\"1993\":{\"title\":\"策略梯度与PPO回顾\",\"titles\":[\"ReMax\"]},\"1994\":{\"title\":\"6. 奖励函数反推\",\"titles\":[\"DPO公式推导\",\"核心目标函数推导\"]},\"1995\":{\"title\":\"训练阶段的显存分析\",\"titles\":[]},\"1996\":{\"title\":\"💡启发点\",\"titles\":[\"DoRA\"]},\"1997\":{\"title\":\"行动清单\",\"titles\":[\"LoRA+\"]},\"1998\":{\"title\":\"短时记忆（STM）或工作记忆\",\"titles\":[\"记忆（Memory）\",\"记忆的定义与分类\"]},\"1999\":{\"title\":\"可选的基座模型\",\"titles\":[\"RAG优化\",\"二、基于多模态大模型的解析技术\"]},\"2000\":{\"title\":\"结果数量（topK）\",\"titles\":[\"RAG优化中查询索引阶段\",\"索引/查询算法\",\"常见的向量搜索算法\",\"4.检索参数\"]},\"2001\":{\"title\":\"知识文档的准备\",\"titles\":[\"RAG流程与分类\"]},\"2002\":{\"title\":\"提示\",\"titles\":[\"基于语义分块\",\"扩展：基于 spaCy 的文本切块\"]},\"2003\":{\"title\":\"后续追踪\",\"titles\":[\"RL在NLP场景下的拓展\"]},\"2004\":{\"title\":\"技术术语转述\",\"titles\":[\"GRPO\",\"核心观点\"]},\"2005\":{\"title\":\"重点段落\",\"titles\":[\"VAPO\"]},\"2006\":{\"title\":\"Accelerate\",\"titles\":[]},\"2007\":{\"title\":\"操作步骤\",\"titles\":[\"REINFORCE算法改进：RLOO与REINFORCE++\"]},\"2008\":{\"title\":\"显存节省（Memory-efficient）\",\"titles\":[\"介绍\",\"重点段落与数据\"]},\"2009\":{\"title\":\"常见错误\",\"titles\":[\"深入理解Prompt到Response的MDP模型分析\"]},\"2010\":{\"title\":\"DeepSpeed\",\"titles\":[]},\"2011\":{\"title\":\"Reasoning and Acting\",\"titles\":[\"智能体的分类\",\"按行为模式分类\",\"具体方法\"]},\"2012\":{\"title\":\"公式显示\",\"titles\":[\"深度偏好优化（DPO）损失函数解析与代码示例\"]},\"2013\":{\"title\":\"2. 参数更新与内在秩\",\"titles\":[\"LoRA\",\"重点段落\"]},\"2014\":{\"title\":\"后续每个token的推理延迟\",\"titles\":[\"首Token时延优化\",\"首Token时延\"]},\"2015\":{\"title\":\"行动清单\",\"titles\":[\"QLoRA\"]},\"2016\":{\"title\":\"Megatron-LM\",\"titles\":[]},\"2017\":{\"title\":\"行动清单\",\"titles\":[\"P-Tuning V2\"]},\"2018\":{\"title\":\"常见错误\",\"titles\":[\"DPOP\"]},\"2019\":{\"title\":\"行动清单\",\"titles\":[\"P-Tuning\"]},\"2020\":{\"title\":\"关键段落\",\"titles\":[\"Method\"]},\"2021\":{\"title\":\"核心观点总结\",\"titles\":[\"模型显存总体分析\"]},\"2022\":{\"title\":\"一句话总结\",\"titles\":[\"智能体的框架和应用\",\"OpenManus/OpenManus-RL 框架\",\"RAGEN：推理驱动的交互优化框架\"]},\"2023\":{\"title\":\"推理阶段显存分析\",\"titles\":[\"显存优化与推理显存分析\",\"内容总结\"]},\"2024\":{\"title\":\"技术术语通俗解释\",\"titles\":[\"Prefix-Tuning\"]},\"2025\":{\"title\":\"💡启发点\",\"titles\":[\"VeRA\"]},\"2026\":{\"title\":\"迭代训练\",\"titles\":[\"Self-Reward\",\"实现方法\"]},\"2027\":{\"title\":\"性能受限类型\",\"titles\":[\"计算与内存限制\",\"计算带宽与内存带宽\"]},\"2028\":{\"title\":\"警告区块\",\"titles\":[\"X-LoRA\"]},\"2029\":{\"title\":\"Megatron和DeepSpeed后端实现的区别\",\"titles\":[]},\"2030\":{\"title\":\"公式说明\",\"titles\":[\"FlashAttention Forword流程\",\"FlashAttention的做法\"]},\"2031\":{\"title\":\"X-ray\",\"titles\":[]},\"2032\":{\"title\":\"技术术语转述\",\"titles\":[\"Prompt Tuning\"]},\"2033\":{\"title\":\"SmoothQuant\",\"titles\":[\"PTQ 训练后量化\",\"训练后量化（PTQ）\",\"PTQ方法\"]},\"2034\":{\"title\":\"操作步骤\",\"titles\":[\"介绍\"]},\"2035\":{\"title\":\"NDCG：归一化折损累计增益\",\"titles\":[\"RAG评估\",\"针对检索环节的评估\"]},\"2036\":{\"title\":\"开源数据集\",\"titles\":[]},\"2037\":{\"title\":\"定义\",\"titles\":[\"智能体系统分类\",\"工作流（Workflow）\",\"3. 并行化（Parallelization）\"]},\"2038\":{\"title\":\"行动清单\",\"titles\":[\"MOE并行训练\"]},\"2039\":{\"title\":\"3. length_function\",\"titles\":[\"固定长度分块\",\"参数说明\"]},\"2040\":{\"title\":\"行动清单\",\"titles\":[\"AdaLoRA\"]},\"2041\":{\"title\":\"常见错误\",\"titles\":[\"DAPO\"]},\"2042\":{\"title\":\"CoT-SC：Self Consistency\",\"titles\":[\"Chain-of-Thought 思维链\",\"CoT 改进方法\"]},\"2043\":{\"title\":\"瓶颈分析：浮点运算的主要来源\",\"titles\":[\"推理耗时\",\"推理机制\"]},\"2044\":{\"title\":\"PPO算法简化\",\"titles\":[\"ReMax-improvement\",\"策略梯度与PPO回顾\"]},\"2045\":{\"title\":\"重点段落\",\"titles\":[\"ReMax\",\"策略梯度与PPO回顾\"]},\"2046\":{\"title\":\"7. 偏好概率模型\",\"titles\":[\"DPO公式推导\",\"核心目标函数推导\"]},\"2047\":{\"title\":\"元数据\",\"titles\":[\"训练阶段的显存分析\"]},\"2048\":{\"title\":\"行动清单\",\"titles\":[\"DoRA\"]},\"2049\":{\"title\":\"长时记忆（LTM）\",\"titles\":[\"记忆（Memory）\",\"记忆的定义与分类\"]},\"2050\":{\"title\":\"Prompt示例\",\"titles\":[\"RAG优化\",\"二、基于多模态大模型的解析技术\"]},\"2051\":{\"title\":\"相似度度量方法\",\"titles\":[\"RAG优化中查询索引阶段\",\"索引/查询算法\",\"常见的向量搜索算法\",\"4.检索参数\"]},\"2052\":{\"title\":\"转换为纯文本数据\",\"titles\":[\"RAG流程与分类\",\"知识文档的准备\"]},\"2053\":{\"title\":\"操作步骤\",\"titles\":[\"GRPO\"]},\"2054\":{\"title\":\"Value-model-based V.S. Value-model-free\",\"titles\":[\"VAPO\",\"重点段落\"]},\"2055\":{\"title\":\"Accelerate\",\"titles\":[\"Accelerate\"]},\"2056\":{\"title\":\"常见错误\",\"titles\":[\"REINFORCE算法改进：RLOO与REINFORCE++\"]},\"2057\":{\"title\":\"精确注意力（Exact Attention）\",\"titles\":[\"介绍\",\"重点段落与数据\"]},\"2058\":{\"title\":\"💡 启发点\",\"titles\":[\"深入理解Prompt到Response的MDP模型分析\"]},\"2059\":{\"title\":\"混合精度训练\",\"titles\":[\"DeepSpeed\"]},\"2060\":{\"title\":\"流程及与CoT和Act-only方法的对比\",\"titles\":[\"智能体的分类\",\"按行为模式分类\",\"具体方法\"]},\"2061\":{\"title\":\"来源标注\",\"titles\":[\"深度偏好优化（DPO）损失函数解析与代码示例\"]},\"2062\":{\"title\":\"3. 矩阵初始化策略\",\"titles\":[\"LoRA\",\"重点段落\"]},\"2063\":{\"title\":\"数据多样性探索\",\"titles\":[]},\"2064\":{\"title\":\"优化System Prompt\",\"titles\":[\"首Token时延优化\"]},\"2065\":{\"title\":\"数据转换\",\"titles\":[\"QLoRA\"]},\"2066\":{\"title\":\"Megatron-LM\",\"titles\":[\"Megatron-LM\"]},\"2067\":{\"title\":\"数据生产合成与质量过滤\",\"titles\":[]},\"2068\":{\"title\":\"💡启发点\",\"titles\":[\"DPOP\"]},\"2069\":{\"title\":\"数据转换\",\"titles\":[\"P-Tuning\"]},\"2070\":{\"title\":\"自我进化过程\",\"titles\":[\"Method\",\"关键段落\"]},\"2071\":{\"title\":\"重点段落与数据\",\"titles\":[\"模型显存总体分析\"]},\"2072\":{\"title\":\"具体实现\",\"titles\":[\"智能体的框架和应用\",\"OpenManus/OpenManus-RL 框架\",\"RAGEN：推理驱动的交互优化框架\"]},\"2073\":{\"title\":\"显存优化方法\",\"titles\":[\"显存优化与推理显存分析\",\"内容总结\"]},\"2074\":{\"title\":\"操作步骤\",\"titles\":[\"Prefix-Tuning\"]},\"2075\":{\"title\":\"行动清单\",\"titles\":[\"VeRA\"]},\"2076\":{\"title\":\"实验结果与分析\",\"titles\":[\"Self-Reward\"]},\"2077\":{\"title\":\"GPU内存分级\",\"titles\":[\"计算与内存限制\"]},\"2078\":{\"title\":\"行动清单\",\"titles\":[\"X-LoRA\"]},\"2079\":{\"title\":\"Deepspeed 后端\",\"titles\":[\"Megatron和DeepSpeed后端实现的区别\"]},\"2080\":{\"title\":\"Kernel融合\",\"titles\":[\"FlashAttention Forword流程\"]},\"2081\":{\"title\":\"构建思想\",\"titles\":[\"X-ray\"]},\"2082\":{\"title\":\"操作步骤\",\"titles\":[\"Prompt Tuning\"]},\"2083\":{\"title\":\"数据飞轮在SFT中的应用与优化\",\"titles\":[]},\"2084\":{\"title\":\"多轮对话专项提升\",\"titles\":[]},\"2085\":{\"title\":\"GPT-Q\",\"titles\":[\"PTQ 训练后量化\",\"训练后量化（PTQ）\",\"PTQ方法\"]},\"2086\":{\"title\":\"常见错误\",\"titles\":[\"介绍\"]},\"2087\":{\"title\":\"DCG 的思想\",\"titles\":[\"RAG评估\",\"针对检索环节的评估\",\"NDCG：归一化折损累计增益\"]},\"2088\":{\"title\":\"元数据\",\"titles\":[\"开源数据集\"]},\"2089\":{\"title\":\"4. 协调者-工作者 Orchestrator-Workers）\",\"titles\":[\"智能体系统分类\",\"工作流（Workflow）\"]},\"2090\":{\"title\":\"数据转换\",\"titles\":[\"MOE并行训练\"]},\"2091\":{\"title\":\"4. separators\",\"titles\":[\"固定长度分块\",\"参数说明\"]},\"2092\":{\"title\":\"数据转换\",\"titles\":[\"AdaLoRA\"]},\"2093\":{\"title\":\"行动清单\",\"titles\":[\"DAPO\"]},\"2094\":{\"title\":\"ToT：Tree-of-Thoughts\",\"titles\":[\"Chain-of-Thought 思维链\",\"CoT 改进方法\"]},\"2095\":{\"title\":\"时延计算\",\"titles\":[\"推理耗时\"]},\"2096\":{\"title\":\"操作步骤\",\"titles\":[\"ReMax-improvement\"]},\"2097\":{\"title\":\"PPO算法简化\",\"titles\":[\"ReMax\",\"策略梯度与PPO回顾\"]},\"2098\":{\"title\":\"⚠ 常见错误警示\",\"titles\":[\"DPO公式推导\"]},\"2099\":{\"title\":\"核心观点总结\",\"titles\":[\"训练阶段的显存分析\"]},\"2100\":{\"title\":\"多轮对话专项提升2\",\"titles\":[]},\"2101\":{\"title\":\"训练启动脚本\",\"titles\":[]},\"2102\":{\"title\":\"最大内部产品搜索（Maximum Inner Product Search, MIPS）\",\"titles\":[\"记忆（Memory）\"]},\"2103\":{\"title\":\"优势与挑战\",\"titles\":[\"RAG优化\",\"二、基于多模态大模型的解析技术\"]},\"2104\":{\"title\":\"5.高级检索策略\",\"titles\":[\"RAG优化中查询索引阶段\",\"索引/查询算法\",\"常见的向量搜索算法\"]},\"2105\":{\"title\":\"文档切片\",\"titles\":[\"RAG流程与分类\",\"知识文档的准备\"]},\"2106\":{\"title\":\"常见错误\",\"titles\":[\"GRPO\"]},\"2107\":{\"title\":\"Value Model 的挑战\",\"titles\":[\"VAPO\",\"重点段落\"]},\"2108\":{\"title\":\"分布式推理\",\"titles\":[\"Accelerate\"]},\"2109\":{\"title\":\"💡 启发点\",\"titles\":[\"REINFORCE算法改进：RLOO与REINFORCE++\"]},\"2110\":{\"title\":\"技术术语通俗解释\",\"titles\":[\"介绍\"]},\"2111\":{\"title\":\"行动清单\",\"titles\":[\"深入理解Prompt到Response的MDP模型分析\"]},\"2112\":{\"title\":\"ZeRO 零冗余优化器\",\"titles\":[\"DeepSpeed\"]},\"2113\":{\"title\":\"Reflexion\",\"titles\":[\"智能体的分类\",\"按行为模式分类\"]},\"2114\":{\"title\":\"训练技巧和训练策略\",\"titles\":[]},\"2115\":{\"title\":\"操作步骤\",\"titles\":[\"LoRA\"]},\"2116\":{\"title\":\"元数据\",\"titles\":[\"数据多样性探索\"]},\"2117\":{\"title\":\"第一种形式：Prefix Sharing\",\"titles\":[\"首Token时延优化\",\"优化System Prompt\"]},\"2118\":{\"title\":\"Megatron-LM 的优缺点\",\"titles\":[\"Megatron-LM\",\"Megatron-LM\"]},\"2119\":{\"title\":\"数据生产合成\",\"titles\":[\"数据生产合成与质量过滤\"]},\"2120\":{\"title\":\"行动清单\",\"titles\":[\"DPOP\"]},\"2121\":{\"title\":\"公式显示\",\"titles\":[\"P-Tuning\"]},\"2122\":{\"title\":\"复杂行为表现\",\"titles\":[\"Method\",\"关键段落\"]},\"2123\":{\"title\":\"显存消耗内容概述\",\"titles\":[\"模型显存总体分析\",\"重点段落与数据\"]},\"2124\":{\"title\":\"1. 使用 MDP 进行建模\",\"titles\":[\"智能体的框架和应用\",\"OpenManus/OpenManus-RL 框架\",\"RAGEN：推理驱动的交互优化框架\",\"具体实现\"]},\"2125\":{\"title\":\"操作步骤\",\"titles\":[\"显存优化与推理显存分析\"]},\"2126\":{\"title\":\"常见错误\",\"titles\":[\"Prefix-Tuning\"]},\"2127\":{\"title\":\"常见错误\",\"titles\":[\"Self-Reward\"]},\"2128\":{\"title\":\"GPU运行模式\",\"titles\":[\"计算与内存限制\"]},\"2129\":{\"title\":\"Megatron 后端\",\"titles\":[\"Megatron和DeepSpeed后端实现的区别\"]},\"2130\":{\"title\":\"一个分块计算Softmax的例子\",\"titles\":[\"FlashAttention Forword流程\"]},\"2131\":{\"title\":\"训练框架及参数设置\",\"titles\":[]},\"2132\":{\"title\":\"大模型并行训练\",\"titles\":[\"X-ray\"]},\"2133\":{\"title\":\"常见错误\",\"titles\":[\"Prompt Tuning\"]},\"2134\":{\"title\":\"元数据\",\"titles\":[\"数据飞轮在SFT中的应用与优化\"]},\"2135\":{\"title\":\"元数据\",\"titles\":[\"多轮对话专项提升\"]},\"2136\":{\"title\":\"💡 启发点\",\"titles\":[\"介绍\"]},\"2137\":{\"title\":\"DCG 公式\",\"titles\":[\"RAG评估\",\"针对检索环节的评估\",\"NDCG：归一化折损累计增益\"]},\"2138\":{\"title\":\"内容处理\",\"titles\":[\"开源数据集\"]},\"2139\":{\"title\":\"适用场景\",\"titles\":[\"智能体系统分类\",\"工作流（Workflow）\"]},\"2140\":{\"title\":\"公式显示\",\"titles\":[\"MOE并行训练\"]},\"2141\":{\"title\":\"工作原理\",\"titles\":[\"固定长度分块\"]},\"2142\":{\"title\":\"公式显示\",\"titles\":[\"AdaLoRA\"]},\"2143\":{\"title\":\"数据转换\",\"titles\":[\"DAPO\"]},\"2144\":{\"title\":\"GoT：Graph-of-Thoughts\",\"titles\":[\"Chain-of-Thought 思维链\",\"CoT 改进方法\"]},\"2145\":{\"title\":\"计算一个 token 所需要的数据量\",\"titles\":[\"推理耗时\",\"时延计算\"]},\"2146\":{\"title\":\"常见错误\",\"titles\":[\"ReMax-improvement\"]},\"2147\":{\"title\":\"操作步骤\",\"titles\":[\"ReMax\"]},\"2148\":{\"title\":\"💡 创新点解析\",\"titles\":[\"DPO公式推导\"]},\"2149\":{\"title\":\"重点段落\",\"titles\":[\"训练阶段的显存分析\"]},\"2150\":{\"title\":\"分类：机器学习\",\"titles\":[\"多轮对话专项提升2\"]},\"2151\":{\"title\":\"核心观点总结\",\"titles\":[\"训练启动脚本\"]},\"2152\":{\"title\":\"LSH （局部敏感哈希）\",\"titles\":[\"记忆（Memory）\",\"最大内部产品搜索（Maximum Inner Product Search, MIPS）\"]},\"2153\":{\"title\":\"三、多级标题如何处理\",\"titles\":[\"RAG优化\"]},\"2154\":{\"title\":\"上下文压缩\",\"titles\":[\"RAG优化中查询索引阶段\",\"索引/查询算法\",\"常见的向量搜索算法\",\"5.高级检索策略\"]},\"2155\":{\"title\":\"Embedding模型\",\"titles\":[\"RAG流程与分类\"]},\"2156\":{\"title\":\"💡启发点\",\"titles\":[\"GRPO\"]},\"2157\":{\"title\":\"蒙特卡洛估计与价值模型\",\"titles\":[\"VAPO\",\"重点段落\"]},\"2158\":{\"title\":\"分布式训练\",\"titles\":[\"Accelerate\"]},\"2159\":{\"title\":\"行动清单\",\"titles\":[\"REINFORCE算法改进：RLOO与REINFORCE++\"]},\"2160\":{\"title\":\"操作步骤\",\"titles\":[\"介绍\"]},\"2161\":{\"title\":\"ZeRO的显存分类\",\"titles\":[\"DeepSpeed\",\"ZeRO 零冗余优化器\"]},\"2162\":{\"title\":\"流程图\",\"titles\":[\"智能体的分类\",\"按行为模式分类\",\"Reflexion\"]},\"2163\":{\"title\":\"训练技巧\",\"titles\":[\"训练技巧和训练策略\"]},\"2164\":{\"title\":\"常见错误\",\"titles\":[\"LoRA\"]},\"2165\":{\"title\":\"核心观点总结\",\"titles\":[\"数据多样性探索\"]},\"2166\":{\"title\":\"第二种形式：Prompt Cache\",\"titles\":[\"首Token时延优化\",\"优化System Prompt\"]},\"2167\":{\"title\":\"Megatron-LM 的特点\",\"titles\":[\"Megatron-LM\",\"Megatron-LM\"]},\"2168\":{\"title\":\"生产合成 Prompt\",\"titles\":[\"数据生产合成与质量过滤\",\"数据生产合成\"]},\"2169\":{\"title\":\"技术术语解释\",\"titles\":[\"Method\",\"关键段落\"]},\"2170\":{\"title\":\"显存估算与实际测量差异\",\"titles\":[\"模型显存总体分析\",\"重点段落与数据\"]},\"2171\":{\"title\":\"2. RICO 算法：推理-交互链优化\",\"titles\":[\"智能体的框架和应用\",\"OpenManus/OpenManus-RL 框架\",\"RAGEN：推理驱动的交互优化框架\",\"具体实现\"]},\"2172\":{\"title\":\"常见错误\",\"titles\":[\"显存优化与推理显存分析\"]},\"2173\":{\"title\":\"💡启发点\",\"titles\":[\"Prefix-Tuning\"]},\"2174\":{\"title\":\"行动清单\",\"titles\":[\"Self-Reward\"]},\"2175\":{\"title\":\"kernel融合\",\"titles\":[\"计算与内存限制\"]},\"2176\":{\"title\":\"计算block1：\",\"titles\":[\"FlashAttention Forword流程\",\"一个分块计算Softmax的例子\"]},\"2177\":{\"title\":\"综述\",\"titles\":[\"训练框架及参数设置\"]},\"2178\":{\"title\":\"数据并行（Data Parallel，DP）\",\"titles\":[\"X-ray\",\"大模型并行训练\"]},\"2179\":{\"title\":\"💡启发点\",\"titles\":[\"Prompt Tuning\"]},\"2180\":{\"title\":\"核心观点总结\",\"titles\":[\"数据飞轮在SFT中的应用与优化\"]},\"2181\":{\"title\":\"核心观点总结\",\"titles\":[\"多轮对话专项提升\"]},\"2182\":{\"title\":\"行动清单\",\"titles\":[\"介绍\"]},\"2183\":{\"title\":\"IDCG 和 NDCG\",\"titles\":[\"RAG评估\",\"针对检索环节的评估\",\"NDCG：归一化折损累计增益\"]},\"2184\":{\"title\":\"重点数据集\",\"titles\":[\"开源数据集\",\"内容处理\"]},\"2185\":{\"title\":\"示例\",\"titles\":[\"智能体系统分类\",\"工作流（Workflow）\"]},\"2186\":{\"title\":\"MOE推理优化\",\"titles\":[]},\"2187\":{\"title\":\"公式显示\",\"titles\":[\"DAPO\"]},\"2188\":{\"title\":\"GoT 的核心特点\",\"titles\":[\"Chain-of-Thought 思维链\",\"CoT 改进方法\",\"GoT：Graph-of-Thoughts\"]},\"2189\":{\"title\":\"推理 TPS 计算\",\"titles\":[\"推理耗时\"]},\"2190\":{\"title\":\"💡启发点\",\"titles\":[\"ReMax-improvement\"]},\"2191\":{\"title\":\"常见错误\",\"titles\":[\"ReMax\"]},\"2192\":{\"title\":\"静态值分析\",\"titles\":[\"训练阶段的显存分析\",\"重点段落\"]},\"2193\":{\"title\":\"标签：多轮对话、损失函数优化、加速计算\",\"titles\":[\"多轮对话专项提升2\"]},\"2194\":{\"title\":\"重点段落\",\"titles\":[\"训练启动脚本\"]},\"2195\":{\"title\":\"ANNOY （Approximate Nearest Neighbors Oh Yeah）\",\"titles\":[\"记忆（Memory）\",\"最大内部产品搜索（Maximum Inner Product Search, MIPS）\"]},\"2196\":{\"title\":\"为什么要处理多级标题？\",\"titles\":[\"RAG优化\",\"三、多级标题如何处理\"]},\"2197\":{\"title\":\"句子窗口搜索\",\"titles\":[\"RAG优化中查询索引阶段\",\"索引/查询算法\",\"常见的向量搜索算法\",\"5.高级检索策略\"]},\"2198\":{\"title\":\"向量数据库\",\"titles\":[\"RAG流程与分类\"]},\"2199\":{\"title\":\"行动清单\",\"titles\":[\"GRPO\"]},\"2200\":{\"title\":\"操作步骤\",\"titles\":[\"VAPO\"]},\"2201\":{\"title\":\"代码块\",\"titles\":[\"Accelerate\",\"分布式训练\"]},\"2202\":{\"title\":\"来源\",\"titles\":[\"REINFORCE算法改进：RLOO与REINFORCE++\"]},\"2203\":{\"title\":\"常见错误\",\"titles\":[\"介绍\"]},\"2204\":{\"title\":\"ZeRO 三个阶段以及显存占用分析\",\"titles\":[\"DeepSpeed\",\"ZeRO 零冗余优化器\"]},\"2205\":{\"title\":\"内部反馈与外部反馈\",\"titles\":[\"智能体的分类\",\"按行为模式分类\",\"Reflexion\"]},\"2206\":{\"title\":\"关键步骤\",\"titles\":[\"训练技巧和训练策略\",\"训练技巧\"]},\"2207\":{\"title\":\"💡 启发点\",\"titles\":[\"LoRA\"]},\"2208\":{\"title\":\"重点段落提取\",\"titles\":[\"数据多样性探索\"]},\"2209\":{\"title\":\"提醒\",\"titles\":[\"Megatron-LM\",\"Megatron-LM\"]},\"2210\":{\"title\":\"生产合成 Answer\",\"titles\":[\"数据生产合成与质量过滤\",\"数据生产合成\"]},\"2211\":{\"title\":\"💡启发点\",\"titles\":[\"Method\",\"关键段落\"]},\"2212\":{\"title\":\"操作步骤\",\"titles\":[\"模型显存总体分析\"]},\"2213\":{\"title\":\"3. 奖励归一化策略\",\"titles\":[\"智能体的框架和应用\",\"OpenManus/OpenManus-RL 框架\",\"RAGEN：推理驱动的交互优化框架\",\"具体实现\"]},\"2214\":{\"title\":\"行动清单\",\"titles\":[\"显存优化与推理显存分析\"]},\"2215\":{\"title\":\"行动清单\",\"titles\":[\"Prefix-Tuning\"]},\"2216\":{\"title\":\"计算block2：\",\"titles\":[\"FlashAttention Forword流程\",\"一个分块计算Softmax的例子\"]},\"2217\":{\"title\":\"参数设置与注意事项\",\"titles\":[\"训练框架及参数设置\"]},\"2218\":{\"title\":\"张量并行（Tensor Parallel，TP）\",\"titles\":[\"X-ray\",\"大模型并行训练\"]},\"2219\":{\"title\":\"行动清单\",\"titles\":[\"Prompt Tuning\"]},\"2220\":{\"title\":\"重点段落与数据\",\"titles\":[\"数据飞轮在SFT中的应用与优化\"]},\"2221\":{\"title\":\"重点段落\",\"titles\":[\"多轮对话专项提升\"]},\"2222\":{\"title\":\"针对生成环节的评估\",\"titles\":[\"RAG评估\"]},\"2223\":{\"title\":\"数据集格式与内容\",\"titles\":[\"开源数据集\",\"内容处理\"]},\"2224\":{\"title\":\"5. 工作流：评估-优化循环 Evaluator-Optimizer\",\"titles\":[\"智能体系统分类\",\"工作流（Workflow）\"]},\"2225\":{\"title\":\"元数据\",\"titles\":[\"MOE推理优化\"]},\"2226\":{\"title\":\"Clip-Higher技术改进：提升低概率Token探索能力\",\"titles\":[]},\"2227\":{\"title\":\"GoT 的模块组成\",\"titles\":[\"Chain-of-Thought 思维链\",\"CoT 改进方法\",\"GoT：Graph-of-Thoughts\"]},\"2228\":{\"title\":\"如何计算 TPS？\",\"titles\":[\"推理耗时\",\"推理 TPS 计算\"]},\"2229\":{\"title\":\"行动清单\",\"titles\":[\"ReMax-improvement\"]},\"2230\":{\"title\":\"💡启发点\",\"titles\":[\"ReMax\"]},\"2231\":{\"title\":\"动态值分析\",\"titles\":[\"训练阶段的显存分析\",\"重点段落\"]},\"2232\":{\"title\":\"日期：2023年10月30日\",\"titles\":[\"多轮对话专项提升2\"]},\"2233\":{\"title\":\"操作步骤\",\"titles\":[\"训练启动脚本\"]},\"2234\":{\"title\":\"HNSW （Hierarchical Navigable Small World）\",\"titles\":[\"记忆（Memory）\",\"最大内部产品搜索（Maximum Inner Product Search, MIPS）\"]},\"2235\":{\"title\":\"具体做法\",\"titles\":[\"RAG优化\",\"三、多级标题如何处理\"]},\"2236\":{\"title\":\"父文档搜索\",\"titles\":[\"RAG优化中查询索引阶段\",\"索引/查询算法\",\"常见的向量搜索算法\",\"5.高级检索策略\"]},\"2237\":{\"title\":\"优化存储与检索效率\",\"titles\":[\"RAG流程与分类\",\"向量数据库\"]},\"2238\":{\"title\":\"GRPO优势函数估计与奖励监督RL\",\"titles\":[]},\"2239\":{\"title\":\"常见错误\",\"titles\":[\"VAPO\"]},\"2240\":{\"title\":\"💡 启发点\",\"titles\":[\"介绍\"]},\"2241\":{\"title\":\"数据通信量分析\",\"titles\":[\"DeepSpeed\",\"ZeRO 零冗余优化器\",\"ZeRO 三个阶段以及显存占用分析\"]},\"2242\":{\"title\":\"Lifelong Learning Agents\",\"titles\":[\"智能体的分类\",\"按行为模式分类\"]},\"2243\":{\"title\":\"常见错误\",\"titles\":[\"训练技巧和训练策略\",\"训练技巧\"]},\"2244\":{\"title\":\"行动清单\",\"titles\":[\"LoRA\"]},\"2245\":{\"title\":\"数据用途的多样化\",\"titles\":[\"数据多样性探索\",\"重点段落提取\"]},\"2246\":{\"title\":\"大型模型训练的挑战\",\"titles\":[\"Megatron-LM\"]},\"2247\":{\"title\":\"数据质量过滤\",\"titles\":[\"数据生产合成与质量过滤\"]},\"2248\":{\"title\":\"DeepSeek-R1-Zero的Aha Moment\",\"titles\":[\"Method\"]},\"2249\":{\"title\":\"常见错误\",\"titles\":[\"模型显存总体分析\"]},\"2250\":{\"title\":\"4. 模型评估与数据平衡\",\"titles\":[\"智能体的框架和应用\",\"OpenManus/OpenManus-RL 框架\",\"RAGEN：推理驱动的交互优化框架\",\"具体实现\"]},\"2251\":{\"title\":\"Forward具体流程\",\"titles\":[]},\"2252\":{\"title\":\"技术细节\",\"titles\":[\"训练框架及参数设置\"]},\"2253\":{\"title\":\"流水线并行（Pipeline Parallel，PP）\",\"titles\":[\"X-ray\",\"大模型并行训练\"]},\"2254\":{\"title\":\"数据转换\",\"titles\":[\"Prompt Tuning\"]},\"2255\":{\"title\":\"操作步骤\",\"titles\":[\"数据飞轮在SFT中的应用与优化\"]},\"2256\":{\"title\":\"多轮对话数据判断\",\"titles\":[\"多轮对话专项提升\",\"重点段落\"]},\"2257\":{\"title\":\"非量化评估\",\"titles\":[\"RAG评估\",\"针对生成环节的评估\"]},\"2258\":{\"title\":\"思考\",\"titles\":[\"开源数据集\"]},\"2259\":{\"title\":\"适用场景\",\"titles\":[\"智能体系统分类\",\"工作流（Workflow）\"]},\"2260\":{\"title\":\"核心观点总结\",\"titles\":[\"MOE推理优化\"]},\"2261\":{\"title\":\"元数据\",\"titles\":[\"Clip-Higher技术改进：提升低概率Token探索能力\"]},\"2262\":{\"title\":\"Controller 的两个重要组件\",\"titles\":[\"Chain-of-Thought 思维链\",\"CoT 改进方法\",\"GoT：Graph-of-Thoughts\",\"GoT 的模块组成\"]},\"2263\":{\"title\":\"TPS 估算方法\",\"titles\":[\"推理耗时\"]},\"2264\":{\"title\":\"ReMax具体算法\",\"titles\":[]},\"2265\":{\"title\":\"行动清单\",\"titles\":[\"ReMax\"]},\"2266\":{\"title\":\"操作步骤\",\"titles\":[\"训练阶段的显存分析\"]},\"2267\":{\"title\":\"核心观点总结\",\"titles\":[\"多轮对话专项提升2\"]},\"2268\":{\"title\":\"常见错误\",\"titles\":[\"训练启动脚本\"]},\"2269\":{\"title\":\"工具使用（Tool Use）\",\"titles\":[]},\"2270\":{\"title\":\"四、好用的PDF文件解析工具推荐\",\"titles\":[\"RAG优化\"]},\"2271\":{\"title\":\"自动合并\",\"titles\":[\"RAG优化中查询索引阶段\",\"索引/查询算法\",\"常见的向量搜索算法\",\"5.高级检索策略\"]},\"2272\":{\"title\":\"查询检索\",\"titles\":[\"RAG流程与分类\"]},\"2273\":{\"title\":\"核心观点总结\",\"titles\":[\"GRPO优势函数估计与奖励监督RL\"]},\"2274\":{\"title\":\"💡启发点\",\"titles\":[\"VAPO\"]},\"2275\":{\"title\":\"行动清单\",\"titles\":[\"介绍\"]},\"2276\":{\"title\":\"传统数据并行\",\"titles\":[\"DeepSpeed\",\"ZeRO 零冗余优化器\",\"ZeRO 三个阶段以及显存占用分析\",\"数据通信量分析\"]},\"2277\":{\"title\":\"Voyager\",\"titles\":[\"智能体的分类\",\"按行为模式分类\",\"Lifelong Learning Agents\"]},\"2278\":{\"title\":\"SFT阶段的Packing策略\",\"titles\":[\"训练技巧和训练策略\"]},\"2279\":{\"title\":\"LoRA 微调的初始化影响与核心代码分析\",\"titles\":[]},\"2280\":{\"title\":\"数据形式的多样化\",\"titles\":[\"数据多样性探索\",\"重点段落提取\"]},\"2281\":{\"title\":\"显存限制\",\"titles\":[\"Megatron-LM\",\"大型模型训练的挑战\"]},\"2282\":{\"title\":\"IFD 过滤\",\"titles\":[\"数据生产合成与质量过滤\",\"数据质量过滤\"]},\"2283\":{\"title\":\"强化学习的核心价值\",\"titles\":[\"Method\",\"DeepSeek-R1-Zero的Aha Moment\"]},\"2284\":{\"title\":\"代码示例\",\"titles\":[\"模型显存总体分析\"]},\"2285\":{\"title\":\"RL-Agents：全面强化学习算法测试框架\",\"titles\":[\"智能体的框架和应用\",\"OpenManus/OpenManus-RL 框架\"]},\"2286\":{\"title\":\"Flash Attention 具体做法\",\"titles\":[\"Forward具体流程\"]},\"2287\":{\"title\":\"常见错误\",\"titles\":[\"训练框架及参数设置\"]},\"2288\":{\"title\":\"ZeRO （Zero Redundancy Optimizer），\",\"titles\":[\"X-ray\",\"大模型并行训练\"]},\"2289\":{\"title\":\"公式显示\",\"titles\":[\"Prompt Tuning\"]},\"2290\":{\"title\":\"常见错误\",\"titles\":[\"数据飞轮在SFT中的应用与优化\"]},\"2291\":{\"title\":\"多轮对话数据合成\",\"titles\":[\"多轮对话专项提升\",\"重点段落\"]},\"2292\":{\"title\":\"量化评估\",\"titles\":[\"RAG评估\",\"针对生成环节的评估\"]},\"2293\":{\"title\":\"附加要求\",\"titles\":[\"开源数据集\"]},\"2294\":{\"title\":\"示例\",\"titles\":[\"智能体系统分类\",\"工作流（Workflow）\"]},\"2295\":{\"title\":\"重点段落\",\"titles\":[\"MOE推理优化\"]},\"2296\":{\"title\":\"内容处理\",\"titles\":[\"Clip-Higher技术改进：提升低概率Token探索能力\"]},\"2297\":{\"title\":\"元数据\",\"titles\":[\"ReMax具体算法\"]},\"2298\":{\"title\":\"ReMax具体算法\",\"titles\":[]},\"2299\":{\"title\":\"常见错误\",\"titles\":[\"训练阶段的显存分析\"]},\"2300\":{\"title\":\"重点段落\",\"titles\":[\"多轮对话专项提升2\"]},\"2301\":{\"title\":\"💡启发点\",\"titles\":[\"训练启动脚本\"]},\"2302\":{\"title\":\"智能体与LLM的区别\",\"titles\":[]},\"2303\":{\"title\":\"文本分块策略\",\"titles\":[\"RAG优化\"]},\"2304\":{\"title\":\"多向量检索\",\"titles\":[\"RAG优化中查询索引阶段\",\"索引/查询算法\",\"常见的向量搜索算法\",\"5.高级检索策略\"]},\"2305\":{\"title\":\"生成回答\",\"titles\":[\"RAG流程与分类\"]},\"2306\":{\"title\":\"重点段落\",\"titles\":[\"GRPO优势函数估计与奖励监督RL\"]},\"2307\":{\"title\":\"行动清单\",\"titles\":[\"VAPO\"]},\"2308\":{\"title\":\"ZeRO1、2阶段（优化器状态分区、梯度分区）\",\"titles\":[\"DeepSpeed\",\"ZeRO 零冗余优化器\",\"ZeRO 三个阶段以及显存占用分析\",\"数据通信量分析\"]},\"2309\":{\"title\":\"流程图\",\"titles\":[\"智能体的分类\",\"按行为模式分类\",\"Lifelong Learning Agents\"]},\"2310\":{\"title\":\"重点段落\",\"titles\":[\"训练技巧和训练策略\",\"SFT阶段的Packing策略\"]},\"2311\":{\"title\":\"核心观点总结\",\"titles\":[\"LoRA 微调的初始化影响与核心代码分析\"]},\"2312\":{\"title\":\"多轮聊天与答复分布\",\"titles\":[\"数据多样性探索\",\"重点段落提取\"]},\"2313\":{\"title\":\"计算挑战\",\"titles\":[\"Megatron-LM\",\"大型模型训练的挑战\"]},\"2314\":{\"title\":\"总体流程\",\"titles\":[\"数据生产合成与质量过滤\",\"数据质量过滤\"]},\"2315\":{\"title\":\"DeepSeek-R1-Zero的缺点与局限性\",\"titles\":[\"Method\",\"DeepSeek-R1-Zero的Aha Moment\"]},\"2316\":{\"title\":\"💡启发点\",\"titles\":[\"模型显存总体分析\"]},\"2317\":{\"title\":\"一句话总结\",\"titles\":[\"智能体的框架和应用\",\"OpenManus/OpenManus-RL 框架\",\"RL-Agents：全面强化学习算法测试框架\"]},\"2318\":{\"title\":\"计算初始attention分数\",\"titles\":[\"Forward具体流程\",\"Flash Attention 具体做法\"]},\"2319\":{\"title\":\"💡启发点\",\"titles\":[\"训练框架及参数设置\"]},\"2320\":{\"title\":\"Megatron-LM、Deepspeed 与 Ray：分布式计算的利器\",\"titles\":[]},\"2321\":{\"title\":\"📈趋势预测\",\"titles\":[\"数据飞轮在SFT中的应用与优化\"]},\"2322\":{\"title\":\"多轮计算loss\",\"titles\":[\"多轮对话专项提升\",\"重点段落\"]},\"2323\":{\"title\":\"意图分流评估\",\"titles\":[\"RAG评估\"]},\"2324\":{\"title\":\"操作步骤\",\"titles\":[\"开源数据集\",\"附加要求\"]},\"2325\":{\"title\":\"总结\",\"titles\":[]},\"2326\":{\"title\":\"滑动窗口注意力机制\",\"titles\":[\"MOE推理优化\",\"重点段落\"]},\"2327\":{\"title\":\"核心观点\",\"titles\":[\"Clip-Higher技术改进：提升低概率Token探索能力\",\"内容处理\"]},\"2328\":{\"title\":\"核心观点总结\",\"titles\":[\"ReMax具体算法\"]},\"2329\":{\"title\":\"元数据\",\"titles\":[\"ReMax具体算法\"]},\"2330\":{\"title\":\"💡 启发点\",\"titles\":[\"训练阶段的显存分析\"]},\"2331\":{\"title\":\"通俗解读\",\"titles\":[\"多轮对话专项提升2\"]},\"2332\":{\"title\":\"行动清单\",\"titles\":[\"训练启动脚本\"]},\"2333\":{\"title\":\"与LLM的交互方式\",\"titles\":[\"智能体与LLM的区别\"]},\"2334\":{\"title\":\"文本分块策略的意义\",\"titles\":[\"RAG优化\"]},\"2335\":{\"title\":\"多代理检索\",\"titles\":[\"RAG优化中查询索引阶段\",\"索引/查询算法\",\"常见的向量搜索算法\",\"5.高级检索策略\"]},\"2336\":{\"title\":\"RAG分类\",\"titles\":[\"RAG流程与分类\"]},\"2337\":{\"title\":\"操作步骤\",\"titles\":[\"GRPO优势函数估计与奖励监督RL\"]},\"2338\":{\"title\":\"数据转换\",\"titles\":[\"VAPO\"]},\"2339\":{\"title\":\"深入理解 ZERO3 与 CPU 卸载技术\",\"titles\":[\"DeepSpeed\",\"ZeRO 零冗余优化器\",\"ZeRO 三个阶段以及显存占用分析\",\"数据通信量分析\"]},\"2340\":{\"title\":\"实验结果\",\"titles\":[\"智能体的分类\",\"按行为模式分类\",\"Lifelong Learning Agents\"]},\"2341\":{\"title\":\"训练策略\",\"titles\":[\"训练技巧和训练策略\"]},\"2342\":{\"title\":\"重点分析\",\"titles\":[\"LoRA 微调的初始化影响与核心代码分析\"]},\"2343\":{\"title\":\"常见错误警告\",\"titles\":[\"数据多样性探索\"]},\"2344\":{\"title\":\"并行策略挑战\",\"titles\":[\"Megatron-LM\",\"大型模型训练的挑战\"]},\"2345\":{\"title\":\"思考\",\"titles\":[\"数据生产合成与质量过滤\"]},\"2346\":{\"title\":\"操作步骤：如何优化DeepSeek-R1-Zero的使用\",\"titles\":[\"Method\",\"DeepSeek-R1-Zero的Aha Moment\"]},\"2347\":{\"title\":\"数据表格\",\"titles\":[\"模型显存总体分析\"]},\"2348\":{\"title\":\"具体实现\",\"titles\":[\"智能体的框架和应用\",\"OpenManus/OpenManus-RL 框架\",\"RL-Agents：全面强化学习算法测试框架\"]},\"2349\":{\"title\":\"afe softmax + mask + dropout\",\"titles\":[\"Forward具体流程\",\"Flash Attention 具体做法\"]},\"2350\":{\"title\":\"[思考] 未来展望与问题\",\"titles\":[\"训练框架及参数设置\"]},\"2351\":{\"title\":\"Megatron-LM\",\"titles\":[\"Megatron-LM、Deepspeed 与 Ray：分布式计算的利器\"]},\"2352\":{\"title\":\"💡启发点\",\"titles\":[\"数据飞轮在SFT中的应用与优化\"]},\"2353\":{\"title\":\"常见错误\",\"titles\":[\"多轮对话专项提升\"]},\"2354\":{\"title\":\"分类任务评估\",\"titles\":[\"RAG评估\",\"意图分流评估\"]},\"2355\":{\"title\":\"常见错误\",\"titles\":[\"开源数据集\",\"附加要求\"]},\"2356\":{\"title\":\"Rolling Buffer Cache\",\"titles\":[\"MOE推理优化\",\"重点段落\"]},\"2357\":{\"title\":\"技术术语转述\",\"titles\":[\"Clip-Higher技术改进：提升低概率Token探索能力\",\"内容处理\"]},\"2358\":{\"title\":\"重点段落\",\"titles\":[\"ReMax具体算法\"]},\"2359\":{\"title\":\"核心观点总结\",\"titles\":[\"ReMax具体算法\"]},\"2360\":{\"title\":\"行动清单\",\"titles\":[\"训练阶段的显存分析\"]},\"2361\":{\"title\":\"操作步骤\",\"titles\":[\"多轮对话专项提升2\"]},\"2362\":{\"title\":\"📈趋势预测\",\"titles\":[\"训练启动脚本\"]},\"2363\":{\"title\":\"与Agent的交互方式\",\"titles\":[\"智能体与LLM的区别\"]},\"2364\":{\"title\":\"理想文本块的特性\",\"titles\":[\"RAG优化\",\"文本分块策略的意义\"]},\"2365\":{\"title\":\"Self-RAG\",\"titles\":[\"RAG优化中查询索引阶段\",\"索引/查询算法\",\"常见的向量搜索算法\",\"5.高级检索策略\"]},\"2366\":{\"title\":\"三个阶段：Naive RAG、Advanced RAG、Modular RAG\",\"titles\":[\"RAG流程与分类\",\"RAG分类\"]},\"2367\":{\"title\":\"常见错误\",\"titles\":[\"GRPO优势函数估计与奖励监督RL\"]},\"2368\":{\"title\":\"来源标注\",\"titles\":[\"VAPO\"]},\"2369\":{\"title\":\"通信效率分析\",\"titles\":[\"DeepSpeed\",\"ZeRO 零冗余优化器\",\"ZeRO 三个阶段以及显存占用分析\",\"数据通信量分析\",\"深入理解 ZERO3 与 CPU 卸载技术\"]},\"2370\":{\"title\":\"Ghost in the Minecraft (GITM)\",\"titles\":[\"智能体的分类\",\"按行为模式分类\"]},\"2371\":{\"title\":\"多任务学习\",\"titles\":[\"训练技巧和训练策略\",\"训练策略\"]},\"2372\":{\"title\":\"初始化策略对比\",\"titles\":[\"LoRA 微调的初始化影响与核心代码分析\",\"重点分析\"]},\"2373\":{\"title\":\"💡启发点\",\"titles\":[\"数据多样性探索\"]},\"2374\":{\"title\":\"数据并行\",\"titles\":[\"Megatron-LM\"]},\"2375\":{\"title\":\"操作步骤\",\"titles\":[\"数据生产合成与质量过滤\"]},\"2376\":{\"title\":\"提高模型推理性能与用户友好性方法探讨\",\"titles\":[\"Method\"]},\"2377\":{\"title\":\"行动清单\",\"titles\":[\"模型显存总体分析\"]},\"2378\":{\"title\":\"1. 规划算法\",\"titles\":[\"智能体的框架和应用\",\"OpenManus/OpenManus-RL 框架\",\"RL-Agents：全面强化学习算法测试框架\",\"具体实现\"]},\"2379\":{\"title\":\"计算output\",\"titles\":[\"Forward具体流程\",\"Flash Attention 具体做法\"]},\"2380\":{\"title\":\"行动清单\",\"titles\":[\"训练框架及参数设置\"]},\"2381\":{\"title\":\"Deepspeed\",\"titles\":[\"Megatron-LM、Deepspeed 与 Ray：分布式计算的利器\"]},\"2382\":{\"title\":\"[思考]板块\",\"titles\":[\"数据飞轮在SFT中的应用与优化\"]},\"2383\":{\"title\":\"💡启发点\",\"titles\":[\"多轮对话专项提升\"]},\"2384\":{\"title\":\"Function Call 的评估\",\"titles\":[\"RAG评估\",\"意图分流评估\"]},\"2385\":{\"title\":\"💡启发点\",\"titles\":[\"开源数据集\",\"附加要求\"]},\"2386\":{\"title\":\"Chunking方法\",\"titles\":[\"MOE推理优化\",\"重点段落\"]},\"2387\":{\"title\":\"操作步骤\",\"titles\":[\"Clip-Higher技术改进：提升低概率Token探索能力\"]},\"2388\":{\"title\":\"ReMax的基本概念\",\"titles\":[\"ReMax具体算法\",\"重点段落\"]},\"2389\":{\"title\":\"重点段落\",\"titles\":[\"ReMax具体算法\"]},\"2390\":{\"title\":\"常见错误\",\"titles\":[\"多轮对话专项提升2\"]},\"2391\":{\"title\":\"后续追踪\",\"titles\":[\"训练启动脚本\"]},\"2392\":{\"title\":\"与强化学习智能体的区别\",\"titles\":[]},\"2393\":{\"title\":\"文本分块策略对大模型输出的影响\",\"titles\":[\"RAG优化\"]},\"2394\":{\"title\":\"重排模型\",\"titles\":[\"RAG优化中查询索引阶段\",\"索引/查询算法\",\"常见的向量搜索算法\",\"5.高级检索策略\"]},\"2395\":{\"title\":\"相关综述论文\",\"titles\":[\"RAG流程与分类\",\"RAG分类\"]},\"2396\":{\"title\":\"💡 启发点\",\"titles\":[\"GRPO优势函数估计与奖励监督RL\"]},\"2397\":{\"title\":\"CPU卸载策略\",\"titles\":[\"DeepSpeed\",\"ZeRO 零冗余优化器\",\"ZeRO 三个阶段以及显存占用分析\",\"数据通信量分析\",\"深入理解 ZERO3 与 CPU 卸载技术\"]},\"2398\":{\"title\":\"流程图\",\"titles\":[\"智能体的分类\",\"按行为模式分类\",\"Ghost in the Minecraft (GITM)\"]},\"2399\":{\"title\":\"顺序训练\",\"titles\":[\"训练技巧和训练策略\",\"训练策略\"]},\"2400\":{\"title\":\"LoRA 微调核心代码\",\"titles\":[\"LoRA 微调的初始化影响与核心代码分析\",\"重点分析\"]},\"2401\":{\"title\":\"行动清单\",\"titles\":[\"数据多样性探索\"]},\"2402\":{\"title\":\"限制\",\"titles\":[\"Megatron-LM\",\"数据并行\"]},\"2403\":{\"title\":\"常见错误\",\"titles\":[\"数据生产合成与质量过滤\"]},\"2404\":{\"title\":\"元数据\",\"titles\":[\"Method\"]},\"2405\":{\"title\":\"2. 安全规划\",\"titles\":[\"智能体的框架和应用\",\"OpenManus/OpenManus-RL 框架\",\"RL-Agents：全面强化学习算法测试框架\",\"具体实现\"]},\"2406\":{\"title\":\"计算的伪代码\",\"titles\":[\"Forward具体流程\",\"Flash Attention 具体做法\"]},\"2407\":{\"title\":\"📈趋势预测\",\"titles\":[\"训练框架及参数设置\"]},\"2408\":{\"title\":\"Ray\",\"titles\":[\"Megatron-LM、Deepspeed 与 Ray：分布式计算的利器\"]},\"2409\":{\"title\":\"行动清单\",\"titles\":[\"数据飞轮在SFT中的应用与优化\"]},\"2410\":{\"title\":\"行动清单\",\"titles\":[\"多轮对话专项提升\"]},\"2411\":{\"title\":\"答案评估\",\"titles\":[\"RAG评估\"]},\"2412\":{\"title\":\"行动清单\",\"titles\":[\"开源数据集\",\"附加要求\"]},\"2413\":{\"title\":\"步骤流程\",\"titles\":[\"MOE推理优化\"]},\"2414\":{\"title\":\"常见错误\",\"titles\":[\"Clip-Higher技术改进：提升低概率Token探索能力\"]},\"2415\":{\"title\":\"REINFORCE方法的修正\",\"titles\":[\"ReMax具体算法\",\"重点段落\"]},\"2416\":{\"title\":\"ReMax的基本概念\",\"titles\":[\"ReMax具体算法\",\"重点段落\"]},\"2417\":{\"title\":\"代码示例\",\"titles\":[\"多轮对话专项提升2\"]},\"2418\":{\"title\":\"强化学习智能体\",\"titles\":[\"与强化学习智能体的区别\"]},\"2419\":{\"title\":\"文本分块过长的影响\",\"titles\":[\"RAG优化\",\"文本分块策略对大模型输出的影响\"]},\"2420\":{\"title\":\"Naive RAG\",\"titles\":[\"RAG流程与分类\"]},\"2421\":{\"title\":\"行动清单\",\"titles\":[\"GRPO优势函数估计与奖励监督RL\"]},\"2422\":{\"title\":\"CPU卸载的优化目标\",\"titles\":[\"DeepSpeed\",\"ZeRO 零冗余优化器\",\"ZeRO 三个阶段以及显存占用分析\",\"数据通信量分析\",\"深入理解 ZERO3 与 CPU 卸载技术\"]},\"2423\":{\"title\":\"LLM Planner 示例\",\"titles\":[\"智能体的分类\",\"按行为模式分类\"]},\"2424\":{\"title\":\"混合序列训练\",\"titles\":[\"训练技巧和训练策略\",\"训练策略\"]},\"2425\":{\"title\":\"LoRA 设置降维和升维矩阵\",\"titles\":[\"LoRA 微调的初始化影响与核心代码分析\",\"重点分析\"]},\"2426\":{\"title\":\"📈趋势预测\",\"titles\":[\"数据多样性探索\"]},\"2427\":{\"title\":\"All-Reduce 操作\",\"titles\":[\"Megatron-LM\"]},\"2428\":{\"title\":\"💡 启发点\",\"titles\":[\"数据生产合成与质量过滤\"]},\"2429\":{\"title\":\"核心观点总结\",\"titles\":[\"Method\"]},\"2430\":{\"title\":\"3. 基于值的算法\",\"titles\":[\"智能体的框架和应用\",\"OpenManus/OpenManus-RL 框架\",\"RL-Agents：全面强化学习算法测试框架\",\"具体实现\"]},\"2431\":{\"title\":\"图例加深理解\",\"titles\":[\"Forward具体流程\",\"Flash Attention 具体做法\"]},\"2432\":{\"title\":\"后续追踪\",\"titles\":[\"训练框架及参数设置\"]},\"2433\":{\"title\":\"代码示例\",\"titles\":[\"Megatron-LM、Deepspeed 与 Ray：分布式计算的利器\",\"Ray\"]},\"2434\":{\"title\":\"后续追踪\",\"titles\":[\"数据飞轮在SFT中的应用与优化\"]},\"2435\":{\"title\":\"📈趋势预测\",\"titles\":[\"多轮对话专项提升\"]},\"2436\":{\"title\":\"事实性\",\"titles\":[\"RAG评估\",\"答案评估\"]},\"2437\":{\"title\":\"📈趋势预测\",\"titles\":[\"开源数据集\",\"附加要求\"]},\"2438\":{\"title\":\"常见错误\",\"titles\":[\"MOE推理优化\"]},\"2439\":{\"title\":\"💡启发点\",\"titles\":[\"Clip-Higher技术改进：提升低概率Token探索能力\"]},\"2440\":{\"title\":\"基线计算的创新\",\"titles\":[\"ReMax具体算法\",\"重点段落\"]},\"2441\":{\"title\":\"REINFORCE方法的修正\",\"titles\":[\"ReMax具体算法\",\"重点段落\"]},\"2442\":{\"title\":\"💡启发点\",\"titles\":[\"多轮对话专项提升2\"]},\"2443\":{\"title\":\"基于大模型的智能体\",\"titles\":[\"与强化学习智能体的区别\"]},\"2444\":{\"title\":\"1. 语义模糊\",\"titles\":[\"RAG优化\",\"文本分块策略对大模型输出的影响\",\"文本分块过长的影响\"]},\"2445\":{\"title\":\"优点\",\"titles\":[\"RAG流程与分类\",\"Naive RAG\"]},\"2446\":{\"title\":\"数据转换\",\"titles\":[\"GRPO优势函数估计与奖励监督RL\"]},\"2447\":{\"title\":\"数据卸载策略\",\"titles\":[\"DeepSpeed\",\"ZeRO 零冗余优化器\",\"ZeRO 三个阶段以及显存占用分析\",\"数据通信量分析\",\"深入理解 ZERO3 与 CPU 卸载技术\"]},\"2448\":{\"title\":\"RAG Agent\",\"titles\":[\"智能体的分类\",\"按行为模式分类\"]},\"2449\":{\"title\":\"思考\",\"titles\":[\"训练技巧和训练策略\"]},\"2450\":{\"title\":\"常见错误\",\"titles\":[\"LoRA 微调的初始化影响与核心代码分析\"]},\"2451\":{\"title\":\"后续追踪\",\"titles\":[\"数据多样性探索\"]},\"2452\":{\"title\":\"工作原理\",\"titles\":[\"Megatron-LM\",\"All-Reduce 操作\"]},\"2453\":{\"title\":\"行动清单\",\"titles\":[\"数据生产合成与质量过滤\"]},\"2454\":{\"title\":\"重点段落\",\"titles\":[\"Method\"]},\"2455\":{\"title\":\"4. 安全基于值的方法\",\"titles\":[\"智能体的框架和应用\",\"OpenManus/OpenManus-RL 框架\",\"RL-Agents：全面强化学习算法测试框架\",\"具体实现\"]},\"2456\":{\"title\":\"当 j=1 时\",\"titles\":[\"Forward具体流程\",\"Flash Attention 具体做法\"]},\"2457\":{\"title\":\"后续追踪\",\"titles\":[\"多轮对话专项提升\"]},\"2458\":{\"title\":\"噪音评估\",\"titles\":[\"RAG评估\"]},\"2459\":{\"title\":\"后续追踪\",\"titles\":[\"开源数据集\",\"附加要求\"]},\"2460\":{\"title\":\"💡启发点\",\"titles\":[\"MOE推理优化\"]},\"2461\":{\"title\":\"行动清单\",\"titles\":[\"Clip-Higher技术改进：提升低概率Token探索能力\"]},\"2462\":{\"title\":\"操作步骤\",\"titles\":[\"ReMax具体算法\"]},\"2463\":{\"title\":\"基线计算的创新\",\"titles\":[\"ReMax具体算法\",\"重点段落\"]},\"2464\":{\"title\":\"行动清单\",\"titles\":[\"多轮对话专项提升2\"]},\"2465\":{\"title\":\"2. 降低召回精度\",\"titles\":[\"RAG优化\",\"文本分块策略对大模型输出的影响\",\"文本分块过长的影响\"]},\"2466\":{\"title\":\"缺点\",\"titles\":[\"RAG流程与分类\",\"Naive RAG\"]},\"2467\":{\"title\":\"GRPO策略更新与实现：深度学习中的强化学习优化\",\"titles\":[]},\"2468\":{\"title\":\"计算卸载策略\",\"titles\":[\"DeepSpeed\",\"ZeRO 零冗余优化器\",\"ZeRO 三个阶段以及显存占用分析\",\"数据通信量分析\",\"深入理解 ZERO3 与 CPU 卸载技术\"]},\"2469\":{\"title\":\"从外部来源检索信息的范式\",\"titles\":[\"智能体的分类\",\"按行为模式分类\"]},\"2470\":{\"title\":\"行动清单\",\"titles\":[\"训练技巧和训练策略\"]},\"2471\":{\"title\":\"行动清单\",\"titles\":[\"LoRA 微调的初始化影响与核心代码分析\"]},\"2472\":{\"title\":\"模型并行\",\"titles\":[\"Megatron-LM\"]},\"2473\":{\"title\":\"📈 趋势预测\",\"titles\":[\"数据生产合成与质量过滤\"]},\"2474\":{\"title\":\"冷启动的作用\",\"titles\":[\"Method\",\"重点段落\"]},\"2475\":{\"title\":\"当 j=2 时\",\"titles\":[\"Forward具体流程\",\"Flash Attention 具体做法\"]},\"2476\":{\"title\":\"[思考]\",\"titles\":[\"多轮对话专项提升\"]},\"2477\":{\"title\":\"分专项能力评估\",\"titles\":[\"RAG评估\"]},\"2478\":{\"title\":\"行动清单\",\"titles\":[\"MOE推理优化\"]},\"2479\":{\"title\":\"数据转换\",\"titles\":[\"Clip-Higher技术改进：提升低概率Token探索能力\"]},\"2480\":{\"title\":\"常见错误\",\"titles\":[\"ReMax具体算法\"]},\"2481\":{\"title\":\"操作步骤\",\"titles\":[\"ReMax具体算法\"]},\"2482\":{\"title\":\"数据转换\",\"titles\":[\"多轮对话专项提升2\"]},\"2483\":{\"title\":\"3. 输入受限\",\"titles\":[\"RAG优化\",\"文本分块策略对大模型输出的影响\",\"文本分块过长的影响\"]},\"2484\":{\"title\":\"Advanced RAG\",\"titles\":[\"RAG流程与分类\"]},\"2485\":{\"title\":\"GRPO策略更新公式\",\"titles\":[\"GRPO策略更新与实现：深度学习中的强化学习优化\"]},\"2486\":{\"title\":\"通信量分析\",\"titles\":[\"DeepSpeed\",\"ZeRO 零冗余优化器\",\"ZeRO 三个阶段以及显存占用分析\",\"数据通信量分析\",\"深入理解 ZERO3 与 CPU 卸载技术\"]},\"2487\":{\"title\":\"具体方法\",\"titles\":[\"智能体的分类\"]},\"2488\":{\"title\":\"📈趋势预测\",\"titles\":[\"训练技巧和训练策略\"]},\"2489\":{\"title\":\"Model Parallelism MP\",\"titles\":[\"Megatron-LM\"]},\"2490\":{\"title\":\"后续追踪\",\"titles\":[\"数据生产合成与质量过滤\"]},\"2491\":{\"title\":\"推理过程中的语言一致性奖励\",\"titles\":[\"Method\",\"重点段落\"]},\"2492\":{\"title\":\"Tilling 中的 Safe Softmax\",\"titles\":[\"Forward具体流程\"]},\"2493\":{\"title\":\"1. 易混淆实体\",\"titles\":[\"RAG评估\",\"分专项能力评估\"]},\"2494\":{\"title\":\"动态采样技术在机器学习中的应用与挑战\",\"titles\":[]},\"2495\":{\"title\":\"💡 启发点\",\"titles\":[\"ReMax具体算法\"]},\"2496\":{\"title\":\"常见错误\",\"titles\":[\"ReMax具体算法\"]},\"2497\":{\"title\":\"📈趋势预测\",\"titles\":[\"多轮对话专项提升2\"]},\"2498\":{\"title\":\"文本分块过短的影响\",\"titles\":[\"RAG优化\",\"文本分块策略对大模型输出的影响\"]},\"2499\":{\"title\":\"优点\",\"titles\":[\"RAG流程与分类\",\"Advanced RAG\"]},\"2500\":{\"title\":\"代码实现\",\"titles\":[\"GRPO策略更新与实现：深度学习中的强化学习优化\"]},\"2501\":{\"title\":\"Verify-and-Edit\",\"titles\":[\"智能体的分类\",\"具体方法\",\"从外部来源检索信息的范式\"]},\"2502\":{\"title\":\"后续追踪\",\"titles\":[\"训练技巧和训练策略\"]},\"2503\":{\"title\":\"Activation Checkpointing（gradient_checkpointing）\",\"titles\":[\"Megatron-LM\",\"Model Parallelism MP\"]},\"2504\":{\"title\":\"数据收集与处理\",\"titles\":[\"Method\",\"重点段落\"]},\"2505\":{\"title\":\"我们定义：\",\"titles\":[\"Forward具体流程\",\"Tilling 中的 Safe Softmax\"]},\"2506\":{\"title\":\"2. 弱相关性\",\"titles\":[\"RAG评估\",\"分专项能力评估\"]},\"2507\":{\"title\":\"核心观点总结\",\"titles\":[\"动态采样技术在机器学习中的应用与挑战\"]},\"2508\":{\"title\":\"行动清单\",\"titles\":[\"ReMax具体算法\"]},\"2509\":{\"title\":\"💡 启发点\",\"titles\":[\"ReMax具体算法\"]},\"2510\":{\"title\":\"后续追踪\",\"titles\":[\"多轮对话专项提升2\"]},\"2511\":{\"title\":\"1. 上下文缺失\",\"titles\":[\"RAG优化\",\"文本分块策略对大模型输出的影响\",\"文本分块过短的影响\"]},\"2512\":{\"title\":\"缺点\",\"titles\":[\"RAG流程与分类\",\"Advanced RAG\"]},\"2513\":{\"title\":\"常见错误\",\"titles\":[\"GRPO策略更新与实现：深度学习中的强化学习优化\"]},\"2514\":{\"title\":\"方法简介\",\"titles\":[\"智能体的分类\",\"具体方法\",\"从外部来源检索信息的范式\",\"Verify-and-Edit\"]},\"2515\":{\"title\":\"张量并行 Intra-Layer Tensor Parallelism\",\"titles\":[\"Megatron-LM\"]},\"2516\":{\"title\":\"技术术语转述\",\"titles\":[\"Method\"]},\"2517\":{\"title\":\"思路转变：\",\"titles\":[\"Forward具体流程\",\"Tilling 中的 Safe Softmax\"]},\"2518\":{\"title\":\"3. Function Call\",\"titles\":[\"RAG评估\",\"分专项能力评估\"]},\"2519\":{\"title\":\"动态采样的操作步骤\",\"titles\":[\"动态采样技术在机器学习中的应用与挑战\"]},\"2520\":{\"title\":\"数据转换\",\"titles\":[\"ReMax具体算法\"]},\"2521\":{\"title\":\"行动清单\",\"titles\":[\"ReMax具体算法\"]},\"2522\":{\"title\":\"2.主题信息丢失\",\"titles\":[\"RAG优化\",\"文本分块策略对大模型输出的影响\",\"文本分块过短的影响\"]},\"2523\":{\"title\":\"Modular RAG\",\"titles\":[\"RAG流程与分类\"]},\"2524\":{\"title\":\"行动清单\",\"titles\":[\"GRPO策略更新与实现：深度学习中的强化学习优化\"]},\"2525\":{\"title\":\"流程图\",\"titles\":[\"智能体的分类\",\"具体方法\",\"从外部来源检索信息的范式\",\"Verify-and-Edit\"]},\"2526\":{\"title\":\"代码块\",\"titles\":[\"Megatron-LM\",\"张量并行 Intra-Layer Tensor Parallelism\"]},\"2527\":{\"title\":\"操作步骤\",\"titles\":[\"Method\"]},\"2528\":{\"title\":\"更新公式：\",\"titles\":[\"Forward具体流程\",\"Tilling 中的 Safe Softmax\"]},\"2529\":{\"title\":\"4. 时效性\",\"titles\":[\"RAG评估\",\"分专项能力评估\"]},\"2530\":{\"title\":\"常见错误\",\"titles\":[\"动态采样技术在机器学习中的应用与挑战\"]},\"2531\":{\"title\":\"公式显示\",\"titles\":[\"ReMax具体算法\"]},\"2532\":{\"title\":\"数据转换\",\"titles\":[\"ReMax具体算法\"]},\"2533\":{\"title\":\"3.碎片化问题\",\"titles\":[\"RAG优化\",\"文本分块策略对大模型输出的影响\",\"文本分块过短的影响\"]},\"2534\":{\"title\":\"优点\",\"titles\":[\"RAG流程与分类\",\"Modular RAG\"]},\"2535\":{\"title\":\"GRPO代码优化与重要性采样分析\",\"titles\":[]},\"2536\":{\"title\":\"Demonstrate-Search-Predict\",\"titles\":[\"智能体的分类\",\"具体方法\",\"从外部来源检索信息的范式\"]},\"2537\":{\"title\":\"GEMMs行并行\",\"titles\":[\"Megatron-LM\",\"张量并行 Intra-Layer Tensor Parallelism\"]},\"2538\":{\"title\":\"常见错误\",\"titles\":[\"Method\"]},\"2539\":{\"title\":\"Forward计算代码解析\",\"titles\":[\"Forward具体流程\",\"Tilling 中的 Safe Softmax\"]},\"2540\":{\"title\":\"5. 拒答\",\"titles\":[\"RAG评估\",\"分专项能力评估\"]},\"2541\":{\"title\":\"💡 启发点\",\"titles\":[\"动态采样技术在机器学习中的应用与挑战\"]},\"2542\":{\"title\":\"公式显示\",\"titles\":[\"ReMax具体算法\"]},\"2543\":{\"title\":\"如何制定合适的文本分块策略？\",\"titles\":[\"RAG优化\"]},\"2544\":{\"title\":\"缺点\",\"titles\":[\"RAG流程与分类\",\"Modular RAG\"]},\"2545\":{\"title\":\"核心观点总结\",\"titles\":[\"GRPO代码优化与重要性采样分析\"]},\"2546\":{\"title\":\"方法简介\",\"titles\":[\"智能体的分类\",\"具体方法\",\"从外部来源检索信息的范式\",\"Demonstrate-Search-Predict\"]},\"2547\":{\"title\":\"GEMMs列并行与Transformer中的张量并行\",\"titles\":[\"Megatron-LM\"]},\"2548\":{\"title\":\"💡启发点\",\"titles\":[\"Method\"]},\"2549\":{\"title\":\"数据块的拆分\",\"titles\":[\"Forward具体流程\",\"Tilling 中的 Safe Softmax\"]},\"2550\":{\"title\":\"开源RAG评估框架\",\"titles\":[\"RAG评估\"]},\"2551\":{\"title\":\"行动清单\",\"titles\":[\"动态采样技术在机器学习中的应用与挑战\"]},\"2552\":{\"title\":\"常见文本分块策略\",\"titles\":[\"RAG优化\"]},\"2553\":{\"title\":\"重点段落\",\"titles\":[\"GRPO代码优化与重要性采样分析\"]},\"2554\":{\"title\":\"示例流程\",\"titles\":[\"智能体的分类\",\"具体方法\",\"从外部来源检索信息的范式\",\"Demonstrate-Search-Predict\"]},\"2555\":{\"title\":\"GEMMs列并行\",\"titles\":[\"Megatron-LM\"]},\"2556\":{\"title\":\"行动清单\",\"titles\":[\"Method\"]},\"2557\":{\"title\":\"循环计算过程\",\"titles\":[\"Forward具体流程\"]},\"2558\":{\"title\":\"1. Ragas\",\"titles\":[\"RAG评估\",\"开源RAG评估框架\"]},\"2559\":{\"title\":\"Token-Level Loss 优化策略：提升深度学习模型的训练效果\",\"titles\":[]},\"2560\":{\"title\":\"固定大小的分块\",\"titles\":[\"RAG优化\"]},\"2561\":{\"title\":\"重要性采样的不足\",\"titles\":[\"GRPO代码优化与重要性采样分析\",\"重点段落\"]},\"2562\":{\"title\":\"Iterative Retrieval Augmentation\",\"titles\":[\"智能体的分类\",\"具体方法\",\"从外部来源检索信息的范式\"]},\"2563\":{\"title\":\"Transformer中的张量并行\",\"titles\":[\"Megatron-LM\"]},\"2564\":{\"title\":\"数据转换\",\"titles\":[\"Method\"]},\"2565\":{\"title\":\"Step 6: 外层循环\",\"titles\":[\"Forward具体流程\",\"循环计算过程\"]},\"2566\":{\"title\":\"（1）忠实性\",\"titles\":[\"RAG评估\",\"开源RAG评估框架\",\"1. Ragas\"]},\"2567\":{\"title\":\"元数据\",\"titles\":[\"Token-Level Loss 优化策略：提升深度学习模型的训练效果\"]},\"2568\":{\"title\":\"优点\",\"titles\":[\"RAG优化\",\"固定大小的分块\"]},\"2569\":{\"title\":\"PPO的重要性采样处理\",\"titles\":[\"GRPO代码优化与重要性采样分析\",\"重点段落\"]},\"2570\":{\"title\":\"方法简介\",\"titles\":[\"智能体的分类\",\"具体方法\",\"从外部来源检索信息的范式\",\"Iterative Retrieval Augmentation\"]},\"2571\":{\"title\":\"Masked Multi-Head Self Attention\",\"titles\":[\"Megatron-LM\",\"Transformer中的张量并行\"]},\"2572\":{\"title\":\"实验结果\",\"titles\":[]},\"2573\":{\"title\":\"Step 8: 内层循环\",\"titles\":[\"Forward具体流程\",\"循环计算过程\"]},\"2574\":{\"title\":\"（2）答案相关性\",\"titles\":[\"RAG评估\",\"开源RAG评估框架\",\"1. Ragas\"]},\"2575\":{\"title\":\"核心观点总结\",\"titles\":[\"Token-Level Loss 优化策略：提升深度学习模型的训练效果\"]},\"2576\":{\"title\":\"缺点\",\"titles\":[\"RAG优化\",\"固定大小的分块\"]},\"2577\":{\"title\":\"TRL实现的简化\",\"titles\":[\"GRPO代码优化与重要性采样分析\",\"重点段落\"]},\"2578\":{\"title\":\"示例检索 Query 生成\",\"titles\":[\"智能体的分类\",\"具体方法\",\"从外部来源检索信息的范式\",\"Iterative Retrieval Augmentation\"]},\"2579\":{\"title\":\"Feed Forward Neural Network\",\"titles\":[\"Megatron-LM\",\"Transformer中的张量并行\"]},\"2580\":{\"title\":\"DeepSeek-R1在Chinese SimpleQA中的表现\",\"titles\":[\"实验结果\"]},\"2581\":{\"title\":\"Step 10: 相似度计算\",\"titles\":[\"Forward具体流程\",\"循环计算过程\"]},\"2582\":{\"title\":\"（3）上下文相关性\",\"titles\":[\"RAG评估\",\"开源RAG评估框架\",\"1. Ragas\"]},\"2583\":{\"title\":\"重点段落\",\"titles\":[\"Token-Level Loss 优化策略：提升深度学习模型的训练效果\"]},\"2584\":{\"title\":\"内容分块\",\"titles\":[\"RAG优化\"]},\"2585\":{\"title\":\"操作步骤\",\"titles\":[\"GRPO代码优化与重要性采样分析\"]},\"2586\":{\"title\":\"流程图\",\"titles\":[\"智能体的分类\",\"具体方法\",\"从外部来源检索信息的范式\",\"Iterative Retrieval Augmentation\"]},\"2587\":{\"title\":\"切分MLP\",\"titles\":[\"Megatron-LM\"]},\"2588\":{\"title\":\"总结生成的长度分析\",\"titles\":[\"实验结果\"]},\"2589\":{\"title\":\"Step 11: 掩码处理\",\"titles\":[\"Forward具体流程\",\"循环计算过程\"]},\"2590\":{\"title\":\"2. LangSmith\",\"titles\":[\"RAG评估\",\"开源RAG评估框架\"]},\"2591\":{\"title\":\"Token-Level Loss的优势\",\"titles\":[\"Token-Level Loss 优化策略：提升深度学习模型的训练效果\",\"重点段落\"]},\"2592\":{\"title\":\"优点\",\"titles\":[\"RAG优化\",\"内容分块\"]},\"2593\":{\"title\":\"常见错误\",\"titles\":[\"GRPO代码优化与重要性采样分析\"]},\"2594\":{\"title\":\"IRP：说明性文本生成任务\",\"titles\":[\"智能体的分类\",\"具体方法\",\"从外部来源检索信息的范式\"]},\"2595\":{\"title\":\"对比按照行列切分权重的方法\",\"titles\":[\"Megatron-LM\",\"切分MLP\"]},\"2596\":{\"title\":\"蒸馏实验结果\",\"titles\":[\"实验结果\"]},\"2597\":{\"title\":\"Step 12: 权重计算\",\"titles\":[\"Forward具体流程\",\"循环计算过程\"]},\"2598\":{\"title\":\"训练过程的稳定性\",\"titles\":[\"Token-Level Loss 优化策略：提升深度学习模型的训练效果\",\"重点段落\"]},\"2599\":{\"title\":\"缺点\",\"titles\":[\"RAG优化\",\"内容分块\"]},\"2600\":{\"title\":\"示例代码\",\"titles\":[\"GRPO代码优化与重要性采样分析\"]},\"2601\":{\"title\":\"方法简介\",\"titles\":[\"智能体的分类\",\"具体方法\",\"从外部来源检索信息的范式\",\"IRP：说明性文本生成任务\"]},\"2602\":{\"title\":\"行并行\",\"titles\":[\"Megatron-LM\",\"切分MLP\",\"对比按照行列切分权重的方法\"]},\"2603\":{\"title\":\"核心观点总结\",\"titles\":[\"实验结果\"]},\"2604\":{\"title\":\"Step 13: 更新最大值和权重\",\"titles\":[\"Forward具体流程\",\"循环计算过程\"]},\"2605\":{\"title\":\"问题解决与策略调整\",\"titles\":[\"Token-Level Loss 优化策略：提升深度学习模型的训练效果\",\"重点段落\"]},\"2606\":{\"title\":\"递归分块\",\"titles\":[\"RAG优化\"]},\"2607\":{\"title\":\"行动清单\",\"titles\":[\"GRPO代码优化与重要性采样分析\"]},\"2608\":{\"title\":\"流程细节\",\"titles\":[\"智能体的分类\",\"具体方法\",\"从外部来源检索信息的范式\",\"IRP：说明性文本生成任务\"]},\"2609\":{\"title\":\"列并行\",\"titles\":[\"Megatron-LM\",\"切分MLP\",\"对比按照行列切分权重的方法\"]},\"2610\":{\"title\":\"重点段落与数据\",\"titles\":[\"实验结果\"]},\"2611\":{\"title\":\"Step 14: Dropout操作\",\"titles\":[\"Forward具体流程\",\"循环计算过程\"]},\"2612\":{\"title\":\"操作步骤\",\"titles\":[\"Token-Level Loss 优化策略：提升深度学习模型的训练效果\"]},\"2613\":{\"title\":\"优点\",\"titles\":[\"RAG优化\",\"递归分块\"]},\"2614\":{\"title\":\"数据转换\",\"titles\":[\"GRPO代码优化与重要性采样分析\"]},\"2615\":{\"title\":\"流程图\",\"titles\":[\"智能体的分类\",\"具体方法\",\"从外部来源检索信息的范式\",\"IRP：说明性文本生成任务\"]},\"2616\":{\"title\":\"GELU计算中的行列切割策略\",\"titles\":[\"Megatron-LM\"]},\"2617\":{\"title\":\"1. 蒸馏模型的性能提升\",\"titles\":[\"实验结果\",\"重点段落与数据\"]},\"2618\":{\"title\":\"Step 15: 更新输出块\",\"titles\":[\"Forward具体流程\",\"循环计算过程\"]},\"2619\":{\"title\":\"常见错误\",\"titles\":[\"Token-Level Loss 优化策略：提升深度学习模型的训练效果\"]},\"2620\":{\"title\":\"缺点\",\"titles\":[\"RAG优化\",\"递归分块\"]},\"2621\":{\"title\":\"通信量分析\",\"titles\":[\"Megatron-LM\"]},\"2622\":{\"title\":\"2. 大规模模型的对比结果\",\"titles\":[\"实验结果\",\"重点段落与数据\"]},\"2623\":{\"title\":\"Step 16: 更新块信息\",\"titles\":[\"Forward具体流程\",\"循环计算过程\"]},\"2624\":{\"title\":\"💡 启发点\",\"titles\":[\"Token-Level Loss 优化策略：提升深度学习模型的训练效果\"]},\"2625\":{\"title\":\"从小到大分块\",\"titles\":[\"RAG优化\"]},\"2626\":{\"title\":\"Self-Attention的切分策略\",\"titles\":[\"Megatron-LM\"]},\"2627\":{\"title\":\"💡启发点\",\"titles\":[\"实验结果\"]},\"2628\":{\"title\":\"拼接结果\",\"titles\":[\"Forward具体流程\",\"循环计算过程\"]},\"2629\":{\"title\":\"行动清单\",\"titles\":[\"Token-Level Loss 优化策略：提升深度学习模型的训练效果\"]},\"2630\":{\"title\":\"优点\",\"titles\":[\"RAG优化\",\"从小到大分块\"]},\"2631\":{\"title\":\"多头注意力并行切分\",\"titles\":[\"Megatron-LM\",\"Self-Attention的切分策略\"]},\"2632\":{\"title\":\"discussion\",\"titles\":[]},\"2633\":{\"title\":\"计算量和显存\",\"titles\":[\"Forward具体流程\",\"循环计算过程\"]},\"2634\":{\"title\":\"Token-Level Loss 优化策略：提升深度学习模型的训练效果\",\"titles\":[]},\"2635\":{\"title\":\"缺点\",\"titles\":[\"RAG优化\",\"从小到大分块\"]},\"2636\":{\"title\":\"当num_heads = 2时的情况\",\"titles\":[\"Megatron-LM\",\"Self-Attention的切分策略\"]},\"2637\":{\"title\":\"核心观点总结\",\"titles\":[\"discussion\"]},\"2638\":{\"title\":\"FlashAttention 计算流程\",\"titles\":[\"Forward具体流程\"]},\"2639\":{\"title\":\"元数据\",\"titles\":[\"Token-Level Loss 优化策略：提升深度学习模型的训练效果\"]},\"2640\":{\"title\":\"特殊结构分块\",\"titles\":[\"RAG优化\"]},\"2641\":{\"title\":\"通信量分析\",\"titles\":[\"Megatron-LM\",\"Self-Attention的切分策略\"]},\"2642\":{\"title\":\"重点段落\",\"titles\":[\"discussion\"]},\"2643\":{\"title\":\"计算量\",\"titles\":[\"Forward具体流程\",\"FlashAttention 计算流程\"]},\"2644\":{\"title\":\"核心观点总结\",\"titles\":[\"Token-Level Loss 优化策略：提升深度学习模型的训练效果\"]},\"2645\":{\"title\":\"优点\",\"titles\":[\"RAG优化\",\"特殊结构分块\"]},\"2646\":{\"title\":\"Embedding切分策略\",\"titles\":[\"Megatron-LM\"]},\"2647\":{\"title\":\"技术术语解释\",\"titles\":[\"discussion\"]},\"2648\":{\"title\":\"显存\",\"titles\":[\"Forward具体流程\",\"FlashAttention 计算流程\"]},\"2649\":{\"title\":\"重点段落\",\"titles\":[\"Token-Level Loss 优化策略：提升深度学习模型的训练效果\"]},\"2650\":{\"title\":\"缺点\",\"titles\":[\"RAG优化\",\"特殊结构分块\"]},\"2651\":{\"title\":\"输入层embedding\",\"titles\":[\"Megatron-LM\",\"Embedding切分策略\"]},\"2652\":{\"title\":\"操作步骤\",\"titles\":[\"discussion\"]},\"2653\":{\"title\":\"IO复杂度\",\"titles\":[\"Forward具体流程\",\"FlashAttention 计算流程\"]},\"2654\":{\"title\":\"Token-Level Loss的优势\",\"titles\":[\"Token-Level Loss 优化策略：提升深度学习模型的训练效果\",\"重点段落\"]},\"2655\":{\"title\":\"分块大小的选择\",\"titles\":[\"RAG优化\"]},\"2656\":{\"title\":\"输出层embedding\",\"titles\":[\"Megatron-LM\",\"Embedding切分策略\"]},\"2657\":{\"title\":\"常见错误\",\"titles\":[\"discussion\"]},\"2658\":{\"title\":\"训练过程的稳定性\",\"titles\":[\"Token-Level Loss 优化策略：提升深度学习模型的训练效果\",\"重点段落\"]},\"2659\":{\"title\":\"Embedding模型阶段\",\"titles\":[\"RAG优化\"]},\"2660\":{\"title\":\"Cross-entropy切分的基本流程\",\"titles\":[\"Megatron-LM\"]},\"2661\":{\"title\":\"💡启发点\",\"titles\":[\"discussion\"]},\"2662\":{\"title\":\"问题解决与策略调整\",\"titles\":[\"Token-Level Loss 优化策略：提升深度学习模型的训练效果\",\"重点段落\"]},\"2663\":{\"title\":\"不同嵌入模型的效果差异\",\"titles\":[\"RAG优化\",\"Embedding模型阶段\"]},\"2664\":{\"title\":\"优化策略\",\"titles\":[\"Megatron-LM\"]},\"2665\":{\"title\":\"操作步骤\",\"titles\":[\"Token-Level Loss 优化策略：提升深度学习模型的训练效果\"]},\"2666\":{\"title\":\"向量数据库阶段\",\"titles\":[\"RAG优化\"]},\"2667\":{\"title\":\"GPU上的局部计算\",\"titles\":[\"Megatron-LM\",\"优化策略\"]},\"2668\":{\"title\":\"常见错误\",\"titles\":[\"Token-Level Loss 优化策略：提升深度学习模型的训练效果\"]},\"2669\":{\"title\":\"元数据的作用\",\"titles\":[\"RAG优化\",\"向量数据库阶段\"]},\"2670\":{\"title\":\"AllReduce操作\",\"titles\":[\"Megatron-LM\",\"优化策略\"]},\"2671\":{\"title\":\"💡 启发点\",\"titles\":[\"Token-Level Loss 优化策略：提升深度学习模型的训练效果\"]},\"2672\":{\"title\":\"示例：日期作为元数据标签\",\"titles\":[\"RAG优化\",\"向量数据库阶段\",\"元数据的作用\"]},\"2673\":{\"title\":\"计算局部Cross-entropy\",\"titles\":[\"Megatron-LM\",\"优化策略\"]},\"2674\":{\"title\":\"行动清单\",\"titles\":[\"Token-Level Loss 优化策略：提升深度学习模型的训练效果\"]},\"2675\":{\"title\":\"其他元数据类型\",\"titles\":[\"RAG优化\",\"向量数据库阶段\",\"元数据的作用\"]},\"2676\":{\"title\":\"汇总总Loss\",\"titles\":[\"Megatron-LM\",\"优化策略\"]},\"2677\":{\"title\":\"优化过长回答的奖励机制：提升模型性能\",\"titles\":[]},\"2678\":{\"title\":\"[[大语言模型学习/大模型应用/RAG检索增强生成/RAG优化中查询索引阶段|RAG优化中查询索引阶段]]\",\"titles\":[]},\"2679\":{\"title\":\"TransformerBlock中的通信优化\",\"titles\":[\"Megatron-LM\"]},\"2680\":{\"title\":\"分类：机器学习优化\",\"titles\":[\"优化过长回答的奖励机制：提升模型性能\"]},\"2681\":{\"title\":\"生成回答阶段的设计与优化\",\"titles\":[\"[[大语言模型学习/大模型应用/RAG检索增强生成/RAG优化中查询索引阶段|RAG优化中查询索引阶段]]\"]},\"2682\":{\"title\":\"张量并行与序列并行\",\"titles\":[\"Megatron-LM\"]},\"2683\":{\"title\":\"标签：奖励机制，模型训练，性能提升\",\"titles\":[\"优化过长回答的奖励机制：提升模型性能\",\"分类：机器学习优化\"]},\"2684\":{\"title\":\"提示词设计的关键要点\",\"titles\":[\"[[大语言模型学习/大模型应用/RAG检索增强生成/RAG优化中查询索引阶段|RAG优化中查询索引阶段]]\",\"生成回答阶段的设计与优化\"]},\"2685\":{\"title\":\"流水线并行 Inter-Layer Pipeline Parallelism\",\"titles\":[]},\"2686\":{\"title\":\"日期：2025年4月12日\",\"titles\":[\"优化过长回答的奖励机制：提升模型性能\",\"分类：机器学习优化\"]},\"2687\":{\"title\":\"提示词对模型行为的影响\",\"titles\":[\"[[大语言模型学习/大模型应用/RAG检索增强生成/RAG优化中查询索引阶段|RAG优化中查询索引阶段]]\",\"生成回答阶段的设计与优化\",\"提示词设计的关键要点\"]},\"2688\":{\"title\":\"代码块\",\"titles\":[\"流水线并行 Inter-Layer Pipeline Parallelism\"]},\"2689\":{\"title\":\"核心观点\",\"titles\":[\"优化过长回答的奖励机制：提升模型性能\"]},\"2690\":{\"title\":\"减少主观性和幻觉的提示词策略\",\"titles\":[\"[[大语言模型学习/大模型应用/RAG检索增强生成/RAG优化中查询索引阶段|RAG优化中查询索引阶段]]\",\"生成回答阶段的设计与优化\",\"提示词设计的关键要点\"]},\"2691\":{\"title\":\"Gpipe\",\"titles\":[\"流水线并行 Inter-Layer Pipeline Parallelism\",\"代码块\"]},\"2692\":{\"title\":\"重点内容\",\"titles\":[\"优化过长回答的奖励机制：提升模型性能\"]},\"2693\":{\"title\":\"动态调整提示词以适应场景需求\",\"titles\":[\"[[大语言模型学习/大模型应用/RAG检索增强生成/RAG优化中查询索引阶段|RAG优化中查询索引阶段]]\",\"生成回答阶段的设计与优化\",\"提示词设计的关键要点\"]},\"2694\":{\"title\":\"PipeDream\",\"titles\":[\"流水线并行 Inter-Layer Pipeline Parallelism\",\"代码块\"]},\"2695\":{\"title\":\"操作步骤\",\"titles\":[\"优化过长回答的奖励机制：提升模型性能\"]},\"2696\":{\"title\":\"模型选择与开发框架\",\"titles\":[\"[[大语言模型学习/大模型应用/RAG检索增强生成/RAG优化中查询索引阶段|RAG优化中查询索引阶段]]\",\"生成回答阶段的设计与优化\"]},\"2697\":{\"title\":\"Virtual Pipeline\",\"titles\":[\"流水线并行 Inter-Layer Pipeline Parallelism\",\"代码块\"]},\"2698\":{\"title\":\"常见错误\",\"titles\":[\"优化过长回答的奖励机制：提升模型性能\"]},\"2699\":{\"title\":\"根据需求选择合适的 LLM\",\"titles\":[\"[[大语言模型学习/大模型应用/RAG检索增强生成/RAG优化中查询索引阶段|RAG优化中查询索引阶段]]\",\"生成回答阶段的设计与优化\",\"模型选择与开发框架\"]},\"2700\":{\"title\":\"3D并行\",\"titles\":[\"流水线并行 Inter-Layer Pipeline Parallelism\"]},\"2701\":{\"title\":\"行动清单\",\"titles\":[\"优化过长回答的奖励机制：提升模型性能\"]},\"2702\":{\"title\":\"使用开发框架搭建 RAG 系统\",\"titles\":[\"[[大语言模型学习/大模型应用/RAG检索增强生成/RAG优化中查询索引阶段|RAG优化中查询索引阶段]]\",\"生成回答阶段的设计与优化\",\"模型选择与开发框架\"]},\"2703\":{\"title\":\"数据并行\",\"titles\":[\"流水线并行 Inter-Layer Pipeline Parallelism\"]},\"2704\":{\"title\":\"计算效率高， 实现简单\",\"titles\":[\"流水线并行 Inter-Layer Pipeline Parallelism\",\"数据并行\"]},\"2705\":{\"title\":\"张量并行\",\"titles\":[\"流水线并行 Inter-Layer Pipeline Parallelism\"]},\"2706\":{\"title\":\"因模型结构而异， 实现难度大\",\"titles\":[\"流水线并行 Inter-Layer Pipeline Parallelism\",\"张量并行\"]},\"2707\":{\"title\":\"流水线并行\",\"titles\":[\"流水线并行 Inter-Layer Pipeline Parallelism\"]},\"2708\":{\"title\":\"通信成本最低\",\"titles\":[\"流水线并行 Inter-Layer Pipeline Parallelism\",\"流水线并行\"]},\"2709\":{\"title\":\"显存和通信效率比较\",\"titles\":[\"流水线并行 Inter-Layer Pipeline Parallelism\"]},\"2710\":{\"title\":\"3D并行技术的混合应用\",\"titles\":[\"流水线并行 Inter-Layer Pipeline Parallelism\"]},\"2711\":{\"title\":\"4D并行技术在LLaMA3中的应用\",\"titles\":[\"流水线并行 Inter-Layer Pipeline Parallelism\"]}},\"dirtCount\":0,\"index\":[[\"量\",{\"2\":{\"2697\":1}}],[\"量化评估通常使用一些文本相似性指标来衡量生成内容与参考答案之间的相似程度\",{\"2\":{\"2292\":1}}],[\"量化评估\",{\"0\":{\"2292\":1}}],[\"量化权重\",{\"2\":{\"2085\":1}}],[\"量化误差=i=1∑n​∣原始权重i​−量化权重i​∣\",{\"2\":{\"2085\":1}}],[\"量化误差=∑i=1n∣原始权重i−量化权重i∣\",{\"2\":{\"2085\":1}}],[\"量化误差\",{\"2\":{\"2085\":1}}],[\"量化需要准备校准数据集\",{\"2\":{\"2085\":1}}],[\"量化感知微调\",{\"0\":{\"1209\":1,\"1494\":1},\"1\":{\"1538\":1,\"1588\":1,\"1641\":1,\"1695\":1},\"2\":{\"1209\":1}}],[\"量化感知训练首先需要对模型进行正常的预训练\",{\"2\":{\"1355\":1}}],[\"量化感知训练的基本原理\",{\"0\":{\"1355\":1}}],[\"量化感知训练\",{\"0\":{\"1160\":1,\"1308\":1},\"1\":{\"1355\":1,\"1400\":1,\"1448\":1},\"2\":{\"1160\":1,\"1308\":1,\"1813\":1}}],[\"量化可以分为以下几类\",{\"2\":{\"1110\":1}}],[\"量化技术被广泛应用于减少模型的复杂性和提高效率\",{\"2\":{\"1753\":1}}],[\"量化技术通过将模型参数和计算从浮点数表示转换为低精度表示\",{\"2\":{\"1110\":1}}],[\"量化技术应运而生\",{\"2\":{\"1110\":1}}],[\"量化分类\",{\"0\":{\"1110\":1},\"1\":{\"1160\":1,\"1209\":1,\"1260\":1}}],[\"量化示意图\",{\"0\":{\"1065\":1},\"2\":{\"1065\":1}}],[\"量化粒度更细\",{\"2\":{\"981\":1}}],[\"量化方法可以进行以下分类\",{\"0\":{\"904\":1},\"1\":{\"939\":1,\"981\":1,\"1022\":1}}],[\"量化形式\",{\"0\":{\"833\":1},\"1\":{\"868\":1,\"904\":1,\"939\":1,\"981\":1,\"1022\":1,\"1065\":1}}],[\"量化激活值不仅可以大大减少内存占用\",{\"2\":{\"799\":1}}],[\"量化对象\",{\"0\":{\"799\":1}}],[\"量化和混合精度训练\",{\"2\":{\"763\":1}}],[\"量化\",{\"2\":{\"40\":1,\"763\":1,\"799\":1,\"1982\":1,\"2085\":1}}],[\"虚拟流水线则采取相反的策略\",{\"2\":{\"2688\":1}}],[\"闲着\",{\"2\":{\"2688\":2}}],[\"汇总总loss\",{\"0\":{\"2676\":1}}],[\"汇总结果会被广播回每个节点\",{\"2\":{\"2452\":1}}],[\"把它们concat起来形成yyy\",{\"2\":{\"2660\":1}}],[\"把二者的难度中和一下\",{\"2\":{\"2033\":1}}],[\"明确定义细粒度步骤具有挑战性\",{\"2\":{\"2642\":1}}],[\"库时\",{\"2\":{\"2606\":1}}],[\"库中的代码实现的核心部分\",{\"2\":{\"2500\":1}}],[\"=gelu\",{\"2\":{\"2602\":1}}],[\"≠gelu\",{\"2\":{\"2602\":1}}],[\"掩码处理\",{\"0\":{\"2589\":1}}],[\"倾向于拒绝回答某些查询\",{\"2\":{\"2580\":1}}],[\"次外循环\",{\"2\":{\"2653\":1}}],[\"次\",{\"2\":{\"2579\":1}}],[\"次的transformer层\",{\"2\":{\"2579\":1}}],[\"红色的\",{\"2\":{\"2579\":1}}],[\"紫色块对应于全连接层\",{\"2\":{\"2579\":1}}],[\"掉临时句子中概率低于阈值的\",{\"2\":{\"2578\":1}}],[\"忠实性=总答案数基于上下文生成的正确答案数​\",{\"2\":{\"2566\":1}}],[\"忠实性=基于上下文生成的正确答案数总答案数\",{\"2\":{\"2566\":1}}],[\"忠实性\",{\"0\":{\"2566\":1},\"2\":{\"2566\":1}}],[\"附件中未显示具体流程图\",{\"2\":{\"2554\":1}}],[\"附加要求\",{\"0\":{\"2293\":1},\"1\":{\"2324\":1,\"2355\":1,\"2385\":1,\"2412\":1,\"2437\":1,\"2459\":1}}],[\"版本则只更新一次\",{\"2\":{\"2545\":1}}],[\"拒答可以分为以下两种情况\",{\"2\":{\"2540\":1}}],[\"拒答\",{\"0\":{\"2540\":1}}],[\"拒绝采样方法\",{\"0\":{\"1164\":1}}],[\"拒绝采样\",{\"2\":{\"986\":1,\"1164\":1,\"1181\":1,\"1267\":1,\"2516\":1}}],[\"碎片化问题\",{\"0\":{\"2533\":1}}],[\"融合多个回答模块\",{\"2\":{\"2523\":1}}],[\"融合多模态信息\",{\"2\":{\"1543\":1}}],[\"功能模块化\",{\"2\":{\"2523\":1}}],[\"仍然会出现事实性问题\",{\"2\":{\"2514\":1}}],[\"仍然是千卡集群以上最佳的选择\",{\"2\":{\"2118\":1}}],[\"仍然是一个快速而有效的选择\",{\"2\":{\"1260\":1}}],[\"弱相关性\",{\"0\":{\"2506\":1}}],[\"易混淆实体\",{\"0\":{\"2493\":1}}],[\"易知\",{\"2\":{\"2286\":2}}],[\"响应生成质量存在幻觉\",{\"2\":{\"2466\":1}}],[\"噪音文档是指那些与问题相关但不包含任何相关信息的文档\",{\"2\":{\"2458\":1}}],[\"噪音评估\",{\"0\":{\"2458\":1}}],[\"噪声数据会显著影响分词效果\",{\"2\":{\"461\":1}}],[\"试验不同模型组合以优化训练效果\",{\"2\":{\"2453\":1}}],[\"试错往往是无法避免的\",{\"2\":{\"1557\":1}}],[\"求\",{\"2\":{\"2643\":1}}],[\"求最大值等\",{\"2\":{\"2452\":1}}],[\"求平均\",{\"2\":{\"2452\":1}}],[\"求和\",{\"2\":{\"2452\":1}}],[\"供大型语言模型生成答案\",{\"2\":{\"2445\":1}}],[\"卡\",{\"2\":{\"2433\":1}}],[\"卡上\",{\"2\":{\"2079\":1,\"2129\":1}}],[\"攻击等\",{\"2\":{\"2418\":1}}],[\"处于较低的抽象层次\",{\"2\":{\"2408\":1}}],[\"处理器每秒钟从内存中读取的数据量\",{\"2\":{\"1977\":1}}],[\"处理器每秒钟可以执行的数学计算次数\",{\"2\":{\"1977\":1}}],[\"处理速度较慢\",{\"2\":{\"1562\":1}}],[\"处理时间长\",{\"2\":{\"1562\":1}}],[\"处理率在前几个交互步骤中就能快速收敛到一个较高值\",{\"2\":{\"1701\":1}}],[\"处理率随交互步骤数收敛较慢\",{\"2\":{\"1701\":1}}],[\"处理率能够更细致地衡量模型在任务处理过程中的表现\",{\"2\":{\"1544\":1}}],[\"处理率用来表示\",{\"2\":{\"1544\":1}}],[\"处理率\",{\"0\":{\"1544\":1},\"2\":{\"1544\":1}}],[\"处理\",{\"2\":{\"1258\":1,\"1306\":1}}],[\"处理机制\",{\"0\":{\"1258\":1},\"2\":{\"1108\":1}}],[\"处理元音字母\",{\"2\":{\"783\":1}}],[\"处理噪声能力强\",{\"2\":{\"419\":1}}],[\"处理输入特征并生成非线性输出\",{\"2\":{\"178\":1}}],[\"处理多个外部服务的api集成是复杂的任务\",{\"2\":{\"137\":1}}],[\"处理业务逻辑或用户请求\",{\"2\":{\"118\":1}}],[\"稳健值迭代\",{\"2\":{\"2405\":1}}],[\"稳定阶段\",{\"2\":{\"1344\":1}}],[\"稳定性较好\",{\"2\":{\"315\":1}}],[\"冷启动数据用于稳定强化学习初期训练\",{\"2\":{\"2474\":1}}],[\"冷启动的作用\",{\"0\":{\"2474\":1}}],[\"冷启动\",{\"2\":{\"2404\":1,\"2516\":1}}],[\"顺序训练\",{\"0\":{\"2399\":1}}],[\"顺序重建连续tokens\",{\"2\":{\"1004\":1}}],[\"却只是前\",{\"2\":{\"2379\":1}}],[\"想一想\",{\"2\":{\"2379\":1}}],[\"细节语义信息容易被平均化或淡化\",{\"2\":{\"2444\":1}}],[\"细心的你肯定又发现了\",{\"2\":{\"2379\":1}}],[\"细粒度专家分配\",{\"2\":{\"998\":1}}],[\"乐观规划算法\",{\"2\":{\"2378\":1}}],[\"划分成多组\",{\"2\":{\"2685\":1}}],[\"划分技能库并准备种子提示\",{\"2\":{\"2375\":1}}],[\"划分策略\",{\"2\":{\"1421\":1}}],[\"张卡\",{\"2\":{\"2374\":1}}],[\"张量并行的实现难度较大\",{\"2\":{\"2706\":1}}],[\"张量并行的并行度可以低于\",{\"2\":{\"2079\":1}}],[\"张量并行对attentionblock和mlp都进行了并行化\",{\"2\":{\"2682\":1}}],[\"张量并行与序列并行\",{\"0\":{\"2682\":1}}],[\"张量并行就是要对transformer进行切分\",{\"2\":{\"2579\":1}}],[\"张量并行又可以分成行并行和列并行\",{\"2\":{\"2526\":1}}],[\"张量并行涉及\",{\"2\":{\"2218\":1}}],[\"张量并行\",{\"0\":{\"2218\":1,\"2515\":1,\"2705\":1},\"1\":{\"2526\":1,\"2537\":1,\"2706\":1},\"2\":{\"2167\":1,\"2710\":1}}],[\"克服了许多技术挑战\",{\"2\":{\"2366\":1}}],[\"便于构建复杂的\",{\"2\":{\"2702\":1}}],[\"便于分类和检索\",{\"2\":{\"2675\":1}}],[\"便于计算机进行处理和分析\",{\"2\":{\"2659\":1}}],[\"便于语言模型处理和理解\",{\"2\":{\"2364\":1}}],[\"便能自主学习出更优的问题解决策略\",{\"2\":{\"2283\":1}}],[\"写回hbm\",{\"2\":{\"2653\":1}}],[\"写下初稿\",{\"2\":{\"2363\":1}}],[\"写一个mit的xv6操作系统\",{\"2\":{\"56\":1}}],[\"极大地提高了模型训练的效率\",{\"2\":{\"2351\":1}}],[\"呢\",{\"2\":{\"2349\":1}}],[\"警惕\",{\"2\":{\"2343\":1}}],[\"警告或反对的内容\",{\"2\":{\"1368\":1}}],[\"警告\",{\"2\":{\"223\":1,\"600\":1,\"601\":1,\"647\":1,\"673\":1,\"686\":1,\"731\":1,\"809\":1,\"834\":1,\"1157\":1,\"1174\":1,\"1189\":1,\"1314\":1,\"1352\":1,\"1399\":1,\"1601\":1,\"1696\":1,\"1733\":1,\"1778\":1,\"1850\":1,\"1945\":1,\"1975\":1,\"2018\":1,\"2086\":1,\"2127\":1,\"2290\":1,\"2390\":1,\"2403\":1,\"2513\":1,\"2530\":1,\"2593\":1,\"2657\":1}}],[\"警告区块\",{\"0\":{\"566\":1,\"718\":1,\"1236\":1,\"1741\":1,\"2028\":1},\"2\":{\"198\":1,\"565\":1,\"627\":1,\"967\":1,\"1335\":1,\"1482\":1}}],[\"卸载策略如何优化深度学习模型的训练过程\",{\"2\":{\"2339\":1}}],[\"卸载技术\",{\"0\":{\"2339\":1},\"1\":{\"2369\":1,\"2397\":1,\"2422\":1,\"2447\":1,\"2468\":1,\"2486\":1}}],[\"制定详细的评估指标并测试其有效性\",{\"2\":{\"2332\":1}}],[\"制定api密钥管理策略以确保安全性\",{\"2\":{\"242\":1}}],[\"促进低概率token的探索\",{\"2\":{\"2327\":1}}],[\"意图分流不仅用于解析用户意图\",{\"2\":{\"2323\":1}}],[\"意图分流环节扮演了重要角色\",{\"2\":{\"2323\":1}}],[\"意图分流评估\",{\"0\":{\"2323\":1},\"1\":{\"2354\":1,\"2384\":1}}],[\"意味着每个输入都有唯一的输出\",{\"2\":{\"918\":1}}],[\"蒙特卡罗树搜索\",{\"2\":{\"2378\":1}}],[\"蒙特卡罗树搜索和深度\",{\"2\":{\"2317\":1}}],[\"蒙特卡洛估计通常伴随着高方差\",{\"2\":{\"2157\":1}}],[\"蒙特卡洛估计与价值模型\",{\"0\":{\"2157\":1}}],[\"蒙特卡洛估计可能导致方差过大\",{\"2\":{\"2146\":1,\"2191\":1}}],[\"蒙特卡洛估计\",{\"2\":{\"1992\":1,\"2045\":1}}],[\"蒙特卡洛\",{\"2\":{\"617\":1}}],[\"蒙特卡洛方法将在实时数据分析和预测建模中发挥更大作用\",{\"2\":{\"952\":1}}],[\"蒙特卡洛方法在复杂系统模拟中的广泛应用\",{\"2\":{\"878\":1}}],[\"蒙特卡洛方法利用随机抽样来估计复杂系统的行为\",{\"2\":{\"713\":1}}],[\"蒙特卡洛方法无偏但方差较大\",{\"2\":{\"672\":1}}],[\"蒙特卡洛方法\",{\"0\":{\"607\":1},\"1\":{\"641\":1,\"675\":1,\"713\":1,\"747\":1,\"778\":1,\"809\":1,\"843\":1,\"878\":1,\"914\":1,\"952\":1,\"993\":1},\"2\":{\"151\":1,\"540\":1,\"641\":1,\"675\":1}}],[\"蒙特卡洛方法|蒙特卡洛方法\",{\"2\":{\"5\":1}}],[\"年\",{\"2\":{\"2313\":1}}],[\"年龄\",{\"2\":{\"164\":2}}],[\"折扣累积奖励\",{\"2\":{\"2306\":1}}],[\"折扣因子\",{\"2\":{\"643\":1,\"646\":1,\"656\":1,\"820\":1}}],[\"难度升级策略\",{\"2\":{\"2401\":1}}],[\"难度升级可以使用\",{\"2\":{\"2280\":1}}],[\"难以理解\",{\"2\":{\"2315\":1}}],[\"难以定义奖励函数的问题\",{\"2\":{\"1633\":1}}],[\"底层的叶子节点的块大小为$$128$$\",{\"2\":{\"2271\":1}}],[\"底层api替换\",{\"2\":{\"2073\":1}}],[\"顶层节点的块大小为$$1024$$\",{\"2\":{\"2271\":1}}],[\"顶层智能体\",{\"0\":{\"1904\":1}}],[\"好用的pdf文件解析工具推荐\",{\"0\":{\"2270\":1}}],[\"好处\",{\"2\":{\"183\":1}}],[\"估算方法\",{\"0\":{\"2263\":1}}],[\"估计q值\",{\"2\":{\"586\":1}}],[\"估计每个子词的概率\",{\"2\":{\"393\":1}}],[\"润色的过程\",{\"2\":{\"2259\":1}}],[\"判断\",{\"2\":{\"2312\":1}}],[\"判断是否适用这一工作流的两个重要标准是\",{\"2\":{\"2259\":1}}],[\"判断标题层级\",{\"2\":{\"2235\":1}}],[\"迭代\",{\"2\":{\"2363\":1}}],[\"迭代式生成代码\",{\"2\":{\"2277\":1}}],[\"迭代优化有效\",{\"2\":{\"2259\":1}}],[\"迭代训练\",{\"0\":{\"2026\":1}}],[\"答案应基于给定的上下文\",{\"2\":{\"2566\":1}}],[\"答案评估\",{\"0\":{\"2411\":1},\"1\":{\"2436\":1}}],[\"答案相关性和上下文相关性的框架\",{\"2\":{\"2558\":1}}],[\"答案相关性\",{\"0\":{\"2574\":1},\"2\":{\"2257\":1}}],[\"答案忠实性\",{\"2\":{\"2257\":1}}],[\"答复并对其评分\",{\"2\":{\"2227\":1}}],[\"答复中的信息\",{\"2\":{\"2227\":1}}],[\"聊天\",{\"2\":{\"2245\":1}}],[\"擅长的任务项\",{\"2\":{\"2245\":1}}],[\"父文档搜索是一种与窗口搜索类似的解决方案\",{\"2\":{\"2236\":1}}],[\"父文档搜索\",{\"0\":{\"2236\":1}}],[\"六度分隔\",{\"2\":{\"2234\":1}}],[\"启动训练\",{\"2\":{\"2233\":1}}],[\"启发式规则合成\",{\"2\":{\"2168\":1}}],[\"启发式方法\",{\"0\":{\"874\":1},\"1\":{\"910\":1}}],[\"启发标注\",{\"0\":{\"1507\":1}}],[\"启发了我们思考如何通过简单的随机过程解决复杂问题\",{\"2\":{\"878\":1}}],[\"启发点\",{\"0\":{\"232\":1,\"264\":1,\"270\":1,\"404\":1,\"664\":1,\"711\":1,\"915\":1,\"1303\":1,\"1348\":1,\"1357\":1,\"1372\":1,\"1397\":1,\"1656\":1,\"1693\":1,\"1908\":1,\"1979\":1,\"2058\":1,\"2109\":1,\"2136\":1,\"2207\":1,\"2240\":1,\"2330\":1,\"2396\":1,\"2428\":1,\"2495\":1,\"2509\":1,\"2541\":1,\"2624\":1,\"2671\":1},\"1\":{\"293\":1,\"315\":1},\"2\":{\"155\":1,\"157\":1,\"162\":1,\"183\":1,\"190\":1,\"205\":1,\"216\":1,\"246\":1,\"263\":1,\"293\":1,\"301\":1,\"308\":1,\"319\":1,\"324\":1,\"369\":1,\"434\":1,\"445\":1,\"456\":1,\"488\":1,\"501\":1,\"503\":1,\"507\":1,\"532\":1,\"537\":1,\"548\":1,\"558\":1,\"568\":1,\"589\":1,\"610\":1,\"622\":1,\"656\":1,\"741\":1,\"840\":1,\"867\":1,\"882\":1,\"996\":1,\"1006\":1,\"1025\":1,\"1187\":1,\"1198\":1,\"1207\":1,\"1246\":1,\"1262\":1,\"1282\":1,\"1306\":1,\"1517\":1,\"1614\":1,\"1650\":1,\"1667\":1,\"1825\":1,\"1832\":1,\"2248\":1,\"2485\":1,\"2600\":1}}],[\"评分模块\",{\"2\":{\"2227\":1}}],[\"评估token\",{\"2\":{\"2629\":1,\"2674\":1}}],[\"评估结果\",{\"2\":{\"2622\":1}}],[\"评估和监控基于任何\",{\"2\":{\"2590\":1}}],[\"评估动态采样对模型性能的影响\",{\"2\":{\"2551\":1}}],[\"评估chunking方法在不同模型架构中的适用性\",{\"2\":{\"2478\":1}}],[\"评估clip\",{\"2\":{\"2461\":1}}],[\"评估当前模型的损失函数设置是否合理\",{\"2\":{\"2470\":1}}],[\"评估当前策略性能的模型\",{\"2\":{\"2004\":1}}],[\"评估现有对话数据是否符合真多轮和伪多轮的标准\",{\"2\":{\"2410\":1}}],[\"评估vapo在实际应用中的可行性和效率\",{\"2\":{\"2307\":1}}],[\"评估者\",{\"2\":{\"2294\":1}}],[\"评估激活值\",{\"2\":{\"2266\":1}}],[\"评估准备\",{\"2\":{\"2233\":1}}],[\"评估准确率达\",{\"2\":{\"49\":1}}],[\"评估生成内容的质量是一个至关重要的环节\",{\"2\":{\"2222\":1}}],[\"评估生成答案的正确性\",{\"2\":{\"1797\":1}}],[\"评估原则\",{\"2\":{\"2194\":1}}],[\"评估\",{\"0\":{\"2224\":1},\"2\":{\"2089\":1}}],[\"评估x\",{\"2\":{\"2078\":1}}],[\"评估reference\",{\"2\":{\"2053\":1}}],[\"评估rlhf在不同任务中的效果\",{\"2\":{\"1863\":1}}],[\"评估mixtral在不同任务场景下的性能表现\",{\"2\":{\"2038\":1}}],[\"评估微调后的模型性能\",{\"2\":{\"2034\":1}}],[\"评估llama\",{\"2\":{\"1953\":1}}],[\"评估gae与value结合使用的效果\",{\"2\":{\"1934\":1}}],[\"评估gpt\",{\"2\":{\"1370\":1}}],[\"评估召回相关文档的比率\",{\"2\":{\"1933\":1}}],[\"评估instructgpt在不同领域指令遵循能力的表现\",{\"2\":{\"1861\":1}}],[\"评估指标单一\",{\"2\":{\"1453\":1}}],[\"评估拒绝采样在其他模型中的适用性\",{\"2\":{\"1403\":1}}],[\"评估的一些做法和思考\",{\"2\":{\"1309\":1}}],[\"评估一直以来都是一个非常令人头疼的问题\",{\"2\":{\"1309\":1}}],[\"评估方式\",{\"0\":{\"1268\":1,\"1407\":1}}],[\"评估最佳结果\",{\"2\":{\"1152\":1}}],[\"评估示例质量\",{\"2\":{\"1075\":1}}],[\"评估actor产生的轨迹质量\",{\"2\":{\"2113\":1}}],[\"评估agenttuning框架在不同环境中的适用性\",{\"2\":{\"1008\":1}}],[\"评估ai工具在多服务集成中的作用\",{\"2\":{\"265\":1}}],[\"评估不同的数据标注工具\",{\"2\":{\"2409\":1}}],[\"评估不同句子在模型中的概率变化\",{\"2\":{\"626\":1}}],[\"评估不同分词算法在实际任务中的表现\",{\"2\":{\"555\":1}}],[\"评估语言理解和推理的更深层次\",{\"2\":{\"549\":1}}],[\"评估根据陈述推理正确类别的能力\",{\"2\":{\"549\":1}}],[\"评估广泛主题领域的理解和推理能力\",{\"2\":{\"549\":1}}],[\"评估模型在长文本中提取单一关键信息的能力\",{\"2\":{\"524\":1}}],[\"评估其对混合精度训练性能的影响\",{\"2\":{\"698\":1}}],[\"评估其性能和生成质量\",{\"2\":{\"481\":1}}],[\"评估其适用性\",{\"2\":{\"334\":1}}],[\"评估子词重要性\",{\"2\":{\"393\":1}}],[\"评估显存使用情况\",{\"2\":{\"353\":1}}],[\"评估与部署\",{\"2\":{\"40\":1}}],[\"社交媒体等渠道获取数据\",{\"2\":{\"2220\":1}}],[\"清洗和标注后用于模型训练\",{\"2\":{\"2220\":1}}],[\"清洗后达到570g\",{\"2\":{\"1278\":1}}],[\"诚实性\",{\"2\":{\"2194\":1}}],[\"静态值分析\",{\"0\":{\"2192\":1}}],[\"静态预测任务适合有监督学习\",{\"2\":{\"858\":1}}],[\"综上所述\",{\"2\":{\"2655\":1}}],[\"综合以上三点\",{\"2\":{\"2643\":1}}],[\"综合采样策略对生成质量的提升\",{\"2\":{\"739\":1}}],[\"综合采样策略\",{\"0\":{\"441\":1},\"1\":{\"468\":1}}],[\"综述\",{\"0\":{\"2177\":1}}],[\"资料\",{\"2\":{\"2174\":1}}],[\"资源需求\",{\"2\":{\"1539\":1}}],[\"资源预算\",{\"2\":{\"1132\":1}}],[\"资源管理优化\",{\"2\":{\"605\":1}}],[\"节省gpu资源\",{\"2\":{\"2166\":1}}],[\"节省计算成本\",{\"2\":{\"40\":1}}],[\"搜索结果越单一\",{\"2\":{\"2163\":1}}],[\"剩余状态\",{\"2\":{\"2161\":1}}],[\"剩余节点\",{\"2\":{\"48\":1}}],[\"φ=b∗s∗h\",{\"2\":{\"2621\":2,\"2641\":2}}],[\"φ\",{\"2\":{\"2161\":1,\"2621\":1,\"2641\":2}}],[\"日常语言中往往充满歧义和无意义的助词\",{\"2\":{\"2155\":1}}],[\"日期最近的电子邮件可能更符合用户的查询需求\",{\"2\":{\"2672\":1}}],[\"日期是一个常见且实用的元数据标签\",{\"2\":{\"2672\":1}}],[\"日期作为元数据标签\",{\"0\":{\"2672\":1}}],[\"日期\",{\"0\":{\"604\":1,\"839\":1,\"1005\":1,\"1039\":1,\"1067\":1,\"1100\":1,\"1214\":1,\"1319\":1,\"1570\":1,\"1581\":1,\"1691\":1,\"1734\":1,\"1815\":1,\"1828\":1,\"1841\":1,\"1888\":1,\"1900\":1,\"2232\":1,\"2686\":1},\"2\":{\"71\":1,\"74\":1,\"80\":1,\"85\":1,\"87\":1,\"88\":1,\"92\":1,\"94\":1,\"96\":1,\"104\":1,\"110\":1,\"119\":1,\"132\":1,\"139\":1,\"142\":1,\"154\":1,\"160\":1,\"181\":1,\"182\":1,\"225\":1,\"226\":1,\"229\":1,\"273\":1,\"286\":1,\"297\":1,\"320\":1,\"328\":1,\"344\":1,\"345\":1,\"347\":1,\"377\":1,\"382\":1,\"384\":1,\"396\":1,\"397\":1,\"398\":1,\"405\":1,\"424\":1,\"431\":1,\"436\":1,\"437\":1,\"478\":1,\"484\":1,\"487\":1,\"489\":1,\"539\":1,\"540\":1,\"543\":1,\"545\":1,\"550\":1,\"552\":1,\"573\":1,\"588\":1,\"617\":1,\"641\":1,\"642\":1,\"659\":1,\"832\":1,\"835\":1,\"836\":1,\"848\":1,\"854\":1,\"859\":1,\"861\":1,\"862\":1,\"865\":1,\"883\":1,\"887\":1,\"890\":1,\"899\":1,\"908\":1,\"920\":1,\"922\":1,\"930\":1,\"935\":1,\"986\":1,\"987\":1,\"988\":1,\"990\":1,\"1000\":1,\"1001\":1,\"1015\":1,\"1017\":1,\"1018\":1,\"1044\":1,\"1063\":1,\"1070\":1,\"1085\":1,\"1086\":1,\"1098\":1,\"1101\":1,\"1103\":1,\"1148\":1,\"1414\":1,\"1445\":1,\"1449\":1,\"1461\":1,\"1471\":1,\"1473\":1,\"1478\":1,\"1479\":1,\"1486\":1,\"1489\":1,\"1497\":1,\"1516\":1,\"1546\":1,\"1568\":1,\"1575\":1,\"1583\":1,\"1599\":1,\"1604\":1,\"1605\":1,\"1615\":1,\"1624\":1,\"1625\":1,\"1638\":1,\"1682\":1,\"1689\":1,\"1694\":1,\"1707\":1,\"1726\":1,\"1785\":1,\"1919\":1,\"1969\":1,\"2047\":1,\"2067\":1,\"2088\":1,\"2101\":1,\"2114\":1,\"2116\":1,\"2131\":1,\"2134\":1,\"2135\":1,\"2225\":1,\"2238\":1,\"2261\":1,\"2279\":1,\"2297\":1,\"2329\":1,\"2404\":1,\"2467\":1,\"2494\":1,\"2535\":1,\"2567\":1,\"2639\":1}}],[\"端到端训练\",{\"2\":{\"2148\":1}}],[\"恰恰又引入了大量的生成\",{\"2\":{\"2145\":1}}],[\"众卡围观\",{\"2\":{\"2688\":1}}],[\"众人又都不使用\",{\"2\":{\"2145\":1}}],[\"众多模型如bert\",{\"2\":{\"99\":1}}],[\"考试数据集\",{\"2\":{\"2184\":1}}],[\"考试\",{\"2\":{\"2138\":1}}],[\"考虑在代码实现中加入clip操作\",{\"2\":{\"2607\":1}}],[\"考虑在其他模型中应用类似的词汇表扩展策略\",{\"2\":{\"1294\":1}}],[\"考虑到大模型强化学习中只有最后一个动作处有奖励\",{\"2\":{\"2462\":1,\"2481\":1}}],[\"考虑提高当前response中token的生成概率\",{\"2\":{\"2387\":1}}],[\"考虑与较大激活幅度对应的权重通道的重要性\",{\"2\":{\"2085\":1}}],[\"考虑其对策略偏离的影响\",{\"2\":{\"2053\":1}}],[\"考虑\",{\"2\":{\"631\":1}}],[\"伪多轮数据\",{\"2\":{\"2135\":1}}],[\"伪量化节点\",{\"0\":{\"1813\":1},\"2\":{\"1355\":1,\"1813\":1}}],[\"必然伴随着大数据的处理\",{\"2\":{\"2132\":1}}],[\"必须用两次梯度的总和进行更新\",{\"2\":{\"2656\":1}}],[\"必须时刻保证输入层和输出层共用一套word\",{\"2\":{\"2656\":1}}],[\"必须对所有可能的yyy求和\",{\"2\":{\"2098\":1}}],[\"必须有特定领域的pddl定义和合适的planner工具\",{\"2\":{\"1465\":1}}],[\"省略掉参数\",{\"2\":{\"2129\":1}}],[\"侧就可以\",{\"2\":{\"2129\":1}}],[\"临时变量\",{\"2\":{\"2123\":1}}],[\"详细探讨了p\",{\"2\":{\"2121\":1}}],[\"详细解析\",{\"0\":{\"141\":1},\"1\":{\"162\":1,\"183\":1,\"205\":1,\"227\":1}}],[\"千卡以内可以选择\",{\"2\":{\"2118\":1}}],[\"千亿级别模型在一分钟内即可完成加载\",{\"2\":{\"1451\":1}}],[\"拉垮\",{\"2\":{\"2118\":1}}],[\"什么出错了\",{\"2\":{\"2113\":1}}],[\"什么是基于语义分块\",{\"0\":{\"1425\":1},\"1\":{\"1470\":1,\"1514\":1,\"1562\":1}}],[\"什么是rag\",{\"0\":{\"1333\":1}}],[\"什么是rope\",{\"0\":{\"247\":1}}],[\"什么是位置编码\",{\"0\":{\"1231\":1}}],[\"什么是llm\",{\"0\":{\"1184\":1},\"1\":{\"1233\":1}}],[\"什么是4d\",{\"2\":{\"917\":1}}],[\"什么是词嵌入\",{\"0\":{\"882\":1},\"1\":{\"918\":1}}],[\"什么是独热编码\",{\"0\":{\"871\":1}}],[\"什么是word2vec\",{\"0\":{\"870\":1}}],[\"什么是继续预训练\",{\"0\":{\"475\":1}}],[\"什么是\",{\"0\":{\"415\":1}}],[\"什么是混合精度训练\",{\"0\":{\"408\":1}}],[\"什么是alibi\",{\"0\":{\"293\":1}}],[\"什么是语言模型采样方法\",{\"0\":{\"249\":1}}],[\"什么是dca\",{\"0\":{\"86\":1}}],[\"什么是梯度\",{\"2\":{\"32\":1}}],[\"什么是transformer\",{\"0\":{\"26\":1},\"1\":{\"29\":1,\"34\":1,\"40\":1,\"49\":1,\"57\":1,\"65\":1}}],[\"放到不同的\",{\"2\":{\"2108\":1,\"2129\":1}}],[\"放置位置\",{\"0\":{\"467\":1}}],[\"哪怕\",{\"2\":{\"2108\":1}}],[\"哪些被抑制\",{\"2\":{\"199\":1}}],[\"配分函数计算遗漏\",{\"2\":{\"2098\":1}}],[\"配置文件\",{\"2\":{\"1451\":1}}],[\"配置自动化监控系统\",{\"2\":{\"662\":1}}],[\"句号等更细粒度的规则进行分割\",{\"2\":{\"2606\":1}}],[\"句号等位置切分\",{\"2\":{\"2091\":1}}],[\"句子组或主题为单位进行划分\",{\"2\":{\"2543\":1}}],[\"句子窗口搜索\",{\"0\":{\"2197\":1}}],[\"句子级别奖励的必要性\",{\"2\":{\"1673\":1}}],[\"句子级别过滤\",{\"2\":{\"548\":1}}],[\"协调者\",{\"0\":{\"2089\":1},\"2\":{\"2089\":3}}],[\"协议\",{\"2\":{\"1347\":2}}],[\"肯定是排在前面的\",{\"2\":{\"2087\":1}}],[\"排在后面的\",{\"2\":{\"2087\":2}}],[\"排在前面的\",{\"2\":{\"2087\":1}}],[\"排序的方法多种多样\",{\"2\":{\"1413\":1}}],[\"舍入到最近的定点数\",{\"2\":{\"2085\":1}}],[\"舍入误差\",{\"0\":{\"523\":1},\"2\":{\"591\":1}}],[\"借鉴\",{\"2\":{\"2081\":1}}],[\"借助外部工具\",{\"2\":{\"1619\":1}}],[\"借助预先设计的prompt\",{\"2\":{\"1273\":1}}],[\"借助搜索引擎广泛获取相关信息\",{\"2\":{\"494\":1}}],[\"间互为参数服务器\",{\"2\":{\"2288\":1}}],[\"间的拆分\",{\"2\":{\"2253\":1}}],[\"间的交互\",{\"2\":{\"251\":1}}],[\"间来回切换\",{\"2\":{\"2079\":1}}],[\"切分mlp\",{\"0\":{\"2587\":1},\"1\":{\"2595\":1,\"2602\":1,\"2609\":1}}],[\"切分策略\",{\"2\":{\"1450\":1}}],[\"切换到张量并行的参数分片模式\",{\"2\":{\"2079\":1}}],[\"片下内存\",{\"2\":{\"2077\":1}}],[\"片上内存\",{\"2\":{\"2077\":1}}],[\"读取\",{\"2\":{\"2145\":1}}],[\"读取14\",{\"2\":{\"483\":1}}],[\"读写速度越快\",{\"2\":{\"2077\":1}}],[\"胜率逐步提升\",{\"2\":{\"2076\":1}}],[\"存在以下两方面的限制\",{\"2\":{\"2570\":1}}],[\"存在明确的评估标准\",{\"2\":{\"2259\":1}}],[\"存在低级\",{\"2\":{\"2118\":1}}],[\"存放在gpu显存中\",{\"2\":{\"2064\":1}}],[\"存储标题信息\",{\"2\":{\"2235\":1}}],[\"存储和清洗数据以备分析\",{\"2\":{\"2220\":1}}],[\"存储空间大\",{\"2\":{\"2077\":1}}],[\"存储空间小\",{\"2\":{\"2077\":1}}],[\"存储成本降低\",{\"2\":{\"1932\":1}}],[\"存储\",{\"2\":{\"1892\":1}}],[\"存储并处理信息\",{\"2\":{\"1772\":1}}],[\"存储最优比\",{\"2\":{\"1277\":1}}],[\"存储梯度\",{\"2\":{\"553\":1}}],[\"存储为\",{\"2\":{\"435\":1}}],[\"存储一份\",{\"2\":{\"435\":1}}],[\"章\",{\"2\":{\"2059\":1}}],[\"章节或小节的引用\",{\"2\":{\"2675\":1}}],[\"章节分割等\",{\"2\":{\"2141\":1}}],[\"章节\",{\"2\":{\"1379\":1}}],[\"光学字符识别\",{\"2\":{\"2052\":1}}],[\"距离\",{\"2\":{\"2051\":1}}],[\"距离越远的相对位置\",{\"2\":{\"1258\":1}}],[\"欧式距离\",{\"2\":{\"2051\":1}}],[\"涉及到很多重复计算\",{\"2\":{\"2166\":1}}],[\"涉及自动执行的技能和例行程序\",{\"2\":{\"2049\":1}}],[\"涉及训练数据的收集与清洗\",{\"2\":{\"1046\":1}}],[\"陈述性记忆\",{\"2\":{\"2049\":1}}],[\"抵消\",{\"2\":{\"2046\":1}}],[\"瓶颈分析\",{\"0\":{\"2043\":1}}],[\"边缘化推理路径\",{\"2\":{\"2042\":1}}],[\"边训练边剪枝\",{\"2\":{\"826\":1}}],[\"依旧需要更强大的基础模型和大规模的强化学习\",{\"2\":{\"2637\":1}}],[\"依次在每个数据集上应用sft\",{\"2\":{\"2399\":1}}],[\"依然是使用少样本思维链范例编写的\",{\"2\":{\"2042\":1}}],[\"依赖llm来强化信息检索和输出\",{\"0\":{\"1611\":1}}],[\"依赖于预先标注好的静态数据集\",{\"2\":{\"690\":1}}],[\"投票\",{\"2\":{\"2037\":1}}],[\"消除框架副本\",{\"2\":{\"2073\":1}}],[\"消融实验\",{\"2\":{\"2024\":1}}],[\"消失问题\",{\"2\":{\"121\":1}}],[\"足够数量的检索结果可以确保系统覆盖到用户查询的各个方面\",{\"2\":{\"2000\":1}}],[\"足够接近\",{\"2\":{\"1377\":1}}],[\"秒\",{\"2\":{\"1998\":1,\"2228\":3}}],[\"那就把这些特征拿出来单独计算\",{\"2\":{\"1982\":1}}],[\"那么相应地\",{\"2\":{\"2616\":1}}],[\"那么相应的向量就可以帮助提高这部分内容的检索排名\",{\"2\":{\"2304\":1}}],[\"那么这里是不是应该用\",{\"2\":{\"2349\":1}}],[\"那么它在\",{\"2\":{\"1786\":1}}],[\"那么奖励黑客没有发生\",{\"2\":{\"1505\":1}}],[\"那么检索系统也会面临同样的困难\",{\"2\":{\"1421\":1}}],[\"那么如何解决呢\",{\"2\":{\"847\":1}}],[\"那么通过一个块表就可以将连续的逻辑块映射到非连续的物理块\",{\"2\":{\"750\":1}}],[\"那么使用\",{\"2\":{\"22\":1}}],[\"都采取了不同的策略来优化性能和效率\",{\"2\":{\"2129\":1}}],[\"都需要自动将数据放到对应的卡上\",{\"2\":{\"2108\":1}}],[\"都属于\",{\"2\":{\"2085\":1}}],[\"都会受到这些离群值的很大影响\",{\"2\":{\"1982\":1}}],[\"都实现了相关算法\",{\"2\":{\"1412\":1}}],[\"痛点\",{\"2\":{\"1978\":1}}],[\"δϕ\",{\"2\":{\"1962\":1}}],[\"δt\",{\"2\":{\"1343\":1}}],[\"赋予较高得分\",{\"2\":{\"1949\":1}}],[\"赋予频繁出现的单词较低的得分\",{\"2\":{\"1949\":1}}],[\"稠密搜索可能存在一定的限制\",{\"2\":{\"1949\":1}}],[\"稠密搜索是通过向量进行搜索的一种方式\",{\"2\":{\"1949\":1}}],[\"触碰记忆\",{\"2\":{\"1947\":1}}],[\"触发copy\",{\"2\":{\"846\":1}}],[\"回答相关查询\",{\"2\":{\"2690\":1}}],[\"回声记忆\",{\"2\":{\"1947\":1}}],[\"回归\",{\"2\":{\"380\":1}}],[\"回归任务\",{\"2\":{\"39\":1}}],[\"听觉等\",{\"2\":{\"1947\":1}}],[\"听觉感知\",{\"2\":{\"1518\":1}}],[\"感官记忆是记忆的最早期阶段\",{\"2\":{\"1947\":1}}],[\"感官记忆\",{\"0\":{\"1947\":1}}],[\"感知是智能体与外界环境交互的基础\",{\"2\":{\"1518\":1}}],[\"感知\",{\"0\":{\"1518\":1},\"2\":{\"1355\":1,\"1474\":1}}],[\"感知环境状态\",{\"2\":{\"639\":1}}],[\"∥π∗\",{\"2\":{\"1944\":2}}],[\"∥πref​\",{\"2\":{\"1552\":1,\"1720\":1}}],[\"∥πref\",{\"2\":{\"1552\":1,\"1720\":1}}],[\"ψt\",{\"2\":{\"1942\":1,\"1992\":1,\"1993\":1,\"2045\":1}}],[\"照猫画虎\",{\"2\":{\"1940\":1}}],[\"项中包含正确信息的项的占比\",{\"2\":{\"1933\":1}}],[\"项目地址\",{\"2\":{\"1404\":1}}],[\"项目\",{\"2\":{\"1341\":1,\"1404\":1,\"2069\":1}}],[\"项目源码\",{\"2\":{\"358\":1}}],[\"项目结构\",{\"2\":{\"60\":1}}],[\"项目介绍\",{\"2\":{\"60\":1}}],[\"项目二\",{\"2\":{\"53\":1}}],[\"项目一\",{\"2\":{\"53\":1}}],[\"命中率\",{\"0\":{\"1933\":1},\"2\":{\"1933\":1}}],[\"命名实体识别\",{\"2\":{\"59\":1}}],[\"命名空间\",{\"2\":{\"27\":2}}],[\"命名空间中的所有内容都引入当前作用域\",{\"2\":{\"27\":1}}],[\"耗时更短\",{\"2\":{\"1932\":1}}],[\"零冗余优化器\",{\"0\":{\"2112\":1},\"1\":{\"2161\":1,\"2204\":1,\"2241\":1,\"2276\":1,\"2308\":1,\"2339\":1,\"2369\":1,\"2397\":1,\"2422\":1,\"2447\":1,\"2468\":1,\"2486\":1}}],[\"零初始化策略在保持预训练知识方面表现优异\",{\"2\":{\"1898\":1}}],[\"零为中心\",{\"2\":{\"215\":1,\"330\":1}}],[\"令\",{\"2\":{\"1889\":1}}],[\"令牌数量\",{\"2\":{\"1393\":1}}],[\"补全步骤\",{\"2\":{\"1885\":1}}],[\"流水线空闲时间\",{\"2\":{\"2691\":1}}],[\"流水线执行\",{\"2\":{\"2688\":1}}],[\"流水线并行具有最低的通信成本\",{\"2\":{\"2708\":1}}],[\"流水线并行是一种将网络按层切分\",{\"2\":{\"2685\":1}}],[\"流水线并行涉及\",{\"2\":{\"2253\":1}}],[\"流水线并行\",{\"0\":{\"2253\":1,\"2685\":1,\"2707\":1},\"1\":{\"2688\":1,\"2691\":1,\"2694\":1,\"2697\":1,\"2700\":1,\"2703\":1,\"2704\":1,\"2705\":1,\"2706\":1,\"2707\":1,\"2708\":2,\"2709\":1,\"2710\":1,\"2711\":1},\"2\":{\"2177\":1,\"2709\":2}}],[\"流水线并行和专家并行\",{\"2\":{\"2167\":1}}],[\"流水线\",{\"2\":{\"1885\":1}}],[\"流程细节\",{\"0\":{\"2608\":1}}],[\"流程设计与编排\",{\"2\":{\"2523\":1}}],[\"流程图\",{\"0\":{\"2162\":1,\"2309\":1,\"2398\":1,\"2525\":1,\"2586\":1,\"2615\":1}}],[\"流程及与cot和act\",{\"0\":{\"2060\":1}}],[\"流程\",{\"0\":{\"539\":1},\"1\":{\"572\":1,\"605\":1,\"639\":1,\"673\":1,\"711\":1,\"745\":1,\"776\":1,\"807\":1,\"841\":1},\"2\":{\"5\":1,\"151\":1,\"553\":1,\"589\":1}}],[\"流程|强化学习问题\",{\"2\":{\"5\":1}}],[\"唤醒\",{\"2\":{\"1885\":1}}],[\"希望对您有所帮助\",{\"2\":{\"2214\":1}}],[\"希望这篇文章能帮助您更好地理解这些概念\",{\"2\":{\"2175\":1}}],[\"希望这篇笔记能够帮助你更好地理解tdpo算法及其优势\",{\"2\":{\"1880\":1}}],[\"希望它对prompt做续写\",{\"2\":{\"781\":1}}],[\"越靠前越好\",{\"2\":{\"1876\":1}}],[\"越界问题\",{\"2\":{\"335\":1}}],[\"遍历每个活跃的适配器\",{\"2\":{\"1871\":1}}],[\"稀疏和稠密搜索权重\",{\"0\":{\"1949\":1}}],[\"稀疏近似和低秩近似是两种常见的方法\",{\"2\":{\"1869\":1}}],[\"稀疏式\",{\"2\":{\"440\":1,\"560\":1}}],[\"种子数据包括指令跟随数据\",{\"2\":{\"1867\":1}}],[\"嵌套表格等\",{\"2\":{\"1834\":1}}],[\"嵌入模型\",{\"2\":{\"2655\":1,\"2659\":1}}],[\"嵌入到语言模型\",{\"2\":{\"2546\":1}}],[\"嵌入向量\",{\"2\":{\"1225\":1,\"1470\":1}}],[\"嵌入投影\",{\"2\":{\"1045\":1}}],[\"嵌入间的局部关系受损\",{\"2\":{\"312\":1}}],[\"嵌入反映相对位置信息\",{\"2\":{\"290\":1}}],[\"嵌入几乎保持绝对位置信息\",{\"2\":{\"290\":1}}],[\"嵌入维度\",{\"2\":{\"190\":1,\"290\":1}}],[\"待处理的文本\",{\"2\":{\"1823\":1,\"1837\":1,\"1951\":1}}],[\"务必确保forward\",{\"2\":{\"1821\":1}}],[\"务必确保输入文本序列的格式正确\",{\"2\":{\"1157\":1}}],[\"务必确保输入数据格式正确\",{\"2\":{\"1080\":1}}],[\"市场营销文案生成\",{\"2\":{\"1820\":1}}],[\"市场分析\",{\"2\":{\"39\":1}}],[\"插入\",{\"0\":{\"1813\":1}}],[\"插值到\",{\"2\":{\"466\":1}}],[\"插值公式中引入参数\",{\"2\":{\"221\":1}}],[\"介于路由器与状态机之间\",{\"0\":{\"1786\":1}}],[\"介绍\",{\"0\":{\"88\":1,\"134\":1,\"692\":1,\"814\":1,\"849\":1,\"1643\":1,\"1785\":1},\"1\":{\"102\":1,\"118\":1,\"137\":1,\"154\":1,\"157\":1,\"174\":1,\"177\":1,\"195\":1,\"198\":1,\"216\":1,\"219\":1,\"239\":1,\"242\":1,\"263\":1,\"265\":1,\"287\":1,\"309\":1,\"332\":1,\"356\":1,\"383\":1,\"409\":1,\"728\":1,\"763\":1,\"794\":1,\"825\":1,\"848\":1,\"882\":1,\"883\":1,\"918\":1,\"919\":1,\"955\":1,\"956\":1,\"996\":1,\"997\":1,\"1036\":1,\"1037\":1,\"1079\":1,\"1080\":1,\"1125\":1,\"1126\":1,\"1176\":1,\"1177\":1,\"1225\":1,\"1226\":1,\"1276\":1,\"1697\":1,\"1755\":1,\"1815\":1,\"1846\":1,\"1875\":1,\"1903\":1,\"1932\":1,\"1957\":1,\"1983\":1,\"2008\":1,\"2034\":1,\"2057\":1,\"2086\":1,\"2110\":1,\"2136\":1,\"2160\":1,\"2182\":1,\"2203\":1,\"2240\":1,\"2275\":1},\"2\":{\"46\":1,\"55\":1,\"84\":1,\"151\":1,\"172\":1,\"193\":1,\"214\":1}}],[\"介绍|词嵌入介绍\",{\"2\":{\"5\":1}}],[\"介绍|位置编码介绍\",{\"2\":{\"5\":1}}],[\"已经提供了模型内通信\",{\"2\":{\"2081\":1}}],[\"已生成的新子序列长度为\",{\"2\":{\"1782\":1}}],[\"已被优化为\",{\"2\":{\"1451\":1}}],[\"暂不考虑gqa\",{\"2\":{\"1782\":1}}],[\"出于效率考虑\",{\"2\":{\"1782\":1}}],[\"出现这种阶段现象\",{\"2\":{\"847\":1}}],[\"桌子君的教育历史是什么\",{\"2\":{\"1774\":1}}],[\"桌子君在特定时期去了哪所学校\",{\"2\":{\"1774\":1}}],[\"往往由以下三部分组成\",{\"2\":{\"1766\":1}}],[\"外层循环\",{\"0\":{\"2565\":1}}],[\"外部反馈是环境给出的标量奖励之类的反馈\",{\"2\":{\"2205\":1}}],[\"外显记忆\",{\"2\":{\"2049\":1}}],[\"外\",{\"2\":{\"1758\":1}}],[\"外推阶段的输入值需慎重选择\",{\"2\":{\"269\":1}}],[\"外推能力扩展技术\",{\"0\":{\"1255\":1}}],[\"外推能力\",{\"2\":{\"239\":1}}],[\"除\",{\"2\":{\"1758\":1}}],[\"除了pp\",{\"2\":{\"2711\":1}}],[\"除了日期\",{\"2\":{\"2675\":1}}],[\"除了基础检索参数外\",{\"2\":{\"2104\":1}}],[\"除了大矩阵乘法是计算受限\",{\"2\":{\"2027\":1}}],[\"除了使用传统的任务成功率之外\",{\"2\":{\"1544\":1}}],[\"除了qkv\",{\"2\":{\"894\":1}}],[\"除了降低成本\",{\"2\":{\"825\":1}}],[\"除了rope\",{\"2\":{\"740\":1}}],[\"除了z\",{\"2\":{\"736\":1}}],[\"除了\",{\"2\":{\"299\":1}}],[\"忘记应用裁剪操作可能导致不稳定的训练过程\",{\"2\":{\"1757\":1}}],[\"倒数排名\",{\"2\":{\"1756\":3}}],[\"倒数排名接近\",{\"2\":{\"1698\":1}}],[\"含有不可执行代码的响应会导致\",{\"2\":{\"1740\":1}}],[\"沙盒输出掩码\",{\"2\":{\"1740\":1}}],[\"属性上更进一步\",{\"2\":{\"1786\":1}}],[\"属性\",{\"2\":{\"1728\":1,\"1847\":1}}],[\"属于正类的概率\",{\"2\":{\"90\":1}}],[\"认为相关的信息和文档模式\",{\"2\":{\"1717\":1}}],[\"认证与集成复杂性\",{\"0\":{\"157\":1}}],[\"认证管理\",{\"2\":{\"88\":1}}],[\"乘以一个向量\",{\"2\":{\"1991\":1}}],[\"乘\",{\"2\":{\"1712\":1}}],[\"聚合信息给予奖励\",{\"2\":{\"1958\":1}}],[\"聚合操作\",{\"0\":{\"1688\":1},\"2\":{\"2188\":1}}],[\"聚类方法\",{\"2\":{\"2314\":1}}],[\"聚类基因表达数据\",{\"2\":{\"39\":1}}],[\"聚类算法通过将数据划分为多个簇\",{\"2\":{\"1467\":1}}],[\"聚类算法易受噪声数据影响\",{\"2\":{\"565\":1}}],[\"聚类算法\",{\"0\":{\"1467\":1},\"2\":{\"39\":1,\"345\":1}}],[\"ϕ\",{\"2\":{\"1685\":2}}],[\"程度\",{\"2\":{\"1672\":1}}],[\"程度由什么决定\",{\"0\":{\"1672\":1},\"1\":{\"1728\":1,\"1786\":1,\"1847\":1,\"1904\":1}}],[\"程序性记忆\",{\"2\":{\"2049\":1}}],[\"程序\",{\"2\":{\"1474\":1}}],[\"ℓf​\",{\"2\":{\"1671\":1}}],[\"ℓf\",{\"2\":{\"1671\":1}}],[\"搭配词和句子开头的词建立模型\",{\"2\":{\"1665\":1}}],[\"思路转变\",{\"0\":{\"2517\":1}}],[\"思想上类似\",{\"2\":{\"2288\":1}}],[\"思维的变换及其顺序和依赖关系\",{\"2\":{\"2262\":1}}],[\"思维链\",{\"0\":{\"1655\":1},\"1\":{\"1708\":1,\"1766\":1,\"1826\":1,\"1885\":1,\"1940\":1,\"1990\":1,\"2042\":1,\"2094\":1,\"2144\":1,\"2188\":1,\"2227\":1,\"2262\":1},\"2\":{\"1990\":1,\"2516\":1}}],[\"思考与启发\",{\"0\":{\"406\":1}}],[\"思考与延伸问题\",{\"0\":{\"233\":1,\"490\":1}}],[\"思考板块\",{\"0\":{\"300\":1,\"628\":1,\"632\":1}}],[\"思考\",{\"0\":{\"217\":1,\"219\":1,\"258\":1,\"260\":1,\"279\":1,\"289\":1,\"299\":1,\"304\":1,\"310\":1,\"337\":1,\"356\":1,\"362\":1,\"413\":1,\"432\":1,\"453\":1,\"466\":1,\"469\":1,\"563\":1,\"564\":1,\"616\":1,\"628\":1,\"631\":1,\"635\":1,\"660\":1,\"685\":1,\"694\":1,\"702\":1,\"705\":1,\"719\":1,\"727\":1,\"736\":1,\"754\":1,\"770\":1,\"771\":1,\"776\":1,\"785\":1,\"797\":1,\"850\":1,\"876\":1,\"965\":1,\"966\":1,\"994\":1,\"1176\":1,\"1210\":1,\"1354\":1,\"1447\":1,\"1472\":1,\"1481\":1,\"1508\":1,\"1577\":1,\"1580\":1,\"1593\":1,\"1606\":1,\"1758\":1,\"1897\":1,\"1971\":1,\"1973\":1,\"2258\":1,\"2345\":1,\"2350\":1,\"2382\":1,\"2449\":1,\"2476\":1},\"1\":{\"333\":1},\"2\":{\"162\":1,\"233\":1,\"647\":1,\"740\":1,\"913\":1,\"2363\":1}}],[\"粘贴您选取的文本\",{\"2\":{\"1651\":1,\"2478\":1}}],[\"管理计算资源\",{\"2\":{\"1642\":1}}],[\"管理整个组织\",{\"2\":{\"1429\":1}}],[\"产生一个thought\",{\"2\":{\"2011\":1}}],[\"产生reward\",{\"2\":{\"1633\":1}}],[\"产生新思想和创新\",{\"2\":{\"1382\":1}}],[\"修正线性单元\",{\"2\":{\"2526\":1}}],[\"修正\",{\"2\":{\"1619\":1}}],[\"修改为\",{\"2\":{\"293\":1}}],[\"修改输出层\",{\"2\":{\"40\":1}}],[\"吴恩达\",{\"2\":{\"1617\":1}}],[\"各种主流代码语言\",{\"2\":{\"2640\":1}}],[\"各种临时缓冲区\",{\"2\":{\"2161\":1}}],[\"各种实现方式和理解层出不穷\",{\"2\":{\"1617\":1}}],[\"各项子能力分析\",{\"0\":{\"1759\":1}}],[\"各个示例放入的顺序也非常关键\",{\"2\":{\"1413\":1}}],[\"今天\",{\"2\":{\"1609\":1}}],[\"奇异值分解\",{\"2\":{\"1653\":1}}],[\"奇异值\",{\"2\":{\"1599\":1}}],[\"奇数维度\",{\"2\":{\"332\":1}}],[\"另一篇内容错误时\",{\"2\":{\"2506\":1}}],[\"另一个模型实例同时对查询进行不恰当内容或非法请求筛查\",{\"2\":{\"2037\":1}}],[\"另一方面\",{\"2\":{\"1578\":1}}],[\"另50\",{\"2\":{\"1037\":1}}],[\"批判\",{\"2\":{\"1619\":1}}],[\"批大小为1\",{\"2\":{\"1572\":1}}],[\"批量大小为512\",{\"2\":{\"1134\":1}}],[\"批量大小\",{\"2\":{\"190\":1,\"2194\":1}}],[\"天气等信息\",{\"2\":{\"1569\":1}}],[\"天气预报\",{\"2\":{\"39\":1}}],[\"余弦相似度更受青睐\",{\"2\":{\"2051\":1}}],[\"余弦相似度\",{\"2\":{\"2051\":1}}],[\"余弦相似度的阈值可能因文档而异\",{\"2\":{\"1562\":1}}],[\"余弦函数为输入序列添加位置信息\",{\"2\":{\"34\":1}}],[\"阈值调整\",{\"2\":{\"1562\":1}}],[\"局限性\",{\"0\":{\"1562\":1}}],[\"局部敏感哈希\",{\"0\":{\"2152\":1}}],[\"局部关系损害\",{\"2\":{\"335\":1}}],[\"局部与远程稀疏相关\",{\"0\":{\"168\":1}}],[\"局部引入\",{\"2\":{\"22\":1}}],[\"局部和全局的命名空间引入\",{\"0\":{\"17\":1}}],[\"递归地将文本分解为更小的块\",{\"2\":{\"2606\":1}}],[\"递归地对文本进行切分\",{\"2\":{\"2141\":1}}],[\"递归分块适合对语义保留要求高\",{\"2\":{\"2620\":1}}],[\"递归分块是一种推荐程度较高的方法\",{\"2\":{\"2606\":1}}],[\"递归分块\",{\"0\":{\"2606\":1},\"1\":{\"2613\":1,\"2620\":1}}],[\"递归式分块的方法能够在保持原始结构的基础上\",{\"2\":{\"1561\":1}}],[\"递归细化\",{\"2\":{\"1561\":1}}],[\"递归复用\",{\"2\":{\"125\":1}}],[\"空中掉落\",{\"2\":{\"2466\":1}}],[\"空间上距离较近的向量更有可能被分入同一个桶\",{\"2\":{\"1559\":1}}],[\"空指针\",{\"2\":{\"47\":1}}],[\"里\",{\"2\":{\"1559\":1}}],[\"里面是每组数据包含的数据长度\",{\"2\":{\"917\":1}}],[\"里面存储的是一个链表节点的哈希表\",{\"2\":{\"47\":1}}],[\"桶的数量远小于输入内容的数量\",{\"2\":{\"2152\":1}}],[\"桶\",{\"2\":{\"1559\":1}}],[\"哈希值相同的向量将被分配到同一个组中\",{\"2\":{\"1559\":1}}],[\"失效机制\",{\"2\":{\"1558\":1}}],[\"衡量生成文本与参考文本在词汇和短语上的匹配程度\",{\"2\":{\"2292\":1}}],[\"衡量两个集合之间的不相似性\",{\"2\":{\"2051\":1}}],[\"衡量检索到的文档的全面性\",{\"2\":{\"1984\":1}}],[\"衡量的是相关结果首次出现的位置\",{\"2\":{\"1876\":1}}],[\"衡量标准\",{\"0\":{\"1876\":1}}],[\"衡量策略π\",{\"2\":{\"1552\":1}}],[\"衡量模型预测下一个词的难易程度\",{\"2\":{\"583\":1}}],[\"才能更有效地生成和提供信息\",{\"2\":{\"1611\":1}}],[\"才能使模型比较好地收敛\",{\"2\":{\"1076\":1}}],[\"才失败是完全不同的两种情况\",{\"2\":{\"1544\":1}}],[\"充分发挥了代码生成和执行的能力\",{\"2\":{\"1730\":1}}],[\"充分利用了这一特性\",{\"2\":{\"1853\":1}}],[\"充分利用\",{\"2\":{\"1542\":1}}],[\"充当数据交换中介\",{\"2\":{\"118\":1}}],[\"归一化奖励\",{\"2\":{\"2446\":1}}],[\"归一化折损累计增益\",{\"0\":{\"2035\":1},\"1\":{\"2087\":1,\"2137\":1,\"2183\":1}}],[\"归一化维度\",{\"2\":{\"227\":1}}],[\"归纳总结\",{\"0\":{\"1540\":1}}],[\"κlognd​qk⊤\",{\"2\":{\"1535\":1}}],[\"手动添加常见汉字或特定领域词汇\",{\"2\":{\"1531\":1}}],[\"手动添加常见汉字或业务场景相关词汇\",{\"2\":{\"1302\":1}}],[\"框架构建的链和智能代理的工具\",{\"2\":{\"2590\":1}}],[\"框架相关\",{\"2\":{\"2123\":1}}],[\"框架及其独特的\",{\"2\":{\"2022\":1}}],[\"框架借鉴了\",{\"2\":{\"1860\":1}}],[\"框架进行预训练实验\",{\"2\":{\"1818\":1}}],[\"框架的核心在于通过强化学习\",{\"2\":{\"1684\":1}}],[\"框架的基本启动代码示例\",{\"2\":{\"1646\":1}}],[\"框架中\",{\"2\":{\"1578\":1}}],[\"框架\",{\"0\":{\"1529\":1,\"1630\":1,\"1798\":1},\"1\":{\"1578\":1,\"1684\":1,\"1740\":1,\"1860\":1,\"1917\":1,\"1970\":1,\"2022\":1,\"2072\":1,\"2124\":1,\"2171\":1,\"2213\":1,\"2250\":1,\"2285\":1,\"2317\":1,\"2348\":1,\"2378\":1,\"2405\":1,\"2430\":1,\"2455\":1},\"2\":{\"1592\":1}}],[\"框架通常会对底层逻辑进行抽象处理\",{\"2\":{\"1392\":1}}],[\"视觉感知\",{\"2\":{\"1518\":1}}],[\"视频bvid\",{\"2\":{\"559\":1}}],[\"视频id\",{\"2\":{\"559\":2}}],[\"视频与文本结合\",{\"2\":{\"535\":1}}],[\"眼睛\",{\"0\":{\"1518\":1}}],[\"剔除可能误导用户的信息\",{\"2\":{\"1510\":1}}],[\"灵感\",{\"2\":{\"1507\":1}}],[\"灵活性强\",{\"2\":{\"2613\":1,\"2630\":1}}],[\"灵活性\",{\"2\":{\"1514\":1}}],[\"灵活性与可解码性\",{\"2\":{\"318\":1}}],[\"灵活\",{\"2\":{\"1373\":1}}],[\"灵活的解决方案\",{\"2\":{\"373\":1}}],[\"了解目前是否已有结合两者优势的新方法\",{\"2\":{\"1555\":1}}],[\"了\",{\"2\":{\"1505\":1,\"1870\":1}}],[\"黑\",{\"2\":{\"1505\":1,\"1551\":1}}],[\"黑盒知识蒸馏\",{\"0\":{\"1078\":1},\"1\":{\"1124\":1,\"1175\":1,\"1224\":1,\"1275\":1}}],[\"符号推理\",{\"2\":{\"1708\":1}}],[\"符号\",{\"2\":{\"1499\":1}}],[\"符合贪心优化\",{\"2\":{\"1023\":1}}],[\"近似为\",{\"2\":{\"2276\":1}}],[\"近似注意力方法\",{\"0\":{\"1869\":1},\"1\":{\"1926\":1}}],[\"近端策略优化\",{\"2\":{\"1495\":1,\"1589\":1}}],[\"近年来\",{\"2\":{\"1439\":1}}],[\"幻觉问题\",{\"0\":{\"1468\":1},\"2\":{\"1468\":1}}],[\"硬件优化\",{\"2\":{\"1464\":1}}],[\"硬件适配\",{\"2\":{\"334\":1}}],[\"¯eostre\",{\"2\":{\"1458\":1}}],[\"真实反馈\",{\"2\":{\"1454\":1}}],[\"弥补合成数据质量不足的问题\",{\"2\":{\"2220\":1}}],[\"弥补了这一不足\",{\"2\":{\"1453\":1}}],[\"弥补这一不足\",{\"2\":{\"1163\":1}}],[\"破坏模型的一致性\",{\"2\":{\"1452\":1}}],[\"偏向于长的回答\",{\"2\":{\"2588\":1}}],[\"偏好概率模型\",{\"0\":{\"2046\":1}}],[\"偏好回答的概率会增加\",{\"2\":{\"1675\":1}}],[\"偏好建模方法\",{\"2\":{\"1536\":1}}],[\"偏好标签\",{\"2\":{\"1536\":1}}],[\"偏好标签与建模\",{\"2\":{\"1536\":1}}],[\"偏好标签收集\",{\"2\":{\"1530\":1}}],[\"偏好优化\",{\"2\":{\"1449\":1,\"1473\":1}}],[\"偏置项的选择性保留\",{\"2\":{\"1155\":1}}],[\"科学工程\",{\"2\":{\"1441\":1}}],[\"科技动态等\",{\"2\":{\"1558\":1}}],[\"科技\",{\"2\":{\"49\":1}}],[\"灾害救援\",{\"2\":{\"1431\":1}}],[\"物流与运输\",{\"2\":{\"1431\":1}}],[\"物理块block3只和a1的逻辑块block1映射\",{\"2\":{\"846\":1}}],[\"激发模型原有的元认知\",{\"2\":{\"1420\":1}}],[\"激活检查点是一种在前向传播过程中计算节点的激活值并保存的方法\",{\"2\":{\"2503\":1}}],[\"激活采用不同粒度\",{\"2\":{\"2033\":1}}],[\"激活路由专家数量\",{\"2\":{\"1318\":1}}],[\"激活值大小与模型参数\",{\"2\":{\"2231\":1}}],[\"激活值可以通过\",{\"2\":{\"2161\":1}}],[\"激活值的量化比权重的量化难得多\",{\"2\":{\"2033\":1}}],[\"激活值等构成\",{\"2\":{\"2021\":1}}],[\"激活值\",{\"2\":{\"799\":1,\"2123\":1,\"2231\":1}}],[\"激活所有专家\",{\"2\":{\"440\":1}}],[\"激活函数的选择对模型性能有直接影响\",{\"2\":{\"1242\":1}}],[\"激活函数的选择不仅影响模型性能\",{\"2\":{\"406\":1}}],[\"激活函数的优势\",{\"2\":{\"1140\":1}}],[\"激活函数与参数初始化\",{\"2\":{\"932\":1}}],[\"激活函数与ffn结构优化\",{\"0\":{\"103\":1},\"1\":{\"119\":1,\"138\":1,\"158\":1,\"178\":1,\"199\":1,\"220\":1,\"243\":1,\"266\":1,\"289\":1,\"311\":1,\"334\":1},\"2\":{\"5\":1,\"73\":1}}],[\"激活函数从\",{\"2\":{\"889\":1}}],[\"激活函数选择合适的专家网络\",{\"2\":{\"440\":1}}],[\"激活函数选择对模型性能影响有多大\",{\"2\":{\"289\":1}}],[\"激活函数优缺点对比表\",{\"0\":{\"330\":1}}],[\"激活函数是神经网络的核心组件之一\",{\"2\":{\"152\":1}}],[\"激活函数\",{\"2\":{\"119\":1,\"132\":1,\"144\":1,\"199\":1,\"330\":1,\"961\":1,\"1092\":2,\"1292\":1,\"1358\":1,\"2579\":1}}],[\"激活函数详解与比较\",{\"0\":{\"114\":1},\"1\":{\"132\":1,\"152\":1,\"173\":1,\"194\":1,\"215\":1,\"238\":1,\"261\":1,\"285\":1,\"307\":1,\"330\":1,\"354\":1,\"380\":1,\"406\":1},\"2\":{\"5\":1,\"73\":1}}],[\"少量数据\",{\"2\":{\"1419\":1}}],[\"少量高质量数据优于大量低质量数据\",{\"2\":{\"1357\":1}}],[\"泛化到更复杂的思维模式\",{\"2\":{\"2188\":1}}],[\"泛化问题\",{\"2\":{\"1414\":1,\"1505\":1}}],[\"泛型编程可以看作是过程编程的一种增强\",{\"2\":{\"20\":1}}],[\"泛型编程通过模板使得函数和数据结构可以适应不同的数据类型\",{\"2\":{\"20\":1}}],[\"泛型编程通过模板实现类型无关的代码\",{\"2\":{\"20\":1}}],[\"泛型编程通过模板来编写与类型无关的代码\",{\"2\":{\"15\":1}}],[\"泛型编程关注算法和数据结构的通用性\",{\"2\":{\"20\":1}}],[\"泛型编程\",{\"0\":{\"15\":1},\"2\":{\"20\":3}}],[\"故障的情景\",{\"2\":{\"1407\":1}}],[\"业务场景相关token覆盖不足\",{\"2\":{\"1394\":1}}],[\"抽象层遮蔽底层提示与响应\",{\"2\":{\"1392\":1}}],[\"抽象摘要\",{\"2\":{\"1019\":1}}],[\"抽象摘要和文本分类\",{\"2\":{\"901\":1}}],[\"尽可能以自然段落\",{\"2\":{\"2543\":1}}],[\"尽可能减少嵌入内容中的噪声\",{\"2\":{\"2303\":1}}],[\"尽可能生成一些思考过程\",{\"2\":{\"1885\":1}}],[\"尽可能保持原文档中的文本顺序和格式\",{\"2\":{\"1716\":1}}],[\"尽量选择在标点符号或段落结束处进行截断\",{\"2\":{\"1652\":1}}],[\"尽量避免\",{\"2\":{\"1542\":1}}],[\"尽量避免引入复杂并行技术\",{\"2\":{\"1389\":1}}],[\"尽管强化学习可以提升小模型的性能\",{\"2\":{\"2637\":1}}],[\"尽管推理能力显著提升\",{\"2\":{\"2315\":1}}],[\"尽管\",{\"2\":{\"2094\":1}}],[\"尽管假设回复可能包含虚假信息\",{\"2\":{\"1717\":1}}],[\"尽管基于自生成的方法在许多任务中表现良好\",{\"2\":{\"1459\":1}}],[\"尽管框架封装了许多功能\",{\"2\":{\"1392\":1}}],[\"尽管正弦位置编码具有生成规律\",{\"2\":{\"1343\":1}}],[\"尽管模型的权重和激活值仍然以浮点数形式存储和更新\",{\"2\":{\"1160\":1}}],[\"尽管增加了内存消耗\",{\"2\":{\"1155\":1}}],[\"尽管公开数据丰富\",{\"2\":{\"1114\":1}}],[\"尽管bbpe有诸多优点\",{\"2\":{\"341\":1}}],[\"寻找最优策略\",{\"2\":{\"2378\":1}}],[\"寻找最佳平衡点\",{\"2\":{\"1686\":1}}],[\"寻找更优解\",{\"2\":{\"1587\":1}}],[\"寻找绝对的最优解往往计算成本极高\",{\"2\":{\"1377\":1}}],[\"寻找数据中的隐藏模式或分布\",{\"2\":{\"39\":1}}],[\"索引的作用是筛选出与查询相关的数据\",{\"2\":{\"1377\":1}}],[\"索引\",{\"0\":{\"1377\":1},\"1\":{\"1422\":1,\"1467\":1,\"1511\":1,\"1559\":1,\"1610\":1,\"1663\":1,\"1717\":1,\"1774\":1,\"1835\":1,\"1894\":1,\"1949\":1,\"2000\":1,\"2051\":1,\"2104\":1,\"2154\":1,\"2197\":1,\"2236\":1,\"2271\":1,\"2304\":1,\"2335\":1,\"2365\":1,\"2394\":1},\"2\":{\"2420\":1}}],[\"索引形式的单词\",{\"2\":{\"996\":1}}],[\"他们还使用了4d并行技术\",{\"2\":{\"2711\":1}}],[\"他们使用总包的方式\",{\"2\":{\"1368\":1}}],[\"他欠我100万\",{\"2\":{\"216\":1}}],[\"称为kernel\",{\"2\":{\"2128\":1}}],[\"称为离群特征\",{\"2\":{\"1982\":1}}],[\"称为\",{\"2\":{\"1367\":1}}],[\"事实性评估旨在验证生成答案的准确性\",{\"2\":{\"2436\":1}}],[\"事实性\",{\"0\":{\"2436\":1},\"2\":{\"1356\":2}}],[\"许多大模型都可以作为基座模型使用\",{\"2\":{\"1999\":1}}],[\"许多近似注意力的方法被提出\",{\"2\":{\"1807\":1}}],[\"许多评估在完全可观测的环境中进行\",{\"2\":{\"1453\":1}}],[\"许多优秀的语言模型在中文任务上的表现不佳\",{\"2\":{\"1349\":1}}],[\"许多高质量数据\",{\"2\":{\"465\":1}}],[\"毕昇\",{\"2\":{\"1347\":1}}],[\"毕业设计导航\",{\"0\":{\"4\":1}}],[\"闭源\",{\"2\":{\"1347\":1}}],[\"η\",{\"2\":{\"1344\":1}}],[\"两路数据并行以及32个worker来实现高效的3d并行\",{\"2\":{\"2710\":1}}],[\"两张卡\",{\"2\":{\"2526\":1,\"2688\":1}}],[\"两步\",{\"2\":{\"2276\":1,\"2308\":1}}],[\"两种精度的数据类型\",{\"2\":{\"2059\":1}}],[\"两种形式\",{\"2\":{\"1826\":1}}],[\"两种类型\",{\"2\":{\"1752\":1}}],[\"两个核心类\",{\"2\":{\"2433\":1}}],[\"两个表示的点积\",{\"2\":{\"1671\":1}}],[\"两个维度进行考量\",{\"2\":{\"1356\":1}}],[\"两个位置编码之间的点积仅取决于距离\",{\"2\":{\"1343\":1}}],[\"两者通过循环往复的方式不断优化最终结果\",{\"2\":{\"2224\":1}}],[\"两者各有其独特的优势\",{\"2\":{\"2129\":1}}],[\"两者各有优缺点\",{\"2\":{\"1131\":1}}],[\"两者都是token序列\",{\"2\":{\"1787\":1}}],[\"两者都使用语言模型来选择子词\",{\"2\":{\"445\":1}}],[\"两者都基于\",{\"2\":{\"420\":1}}],[\"辩论和讨论\",{\"2\":{\"1338\":1}}],[\"集成\",{\"2\":{\"2081\":2}}],[\"集成了\",{\"2\":{\"1776\":1}}],[\"集体决策\",{\"2\":{\"1338\":1}}],[\"集中管理api请求\",{\"2\":{\"198\":1}}],[\"某个智能体可能发现了一个新的环境变化\",{\"2\":{\"1338\":1}}],[\"某些数据库支持将向量和元数据一同存储\",{\"2\":{\"2669\":1}}],[\"某些chunk可能超出大语言模型的上下文长度限制\",{\"2\":{\"1513\":1}}],[\"某些任务如mmlu和gsm8k只有预训练损失降低到一定程度才可能有效果\",{\"2\":{\"1008\":1}}],[\"某些维度可能超出边界\",{\"2\":{\"335\":1}}],[\"某些维度可能被轻微外推到边界之外\",{\"2\":{\"244\":1}}],[\"某些维度的波长可能超过预训练时的最大上下文长度\",{\"2\":{\"290\":1}}],[\"乱码等\",{\"2\":{\"1331\":1}}],[\"丧失\",{\"2\":{\"1328\":1}}],[\"延迟\",{\"2\":{\"1324\":1}}],[\"延伸问题\",{\"0\":{\"217\":1,\"219\":1,\"299\":1,\"333\":1,\"356\":1,\"453\":1,\"563\":1,\"631\":1,\"635\":1,\"702\":1,\"719\":1,\"736\":1,\"771\":1,\"785\":1,\"1176\":1,\"1210\":1,\"1354\":1,\"1447\":1,\"1481\":1,\"1577\":1,\"1593\":1,\"1758\":1}}],[\"吞吐量\",{\"2\":{\"1324\":1}}],[\"成为存储和检索这些向量的重要工具\",{\"2\":{\"2666\":1}}],[\"成为性能瓶颈\",{\"2\":{\"2422\":1}}],[\"成为了一种有效的方法\",{\"2\":{\"1308\":1}}],[\"成本时\",{\"2\":{\"1201\":1}}],[\"邻近位置\",{\"2\":{\"1306\":1}}],[\"蚁群\",{\"2\":{\"1300\":1}}],[\"颜色交替更为频繁\",{\"2\":{\"1296\":1}}],[\"左半部分由于高频率的影响\",{\"2\":{\"1296\":1}}],[\"左侧移出窗口的字母为元音字母\",{\"2\":{\"783\":1}}],[\"左侧移出窗口的字母非元音字母\",{\"2\":{\"783\":1}}],[\"左侧移出窗口的字母也是元音字母\",{\"2\":{\"783\":1}}],[\"占比\",{\"2\":{\"1290\":1}}],[\"占用gpu推理的时间是漫长的\",{\"2\":{\"1843\":1}}],[\"占用\",{\"2\":{\"488\":2}}],[\"截断范围示例\",{\"0\":{\"1499\":1}}],[\"截断处理\",{\"2\":{\"1266\":1}}],[\"截取前11层encoder+1层decoder进行下游任务微调\",{\"2\":{\"1288\":1}}],[\"摘要类问题处理索引\",{\"2\":{\"1285\":1}}],[\"摘要生成以及多语言任务等不同领域\",{\"2\":{\"2138\":1}}],[\"摘要生成\",{\"2\":{\"34\":1}}],[\"困难\",{\"2\":{\"1275\":1}}],[\"困惑度监控样本过少可能导致误判结果\",{\"2\":{\"627\":1}}],[\"困惑度是衡量语言模型好坏的重要指标\",{\"2\":{\"558\":1}}],[\"困惑度只能在同一模型的不同版本之间进行比较\",{\"2\":{\"516\":1}}],[\"困惑度越低\",{\"2\":{\"268\":1,\"558\":1}}],[\"困惑度指标的重要性\",{\"0\":{\"268\":1}}],[\"困惑度进一步降低\",{\"2\":{\"245\":1}}],[\"困惑度\",{\"0\":{\"516\":1,\"558\":1},\"2\":{\"40\":1,\"245\":2,\"268\":1,\"431\":1,\"437\":1,\"464\":1,\"583\":1}}],[\"退后问题\",{\"2\":{\"1774\":1}}],[\"退后\",{\"2\":{\"1774\":1}}],[\"退后提示\",{\"0\":{\"1774\":1}}],[\"退火阶段\",{\"2\":{\"1344\":1}}],[\"退火\",{\"2\":{\"1267\":1}}],[\"退出评估迭代\",{\"2\":{\"647\":1}}],[\"⊤f\",{\"2\":{\"1671\":8}}],[\"⊤\",{\"2\":{\"1266\":2}}],[\"替代展开策略\",{\"2\":{\"1917\":1}}],[\"替代传统位置编码方法\",{\"2\":{\"1606\":1}}],[\"替代绝对位置信息\",{\"2\":{\"1266\":1}}],[\"替换reward\",{\"2\":{\"1954\":1}}],[\"替换为\",{\"2\":{\"1951\":1}}],[\"替换绝对位置向量为相对位置向量\",{\"2\":{\"1405\":1}}],[\"替换了传统的ffn部分\",{\"2\":{\"1198\":1}}],[\"剪裁\",{\"2\":{\"1258\":1}}],[\"剪枝后权重矩阵稀疏\",{\"2\":{\"1010\":1}}],[\"剪枝算法简单\",{\"2\":{\"969\":1}}],[\"剪枝技术主要分为非结构化剪枝和结构化剪枝两大类\",{\"2\":{\"896\":1}}],[\"剪枝分类\",{\"0\":{\"896\":1},\"1\":{\"931\":1,\"969\":1,\"1010\":1,\"1050\":1,\"1094\":1,\"1143\":1}}],[\"剪枝流程\",{\"0\":{\"764\":1},\"1\":{\"795\":1,\"826\":1,\"860\":1}}],[\"剪枝可以在不显著影响模型性能的情况下\",{\"2\":{\"763\":1}}],[\"剪枝\",{\"2\":{\"763\":1,\"795\":1}}],[\"剪枝更关注去除不必要的参数\",{\"2\":{\"729\":1}}],[\"渐进式方法帮助模型适应增加的上下文长度\",{\"2\":{\"1256\":1}}],[\"家庭中的扫地机器人等\",{\"2\":{\"1241\":1}}],[\"家族模型\",{\"2\":{\"474\":1}}],[\"被分割成\",{\"2\":{\"2374\":1}}],[\"被视为两个样本之间的相似性分数\",{\"2\":{\"1671\":1}}],[\"被用作路由器\",{\"2\":{\"1569\":1}}],[\"被定义为文本中的原子表达\",{\"2\":{\"1367\":1}}],[\"被路由至一个或多个特定的索引\",{\"2\":{\"1332\":1}}],[\"被称为\",{\"2\":{\"1237\":1}}],[\"被拆分成\",{\"2\":{\"956\":1}}],[\"规约梯度的通信开销与模型大小成正相关\",{\"2\":{\"2704\":1}}],[\"规定了应用于\",{\"2\":{\"2262\":1}}],[\"规范文本格式\",{\"2\":{\"1331\":1}}],[\"规范化技术\",{\"2\":{\"889\":1}}],[\"规划算法\",{\"0\":{\"2378\":1}}],[\"规划能力\",{\"2\":{\"1759\":1}}],[\"规划任务并采取行动\",{\"2\":{\"1241\":1}}],[\"规划\",{\"0\":{\"1283\":1},\"1\":{\"1330\":1,\"1375\":1,\"1420\":1,\"1465\":1},\"2\":{\"1233\":1,\"1408\":1}}],[\"浮点运算的主要来源\",{\"0\":{\"2043\":1}}],[\"浮点运算次数\",{\"2\":{\"1232\":1}}],[\"浮点数计算次数\",{\"2\":{\"1869\":1}}],[\"浮点类型\",{\"2\":{\"15\":1}}],[\"容错性强\",{\"2\":{\"1384\":1}}],[\"容量系数过大可能导致计算和通讯压力增大\",{\"2\":{\"1371\":1}}],[\"容量系数影响专家处理token的能力\",{\"2\":{\"1229\":1}}],[\"容易错误地设置窗口大小w过小\",{\"2\":{\"2438\":1}}],[\"容易导致\",{\"2\":{\"2118\":1}}],[\"容易产生偏见或错误\",{\"2\":{\"1743\":1}}],[\"容易造成数据冗余和训练复杂度增加\",{\"2\":{\"1091\":1}}],[\"容易上手\",{\"2\":{\"943\":1}}],[\"容易出现目标漂移现象\",{\"2\":{\"777\":1}}],[\"容易忽略排除当前response的奖励\",{\"2\":{\"2056\":1}}],[\"容易忽略句子级别的偏好标签\",{\"2\":{\"2009\":1}}],[\"容易忽略cross\",{\"2\":{\"1051\":1}}],[\"容易忽略$$\",{\"2\":{\"720\":1}}],[\"容易忽视模板字符的词向量在训练过程中的固定性\",{\"2\":{\"2133\":1}}],[\"容易忽视动态掩码策略的重要性\",{\"2\":{\"1194\":1}}],[\"容易忽视状态和动作的明确定义\",{\"2\":{\"684\":1}}],[\"容易忽视kv\",{\"2\":{\"546\":1}}],[\"鼓励学生模型从教师模型中提取相关的原理\",{\"2\":{\"1224\":1}}],[\"⊥\",{\"2\":{\"1222\":1}}],[\"要突破智能的边界\",{\"2\":{\"2637\":1}}],[\"要求语言模型生成问题\",{\"2\":{\"2578\":1}}],[\"要求不同的expert明确负责不同任务\",{\"2\":{\"1762\":1}}],[\"要求教师模型和学生模型同时更新\",{\"2\":{\"995\":1}}],[\"要枚举所有可能的demonstrations组合几乎不可能\",{\"2\":{\"1222\":1}}],[\"呈指数关系\",{\"2\":{\"1222\":1}}],[\"呈现下降趋势\",{\"2\":{\"558\":1}}],[\"持续改进数据质量和数量\",{\"2\":{\"2255\":1}}],[\"持续递归\",{\"2\":{\"2141\":1}}],[\"持续关注\",{\"2\":{\"841\":1,\"1878\":1}}],[\"持家游戏属于游戏类型\",{\"2\":{\"1217\":1}}],[\"横向思维谜题\",{\"2\":{\"1217\":1}}],[\"离散稳健乐观规划\",{\"2\":{\"2405\":1}}],[\"离线方法\",{\"2\":{\"1721\":1}}],[\"离线方法依赖于数据集的质量和与模型能力的相似性\",{\"2\":{\"1667\":1}}],[\"离线方法则不要求模型亲自生成答案\",{\"2\":{\"1667\":1}}],[\"离线\",{\"0\":{\"1667\":1}}],[\"离线学习\",{\"2\":{\"1516\":1}}],[\"离线训练阶段\",{\"2\":{\"1230\":1}}],[\"离不开强大的框架支持\",{\"2\":{\"1200\":1}}],[\"离开窗口\",{\"2\":{\"769\":1}}],[\"记忆工具并在后续步骤中使用时\",{\"2\":{\"1904\":1}}],[\"记忆可以分为以下几种类型\",{\"2\":{\"1892\":1}}],[\"记忆可以定义为一种用于获取\",{\"2\":{\"1892\":1}}],[\"记忆的定义与分类\",{\"0\":{\"1892\":1},\"1\":{\"1947\":1,\"1998\":1,\"2049\":1}}],[\"记忆能力\",{\"2\":{\"1759\":1}}],[\"记忆\",{\"0\":{\"1661\":1},\"1\":{\"1715\":1,\"1772\":1,\"1833\":1,\"1892\":1,\"1947\":1,\"1998\":1,\"2049\":1,\"2102\":1,\"2152\":1,\"2195\":1,\"2234\":1},\"2\":{\"1233\":1}}],[\"记忆和执行任务能力的系统\",{\"2\":{\"1184\":1}}],[\"记录并分析不同训练步数下的模型表现\",{\"2\":{\"2701\":1}}],[\"记录训练过程中的参数变化以验证优化效果\",{\"2\":{\"1997\":1}}],[\"记录实验结果\",{\"2\":{\"645\":1}}],[\"记录更新次数\",{\"2\":{\"640\":1}}],[\"执行后续操作\",{\"2\":{\"2565\":1}}],[\"执行操作分为三步\",{\"2\":{\"2128\":1}}],[\"执行一次乘加\",{\"2\":{\"2043\":2}}],[\"执行peft方法进行微调\",{\"2\":{\"2034\":1}}],[\"执行环境选择\",{\"2\":{\"1740\":1}}],[\"执行前向传播学习\",{\"2\":{\"1721\":1}}],[\"执行工具的能力越强\",{\"2\":{\"1594\":1}}],[\"执行过程中获取环境真实反馈\",{\"0\":{\"1454\":1}}],[\"执行及排序等方面的应用取得了显著成果\",{\"2\":{\"1439\":1}}],[\"执行任务\",{\"2\":{\"1184\":1}}],[\"执行反馈\",{\"2\":{\"1181\":1}}],[\"↓\",{\"2\":{\"1178\":2}}],[\"↑\",{\"2\":{\"1178\":1}}],[\"丢弃无法正常处理的溢出token\",{\"2\":{\"1170\":1}}],[\"丢弃命中特定关键词\",{\"2\":{\"548\":1}}],[\"没有标题信息很难得到满意的结果\",{\"2\":{\"2196\":1}}],[\"没有之一\",{\"2\":{\"2118\":1}}],[\"没有\",{\"2\":{\"2118\":1}}],[\"没有复杂的决策逻辑\",{\"2\":{\"1728\":1}}],[\"没有状态转移\",{\"2\":{\"1673\":1}}],[\"没有企业愿意承担数据泄露的风险\",{\"2\":{\"1512\":1}}],[\"没有经过特定任务的微调\",{\"2\":{\"1162\":1}}],[\"没有专用硬件难以实现压缩和加速的效果\",{\"2\":{\"1010\":1}}],[\"法语\",{\"2\":{\"1154\":1}}],[\"法律等\",{\"2\":{\"475\":1}}],[\"英语\",{\"2\":{\"1154\":1}}],[\"英文多轮对话\",{\"2\":{\"2223\":1}}],[\"英文语料采样\",{\"0\":{\"873\":1}}],[\"英文知识\",{\"2\":{\"525\":1}}],[\"英文质量较高但不宜过少\",{\"2\":{\"474\":1}}],[\"英文\",{\"2\":{\"474\":4,\"803\":1}}],[\"质量过滤\",{\"2\":{\"2067\":1}}],[\"质量提升\",{\"2\":{\"1130\":1}}],[\"质量较差的样本可能因聚类分布而被采样\",{\"2\":{\"421\":1}}],[\"⊕rmsnorm\",{\"2\":{\"1127\":2}}],[\"隔离共享模块以减少知识冗余\",{\"2\":{\"1120\":1}}],[\"隔离一些共享专家模块以减少知识冗余\",{\"2\":{\"1030\":1}}],[\"∗2=4\",{\"2\":{\"1119\":2}}],[\"尺寸大小为\",{\"2\":{\"1119\":1}}],[\"很明显\",{\"2\":{\"1782\":1}}],[\"很难提供统一的评估标准和方法等\",{\"2\":{\"1118\":1}}],[\"很多复杂任务通常由多个步骤组成\",{\"2\":{\"1375\":1}}],[\"很多算法需要处理数值型数据\",{\"2\":{\"1068\":1}}],[\"很多人容易忽略缩放因子的作用\",{\"2\":{\"192\":1}}],[\"超过\",{\"2\":{\"1536\":1}}],[\"超过5\",{\"2\":{\"1117\":1}}],[\"超越对象\",{\"2\":{\"2622\":1}}],[\"超越了之前的算法\",{\"2\":{\"1955\":1}}],[\"超越人类绩效\",{\"2\":{\"1429\":1}}],[\"超越传统意义上的任务执行\",{\"2\":{\"1382\":1}}],[\"超出免费额度后需要购买套餐\",{\"2\":{\"1347\":2}}],[\"超长序列处理需随机初始化额外的位置向量\",{\"2\":{\"1281\":1}}],[\"超参数设置为\",{\"2\":{\"1204\":1}}],[\"超参数设置问题\",{\"2\":{\"175\":1}}],[\"超参数调优\",{\"2\":{\"349\":1}}],[\"超参数选择\",{\"2\":{\"338\":1}}],[\"世界模型等模块\",{\"2\":{\"1578\":1}}],[\"世界\",{\"2\":{\"1111\":1}}],[\"喜欢\",{\"2\":{\"1111\":1}}],[\"窗口过小可能丢失上下文信息\",{\"2\":{\"1109\":1}}],[\"窗口大小为n\",{\"2\":{\"1021\":1}}],[\"窗口大小不足\",{\"2\":{\"769\":1}}],[\"兼顾了灵活性和性能\",{\"2\":{\"1088\":1}}],[\"效果好\",{\"2\":{\"2145\":1}}],[\"效果\",{\"2\":{\"1278\":1}}],[\"效果仍优于直接训练的dense模型\",{\"2\":{\"1083\":1}}],[\"效率下降\",{\"2\":{\"941\":1}}],[\"效率高\",{\"2\":{\"595\":1}}],[\"效率增加50\",{\"2\":{\"502\":1}}],[\"扩充\",{\"2\":{\"1069\":1,\"1264\":1}}],[\"扩展现有数据集以提高模型通用能力\",{\"2\":{\"2556\":1}}],[\"扩展\",{\"0\":{\"1896\":1},\"1\":{\"1951\":1,\"2002\":1}}],[\"扩展长文本处理能力至更多实际场景\",{\"2\":{\"1492\":1}}],[\"扩展知识库的语言适应性\",{\"2\":{\"1466\":1}}],[\"扩展知识面\",{\"2\":{\"153\":1}}],[\"扩展多语言支持\",{\"2\":{\"1327\":1}}],[\"扩展到15t\",{\"2\":{\"1117\":1}}],[\"扩展特征空间\",{\"2\":{\"943\":1}}],[\"扩展benchmark测试以涵盖更多领域\",{\"2\":{\"756\":1}}],[\"扩展上下文长度至目标值\",{\"2\":{\"567\":1}}],[\"扩展模型的上下文长度\",{\"2\":{\"475\":1}}],[\"扩展性强\",{\"2\":{\"292\":1}}],[\"扩展范围灵活\",{\"2\":{\"292\":1}}],[\"扩展rope嵌入与注意力优化的实践\",{\"0\":{\"122\":1},\"1\":{\"142\":1,\"163\":1,\"184\":1,\"206\":1,\"228\":1,\"252\":1,\"276\":1,\"300\":1,\"322\":1,\"346\":1,\"372\":1},\"2\":{\"5\":1,\"84\":1}}],[\"扩展rope嵌入与注意力优化的实践|yarn方法解析\",{\"2\":{\"5\":1}}],[\"取决于具体的推理输入\",{\"2\":{\"1813\":1}}],[\"取决于输入序列的长度\",{\"2\":{\"750\":1}}],[\"取最后一个值或使用transformer聚合\",{\"2\":{\"1688\":1}}],[\"取得很好的成绩\",{\"2\":{\"1195\":1}}],[\"取得良好效果\",{\"2\":{\"1053\":1}}],[\"度量值\",{\"2\":{\"1050\":1}}],[\"度量值=权重大小×输入激活范数\",{\"2\":{\"1050\":2}}],[\"样本库中的所有样本以及一个停止信号标识\",{\"2\":{\"1222\":1}}],[\"样本构建\",{\"2\":{\"1047\":1}}],[\"样本构建与损失计算\",{\"0\":{\"1047\":1},\"2\":{\"1047\":1}}],[\"样本批次维度\",{\"2\":{\"227\":1}}],[\"拥有1\",{\"2\":{\"1040\":1}}],[\"地学习推理能力\",{\"2\":{\"1940\":1}}],[\"地图是现实地理信息的二维表示\",{\"2\":{\"1036\":1}}],[\"地址\",{\"2\":{\"741\":1,\"2184\":3}}],[\"就把\",{\"2\":{\"2641\":1}}],[\"就需要进行行切割\",{\"2\":{\"2616\":1}}],[\"就是把权重矩阵aaa按照行切分成两部分\",{\"2\":{\"2537\":1}}],[\"就是把多个对话合并成一个进行处理\",{\"2\":{\"2331\":1}}],[\"就和标准场景下的结果完全一致了\",{\"2\":{\"2517\":1}}],[\"就比如使用子问题查询\",{\"2\":{\"2335\":1}}],[\"就不需要单独训练一个reward\",{\"2\":{\"1954\":1}}],[\"就会变成无穷大\",{\"2\":{\"1925\":1}}],[\"就像地图\",{\"2\":{\"1036\":1}}],[\"就可以得到对于当前位置来说\",{\"2\":{\"2660\":1}}],[\"就可以更新局部的优化器状态\",{\"2\":{\"2308\":1}}],[\"就可以构成4d\",{\"2\":{\"917\":1}}],[\"就可以解决了\",{\"2\":{\"847\":1}}],[\"路由和扩充技术可以更好地匹配用户问题与文档内容\",{\"2\":{\"2484\":1}}],[\"路由\",{\"0\":{\"1879\":1},\"1\":{\"1935\":1}}],[\"路由网络选择两个最优专家处理输入\",{\"2\":{\"1822\":1}}],[\"路由器\",{\"0\":{\"1728\":1},\"2\":{\"1728\":1,\"1786\":2}}],[\"路由器可以多次调用外部工具获取诸如时间\",{\"2\":{\"1569\":1}}],[\"路由与门控机制\",{\"0\":{\"1704\":1}}],[\"路由偏置项调参\",{\"2\":{\"1324\":1}}],[\"路由专家数量\",{\"2\":{\"1318\":1}}],[\"路由的专家分布在多个设备上\",{\"2\":{\"1030\":1}}],[\"路由激活函数\",{\"2\":{\"998\":1}}],[\"获取用户行为数据及社交媒体信息\",{\"2\":{\"2255\":1}}],[\"获取相应的lora权重和缩放参数\",{\"2\":{\"1871\":1}}],[\"获取缩放值\",{\"2\":{\"1809\":1}}],[\"获取词向量\",{\"2\":{\"1111\":1}}],[\"获取该词的索引\",{\"2\":{\"1025\":1}}],[\"获取初始状态\",{\"2\":{\"646\":1}}],[\"卷积核的数量时\",{\"2\":{\"1022\":1}}],[\"卷积神经网络\",{\"2\":{\"44\":1,\"144\":1}}],[\"列切割\",{\"2\":{\"2609\":1}}],[\"列并行的方法如下\",{\"2\":{\"2609\":1}}],[\"列并行\",{\"0\":{\"2609\":1}}],[\"列出了\",{\"2\":{\"2245\":1}}],[\"列权重使用一组\",{\"2\":{\"1022\":1}}],[\"列表初始化\",{\"2\":{\"14\":1}}],[\"谷歌\",{\"2\":{\"1015\":1}}],[\"决策是智能体进行自主行动的核心环节\",{\"2\":{\"1567\":1}}],[\"决策\",{\"0\":{\"1567\":1},\"2\":{\"1474\":1}}],[\"决策树\",{\"2\":{\"39\":1}}],[\"决定进入下一个状态\",{\"2\":{\"1847\":1}}],[\"决定数据流向哪个专家\",{\"2\":{\"1170\":1}}],[\"决定了每个词在向量空间中的表示复杂度\",{\"2\":{\"996\":1}}],[\"⚡️\",{\"2\":{\"983\":1}}],[\"安全基于值的方法\",{\"0\":{\"2455\":1}}],[\"安全规划\",{\"0\":{\"2405\":1}}],[\"安全\",{\"2\":{\"967\":1}}],[\"安全管理不同api密钥\",{\"2\":{\"198\":1}}],[\"生产合成\",{\"0\":{\"2168\":1,\"2210\":1}}],[\"生僻词处理效率较低\",{\"2\":{\"1023\":1}}],[\"生僻词\",{\"2\":{\"941\":1}}],[\"生成分为隐式和显式两种方式\",{\"2\":{\"2578\":1}}],[\"生成问题的回答\",{\"2\":{\"2420\":1}}],[\"生成和批评\",{\"2\":{\"2365\":1}}],[\"生成答案是否与用户问题直接相关\",{\"2\":{\"2257\":1}}],[\"生成答案是否忠于原始数据或参考资料\",{\"2\":{\"2257\":1}}],[\"生成内容的语言结构复杂\",{\"2\":{\"2315\":1}}],[\"生成内容与上下文是否一致\",{\"2\":{\"2257\":1}}],[\"生成内容更为真实\",{\"2\":{\"1278\":1}}],[\"生成每个后续\",{\"2\":{\"2228\":1}}],[\"生成推理驱动的行动轨迹\",{\"2\":{\"2171\":1}}],[\"生成阶段\",{\"2\":{\"2171\":1}}],[\"生成不同格式和风格的\",{\"2\":{\"2168\":1}}],[\"生成文本和动作\",{\"2\":{\"2113\":1}}],[\"生成文本等\",{\"2\":{\"1238\":1}}],[\"生成效率\",{\"2\":{\"2081\":1}}],[\"生成效果的主要因素\",{\"2\":{\"1496\":1}}],[\"生成会十分缓慢\",{\"2\":{\"2079\":1}}],[\"生成回答阶段是一个至关重要的环节\",{\"2\":{\"2681\":1}}],[\"生成回答阶段的设计与优化\",{\"0\":{\"2681\":1},\"1\":{\"2684\":1,\"2687\":1,\"2690\":1,\"2693\":1,\"2696\":1,\"2699\":1,\"2702\":1}}],[\"生成回答\",{\"0\":{\"2305\":1},\"2\":{\"1950\":1}}],[\"生成response的阶段\",{\"2\":{\"1927\":1}}],[\"生成首token的时间与处理输入给大模型的prompt的计算量有关\",{\"2\":{\"1910\":1}}],[\"生成首token阶段也被称为预填充阶段\",{\"2\":{\"1910\":1}}],[\"生成首token是一个计算密集型任务\",{\"2\":{\"1910\":1}}],[\"生成其余token\",{\"2\":{\"1782\":1}}],[\"生成第1个token\",{\"2\":{\"1782\":1}}],[\"生成输出\",{\"2\":{\"1721\":1}}],[\"生成初步回答\",{\"2\":{\"1619\":1}}],[\"生成格式以及生成效果的稳定性往往很难控制\",{\"2\":{\"1540\":1}}],[\"生成长度为100\",{\"2\":{\"1435\":1}}],[\"生成多条推理链\",{\"2\":{\"2514\":1}}],[\"生成多个搜索查询\",{\"2\":{\"1835\":1}}],[\"生成多个推理解决方案\",{\"2\":{\"1224\":1}}],[\"生成多样化的回复\",{\"2\":{\"49\":1}}],[\"生成性预训练\",{\"2\":{\"930\":1}}],[\"生成的答案应针对所提供的问题\",{\"2\":{\"2574\":1}}],[\"生成的内容是否准确\",{\"2\":{\"2257\":1}}],[\"生成的内容是否完整\",{\"2\":{\"2257\":1}}],[\"生成的\",{\"2\":{\"2228\":2}}],[\"生成的行动虽然正确\",{\"2\":{\"1594\":1}}],[\"生成的行动本身无法执行\",{\"2\":{\"1594\":1}}],[\"生成的解释来增强较小推理器的训练\",{\"2\":{\"1224\":1}}],[\"生成的文本基于模型对上下文的理解\",{\"2\":{\"742\":1}}],[\"生成的token\",{\"2\":{\"581\":1,\"1613\":1}}],[\"生成与上下文相关的响应或输出\",{\"2\":{\"742\":1}}],[\"生成\",{\"0\":{\"2578\":1},\"2\":{\"435\":1,\"1941\":1,\"2420\":1}}],[\"生成从小到大的词表\",{\"2\":{\"420\":1}}],[\"生成更连贯\",{\"2\":{\"1514\":1}}],[\"生成更稳定\",{\"2\":{\"416\":1}}],[\"生成更随机\",{\"2\":{\"416\":1}}],[\"生成位置编码\",{\"2\":{\"263\":1}}],[\"生成一个关于人工智能的总结\",{\"2\":{\"708\":1}}],[\"生成一个高效的子词词表\",{\"2\":{\"319\":1}}],[\"生成一个\",{\"2\":{\"147\":1}}],[\"生成权重\",{\"2\":{\"112\":1}}],[\"生成任务选\",{\"2\":{\"40\":1}}],[\"贪心优化\",{\"2\":{\"941\":1}}],[\"贪婪策略选择当前状态\",{\"2\":{\"775\":1}}],[\"贪婪策略选择动作\",{\"2\":{\"577\":1,\"646\":1,\"681\":1}}],[\"贪婪策略中的参数\",{\"2\":{\"646\":1}}],[\"贪婪策略在选择动作时兼顾探索和利用\",{\"2\":{\"646\":1}}],[\"贪婪策略与探索\",{\"2\":{\"646\":1}}],[\"贪婪策略采取动作\",{\"2\":{\"640\":1}}],[\"贪婪算法局限性\",{\"2\":{\"562\":1}}],[\"贪婪算法\",{\"2\":{\"543\":1}}],[\"范围随任务需求变化\",{\"2\":{\"1447\":1}}],[\"范围\",{\"2\":{\"1344\":1,\"1399\":1}}],[\"范围内\",{\"2\":{\"1246\":1,\"1296\":1}}],[\"范围内均匀采样一个span\",{\"2\":{\"1089\":1}}],[\"范围最大\",{\"2\":{\"939\":1}}],[\"范数进行裁剪\",{\"2\":{\"622\":1}}],[\"隐式\",{\"2\":{\"2578\":1}}],[\"隐性记忆是无意识的\",{\"2\":{\"2049\":1}}],[\"隐性\",{\"2\":{\"2049\":1}}],[\"隐藏层向量\",{\"2\":{\"1782\":1}}],[\"隐含层\",{\"2\":{\"938\":2}}],[\"隐层向量\",{\"2\":{\"283\":1}}],[\"筛选\",{\"2\":{\"929\":1}}],[\"万亿中英标识符的预训练\",{\"2\":{\"925\":1}}],[\"万条\",{\"2\":{\"474\":1}}],[\"维度为\",{\"2\":{\"1782\":1}}],[\"维度为512的位置编码\",{\"2\":{\"1435\":1}}],[\"维度为512的序列进行可视化\",{\"2\":{\"1296\":1}}],[\"维度是\",{\"2\":{\"917\":1}}],[\"维基百科\",{\"2\":{\"929\":1}}],[\"维护窗口元素和\",{\"2\":{\"769\":1}}],[\"维护一个大小为\",{\"2\":{\"324\":1}}],[\"维护多个候选序列\",{\"2\":{\"253\":1}}],[\"形状为\",{\"2\":{\"917\":1}}],[\"形成多种rag模式\",{\"2\":{\"2523\":1}}],[\"形成\",{\"2\":{\"1922\":2}}],[\"形成switch\",{\"2\":{\"1129\":1}}],[\"形成字节片段序列\",{\"2\":{\"1021\":1}}],[\"形成种子数据语料库\",{\"2\":{\"532\":1}}],[\"形成新子词\",{\"2\":{\"497\":1}}],[\"形成最终输入\",{\"2\":{\"287\":1}}],[\"机评利用大模型如gpt4进行\",{\"2\":{\"2194\":1}}],[\"机评与人评\",{\"2\":{\"2194\":1}}],[\"机制有关\",{\"2\":{\"2145\":1}}],[\"机制在其他\",{\"2\":{\"1493\":1}}],[\"机制\",{\"2\":{\"917\":1,\"1447\":1,\"2042\":1}}],[\"机器人控制等\",{\"2\":{\"2418\":1}}],[\"机器人控制等领域\",{\"2\":{\"912\":1}}],[\"机器人控制等领域的快速发展\",{\"2\":{\"893\":1}}],[\"机器人团队在受灾区域搜索幸存者\",{\"2\":{\"1431\":1}}],[\"机器人等领域的应用增加\",{\"2\":{\"852\":1}}],[\"机器阅读理解\",{\"2\":{\"207\":1}}],[\"机器翻译中\",{\"2\":{\"188\":1}}],[\"机器翻译\",{\"2\":{\"38\":1,\"39\":1,\"80\":1,\"1019\":1}}],[\"机器学习技术文档\",{\"2\":{\"1953\":1}}],[\"机器学习技术\",{\"0\":{\"1697\":1},\"1\":{\"1755\":1,\"1815\":1},\"2\":{\"1624\":1}}],[\"机器学习架构\",{\"2\":{\"988\":1}}],[\"机器学习模型\",{\"0\":{\"984\":1}}],[\"机器学习算法\",{\"2\":{\"487\":1,\"543\":1,\"545\":1,\"1575\":1}}],[\"机器学习优化\",{\"0\":{\"2680\":1},\"1\":{\"2683\":1,\"2686\":1},\"2\":{\"181\":1,\"1605\":1}}],[\"机器学习原理\",{\"2\":{\"106\":1}}],[\"机器学习基础\",{\"0\":{\"77\":1},\"1\":{\"91\":1,\"106\":1},\"2\":{\"578\":1}}],[\"机器学习两章\",{\"2\":{\"56\":1}}],[\"机器学习的资料是真的多啊\",{\"2\":{\"56\":1}}],[\"机器学习的训练过程的核心就是通过调整模型的参数\",{\"2\":{\"32\":1}}],[\"机器学习\",{\"0\":{\"1024\":1,\"1584\":1,\"1623\":1,\"2150\":1},\"2\":{\"56\":1,\"106\":2,\"139\":1,\"377\":1,\"396\":1,\"397\":1,\"437\":1,\"478\":1,\"539\":1,\"543\":1,\"552\":1,\"617\":1,\"774\":1,\"832\":1,\"835\":1,\"836\":1,\"862\":1,\"890\":1,\"986\":1,\"987\":1,\"999\":1,\"1014\":1,\"1017\":1,\"1055\":1,\"1101\":1,\"1111\":1,\"1221\":1,\"1445\":1,\"1449\":1,\"1473\":1,\"1479\":1,\"1489\":1,\"1516\":2,\"1575\":1,\"1583\":1,\"1615\":1,\"1638\":1,\"1689\":1,\"1694\":1,\"1726\":1,\"2101\":1,\"2114\":1,\"2131\":1,\"2134\":1,\"2279\":1,\"2297\":1,\"2329\":1,\"2494\":1}}],[\"机器学习引言\",{\"0\":{\"39\":1}}],[\"机器学习概述\",{\"2\":{\"37\":1}}],[\"得分\",{\"2\":{\"2338\":1}}],[\"得益于目前\",{\"2\":{\"917\":1}}],[\"得到总loss\",{\"2\":{\"2676\":1}}],[\"得到每行的loss\",{\"2\":{\"2673\":1}}],[\"得到每行最终的\",{\"2\":{\"2670\":1}}],[\"得到各自gpu上的\",{\"2\":{\"2667\":1}}],[\"得到下一代模型\",{\"2\":{\"1976\":1}}],[\"得到符合人类偏好的奖励函数\",{\"2\":{\"1586\":1}}],[\"得到prob数据\",{\"2\":{\"1119\":1}}],[\"得到一个二维数组\",{\"2\":{\"917\":1}}],[\"得到初始状态\",{\"2\":{\"775\":1}}],[\"得到的结果与标准场景下完全一致\",{\"2\":{\"2528\":1}}],[\"得到的\",{\"2\":{\"653\":1}}],[\"得到\",{\"2\":{\"435\":1,\"2349\":1}}],[\"得到另一个向量\",{\"2\":{\"351\":1,\"1991\":1}}],[\"得到概率值后\",{\"2\":{\"105\":1}}],[\"咱们来看看\",{\"0\":{\"917\":1}}],[\"算子实现\",{\"2\":{\"2381\":1}}],[\"算子融合\",{\"2\":{\"2110\":1}}],[\"算子优化\",{\"2\":{\"1972\":1,\"2073\":1}}],[\"算子对其他模型层的支持进展\",{\"2\":{\"1878\":1}}],[\"算子对更多层\",{\"2\":{\"1700\":1}}],[\"算子的使用方法\",{\"2\":{\"1818\":1}}],[\"算子的优势\",{\"2\":{\"1592\":1}}],[\"算子显著提升了效率\",{\"2\":{\"1592\":1}}],[\"算子也在开发中\",{\"2\":{\"1451\":1}}],[\"算子\",{\"2\":{\"1451\":1}}],[\"算力和数据的改进\",{\"2\":{\"898\":1}}],[\"算法通常会通过多次更新策略来提高样本效率\",{\"2\":{\"2545\":1}}],[\"算法通过引入ppo\",{\"2\":{\"1596\":1}}],[\"算法通过拟合奖励函数与人类偏好\",{\"2\":{\"1491\":1}}],[\"算法\",{\"0\":{\"2171\":1},\"2\":{\"2022\":1,\"2102\":2,\"2297\":1,\"2329\":1,\"2338\":1}}],[\"算法将退化为最大熵强化学习\",{\"2\":{\"1954\":1}}],[\"算法是一个重要的工具\",{\"2\":{\"1841\":1}}],[\"算法是一种重要的实现策略\",{\"2\":{\"1559\":1}}],[\"算法以及检索系统的设计等\",{\"2\":{\"1775\":1,\"1895\":1}}],[\"算法优化\",{\"2\":{\"1726\":1}}],[\"算法与优化\",{\"2\":{\"1546\":1}}],[\"算法来优化actor模型\",{\"2\":{\"1523\":1}}],[\"算法训练策略\",{\"2\":{\"1491\":1}}],[\"算法创新\",{\"2\":{\"1277\":1}}],[\"算法流程\",{\"0\":{\"744\":1,\"789\":1},\"1\":{\"775\":1},\"2\":{\"647\":1,\"2081\":1}}],[\"算法流程以及python实现代码\",{\"2\":{\"577\":1}}],[\"算法实现较复杂\",{\"2\":{\"419\":1}}],[\"图略\",{\"2\":{\"2631\":1,\"2636\":1}}],[\"图例加深理解\",{\"0\":{\"2431\":1}}],[\"图中的\",{\"2\":{\"2318\":1}}],[\"图推理状态\",{\"2\":{\"2262\":1}}],[\"图示内容请参考相关资料\",{\"2\":{\"2188\":1}}],[\"图标记忆\",{\"2\":{\"1947\":1}}],[\"图片和视频\",{\"2\":{\"2001\":1,\"2052\":1}}],[\"图片等复杂数据映射到低维空间\",{\"2\":{\"1036\":1}}],[\"图片\",{\"2\":{\"882\":1}}],[\"图像右半部分颜色变化趋于平稳\",{\"2\":{\"1296\":1}}],[\"图像等\",{\"2\":{\"318\":1}}],[\"图像\",{\"2\":{\"227\":1}}],[\"图像分割\",{\"2\":{\"39\":1}}],[\"图像分类\",{\"2\":{\"39\":1}}],[\"然而需要注意损失函数的计算问题\",{\"2\":{\"2300\":1}}],[\"然而相对cv等经典应用场景\",{\"2\":{\"1843\":1}}],[\"然而decode环节的计算强度相对就低得多了\",{\"2\":{\"1843\":1}}],[\"然而\",{\"2\":{\"875\":1,\"995\":1,\"1160\":1,\"1209\":1,\"1215\":1,\"1260\":1,\"1285\":1,\"1321\":1,\"1377\":1,\"1469\":1,\"1496\":1,\"1505\":1,\"1559\":1,\"1610\":1,\"1807\":1,\"1813\":1,\"1841\":1,\"1869\":1,\"1884\":1,\"1949\":1,\"1954\":1,\"1978\":1,\"2000\":1,\"2066\":1,\"2094\":1,\"2250\":1,\"2278\":1,\"2351\":1,\"2505\":1,\"2637\":1,\"2660\":1,\"2672\":1,\"2688\":1,\"2704\":1,\"2706\":1}}],[\"然后得到输出\",{\"2\":{\"2526\":1}}],[\"然后再加上偏置向量\",{\"2\":{\"2526\":1}}],[\"然后再将短文本再多进行一次\",{\"2\":{\"847\":1}}],[\"然后分布到不同的设备上进行计算\",{\"2\":{\"2515\":1}}],[\"然后允许\",{\"2\":{\"2514\":1}}],[\"然后在通用能力数据集上应用sft\",{\"2\":{\"2424\":1}}],[\"然后在向量数据库中进行匹配\",{\"2\":{\"1610\":1}}],[\"然后迭代地进行计划\",{\"2\":{\"2370\":1}}],[\"然后为每个答案生成反思评分来评估检索到的文档是否相关\",{\"2\":{\"2365\":1}}],[\"然后继续合成回答\",{\"2\":{\"2291\":1}}],[\"然后聚合结果\",{\"2\":{\"2195\":1}}],[\"然后随机选择种子\",{\"2\":{\"2168\":1}}],[\"然后将梯度传递给前一个设备进行梯度计算和参数更新\",{\"2\":{\"2691\":1}}],[\"然后将计算结果合并成输出矩阵\",{\"2\":{\"2526\":1}}],[\"然后将反思结果加入prompt作为记忆\",{\"2\":{\"2113\":1}}],[\"然后将它们的输出以编程方式聚合在一起\",{\"2\":{\"2037\":1}}],[\"然后将所有的信息加入到prompt中\",{\"2\":{\"2011\":1}}],[\"然后将prompt与response结合计算损失\",{\"2\":{\"1572\":1}}],[\"然后给出最终答案\",{\"2\":{\"1859\":1}}],[\"然后使用critic当前的输出values对齐returns\",{\"2\":{\"1591\":1}}],[\"然后reward\",{\"2\":{\"1576\":1}}],[\"然后进入moe层\",{\"2\":{\"1456\":1}}],[\"然后确认全局有多少套专家副本在运行\",{\"2\":{\"1410\":1}}],[\"然后利用python解释器生成答案的方法\",{\"2\":{\"1730\":1}}],[\"然后利用ppo或其他算法训练策略\",{\"2\":{\"1539\":1}}],[\"然后利用这些模型识别句子边界\",{\"2\":{\"1665\":1}}],[\"然后利用这些指令来增强学生模型的能力\",{\"2\":{\"1275\":1}}],[\"然后利用专注于娱乐和影视内容的索引来生成相关推荐\",{\"2\":{\"1332\":1}}],[\"然后通过反馈机制进行学习\",{\"2\":{\"1614\":1}}],[\"然后通过任务特定的教师模型将这些扰动数据过滤\",{\"2\":{\"1224\":1}}],[\"然后通过一个特殊的函数\",{\"2\":{\"51\":1}}],[\"然后复制num\",{\"2\":{\"917\":1}}],[\"然后贪心检索最大长度加入\",{\"2\":{\"917\":1}}],[\"然后从头训练剪枝的模型\",{\"0\":{\"860\":1}}],[\"然后从值函数导出策略\",{\"2\":{\"724\":1}}],[\"然后微调\",{\"0\":{\"826\":1}}],[\"然后剪枝\",{\"0\":{\"795\":1}}],[\"然后\",{\"2\":{\"612\":1,\"917\":1,\"1717\":1,\"1925\":1,\"2236\":1,\"2286\":1,\"2578\":1,\"2625\":1}}],[\"然后就是辅助一些书籍\",{\"2\":{\"56\":1}}],[\"然后根据提纲写出完整文档\",{\"2\":{\"1820\":1}}],[\"然后根据目标kl来决定β\",{\"2\":{\"1033\":1}}],[\"然后根据概率值做出分类决策\",{\"2\":{\"42\":1}}],[\"然后根据特定参数给出的预测值与真实值的平方差和来确定是不是合适的参数\",{\"2\":{\"32\":1}}],[\"帮助读者理解其内在逻辑和操作步骤\",{\"2\":{\"2539\":1}}],[\"帮助读者更好地理解这一领域的最新进展\",{\"2\":{\"860\":1}}],[\"帮助性\",{\"2\":{\"2194\":1}}],[\"帮助学习人类偏好\",{\"2\":{\"1491\":1}}],[\"帮助提升agent在复杂任务中的可靠性\",{\"2\":{\"1407\":1}}],[\"帮助大家更好地理解和实践这一过程\",{\"2\":{\"1185\":1}}],[\"帮助大家更好地理解和使用这些工具\",{\"2\":{\"1151\":1}}],[\"帮助理解不同粒度选择对于模型性能和计算复杂度的影响\",{\"2\":{\"1065\":1}}],[\"帮助模型停止生成内容\",{\"2\":{\"1249\":1}}],[\"帮助模型理解单词之间的位置关系\",{\"2\":{\"956\":1}}],[\"帮助模型理解如何处理类似的任务\",{\"2\":{\"670\":1}}],[\"帮助模型理解输入序列的全局信息\",{\"2\":{\"146\":1}}],[\"帮助模型掌握语言和其他复杂技能\",{\"2\":{\"449\":1}}],[\"识别高消耗进程\",{\"2\":{\"2377\":1}}],[\"识别显存消耗的各个组成部分\",{\"2\":{\"2212\":1}}],[\"识别需要保留的模型\",{\"2\":{\"2053\":1}}],[\"识别需要调整的关键参数\",{\"2\":{\"2034\":1}}],[\"识别和处理模型的过拟合现象\",{\"2\":{\"1551\":1}}],[\"识别和生成\",{\"2\":{\"1275\":1}}],[\"识别应用场景\",{\"2\":{\"858\":1}}],[\"识别图片中的物体\",{\"2\":{\"39\":1}}],[\"区分精度可以降低\",{\"2\":{\"1306\":1}}],[\"区分句子对中的两个句子\",{\"2\":{\"1226\":1}}],[\"区分数据来源\",{\"2\":{\"858\":1}}],[\"区别于ppo将kl散度约束项加到奖励值中\",{\"2\":{\"2485\":1}}],[\"区别于无监督学习\",{\"2\":{\"503\":1}}],[\"区别\",{\"2\":{\"205\":1,\"420\":1,\"445\":1}}],[\"区别与联系\",{\"0\":{\"20\":1}}],[\"固定某个外循环\",{\"2\":{\"2653\":1}}],[\"固定大小分块适用于对上下文要求不高或对计算资源有限制的场景\",{\"2\":{\"2576\":1}}],[\"固定大小的分块是最简单和直接的方法\",{\"2\":{\"2560\":1}}],[\"固定大小的分块\",{\"0\":{\"2560\":1},\"1\":{\"2568\":1,\"2576\":1}}],[\"固定模板\",{\"2\":{\"2254\":1}}],[\"固定且可预测\",{\"2\":{\"2139\":1}}],[\"固定其余参数\",{\"2\":{\"2034\":1}}],[\"固定的文本模板\",{\"2\":{\"2032\":1}}],[\"固定长度\",{\"2\":{\"1763\":1}}],[\"固定长度分块|固定长度分块\",{\"2\":{\"2576\":1}}],[\"固定长度分块是一种最简单直观的文本分块方法\",{\"2\":{\"1366\":1}}],[\"固定长度分块\",{\"0\":{\"1320\":1},\"1\":{\"1366\":1,\"1411\":1,\"1457\":1,\"1503\":1,\"1548\":1,\"1598\":1,\"1652\":1,\"1705\":1,\"1763\":1,\"1823\":1,\"1882\":1,\"1937\":1,\"1987\":1,\"2039\":1,\"2091\":1,\"2141\":1},\"2\":{\"237\":1}}],[\"固定位置编码与可学习位置编码哪种更具优势\",{\"2\":{\"1481\":1}}],[\"固定目标函数\",{\"2\":{\"858\":1}}],[\"固定数据分布\",{\"2\":{\"858\":1}}],[\"非推理数据\",{\"2\":{\"2564\":1}}],[\"非推理数据则采用deepseek\",{\"2\":{\"2504\":1}}],[\"非量化评估主要关注生成内容的以下几个方面\",{\"2\":{\"2257\":1}}],[\"非量化评估\",{\"0\":{\"2257\":1}}],[\"非零掩码和softmax函数正确配置\",{\"2\":{\"2028\":1}}],[\"非公开的或离线的数据\",{\"2\":{\"1423\":1}}],[\"非常重要\",{\"2\":{\"1033\":1}}],[\"非常适合在gpu上进行并行操作\",{\"2\":{\"2563\":1}}],[\"非常适合用于表示位置信息\",{\"2\":{\"263\":1}}],[\"非常适合nlp任务\",{\"2\":{\"190\":1}}],[\"非叶节点包含参数化的sigmoid函数\",{\"2\":{\"980\":1}}],[\"非结构化剪枝方法\",{\"0\":{\"1050\":1}}],[\"非结构化剪枝通常需要对大语言模型\",{\"2\":{\"931\":1}}],[\"非结构化剪枝会导致模型出现不规则的稀疏结构\",{\"2\":{\"931\":1}}],[\"非结构化剪枝是指随机对独立权重或者神经元链接进行剪枝\",{\"2\":{\"931\":1}}],[\"非结构化剪枝\",{\"0\":{\"931\":1},\"1\":{\"969\":1,\"1010\":1,\"1050\":1}}],[\"非对称量化可以根据实际数据的分布确定最小值和最大值\",{\"2\":{\"868\":1}}],[\"非长文本继续预训练\",{\"2\":{\"847\":1}}],[\"备注\",{\"2\":{\"837\":1,\"873\":1,\"909\":1,\"1323\":1}}],[\"独热编码是一种简单有效的离散特征处理方式\",{\"2\":{\"1163\":1}}],[\"独热编码是一种将分类变量转换为数值向量的技术\",{\"2\":{\"871\":1}}],[\"独热编码消除了类别之间的偏序关系\",{\"2\":{\"1068\":1}}],[\"独热编码的必要性主要体现在以下几点\",{\"2\":{\"1068\":1}}],[\"独热编码的实现非常直观\",{\"2\":{\"943\":1}}],[\"独热编码无法体现词与词之间的相似性\",{\"2\":{\"985\":1}}],[\"独热编码能够将分类变量转化为数值向量\",{\"2\":{\"943\":1}}],[\"独热编码\",{\"2\":{\"836\":1}}],[\"独立生成多个思维链\",{\"2\":{\"2042\":1}}],[\"独立性\",{\"2\":{\"1241\":1}}],[\"独立配置\",{\"2\":{\"1048\":1}}],[\"独立子词表\",{\"2\":{\"631\":1}}],[\"独立思考这些信息\",{\"2\":{\"162\":1}}],[\"独立计算的核心\",{\"0\":{\"162\":1}}],[\"独立处理每个\",{\"2\":{\"121\":1}}],[\"霍夫曼树构建不合理\",{\"2\":{\"1109\":1}}],[\"霍夫曼树通过构建二叉树代替传统神经网络的softmax层\",{\"2\":{\"941\":1}}],[\"霍夫曼树\",{\"0\":{\"941\":1},\"2\":{\"835\":1}}],[\"做allreduce操作\",{\"2\":{\"2676\":1}}],[\"做safe\",{\"2\":{\"2349\":1}}],[\"做了什么\",{\"2\":{\"2113\":1}}],[\"做法\",{\"0\":{\"1470\":1}}],[\"做分类任务示例\",{\"2\":{\"961\":1}}],[\"做\",{\"2\":{\"813\":1}}],[\"首要步骤是准备知识文档\",{\"2\":{\"2001\":1}}],[\"首个token的推理延迟≥模型浮点计算量\",{\"2\":{\"1963\":1}}],[\"首个token的推理延迟≥gpu半精度浮点算力模型浮点计算量\",{\"2\":{\"1963\":1}}],[\"首个token的推理延迟可以表示为\",{\"2\":{\"1963\":1}}],[\"首个token的推理延迟\",{\"0\":{\"1963\":1},\"2\":{\"1963\":1}}],[\"首token时延\",{\"0\":{\"1910\":1},\"1\":{\"1963\":1,\"2014\":1}}],[\"首token时延优化\",{\"0\":{\"1854\":1},\"1\":{\"1910\":1,\"1963\":1,\"2014\":1,\"2064\":1,\"2117\":1,\"2166\":1},\"2\":{\"193\":1}}],[\"首次在2017年的论文\",{\"2\":{\"1633\":1}}],[\"首先考虑head=1的情况\",{\"2\":{\"2631\":1}}],[\"首先生成一个风格化的内容计划\",{\"2\":{\"2601\":1}}],[\"首先将文档分为尺寸较大的主文档\",{\"2\":{\"2236\":1}}],[\"首先将查询路由至专门处理当前热点话题的索引\",{\"2\":{\"1332\":1}}],[\"首先使用偏好数据训练奖励函数模型\",{\"2\":{\"1539\":1}}],[\"首先\",{\"2\":{\"1321\":1,\"1465\":1,\"1867\":1,\"1925\":1,\"2256\":1,\"2286\":1,\"2549\":1,\"2606\":1,\"2660\":1}}],[\"首先对教师模型进行充分训练\",{\"2\":{\"954\":1}}],[\"首先训练一个完整的模型\",{\"2\":{\"795\":1}}],[\"到多机多卡上\",{\"2\":{\"2433\":1}}],[\"到量化操作\",{\"2\":{\"1355\":1}}],[\"到指定范围内\",{\"2\":{\"1258\":1}}],[\"到\",{\"2\":{\"789\":1}}],[\"右侧新进入窗口的字母非元音字母\",{\"2\":{\"783\":1}}],[\"右侧新进入窗口的字母为元音字母\",{\"2\":{\"783\":2}}],[\"填充到固定长度\",{\"2\":{\"782\":1}}],[\"给出了与\",{\"2\":{\"2033\":1}}],[\"给出一些翻译示例来帮助模型进行语言翻译\",{\"2\":{\"708\":1}}],[\"给llm一个简单的提示词\",{\"2\":{\"1420\":1}}],[\"给定固定预算\",{\"2\":{\"1282\":1}}],[\"给定\",{\"2\":{\"1279\":1}}],[\"给模型发送一个请求\",{\"2\":{\"781\":1}}],[\"ϵhigh=0\",{\"2\":{\"2327\":1}}],[\"ϵlow=0\",{\"2\":{\"2327\":1}}],[\"ϵ=0\",{\"2\":{\"2327\":1}}],[\"ϵ=1e−8\",{\"2\":{\"1204\":2}}],[\"ϵ\",{\"2\":{\"775\":1,\"1622\":1,\"2479\":1}}],[\"神经架构搜索\",{\"2\":{\"763\":1}}],[\"神经网络的计算可以被抽象为一系列的矩阵和向量操作\",{\"2\":{\"2526\":1}}],[\"神经网络中的线性层\",{\"2\":{\"2526\":1}}],[\"神经网络\",{\"2\":{\"617\":1}}],[\"神经网络与深度学习\",{\"2\":{\"165\":1}}],[\"神经网络优化\",{\"2\":{\"119\":1}}],[\"神经网络基础\",{\"2\":{\"44\":1,\"144\":1}}],[\"半径为k子数组的长度是k\",{\"2\":{\"762\":1}}],[\"半径为k的子数组平均值\",{\"0\":{\"762\":1}}],[\"传递知识\",{\"2\":{\"749\":1}}],[\"传统ppo代码会对一批样本更新多个epoch\",{\"2\":{\"2569\":1}}],[\"传统上使用蒙特卡洛方法估计回报\",{\"2\":{\"2415\":1,\"2441\":1}}],[\"传统数据并行\",{\"0\":{\"2276\":1}}],[\"传统推理方式\",{\"0\":{\"1941\":1}}],[\"传统rlhf损失函数\",{\"2\":{\"1634\":1}}],[\"传统强化学习的rlhf\",{\"2\":{\"1634\":1}}],[\"传统位置编码中包含绝对位置信息\",{\"2\":{\"1266\":1}}],[\"传统的pipeline并行通常会在一个设备上放置几个block\",{\"2\":{\"2697\":1}}],[\"传统的ppo\",{\"2\":{\"2545\":1}}],[\"传统的流水线并行通常会在一个设备上放置几个模块\",{\"2\":{\"2688\":1}}],[\"传统的损失计算方式可能会导致长样本的贡献被低估\",{\"2\":{\"2575\":1,\"2644\":1}}],[\"传统的损失计算方式可能导致短输出的数据训练不充分\",{\"2\":{\"2267\":1}}],[\"传统的检索增强语言模型\",{\"2\":{\"2570\":1}}],[\"传统的因果解码形式需要每个token与之前所有的token进行注意力计算\",{\"2\":{\"2326\":1}}],[\"传统的crossentropyloss在不同轮次输出长度不同时可能导致训练不充分\",{\"2\":{\"2300\":1}}],[\"传统的cot\",{\"2\":{\"2011\":1}}],[\"传统的无价值模型方法\",{\"2\":{\"2054\":1}}],[\"传统的哈希算法中\",{\"2\":{\"1559\":1}}],[\"传统的表格法在这种情况下无法有效记录状态动作对的q值\",{\"2\":{\"606\":1}}],[\"传统的推理方式采用逐个token生成的方法\",{\"2\":{\"351\":1}}],[\"传统的前馈神经网络\",{\"2\":{\"138\":1}}],[\"传统ffn\",{\"2\":{\"220\":1}}],[\"传统ffn模块的计算公式为\",{\"2\":{\"178\":1}}],[\"传统self\",{\"2\":{\"147\":1}}],[\"白盒知识蒸馏与黑盒知识蒸馏的区别\",{\"0\":{\"1124\":1}}],[\"白盒知识蒸馏中\",{\"2\":{\"780\":1}}],[\"白盒知识蒸馏和黑盒知识蒸馏是两个主要研究方向\",{\"2\":{\"749\":1}}],[\"白盒知识蒸馏\",{\"0\":{\"749\":1},\"1\":{\"780\":1,\"811\":1,\"845\":1,\"880\":1,\"916\":1,\"954\":1,\"995\":1,\"1035\":1},\"2\":{\"1124\":1}}],[\"遵循策略\",{\"2\":{\"748\":1}}],[\"点击访问\",{\"2\":{\"741\":8}}],[\"点赞\",{\"2\":{\"548\":1}}],[\"跟踪openrlhf框架在社区中的应用案例\",{\"2\":{\"2432\":1}}],[\"跟踪最新的sft技术发展动态\",{\"2\":{\"2434\":1}}],[\"跟踪最新的\",{\"2\":{\"738\":1}}],[\"跟踪最新发布的大规模开源模型及其预训练技术进展\",{\"2\":{\"707\":1}}],[\"跟进codellama的最新成果及其在实际应用中的表现\",{\"2\":{\"740\":1}}],[\"撰写评测报告\",{\"2\":{\"737\":1}}],[\"∈rn×np\",{\"2\":{\"2080\":2}}],[\"∈rn×n\",{\"2\":{\"2080\":3}}],[\"∈rn×ns\",{\"2\":{\"2080\":1}}],[\"∈d​\",{\"2\":{\"1536\":1,\"1634\":1,\"1727\":1}}],[\"∈d\",{\"2\":{\"1536\":1,\"1634\":1,\"1727\":1}}],[\"∈amax​q∗\",{\"2\":{\"767\":1}}],[\"∈aq∗\",{\"2\":{\"767\":1}}],[\"∈a∑​π\",{\"2\":{\"732\":1}}],[\"∈aπ\",{\"2\":{\"732\":1}}],[\"∈s∑​p\",{\"2\":{\"656\":1,\"732\":2,\"767\":3,\"810\":1}}],[\"∈sp\",{\"2\":{\"656\":1,\"732\":2,\"767\":3,\"810\":1}}],[\"贝尔曼最优方程描述了最优价值函数的关系\",{\"2\":{\"767\":1}}],[\"贝尔曼期望方程用于描述状态价值函数\",{\"2\":{\"732\":1}}],[\"贝尔曼期望方程\",{\"0\":{\"732\":1}}],[\"贝尔曼方程的应用将变得更加广泛\",{\"2\":{\"937\":1}}],[\"贝尔曼方程如何影响强化学习算法的设计\",{\"2\":{\"797\":1}}],[\"贝尔曼方程在强化学习中是一个核心概念\",{\"2\":{\"696\":1}}],[\"贝尔曼方程\",{\"0\":{\"624\":1},\"1\":{\"659\":1,\"696\":1,\"732\":1,\"767\":1,\"797\":1,\"831\":1,\"866\":1,\"902\":1,\"937\":1,\"979\":1},\"2\":{\"151\":1,\"545\":1,\"659\":1}}],[\"贝尔曼方程|贝尔曼方程\",{\"2\":{\"5\":1}}],[\"位\",{\"2\":{\"1756\":3}}],[\"位整数\",{\"2\":{\"1110\":1}}],[\"位整数表示\",{\"2\":{\"729\":1}}],[\"位运算来提升推理速度\",{\"2\":{\"768\":1}}],[\"位数仅为\",{\"2\":{\"768\":1}}],[\"位浮点数表示转换为\",{\"2\":{\"729\":1}}],[\"位置敏感哈希\",{\"0\":{\"1511\":1},\"1\":{\"1559\":1},\"2\":{\"1559\":1}}],[\"位置标签\",{\"2\":{\"1418\":1}}],[\"位置标记\",{\"2\":{\"1045\":1}}],[\"位置\",{\"2\":{\"1207\":2,\"1353\":2}}],[\"位置id通过embedding表投影为两个向量\",{\"2\":{\"1045\":1}}],[\"位置嵌入\",{\"2\":{\"956\":1,\"1226\":1}}],[\"位置内插后\",{\"2\":{\"245\":1}}],[\"位置内插\",{\"2\":{\"180\":1}}],[\"位置内插法可能成为主流技术之一\",{\"2\":{\"360\":1}}],[\"位置内插法通过缩放位置索引\",{\"2\":{\"222\":1}}],[\"位置内插法\",{\"2\":{\"160\":1}}],[\"位置内插法扩展语言模型上下文长度\",{\"0\":{\"140\":1},\"1\":{\"160\":1,\"180\":1,\"201\":1,\"222\":1,\"245\":1,\"268\":1,\"291\":1,\"313\":1,\"336\":1,\"360\":1,\"387\":1,\"413\":1},\"2\":{\"84\":1}}],[\"位置内插法扩展语言模型上下文长度|位置内插法扩展语言模型上下文长度\",{\"2\":{\"5\":1}}],[\"位置等信息预测房价\",{\"2\":{\"39\":1}}],[\"位置编码的定义与公式\",{\"0\":{\"1246\":1}}],[\"位置编码的设计要求\",{\"0\":{\"239\":1}}],[\"位置编码训练\",{\"2\":{\"1243\":1}}],[\"位置编码从每个\",{\"2\":{\"1048\":1}}],[\"位置编码改进\",{\"0\":{\"1048\":1}}],[\"位置编码优化\",{\"2\":{\"1041\":1}}],[\"位置编码对模型性能提升的具体贡献\",{\"2\":{\"409\":1}}],[\"位置编码需要满足以下几个要求\",{\"2\":{\"239\":1}}],[\"位置编码是深度学习中用于标识序列中位置信息的技术\",{\"2\":{\"1231\":1}}],[\"位置编码是通过静态的三角函数形式生成的\",{\"2\":{\"1215\":1}}],[\"位置编码是解决无向attention机制中时序信息缺失问题的核心\",{\"2\":{\"216\":1}}],[\"位置编码是transformer模型中不可或缺的一部分\",{\"2\":{\"203\":1}}],[\"位置编码\",{\"2\":{\"28\":1,\"34\":1,\"154\":1,\"174\":1,\"182\":1,\"1044\":1,\"1063\":1,\"1085\":1,\"1098\":1}}],[\"∝s∈s∑​νπθ​​\",{\"2\":{\"723\":1}}],[\"∝∑s∈sνπθ\",{\"2\":{\"723\":1}}],[\"∑\",{\"2\":{\"2670\":2,\"2673\":1}}],[\"∑yπref\",{\"2\":{\"1889\":1}}],[\"∑yπ∗\",{\"2\":{\"1889\":1}}],[\"∑r\",{\"2\":{\"1634\":6}}],[\"∑i=1g∑t=1∣oi∣\",{\"2\":{\"2485\":1,\"2577\":1}}],[\"∑i=1g\",{\"2\":{\"1628\":1}}],[\"∑t\",{\"2\":{\"757\":1}}],[\"∑t=0tψt∇θlog⁡πθ\",{\"2\":{\"1942\":1,\"1993\":1}}],[\"∑t=0t\",{\"2\":{\"757\":1}}],[\"∑a\",{\"2\":{\"732\":1}}],[\"∑a∈aqπθ\",{\"2\":{\"723\":1}}],[\"∑​p\",{\"2\":{\"647\":1}}],[\"师生架构\",{\"2\":{\"715\":1}}],[\"打印device\",{\"2\":{\"2108\":1}}],[\"打印每个文本块\",{\"2\":{\"1823\":1}}],[\"打破样本之间的相关性\",{\"2\":{\"712\":1}}],[\"打分器的训练时间和资源投入应适度\",{\"2\":{\"507\":1}}],[\"教师模型和学生模型采用相同的网络结构\",{\"2\":{\"1035\":1}}],[\"教师模型和学生模型的结构可能不同\",{\"2\":{\"845\":1}}],[\"教师模型参数量大且精度性能高\",{\"2\":{\"995\":1}}],[\"教师模型通常参数量大且训练时间较长\",{\"2\":{\"954\":1}}],[\"教师模型通常来自开源的大语言模型\",{\"2\":{\"677\":1}}],[\"教师模型预训练\",{\"2\":{\"954\":1}}],[\"教师模型在充分学习后\",{\"2\":{\"811\":1}}],[\"教师\",{\"2\":{\"763\":1}}],[\"教师网络会比学生网络大\",{\"2\":{\"715\":1}}],[\"教育资料与论文\",{\"2\":{\"535\":1}}],[\"音频等多种形式的数据整合\",{\"2\":{\"669\":1}}],[\"建模\",{\"2\":{\"1515\":1}}],[\"建立困惑度基准\",{\"2\":{\"662\":1}}],[\"建议将可微调参数平均分配到\",{\"2\":{\"2164\":1}}],[\"建议采用\",{\"2\":{\"1404\":1}}],[\"建议从自身模型中获取数据\",{\"2\":{\"1213\":1}}],[\"建议在模型设计中充分考虑计算资源分配\",{\"2\":{\"1163\":1}}],[\"建议\",{\"2\":{\"631\":1}}],[\"建议划分至三级类别\",{\"2\":{\"474\":1}}],[\"建议使用以下公式进行温度参数的选择\",{\"2\":{\"184\":1}}],[\"轮\",{\"2\":{\"656\":1}}],[\"均方根归一化\",{\"2\":{\"1358\":1}}],[\"均方误差损失函数\",{\"2\":{\"619\":1,\"640\":1}}],[\"均匀随机策略\",{\"2\":{\"656\":1}}],[\"奖励修改方法\",{\"2\":{\"2692\":1}}],[\"奖励值\",{\"2\":{\"2446\":1}}],[\"奖励归一化策略\",{\"0\":{\"2213\":1}}],[\"奖励归一化和优势归一化技术有助于训练稳定性\",{\"2\":{\"911\":1}}],[\"奖励是强化学习\",{\"2\":{\"1797\":1}}],[\"奖励\",{\"2\":{\"1740\":2}}],[\"奖励建模核心观点\",{\"0\":{\"1797\":1}}],[\"奖励建模\",{\"0\":{\"1739\":1}}],[\"奖励公式的具体表达\",{\"0\":{\"1732\":1}}],[\"奖励设计创新\",{\"2\":{\"2143\":1}}],[\"奖励设计的创新\",{\"2\":{\"1884\":1}}],[\"奖励设计在此过程中扮演着关键角色\",{\"2\":{\"1765\":1}}],[\"奖励设计\",{\"2\":{\"1707\":1,\"1740\":1}}],[\"奖励评估\",{\"0\":{\"1637\":1}}],[\"奖励计算\",{\"2\":{\"1582\":1}}],[\"奖励学习与优化\",{\"2\":{\"1536\":1}}],[\"奖励模型能力\",{\"2\":{\"2076\":1}}],[\"奖励模型通常是在sft\",{\"2\":{\"1582\":1}}],[\"奖励模型训练\",{\"0\":{\"1582\":1}}],[\"奖励模型的参数是冻结的\",{\"2\":{\"1533\":1}}],[\"奖励模型\",{\"2\":{\"1489\":1,\"1533\":1}}],[\"奖励模型语料构建\",{\"2\":{\"1213\":1}}],[\"奖励黑客问题\",{\"2\":{\"1505\":1}}],[\"奖励黑客\",{\"2\":{\"1414\":1}}],[\"奖励函数反推\",{\"0\":{\"1994\":1}}],[\"奖励函数\",{\"2\":{\"655\":3,\"1445\":1,\"1552\":1,\"1787\":1,\"2238\":1,\"2520\":1,\"2532\":1}}],[\"奖励机制设计\",{\"0\":{\"1905\":1}}],[\"奖励机制的调整\",{\"0\":{\"1676\":1}}],[\"奖励机制通过调整公式\",{\"2\":{\"1522\":1}}],[\"奖励机制\",{\"0\":{\"2683\":1},\"2\":{\"539\":1,\"1568\":1}}],[\"∼dπϕrl​​​\",{\"2\":{\"1685\":1}}],[\"∼dπϕrl\",{\"2\":{\"1685\":1}}],[\"∼d​\",{\"2\":{\"1582\":1,\"1795\":1}}],[\"∼d\",{\"2\":{\"1582\":1,\"1795\":1}}],[\"∼策略的占用度量​\",{\"2\":{\"655\":1}}],[\"∼策略的占用度量\",{\"2\":{\"655\":1}}],[\"∼数据分布​\",{\"2\":{\"655\":1}}],[\"∼数据分布\",{\"2\":{\"655\":1}}],[\"轨迹的总回报\",{\"2\":{\"654\":1,\"1992\":1,\"2045\":1}}],[\"跨领域数据质量标准化\",{\"2\":{\"650\":1}}],[\"跨组信息流动\",{\"2\":{\"197\":1}}],[\"满足收敛条件\",{\"2\":{\"647\":1}}],[\"满足不同场景需求\",{\"2\":{\"318\":1}}],[\"反向和生成过程涉及到大量数据通信\",{\"2\":{\"2081\":1}}],[\"反向传播时如果有保存下来的梯度就直接使用\",{\"2\":{\"2503\":1}}],[\"反向传播计算梯度\",{\"2\":{\"820\":1}}],[\"反向传播更新参数\",{\"2\":{\"640\":1}}],[\"反向传播\",{\"2\":{\"144\":1,\"435\":1,\"1225\":1}}],[\"反应式推理\",{\"2\":{\"1917\":1}}],[\"反之\",{\"2\":{\"1857\":1}}],[\"反思行为\",{\"2\":{\"2169\":1}}],[\"反思能力\",{\"2\":{\"1759\":1}}],[\"反思与完善\",{\"0\":{\"1509\":1},\"1\":{\"1557\":1}}],[\"反爬机制也会愈发复杂\",{\"2\":{\"701\":1}}],[\"反复更新每个状态的价值\",{\"2\":{\"647\":1}}],[\"∣xj​∣\",{\"2\":{\"2033\":1}}],[\"∣xj∣\",{\"2\":{\"2033\":1}}],[\"∣wj​∣\",{\"2\":{\"2033\":1}}],[\"∣wj∣\",{\"2\":{\"2033\":1}}],[\"∣q∣|q|∣q∣\",{\"2\":{\"1644\":1}}],[\"∣st​=s\",{\"2\":{\"748\":1,\"779\":1}}],[\"∣st=s\",{\"2\":{\"748\":1,\"779\":1}}],[\"∣s\",{\"2\":{\"647\":2,\"656\":2,\"732\":6,\"767\":6,\"810\":2}}],[\"∣∣g∣∣\",{\"2\":{\"622\":2}}],[\"循环计算过程\",{\"0\":{\"2557\":1},\"1\":{\"2565\":1,\"2573\":1,\"2581\":1,\"2589\":1,\"2597\":1,\"2604\":1,\"2611\":1,\"2618\":1,\"2623\":1,\"2628\":1,\"2633\":1}}],[\"循环更新q值\",{\"2\":{\"646\":1}}],[\"循环神经网络\",{\"2\":{\"39\":1,\"44\":1,\"144\":1}}],[\"计数器\",{\"2\":{\"640\":1}}],[\"计算局部cross\",{\"0\":{\"2673\":1}}],[\"计算量\",{\"0\":{\"2643\":1}}],[\"计算量和显存\",{\"0\":{\"2633\":1}}],[\"计算流程\",{\"0\":{\"2638\":1},\"1\":{\"2643\":1,\"2648\":1,\"2653\":1}}],[\"计算下一个节点完成后丢弃中间节点的激活值\",{\"2\":{\"2503\":1}}],[\"计算基于思维链中目标语言单词的比例\",{\"2\":{\"2491\":1}}],[\"计算基线值\",{\"2\":{\"2007\":1}}],[\"计算卸载策略\",{\"0\":{\"2468\":1}}],[\"计算的伪代码\",{\"0\":{\"2406\":1}}],[\"计算output\",{\"0\":{\"2379\":1}}],[\"计算梯度均值\",{\"2\":{\"2374\":1}}],[\"计算梯度后\",{\"2\":{\"2276\":1}}],[\"计算loss时\",{\"2\":{\"2322\":1}}],[\"计算logits的softmax并取log\",{\"2\":{\"1761\":1}}],[\"计算初始attention分数\",{\"0\":{\"2318\":1}}],[\"计算挑战\",{\"0\":{\"2313\":1}}],[\"计算挑战以及并行策略挑战\",{\"2\":{\"2246\":1}}],[\"计算好梯度均值后\",{\"2\":{\"2308\":1}}],[\"计算出归一化奖励作为优势函数\",{\"2\":{\"2337\":1}}],[\"计算出优势函数的估计\",{\"2\":{\"2306\":1}}],[\"计算出每个输出的归一化奖励作为优势函数\",{\"2\":{\"2273\":1}}],[\"计算出的损失值\",{\"2\":{\"435\":1}}],[\"计算其状态参数所需的显存\",{\"2\":{\"2266\":1}}],[\"计算其基线值为其奖励减去其他response奖励的均值\",{\"2\":{\"2007\":1}}],[\"计算block2\",{\"0\":{\"2216\":1}}],[\"计算block1\",{\"0\":{\"2176\":1}}],[\"计算公式如下\",{\"2\":{\"2192\":1}}],[\"计算一个\",{\"0\":{\"2145\":1}}],[\"计算一个线性方程\",{\"2\":{\"76\":1}}],[\"计算如下\",{\"2\":{\"2140\":1}}],[\"计算softmax\",{\"2\":{\"2130\":1}}],[\"计算safe\",{\"2\":{\"1925\":1}}],[\"计算两个向量之间的几何距离\",{\"2\":{\"2051\":1}}],[\"计算两个向量相似度的方法也是一个可选参数\",{\"2\":{\"2051\":1}}],[\"计算带宽\",{\"2\":{\"1977\":1}}],[\"计算带宽与内存带宽\",{\"0\":{\"1977\":1},\"1\":{\"2027\":1}}],[\"计算结果并返回\",{\"2\":{\"1871\":1}}],[\"计算速度已经远超过了显存访问速度\",{\"2\":{\"1869\":1}}],[\"计算优化器状态\",{\"2\":{\"2266\":1}}],[\"计算优化\",{\"2\":{\"1785\":1}}],[\"计算优势\",{\"2\":{\"695\":1}}],[\"计算该过程时\",{\"2\":{\"1782\":1}}],[\"计算每个token的loss\",{\"2\":{\"2612\":1,\"2665\":1}}],[\"计算每个token的log概率\",{\"2\":{\"2585\":1}}],[\"计算每个token的kl散度并加入奖励函数\",{\"2\":{\"637\":1}}],[\"计算每个样本之间的相似性分数\",{\"2\":{\"1784\":1}}],[\"计算每个位置的forward\",{\"2\":{\"1761\":1}}],[\"计算预训练所需资源的公式为\",{\"2\":{\"1232\":1}}],[\"计算预算与数据规模和模型参数数成正比\",{\"2\":{\"1232\":1}}],[\"计算预算公式及其意义\",{\"0\":{\"1232\":1}}],[\"计算预算\",{\"2\":{\"1086\":1,\"1232\":3}}],[\"计算\",{\"0\":{\"1984\":1,\"2189\":1},\"1\":{\"2228\":1},\"2\":{\"1225\":1,\"1703\":1,\"1984\":1,\"1991\":1,\"2263\":2}}],[\"计算相似度\",{\"2\":{\"1075\":1}}],[\"计算也更复杂\",{\"2\":{\"981\":1}}],[\"计算价值函数\",{\"2\":{\"844\":1}}],[\"计算价值网络的梯度\",{\"2\":{\"619\":1}}],[\"计算转移概率和奖励\",{\"2\":{\"831\":1}}],[\"计算圆面积的示例\",{\"2\":{\"747\":1}}],[\"计算目标函数对参数的导数\",{\"2\":{\"723\":1}}],[\"计算当前策略的状态价值函数\",{\"2\":{\"656\":1}}],[\"计算当前token的q\",{\"2\":{\"166\":1,\"187\":1}}],[\"计算在某策略下\",{\"2\":{\"647\":1}}],[\"计算有几个动作得到了最大的q值\",{\"2\":{\"647\":1}}],[\"计算策略网络的梯度\",{\"2\":{\"619\":1}}],[\"计算时\",{\"2\":{\"2688\":2}}],[\"计算时延\",{\"0\":{\"483\":1}}],[\"计算时会对权重进行缩放\",{\"2\":{\"130\":1}}],[\"计算权重\",{\"2\":{\"473\":1}}],[\"计算类内平均样本相似度并反向作为多样性权重\",{\"2\":{\"473\":1}}],[\"计算准备\",{\"2\":{\"435\":1}}],[\"计算子词对的互信息得分\",{\"2\":{\"407\":1}}],[\"计算子词概率\",{\"2\":{\"393\":1}}],[\"计算删除每个子词对总损失\",{\"2\":{\"393\":1}}],[\"计算成本高\",{\"2\":{\"1562\":1}}],[\"计算成本\",{\"0\":{\"1201\":1},\"2\":{\"365\":1}}],[\"计算成本更高\",{\"2\":{\"341\":1}}],[\"计算资源消耗大\",{\"2\":{\"330\":1}}],[\"计算资源消耗较大\",{\"2\":{\"215\":1}}],[\"计算缩放比例\",{\"2\":{\"291\":1}}],[\"计算简单\",{\"2\":{\"238\":1}}],[\"计算机视觉\",{\"2\":{\"227\":1}}],[\"计算点积\",{\"2\":{\"213\":1}}],[\"计算更复杂\",{\"2\":{\"199\":1}}],[\"计算与内存限制\",{\"0\":{\"1807\":1},\"1\":{\"1869\":1,\"1926\":1,\"1977\":1,\"2027\":1,\"2077\":1,\"2128\":1,\"2175\":1},\"2\":{\"193\":1}}],[\"计算内容\",{\"2\":{\"166\":1,\"187\":1}}],[\"计算引擎\",{\"2\":{\"162\":1}}],[\"计算效率和模型性能是两个重要的考量因素\",{\"2\":{\"2539\":1}}],[\"计算效率较低\",{\"2\":{\"1373\":1}}],[\"计算效率降低\",{\"2\":{\"1328\":1}}],[\"计算效率高\",{\"0\":{\"2704\":1},\"2\":{\"941\":1}}],[\"计算效率极高但精度损失较大\",{\"2\":{\"768\":1}}],[\"计算效率\",{\"2\":{\"155\":1}}],[\"计算瓶颈\",{\"2\":{\"149\":1}}],[\"计算查询块与键块的注意力\",{\"2\":{\"135\":1}}],[\"计算复杂度从词汇表大小\",{\"2\":{\"941\":1}}],[\"计算复杂度稍高\",{\"2\":{\"307\":1}}],[\"计算复杂度\",{\"2\":{\"94\":1}}],[\"甚至部分相同的\",{\"2\":{\"2064\":1}}],[\"甚至有害\",{\"2\":{\"1633\":1}}],[\"甚至引入自动化排序算法来优化训练顺序\",{\"2\":{\"633\":1}}],[\"甚至导致崩溃\",{\"2\":{\"169\":1}}],[\"→r1\",{\"2\":{\"778\":1}}],[\"→r0\",{\"2\":{\"778\":1}}],[\"→a1\",{\"2\":{\"778\":1}}],[\"→a0\",{\"2\":{\"778\":1}}],[\"→y^​k+1​\",{\"2\":{\"773\":1}}],[\"→y^k+1llm\",{\"2\":{\"773\":1}}],[\"→\",{\"2\":{\"631\":2,\"1872\":5,\"2098\":2}}],[\"面向企业场景\",{\"2\":{\"1347\":1}}],[\"面向对象编程关注对象和类的设计\",{\"2\":{\"20\":1}}],[\"面向对象编程通过类和对象实现更复杂的模型\",{\"2\":{\"20\":1}}],[\"面向对象编程通过类和对象来组织代码\",{\"2\":{\"12\":1}}],[\"面向对象编程\",{\"2\":{\"12\":1,\"20\":3}}],[\"面向对象编程和泛型编程\",{\"0\":{\"8\":1},\"1\":{\"12\":1}}],[\"面对复杂的反爬机制\",{\"2\":{\"628\":1}}],[\"｜\",{\"2\":{\"626\":1}}],[\"北京\",{\"2\":{\"626\":1}}],[\"熟悉并实践trafilatura库的网页内容抓取功能\",{\"2\":{\"615\":1}}],[\"带行为约束的优化目标通过修改奖励值来限制策略更新\",{\"2\":{\"1720\":1}}],[\"带行为约束的优化目标\",{\"2\":{\"614\":1}}],[\"带频次\",{\"0\":{\"443\":1}}],[\"←q\",{\"2\":{\"611\":2,\"640\":2,\"672\":2,\"710\":2}}],[\"←v\",{\"2\":{\"608\":2}}],[\"金融\",{\"2\":{\"1508\":1}}],[\"金融预测等领域将得到更广泛应用\",{\"2\":{\"953\":1}}],[\"金融风险控制\",{\"2\":{\"605\":1}}],[\"金融领域\",{\"2\":{\"49\":1}}],[\"游戏与模拟\",{\"2\":{\"1431\":1}}],[\"游戏\",{\"2\":{\"605\":1,\"1217\":1}}],[\"双层\",{\"2\":{\"2245\":1}}],[\"双重量化\",{\"2\":{\"1793\":1}}],[\"双重量化和paged\",{\"2\":{\"1679\":1}}],[\"双向\",{\"2\":{\"595\":1}}],[\"双向注意力\",{\"2\":{\"595\":1}}],[\"双指针\",{\"2\":{\"30\":1}}],[\"控制熵值\",{\"2\":{\"2612\":1,\"2665\":1}}],[\"控制文本长度\",{\"2\":{\"2543\":1}}],[\"控制token生成的概率\",{\"2\":{\"2357\":1}}],[\"控制器\",{\"2\":{\"2227\":1}}],[\"控制损失函数敏感度\",{\"2\":{\"1960\":1}}],[\"控制\",{\"2\":{\"656\":1,\"1229\":1}}],[\"控制问题\",{\"2\":{\"605\":1}}],[\"控制softmax归一化增长\",{\"2\":{\"593\":1}}],[\"控制注意力权重分布\",{\"2\":{\"346\":1}}],[\"浅层梯度缩放\",{\"2\":{\"593\":1}}],[\"​×pij​vj​\",{\"2\":{\"2618\":1}}],[\"​评估某段内容是否不当\",{\"2\":{\"2037\":1}}],[\"​审查代码是否存在漏洞\",{\"2\":{\"2037\":1}}],[\"​voting\",{\"2\":{\"2037\":1}}],[\"​自动化多维度模型评估\",{\"2\":{\"2037\":1}}],[\"​并行内容审核与主任务处理\",{\"2\":{\"2037\":1}}],[\"​示例\",{\"2\":{\"2037\":1}}],[\"​+βlogz\",{\"2\":{\"1994\":1,\"2046\":1}}],[\"​∇θ​logπθ​\",{\"2\":{\"1901\":1}}],[\"​​\",{\"2\":{\"1830\":1}}],[\"​​logz\",{\"2\":{\"1830\":1}}],[\"​−m\",{\"2\":{\"2528\":1}}],[\"​−logz\",{\"2\":{\"1830\":1}}],[\"​−βlogπ∗\",{\"2\":{\"2046\":1}}],[\"​−βlogπref​\",{\"2\":{\"1795\":1}}],[\"​−β1​r\",{\"2\":{\"1712\":1}}],[\"​=pi\",{\"2\":{\"2528\":1}}],[\"​=−e\",{\"2\":{\"1795\":1}}],[\"​=ut​+i=1∑ns​​ffni\",{\"2\":{\"1364\":1}}],[\"​a^i\",{\"2\":{\"2485\":1}}],[\"​ai​\",{\"2\":{\"1628\":1}}],[\"​aπθk​​​\",{\"2\":{\"2044\":1,\"2097\":1}}],[\"​aπθk​​\",{\"2\":{\"590\":1}}],[\"​⋅at​\",{\"2\":{\"1622\":1}}],[\"​if\",{\"2\":{\"1364\":1}}],[\"​sectioning\",{\"2\":{\"2037\":1}}],[\"​s\",{\"2\":{\"1344\":1}}],[\"​→r1\",{\"2\":{\"778\":1}}],[\"​→r0\",{\"2\":{\"778\":1}}],[\"​→a1\",{\"2\":{\"778\":1}}],[\"​→a0\",{\"2\":{\"778\":1}}],[\"​q\",{\"2\":{\"623\":1}}],[\"​\",{\"2\":{\"590\":2,\"614\":2,\"622\":1,\"640\":1,\"757\":1,\"778\":4,\"1364\":2,\"1536\":1,\"1582\":1,\"1622\":1,\"1628\":1,\"1634\":1,\"1657\":4,\"1671\":1,\"1683\":1,\"1685\":1,\"1712\":1,\"1732\":2,\"1795\":3,\"1901\":1,\"2030\":1,\"2044\":2,\"2046\":2,\"2097\":2,\"2137\":1,\"2306\":1,\"2347\":8,\"2485\":2,\"2528\":3,\"2577\":1,\"2688\":8}}],[\"​x≤0x\",{\"2\":{\"285\":1}}],[\"∇θ​logπθ​\",{\"2\":{\"586\":1,\"723\":1,\"757\":1,\"2531\":1,\"2542\":1}}],[\"∇θ​j\",{\"2\":{\"586\":1,\"723\":1,\"757\":1}}],[\"∇θlog⁡πθ\",{\"2\":{\"586\":1,\"723\":1,\"757\":1,\"1901\":1,\"2531\":1,\"2542\":1}}],[\"∇θj\",{\"2\":{\"586\":1,\"723\":1,\"757\":1}}],[\"达到平衡探索与利用的目的\",{\"2\":{\"577\":1}}],[\"段落或章节级别的主题信息需要一定的文本长度来表达\",{\"2\":{\"2522\":1}}],[\"段落或主题部分\",{\"2\":{\"1425\":1}}],[\"段落等\",{\"2\":{\"1379\":1,\"1561\":1}}],[\"段落样式等\",{\"2\":{\"1331\":1}}],[\"段落\",{\"2\":{\"575\":1,\"2393\":1}}],[\"既不过短导致上下文缺失\",{\"2\":{\"2543\":1}}],[\"既然只有少量的特征包含离群值\",{\"2\":{\"1982\":1}}],[\"既保留互信息的优势\",{\"2\":{\"564\":1}}],[\"既能减少资源消耗\",{\"2\":{\"408\":1}}],[\"笔记url\",{\"2\":{\"559\":1}}],[\"新生成的1个token\",{\"2\":{\"1782\":1}}],[\"新的奖励公式可以表示为\",{\"2\":{\"1676\":1}}],[\"新增tokens数量\",{\"2\":{\"1487\":1}}],[\"新增领域数据\",{\"2\":{\"558\":1}}],[\"新片段开始\",{\"2\":{\"1470\":1}}],[\"新闻标题分类\",{\"2\":{\"49\":1}}],[\"初步训练阶段\",{\"2\":{\"2282\":1}}],[\"初步切分\",{\"2\":{\"2141\":1}}],[\"初步的\",{\"0\":{\"1728\":1}}],[\"初次分块\",{\"2\":{\"1561\":1}}],[\"初期设置较大的\",{\"2\":{\"589\":1}}],[\"初期\",{\"2\":{\"558\":1}}],[\"初始时新旧策略相同\",{\"2\":{\"2569\":1}}],[\"初始损失不会特别高\",{\"2\":{\"2206\":1}}],[\"初始状态\",{\"2\":{\"1787\":1}}],[\"初始状态是prompt\",{\"2\":{\"1673\":1}}],[\"初始状态为prompt的token序列\",{\"2\":{\"1613\":1}}],[\"初始预训练使用4k\",{\"2\":{\"1305\":1}}],[\"初始预训练\",{\"2\":{\"535\":1,\"1267\":1}}],[\"初始数据爬取\",{\"2\":{\"532\":1}}],[\"初始词表不完整\",{\"2\":{\"498\":1}}],[\"初始词表质量对结果影响显著\",{\"2\":{\"419\":1}}],[\"初始loss总值\",{\"2\":{\"471\":1}}],[\"初始分词方法\",{\"2\":{\"444\":1}}],[\"初始语料库\",{\"0\":{\"443\":1}}],[\"初始阶段使用4k\",{\"2\":{\"1256\":1}}],[\"初始阶段模型参数未调整好时\",{\"2\":{\"192\":1}}],[\"初始阶段\",{\"2\":{\"183\":1}}],[\"初始化预训练参数\",{\"2\":{\"2115\":1}}],[\"初始化参数矩阵并分配秩\",{\"2\":{\"1938\":1}}],[\"初始化参数为正态分布\",{\"2\":{\"1011\":1}}],[\"初始化所有矩阵a和b为相同的随机权值\",{\"2\":{\"1923\":1}}],[\"初始化与种子数据\",{\"0\":{\"1867\":1}}],[\"初始化策略对比\",{\"0\":{\"2372\":1}}],[\"初始化策略对模型的训练动态有显著影响\",{\"2\":{\"2311\":1}}],[\"初始化策略模型与参考模型的logits\",{\"2\":{\"1761\":1}}],[\"初始化策略参数\",{\"2\":{\"789\":1}}],[\"初始化critic模型\",{\"2\":{\"1699\":1}}],[\"初始化或改进\",{\"2\":{\"1539\":1}}],[\"初始化权重时\",{\"2\":{\"1298\":1}}],[\"初始化一个大小为\",{\"2\":{\"1281\":1}}],[\"初始化word2vec模型\",{\"2\":{\"1111\":1}}],[\"初始化q\",{\"2\":{\"646\":1}}],[\"初始化q表格\",{\"2\":{\"646\":1,\"681\":1}}],[\"初始化大词表\",{\"2\":{\"393\":1}}],[\"初始化长度为k\",{\"2\":{\"47\":1}}],[\"初始化\",{\"0\":{\"14\":1},\"2\":{\"775\":1,\"1248\":1,\"1646\":1,\"2279\":1}}],[\"跳过当前权重更新\",{\"2\":{\"553\":1}}],[\"检验提纲是否符合某些标准\",{\"2\":{\"1820\":1}}],[\"检索到的上下文应尽可能少地包含无关信息\",{\"2\":{\"2582\":1}}],[\"检索到的上下文需要能够作为生成答案的理由\",{\"2\":{\"2566\":1}}],[\"检索后优化\",{\"2\":{\"2484\":1}}],[\"检索前优化\",{\"2\":{\"2484\":1}}],[\"检索前优化的目标是\",{\"2\":{\"1496\":1}}],[\"检索信息并将其插入到提示\",{\"2\":{\"2469\":1}}],[\"检索质量低\",{\"2\":{\"2466\":1}}],[\"检索和生成流程\",{\"2\":{\"2445\":1}}],[\"检索和生成质量\",{\"2\":{\"2366\":1}}],[\"检索相关文档片段\",{\"2\":{\"2420\":1}}],[\"检索\",{\"2\":{\"2365\":1,\"2366\":1,\"2420\":1}}],[\"检索结果的数量\",{\"2\":{\"2000\":1}}],[\"检索参数\",{\"0\":{\"1894\":1},\"1\":{\"1949\":1,\"2000\":1,\"2051\":1}}],[\"检索效率就会大大降低\",{\"2\":{\"1496\":1}}],[\"检索优化\",{\"0\":{\"1496\":1}}],[\"检索粒度的选择\",{\"0\":{\"1367\":1},\"1\":{\"1412\":1}}],[\"检索技术\",{\"2\":{\"1333\":1}}],[\"检索增强生成\",{\"2\":{\"1333\":4}}],[\"检索速度快\",{\"2\":{\"941\":1}}],[\"检查检索结果来自哪个文档等\",{\"2\":{\"2702\":1}}],[\"检查梯度回传是否正确\",{\"2\":{\"2607\":1}}],[\"检查梯度是否溢出\",{\"2\":{\"553\":1}}],[\"检查每个块的大小\",{\"2\":{\"2606\":1}}],[\"检查句子中是否包含低可信度的\",{\"2\":{\"2570\":1}}],[\"检查现有模型是否存在梯度消失问题\",{\"2\":{\"2551\":1}}],[\"检查显存使用情况\",{\"2\":{\"2377\":1}}],[\"检查并优化当前模型的显存使用情况\",{\"2\":{\"2360\":1}}],[\"检查训练代码而非数据难度\",{\"2\":{\"2206\":1}}],[\"检查块大小\",{\"2\":{\"2141\":1}}],[\"检查critic模型的初始化方法是否合理\",{\"2\":{\"1934\":1}}],[\"检查目标是否已合并\",{\"2\":{\"1871\":1}}],[\"检查是否启用了sagemaker多处理\",{\"2\":{\"1832\":1}}],[\"检查代码实现中的参数配置\",{\"2\":{\"2524\":1}}],[\"检查代码实现\",{\"2\":{\"1789\":1}}],[\"检查位置编码是否已全局共享\",{\"2\":{\"1141\":1}}],[\"检查相邻两次迭代的变化是否小于阈值\",{\"2\":{\"647\":1}}],[\"检查多个单元之间是否存在完全匹配或模糊匹配重复\",{\"2\":{\"644\":1}}],[\"检查溢出情况\",{\"2\":{\"589\":1}}],[\"检测并纠正潜在的语言混杂问题\",{\"2\":{\"2346\":1}}],[\"检测llm\",{\"2\":{\"1361\":1}}],[\"检测工业设备运行中的异常模式\",{\"2\":{\"39\":1}}],[\"检测与常规交易行为不同的交易\",{\"2\":{\"39\":1}}],[\"倍\",{\"2\":{\"553\":2,\"2369\":1}}],[\"名称\",{\"2\":{\"549\":1}}],[\"名称空间\",{\"0\":{\"10\":1}}],[\"登录\",{\"2\":{\"548\":1}}],[\"篇章级别过滤\",{\"2\":{\"548\":1}}],[\"价值模型往往会在长轨迹序列中产生偏差\",{\"2\":{\"2107\":1}}],[\"价值头层是一个简单的线性层\",{\"2\":{\"1591\":1}}],[\"价值\",{\"2\":{\"647\":1}}],[\"价值网络优化器\",{\"2\":{\"619\":1}}],[\"价值网络\",{\"2\":{\"619\":1}}],[\"价值迭代的方法\",{\"2\":{\"656\":1}}],[\"价值迭代的核心公式是\",{\"2\":{\"647\":1}}],[\"价值迭代能否与其他强化学习算法结合使用以提高性能\",{\"2\":{\"647\":1}}],[\"价值迭代直接利用最优贝尔曼方程\",{\"2\":{\"647\":1}}],[\"价值迭代直接利用最优贝尔曼方程进行更新\",{\"2\":{\"612\":1}}],[\"价值迭代一共进行\",{\"2\":{\"647\":1}}],[\"价值迭代公式\",{\"2\":{\"647\":1}}],[\"价值迭代\",{\"2\":{\"545\":1,\"588\":1}}],[\"价值迭代算法在更大规模问题上的应用将更加广泛\",{\"2\":{\"647\":1}}],[\"价值迭代算法是一种用于求解马尔可夫决策过程\",{\"2\":{\"612\":1}}],[\"价值迭代算法\",{\"0\":{\"512\":1},\"1\":{\"545\":1,\"579\":1,\"612\":1,\"647\":1},\"2\":{\"151\":1,\"647\":1}}],[\"价值迭代算法|价值迭代算法\",{\"2\":{\"5\":1}}],[\"价值函数简化为\",{\"2\":{\"2306\":1}}],[\"价值函数定义为回报\",{\"2\":{\"2306\":1}}],[\"价值函数定义\",{\"2\":{\"2306\":1}}],[\"价值函数的计算公式\",{\"2\":{\"656\":1}}],[\"价值函数\",{\"2\":{\"543\":1,\"659\":1,\"1497\":1}}],[\"添加辅助损失来稳定softmax标准化\",{\"2\":{\"1298\":1}}],[\"添加特殊标记\",{\"2\":{\"542\":1}}],[\"添加全连接分类层\",{\"2\":{\"49\":1}}],[\"序贯决策类似于人生中的重要选择\",{\"2\":{\"572\":1}}],[\"序贯决策\",{\"2\":{\"539\":1}}],[\"序列的顺序对模型的理解至关重要\",{\"2\":{\"1231\":1}}],[\"序列截断需满足t−k≥1t\",{\"2\":{\"1227\":1}}],[\"序列级辅助损失补偿\",{\"2\":{\"1038\":1}}],[\"序列处理与状态信息更新\",{\"2\":{\"778\":1}}],[\"序列\",{\"2\":{\"775\":1}}],[\"序列可以看成进程\",{\"2\":{\"750\":1}}],[\"序列模型\",{\"2\":{\"230\":1}}],[\"序列长度\",{\"2\":{\"190\":1,\"1483\":1}}],[\"序列数据处理\",{\"2\":{\"71\":1}}],[\"覆盖广泛\",{\"2\":{\"535\":1}}],[\"覆盖从理论到落地的完整链路\",{\"2\":{\"65\":1}}],[\"网络等\",{\"2\":{\"2317\":1}}],[\"网络入侵检测\",{\"2\":{\"39\":1}}],[\"网页智能和工具智能等\",{\"2\":{\"1453\":1}}],[\"网页数据\",{\"2\":{\"535\":1}}],[\"网购和浏览网页属于web类型\",{\"2\":{\"1217\":1}}],[\"企业特定领域的专属语料\",{\"2\":{\"535\":1}}],[\"企业自有业务数据\",{\"2\":{\"535\":1}}],[\"企业级模型托管与自动化训练流水线\",{\"2\":{\"65\":1}}],[\"涵盖中华文化相关内容\",{\"2\":{\"2184\":1}}],[\"涵盖多领域知识\",{\"2\":{\"535\":1}}],[\"涵盖任务\",{\"2\":{\"369\":1}}],[\"电子书与教育资料\",{\"2\":{\"535\":1}}],[\"电商客服自动回复\",{\"2\":{\"49\":1}}],[\"至少\",{\"2\":{\"535\":1}}],[\"约束强度系数\",{\"2\":{\"1552\":1}}],[\"约15\",{\"2\":{\"997\":1}}],[\"约10922\",{\"2\":{\"220\":1}}],[\"约\",{\"2\":{\"535\":1}}],[\"变回到\",{\"2\":{\"2579\":1}}],[\"变成\",{\"2\":{\"2579\":1}}],[\"变形后目标\",{\"2\":{\"1657\":1}}],[\"变化情况\",{\"2\":{\"533\":1}}],[\"变量和基本类型\",{\"2\":{\"16\":2}}],[\"遗忘\",{\"2\":{\"533\":1}}],[\"召回候选集\",{\"2\":{\"1075\":1}}],[\"召回候选示例集\",{\"2\":{\"1075\":1}}],[\"召回相似数据\",{\"2\":{\"532\":1}}],[\"召回率\",{\"2\":{\"91\":1,\"2354\":1}}],[\"百科数据及网页资料\",{\"2\":{\"532\":1}}],[\"帖子\",{\"2\":{\"526\":1}}],[\"帖子的数量控制\",{\"2\":{\"526\":1}}],[\"默认值为\",{\"2\":{\"2039\":1}}],[\"默认使用的pdf解析算法是\",{\"2\":{\"1716\":1}}],[\"默认开启\",{\"2\":{\"526\":1}}],[\"默认不开启\",{\"2\":{\"526\":2}}],[\"爬取尽可能多的互联网开源书籍\",{\"2\":{\"532\":1}}],[\"爬取一级评论的数量控制\",{\"2\":{\"526\":1}}],[\"爬取视频\",{\"2\":{\"526\":1}}],[\"爬虫主要分为以下三类\",{\"2\":{\"494\":1}}],[\"爬虫分类与实现方式\",{\"0\":{\"494\":1}}],[\"爬虫配置的基本建议与代码示例\",{\"2\":{\"411\":1}}],[\"爬虫的分类及具体实现方式\",{\"2\":{\"411\":1}}],[\"爬虫技术\",{\"2\":{\"384\":1}}],[\"⚙\",{\"0\":{\"526\":1}}],[\"虽然减少的显存与流水线并行度成正相关\",{\"2\":{\"2708\":1}}],[\"虽然空泡时间和gpipe一致\",{\"2\":{\"2694\":1}}],[\"虽然蒸馏策略既经济又有效\",{\"2\":{\"2642\":1}}],[\"虽然有了全局的\",{\"2\":{\"2505\":1}}],[\"虽然有这么多缺点\",{\"2\":{\"2118\":1}}],[\"虽然每层只能看到部分前置序列\",{\"2\":{\"2260\":1}}],[\"虽然具备一定智能性\",{\"2\":{\"1728\":1}}],[\"虽然这种方法在训练和推理阶段增加了成本\",{\"2\":{\"1668\":1}}],[\"虽然上述框架能够简化基础任务\",{\"2\":{\"1392\":1}}],[\"虽然功能强大\",{\"2\":{\"1378\":1}}],[\"虽然\",{\"2\":{\"1260\":1,\"2379\":1}}],[\"虽然整体参数量有所减少\",{\"2\":{\"1069\":1}}],[\"虽然基于特征的知识转移为学生模型提供了更多信息\",{\"2\":{\"845\":1}}],[\"虽然大模型在许多任务中表现出色\",{\"2\":{\"692\":1}}],[\"虽然td方法牺牲了蒙特卡洛方法的无偏估计\",{\"2\":{\"608\":1}}],[\"虽然目前尚无研究证明loss\",{\"2\":{\"525\":1}}],[\"虽然下一个token生成时可以复用每个矩阵\",{\"2\":{\"429\":1}}],[\"毛刺现象\",{\"2\":{\"525\":1}}],[\"祖先追溯挑战\",{\"2\":{\"524\":1}}],[\"观察训练过程中的变化\",{\"2\":{\"2551\":1}}],[\"观察下图中黄色的离群值\",{\"2\":{\"1982\":1}}],[\"观察性能变化\",{\"2\":{\"1555\":1}}],[\"观察性能提升效果\",{\"2\":{\"698\":1}}],[\"观察显存变化\",{\"2\":{\"730\":1}}],[\"观察对小模型性能的影响\",{\"2\":{\"599\":1}}],[\"观察损失函数变化\",{\"2\":{\"2206\":1}}],[\"观察损失\",{\"2\":{\"533\":1}}],[\"观察趋势\",{\"2\":{\"516\":1}}],[\"观察其对效率的影响\",{\"2\":{\"2093\":1}}],[\"观察其对学习效果的影响\",{\"2\":{\"912\":1}}],[\"观察其对图像和文本融合效果的影响\",{\"2\":{\"414\":1}}],[\"观察其紧凑性与共享能力\",{\"2\":{\"442\":1}}],[\"逻辑依据\",{\"2\":{\"1766\":1}}],[\"逻辑推理\",{\"2\":{\"707\":1}}],[\"逻辑和代码\",{\"2\":{\"651\":1}}],[\"逻辑\",{\"2\":{\"516\":1}}],[\"逻辑回归虽然简单\",{\"2\":{\"185\":1}}],[\"逻辑回归首先像线性回归一样\",{\"2\":{\"76\":1}}],[\"逻辑回归的目标是找到一组权重\",{\"2\":{\"123\":1}}],[\"逻辑回归的全流程可以简单概括为\",{\"2\":{\"185\":1}}],[\"逻辑回归的全流程\",{\"0\":{\"58\":1},\"1\":{\"66\":1,\"76\":1,\"90\":1,\"105\":1,\"123\":1,\"143\":1}}],[\"逻辑回归的核心思想是\",{\"2\":{\"51\":1}}],[\"逻辑回归的核心思想\",{\"0\":{\"51\":1}}],[\"逻辑回归是用来解决分类问题的\",{\"2\":{\"42\":1}}],[\"逻辑回归\",{\"2\":{\"39\":1}}],[\"测量\",{\"0\":{\"516\":1}}],[\"测试系统能否正确解析用户意图并调用合适的功能\",{\"2\":{\"2384\":1}}],[\"测试vera在实际任务中的性能表现\",{\"2\":{\"2075\":1}}],[\"测试做准备\",{\"2\":{\"1436\":1}}],[\"测试集合\",{\"2\":{\"1414\":1}}],[\"测试集应从训练集移除相似数据\",{\"2\":{\"575\":1}}],[\"测试场景\",{\"2\":{\"1324\":1}}],[\"测试gqa在不同规模模型中的推理成本优化效果\",{\"2\":{\"1287\":1}}],[\"测试设备限制路由机制在不同硬件环境下的表现\",{\"2\":{\"1271\":1}}],[\"测试word2vec在不同领域\",{\"2\":{\"1261\":1}}],[\"测试多任务预训练策略对不同数据集的影响\",{\"2\":{\"1239\":1}}],[\"测试\",{\"2\":{\"1025\":1,\"1629\":1,\"1878\":1,\"2590\":1}}],[\"测试其在小规模数据集上的效果\",{\"2\":{\"738\":1}}],[\"测试其效果\",{\"2\":{\"388\":1}}],[\"测试simbert在不同领域文本中的表现\",{\"2\":{\"666\":1}}],[\"测试现有爬虫配置参数\",{\"2\":{\"663\":1}}],[\"测试与调优\",{\"2\":{\"560\":1}}],[\"测试与优化\",{\"2\":{\"62\":1,\"2543\":1}}],[\"测试模型\",{\"2\":{\"1208\":1}}],[\"测试模型的综合分析能力\",{\"2\":{\"524\":1}}],[\"测试模型困惑度并根据需求微调\",{\"2\":{\"291\":1}}],[\"测试位置内插法对不同语言模型的适用性\",{\"2\":{\"387\":1}}],[\"测试核函数形式在其他领域\",{\"2\":{\"327\":1}}],[\"测试yarn方法在不同上下文窗口下的实际效果\",{\"2\":{\"322\":1}}],[\"测试性能提升情况\",{\"2\":{\"303\":1}}],[\"测试不同熵值控制策略对模型性能的影响\",{\"2\":{\"2629\":1,\"2674\":1}}],[\"测试不同对话长度下的模型表现\",{\"2\":{\"2464\":1}}],[\"测试不同门控机制对微调稳定性的影响\",{\"2\":{\"1953\":1}}],[\"测试不同的\",{\"2\":{\"1907\":1}}],[\"测试不同压缩率对模型性能的影响\",{\"2\":{\"1686\":1}}],[\"测试不同gpu配置对训练效率的影响\",{\"2\":{\"1651\":1}}],[\"测试不同显卡配置对预训练效率的影响\",{\"2\":{\"1556\":1}}],[\"测试不同优化器对大规模模型训练的效果\",{\"2\":{\"1527\":1}}],[\"测试不同词表大小对加载速度的具体影响\",{\"2\":{\"1339\":1}}],[\"测试不同参数设置下的ppo性能\",{\"2\":{\"1274\":1}}],[\"测试不同梯度裁剪阈值对模型性能的作用\",{\"2\":{\"730\":1}}],[\"测试不同阈值对收敛速度的影响\",{\"2\":{\"647\":1}}],[\"测试不同频率范围对模型性能的影响\",{\"2\":{\"383\":1}}],[\"测试不同上下文长度对模型性能的影响\",{\"2\":{\"288\":1}}],[\"测试不同缩放因子对梯度稳定性的影响\",{\"2\":{\"284\":1}}],[\"测试不同归一化方式在transformer架构中的性能表现\",{\"2\":{\"282\":1}}],[\"测试linear\",{\"2\":{\"281\":1}}],[\"测试dca的应用潜力\",{\"2\":{\"196\":1}}],[\"防止训练不稳定\",{\"0\":{\"1974\":1}}],[\"防止关注过远内容\",{\"2\":{\"1255\":1}}],[\"防止过拟合\",{\"2\":{\"1162\":1}}],[\"防止偏序关系\",{\"2\":{\"1068\":1}}],[\"防止策略偏离\",{\"2\":{\"514\":1}}],[\"防止分母为零的小值\",{\"2\":{\"190\":1}}],[\"动手学强化学习\",{\"2\":{\"776\":1}}],[\"动手实践智能阅读模型的构建\",{\"2\":{\"511\":1}}],[\"动图演示\",{\"2\":{\"750\":4}}],[\"动量损失放大\",{\"0\":{\"589\":1}}],[\"动作对的价值函数\",{\"2\":{\"2430\":1}}],[\"动作是输出\",{\"2\":{\"2306\":1}}],[\"动作是response\",{\"2\":{\"1673\":1}}],[\"动作空间为整个词表\",{\"2\":{\"1613\":1}}],[\"动作空间即为词表\",{\"2\":{\"581\":1}}],[\"动作集合\",{\"2\":{\"676\":1}}],[\"动作价值函数\",{\"0\":{\"779\":1},\"2\":{\"659\":1,\"732\":1,\"779\":1}}],[\"动作后的回报\",{\"2\":{\"654\":1}}],[\"动作后的回报等\",{\"2\":{\"518\":1}}],[\"动作个数\",{\"2\":{\"646\":1}}],[\"动作作用于环境\",{\"2\":{\"639\":1}}],[\"动作决策\",{\"2\":{\"639\":1}}],[\"动作\",{\"2\":{\"581\":1,\"655\":6,\"1613\":1,\"1787\":1}}],[\"动作的好坏\",{\"2\":{\"518\":1}}],[\"动态采样不仅能提高训练的稳定性\",{\"2\":{\"2541\":1}}],[\"动态采样的操作步骤\",{\"0\":{\"2519\":1}}],[\"动态采样是一种在机器学习训练过程中\",{\"2\":{\"2507\":1}}],[\"动态采样\",{\"2\":{\"2494\":1}}],[\"动态采样技术在机器学习中的应用与挑战\",{\"0\":{\"2494\":1},\"1\":{\"2507\":1,\"2519\":1,\"2530\":1,\"2541\":1,\"2551\":1}}],[\"动态采样策略优化\",{\"2\":{\"1884\":1,\"2143\":1}}],[\"动态值分析\",{\"0\":{\"2231\":1}}],[\"动态生成新的工具或方法\",{\"2\":{\"1904\":1}}],[\"动态秩分配\",{\"0\":{\"1764\":1}}],[\"动态缩放机制\",{\"0\":{\"1809\":1}}],[\"动态缩放\",{\"2\":{\"1638\":1}}],[\"动态适配\",{\"2\":{\"1599\":1}}],[\"动态适应\",{\"0\":{\"602\":1}}],[\"动态控制决策和工具使用\",{\"2\":{\"1316\":1}}],[\"动态ntk插值\",{\"2\":{\"1255\":1}}],[\"动态负载均衡\",{\"2\":{\"998\":1}}],[\"动态掩码策略\",{\"2\":{\"933\":1}}],[\"动态路由\",{\"2\":{\"920\":1}}],[\"动态决策任务更适合强化学习\",{\"2\":{\"858\":1}}],[\"动态\",{\"2\":{\"657\":1,\"694\":1}}],[\"动态调整提示词以适应场景需求\",{\"0\":{\"2693\":1}}],[\"动态调整词表大小和压缩率的技术\",{\"2\":{\"1742\":1}}],[\"动态调整正则化系数\",{\"2\":{\"1626\":1}}],[\"动态调整模型与数据比例\",{\"2\":{\"1464\":1}}],[\"动态调整采样参数\",{\"2\":{\"665\":1}}],[\"动态调整\",{\"2\":{\"589\":1}}],[\"动态调整bbpe的分词策略\",{\"2\":{\"469\":1}}],[\"动态选择注意力区域是未来研究方向\",{\"2\":{\"257\":1}}],[\"动态规划将在更多实际应用中得到广泛使用\",{\"2\":{\"793\":1}}],[\"动态规划如何在非静态环境中有效应用\",{\"2\":{\"727\":1}}],[\"动态规划的基本思想\",{\"2\":{\"656\":1}}],[\"动态规划是一种将复杂问题分解为更小子问题的方法\",{\"2\":{\"621\":1}}],[\"动态规划\",{\"0\":{\"50\":1},\"2\":{\"540\":1,\"545\":1,\"588\":1}}],[\"凑合能用\",{\"2\":{\"507\":1}}],[\"θmax​es∼νβ​\",{\"2\":{\"590\":1}}],[\"θ\",{\"2\":{\"503\":2,\"586\":2,\"723\":2,\"757\":2,\"789\":1,\"1093\":2,\"1628\":2,\"2357\":2,\"2485\":2,\"2577\":2}}],[\"减小了每一步的执行时间\",{\"2\":{\"2697\":1}}],[\"减小学习率\",{\"2\":{\"593\":1}}],[\"减轻模型的计算负担\",{\"2\":{\"2105\":1}}],[\"减轻过拟合问题\",{\"2\":{\"1932\":1}}],[\"减弱其影响\",{\"2\":{\"2087\":1}}],[\"减弱远距离token的衰减效应\",{\"2\":{\"502\":1}}],[\"减去一个正则化系数\",{\"2\":{\"1681\":1}}],[\"减少训练时间和资源消耗\",{\"2\":{\"2692\":1}}],[\"减少训练开销\",{\"2\":{\"57\":1}}],[\"减少主观性和幻觉的提示词策略\",{\"0\":{\"2690\":1}}],[\"减少可供输入的大模型的文本块数量\",{\"2\":{\"2483\":1}}],[\"减少cpu的计算量\",{\"2\":{\"2422\":1}}],[\"减少不必要的显存占用\",{\"2\":{\"2377\":1}}],[\"减少不必要的资源浪费\",{\"2\":{\"2316\":1}}],[\"减少不必要的数据抓取\",{\"2\":{\"559\":1}}],[\"减少大模型微调所需的资源消耗\",{\"2\":{\"2207\":1}}],[\"减少这些访问可以提高计算效率\",{\"2\":{\"2110\":1}}],[\"减少了为每个任务训练独立模型的需求\",{\"2\":{\"2179\":1}}],[\"减少了需微调的参数量级\",{\"2\":{\"1967\":1}}],[\"减少了资源消耗\",{\"2\":{\"1853\":1}}],[\"减少了策略评估与策略更新的交替过程\",{\"2\":{\"647\":1}}],[\"减少上下文长度\",{\"2\":{\"1740\":1}}],[\"减少对hbm的读写次数\",{\"2\":{\"2077\":1}}],[\"减少对模型整体结构的影响\",{\"2\":{\"1722\":1}}],[\"减少对好答案的影响\",{\"2\":{\"1626\":1}}],[\"减少对标注数据的依赖\",{\"2\":{\"503\":1}}],[\"减少人工调整成本\",{\"2\":{\"1526\":1}}],[\"减少人工干预\",{\"2\":{\"327\":1}}],[\"减少昂贵的人工标注\",{\"2\":{\"1008\":1}}],[\"减少冗余信息\",{\"2\":{\"929\":1}}],[\"减少计算量\",{\"2\":{\"983\":1,\"1023\":1}}],[\"减少计算复杂度\",{\"2\":{\"918\":1}}],[\"减少计算压力\",{\"2\":{\"567\":1}}],[\"减少显存占用并提升计算效率\",{\"2\":{\"433\":1}}],[\"减少过拟合风险\",{\"2\":{\"1960\":1}}],[\"减少过拟合\",{\"2\":{\"307\":1}}],[\"减少插值压力\",{\"2\":{\"221\":1}}],[\"减少信息丢失\",{\"2\":{\"211\":1}}],[\"减少kv缓存的存储需求\",{\"2\":{\"170\":1}}],[\"减少存储和计算需求\",{\"2\":{\"39\":1}}],[\"减少冲突的机会\",{\"2\":{\"22\":1}}],[\"减少代码重复\",{\"2\":{\"12\":1}}],[\"垂域数据扩充流程\",{\"0\":{\"500\":1},\"1\":{\"532\":1}}],[\"删除重复文档或冗余信息\",{\"2\":{\"1331\":1}}],[\"删除由纯大写字符或纯数字组成的句子\",{\"2\":{\"548\":1}}],[\"删除单字符子词\",{\"2\":{\"498\":1}}],[\"删除多余空格\",{\"2\":{\"480\":1}}],[\"亿参数的\",{\"2\":{\"2281\":1,\"2313\":1}}],[\"亿参数\",{\"2\":{\"495\":1}}],[\"定制化修改难度增加\",{\"2\":{\"1392\":1}}],[\"定长子串中元音的最大数目\",{\"0\":{\"783\":1}}],[\"定期更新显存管理策略\",{\"2\":{\"2377\":1}}],[\"定期聚合它们的梯度\",{\"2\":{\"2374\":1}}],[\"定期评估模型在不同\",{\"2\":{\"2401\":1}}],[\"定期评估在线方法的反馈机制以确保模型更新的有效性\",{\"2\":{\"1839\":1}}],[\"定期评估和精简子词表\",{\"2\":{\"530\":1}}],[\"定期检查并更新相关内容\",{\"2\":{\"1558\":1}}],[\"定期检查低频单词的过滤阈值\",{\"2\":{\"1159\":1}}],[\"定期检查训练过程中各类数据的loss趋势\",{\"2\":{\"662\":1}}],[\"定向爬取时需注意目标网站的反爬机制\",{\"2\":{\"494\":1}}],[\"定向网站爬取\",{\"2\":{\"494\":1}}],[\"定义并初始化低秩矩阵\",{\"2\":{\"2115\":1}}],[\"定义了一组分割符列表\",{\"2\":{\"2091\":1}}],[\"定义了相邻文本块之间的重叠长度\",{\"2\":{\"1987\":1}}],[\"定义了文本块的最大长度\",{\"2\":{\"1937\":1}}],[\"定义最优策略\",{\"0\":{\"1889\":1}}],[\"定义切分参数\",{\"2\":{\"1823\":1}}],[\"定义onehot编码函数\",{\"2\":{\"1025\":1}}],[\"定义问题\",{\"2\":{\"844\":1}}],[\"定义mdp中的agent\",{\"2\":{\"649\":1}}],[\"定义门控网络的类型\",{\"2\":{\"560\":1}}],[\"定义一个embedding层\",{\"2\":{\"996\":1}}],[\"定义一个normalizer\",{\"2\":{\"480\":1}}],[\"定义一个名为\",{\"2\":{\"10\":1}}],[\"定义以及历史发展\",{\"0\":{\"1136\":1},\"1\":{\"1188\":1,\"1238\":1,\"1289\":1,\"1336\":1,\"1382\":1,\"1429\":1,\"1474\":1,\"1518\":1,\"1567\":1},\"2\":{\"237\":1}}],[\"定义\",{\"0\":{\"1702\":1,\"1935\":1,\"2037\":1},\"2\":{\"12\":2,\"15\":1}}],[\"定义命名空间\",{\"2\":{\"10\":1}}],[\"定义另一个名为\",{\"2\":{\"10\":1}}],[\"合成\",{\"2\":{\"2453\":1}}],[\"合成数据的生成方法需要不断创新以提升模型表现\",{\"2\":{\"2352\":1}}],[\"合成数据的质量直接影响模型的表现\",{\"2\":{\"2220\":1}}],[\"合成数据技术也会更加成熟\",{\"2\":{\"2321\":1}}],[\"合成数据通过多种方式生成\",{\"2\":{\"2220\":1}}],[\"合成数据\",{\"2\":{\"2134\":1}}],[\"合适的上文能够在固定lm的情况下引导生成下文\",{\"2\":{\"1922\":1}}],[\"合法性验证\",{\"2\":{\"1889\":1}}],[\"合理划分文档是提升检索效率的重要环节\",{\"2\":{\"1421\":1}}],[\"合理选择和组织示例顺序能够显著提升模型推断时的效果和效率\",{\"2\":{\"1413\":1}}],[\"合理的分块方式不仅能够提高模型的处理效率\",{\"2\":{\"1334\":1}}],[\"合理利用碎片内存\",{\"2\":{\"750\":1}}],[\"合理设置并发数和内容抓取量\",{\"2\":{\"526\":1}}],[\"合理设置并发数量及请求间隔\",{\"2\":{\"494\":1}}],[\"合理管理梯度存储可以有效控制显存开销\",{\"2\":{\"488\":1}}],[\"合并额外数据扩展数据集\",{\"2\":{\"2504\":1}}],[\"合并多轮对话样本\",{\"2\":{\"2361\":1}}],[\"合并频率最高的字符对\",{\"0\":{\"497\":1}}],[\"合并依据\",{\"2\":{\"420\":1}}],[\"合并\",{\"2\":{\"420\":1,\"497\":1}}],[\"合并零之间的节点\",{\"0\":{\"48\":1}}],[\"广义优势估计\",{\"2\":{\"505\":1,\"1645\":1}}],[\"广告等无关内容\",{\"2\":{\"485\":1}}],[\"广泛应用于自然语言处理任务中\",{\"2\":{\"308\":1}}],[\"广泛应用于自然语言处理\",{\"2\":{\"93\":1}}],[\"阅读\",{\"2\":{\"2366\":1}}],[\"阅读微软\",{\"2\":{\"1493\":1}}],[\"阅读相关论文\",{\"2\":{\"481\":1,\"1555\":1}}],[\"阅读deepseekv2论文了解更多技术细节\",{\"2\":{\"353\":1}}],[\"ü\",{\"2\":{\"480\":1}}],[\"则较小的分块可能更合适\",{\"2\":{\"2655\":1}}],[\"则这里的计算量同样为\",{\"2\":{\"2643\":1}}],[\"则一次allreduce产生的总通信量为\",{\"2\":{\"2621\":1}}],[\"则进一步根据空格\",{\"2\":{\"2606\":1}}],[\"则进行检索\",{\"2\":{\"2570\":1}}],[\"则对其使用单换行符\",{\"2\":{\"2606\":1}}],[\"则视为正确答案\",{\"2\":{\"2458\":1}}],[\"则更适合采用\",{\"2\":{\"2325\":1}}],[\"则共需要存储空间为\",{\"2\":{\"2161\":1}}],[\"则使用下一个分割符\",{\"2\":{\"2141\":1}}],[\"则通过与\",{\"2\":{\"2129\":1}}],[\"则通过残差连接直接送至下一层\",{\"2\":{\"1119\":1}}],[\"则是把量化问题视作优化问题\",{\"2\":{\"2085\":1}}],[\"则初始化为全0\",{\"2\":{\"2062\":1}}],[\"则在\",{\"2\":{\"1940\":1}}],[\"则着重降低坏答案的采样概率\",{\"2\":{\"1857\":1}}],[\"则减去正则化系数\",{\"2\":{\"1857\":1}}],[\"则prefill相当于按batchsize=\",{\"2\":{\"1843\":1}}],[\"则倒数排名较小\",{\"2\":{\"1698\":1}}],[\"则分数为\",{\"2\":{\"1644\":1}}],[\"则将它们合并为一个分块\",{\"2\":{\"1470\":1}}],[\"则可能需要更大的分块来确保足够的信息量支持答案生成\",{\"2\":{\"2655\":1}}],[\"则可能导致上下文信息不足\",{\"2\":{\"2197\":1}}],[\"则可视化低代码平台可能更适合\",{\"2\":{\"1392\":1}}],[\"则可以剔除其中一个\",{\"2\":{\"949\":1}}],[\"则无法直接处理超过\",{\"2\":{\"1281\":1}}],[\"则调整权重值为1\",{\"2\":{\"1119\":1}}],[\"则采用\",{\"2\":{\"1092\":1}}],[\"则直接丢弃整个单元\",{\"2\":{\"644\":1}}],[\"则\",{\"2\":{\"622\":3,\"1756\":1,\"2286\":3}}],[\"则需尽可能多以提升推理能力\",{\"2\":{\"474\":1}}],[\"则负责让每个\",{\"2\":{\"162\":1}}],[\"此过程帮助防止早期训练不稳定\",{\"2\":{\"2474\":1}}],[\"此内容基于openrlhf框架的sft训练与评估文档\",{\"2\":{\"2391\":1}}],[\"此公式帮助我们快速了解推理阶段的显存需求\",{\"2\":{\"2023\":1}}],[\"此类智能体通常独立完成目标\",{\"2\":{\"1241\":1}}],[\"此改动还消除了二维编码的需要\",{\"2\":{\"1006\":1}}],[\"此时通讯量为nnn\",{\"2\":{\"2676\":1}}],[\"此时的通讯量为\",{\"2\":{\"2670\":1}}],[\"此时每个\",{\"2\":{\"2636\":1}}],[\"此时应重点降低坏答案的采样概率\",{\"2\":{\"1681\":1}}],[\"此时可以直接利用\",{\"2\":{\"1663\":1}}],[\"此时\",{\"2\":{\"949\":1,\"1673\":1,\"1848\":1}}],[\"此时物理块block1只和a2的逻辑块block1映射\",{\"2\":{\"846\":1}}],[\"此时元音字母个数\",{\"2\":{\"783\":1}}],[\"此时元音字母个数+1\",{\"2\":{\"783\":1}}],[\"此方法通过消融实验验证\",{\"2\":{\"1974\":1}}],[\"此方法通过对比阈值相似度\",{\"2\":{\"473\":1}}],[\"此方法对于不同模型结构需要构造不同的prefix\",{\"2\":{\"1745\":1}}],[\"此方法的训练速度较快\",{\"2\":{\"1667\":1}}],[\"此方法需要模型亲自输出答案\",{\"2\":{\"1614\":1}}],[\"此方法利用了人类更容易进行比较的特性\",{\"2\":{\"1491\":1}}],[\"此方法不仅增加了模型的泛化能力\",{\"2\":{\"1142\":1}}],[\"此方法直接利用大语言模型\",{\"2\":{\"1032\":1}}],[\"此方法特别适用于已知环境动态的情况\",{\"2\":{\"656\":1}}],[\"此算法不仅能用q值函数指导策略更新\",{\"2\":{\"518\":1}}],[\"此外激活值和权重可以选择不同的粒度进行量化\",{\"2\":{\"1022\":1}}],[\"此外\",{\"2\":{\"411\":1,\"456\":1,\"633\":1,\"701\":1,\"728\":1,\"931\":1,\"934\":1,\"1019\":1,\"1072\":1,\"1143\":1,\"1268\":1,\"1559\":1,\"1578\":1,\"1598\":1,\"1663\":1,\"1664\":1,\"2011\":1,\"2081\":1,\"2085\":1,\"2181\":1,\"2194\":1,\"2370\":1,\"2503\":1,\"2693\":1}}],[\"频繁的通信限制了两个通信阶段之间的计算量\",{\"2\":{\"2706\":1}}],[\"频率\",{\"2\":{\"1436\":1}}],[\"频率越高的位置编码对结果影响越大\",{\"2\":{\"1296\":1}}],[\"频率设置需足够低\",{\"2\":{\"287\":1}}],[\"频次\",{\"2\":{\"470\":1,\"497\":1}}],[\"子问题逐一解决后再合并为完整答案\",{\"2\":{\"2554\":1}}],[\"子问题查询引擎在探索每个子查询时可能会缺乏深度\",{\"2\":{\"2335\":1}}],[\"子任务由中心\",{\"2\":{\"2139\":1}}],[\"子任务是预定义的\",{\"2\":{\"2139\":1}}],[\"子任务可以并行执行以提高速度\",{\"2\":{\"2037\":1}}],[\"子目标分解\",{\"0\":{\"1330\":1},\"1\":{\"1375\":1,\"1420\":1}}],[\"子层之后\",{\"2\":{\"467\":1}}],[\"子词ug对loss影响\",{\"2\":{\"471\":1}}],[\"子词ug的使用频率\",{\"2\":{\"471\":1}}],[\"子词间关联性强\",{\"2\":{\"434\":1}}],[\"子词优化\",{\"2\":{\"320\":1}}],[\"子词编码\",{\"2\":{\"297\":1}}],[\"利用多头注意力固有的并行特性\",{\"2\":{\"2631\":1}}],[\"利用多个领域的知识\",{\"2\":{\"1979\":1}}],[\"利用少样本学习\",{\"2\":{\"2546\":1}}],[\"利用强大模型进行数据合成可以显著提升生成效果\",{\"2\":{\"2428\":1}}],[\"利用强大模型生成更多问题\",{\"2\":{\"2168\":1}}],[\"利用标题区块的高度来判断哪些是一级标题\",{\"2\":{\"2235\":1}}],[\"利用分析工具提取有价值的信息\",{\"2\":{\"2220\":1}}],[\"利用grpo进行尝试\",{\"2\":{\"2053\":1}}],[\"利用gpt\",{\"2\":{\"465\":1}}],[\"利用z\",{\"2\":{\"2046\":1}}],[\"利用高速的sram进行计算\",{\"2\":{\"1810\":1}}],[\"利用人类偏好进行奖励函数优化是一种创新的方法\",{\"2\":{\"1693\":1}}],[\"利用文档内部结构进行分块有一个重要的前提\",{\"2\":{\"1469\":1}}],[\"利用文档内部结构进行分块\",{\"0\":{\"1379\":1},\"1\":{\"1424\":1,\"1469\":1}}],[\"利用纯粹的强化学习方法\",{\"2\":{\"1342\":1}}],[\"利用即时反馈的奖励模型不断改进性能\",{\"2\":{\"1230\":1}}],[\"利用llms将state与当前action构成的新demonstrations\",{\"2\":{\"1222\":1}}],[\"利用该数据集微调学生语言模型\",{\"2\":{\"1124\":1}}],[\"利用c4语料库进行大规模数据训练\",{\"2\":{\"1107\":1}}],[\"利用critic计算优势函数aπθk\",{\"2\":{\"695\":1}}],[\"利用bm25或sbert筛选候选示例集\",{\"2\":{\"1075\":1}}],[\"利用目标llm自生成的大规模负样本进行rlhf对齐\",{\"2\":{\"1008\":1}}],[\"利用类别频率构建霍夫曼树\",{\"2\":{\"980\":1}}],[\"利用样本在教师模型上的特征表示的概率分布\",{\"2\":{\"880\":1}}],[\"利用率\",{\"2\":{\"813\":1,\"2402\":1}}],[\"利用虚拟内存的思想\",{\"2\":{\"750\":1}}],[\"利用点落在圆内与正方形内的比例来估算圆的面积\",{\"2\":{\"747\":1}}],[\"利用蒙特卡洛方法估计q值\",{\"2\":{\"652\":1}}],[\"利用这个最优值来提取最优策略\",{\"2\":{\"612\":1}}],[\"利用启发式规则进行数据清洗\",{\"2\":{\"548\":1}}],[\"利用\",{\"2\":{\"533\":1,\"1224\":1,\"1991\":1}}],[\"利用动态调整机制提升生成效果\",{\"2\":{\"481\":1}}],[\"利用所有可能的分词结果\",{\"2\":{\"419\":1}}],[\"监控语言输出\",{\"2\":{\"2346\":1}}],[\"监控损失趋势\",{\"2\":{\"2206\":1}}],[\"监控性能变化\",{\"2\":{\"2034\":1}}],[\"监控特定token或句子的概率变化\",{\"2\":{\"800\":1}}],[\"监控概率值随预训练的变化\",{\"2\":{\"626\":1}}],[\"监控\",{\"0\":{\"525\":1}}],[\"监控和优化是提高模型性能的关键\",{\"2\":{\"464\":1}}],[\"监督微调\",{\"2\":{\"934\":1,\"1101\":1,\"1150\":1,\"2177\":1,\"2180\":1}}],[\"监督微调与预训练的区别\",{\"0\":{\"1056\":1},\"1\":{\"1101\":1,\"1150\":1,\"1199\":1,\"1249\":1,\"1299\":1,\"1346\":1,\"1391\":1,\"1438\":1,\"1484\":1,\"1528\":1},\"2\":{\"131\":1}}],[\"监督微调与预训练的区别|监督微调与预训练的区别\",{\"2\":{\"5\":1}}],[\"监督学习与无监督学习\",{\"2\":{\"91\":1}}],[\"监督学习表现非常好\",{\"2\":{\"39\":1}}],[\"监督学习的适用场景\",{\"2\":{\"39\":1}}],[\"监督学习的特点是数据有标注\",{\"2\":{\"39\":1}}],[\"监督学习\",{\"2\":{\"37\":1,\"39\":1}}],[\"拼接结果\",{\"0\":{\"2628\":1}}],[\"拼接在一起\",{\"2\":{\"1885\":1}}],[\"拼接跨块注意力输出\",{\"2\":{\"135\":1}}],[\"拼写错误\",{\"2\":{\"461\":1}}],[\"查看使用了哪些上下文\",{\"2\":{\"2702\":1}}],[\"查找与查询向量完全相同的项通常不是目标\",{\"2\":{\"1377\":1}}],[\"查找学术论文\",{\"2\":{\"454\":1}}],[\"查嵌入矩阵\",{\"2\":{\"1225\":1}}],[\"查询检索\",{\"0\":{\"2272\":1},\"2\":{\"1950\":1}}],[\"查询的措辞会直接影响搜索结果\",{\"2\":{\"1610\":1}}],[\"查询转换\",{\"0\":{\"1610\":1},\"1\":{\"1663\":1,\"1717\":1,\"1774\":1,\"1835\":1}}],[\"查询算法\",{\"0\":{\"1377\":1},\"1\":{\"1422\":1,\"1467\":1,\"1511\":1,\"1559\":1,\"1610\":1,\"1663\":1,\"1717\":1,\"1774\":1,\"1835\":1,\"1894\":1,\"1949\":1,\"2000\":1,\"2051\":1,\"2104\":1,\"2154\":1,\"2197\":1,\"2236\":1,\"2271\":1,\"2304\":1,\"2335\":1,\"2365\":1,\"2394\":1}}],[\"查询会根据其特点\",{\"2\":{\"1332\":1}}],[\"查询索引阶段是一个至关重要的环节\",{\"2\":{\"1235\":1}}],[\"查询索引阶段\",{\"2\":{\"237\":1}}],[\"查询\",{\"2\":{\"188\":1,\"1333\":1}}],[\"查询块\",{\"2\":{\"135\":1}}],[\"影响策略学习\",{\"2\":{\"2575\":1,\"2644\":1}}],[\"影响token生成概率的参数\",{\"2\":{\"2357\":1}}],[\"影响用户体验\",{\"2\":{\"2315\":1}}],[\"影响系统对问题的理解\",{\"2\":{\"2197\":1}}],[\"影响可以忽略不计\",{\"2\":{\"2145\":1}}],[\"影响较小\",{\"2\":{\"2087\":1}}],[\"影响更大\",{\"2\":{\"2087\":1}}],[\"影响解码效率和模型知识能力\",{\"2\":{\"1531\":1}}],[\"影响范围\",{\"2\":{\"591\":1}}],[\"影响模型对整体内容的把握\",{\"2\":{\"2522\":1}}],[\"影响模型收敛速度与资源消耗的平衡\",{\"2\":{\"1297\":1}}],[\"影响模型训练效果\",{\"2\":{\"582\":1,\"2593\":1}}],[\"影响模型更新\",{\"2\":{\"523\":1}}],[\"影响模型性能\",{\"2\":{\"222\":1,\"243\":1,\"1109\":1,\"2290\":1}}],[\"影响采样效果\",{\"2\":{\"446\":1}}],[\"部分优化\",{\"2\":{\"2608\":1}}],[\"部分训练\",{\"2\":{\"2608\":1}}],[\"部分拒答\",{\"2\":{\"2540\":1}}],[\"部分可学习\",{\"2\":{\"1606\":1}}],[\"部分可观测环境的缺失\",{\"2\":{\"1453\":1}}],[\"部分用\",{\"2\":{\"917\":1}}],[\"部分\",{\"2\":{\"881\":1,\"1047\":1}}],[\"部分的\",{\"2\":{\"881\":1}}],[\"部分代码示例来自\",{\"2\":{\"771\":1}}],[\"部分簇间样本相似度可能高于簇内样本\",{\"2\":{\"446\":1}}],[\"部署\",{\"2\":{\"2228\":1}}],[\"部署步骤\",{\"2\":{\"79\":1}}],[\"部署环境\",{\"2\":{\"79\":1}}],[\"部署文档\",{\"0\":{\"79\":1}}],[\"部署为\",{\"2\":{\"49\":1}}],[\"式\",{\"2\":{\"440\":1,\"560\":1}}],[\"密集式或\",{\"2\":{\"560\":1}}],[\"密集式\",{\"2\":{\"440\":1}}],[\"密钥管理工具\",{\"2\":{\"198\":1}}],[\"门控网络\",{\"2\":{\"440\":1}}],[\"专有信息源的访问\",{\"2\":{\"2269\":1}}],[\"专门负责处理需要简要回答的问题\",{\"2\":{\"1285\":1}}],[\"专属混合配置\",{\"2\":{\"998\":1}}],[\"专家数量\",{\"2\":{\"1326\":1,\"2090\":1}}],[\"专家分配策略验证\",{\"2\":{\"1324\":1}}],[\"专家容量通过容量系数\",{\"2\":{\"1229\":1}}],[\"专家的缓存区\",{\"2\":{\"1170\":1}}],[\"专家模块分割\",{\"2\":{\"1073\":1}}],[\"专家模型\",{\"2\":{\"908\":1,\"988\":1}}],[\"专家\",{\"2\":{\"1031\":1,\"1704\":1}}],[\"专家组中的每个成员专注于处理输入数据的特定方面\",{\"2\":{\"1121\":1}}],[\"专家组\",{\"2\":{\"990\":1}}],[\"专家网络\",{\"2\":{\"440\":1}}],[\"专为处理状态和动作空间非常大的情况而设计\",{\"2\":{\"606\":1}}],[\"专注于考试相关数据\",{\"2\":{\"2184\":1}}],[\"专注于内容的语义相似性\",{\"2\":{\"2051\":1}}],[\"专注于策略的稳定性和收敛性\",{\"2\":{\"1589\":1}}],[\"专注于研究型任务的多智能体协作工具\",{\"2\":{\"1485\":1}}],[\"专注于团队智能体间的任务分配与协调\",{\"2\":{\"1300\":1}}],[\"专注于基于语言的任务\",{\"2\":{\"1238\":1}}],[\"专注于代码与技术\",{\"2\":{\"535\":1}}],[\"专注于处理特定类型的输入\",{\"2\":{\"440\":1}}],[\"构造任务相关的连续virtual\",{\"2\":{\"2074\":1}}],[\"构造指数形式\",{\"0\":{\"1830\":1}}],[\"构造一个词到索引的映射\",{\"2\":{\"1025\":1}}],[\"构建和维护模块化系统可能较为复杂\",{\"2\":{\"2544\":1}}],[\"构建并收集长思维链数据以微调模型\",{\"2\":{\"2527\":1}}],[\"构建出一个提示模板\",{\"2\":{\"2305\":1}}],[\"构建了多层的小世界网络结构\",{\"2\":{\"2234\":1}}],[\"构建了一个数学指令调优数据集\",{\"2\":{\"1240\":1}}],[\"构建思想\",{\"0\":{\"2081\":1}}],[\"构建高质量的知识向量库是\",{\"2\":{\"1450\":1}}],[\"构建高质量的agent与环境交互轨迹指令微调数据集\",{\"2\":{\"1008\":1}}],[\"构建调用链以及定义工具等功能\",{\"2\":{\"1250\":1}}],[\"构建智能体系统\",{\"2\":{\"1200\":1}}],[\"构建偏好对\",{\"2\":{\"1134\":1}}],[\"构建词汇表\",{\"2\":{\"391\":1}}],[\"构成\",{\"2\":{\"676\":1}}],[\"构成要素\",{\"0\":{\"440\":1}}],[\"针对上述情况\",{\"2\":{\"2664\":1}}],[\"针对上述问题\",{\"2\":{\"1561\":1}}],[\"针对性强\",{\"2\":{\"2645\":1}}],[\"针对生成环节的评估\",{\"0\":{\"2222\":1},\"1\":{\"2257\":1,\"2292\":1},\"2\":{\"2222\":1}}],[\"针对某类输入的优化可能会损害其他输入的性能\",{\"2\":{\"1935\":1}}],[\"针对中文内容\",{\"2\":{\"1763\":1}}],[\"针对业务场景设计定制化词表扩充策略\",{\"2\":{\"1686\":1}}],[\"针对检索环节的评估\",{\"0\":{\"1590\":1},\"1\":{\"1644\":1,\"1698\":1,\"1756\":1,\"1816\":1,\"1876\":1,\"1933\":1,\"1984\":1,\"2035\":1,\"2087\":1,\"2137\":1,\"2183\":1}}],[\"针对部分可观测环境进行了专项设计\",{\"2\":{\"1453\":1}}],[\"针对特定结构化内容\",{\"2\":{\"2640\":1}}],[\"针对特定任务测试不同的提示长度\",{\"2\":{\"2017\":1}}],[\"针对特定任务提供明确指令\",{\"2\":{\"1420\":1}}],[\"针对特定场景\",{\"2\":{\"1819\":1}}],[\"针对特定网站的数据抓取\",{\"2\":{\"494\":1}}],[\"针对每一个prompt\",{\"2\":{\"1368\":1}}],[\"针对企业和个人用户提供了稳定\",{\"2\":{\"1347\":1}}],[\"针对直接寻找具体答案的问题\",{\"2\":{\"1285\":1}}],[\"针对\",{\"2\":{\"1252\":1,\"1451\":1,\"1542\":1,\"1813\":1}}],[\"针对权重\",{\"2\":{\"981\":1}}],[\"针对激活中的离群值\",{\"2\":{\"2033\":1}}],[\"针对激活\",{\"2\":{\"981\":1}}],[\"针对小红书\",{\"2\":{\"663\":1}}],[\"针对不同规模模型\",{\"2\":{\"1758\":1}}],[\"针对不同任务选择合适的提示长度\",{\"2\":{\"1856\":1}}],[\"针对不同任务采用不同提示长度\",{\"2\":{\"1736\":1}}],[\"针对不同任务优化word2vec参数\",{\"2\":{\"1161\":1}}],[\"针对不同类型数据集设计适配性强的去重流程\",{\"2\":{\"816\":1}}],[\"针对不同平台的数据结构差异\",{\"2\":{\"628\":1}}],[\"针对不同格式的内容\",{\"2\":{\"411\":1}}],[\"针对长文本输入切分序列\",{\"2\":{\"567\":1}}],[\"针对现有模型尝试不同插值方法\",{\"2\":{\"439\":1}}],[\"续写能力\",{\"0\":{\"661\":1},\"1\":{\"699\":1,\"735\":1},\"2\":{\"436\":1}}],[\"格式奖励\",{\"2\":{\"1797\":1}}],[\"格式进行更新\",{\"2\":{\"523\":1}}],[\"格式\",{\"2\":{\"435\":1}}],[\"格式的缩放梯度\",{\"2\":{\"435\":1}}],[\"损失token数量\",{\"2\":{\"2482\":1}}],[\"损失掩码\",{\"2\":{\"2482\":1}}],[\"损失越低\",{\"2\":{\"2163\":1}}],[\"损失\",{\"2\":{\"1393\":1}}],[\"损失计算\",{\"2\":{\"1047\":1}}],[\"损失缩放策略如何动态调整\",{\"2\":{\"660\":1}}],[\"损失缩放是混合精度训练的核心技术\",{\"2\":{\"625\":1}}],[\"损失缩放\",{\"2\":{\"435\":1,\"591\":1}}],[\"损失函数的问题\",{\"2\":{\"2331\":1}}],[\"损失函数的优化\",{\"2\":{\"2300\":1}}],[\"损失函数的定义\",{\"2\":{\"1622\":1}}],[\"损失函数优化\",{\"0\":{\"2193\":1}}],[\"损失函数类似于\",{\"2\":{\"1727\":1}}],[\"损失函数可以表示为\",{\"2\":{\"1671\":1}}],[\"损失函数采用交叉熵\",{\"2\":{\"1536\":1}}],[\"损失函数与参数规模呈现等比关系\",{\"2\":{\"1152\":1}}],[\"损失函数与分层softmax\",{\"0\":{\"980\":1}}],[\"损失函数解析与代码示例\",{\"0\":{\"1432\":1},\"1\":{\"1477\":1,\"1521\":1,\"1570\":1,\"1620\":1,\"1675\":1,\"1731\":1,\"1789\":1,\"1850\":1,\"1907\":1,\"1960\":1,\"2012\":1,\"2061\":1},\"2\":{\"151\":1}}],[\"损失函数\",{\"2\":{\"144\":1,\"655\":3,\"980\":1,\"1127\":1,\"1248\":1,\"1521\":1,\"1582\":1}}],[\"知乎专栏\",{\"2\":{\"432\":1}}],[\"知识文档的准备\",{\"0\":{\"2001\":1},\"1\":{\"2052\":1,\"2105\":1},\"2\":{\"1950\":1}}],[\"知识获取能力\",{\"2\":{\"1759\":1}}],[\"知识和语言的技术框架\",{\"2\":{\"1569\":1}}],[\"知识的局限性\",{\"0\":{\"1423\":1}}],[\"知识的类型主要分为三种\",{\"2\":{\"780\":1}}],[\"知识的类型\",{\"0\":{\"780\":1},\"1\":{\"811\":1,\"845\":1,\"880\":1}}],[\"知识注入应采用继续预训练策略\",{\"2\":{\"1199\":1}}],[\"知识注入策略\",{\"2\":{\"1199\":1}}],[\"知识转移还涵盖了蒸馏它们独特的涌现能力\",{\"2\":{\"1124\":1}}],[\"知识形成补充\",{\"2\":{\"845\":1}}],[\"知识\",{\"2\":{\"715\":1}}],[\"知识蒸馏中\",{\"2\":{\"811\":1}}],[\"知识蒸馏是一种重要的模型压缩方法\",{\"2\":{\"749\":1}}],[\"知识蒸馏的过程需要数据集\",{\"2\":{\"715\":1}}],[\"知识蒸馏的基本组成部分\",{\"0\":{\"715\":1}}],[\"知识蒸馏算法由以下三部分组成\",{\"2\":{\"715\":1}}],[\"知识蒸馏可以分为以下两类\",{\"2\":{\"677\":1}}],[\"知识蒸馏\",{\"0\":{\"677\":1},\"1\":{\"715\":1},\"2\":{\"214\":1,\"677\":1,\"763\":1}}],[\"知识复用\",{\"2\":{\"40\":1}}],[\"速度受限于显存带宽\",{\"2\":{\"429\":1}}],[\"速度提升\",{\"2\":{\"40\":1}}],[\"学者们提出了多种针对\",{\"2\":{\"1990\":1}}],[\"学生模型在学习过程中能够更好地模仿教师模型\",{\"2\":{\"1035\":1}}],[\"学生模型只需模仿教师模型的最终预测结果即可\",{\"2\":{\"811\":1}}],[\"学生模型直接学习教师模型输出层的特征\",{\"2\":{\"811\":1}}],[\"学生\",{\"2\":{\"763\":1}}],[\"学术写作指南\",{\"2\":{\"454\":2}}],[\"学术论文写作规范\",{\"2\":{\"428\":1}}],[\"学习常用强化学习算法\",{\"2\":{\"928\":1}}],[\"学习方式的差异\",{\"0\":{\"726\":1}}],[\"学习如何使用专业pdf解析服务或ocr技术提升数据处理效率\",{\"2\":{\"669\":1}}],[\"学习如何实现和优化模型\",{\"2\":{\"511\":1}}],[\"学习并应用其他优化器以降低显存需求\",{\"2\":{\"2360\":1}}],[\"学习并应用wsd策略和z\",{\"2\":{\"662\":1}}],[\"学习并掌握\",{\"2\":{\"1818\":1}}],[\"学习并实践独热编码的基础实现\",{\"2\":{\"1212\":1}}],[\"学习并实践cbow与skip\",{\"2\":{\"1161\":1}}],[\"学习并实现deberta的相对位置编码机制\",{\"2\":{\"1381\":1}}],[\"学习并实现一个简单的\",{\"2\":{\"738\":1}}],[\"学习并实现一个简单的混合精度训练模型\",{\"2\":{\"698\":1}}],[\"学习并实现sentencepiece的基本用法\",{\"2\":{\"645\":1}}],[\"学习并实现swiglu和geglu的代码实现\",{\"2\":{\"311\":1}}],[\"学习并实现s2\",{\"2\":{\"288\":1}}],[\"学习率与调度器\",{\"2\":{\"2217\":1}}],[\"学习率缓慢上升到最大值\",{\"2\":{\"1436\":1}}],[\"学习率公式\",{\"2\":{\"1344\":1}}],[\"学习率线性上升\",{\"2\":{\"1344\":1}}],[\"学习率调度器通常能带来更稳定的收敛效果\",{\"2\":{\"2319\":1}}],[\"学习率调度\",{\"2\":{\"1148\":1,\"1162\":1}}],[\"学习率为5e\",{\"2\":{\"1134\":1}}],[\"学习率设置为1e\",{\"2\":{\"1087\":1}}],[\"学习率设为\",{\"2\":{\"49\":1}}],[\"学习率\",{\"2\":{\"646\":1,\"1186\":1,\"1605\":1,\"2177\":1}}],[\"学习过程中不涉及环境交互\",{\"2\":{\"618\":1}}],[\"学习fasttext和langid工具的语言识别实现\",{\"2\":{\"615\":1}}],[\"学习bbpe的理论基础与实现细节\",{\"2\":{\"442\":1}}],[\"学习transformer中attention机制的数学原理\",{\"2\":{\"303\":1}}],[\"学习transformer结构中attention的具体实现\",{\"2\":{\"284\":1}}],[\"学习transformer的代码实现\",{\"2\":{\"256\":1}}],[\"学习资源\",{\"0\":{\"67\":1,\"106\":1,\"165\":1,\"230\":1,\"302\":1,\"375\":1,\"454\":1,\"544\":1}}],[\"学习资料\",{\"0\":{\"43\":1},\"1\":{\"52\":1,\"59\":1,\"67\":1,\"77\":1,\"91\":1,\"106\":1,\"124\":1,\"144\":1,\"165\":1,\"186\":1,\"207\":1,\"230\":1,\"254\":1,\"278\":1,\"302\":1,\"325\":1,\"349\":1,\"375\":1,\"401\":1,\"428\":1,\"454\":1,\"482\":1,\"511\":1,\"544\":1,\"578\":1}}],[\"学习\",{\"2\":{\"56\":1,\"1125\":1}}],[\"学习各个算法的应用场景是比纸上谈兵更加有深度\",{\"2\":{\"39\":1}}],[\"转化为计算机可以处理的稠密向量\",{\"2\":{\"882\":1}}],[\"转移到较小简单模型\",{\"2\":{\"677\":1}}],[\"转发\",{\"2\":{\"548\":1}}],[\"转回\",{\"2\":{\"523\":1}}],[\"转为\",{\"2\":{\"488\":1}}],[\"转小写\",{\"2\":{\"480\":1}}],[\"转换为纯文本数据\",{\"0\":{\"2052\":1}}],[\"转换为最小化问题\",{\"0\":{\"1712\":1}}],[\"转换为\",{\"2\":{\"889\":1}}],[\"转换为小写\",{\"2\":{\"480\":1}}],[\"转换成概率\",{\"2\":{\"90\":1,\"185\":1}}],[\"转义\",{\"2\":{\"426\":1}}],[\"▁\",{\"2\":{\"426\":1}}],[\"旨在帮助简化分布式训练和混合精度训练的过程\",{\"2\":{\"2055\":1}}],[\"旨在为读者提供清晰的技术理解和应用指导\",{\"2\":{\"1953\":1}}],[\"旨在对齐大型语言模型\",{\"2\":{\"1887\":1,\"1943\":1}}],[\"旨在解决之前方法中存在的模型参数规模和任务通用性问题\",{\"2\":{\"1680\":1}}],[\"旨在克服传统rlhf\",{\"2\":{\"1495\":1}}],[\"旨在提高低概率token的探索能力\",{\"2\":{\"2296\":1}}],[\"旨在提升复杂推理任务中的强化学习效率和稳定性\",{\"2\":{\"1955\":1}}],[\"旨在提升大语言模型\",{\"2\":{\"1708\":1}}],[\"旨在提升处理长文本的能力\",{\"2\":{\"1061\":1}}],[\"旨在提供对roberta优化方法的全面理解\",{\"2\":{\"1386\":1}}],[\"旨在让学生模型学习大语言模型\",{\"2\":{\"1124\":1}}],[\"旨在生成长文本\",{\"2\":{\"1089\":1}}],[\"旨在通过修改基线计算来降低方差\",{\"2\":{\"2328\":1,\"2359\":1}}],[\"旨在通过引入共享的随机权值矩阵\",{\"2\":{\"1636\":1}}],[\"旨在通过更细粒度的专家模块分割和隔离共享专家模块来提高模型的专业化程度和知识获取的准确性\",{\"2\":{\"989\":1}}],[\"旨在通过长远发展理念进行扩展\",{\"2\":{\"960\":1}}],[\"旨在通过与环境的交互来学习最优的行为策略\",{\"2\":{\"572\":1}}],[\"旨在通过扩展上下文长度和增强远程注意力能力\",{\"2\":{\"423\":1}}],[\"旨在检测模型在处理复杂文本时的理解与记忆能力\",{\"2\":{\"492\":1}}],[\"旨在简化不同服务间的集成\",{\"2\":{\"102\":1}}],[\"再用此概率和真值组做cross\",{\"2\":{\"2660\":1}}],[\"再用多数投票选出最合理的答案\",{\"2\":{\"596\":1}}],[\"再看伪代码第8行\",{\"2\":{\"2653\":1}}],[\"再次进行分割\",{\"2\":{\"2606\":1}}],[\"再让文档代理对每个子问题进行多向量或多索引检索\",{\"2\":{\"2335\":1}}],[\"再将主文档分割为更短的小型子文档\",{\"2\":{\"2236\":1}}],[\"再将计算结果写回到hbm中\",{\"2\":{\"2080\":1}}],[\"再将其翻译成另一种语言\",{\"2\":{\"1820\":1}}],[\"再考虑到技术优化\",{\"2\":{\"1910\":1}}],[\"再配合一个新的\",{\"2\":{\"1885\":1}}],[\"再取平均值\",{\"2\":{\"1644\":1}}],[\"再加上大模型本质上并不是完全确定性的系统\",{\"2\":{\"1377\":1}}],[\"再加上验证集中的样本输入组成\",{\"2\":{\"1222\":1}}],[\"再逐步进入复杂内容\",{\"2\":{\"533\":1}}],[\"再逐步合并\",{\"2\":{\"420\":1}}],[\"再结合核函数形式处理\",{\"2\":{\"189\":1}}],[\"共计800k数据用于sft训练\",{\"2\":{\"2504\":1}}],[\"共同制定决策\",{\"2\":{\"1338\":1}}],[\"共同点\",{\"2\":{\"420\":1,\"445\":1}}],[\"共用一个编码\",{\"2\":{\"1306\":1}}],[\"共776k个样本\",{\"2\":{\"1240\":1}}],[\"共12层\",{\"2\":{\"1009\":1}}],[\"共迭代\",{\"2\":{\"656\":1}}],[\"共享权值\",{\"2\":{\"1866\":1}}],[\"共享专家数量\",{\"2\":{\"1318\":1}}],[\"共享专家机制实现计算\",{\"2\":{\"1277\":1}}],[\"共享嵌入矩阵需保持rd×d\",{\"2\":{\"1227\":1}}],[\"共享输入输出embedding\",{\"2\":{\"1198\":1}}],[\"共享模块隔离\",{\"2\":{\"1073\":1}}],[\"共享\",{\"2\":{\"631\":1}}],[\"共享预训练模型\",{\"2\":{\"57\":1}}],[\"共现频率\",{\"2\":{\"499\":1}}],[\"应尽量选择与其匹配的分块大小\",{\"2\":{\"2655\":1}}],[\"应该是它和所有token都做注意力计算后的输出结果\",{\"2\":{\"2379\":1}}],[\"应在prefix层前面加mlp结构\",{\"2\":{\"2126\":1}}],[\"应参考所用嵌入模型的说明文档\",{\"2\":{\"2051\":1}}],[\"应使用prompt\",{\"2\":{\"1914\":1}}],[\"应重点关注降低坏答案的采样概率\",{\"2\":{\"1913\":1}}],[\"应确保行为策略与参考策略一致\",{\"2\":{\"1777\":1}}],[\"应优先利用\",{\"2\":{\"1592\":1}}],[\"应优化权重计算方法\",{\"2\":{\"565\":1}}],[\"应优化算法或使用并行处理\",{\"2\":{\"417\":1}}],[\"应根据硬件条件合理配置\",{\"2\":{\"1351\":1}}],[\"应根据具体任务调整优化器和学习率策略\",{\"2\":{\"1262\":1}}],[\"应结合降维技术优化性能\",{\"2\":{\"1163\":1}}],[\"应结合降维技术\",{\"2\":{\"1113\":1}}],[\"应关注趋势变化\",{\"2\":{\"834\":1}}],[\"应严格控制在经验阈值范围内\",{\"2\":{\"566\":1}}],[\"应用强化学习以进一步提升小模型性能\",{\"2\":{\"2652\":1}}],[\"应用dropout\",{\"2\":{\"2611\":1}}],[\"应用机器学习算法挖掘有价值的信息\",{\"2\":{\"2255\":1}}],[\"应用remax方法于其他大型语言模型\",{\"2\":{\"2229\":1,\"2265\":1}}],[\"应用局限\",{\"2\":{\"1932\":1}}],[\"应用于模型训练\",{\"2\":{\"2695\":1}}],[\"应用于不同模型结构\",{\"0\":{\"1922\":1}}],[\"应用于医学图像处理\",{\"2\":{\"39\":1}}],[\"应用softmax\",{\"2\":{\"1809\":1}}],[\"应用scaling\",{\"2\":{\"1556\":1}}],[\"应用lora处理\",{\"2\":{\"1770\":1}}],[\"应用路线图\",{\"0\":{\"1324\":1}}],[\"应用多阶段训练提升模型性能\",{\"2\":{\"1245\":1}}],[\"应用\",{\"2\":{\"739\":1,\"2702\":1}}],[\"应用上述解码策略于实际项目\",{\"2\":{\"481\":1}}],[\"应用位置内插的操作步骤\",{\"0\":{\"291\":1}}],[\"应用旋转变换后计算点积\",{\"2\":{\"247\":1}}],[\"应用场景\",{\"0\":{\"495\":1,\"605\":1,\"1431\":1},\"2\":{\"188\":1,\"205\":1,\"227\":1,\"264\":1,\"315\":1,\"932\":1,\"1241\":1,\"1259\":1}}],[\"应用实践\",{\"0\":{\"38\":1}}],[\"概念原理\",{\"0\":{\"1708\":1}}],[\"概率计算\",{\"2\":{\"444\":1}}],[\"概率探针能否用于实时监控模型的知识更新情况\",{\"2\":{\"770\":1}}],[\"概率探针通过监控特定token或句子的概率变化来评估模型的知识能力是否有提升或遗忘\",{\"2\":{\"592\":1}}],[\"概率探针\",{\"0\":{\"557\":1},\"1\":{\"592\":1,\"626\":1},\"2\":{\"436\":1}}],[\"概率分布更集中\",{\"2\":{\"416\":1}}],[\"概率分布更平坦\",{\"2\":{\"416\":1}}],[\"概述下一句需要包含的事实\",{\"2\":{\"2601\":1}}],[\"概述\",{\"0\":{\"203\":1}}],[\"温度过高可能使输出过于随机\",{\"2\":{\"630\":1}}],[\"温度低\",{\"2\":{\"416\":1}}],[\"温度高\",{\"2\":{\"416\":1}}],[\"温度参数\",{\"2\":{\"228\":1,\"346\":1}}],[\"温度参数对注意力机制的优化\",{\"0\":{\"228\":1}}],[\"抖音等平台\",{\"2\":{\"663\":1}}],[\"抖音\",{\"2\":{\"411\":1,\"559\":1}}],[\"探讨奖励设计对不同类型任务的影响\",{\"2\":{\"2093\":1}}],[\"探讨其他可能的基线计算方法\",{\"2\":{\"2508\":1,\"2521\":1}}],[\"探讨其他可能的奖励模型以优化grpo\",{\"2\":{\"2421\":1}}],[\"探讨其他算法在rlhf中的应用潜力\",{\"2\":{\"1861\":1}}],[\"探讨其与机器学习算法结合的潜力\",{\"2\":{\"993\":1}}],[\"探讨如何在llm中有效实现基于规则的奖励系统\",{\"2\":{\"2199\":1}}],[\"探讨如何在复杂nlp任务中实现更精确的mdp建模\",{\"2\":{\"2003\":1}}],[\"探讨如何利用多模态数据进一步优化预训练\",{\"2\":{\"1607\":1}}],[\"探讨如何将\",{\"2\":{\"1587\":1}}],[\"探讨并行层设计对模型效率的影响\",{\"2\":{\"1527\":1}}],[\"探讨继续预训练策略在不同领域的应用效果\",{\"2\":{\"1438\":1}}],[\"探讨降低模型推理成本的方法\",{\"2\":{\"1406\":1}}],[\"探讨通信平衡损失在其他领域应用的可能性\",{\"2\":{\"1271\":1}}],[\"探讨\",{\"2\":{\"1140\":1,\"2492\":1}}],[\"探讨两种主要的智能体分类\",{\"2\":{\"1139\":1}}],[\"探讨两种算法在多智能体系统中的协同学习效果\",{\"2\":{\"951\":1}}],[\"探讨dqn在多智能体环境中的表现\",{\"2\":{\"913\":1}}],[\"探讨结合深度学习的方法以提升动态规划的效率\",{\"2\":{\"824\":1}}],[\"探讨td方法在连续状态空间中的应用\",{\"2\":{\"815\":1}}],[\"探讨不同预训练模型对领域数据比例的敏感性\",{\"2\":{\"667\":1}}],[\"探讨它们的优缺点及应用场景\",{\"2\":{\"638\":1}}],[\"探讨模型从长文本中检索多个相关信息的能力\",{\"2\":{\"524\":1}}],[\"探讨了如何通过细致的观察和调整策略来优化模型性能\",{\"2\":{\"464\":1}}],[\"探讨了如何通过调整模型参数和工程优化手段\",{\"2\":{\"423\":1}}],[\"探讨更高效的位置编码方法\",{\"2\":{\"409\":1}}],[\"探索新型评估算法以提高机评准确性\",{\"2\":{\"2391\":1}}],[\"探索新的奖励机制以减少奖励黑客的风险\",{\"2\":{\"1709\":1}}],[\"探索openrlhf框架的更多应用场景\",{\"2\":{\"2380\":1}}],[\"探索混合精度训练在实际项目中的应用\",{\"2\":{\"2360\":1}}],[\"探索分块技术如何在其他计算任务中应用\",{\"2\":{\"2275\":1}}],[\"探索peft在实时系统中的应用潜力\",{\"2\":{\"2182\":1}}],[\"探索ppo在不同环境下的表现\",{\"2\":{\"796\":1}}],[\"探索可能的动作序列\",{\"2\":{\"2171\":1}}],[\"探索grpo方法去掉critic\",{\"2\":{\"2156\":1}}],[\"探索gpt1在不同下游任务中的应用\",{\"2\":{\"1385\":1}}],[\"探索门控机制的进一步改进方法\",{\"2\":{\"2038\":1}}],[\"探索能否通过某种替换去掉critic\",{\"2\":{\"1954\":1}}],[\"探索能力表现为地点的探索情况\",{\"2\":{\"1819\":1}}],[\"探索能力表现为容器的探索情况\",{\"2\":{\"1819\":1}}],[\"探索能力表现为房间的探索情况\",{\"2\":{\"1819\":1}}],[\"探索能力的定义有所不同\",{\"2\":{\"1819\":1}}],[\"探索能力\",{\"0\":{\"1819\":1}}],[\"探索reinforce++在不同大型语言模型中的表现\",{\"2\":{\"2159\":1}}],[\"探索reward\",{\"2\":{\"2053\":1}}],[\"探索rlhf在其他领域的应用\",{\"2\":{\"1920\":1}}],[\"探索roberta在其他语言处理任务中的应用\",{\"2\":{\"1294\":1}}],[\"探索rope位置编码在其他模型中的应用潜力\",{\"2\":{\"1444\":1}}],[\"探索rope与其他位置编码方法的融合效果\",{\"2\":{\"740\":1}}],[\"探索rope应用于非transformer架构\",{\"2\":{\"388\":1}}],[\"探索instructgpt在多语言环境下的适用性\",{\"2\":{\"1918\":1}}],[\"探索了多种推理格式\",{\"2\":{\"1917\":1}}],[\"探索减少ppo计算资源需求的方法\",{\"2\":{\"1814\":1}}],[\"探索鼓励智能体在环境中尝试不同策略\",{\"2\":{\"1765\":1}}],[\"探索与利用的平衡一直是一个重要的研究课题\",{\"2\":{\"1765\":1}}],[\"探索与利用\",{\"2\":{\"1707\":1}}],[\"探索与其他位置编码技术\",{\"2\":{\"387\":1}}],[\"探索高效的显存管理技术以支持更大规模的预训练\",{\"2\":{\"1629\":1}}],[\"探索sft在多语言模型中的应用潜力\",{\"2\":{\"1528\":1}}],[\"探索switch\",{\"2\":{\"1417\":1}}],[\"探索sarsa与深度学习结合的可能性\",{\"2\":{\"886\":1}}],[\"探索sarsa算法在多智能体系统中的应用\",{\"2\":{\"817\":1}}],[\"探索few\",{\"2\":{\"1370\":1}}],[\"探索fasttext在多语言文本分类中的表现\",{\"2\":{\"1307\":1}}],[\"探索进一步优化位置编码的方法\",{\"2\":{\"1339\":1}}],[\"探索嵌入式表示方法\",{\"2\":{\"1263\":1}}],[\"探索t5模型在不同领域应用中的表现\",{\"2\":{\"1257\":1}}],[\"探索二维位置编码技术在其他模型中的应用\",{\"2\":{\"1239\":1}}],[\"探索降维技术\",{\"2\":{\"1212\":1}}],[\"探索bert在不同nlp任务中的应用\",{\"2\":{\"1177\":1}}],[\"探索bart与其他激活函数的兼容性\",{\"2\":{\"1144\":1}}],[\"探索bbpe在非文本数据\",{\"2\":{\"442\":1}}],[\"探索强化学习在新兴领域的应用潜力\",{\"2\":{\"1034\":1}}],[\"探索强化学习在实际应用中的场景\",{\"2\":{\"928\":1}}],[\"探索自动化评估指令执行难度的方法\",{\"2\":{\"2453\":1}}],[\"探索自动化工具以提升数据清洗效率\",{\"2\":{\"816\":1}}],[\"探索自我奖励语言模型在其他领域的应用潜力\",{\"2\":{\"2174\":1}}],[\"探索自我评价机制如何提高数学问题解决能力\",{\"2\":{\"1008\":1}}],[\"探索贝尔曼方程在非马尔科夫决策过程中如何应用\",{\"2\":{\"979\":1}}],[\"探索蒙特卡洛方法在金融风险管理中的应用\",{\"2\":{\"914\":1}}],[\"探索结合深度学习技术对ppo进行改进\",{\"2\":{\"864\":1}}],[\"探索结合其他值函数的可能性\",{\"2\":{\"759\":1}}],[\"探索多任务学习在不同数据集上的效果\",{\"2\":{\"2470\":1}}],[\"探索多任务学习在其他领域的应用潜力\",{\"2\":{\"2017\":1}}],[\"探索多智能体系统中的协作策略优化\",{\"2\":{\"841\":1}}],[\"探索多模态预训练方法\",{\"2\":{\"669\":1}}],[\"探索如何将dpo应用于其他机器学习任务\",{\"2\":{\"1902\":1}}],[\"探索如何将不同策略优化方法结合\",{\"2\":{\"892\":1}}],[\"探索如何在低资源环境下实现高质量中文预训练\",{\"2\":{\"1800\":1}}],[\"探索如何在不完全已知环境中应用动态规划\",{\"2\":{\"761\":1}}],[\"探索如何优化\",{\"2\":{\"1555\":1}}],[\"探索如何优化grpo在强化学习中的应用\",{\"2\":{\"1475\":1}}],[\"探索如何优化replay\",{\"2\":{\"842\":1}}],[\"探索如何结合online和offline方法以提高数据利用率\",{\"2\":{\"821\":1}}],[\"探索如何结合深度学习优化分词过程\",{\"2\":{\"555\":1}}],[\"探索\",{\"2\":{\"739\":1,\"807\":1,\"1493\":1,\"2219\":1}}],[\"探索其在多模态任务中的潜力\",{\"2\":{\"738\":1}}],[\"探索其他框架中类似功能的实现\",{\"2\":{\"2510\":1}}],[\"探索其他基线选择对策略梯度方法的影响\",{\"2\":{\"2229\":1,\"2265\":1}}],[\"探索其他基于svd的优化技术\",{\"2\":{\"2040\":1}}],[\"探索其他优化策略结合dpop算法的可能性\",{\"2\":{\"2120\":1}}],[\"探索其他适配器中应用类似策略的可行性\",{\"2\":{\"1997\":1}}],[\"探索其他模型在偏好建模中的应用\",{\"2\":{\"1751\":1}}],[\"探索其他分布式训练策略\",{\"2\":{\"1651\":1}}],[\"探索其他分布式表示技术\",{\"2\":{\"1261\":1}}],[\"探索其他moe架构中的路由机制\",{\"2\":{\"1363\":1}}],[\"探索其他可能的缓存优化策略\",{\"2\":{\"2478\":1}}],[\"探索其他可能的优化策略以提高模型性能\",{\"2\":{\"2215\":1}}],[\"探索其他可能的优化方法以进一步提高模型性能\",{\"2\":{\"1274\":1}}],[\"探索其他可能的参数共享策略\",{\"2\":{\"2075\":1}}],[\"探索其他可能的权重分解方法\",{\"2\":{\"2048\":1}}],[\"探索其他可能的约束机制以提升策略稳定性\",{\"2\":{\"1961\":1}}],[\"探索其他可能的损失函数组合以优化ppo训练\",{\"2\":{\"709\":1}}],[\"探索其他形式的critic指导策略更新\",{\"2\":{\"822\":1}}],[\"探索其他并行训练机制以进一步提升效率\",{\"2\":{\"668\":1}}],[\"探索其他高效编码方式\",{\"2\":{\"361\":1}}],[\"探索价值迭代在非确定性环境中的应用\",{\"2\":{\"647\":1}}],[\"探索更节省显存的算子和api\",{\"2\":{\"2214\":1}}],[\"探索更复杂的逻辑推理任务对llm能力的影响\",{\"2\":{\"982\":1}}],[\"探索更智能的显存管理工具\",{\"2\":{\"765\":1}}],[\"探索更高效的反反爬技术\",{\"2\":{\"737\":1}}],[\"探索更高效的attention机制以进一步减少推理时延\",{\"2\":{\"683\":1}}],[\"探索更高效的矩阵计算方法\",{\"2\":{\"613\":1}}],[\"探索更多语言环境下的一致性奖励机制\",{\"2\":{\"2556\":1}}],[\"探索更多复杂任务类型的数据需求\",{\"2\":{\"2451\":1}}],[\"探索更多开源项目以丰富研究素材\",{\"2\":{\"2412\":1}}],[\"探索更多的数据收集渠道\",{\"2\":{\"2409\":1}}],[\"探索更多的低秩适应技术与x\",{\"2\":{\"2078\":1}}],[\"探索更多评估方法以提升结果准确性\",{\"2\":{\"2332\":1}}],[\"探索更多聚合操作在奖励模型中的应用\",{\"2\":{\"1921\":1}}],[\"探索更多应用场景中的kl约束优化\",{\"2\":{\"1880\":1}}],[\"探索更多数据过滤和奖励机制以提升样本质量\",{\"2\":{\"1492\":1}}],[\"探索更多关于sft\",{\"2\":{\"2502\":1}}],[\"探索更多关于损失函数优化的技术\",{\"2\":{\"2464\":1}}],[\"探索更多关于伪多轮数据对模型影响的实证研究\",{\"2\":{\"2457\":1}}],[\"探索更多关于mdp模型在nlp中的应用\",{\"2\":{\"2111\":1}}],[\"探索更多关于prompt\",{\"2\":{\"2019\":1}}],[\"探索更多关于4\",{\"2\":{\"2015\":1}}],[\"探索更多关于\",{\"2\":{\"1441\":1}}],[\"探索更多关于gpt\",{\"2\":{\"1350\":1}}],[\"探索更多场景下相对与绝对位置的结合应用\",{\"2\":{\"1427\":1}}],[\"探索更多rl在不同模型上的应用\",{\"2\":{\"1387\":1}}],[\"探索更多领域特定的benchmark\",{\"2\":{\"819\":1}}],[\"探索更多优化参数\",{\"2\":{\"439\":1}}],[\"探索更多高效的ffn结构替代方案\",{\"2\":{\"334\":1}}],[\"探索实际项目中不同分词方法对模型性能的影响\",{\"2\":{\"531\":1}}],[\"探索基于\",{\"2\":{\"1225\":1}}],[\"探索基于互信息优化的新型分词方法\",{\"2\":{\"522\":1}}],[\"探索基于强化学习优化解码策略的新方法\",{\"2\":{\"510\":1}}],[\"探索改进beam\",{\"2\":{\"481\":1}}],[\"探索长上下文模型在实时交互场景中的潜力\",{\"2\":{\"385\":1}}],[\"探索是否可以结合动态温度调整策略\",{\"2\":{\"372\":1}}],[\"探索yarn在多模态模型中的应用潜力\",{\"2\":{\"322\":1}}],[\"探索kv\",{\"2\":{\"303\":1}}],[\"探索注意力掩码微调的最佳实践\",{\"2\":{\"288\":1}}],[\"探索attention机制在多模态学习中的扩展\",{\"2\":{\"350\":1}}],[\"探索attention机制在多模态任务中的表现\",{\"2\":{\"256\":1}}],[\"探索attention在图像处理任务中的应用\",{\"2\":{\"284\":1}}],[\"探索核函数形式在其他领域\",{\"2\":{\"281\":1}}],[\"探索并实施统一认证管理平台\",{\"2\":{\"242\":1}}],[\"探索不同参数设置对模型性能的影响\",{\"2\":{\"2701\":1}}],[\"探索不同初始化策略对vapo性能的影响\",{\"2\":{\"2307\":1}}],[\"探索不同任务下lora的适用性和性能表现\",{\"2\":{\"2244\":1}}],[\"探索不同任务中layer\",{\"2\":{\"234\":1}}],[\"探索不同的正则化手段以优化dpo\",{\"2\":{\"1907\":1}}],[\"探索不同的奖励函数设计对生成质量的影响\",{\"2\":{\"755\":1}}],[\"探索不同截断范围对模型性能的影响\",{\"2\":{\"1647\":1}}],[\"探索不同学习率调度策略的效果\",{\"2\":{\"1310\":1}}],[\"探索不同维度大小对模型性能的影响\",{\"2\":{\"1125\":1}}],[\"探索不同环境下两种算法的性能表现\",{\"2\":{\"912\":1}}],[\"探索不同环境下td方法的应用效果\",{\"2\":{\"752\":1}}],[\"探索不同策略对价值函数的影响\",{\"2\":{\"902\":1}}],[\"探索不同类型的参考策略对行为约束效果的影响\",{\"2\":{\"818\":1}}],[\"探索不同聚类算法对采样质量的影响\",{\"2\":{\"666\":1}}],[\"探索不同bpe参数\",{\"2\":{\"597\":1}}],[\"探索不同分块算法对dca性能的影响\",{\"2\":{\"196\":1}}],[\"探索性数据分析\",{\"2\":{\"39\":1}}],[\"本身比较小\",{\"2\":{\"2653\":1}}],[\"本身不会太长\",{\"2\":{\"2651\":1}}],[\"本身之外的系统交互来服务于用户目标的genai系统\",{\"2\":{\"1184\":1}}],[\"本方案采用的是\",{\"2\":{\"2079\":1}}],[\"本质上是数据并行\",{\"2\":{\"2288\":1}}],[\"本质上\",{\"2\":{\"1333\":1}}],[\"本篇内容详细介绍了数据清洗的关键步骤\",{\"2\":{\"403\":1}}],[\"本文信息来源于多个开源项目\",{\"2\":{\"2258\":1}}],[\"本文提出的一种优化思路是减少这些模型的数量\",{\"2\":{\"1899\":1}}],[\"本文回顾了策略梯度与ppo算法的基本概念\",{\"2\":{\"1887\":1,\"1943\":1}}],[\"本文设计了一个简单的训练模板\",{\"2\":{\"1859\":1}}],[\"本文设计了两种基于规则的奖励机制\",{\"2\":{\"1797\":1}}],[\"本文没有使用orm或prm奖励模型\",{\"2\":{\"1797\":1}}],[\"本文讨论了如何通过合并多轮对话样本来加速计算\",{\"2\":{\"2267\":1}}],[\"本文讨论了如何通过多轮对话数据的构造和优化来提升对话模型的表现\",{\"2\":{\"2181\":1}}],[\"本文讨论了如何选择合适的深度学习模型结构和训练框架\",{\"2\":{\"1265\":1}}],[\"本文讨论了dpo的潜在优势\",{\"2\":{\"1495\":1}}],[\"本文讨论了两种主要的绝对位置编码方法\",{\"2\":{\"1131\":1}}],[\"本文主要探讨了在transformer模型中引入相对位置编码的方法\",{\"2\":{\"1166\":1}}],[\"本文主要探讨了两种主流解码策略\",{\"2\":{\"253\":1}}],[\"本文介绍了openrlhf框架下的sft训练启动脚本\",{\"2\":{\"2151\":1}}],[\"本文介绍了奖励模型的训练流程及其与传统强化学习的区别\",{\"2\":{\"1533\":1}}],[\"本文介绍了palm\",{\"2\":{\"1149\":1}}],[\"本文介绍了两种先进的技术\",{\"2\":{\"203\":1}}],[\"本文还研究了从deepseek\",{\"2\":{\"934\":1}}],[\"本文总结roberta的核心改进点\",{\"2\":{\"898\":1}}],[\"本文基于\",{\"2\":{\"1587\":1}}],[\"本文基于关于强化学习与有监督学习核心区别的原始内容整理与总结\",{\"2\":{\"966\":1}}],[\"本文基于glm130b技术报告及相关资料整理而成\",{\"2\":{\"736\":1}}],[\"本文基于unigram语言模型\",{\"2\":{\"563\":1}}],[\"本文从训练容灾\",{\"2\":{\"464\":1}}],[\"本文以codellama为参考\",{\"2\":{\"423\":1}}],[\"本文对比了三种常见的分词方法\",{\"2\":{\"368\":1}}],[\"本文对常见的激活函数进行了总结\",{\"2\":{\"152\":1}}],[\"本文参考自深度学习相关资料与大语言模型技术文档\",{\"2\":{\"334\":1}}],[\"本文内容改编自现有技术文档和代码示例\",{\"2\":{\"2614\":1}}],[\"本文内容改编自原始技术探讨\",{\"2\":{\"327\":1}}],[\"本文内容参考了相关技术文档与研究论文\",{\"2\":{\"2531\":1,\"2542\":1}}],[\"本文内容参考于transformer模型中关于绝对位置编码的技术文档与相关研究分析\",{\"2\":{\"1481\":1}}],[\"本文内容整理自原文链接\",{\"2\":{\"1878\":1}}],[\"本文内容来源于论文\",{\"2\":{\"2202\":1}}],[\"本文内容来源于对\",{\"2\":{\"2017\":1}}],[\"本文内容来源于\",{\"2\":{\"1441\":1}}],[\"本文内容摘自论文\",{\"2\":{\"631\":1}}],[\"本文内容基于某项目中的实验记录与总结\",{\"2\":{\"2701\":1}}],[\"本文内容基于某技术文档关于中文语言模型预训练与tokenizer优化的部分内容整理与总结\",{\"2\":{\"1580\":1}}],[\"本文内容基于提供的文本进行总结与整理\",{\"2\":{\"2476\":1}}],[\"本文内容基于实验文献\",{\"2\":{\"2471\":1}}],[\"本文内容基于技术文档中的显存分析章节\",{\"2\":{\"2377\":1}}],[\"本文内容基于强化学习领域的ppo算法及其应用于actor模型的研究与实践\",{\"2\":{\"1852\":1}}],[\"本文内容基于强化学习分类及策略优化相关资料编写\",{\"2\":{\"892\":1}}],[\"本文内容基于对sft训练的技术分析与实践经验总结\",{\"2\":{\"2350\":1}}],[\"本文内容基于对强化学习中奖励利用与泛化问题的分析和总结\",{\"2\":{\"1709\":1}}],[\"本文内容基于对价值迭代算法的解析\",{\"2\":{\"647\":1}}],[\"本文内容基于palm\",{\"2\":{\"1527\":1}}],[\"本文内容基于deberta模型相关技术文档及论文整理\",{\"2\":{\"1472\":1}}],[\"本文内容基于sarsa算法的理论与实践经验总结\",{\"2\":{\"754\":1}}],[\"本文内容基于大模型预训练技术文档整理与总结\",{\"2\":{\"635\":1}}],[\"本文内容基于论文\",{\"2\":{\"469\":1,\"2368\":1}}],[\"本文内容基于\",{\"2\":{\"153\":1}}],[\"本文解析了大语言模型\",{\"2\":{\"248\":1}}],[\"本文将围绕系统的智能体属性\",{\"2\":{\"1617\":1}}],[\"本文将重点解析如何通过词表扩充\",{\"2\":{\"1153\":1}}],[\"本文将重点解析attention的两种主要形式\",{\"2\":{\"93\":1}}],[\"本文将从智能体数量的角度\",{\"2\":{\"1139\":1}}],[\"本文将从\",{\"2\":{\"1136\":1}}],[\"本文将总结其核心观点\",{\"2\":{\"1067\":1}}],[\"本文将探讨如何通过提示词设计\",{\"2\":{\"2681\":1}}],[\"本文将探讨在神经网络计算中\",{\"2\":{\"2609\":1}}],[\"本文将探讨gemms列并行和transformer中的张量并行技术\",{\"2\":{\"2547\":1}}],[\"本文将探讨grpo的核心公式\",{\"2\":{\"2467\":1}}],[\"本文将探讨几种常用的训练后量化\",{\"2\":{\"1753\":1}}],[\"本文将探讨一种基于文档结构分块的方法\",{\"2\":{\"1334\":1}}],[\"本文将探讨\",{\"2\":{\"1057\":1}}],[\"本文将深入分析lora微调中的初始化影响\",{\"2\":{\"2311\":1}}],[\"本文将深入解析llama\",{\"2\":{\"1028\":1}}],[\"本文将深入探讨这些改进以及其对模型性能的影响\",{\"2\":{\"1026\":1}}],[\"本文将深入探讨贝尔曼期望方程和贝尔曼最优方程\",{\"2\":{\"696\":1}}],[\"本文将详细解析一个用于前向传播\",{\"2\":{\"2539\":1}}],[\"本文将详细解析dpo损失函数的原理\",{\"2\":{\"1620\":1}}],[\"本文将详细探讨文本分块策略的重要性及其对大模型输出的影响\",{\"2\":{\"2303\":1}}],[\"本文将详细探讨文档知识准备阶段的关键步骤\",{\"2\":{\"1185\":1}}],[\"本文将详细探讨\",{\"2\":{\"926\":1,\"2339\":1}}],[\"本文将详细介绍几种常见的文本分块策略\",{\"2\":{\"2552\":1}}],[\"本文将详细介绍几种常见的示例选择方法\",{\"2\":{\"804\":1}}],[\"本文将详细介绍数据并行的概念\",{\"2\":{\"2344\":1}}],[\"本文将详细介绍这些改进方法的核心思想及其实现方式\",{\"2\":{\"1990\":1}}],[\"本文将详细介绍剪枝技术的分类和具体方法\",{\"2\":{\"860\":1}}],[\"本文将详细介绍sarsa算法的核心思想\",{\"2\":{\"577\":1}}],[\"本文将详细介绍位置编码的设计思路\",{\"2\":{\"174\":1}}],[\"本文将介绍三个重要的分布式计算框架\",{\"2\":{\"2320\":1}}],[\"本文将介绍三种agent评估框架\",{\"2\":{\"1118\":1}}],[\"本文将介绍两种常见的工作流\",{\"2\":{\"2089\":1}}],[\"本文将介绍qat的基本原理及其在大语言模型\",{\"2\":{\"1308\":1}}],[\"本文将介绍智能体系统的框架及其应用\",{\"2\":{\"1151\":1}}],[\"本文将介绍一种常用的技巧\",{\"2\":{\"751\":1}}],[\"本文将介绍模型剪枝的基本概念及其流程\",{\"2\":{\"693\":1}}],[\"本文将对这两种算法进行深入分析\",{\"2\":{\"638\":1}}],[\"本文将讨论几种主要的分类概念\",{\"2\":{\"585\":1}}],[\"本文探讨了一种通过奖励修改来优化过长回答的方法\",{\"2\":{\"2686\":1}}],[\"本文探讨了在grpo\",{\"2\":{\"2545\":1}}],[\"本文探讨了在机器学习中使用mixture\",{\"2\":{\"1365\":1}}],[\"本文探讨了深度学习训练阶段的显存消耗\",{\"2\":{\"2099\":1}}],[\"本文探讨了深度学习模型训练过程中显存占用的优化策略\",{\"2\":{\"433\":1}}],[\"本文探讨了两种基于reinforce算法的改进方法\",{\"2\":{\"1783\":1}}],[\"本文探讨了两种针对长上下文扩展的插值方法\",{\"2\":{\"159\":1}}],[\"本文探讨了将这一过程视为单步mdp和多步mdp的不同视角\",{\"2\":{\"1618\":1}}],[\"本文探讨了如何通过冷启动数据和强化学习方法提高模型的推理性能及用户友好性\",{\"2\":{\"2429\":1}}],[\"本文探讨了如何通过减少模型数量来优化ppo\",{\"2\":{\"1841\":1}}],[\"本文探讨了如何通过对比学习的视角来理解dpo\",{\"2\":{\"1517\":1}}],[\"本文探讨了如何通过调整\",{\"2\":{\"1197\":1}}],[\"本文探讨了如何利用打分模型评估数据质量\",{\"2\":{\"425\":1}}],[\"本文探讨了deepseek\",{\"2\":{\"1046\":1}}],[\"本文探讨了通过纯粹的强化学习\",{\"2\":{\"934\":1}}],[\"本文探讨了数据分类\",{\"2\":{\"422\":1}}],[\"本文探讨了以下几个方面\",{\"2\":{\"411\":1}}],[\"本文探讨了几种优化方法\",{\"2\":{\"202\":1}}],[\"本文探讨了layer\",{\"2\":{\"128\":1}}],[\"本文探讨了从mha演变到mla的过程\",{\"2\":{\"111\":1}}],[\"本文探讨了优化attention计算复杂度的几种技术\",{\"2\":{\"109\":1}}],[\"劣势\",{\"2\":{\"400\":1}}],[\"去掉critic\",{\"2\":{\"1954\":1}}],[\"去掉reference\",{\"2\":{\"1954\":1}}],[\"去掉了value\",{\"2\":{\"1576\":1}}],[\"去掉绝对位置的影响\",{\"2\":{\"1266\":1}}],[\"去掉下一句预测任务\",{\"2\":{\"933\":1,\"1145\":1}}],[\"去污染\",{\"2\":{\"1190\":1,\"1337\":1}}],[\"去重和召回\",{\"2\":{\"1190\":1}}],[\"去重处理\",{\"2\":{\"929\":1}}],[\"去重算法\",{\"2\":{\"398\":1}}],[\"去除kl散度约束\",{\"2\":{\"1989\":1}}],[\"去除特殊字符和不相关信息\",{\"2\":{\"1331\":1}}],[\"去除冗余权重\",{\"2\":{\"795\":1}}],[\"去除重复段落或包含错误信息\",{\"2\":{\"548\":1}}],[\"去除目录\",{\"2\":{\"485\":1}}],[\"去除变音符号\",{\"2\":{\"480\":2}}],[\"去停用词\",{\"2\":{\"59\":1}}],[\"领域中\",{\"2\":{\"1136\":1}}],[\"领域\",{\"2\":{\"804\":1,\"1617\":1}}],[\"领域专项模型将成为主流\",{\"2\":{\"633\":1}}],[\"领域语料及指令数据\",{\"2\":{\"567\":1}}],[\"领域语料和指令数据\",{\"2\":{\"475\":1}}],[\"领域继续预训练\",{\"2\":{\"475\":1}}],[\"领域数据比例过高会显著降低模型的通用能力\",{\"2\":{\"566\":1}}],[\"领域数据比例的阈值范围通常为\",{\"2\":{\"501\":1}}],[\"领域数据比例建议控制在\",{\"2\":{\"501\":1}}],[\"领域数据的使用策略\",{\"0\":{\"501\":1}}],[\"领域数据的比例需要严格控制\",{\"2\":{\"422\":1}}],[\"领域数据\",{\"2\":{\"396\":1}}],[\"领域迁移\",{\"2\":{\"57\":1}}],[\"课程学习能否结合强化学习机制\",{\"2\":{\"705\":1}}],[\"课程学习策略可能会进一步细化\",{\"2\":{\"633\":1}}],[\"课程学习概念\",{\"2\":{\"533\":1}}],[\"课程学习可以有效缓解模型遗忘问题\",{\"2\":{\"422\":1}}],[\"课程学习\",{\"2\":{\"396\":1}}],[\"移除kl散度约束\",{\"2\":{\"2143\":1}}],[\"移除kl散度约束项\",{\"2\":{\"1884\":1}}],[\"移除重参数化的编码器以提高训练速度和鲁棒性\",{\"2\":{\"1856\":1}}],[\"移除sft模型的最后非嵌入层\",{\"2\":{\"1631\":1}}],[\"移除\",{\"2\":{\"1353\":1}}],[\"移除对loss影响最小的子词\",{\"2\":{\"393\":1}}],[\"移位操作未正确实现可能导致数据错乱\",{\"2\":{\"241\":1}}],[\"移位逻辑错误\",{\"2\":{\"241\":1}}],[\"移位处理\",{\"2\":{\"156\":1,\"197\":1,\"218\":1}}],[\"移位机制是否适用于其他类型的注意力模型\",{\"2\":{\"333\":1}}],[\"移位机制保证跨组的信息流动\",{\"2\":{\"156\":1}}],[\"移位机制\",{\"2\":{\"136\":1}}],[\"按编号0\",{\"2\":{\"2697\":1}}],[\"按行加总起来以后得到gpu上的\",{\"2\":{\"2673\":1}}],[\"按行维度切成几份\",{\"2\":{\"2641\":1}}],[\"按行为模式分类\",{\"0\":{\"1476\":1},\"1\":{\"1520\":1,\"1569\":1,\"1619\":1,\"1674\":1,\"1730\":1,\"1788\":1,\"1849\":1,\"1906\":1,\"1959\":1,\"2011\":1,\"2060\":1,\"2113\":1,\"2162\":1,\"2205\":1,\"2242\":1,\"2277\":1,\"2309\":1,\"2340\":1,\"2370\":1,\"2398\":1,\"2423\":1,\"2448\":1,\"2469\":1}}],[\"按行级别去重\",{\"2\":{\"644\":1}}],[\"按照这种方式\",{\"2\":{\"2697\":1}}],[\"按照列来分割的技术\",{\"2\":{\"2555\":1}}],[\"按照\",{\"2\":{\"2549\":1}}],[\"按照对权重矩阵aaa的分块方式\",{\"2\":{\"2526\":1}}],[\"按照分割符顺序递归切分\",{\"2\":{\"2141\":1}}],[\"按照一定的顺序提取文本内容\",{\"2\":{\"1716\":1}}],[\"按照文档的自然结构\",{\"2\":{\"1561\":1}}],[\"按照规定的instruction格式\",{\"2\":{\"1368\":1}}],[\"按照数量分类\",{\"0\":{\"1191\":1},\"1\":{\"1241\":1,\"1291\":1,\"1338\":1,\"1384\":1,\"1431\":1}}],[\"按照loss大小排序\",{\"2\":{\"393\":1}}],[\"按文件级别完全匹配去重\",{\"2\":{\"644\":1}}],[\"按书籍覆盖率超过90\",{\"2\":{\"644\":1}}],[\"按比例缩放rope嵌入\",{\"2\":{\"184\":1}}],[\"精确匹配法\",{\"2\":{\"2458\":1}}],[\"精确率\",{\"2\":{\"2354\":1}}],[\"精确\",{\"2\":{\"2155\":1}}],[\"精确注意力\",{\"0\":{\"2057\":1}}],[\"精准的解决方案\",{\"2\":{\"1332\":1}}],[\"精准匹配模型\",{\"2\":{\"207\":1}}],[\"精度=总行动数正确行动数​\",{\"2\":{\"1594\":1}}],[\"精度=正确行动数总行动数\",{\"2\":{\"1594\":1}}],[\"精度则是生成正确行动比率的一个衡量指标\",{\"2\":{\"1594\":1}}],[\"精度\",{\"0\":{\"1594\":1},\"2\":{\"1594\":1}}],[\"精度不可控\",{\"2\":{\"1010\":1}}],[\"精度下降\",{\"2\":{\"591\":1}}],[\"精度可能导致舍入误差累积\",{\"2\":{\"523\":1}}],[\"精度的缩放损失\",{\"2\":{\"435\":1}}],[\"精度的权重\",{\"2\":{\"435\":1}}],[\"精简词表\",{\"2\":{\"393\":1}}],[\"创造新的应用场景\",{\"2\":{\"2258\":1}}],[\"创造信息丰富的\",{\"2\":{\"1333\":1}}],[\"创建了一个新的linear类\",{\"2\":{\"2400\":1}}],[\"创建文本块\",{\"2\":{\"1823\":1}}],[\"创建\",{\"2\":{\"1470\":1}}],[\"创建一个与词汇表长度相等的全0向量\",{\"2\":{\"1025\":1}}],[\"创建一个包含所有字符和高频n\",{\"2\":{\"393\":1}}],[\"创新启示\",{\"0\":{\"1277\":1}}],[\"创新点解析\",{\"0\":{\"2148\":1}}],[\"创新点\",{\"0\":{\"1083\":1},\"2\":{\"264\":1,\"473\":1,\"1359\":1}}],[\"统计模拟\",{\"2\":{\"641\":1}}],[\"统计两个词在语料中一起出现的次数\",{\"2\":{\"499\":1}}],[\"统计频率并合并\",{\"2\":{\"392\":1}}],[\"统一为同一个通用术语\",{\"2\":{\"1376\":1}}],[\"统一文档中的字体\",{\"2\":{\"1331\":1}}],[\"统一处理不同语言的输入\",{\"2\":{\"426\":1}}],[\"统一缩放比例可能破坏嵌入间的小型关系\",{\"2\":{\"335\":1}}],[\"统一认证管理\",{\"2\":{\"198\":1}}],[\"拆分语料为最小单元\",{\"2\":{\"392\":1}}],[\"找出最大值\",{\"2\":{\"1925\":1}}],[\"找出最常见的一对\",{\"2\":{\"391\":1}}],[\"找出输入对应最佳的demonstrations\",{\"2\":{\"1075\":1}}],[\"找到相应的桶\",{\"2\":{\"1559\":1}}],[\"找到最接近测试样本的训练样本\",{\"2\":{\"910\":1}}],[\"找到出现问题的最近step\",{\"2\":{\"593\":1}}],[\"找到语料中频率最高的相邻字符对\",{\"2\":{\"392\":1}}],[\"找到了奋斗的方向\",{\"2\":{\"56\":1}}],[\"找到了学习的一个小目标\",{\"2\":{\"56\":1}}],[\"向学生模型\",{\"2\":{\"749\":1}}],[\"向词汇表中添加基本词汇\",{\"2\":{\"391\":1}}],[\"向量数据库阶段\",{\"0\":{\"2666\":1},\"1\":{\"2669\":1,\"2672\":1,\"2675\":1}}],[\"向量数据库等\",{\"2\":{\"2469\":1}}],[\"向量数据库优化了处理和存储大规模向量数据的效率\",{\"2\":{\"2237\":1}}],[\"向量数据库是一种专门设计用于存储和检索向量数据的数据库系统\",{\"2\":{\"2198\":1}}],[\"向量数据库\",{\"0\":{\"2198\":1},\"1\":{\"2237\":1},\"2\":{\"1950\":1,\"2666\":1}}],[\"向量数据库通常支持这种权重比例的设定\",{\"2\":{\"1949\":1}}],[\"向量化工具的选择\",{\"2\":{\"1450\":1}}],[\"向量乘法对每个矩阵元素执行一次乘加运算\",{\"2\":{\"2043\":1}}],[\"向量乘法和attention计算是推理过程中的核心操作\",{\"2\":{\"580\":1}}],[\"向量乘法的浮点运算\",{\"2\":{\"376\":1}}],[\"向量乘法\",{\"2\":{\"351\":1,\"1991\":1}}],[\"向量和数组\",{\"2\":{\"16\":2}}],[\"包含了大量的优化技巧\",{\"2\":{\"2351\":1}}],[\"包含23种中文nlp任务的数据\",{\"2\":{\"2184\":1}}],[\"包含26个英文字母及常见符号\",{\"2\":{\"381\":1}}],[\"包含以下三种类型\",{\"2\":{\"1947\":1}}],[\"包含一些建议\",{\"2\":{\"1368\":1}}],[\"包含一个high\",{\"2\":{\"1368\":1}}],[\"包含模型应该避免的内容或规则\",{\"2\":{\"1368\":1}}],[\"包含800万个文档\",{\"2\":{\"1104\":1}}],[\"包含50k的子词单元\",{\"2\":{\"1096\":1}}],[\"包含llama3和llama3\",{\"2\":{\"1028\":1}}],[\"包括其特点\",{\"2\":{\"2552\":1}}],[\"包括其思维及其状态的历史记录\",{\"2\":{\"2262\":1}}],[\"包括值迭代\",{\"2\":{\"2317\":1}}],[\"包括refgpt\",{\"2\":{\"2258\":1}}],[\"包括以下几种方法\",{\"2\":{\"2213\":1}}],[\"包括最大长度\",{\"2\":{\"2194\":1}}],[\"包括两个阶段\",{\"2\":{\"2171\":1}}],[\"包括激活值\",{\"2\":{\"2161\":1}}],[\"包括模型参数\",{\"2\":{\"2161\":1}}],[\"包括多卡并行\",{\"2\":{\"1972\":1}}],[\"包括多样性权重和质量权重\",{\"2\":{\"446\":1}}],[\"包括所使用的语言模型的性能\",{\"2\":{\"1895\":1}}],[\"包括所使用语言模型的性能\",{\"2\":{\"1775\":1}}],[\"包括第一个提示本身\",{\"2\":{\"1885\":1}}],[\"包括上下文相关性和答案相关性\",{\"2\":{\"1356\":1}}],[\"包括上文和当前生成的token序列\",{\"2\":{\"581\":1}}],[\"包括决策和行动\",{\"2\":{\"1336\":1}}],[\"包括启发式过滤器\",{\"2\":{\"1167\":1}}],[\"包括启发式方法\",{\"2\":{\"804\":1}}],[\"包括base和instruct版本\",{\"2\":{\"1156\":1}}],[\"包括加入预训练损失\",{\"2\":{\"1123\":1}}],[\"包括可扩展的数学预训练和对强化学习的探索与分析\",{\"2\":{\"1046\":1}}],[\"包括prm\",{\"2\":{\"1013\":1}}],[\"包括理解人类意图\",{\"2\":{\"967\":1}}],[\"包括cc\",{\"2\":{\"933\":1,\"1052\":1}}],[\"包括网页\",{\"2\":{\"929\":1}}],[\"包括更大的模型参数\",{\"2\":{\"898\":1}}],[\"包括高昂的计算成本和延迟问题\",{\"2\":{\"728\":1}}],[\"包括百科\",{\"2\":{\"651\":1}}],[\"包括在线与离线学习\",{\"2\":{\"585\":1}}],[\"包括示例和任务描述\",{\"2\":{\"536\":1}}],[\"包括\",{\"2\":{\"480\":1,\"1404\":1,\"1917\":1,\"1990\":1,\"2049\":1,\"2308\":1,\"2430\":1}}],[\"包括url过滤\",{\"2\":{\"403\":1}}],[\"包括数据标准化\",{\"2\":{\"373\":1}}],[\"包括进制表示\",{\"2\":{\"202\":1}}],[\"包括它们的优缺点\",{\"2\":{\"152\":1}}],[\"包括中间的优化方法如mqa\",{\"2\":{\"111\":1}}],[\"包括sparse\",{\"2\":{\"109\":1}}],[\"准确实现kl散度的无偏估计\",{\"2\":{\"2524\":1}}],[\"准确性和检索效率\",{\"2\":{\"2484\":1}}],[\"准确的价值模型有助于利用探索过程中产生的样本\",{\"2\":{\"2157\":1}}],[\"准确且响应迅速的代码解释器\",{\"2\":{\"1740\":1}}],[\"准确地找到相关信息\",{\"2\":{\"1235\":1}}],[\"准确地从知识库中检索并生成答案\",{\"2\":{\"1185\":1}}],[\"准确率为1的样本比例上升时\",{\"2\":{\"2530\":1}}],[\"准确率为1的样本会增多\",{\"2\":{\"2507\":1}}],[\"准确率\",{\"2\":{\"39\":1,\"91\":1,\"1324\":1,\"2354\":1}}],[\"准备与训练集一致的高质量评测集合\",{\"2\":{\"2233\":1}}],[\"准备长文本和插入关键信息\",{\"2\":{\"800\":1}}],[\"准备数据集\",{\"2\":{\"651\":1}}],[\"准备基础词表\",{\"2\":{\"381\":1,\"392\":1}}],[\"阶段的\",{\"2\":{\"2263\":2}}],[\"阶段加入特殊场景的任务数据\",{\"2\":{\"2245\":1}}],[\"阶段不应停留太久\",{\"2\":{\"1213\":1}}],[\"阶段\",{\"2\":{\"369\":1,\"1213\":1,\"1436\":1,\"2228\":2,\"2278\":1,\"2308\":1}}],[\"又称为\",{\"2\":{\"2603\":1}}],[\"又称核采样\",{\"2\":{\"340\":1}}],[\"又不会过长以至于增加噪声或使向量表示模糊不清\",{\"2\":{\"2393\":1}}],[\"又实现多样性输出\",{\"2\":{\"564\":1}}],[\"又能增强相对位置信息的表达\",{\"2\":{\"1481\":1}}],[\"又能保持模型的高精度\",{\"2\":{\"408\":1}}],[\"又能处理稀有词\",{\"2\":{\"366\":1}}],[\"略长\",{\"2\":{\"365\":1}}],[\"权衡成本与效果\",{\"2\":{\"465\":1}}],[\"权衡理解与生成能力\",{\"2\":{\"363\":1}}],[\"权重计算\",{\"0\":{\"2597\":1}}],[\"权重裁剪\",{\"2\":{\"2261\":1}}],[\"权重并不是同等重要的\",{\"2\":{\"2085\":1}}],[\"权重采用\",{\"2\":{\"2033\":1}}],[\"权重比例为\",{\"2\":{\"1949\":1}}],[\"权重矩阵拆分\",{\"2\":{\"1770\":1}}],[\"权重分解\",{\"2\":{\"1604\":1}}],[\"权重分布可结合动态调整提升性能\",{\"2\":{\"236\":1}}],[\"权重分布影响信息聚合效果\",{\"2\":{\"236\":1}}],[\"权重初始化\",{\"2\":{\"1248\":1,\"1437\":1}}],[\"权重大小\",{\"2\":{\"1050\":1}}],[\"权重的量化是最常规的\",{\"2\":{\"799\":1}}],[\"权重\",{\"2\":{\"799\":1,\"2145\":1}}],[\"权重更新更稳定\",{\"2\":{\"215\":1,\"330\":1}}],[\"权重更新可能偏向特定方向\",{\"2\":{\"194\":1}}],[\"互信息\",{\"2\":{\"499\":1}}],[\"互信息得分计算如下\",{\"2\":{\"355\":1}}],[\"互信息的公式\",{\"2\":{\"355\":1}}],[\"工作者\",{\"0\":{\"2089\":1},\"2\":{\"2089\":2}}],[\"工作流适用于以下两种情况\",{\"2\":{\"2259\":1}}],[\"工作流不同\",{\"2\":{\"2224\":1}}],[\"工作流可以发挥其动态分配和综合结果的优势\",{\"2\":{\"2185\":1}}],[\"工作流的关键区别在于灵活性\",{\"2\":{\"2139\":1}}],[\"工作流系统通过将任务分解为预定义的步骤\",{\"2\":{\"1595\":1}}],[\"工作流是通过预定义代码路径编排\",{\"2\":{\"1269\":1}}],[\"工作流\",{\"0\":{\"1269\":1,\"1595\":1,\"2224\":1},\"1\":{\"1649\":1,\"1702\":1,\"1760\":1,\"1820\":1,\"1879\":1,\"1935\":1,\"1985\":1,\"2037\":1,\"2089\":1,\"2139\":1,\"2185\":1,\"2224\":1,\"2259\":1,\"2294\":1},\"2\":{\"2089\":2,\"2185\":1,\"2224\":1,\"2325\":2}}],[\"工作原理\",{\"0\":{\"636\":1,\"2141\":1,\"2452\":1},\"1\":{\"670\":1,\"708\":1,\"742\":1}}],[\"工业界目前最常用的量化位数是8比特\",{\"2\":{\"768\":1}}],[\"工程优化\",{\"2\":{\"502\":1,\"567\":1}}],[\"工程实践建议\",{\"0\":{\"353\":1}}],[\"工具使用\",{\"0\":{\"2269\":1}}],[\"工具使用和错误恢复能力上的成熟\",{\"2\":{\"1408\":1}}],[\"工具\",{\"2\":{\"1674\":1,\"2235\":2}}],[\"工具如\",{\"2\":{\"1412\":1}}],[\"工具定义\",{\"2\":{\"1392\":1}}],[\"工具建议\",{\"2\":{\"1263\":1}}],[\"工具调用频率控制\",{\"2\":{\"1740\":1}}],[\"工具调用的结果或代码执行的情况会成为其判断下一步行动的重要依据\",{\"2\":{\"1454\":1}}],[\"工具调用\",{\"2\":{\"1233\":1}}],[\"工具选择\",{\"2\":{\"240\":1}}],[\"工具文档\",{\"2\":{\"67\":1,\"106\":1,\"165\":1,\"230\":1,\"302\":1,\"375\":1}}],[\"工具与资源推荐\",{\"0\":{\"65\":1}}],[\"像\",{\"2\":{\"728\":1}}],[\"像arxiv和wikipedia等精心构建的数据集内容也会被过滤\",{\"2\":{\"456\":1}}],[\"像yarn这样的方法可能会被更广泛地应用于大语言模型\",{\"2\":{\"346\":1}}],[\"像是西瓜书和实战\",{\"2\":{\"56\":1}}],[\"偶数维度\",{\"2\":{\"332\":1}}],[\"复杂搜索任务的多轮优化\",{\"2\":{\"2294\":1}}],[\"复杂行为表现\",{\"0\":{\"2122\":1}}],[\"复杂任务的拆解与执行是一个重要的研究课题\",{\"2\":{\"2089\":1}}],[\"复杂任务可以被拆解为多个子任务\",{\"2\":{\"1384\":1}}],[\"复杂的奖励策略以及丰富的基准测试环境\",{\"2\":{\"1860\":1}}],[\"复杂的任务\",{\"2\":{\"1291\":1}}],[\"复杂性\",{\"2\":{\"1562\":1}}],[\"复杂分类效果一般\",{\"2\":{\"330\":1}}],[\"复杂度降低为o\",{\"2\":{\"1179\":1}}],[\"复杂度是o\",{\"2\":{\"1179\":1}}],[\"复杂度\",{\"2\":{\"315\":1}}],[\"复杂度优化\",{\"2\":{\"305\":1}}],[\"复杂度导致内存瓶颈\",{\"2\":{\"57\":1}}],[\"负责协调整个推理过程\",{\"2\":{\"2227\":1}}],[\"负责准备用于\",{\"2\":{\"2227\":1}}],[\"负责评估该响应并给出反馈\",{\"2\":{\"2224\":1}}],[\"负责生成响应\",{\"2\":{\"2224\":1}}],[\"负责决策的模型\",{\"2\":{\"2004\":1}}],[\"负责系统内多个服务的协调\",{\"2\":{\"118\":1}}],[\"负样本之间的距离计算\",{\"2\":{\"1727\":1}}],[\"负样本的距离\",{\"2\":{\"1566\":1}}],[\"负类走左子树\",{\"2\":{\"980\":1}}],[\"负载均衡损失计算如下\",{\"2\":{\"1279\":1}}],[\"负载均衡损失设计\",{\"0\":{\"1279\":1}}],[\"负载均衡\",{\"0\":{\"1180\":1},\"1\":{\"1229\":1,\"1279\":1,\"1326\":1},\"2\":{\"908\":1,\"988\":1,\"1000\":1}}],[\"负采样时未正确选择负样本会影响训练效果\",{\"2\":{\"1066\":1}}],[\"负采样通过只更新部分权重来减少计算量\",{\"2\":{\"983\":1}}],[\"负采样\",{\"0\":{\"983\":1},\"2\":{\"835\":1}}],[\"负输入有梯度\",{\"2\":{\"330\":1}}],[\"改写可以通过强大模型完成\",{\"2\":{\"2168\":1}}],[\"改善用户提问的质量\",{\"2\":{\"1496\":1}}],[\"改善dead\",{\"2\":{\"330\":1}}],[\"改进措施\",{\"2\":{\"2327\":1}}],[\"改进方法\",{\"0\":{\"1548\":1,\"1990\":1},\"1\":{\"1598\":1,\"1652\":1,\"2042\":1,\"2094\":1,\"2144\":1,\"2188\":1,\"2227\":1,\"2262\":1}}],[\"改进方向\",{\"0\":{\"1388\":1}}],[\"改进点\",{\"0\":{\"1266\":1}}],[\"改进了\",{\"2\":{\"261\":1}}],[\"改变注意力机制的计算顺序\",{\"2\":{\"2008\":1}}],[\"改变了序列化表述\",{\"2\":{\"1198\":1}}],[\"改变\",{\"2\":{\"1111\":1,\"1436\":1}}],[\"改为在全局共享一份\",{\"2\":{\"1048\":1}}],[\"矩阵某一行的向量为\",{\"2\":{\"2492\":1}}],[\"矩阵也切为\",{\"2\":{\"2286\":1}}],[\"矩阵切为\",{\"2\":{\"2286\":2}}],[\"矩阵初始化策略\",{\"0\":{\"2062\":1}}],[\"矩阵乘法和逐点操作的分块计算是容易实现的\",{\"2\":{\"1872\":1}}],[\"矩阵乘法\",{\"2\":{\"1872\":1,\"2080\":2}}],[\"矩阵b的学习率为lr\",{\"2\":{\"1771\":1}}],[\"矩阵a的学习率为lr\",{\"2\":{\"1771\":1}}],[\"矩阵作为知识\",{\"2\":{\"880\":1}}],[\"矩阵\",{\"2\":{\"351\":1,\"376\":1,\"580\":1,\"1991\":1,\"2043\":1,\"2616\":1}}],[\"矩阵维度匹配问题\",{\"2\":{\"338\":1}}],[\"矩阵计算的并行化是提升模型训练和推理速度的关键\",{\"2\":{\"2547\":1}}],[\"矩阵计算\",{\"2\":{\"328\":1}}],[\"矩阵拼接\",{\"2\":{\"125\":1}}],[\"完全拒绝回答问题\",{\"2\":{\"2540\":1}}],[\"完全一致\",{\"2\":{\"926\":1}}],[\"完整性\",{\"2\":{\"2257\":1}}],[\"完整的\",{\"2\":{\"1885\":1}}],[\"完整代码与实现可参考\",{\"2\":{\"327\":1}}],[\"完成汇总操作后\",{\"2\":{\"2452\":1}}],[\"完成量化\",{\"2\":{\"1813\":1}}],[\"完成模型计算后\",{\"2\":{\"1782\":2}}],[\"完成了从输入到思维链再到输出的映射\",{\"2\":{\"1708\":1}}],[\"完成训练后\",{\"2\":{\"826\":1}}],[\"完成yarn的实现\",{\"2\":{\"184\":1}}],[\"完成更深层次的学习与计算\",{\"2\":{\"121\":1}}],[\"捕捉样本之间的关系\",{\"2\":{\"880\":1}}],[\"捕捉通用特征和模式\",{\"2\":{\"449\":1,\"503\":1}}],[\"捕捉像素之间的关联\",{\"2\":{\"326\":1}}],[\"捕捉全局语义信息\",{\"2\":{\"34\":1}}],[\"较小的分块可能更适合捕捉每个帖子的精确语义\",{\"2\":{\"2655\":1}}],[\"较小的模型不仅具备强大的推理能力\",{\"2\":{\"1224\":1}}],[\"较远位置\",{\"2\":{\"1306\":1}}],[\"较好地平衡了词表大小和未登录词问题\",{\"2\":{\"434\":1}}],[\"较短\",{\"2\":{\"365\":1}}],[\"较弱\",{\"2\":{\"365\":1}}],[\"较大的分块有助于保留更多上下文和主题连贯性\",{\"2\":{\"2655\":1}}],[\"较大模型的推理模式可以很好地蒸馏到较小模型\",{\"2\":{\"1195\":1}}],[\"较大\",{\"2\":{\"365\":1}}],[\"较低\",{\"2\":{\"315\":1,\"365\":1}}],[\"较高\",{\"2\":{\"315\":1,\"365\":1}}],[\"🤔\",{\"0\":{\"310\":1},\"1\":{\"333\":1}}],[\"🧪\",{\"2\":{\"196\":1,\"256\":1}}],[\"个等大小的\",{\"2\":{\"2374\":1}}],[\"个输出的奖励值\",{\"2\":{\"2306\":1}}],[\"个\",{\"2\":{\"2137\":1,\"2286\":3}}],[\"个近邻\",{\"2\":{\"2102\":1}}],[\"个项目左右\",{\"2\":{\"1998\":1}}],[\"个token的结果\",{\"2\":{\"2379\":1}}],[\"个token的batch\",{\"2\":{\"1279\":1}}],[\"个token过attention后的输出结果\",{\"2\":{\"2379\":1}}],[\"个token间的原始相关性分数\",{\"2\":{\"2318\":1}}],[\"个token和前\",{\"2\":{\"2318\":1,\"2379\":1}}],[\"个token\",{\"2\":{\"1843\":1}}],[\"个字符\",{\"2\":{\"1763\":2,\"1937\":1,\"1987\":1}}],[\"个字符的重叠\",{\"2\":{\"1598\":1}}],[\"个查询\",{\"2\":{\"1756\":1}}],[\"个查询中第一个相关结果的排名\",{\"2\":{\"1644\":1}}],[\"个结果匹配分数为\",{\"2\":{\"1644\":1}}],[\"个专家的概率总和\",{\"2\":{\"1279\":1,\"1326\":1}}],[\"个专家的token数\",{\"2\":{\"1279\":1,\"1326\":1}}],[\"个专家和包含\",{\"2\":{\"1279\":1}}],[\"个合适的示例\",{\"2\":{\"1273\":1}}],[\"个回答\",{\"2\":{\"528\":1}}],[\"个候选序列\",{\"2\":{\"324\":1}}],[\"个词\",{\"2\":{\"324\":1}}],[\"个词中随机选择的方法\",{\"2\":{\"295\":1}}],[\"个人见解\",{\"0\":{\"280\":1,\"289\":1,\"727\":1},\"1\":{\"304\":1}}],[\"个人观点对比表格\",{\"0\":{\"1259\":1}}],[\"个人观点对比\",{\"0\":{\"326\":1}}],[\"个人观点\",{\"0\":{\"236\":1,\"257\":1,\"610\":1,\"1163\":1},\"2\":{\"236\":1,\"257\":1,\"326\":1,\"610\":1,\"1163\":1,\"1259\":1}}],[\"具有更高的特征学习效率\",{\"2\":{\"2372\":1}}],[\"具有显存利用率高\",{\"2\":{\"2129\":1}}],[\"具有降低模型复杂性和内存使用的优势\",{\"2\":{\"1094\":1}}],[\"具体架构如下\",{\"2\":{\"2579\":1}}],[\"具体出处请参阅相关文献\",{\"2\":{\"2531\":1,\"2542\":1}}],[\"具体在多代理选取哪些优化步骤尚未有确切定论\",{\"2\":{\"2335\":1}}],[\"具体包括以下部分\",{\"2\":{\"2227\":1}}],[\"具体包括以下几个方面\",{\"2\":{\"1500\":1}}],[\"具体实现\",{\"0\":{\"2072\":1,\"2348\":1},\"1\":{\"2124\":1,\"2171\":1,\"2213\":1,\"2250\":1,\"2378\":1,\"2405\":1,\"2430\":1,\"2455\":1}}],[\"具体而言\",{\"2\":{\"2011\":1,\"2059\":1,\"2195\":1}}],[\"具体方法\",{\"0\":{\"1959\":1,\"2487\":1},\"1\":{\"2011\":1,\"2060\":1,\"2501\":1,\"2514\":1,\"2525\":1,\"2536\":1,\"2546\":1,\"2554\":1,\"2562\":1,\"2570\":1,\"2578\":1,\"2586\":1,\"2594\":1,\"2601\":1,\"2608\":1,\"2615\":1}}],[\"具体总结\",{\"0\":{\"1917\":1}}],[\"具体过程如下\",{\"2\":{\"1885\":1}}],[\"具体做法\",{\"0\":{\"1740\":1,\"2235\":1,\"2286\":1},\"1\":{\"2318\":1,\"2349\":1,\"2379\":1,\"2406\":1,\"2431\":1,\"2456\":1,\"2475\":1}}],[\"具体内容可以参考3\",{\"2\":{\"1641\":1}}],[\"具体公式为\",{\"2\":{\"2692\":1}}],[\"具体公式与理论参考原始论文\",{\"2\":{\"1472\":1}}],[\"具体公式如下\",{\"2\":{\"537\":1,\"1246\":1}}],[\"具体指令\",{\"2\":{\"1420\":1}}],[\"具体答案寻求索引\",{\"2\":{\"1285\":1}}],[\"具体定义如下\",{\"2\":{\"1222\":1}}],[\"具体来源及采样比例如下表所示\",{\"2\":{\"1211\":1}}],[\"具体来说\",{\"2\":{\"750\":1,\"949\":1,\"1160\":1,\"1275\":1,\"1332\":1,\"1465\":1,\"1561\":1,\"1572\":1,\"1613\":1,\"1681\":1,\"2042\":1,\"2418\":1,\"2436\":1,\"2608\":1}}],[\"具体的实现细节如下所示\",{\"2\":{\"917\":1}}],[\"具体步骤包括\",{\"2\":{\"997\":1}}],[\"具体步骤包括采样序列\",{\"2\":{\"747\":1}}],[\"具体步骤如下\",{\"2\":{\"795\":1,\"826\":1,\"1075\":1,\"1771\":1}}],[\"具体问题具体分析\",{\"2\":{\"39\":1}}],[\"具备完整的\",{\"2\":{\"2081\":1}}],[\"具备更高级的语言分析能力\",{\"2\":{\"1896\":1}}],[\"具备较强的推理能力\",{\"2\":{\"1289\":1}}],[\"具备多语言支持\",{\"2\":{\"373\":1}}],[\"具备强大的零样本\",{\"2\":{\"294\":1}}],[\"映射\",{\"2\":{\"1353\":1}}],[\"映射值\",{\"2\":{\"1258\":1}}],[\"映射规则如下\",{\"2\":{\"1258\":1}}],[\"映射到低维向量空间的技术\",{\"2\":{\"882\":1}}],[\"映射拥挤\",{\"2\":{\"292\":1}}],[\"映射至训练范围\",{\"2\":{\"291\":1}}],[\"映射位置索引\",{\"2\":{\"291\":1}}],[\"映射关系拥挤\",{\"2\":{\"246\":1}}],[\"短对话可能会被低估\",{\"2\":{\"2331\":1}}],[\"短时记忆的容量通常为\",{\"2\":{\"1998\":1}}],[\"短时记忆存储我们当前意识到的信息\",{\"2\":{\"1998\":1}}],[\"短时记忆\",{\"0\":{\"1998\":1}}],[\"短期记忆指的是利用模型的短期记忆进行学习的能力\",{\"2\":{\"1772\":1}}],[\"短期记忆\",{\"0\":{\"1772\":1}}],[\"短期记忆与长期记忆\",{\"0\":{\"1715\":1},\"1\":{\"1772\":1,\"1833\":1}}],[\"短文本块可能缺乏必要的上下文信息\",{\"2\":{\"2511\":1}}],[\"短文本的梯度更集中\",{\"2\":{\"2278\":1}}],[\"短文本推理\",{\"2\":{\"1324\":1}}],[\"短文本和长文本各自\",{\"2\":{\"847\":1}}],[\"短波长维度\",{\"2\":{\"290\":1}}],[\"短小的代码段\",{\"2\":{\"27\":1}}],[\"波长不均问题\",{\"2\":{\"335\":1}}],[\"波长定义\",{\"2\":{\"290\":1}}],[\"波长与上下文长度的关系\",{\"0\":{\"267\":1},\"1\":{\"290\":1,\"312\":1}}],[\"原论文也是这么分析的\",{\"2\":{\"2653\":1}}],[\"原有问题\",{\"2\":{\"2327\":1}}],[\"原有方法对重要性权重的裁剪阈值设置较低\",{\"2\":{\"2296\":1}}],[\"原因同上\",{\"2\":{\"1782\":1}}],[\"原因是性能优化不足\",{\"2\":{\"1404\":1}}],[\"原问题\",{\"2\":{\"1774\":1}}],[\"原理\",{\"0\":{\"1665\":1}}],[\"原版bert在算力上有所限制\",{\"2\":{\"1012\":1}}],[\"原文链接\",{\"2\":{\"2451\":1}}],[\"原文链接或出处信息\",{\"2\":{\"2244\":1}}],[\"原文链接或书名章节\",{\"2\":{\"1921\":1}}],[\"原文提供者未注明\",{\"2\":{\"1880\":1}}],[\"原文摘录并改编自技术资料\",{\"2\":{\"1263\":1}}],[\"原文参考\",{\"2\":{\"1261\":1}}],[\"原文参考自\",{\"2\":{\"299\":1}}],[\"原文详述了ulm在自然语言处理中的应用与实现细节\",{\"2\":{\"563\":1}}],[\"原文出处\",{\"2\":{\"358\":1,\"361\":1,\"362\":1,\"409\":1,\"694\":1,\"705\":1,\"851\":1,\"1008\":1,\"1310\":1,\"1406\":1,\"1508\":1,\"1577\":1,\"1852\":1,\"2075\":1}}],[\"原文来源\",{\"2\":{\"350\":1,\"2187\":1}}],[\"原文内容基于深度学习与强化学习结合的技术文档\",{\"2\":{\"1934\":1}}],[\"原文内容来源于相关技术文档和学习资料\",{\"2\":{\"965\":1}}],[\"原文内容整理自深度学习相关博客笔记\",{\"2\":{\"1606\":1}}],[\"原文内容整理自关于监督微调与预训练的比较分析\",{\"2\":{\"1528\":1}}],[\"原文内容整理自技术文档\",{\"2\":{\"771\":1}}],[\"原文内容整理自自然语言处理领域基础知识\",{\"2\":{\"564\":1}}],[\"原文内容参考\",{\"2\":{\"660\":1}}],[\"原文内容\",{\"2\":{\"284\":1,\"2215\":1}}],[\"原始文档内容未提供具体出处信息\",{\"2\":{\"2629\":1,\"2674\":1}}],[\"原始文本内容来自于技术文档\",{\"2\":{\"2121\":1}}],[\"原始文本来源未提供\",{\"2\":{\"2551\":1}}],[\"原始文本来源\",{\"2\":{\"1386\":1}}],[\"原始文本摘自强化学习教材\",{\"2\":{\"797\":1}}],[\"原始值\",{\"2\":{\"2479\":1}}],[\"原始裁剪阈值设置过低\",{\"2\":{\"2414\":1}}],[\"原始裁剪阈值设置为\",{\"2\":{\"2327\":1}}],[\"原始grpo公式\",{\"2\":{\"2187\":3}}],[\"原始推导参考\",{\"2\":{\"2148\":1}}],[\"原始权重\",{\"2\":{\"2085\":1}}],[\"原始内存需求\",{\"2\":{\"2065\":1}}],[\"原始内容提供者不详\",{\"2\":{\"1144\":1}}],[\"原始内容摘自关于蒙特卡洛方法的技术文档\",{\"2\":{\"993\":1}}],[\"原始内容摘自某技术文档\",{\"2\":{\"850\":1}}],[\"原始内容选自大海捞针与概率探针测试文档\",{\"2\":{\"770\":1}}],[\"原始内容来自技术文档关于clip\",{\"2\":{\"2479\":1}}],[\"原始内容来自peft\",{\"2\":{\"2142\":1}}],[\"原始内容来自用户提供的文本\",{\"2\":{\"2065\":1}}],[\"原始内容来自知乎\",{\"2\":{\"1839\":1}}],[\"原始内容来自switch\",{\"2\":{\"1417\":1}}],[\"原始内容来自于某强化学习教程\",{\"2\":{\"824\":1}}],[\"原始内容来自某技术文档或研究论文\",{\"2\":{\"709\":1}}],[\"原始内容来源\",{\"2\":{\"413\":1,\"909\":1}}],[\"原始约束目标\",{\"0\":{\"1552\":1}}],[\"原始来源\",{\"2\":{\"1276\":1}}],[\"原始的transformer\",{\"2\":{\"1009\":1}}],[\"原始出处未提供\",{\"2\":{\"647\":1,\"2564\":1}}],[\"原始出处\",{\"2\":{\"240\":1,\"300\":1,\"303\":1,\"466\":1,\"628\":1,\"685\":1,\"740\":1,\"776\":1,\"818\":1,\"864\":1,\"876\":1,\"913\":1,\"994\":1,\"1140\":1,\"1239\":1,\"1257\":1,\"1324\":1,\"1339\":1,\"1364\":1,\"1369\":1,\"1372\":1,\"1385\":1,\"1386\":1,\"1387\":1,\"1395\":1,\"1403\":1,\"1455\":1,\"1462\":1,\"1475\":1,\"1481\":1,\"1580\":1,\"1647\":1,\"1651\":1,\"1811\":1,\"1814\":1,\"1880\":1,\"1902\":1,\"1921\":1,\"1953\":1,\"1961\":1,\"1997\":1,\"2003\":1,\"2048\":1,\"2061\":1,\"2078\":1,\"2111\":1,\"2120\":1,\"2140\":1,\"2174\":1,\"2182\":1,\"2199\":1,\"2214\":1,\"2215\":1,\"2229\":1,\"2244\":1,\"2265\":1,\"2289\":1,\"2345\":1,\"2360\":1,\"2377\":1,\"2391\":1,\"2434\":1,\"2446\":1,\"2451\":1,\"2476\":1,\"2478\":1,\"2524\":1,\"2614\":1,\"2629\":1,\"2674\":1,\"2701\":1}}],[\"原始输入维度\",{\"2\":{\"220\":1}}],[\"引导\",{\"2\":{\"1885\":1}}],[\"引导基础模型遵循指令\",{\"2\":{\"1859\":1}}],[\"引导层\",{\"2\":{\"845\":1}}],[\"引发目标网站封禁\",{\"2\":{\"594\":1}}],[\"引用块\",{\"2\":{\"2258\":1}}],[\"引用自提供的文本内容\",{\"2\":{\"2075\":1}}],[\"引用\",{\"2\":{\"1920\":1}}],[\"引用与参考文献格式\",{\"2\":{\"428\":1}}],[\"引用来源\",{\"2\":{\"284\":1,\"719\":1,\"1606\":1,\"2479\":1}}],[\"引入语言一致性奖励是提升模型在多语言环境下表现的创新方法\",{\"2\":{\"2548\":1}}],[\"引入混合检索和图结构优化\",{\"2\":{\"2499\":1}}],[\"引入统计量以优化计算顺序\",{\"2\":{\"2160\":1}}],[\"引入动态采样\",{\"2\":{\"1989\":1}}],[\"引入额外的统计量\",{\"0\":{\"1980\":1}}],[\"引入多任务学习进行预训练\",{\"2\":{\"1856\":1}}],[\"引入4\",{\"2\":{\"1855\":1}}],[\"引入行为约束项的奖励函数设计\",{\"2\":{\"1799\":1}}],[\"引入零初始化的注意力机制以保持预训练知识\",{\"2\":{\"1779\":1}}],[\"引入配分函数\",{\"0\":{\"1769\":1},\"1\":{\"1830\":1}}],[\"引入超参数\",{\"2\":{\"1740\":1}}],[\"引入重叠\",{\"0\":{\"1598\":1}}],[\"引入相对位置信息\",{\"2\":{\"1405\":1}}],[\"引入相对位置向量\",{\"2\":{\"1266\":1}}],[\"引入了更多模块化设计\",{\"2\":{\"2366\":1}}],[\"引入了渐进的奖励归一化策略\",{\"2\":{\"2213\":1}}],[\"引入了多种新的指标\",{\"2\":{\"1453\":1}}],[\"引入了可学习的位置编码\",{\"2\":{\"1388\":1}}],[\"引入了一种哈希函数\",{\"2\":{\"2152\":1}}],[\"引入了一种基于\",{\"2\":{\"1224\":1}}],[\"引入了一次性剪枝策略\",{\"2\":{\"1050\":1}}],[\"引入偏置项\",{\"2\":{\"1353\":1}}],[\"引入细粒度专家分割是提高语言模型效率的关键创新\",{\"2\":{\"1220\":1}}],[\"引入辅助损失函数以确保负载均衡\",{\"2\":{\"1219\":1}}],[\"引入mqa\",{\"2\":{\"1198\":1}}],[\"引入通信平衡损失以确保设备负载均衡\",{\"2\":{\"1120\":1}}],[\"引入目标网络来计算td目标\",{\"2\":{\"746\":1}}],[\"引入一个小量$$\",{\"2\":{\"646\":1}}],[\"引入z\",{\"2\":{\"593\":1}}],[\"引入\",{\"2\":{\"502\":1,\"2081\":1}}],[\"引入门控机制\",{\"2\":{\"199\":1}}],[\"引入温度参数统一影响困惑度\",{\"2\":{\"184\":1}}],[\"引入整个\",{\"2\":{\"27\":1}}],[\"确认全局专家副本数量\",{\"2\":{\"1502\":1}}],[\"确认前馈网络激活函数已更改为\",{\"2\":{\"1141\":1}}],[\"确认词表大小调整至\",{\"2\":{\"1141\":1}}],[\"确认任务类型\",{\"2\":{\"380\":1}}],[\"确定过长回答的阈值\",{\"2\":{\"2695\":1}}],[\"确定当前优势值是否为正\",{\"2\":{\"2387\":1}}],[\"确定当前选择答案在sft和policy模型中的采样概率\",{\"2\":{\"1966\":1}}],[\"确定数据类型\",{\"2\":{\"2266\":1}}],[\"确定模型参数量\",{\"2\":{\"2263\":1}}],[\"确定模型结构调整\",{\"2\":{\"1264\":1}}],[\"确定模型结构\",{\"2\":{\"1203\":1,\"1542\":1}}],[\"确定任务目标\",{\"2\":{\"2200\":1}}],[\"确定任务类型并定义合适的\",{\"2\":{\"2082\":1}}],[\"确定需要微调的模型及其任务\",{\"2\":{\"2034\":1}}],[\"确定正样本\",{\"2\":{\"1784\":1}}],[\"确定每个部分的风格和内容\",{\"2\":{\"1773\":1}}],[\"确定哪些信息应该包含在上下文中\",{\"2\":{\"1550\":1}}],[\"确定gpu数量用于装载专家\",{\"2\":{\"1502\":1}}],[\"确定可用计算预算\",{\"2\":{\"1374\":1}}],[\"确定最佳模型大小和数据集规模\",{\"2\":{\"1132\":1}}],[\"确定ppo优化目标\",{\"2\":{\"1123\":1}}],[\"确定性策略和随机性策略的选择对强化学习结果有何影响\",{\"2\":{\"915\":1}}],[\"确定性或随机性\",{\"2\":{\"844\":1}}],[\"确定状态和动作集合\",{\"2\":{\"831\":1}}],[\"确定动作空间和状态转移方式\",{\"2\":{\"649\":1}}],[\"确定处理单元\",{\"2\":{\"644\":1}}],[\"确定专家网络数目\",{\"2\":{\"560\":1}}],[\"确定目标长度\",{\"2\":{\"359\":1}}],[\"确定目标上下文长度\",{\"2\":{\"291\":1}}],[\"确定缩放因子\",{\"2\":{\"291\":1}}],[\"确定输入序列的长度和模型维度\",{\"2\":{\"287\":1}}],[\"确定上下文窗口扩展比例\",{\"2\":{\"276\":1}}],[\"确保长样本中的每个部分都对总损失有足够的贡献\",{\"2\":{\"2591\":1,\"2654\":1}}],[\"确保策略更新次数\",{\"2\":{\"2585\":1}}],[\"确保策略的稳定性\",{\"2\":{\"1522\":1}}],[\"确保算法在最坏情况下仍能取得较好的结果\",{\"2\":{\"2405\":1}}],[\"确保最终展示给用户的结果更加符合其查询意图\",{\"2\":{\"2394\":1}}],[\"确保采样组足够大以保证估计的准确性\",{\"2\":{\"2367\":1}}],[\"确保每个token对总损失有均等的贡献\",{\"2\":{\"2612\":1,\"2665\":1}}],[\"确保每个token只能看到前面的token\",{\"2\":{\"2361\":1}}],[\"确保每个文本块具有相对独立的语义\",{\"2\":{\"2543\":1}}],[\"确保每个批次\",{\"2\":{\"2519\":1}}],[\"确保每个对话都能被公平地训练\",{\"2\":{\"2331\":1}}],[\"确保每个设备的发送和接收数据量保持在合理范围内\",{\"2\":{\"1171\":1}}],[\"确保每个设备在处理数据时不会超载\",{\"2\":{\"1073\":1}}],[\"确保初始模型遇到足够多样的指令\",{\"2\":{\"2314\":1}}],[\"确保选择正确的数据类型进行估算\",{\"2\":{\"2299\":1}}],[\"确保评估任务类型明确\",{\"2\":{\"2233\":1}}],[\"确保使用通用的数据进行采样\",{\"2\":{\"2206\":1}}],[\"确保使用正确的向量表示和点积操作\",{\"2\":{\"1845\":1}}],[\"确保使用正确的分布比例\",{\"2\":{\"671\":1}}],[\"确保其支持目标度量方法\",{\"2\":{\"2051\":1}}],[\"确保其容量计算正确\",{\"2\":{\"1270\":1}}],[\"确保根据具体任务调整提示长度\",{\"2\":{\"1965\":1}}],[\"确保比例关系正确\",{\"2\":{\"1946\":1}}],[\"确保方向矩阵的维度与输入输出特征匹配\",{\"2\":{\"1945\":1}}],[\"确保共享权值的一致性\",{\"2\":{\"1923\":1}}],[\"确保适配器正确集成到每个网络层\",{\"2\":{\"1911\":1}}],[\"确保门控机制的准确性\",{\"2\":{\"1881\":1}}],[\"确保代码逻辑与理论一致\",{\"2\":{\"1789\":1}}],[\"确保权重衰减设置正确\",{\"2\":{\"1771\":1}}],[\"确保线性层的输出为标量值\",{\"2\":{\"1741\":1}}],[\"确保对当前状态的预估收益进行校正\",{\"2\":{\"1699\":1}}],[\"确保对各类查询的精确匹配\",{\"2\":{\"1332\":1}}],[\"确保奖励模型与人类偏好对齐\",{\"2\":{\"1642\":1}}],[\"确保训练过程中策略的稳定性\",{\"2\":{\"1621\":1}}],[\"确保训练过程中监控测试集的表现\",{\"2\":{\"1551\":1}}],[\"确保上下文的连贯性\",{\"2\":{\"1598\":1}}],[\"确保上下文扩展效果满足预期\",{\"2\":{\"359\":1}}],[\"确保包含\",{\"2\":{\"1542\":1}}],[\"确保知识库中的信息真实可靠\",{\"2\":{\"1510\":1}}],[\"确保模型不偏离初始sft策略\",{\"2\":{\"1631\":1}}],[\"确保模型不仅在训练集上表现良好\",{\"2\":{\"1505\":1}}],[\"确保模型的稳定性\",{\"2\":{\"1591\":1}}],[\"确保模型收敛\",{\"2\":{\"1123\":1}}],[\"确保截断范围\",{\"2\":{\"1405\":1}}],[\"确保生成的内容符合真实世界的事实\",{\"2\":{\"1356\":1}}],[\"确保生成顺序的逻辑性\",{\"2\":{\"167\":1}}],[\"确保高价值领域得到足够重视\",{\"2\":{\"1352\":1}}],[\"确保高质量输入\",{\"2\":{\"1061\":1}}],[\"确保在实际应用中\",{\"2\":{\"2524\":1}}],[\"确保在训练过程中不会因为某一组内的输出准确率为1而导致优势为0\",{\"2\":{\"2519\":1}}],[\"确保在应用缩放时\",{\"2\":{\"2028\":1}}],[\"确保在计算损失时应用裁剪操作\",{\"2\":{\"1934\":1}}],[\"确保在不同层中使用适合的初始化策略\",{\"2\":{\"1345\":1}}],[\"确保在obsidian中正常显示\",{\"2\":{\"173\":1}}],[\"确保基准测试题目或答案不被包含在训练数据中\",{\"2\":{\"1337\":1}}],[\"确保格式一致\",{\"2\":{\"1331\":1}}],[\"确保正确配置zero\",{\"2\":{\"2287\":1}}],[\"确保正确选择token子集以避免信息丢失\",{\"2\":{\"1325\":1}}],[\"确保正确计算折扣因子\",{\"2\":{\"856\":1}}],[\"确保sft数据保持原始长度\",{\"2\":{\"1299\":1}}],[\"确保准确判断偏好数据与非偏好数据\",{\"2\":{\"1280\":1}}],[\"确保稳定性\",{\"2\":{\"1255\":1}}],[\"确保二维位置编码技术正确应用\",{\"2\":{\"1137\":1}}],[\"确保解码器的各层执行cross\",{\"2\":{\"1011\":1}}],[\"确保数据集和预训练模型路径正确\",{\"2\":{\"2233\":1}}],[\"确保数据集的多样性和质量\",{\"2\":{\"1236\":1}}],[\"确保数据的多样性和代表性\",{\"2\":{\"1639\":1}}],[\"确保数据的准确性\",{\"0\":{\"1284\":1}}],[\"确保数据的唯一性\",{\"2\":{\"929\":1}}],[\"确保数据唯一性\",{\"2\":{\"1190\":1}}],[\"确保数据比例合理\",{\"2\":{\"567\":1}}],[\"确保随机抽样的充分性和样本量的足够大\",{\"2\":{\"809\":1}}],[\"确保多样性与公平性\",{\"2\":{\"650\":1}}],[\"确保所有层使用相同的权值\",{\"2\":{\"1975\":1}}],[\"确保所有状态都被正确地遍历和更新\",{\"2\":{\"647\":1}}],[\"确保所有api密钥的安全存储和管理\",{\"2\":{\"198\":1}}],[\"确保通用能力不受损\",{\"2\":{\"599\":1}}],[\"确保抓取内容时合法合规\",{\"2\":{\"485\":1}}],[\"确保梯度计算准确性\",{\"2\":{\"435\":1}}],[\"确保覆盖语料中的所有单词\",{\"2\":{\"393\":1}}],[\"确保残差连接在深层网络中被正确实现\",{\"2\":{\"275\":1}}],[\"确保即使网络很深\",{\"2\":{\"183\":1}}],[\"确保相邻组之间的信息流动\",{\"2\":{\"136\":1}}],[\"确保计算结果与不使用缓存时保持一致\",{\"2\":{\"125\":1}}],[\"确保更好的梯度回传\",{\"2\":{\"121\":1}}],[\"请根据提供的上下文信息\",{\"2\":{\"2690\":1}}],[\"请求经典planner根据现有的领域pddl生成一个pddl计划\",{\"2\":{\"1465\":1}}],[\"请注意\",{\"2\":{\"1171\":1}}],[\"请将下面的一段英语翻译成法语\",{\"2\":{\"1154\":1}}],[\"请确保在开发过程中保持对不同服务的认证机制的敏感性\",{\"2\":{\"265\":1}}],[\"请留意短信通知\",{\"2\":{\"49\":1}}],[\"α​\",{\"2\":{\"2033\":1}}],[\"αmax⁡\",{\"2\":{\"2033\":1}}],[\"α需人工设置\",{\"2\":{\"330\":1}}],[\"α\",{\"2\":{\"261\":3,\"285\":2,\"2215\":1}}],[\"αx\",{\"2\":{\"261\":2}}],[\"性能提升\",{\"0\":{\"2683\":1}}],[\"性能受限于内存带宽\",{\"2\":{\"2027\":1}}],[\"性能受限于计算带宽\",{\"2\":{\"2027\":1}}],[\"性能受限类型\",{\"0\":{\"2027\":1}}],[\"性能表现\",{\"2\":{\"1932\":1}}],[\"性能\",{\"0\":{\"1915\":1}}],[\"性能显著优于\",{\"2\":{\"1451\":1}}],[\"性能对比表\",{\"2\":{\"1324\":1}}],[\"性能对比\",{\"0\":{\"1178\":1}}],[\"性能越好\",{\"2\":{\"558\":1}}],[\"性能平衡\",{\"2\":{\"259\":1}}],[\"性能下降\",{\"2\":{\"259\":1}}],[\"性能影响\",{\"2\":{\"259\":1}}],[\"性能最优\",{\"2\":{\"40\":1}}],[\"元素数量\",{\"2\":{\"259\":1}}],[\"元数据是指与向量关联的非向量化数据\",{\"2\":{\"2669\":1}}],[\"元数据的作用\",{\"0\":{\"2669\":1},\"1\":{\"2672\":1,\"2675\":1}}],[\"元数据的引入可以显著提升检索效率和用户体验\",{\"2\":{\"2666\":1}}],[\"元数据\",{\"0\":{\"71\":1,\"74\":1,\"80\":1,\"87\":1,\"92\":1,\"94\":1,\"96\":1,\"104\":1,\"110\":1,\"119\":1,\"132\":1,\"139\":1,\"142\":1,\"154\":1,\"160\":1,\"181\":1,\"225\":1,\"273\":1,\"286\":1,\"297\":1,\"320\":1,\"344\":1,\"347\":1,\"377\":1,\"384\":1,\"396\":1,\"398\":1,\"405\":1,\"437\":1,\"487\":1,\"489\":1,\"543\":1,\"545\":1,\"550\":1,\"552\":1,\"617\":1,\"641\":1,\"659\":1,\"832\":1,\"835\":1,\"836\":1,\"848\":1,\"861\":1,\"862\":1,\"865\":1,\"883\":1,\"887\":1,\"890\":1,\"899\":1,\"908\":1,\"920\":1,\"922\":1,\"930\":1,\"935\":1,\"986\":1,\"987\":1,\"988\":1,\"990\":1,\"1000\":1,\"1015\":1,\"1017\":1,\"1018\":1,\"1044\":1,\"1063\":1,\"1070\":1,\"1085\":1,\"1098\":1,\"1101\":1,\"1103\":1,\"1148\":1,\"1165\":1,\"1449\":1,\"1461\":1,\"1473\":1,\"1479\":1,\"1486\":1,\"1568\":1,\"1575\":1,\"1599\":1,\"1604\":1,\"1605\":1,\"1624\":1,\"1638\":1,\"1682\":1,\"1689\":1,\"1694\":1,\"1707\":1,\"1726\":1,\"1919\":1,\"1969\":1,\"2047\":1,\"2088\":1,\"2116\":1,\"2134\":1,\"2135\":1,\"2225\":1,\"2261\":1,\"2297\":1,\"2329\":1,\"2404\":1,\"2567\":1,\"2639\":1},\"2\":{\"226\":1,\"436\":1,\"478\":1,\"573\":1,\"854\":1,\"859\":1,\"1414\":1,\"1489\":1,\"1497\":1,\"1516\":1,\"1546\":1,\"1583\":1,\"1615\":1,\"1625\":1,\"1785\":1,\"2238\":1,\"2279\":1}}],[\"板块\",{\"0\":{\"258\":1,\"279\":1,\"304\":1,\"337\":1,\"413\":1,\"432\":1,\"466\":1,\"469\":1,\"564\":1,\"685\":1,\"694\":1,\"705\":1,\"776\":1,\"850\":1,\"966\":1,\"994\":1,\"1472\":1,\"1508\":1,\"1580\":1,\"1971\":1,\"2382\":1},\"2\":{\"647\":1}}],[\"尝试基于规则的奖励系统\",{\"2\":{\"2053\":1}}],[\"尝试使用\",{\"2\":{\"1818\":1}}],[\"尝试构建自定义模型\",{\"2\":{\"737\":1}}],[\"尝试动量式\",{\"2\":{\"730\":1}}],[\"尝试抓取不同类型的数据并分析其结构\",{\"2\":{\"663\":1}}],[\"尝试不同领域的继续预训练\",{\"2\":{\"668\":1}}],[\"尝试不同分词算法\",{\"2\":{\"645\":1}}],[\"尝试不同激活函数组合以优化模型性能\",{\"2\":{\"380\":1}}],[\"尝试在特定任务中替换\",{\"2\":{\"1555\":1}}],[\"尝试在多模态模型\",{\"2\":{\"414\":1}}],[\"尝试在机器翻译任务中分别调整self\",{\"2\":{\"256\":1}}],[\"尝试引入稀疏矩阵技术\",{\"2\":{\"196\":1}}],[\"误差可能超过30\",{\"2\":{\"2170\":1}}],[\"误将中间token的值作为最终奖励\",{\"2\":{\"1802\":1}}],[\"误用\",{\"2\":{\"1592\":1}}],[\"误用独热编码\",{\"2\":{\"1113\":1}}],[\"误区3\",{\"2\":{\"718\":1,\"1452\":1}}],[\"误区2\",{\"2\":{\"718\":1,\"1452\":1}}],[\"误区1\",{\"2\":{\"718\":1,\"1452\":1}}],[\"误区提醒\",{\"2\":{\"527\":1,\"792\":1}}],[\"误区警告\",{\"2\":{\"210\":1}}],[\"误以为它也会进行\",{\"2\":{\"251\":1}}],[\"压缩率\",{\"2\":{\"1531\":1}}],[\"压缩率过低会导致解码效率低\",{\"2\":{\"1302\":1}}],[\"压缩率控制\",{\"2\":{\"1302\":1}}],[\"压缩率控制等方式优化tokenizer\",{\"2\":{\"1153\":1}}],[\"压缩99\",{\"2\":{\"1083\":1}}],[\"压缩后的模型可以更快地进行推理\",{\"2\":{\"825\":1}}],[\"压缩后的模型能够更高效地利用有限的计算资源\",{\"2\":{\"794\":1}}],[\"压缩后的维度\",{\"2\":{\"259\":1}}],[\"压缩效果和词汇表大小可灵活调整\",{\"2\":{\"318\":1}}],[\"压缩到1000以内\",{\"2\":{\"246\":1}}],[\"压缩数据\",{\"2\":{\"39\":1}}],[\"经常会存在关键实体具有不同含义的情况\",{\"2\":{\"2493\":1}}],[\"经常出现\",{\"2\":{\"2118\":1}}],[\"经典的rag方法\",{\"2\":{\"2366\":1}}],[\"经典的多头注意力\",{\"2\":{\"111\":1}}],[\"经验学习\",{\"2\":{\"2314\":1}}],[\"经验回放\",{\"0\":{\"712\":1}}],[\"经验回放池\",{\"2\":{\"640\":1}}],[\"经过多次迭代更新后\",{\"2\":{\"2528\":1}}],[\"经过了\",{\"2\":{\"925\":1}}],[\"经过压缩的模型甚至可以达到与原始大模型相当的性能\",{\"2\":{\"825\":1}}],[\"经过200步微调\",{\"2\":{\"245\":1}}],[\"理想文本块的特性\",{\"0\":{\"2364\":1}}],[\"理想情况下\",{\"2\":{\"1667\":1,\"1675\":1}}],[\"理论\",{\"2\":{\"2234\":1}}],[\"理论尺度因子\",{\"2\":{\"244\":1}}],[\"理解grpo与ppo的区别及其应用场景\",{\"2\":{\"2524\":1}}],[\"理解计算与内存限制对于优化模型性能至关重要\",{\"2\":{\"2175\":1}}],[\"理解\",{\"2\":{\"1843\":1}}],[\"理解损失函数公式\",{\"2\":{\"1789\":1}}],[\"理解dpo损失函数\",{\"0\":{\"1675\":1}}],[\"理解两种学习方式的优化目标\",{\"2\":{\"858\":1}}],[\"理解能力强\",{\"2\":{\"595\":1}}],[\"理解其合并过程\",{\"2\":{\"531\":1}}],[\"理解句子含义\",{\"2\":{\"216\":1}}],[\"组成的\",{\"2\":{\"2710\":1}}],[\"组成的矩形矩阵\",{\"2\":{\"917\":1}}],[\"组成的下三角矩阵\",{\"2\":{\"917\":1}}],[\"组大小设置不合理\",{\"2\":{\"241\":1}}],[\"组内独立计算\",{\"2\":{\"197\":1}}],[\"官方并未提供中文分句模型的预训练权重\",{\"2\":{\"1719\":1}}],[\"官方代码链接\",{\"2\":{\"240\":1}}],[\"官网\",{\"2\":{\"65\":1}}],[\"验证不同ϵ\",{\"2\":{\"1852\":1}}],[\"验证或修正部分回答\",{\"2\":{\"1619\":1}}],[\"验证\",{\"2\":{\"1403\":1,\"2227\":1}}],[\"验证模型与数据组合是否接近最优点\",{\"2\":{\"1374\":1}}],[\"验证其在多语言模型中的适用性\",{\"2\":{\"704\":1}}],[\"验证嵌入分布是否均匀\",{\"2\":{\"359\":1}}],[\"验证效果\",{\"2\":{\"291\":1}}],[\"验证pre\",{\"2\":{\"282\":1}}],[\"验证dca在超长文本场景中是否能显著提升模型表现\",{\"2\":{\"240\":1}}],[\"验证集评估后压缩模型\",{\"2\":{\"40\":1}}],[\"🌐\",{\"2\":{\"240\":1}}],[\"编号0\",{\"2\":{\"2697\":1}}],[\"编辑过程通过对外部信息进行检索\",{\"2\":{\"2514\":1}}],[\"编写文档提纲\",{\"2\":{\"1820\":1}}],[\"编程范式\",{\"2\":{\"2081\":1}}],[\"编程范式来实现模型间通信\",{\"2\":{\"2081\":1}}],[\"编程任务则通过测试用例和编译器验证\",{\"2\":{\"1797\":1}}],[\"编程与工具\",{\"0\":{\"254\":1},\"1\":{\"278\":1,\"302\":1},\"2\":{\"578\":1}}],[\"编解码的可逆性是提升数据一致性的重要特性\",{\"2\":{\"610\":1}}],[\"编解码的可逆性\",{\"2\":{\"426\":1}}],[\"编解码可逆性\",{\"2\":{\"373\":1}}],[\"编码可视化特点\",{\"0\":{\"1296\":1}}],[\"编码维度为\",{\"2\":{\"1281\":1}}],[\"编码单词位置信息\",{\"2\":{\"1226\":1}}],[\"编码器\",{\"2\":{\"1225\":1,\"1922\":1}}],[\"编码\",{\"2\":{\"1217\":1,\"1555\":1}}],[\"编码会变得非常稀疏且高维\",{\"2\":{\"985\":1}}],[\"编码为1\",{\"2\":{\"980\":1}}],[\"编码为0\",{\"2\":{\"980\":1}}],[\"编码技巧\",{\"2\":{\"836\":1}}],[\"编码序列长度\",{\"2\":{\"365\":1}}],[\"编码序列长度增加\",{\"2\":{\"341\":1}}],[\"编码后的数据可以无损解码回原始数据\",{\"2\":{\"318\":1}}],[\"编码函数需连续且有界\",{\"2\":{\"239\":1}}],[\"编译器能够自动推导出函数或类实例化的具体类型\",{\"2\":{\"15\":1}}],[\"连续为1\",{\"2\":{\"2256\":1}}],[\"连续性与有界性\",{\"2\":{\"239\":1}}],[\"连接mcp核心\",{\"2\":{\"118\":1}}],[\"连接mcp服务器和mcp客户端\",{\"2\":{\"102\":1}}],[\"相当于我们加载了完整的\",{\"2\":{\"2653\":1}}],[\"相当于用\",{\"2\":{\"2308\":1}}],[\"相反\",{\"2\":{\"2335\":1,\"2498\":1}}],[\"相邻文本块将共享\",{\"2\":{\"1987\":1}}],[\"相似度度量方法\",{\"0\":{\"2051\":1}}],[\"相似度计算\",{\"0\":{\"2581\":1},\"2\":{\"1470\":1}}],[\"相似度计算指标\",{\"2\":{\"735\":1}}],[\"相似\",{\"2\":{\"1377\":1}}],[\"相互作用和集体决策过程\",{\"2\":{\"1291\":1}}],[\"相同\",{\"2\":{\"1258\":1}}],[\"相同相对位置的编码结果应一致\",{\"2\":{\"239\":1}}],[\"相关综述论文\",{\"0\":{\"2395\":1}}],[\"相关性\",{\"2\":{\"1356\":2}}],[\"相关研究可以参考论文\",{\"2\":{\"949\":1}}],[\"相关的部分\",{\"2\":{\"868\":1}}],[\"相对常见的cv业务而言\",{\"2\":{\"1843\":1}}],[\"相对于初代\",{\"2\":{\"1007\":1}}],[\"相对上面的量化对象略微小众一些\",{\"2\":{\"799\":1}}],[\"相对位置信息的破坏\",{\"2\":{\"1343\":1}}],[\"相对位置\",{\"2\":{\"1044\":1,\"1063\":1}}],[\"相对位置一致性\",{\"2\":{\"239\":1}}],[\"相对位置编码是否会增加模型复杂度并影响性能\",{\"2\":{\"1593\":1}}],[\"相对位置编码是否适用于所有类型的transformer任务\",{\"2\":{\"1593\":1}}],[\"相对位置编码是否能完全取代绝对位置编码\",{\"2\":{\"1472\":1}}],[\"相对位置编码的基础原理\",{\"0\":{\"1215\":1},\"1\":{\"1266\":1}}],[\"相对位置编码的简化\",{\"0\":{\"1207\":1}}],[\"相对位置编码与xlnet位置编码详解\",{\"0\":{\"1027\":1},\"1\":{\"1070\":1,\"1116\":1,\"1166\":1,\"1215\":1,\"1266\":1,\"1313\":1,\"1359\":1,\"1405\":1,\"1452\":1,\"1499\":1,\"1543\":1,\"1593\":1,\"1647\":1},\"2\":{\"5\":1,\"84\":1}}],[\"相对位置编码\",{\"2\":{\"5\":3,\"222\":1,\"1070\":1}}],[\"相对位置编码|相对位置编码\",{\"2\":{\"5\":1}}],[\"相比让一个\",{\"2\":{\"2037\":1}}],[\"相比单一\",{\"2\":{\"1786\":1}}],[\"相比\",{\"2\":{\"1224\":1}}],[\"相比传统的多项交互式编码\",{\"2\":{\"1207\":1}}],[\"相比之下\",{\"2\":{\"1012\":1,\"1650\":1}}],[\"相比cbow\",{\"2\":{\"938\":1}}],[\"相比gpt\",{\"2\":{\"932\":1}}],[\"相比于传统强化学习智能体\",{\"2\":{\"2443\":1}}],[\"相比于静态的三角函数式编码\",{\"2\":{\"1359\":1}}],[\"相比于单个智能体\",{\"2\":{\"1291\":1}}],[\"相比于\",{\"2\":{\"845\":1,\"2188\":1}}],[\"相比于第一种方法\",{\"2\":{\"826\":1}}],[\"相比trpo复杂的kl散度估计\",{\"2\":{\"658\":1}}],[\"相比直接外推\",{\"2\":{\"245\":1}}],[\"相较于标准的数据并行\",{\"2\":{\"2369\":1}}],[\"相较于传统adam优化器\",{\"2\":{\"1248\":1}}],[\"相较于\",{\"2\":{\"1026\":1}}],[\"相较relu计算复杂度稍高\",{\"2\":{\"330\":1}}],[\"相较\",{\"2\":{\"307\":1}}],[\"绝对位置\",{\"2\":{\"1044\":1}}],[\"绝对位置表示\",{\"2\":{\"239\":1}}],[\"绝对位置编码\",{\"2\":{\"5\":2}}],[\"绝对位置编码|绝对位置编码\",{\"2\":{\"5\":1}}],[\"说明性文本生成任务\",{\"0\":{\"2594\":1},\"1\":{\"2601\":1,\"2608\":1,\"2615\":1}}],[\"说明模型对下一个单词的预测越准确\",{\"2\":{\"268\":1,\"558\":1}}],[\"说明\",{\"2\":{\"239\":1,\"1594\":1,\"2184\":3,\"2482\":1}}],[\"死亡\",{\"2\":{\"238\":1}}],[\"智能截断\",{\"0\":{\"1652\":1}}],[\"智能化的任务处理\",{\"2\":{\"1151\":1}}],[\"智能体与llm的区别\",{\"0\":{\"2302\":1},\"1\":{\"2333\":1,\"2363\":1}}],[\"智能体评估中存在的几个关键问题\",{\"2\":{\"1453\":1}}],[\"智能体可以根据优先级对任务进行合理排序\",{\"2\":{\"1439\":1}}],[\"智能体能够获取环境信息\",{\"2\":{\"1518\":1}}],[\"智能体能够逐步执行每个步骤\",{\"2\":{\"1439\":1}}],[\"智能体能够根据输入内容\",{\"2\":{\"1439\":1}}],[\"智能体之间通过通信机制共享信息\",{\"2\":{\"1338\":1}}],[\"智能体独自运行\",{\"2\":{\"1241\":1}}],[\"智能体框架\",{\"0\":{\"1200\":1},\"1\":{\"1250\":1,\"1300\":1,\"1347\":1}}],[\"智能体系统可以在多种场景中实现自动化\",{\"2\":{\"1151\":1}}],[\"智能体系统分类\",{\"0\":{\"1169\":1},\"1\":{\"1218\":1,\"1269\":1,\"1316\":1,\"1362\":1,\"1408\":1,\"1454\":1,\"1501\":1,\"1545\":1,\"1595\":1,\"1649\":1,\"1702\":1,\"1760\":1,\"1820\":1,\"1879\":1,\"1935\":1,\"1985\":1,\"2037\":1,\"2089\":1,\"2139\":1,\"2185\":1,\"2224\":1,\"2259\":1,\"2294\":1},\"2\":{\"237\":1}}],[\"智能体是能够感知环境并采取行动以实现特定目标的系统\",{\"2\":{\"1139\":1}}],[\"智能体在各个层级的能力差异显而易见\",{\"2\":{\"1136\":1}}],[\"智能体根据奖励调整策略\",{\"2\":{\"639\":1}}],[\"智能体计算并选择一个动作\",{\"2\":{\"639\":1}}],[\"智能体感知当前环境状态\",{\"2\":{\"639\":1}}],[\"智能体\",{\"2\":{\"539\":1,\"552\":1,\"760\":1,\"792\":1,\"1136\":1,\"1139\":1,\"1151\":1,\"1474\":1,\"1617\":1,\"2269\":1}}],[\"智能体的输入和输出通常局限于特定的环境中\",{\"2\":{\"2418\":1}}],[\"智能体的\",{\"0\":{\"1518\":1,\"1567\":1}}],[\"智能体的核心定义\",{\"0\":{\"1474\":1},\"1\":{\"1518\":1,\"1567\":1}}],[\"智能体的定义也在不断演进\",{\"2\":{\"1136\":1}}],[\"智能体的作用\",{\"0\":{\"760\":1}}],[\"智能体的框架和应用\",{\"0\":{\"1151\":1},\"1\":{\"1200\":1,\"1250\":1,\"1300\":1,\"1347\":1,\"1392\":1,\"1439\":1,\"1485\":1,\"1529\":1,\"1578\":1,\"1630\":1,\"1684\":1,\"1740\":1,\"1798\":1,\"1860\":1,\"1917\":1,\"1970\":1,\"2022\":1,\"2072\":1,\"2124\":1,\"2171\":1,\"2213\":1,\"2250\":1,\"2285\":1,\"2317\":1,\"2348\":1,\"2378\":1,\"2405\":1,\"2430\":1,\"2455\":1},\"2\":{\"237\":1}}],[\"智能体的分类\",{\"0\":{\"1139\":1},\"1\":{\"1191\":1,\"1241\":1,\"1291\":1,\"1338\":1,\"1384\":1,\"1431\":1,\"1476\":1,\"1520\":1,\"1569\":1,\"1619\":1,\"1674\":1,\"1730\":1,\"1788\":1,\"1849\":1,\"1906\":1,\"1959\":1,\"2011\":1,\"2060\":1,\"2113\":1,\"2162\":1,\"2205\":1,\"2242\":1,\"2277\":1,\"2309\":1,\"2340\":1,\"2370\":1,\"2398\":1,\"2423\":1,\"2448\":1,\"2469\":1,\"2487\":1,\"2501\":1,\"2514\":1,\"2525\":1,\"2536\":1,\"2546\":1,\"2554\":1,\"2562\":1,\"2570\":1,\"2578\":1,\"2586\":1,\"2594\":1,\"2601\":1,\"2608\":1,\"2615\":1},\"2\":{\"237\":1}}],[\"智能阅读模型相关技术\",{\"0\":{\"186\":1},\"1\":{\"207\":1,\"230\":1},\"2\":{\"578\":1}}],[\"作诗\",{\"2\":{\"2223\":1}}],[\"作者提出了一种新的检索单位\",{\"2\":{\"1367\":1}}],[\"作者观点\",{\"0\":{\"236\":1,\"257\":1,\"326\":1,\"610\":1,\"1163\":1,\"1259\":1},\"2\":{\"236\":1,\"257\":1,\"326\":1,\"610\":1,\"1163\":1,\"1259\":1}}],[\"作为下一句的前缀\",{\"2\":{\"2601\":1}}],[\"作为框架完全没有分层分模块\",{\"2\":{\"2118\":1}}],[\"作为输入\",{\"2\":{\"1856\":1}}],[\"作为输入进行一次新的推理\",{\"2\":{\"1782\":1}}],[\"作为整个响应的奖励\",{\"2\":{\"1582\":1}}],[\"作为\",{\"2\":{\"1578\":1,\"1873\":1,\"2082\":1}}],[\"作为中间接口来描述规划问题\",{\"2\":{\"1465\":1}}],[\"作为可训练参数\",{\"2\":{\"1353\":1}}],[\"作为评估指标\",{\"2\":{\"1268\":1}}],[\"作为模型结构\",{\"2\":{\"1265\":1}}],[\"作为核心计算引擎\",{\"2\":{\"1184\":1}}],[\"作为位置编码\",{\"2\":{\"1112\":1}}],[\"作为激活函数\",{\"2\":{\"1112\":1}}],[\"作为层归一化方法\",{\"2\":{\"1112\":1}}],[\"作为demonstration\",{\"2\":{\"910\":1}}],[\"作为训练样本的文本表征\",{\"2\":{\"910\":1}}],[\"作为训练目标\",{\"2\":{\"503\":1}}],[\"作为一种强化学习算法\",{\"2\":{\"875\":1}}],[\"作为主要训练目标\",{\"2\":{\"449\":1}}],[\"作为主权重\",{\"2\":{\"435\":1}}],[\"作用\",{\"2\":{\"146\":1,\"162\":1,\"167\":1,\"183\":1}}],[\"比基于模板或模型生成的响应更能提高对齐质量\",{\"2\":{\"967\":1}}],[\"比例分配以及领域数据的使用策略\",{\"2\":{\"422\":1}}],[\"比较高\",{\"2\":{\"2691\":1}}],[\"比较peft与其他微调方法的优缺点\",{\"2\":{\"2182\":1}}],[\"比较ppo与其他强化学习算法的优劣\",{\"2\":{\"796\":1}}],[\"比较标准transformer与xlnet在长文本建模上的性能差异\",{\"2\":{\"1647\":1}}],[\"比较其与\",{\"2\":{\"1493\":1}}],[\"比较相邻分段的\",{\"2\":{\"1470\":1}}],[\"比较gpt1与其他语言模型的性能差异\",{\"2\":{\"1385\":1}}],[\"比较公平地对每个llm在8个环境中的表现给出了一个总得分\",{\"2\":{\"1268\":1}}],[\"比较hierarchical\",{\"2\":{\"1161\":1}}],[\"比较bart与其他transformer模型在不同任务中的表现\",{\"2\":{\"1144\":1}}],[\"比较bpe与其他分词方法\",{\"2\":{\"597\":1}}],[\"比较bpe与wordpiece在oov处理上的性能差异\",{\"2\":{\"522\":1}}],[\"比较两种方法在特定任务上的性能差异\",{\"2\":{\"928\":1}}],[\"比较sarsa与q\",{\"2\":{\"817\":1}}],[\"比较tdpo和ppo在相同环境下的效果\",{\"2\":{\"1880\":1}}],[\"比较td与其他强化学习算法在具体任务中的效率\",{\"2\":{\"752\":1}}],[\"比较transformer与rnn在长句处理上的表现差异\",{\"2\":{\"383\":1}}],[\"比较价值迭代与策略迭代的效率\",{\"2\":{\"647\":1}}],[\"比较微调与非微调情况下的性能差异\",{\"2\":{\"387\":1}}],[\"比较yarn与其他位置编码方法\",{\"2\":{\"322\":1}}],[\"比较不同标注数据对微调结果的差异\",{\"2\":{\"1403\":1}}],[\"比较不同深度学习框架中\",{\"2\":{\"1225\":1}}],[\"比较不同激活函数对模型训练速度和性能的影响\",{\"2\":{\"311\":1}}],[\"比较不同归一化方式\",{\"2\":{\"234\":1}}],[\"比如gelu这里就不用all\",{\"2\":{\"2609\":1}}],[\"比如激活检查点\",{\"2\":{\"2489\":1}}],[\"比如将文档按三层树状结构进行切割\",{\"2\":{\"2271\":1}}],[\"比如基于不好的结果进行反向回溯推理\",{\"2\":{\"2094\":1}}],[\"比如强制进行反思性推理或推广特定解题策略\",{\"2\":{\"1859\":1}}],[\"比如方向性信息的丢失和相对位置表达能力的破坏\",{\"2\":{\"1147\":1}}],[\"比如\",{\"2\":{\"847\":1,\"2335\":1}}],[\"比如加入更多的上下文交互\",{\"2\":{\"299\":1}}],[\"比如输入一个新病人的年龄\",{\"2\":{\"143\":1}}],[\"比如健康\",{\"2\":{\"105\":1}}],[\"比如患病\",{\"2\":{\"105\":1}}],[\"比如0\",{\"2\":{\"105\":1}}],[\"比如年龄\",{\"2\":{\"76\":1}}],[\"比如病人的年龄\",{\"2\":{\"66\":1}}],[\"比如判断一封邮件是垃圾邮件还是正常邮件\",{\"2\":{\"42\":1}}],[\"比如分类某种类型的事物\",{\"2\":{\"39\":1}}],[\"错误答案获得\",{\"2\":{\"1740\":1}}],[\"错误消息处理\",{\"2\":{\"1740\":1}}],[\"错误使用模型类型\",{\"2\":{\"1066\":1}}],[\"错误地假设环境动态未知会导致算法无法正常运作\",{\"2\":{\"691\":1}}],[\"错误地将其与其他单一分词方法混为一谈\",{\"2\":{\"472\":1}}],[\"错误三\",{\"2\":{\"594\":1}}],[\"错误二\",{\"2\":{\"594\":1}}],[\"错误一\",{\"2\":{\"594\":1}}],[\"错误2\",{\"2\":{\"231\":1}}],[\"错误1\",{\"2\":{\"231\":1}}],[\"会在所有树中迭代地搜索最接近查询点的一半\",{\"2\":{\"2195\":1}}],[\"会重新评估其过去的步骤并尝试新的方法\",{\"2\":{\"2169\":1}}],[\"会是\",{\"2\":{\"2145\":1}}],[\"会综合各个工作者的结果\",{\"2\":{\"2089\":1}}],[\"会有更多人点击\",{\"2\":{\"2087\":1}}],[\"会生成看似合理但实际上错误的信息\",{\"2\":{\"1468\":1}}],[\"会造成大量无效计算\",{\"2\":{\"782\":1}}],[\"会导致梯度消失问题\",{\"2\":{\"2507\":1}}],[\"会导致性能显著下降\",{\"2\":{\"1974\":1,\"2173\":1}}],[\"会导致显存占用增加至\",{\"2\":{\"488\":1}}],[\"会导致后续生成无法复用缓存\",{\"2\":{\"231\":1}}],[\"会影响跨块注意力效果\",{\"2\":{\"175\":1}}],[\"若不加以处理\",{\"2\":{\"2507\":1}}],[\"若policy模型采样概率更高\",{\"2\":{\"1857\":1}}],[\"若当前选择的答案在sft模型中采样概率高于policy模型\",{\"2\":{\"1857\":1}}],[\"若数据集与模型能力不匹配\",{\"2\":{\"1778\":1}}],[\"若显存充足\",{\"2\":{\"1389\":1}}],[\"若两个expert都溢出\",{\"2\":{\"1119\":1}}],[\"若一直选择q值最大的动作\",{\"2\":{\"646\":1}}],[\"若\",{\"2\":{\"622\":3}}],[\"若溢出\",{\"2\":{\"589\":1}}],[\"若无溢出\",{\"2\":{\"589\":1}}],[\"若组大小过小\",{\"2\":{\"241\":1}}],[\"若在初始阶段未存储key和value向量\",{\"2\":{\"231\":1}}],[\"若需要进一步缩小跨度\",{\"2\":{\"223\":1}}],[\"举例来说\",{\"2\":{\"2281\":1}}],[\"举例\",{\"2\":{\"227\":1}}],[\"举个例子\",{\"0\":{\"164\":1},\"2\":{\"2313\":1}}],[\"否则策略可能次优\",{\"2\":{\"1642\":1}}],[\"否则可能影响模型性能\",{\"2\":{\"1881\":1}}],[\"否则可能影响小语种任务的表现\",{\"2\":{\"601\":1}}],[\"否则可能导致策略更新不稳定\",{\"2\":{\"2513\":1}}],[\"否则可能导致不稳定的学习过程\",{\"2\":{\"2041\":1}}],[\"否则可能导致不准确的预测结果\",{\"2\":{\"1080\":1}}],[\"否则可能导致缩放不准确\",{\"2\":{\"2028\":1}}],[\"否则可能导致计算错误\",{\"2\":{\"1945\":1}}],[\"否则可能导致模型不一致性\",{\"2\":{\"1547\":1}}],[\"否则可能导致模型性能下降\",{\"2\":{\"566\":1,\"1189\":1,\"1463\":1,\"1911\":1}}],[\"否则可能导致估计偏差\",{\"2\":{\"809\":1}}],[\"否则可能导致错误的策略更新\",{\"2\":{\"758\":1}}],[\"否则可能导致训练过程不稳定\",{\"2\":{\"671\":1}}],[\"否则将梯度缩小\",{\"2\":{\"553\":1}}],[\"否则会导致loss计算错误\",{\"2\":{\"2353\":1}}],[\"否则会导致概率分布不合法\",{\"2\":{\"2098\":1}}],[\"否则会导致策略更新过于激进\",{\"2\":{\"731\":1}}],[\"否则会导致oov\",{\"2\":{\"498\":1}}],[\"否则会导致计算错误\",{\"2\":{\"338\":1}}],[\"否则为\",{\"2\":{\"488\":1}}],[\"否\",{\"2\":{\"227\":1}}],[\"采取一个动作\",{\"2\":{\"2011\":1}}],[\"采取行动\",{\"2\":{\"1594\":1}}],[\"采样mmm条response\",{\"2\":{\"2007\":1}}],[\"采样响应\",{\"2\":{\"2007\":1}}],[\"采样比例\",{\"2\":{\"1211\":1}}],[\"采样多个span以覆盖原始token的15\",{\"2\":{\"1089\":1}}],[\"采样并更新策略\",{\"2\":{\"789\":1}}],[\"采样若干条序列\",{\"2\":{\"778\":1}}],[\"采样序列\",{\"2\":{\"778\":1}}],[\"采样数据\",{\"2\":{\"695\":1}}],[\"采样的行为策略和更新的目标策略不是同一个策略\",{\"2\":{\"653\":1}}],[\"采样的行为策略和更新的目标策略是同一个策略\",{\"2\":{\"653\":1}}],[\"采样方法决定了输出文本的多样性和质量\",{\"2\":{\"249\":1}}],[\"采样方法\",{\"2\":{\"226\":1}}],[\"采用列切割\",{\"2\":{\"2616\":1}}],[\"采用行切割\",{\"2\":{\"2616\":1}}],[\"采用token\",{\"2\":{\"2575\":1,\"2598\":1,\"2644\":1,\"2658\":1}}],[\"采用transformer\",{\"2\":{\"1243\":1}}],[\"采用传统的索引\",{\"2\":{\"2445\":1}}],[\"采用原生\",{\"2\":{\"2381\":1}}],[\"采用逐通道缩放技术来确定最佳缩放因子\",{\"2\":{\"2085\":1}}],[\"采用svd形式参数化增量更新\",{\"2\":{\"1824\":1}}],[\"采用余弦退火算法逐步降低学习率\",{\"2\":{\"1344\":1}}],[\"采用余弦学习率调度\",{\"2\":{\"1162\":1}}],[\"采用两阶段预训练方法\",{\"2\":{\"1256\":1}}],[\"采用标准语言模型损失函数\",{\"2\":{\"1248\":1}}],[\"采用自监督预训练结合有监督微调\",{\"2\":{\"1243\":1}}],[\"采用对比解码\",{\"2\":{\"1224\":1}}],[\"采用结构化的自然语言提示\",{\"2\":{\"1175\":1}}],[\"采用\",{\"2\":{\"1112\":2,\"1197\":1,\"2609\":2}}],[\"采用多阶段预训练方法和先进的数据过滤技术\",{\"2\":{\"1061\":1}}],[\"采用bbpe编码器\",{\"2\":{\"1041\":1}}],[\"采用了virtual\",{\"2\":{\"2688\":1}}],[\"采用了仅包含解码器的结构\",{\"2\":{\"1198\":1}}],[\"采用了一种多功能的方法来压缩\",{\"2\":{\"1143\":1}}],[\"采用了来自公开可用源的\",{\"2\":{\"1114\":1}}],[\"采用了类似llama的结构\",{\"2\":{\"1060\":1}}],[\"采用了\",{\"2\":{\"1057\":1}}],[\"采用了以下技术\",{\"2\":{\"1002\":1}}],[\"采用了完全的\",{\"2\":{\"889\":1}}],[\"采用真实的人类提示和交互\",{\"2\":{\"967\":1}}],[\"采用词向量\",{\"2\":{\"938\":1}}],[\"采用下三角形式的\",{\"2\":{\"881\":1}}],[\"采用截断方式\",{\"2\":{\"766\":1}}],[\"采用wsd训练策略\",{\"2\":{\"593\":1}}],[\"采用codellama中的ntk\",{\"2\":{\"534\":1}}],[\"采用课程学习的方式\",{\"2\":{\"533\":1}}],[\"采用以下管道化流程\",{\"2\":{\"452\":1}}],[\"采用masked\",{\"2\":{\"167\":1}}],[\"采用统一认证管理平台如oauth2可以减少重复工作\",{\"2\":{\"157\":1}}],[\"λ≫1\",{\"2\":{\"1891\":1}}],[\"λ≫1b\",{\"2\":{\"1891\":1}}],[\"λ在实际应用中有哪些具体场景\",{\"2\":{\"876\":1}}],[\"λ通过考虑多步时序差分来折中这两者\",{\"2\":{\"672\":1}}],[\"λ结合了蒙特卡洛方法和时序差分算法的优点\",{\"2\":{\"672\":1}}],[\"λ算法\",{\"0\":{\"672\":1}}],[\"λ和q\",{\"2\":{\"638\":1}}],[\"λ\",{\"2\":{\"571\":1}}],[\"λ=1\",{\"2\":{\"570\":1}}],[\"λ=s2\",{\"2\":{\"221\":2}}],[\"λj​=2πθj​​=2\",{\"2\":{\"290\":1}}],[\"λj=θj2π=2πbd2\",{\"2\":{\"290\":1}}],[\"λβ\",{\"2\":{\"221\":2}}],[\"λ与q\",{\"0\":{\"506\":1},\"1\":{\"538\":1,\"571\":1,\"604\":1,\"638\":1,\"672\":1,\"710\":1,\"744\":1,\"775\":1,\"806\":1,\"840\":1,\"876\":1,\"912\":1,\"951\":1},\"2\":{\"5\":2,\"151\":1,\"876\":1,\"951\":1}}],[\"低方差估计有助于增强训练稳定性\",{\"2\":{\"2274\":1}}],[\"低于8比特的量化被称为低比特量化\",{\"2\":{\"768\":1}}],[\"低质量或偏向单一领域的数据可能导致模型在实际应用中表现不佳\",{\"2\":{\"601\":1}}],[\"低质内容过滤\",{\"0\":{\"548\":1}}],[\"低loss可能由全是换行符的数据引起\",{\"2\":{\"525\":1}}],[\"低频单词可能会增加噪声\",{\"2\":{\"1109\":1}}],[\"低频或无用子词将逐步被移除\",{\"2\":{\"471\":1}}],[\"低频区域\",{\"2\":{\"221\":1}}],[\"低秩矩阵编码\",{\"2\":{\"1853\":1}}],[\"低秩矩阵\",{\"0\":{\"1678\":1}}],[\"低秩适应\",{\"2\":{\"1638\":1}}],[\"低秩kv压缩\",{\"2\":{\"283\":1}}],[\"低秩分解\",{\"0\":{\"682\":1},\"2\":{\"214\":1,\"763\":1,\"1599\":1}}],[\"缩小至\",{\"2\":{\"1007\":1}}],[\"缩小\",{\"2\":{\"589\":1}}],[\"缩减为原来的2\",{\"2\":{\"220\":1}}],[\"缩放定律\",{\"2\":{\"1132\":1}}],[\"缩放因子=t1​\",{\"2\":{\"252\":1}}],[\"缩放因子=1t\",{\"2\":{\"252\":1}}],[\"缩放因子\",{\"2\":{\"252\":1}}],[\"缩放因子sqrt\",{\"2\":{\"130\":1}}],[\"缩放权重\",{\"2\":{\"213\":1}}],[\"博客笔记\",{\"2\":{\"219\":1}}],[\"博客标题\",{\"0\":{\"78\":1}}],[\"同理大家可以自行推一下backward中的计算量\",{\"2\":{\"2643\":1}}],[\"同一个词可能在不同上下文中指代不同的对象\",{\"2\":{\"2493\":1}}],[\"同一个变量的参数被分片后放到不同的\",{\"2\":{\"2079\":1}}],[\"同一级标题区块的高度误差在\",{\"2\":{\"2235\":1}}],[\"同样支持基于值函数的强化学习算法\",{\"2\":{\"2430\":1}}],[\"同样\",{\"2\":{\"2286\":1}}],[\"同样地\",{\"2\":{\"2271\":1}}],[\"同样集成了\",{\"2\":{\"1896\":1}}],[\"同样需要指数运算\",{\"2\":{\"215\":1}}],[\"同义词和释义扩展\",{\"2\":{\"1466\":1}}],[\"同时我们会经历\",{\"2\":{\"2653\":1}}],[\"同时解决单个gpu内存不足的问题\",{\"2\":{\"2537\":1}}],[\"同时解决了霍夫曼树处理生僻词效率低的问题\",{\"2\":{\"983\":1}}],[\"同时确保每个文本块的长度适中\",{\"2\":{\"2141\":1}}],[\"同时对抽取结果进行人工评估\",{\"2\":{\"2103\":1}}],[\"同时对个人用户也非常友好\",{\"2\":{\"1347\":1}}],[\"同时处理主要回复及安全防护\",{\"2\":{\"2037\":1}}],[\"同时执行多个任务\",{\"2\":{\"2037\":1}}],[\"同时注意\",{\"2\":{\"2030\":1}}],[\"同时能有效覆盖更多潜在答案\",{\"2\":{\"1835\":1}}],[\"同时学习多个相关任务\",{\"2\":{\"1794\":1}}],[\"同时单独训练大小向量mmm\",{\"2\":{\"1770\":1}}],[\"同时又不会太长导致嵌入模型难以表示\",{\"2\":{\"1763\":1}}],[\"同时避免加入敏感或无意义的token\",{\"2\":{\"1632\":1}}],[\"同时避免了信息泄漏问题\",{\"2\":{\"101\":1}}],[\"同时也会对\",{\"2\":{\"2218\":1}}],[\"同时也会降低大语言模型生成回答的质量\",{\"2\":{\"1503\":1}}],[\"同时也可以被划分为tool\",{\"2\":{\"1674\":1}}],[\"同时也增加了语料的多样性\",{\"2\":{\"1466\":1}}],[\"同时也能在文本理解任务中取得领先的效果\",{\"2\":{\"897\":1}}],[\"同时个人用户可在其\",{\"2\":{\"1347\":1}}],[\"同时根据实时变化调整策略\",{\"2\":{\"1338\":1}}],[\"同时通过负载均衡机制提高了计算效率\",{\"2\":{\"1317\":1}}],[\"同时通过掩码调整避免信息泄漏\",{\"2\":{\"156\":1}}],[\"同时引入两个可训练向量\",{\"2\":{\"1313\":1}}],[\"同时分析了其速度\",{\"2\":{\"1265\":1}}],[\"同时总结了四阶段预训练设置的具体流程\",{\"2\":{\"1197\":1}}],[\"同时灵活地在必要时引入绝对位置信息\",{\"2\":{\"1187\":1}}],[\"同时生成针对输入编码的utterance\",{\"2\":{\"1075\":1}}],[\"同时生成一份\",{\"2\":{\"435\":1}}],[\"同时尽量保留其语义信息\",{\"2\":{\"1036\":1}}],[\"同时尽量保留原始信息\",{\"2\":{\"882\":1}}],[\"同时尽量保持模型的性能\",{\"2\":{\"763\":1}}],[\"同时尽量保持模型性能\",{\"2\":{\"693\":1}}],[\"同时提升其处理问题的灵活性和准确性\",{\"2\":{\"2269\":1}}],[\"同时提升了高达2\",{\"2\":{\"750\":1}}],[\"同时提高数据采集效率\",{\"2\":{\"526\":1}}],[\"同时\",{\"2\":{\"730\":1,\"893\":1,\"1030\":1,\"1588\":1,\"2081\":1,\"2533\":1}}],[\"同时减少低质量样本对策略的负面影响\",{\"2\":{\"2605\":1,\"2662\":1}}],[\"同时减少计算开销\",{\"2\":{\"481\":1}}],[\"同时减少训练复杂度\",{\"2\":{\"246\":1}}],[\"同时介绍了课程学习的概念及其在大模型训练中的应用\",{\"2\":{\"422\":1}}],[\"同时介绍了混合专家\",{\"2\":{\"248\":1}}],[\"同时结合了两者的优点\",{\"2\":{\"247\":1}}],[\"同时降低资源消耗\",{\"2\":{\"240\":1}}],[\"同时降低实际深度\",{\"2\":{\"169\":1}}],[\"同时保护它们在多任务解决和语言生成能力上的表现\",{\"2\":{\"1143\":1}}],[\"同时保持其性能\",{\"2\":{\"2647\":1}}],[\"同时保持其压缩性能\",{\"2\":{\"469\":1}}],[\"同时保持良好的性能\",{\"2\":{\"2207\":1}}],[\"同时保持较高的计算精度\",{\"2\":{\"2059\":1}}],[\"同时保持较高的模型性能\",{\"2\":{\"212\":1}}],[\"同时保持了高效性能\",{\"2\":{\"1986\":1}}],[\"同时保持了高性能\",{\"2\":{\"1679\":1}}],[\"同时保持整体\",{\"2\":{\"1094\":1}}],[\"同时保持整体网络结构\",{\"2\":{\"1094\":1}}],[\"同时保留了大分块和小分块的优点\",{\"2\":{\"2630\":1}}],[\"同时保留一定的随机性\",{\"2\":{\"295\":1}}],[\"同时保留其在序列数据处理中的强大功能\",{\"2\":{\"109\":1}}],[\"9层继续放在device1\",{\"2\":{\"2697\":1}}],[\"9b\",{\"2\":{\"2090\":1}}],[\"9b参数\",{\"2\":{\"1121\":1}}],[\"99\",{\"2\":{\"1329\":2}}],[\"93\",{\"2\":{\"1324\":1}}],[\"91\",{\"2\":{\"1324\":1}}],[\"95β2​=0\",{\"2\":{\"1204\":1}}],[\"95\",{\"2\":{\"1204\":2,\"1544\":1}}],[\"9β1​=0\",{\"2\":{\"1204\":1}}],[\"90k\",{\"2\":{\"1178\":1}}],[\"9042\",{\"2\":{\"909\":1}}],[\"90\",{\"2\":{\"495\":1}}],[\"9\",{\"2\":{\"213\":1,\"470\":1,\"497\":2,\"1204\":2,\"1394\":3,\"2539\":1}}],[\"恒等分支\",{\"2\":{\"211\":1}}],[\"混淆deberta中的encoder\",{\"2\":{\"1335\":1}}],[\"混淆模型对邻近标记的理解\",{\"2\":{\"312\":1}}],[\"混淆self\",{\"2\":{\"209\":1}}],[\"混合序列训练\",{\"0\":{\"2424\":1}}],[\"混合提示\",{\"2\":{\"1796\":1}}],[\"混合训练策略\",{\"2\":{\"1464\":1}}],[\"混合型\",{\"2\":{\"664\":1}}],[\"混合精度\",{\"2\":{\"2047\":1}}],[\"混合精度可以大幅提升训练效率\",{\"2\":{\"625\":1}}],[\"混合精度训练可以有效减少显存占用\",{\"2\":{\"2330\":1}}],[\"混合精度训练时\",{\"2\":{\"2118\":1}}],[\"混合精度训练和动态\",{\"2\":{\"730\":1}}],[\"混合精度训练将成为主流方法之一\",{\"2\":{\"698\":1}}],[\"混合精度训练是否适用于所有类型的神经网络\",{\"2\":{\"660\":1}}],[\"混合精度训练是一种在深度学习中提高计算效率和降低显存占用的技术\",{\"2\":{\"408\":1}}],[\"混合精度训练的优势\",{\"0\":{\"462\":1}}],[\"混合精度训练的核心流程\",{\"0\":{\"435\":1}}],[\"混合精度训练\",{\"0\":{\"382\":1,\"2059\":1},\"1\":{\"408\":1,\"435\":1,\"462\":1,\"491\":1,\"523\":1,\"556\":1,\"591\":1,\"625\":1,\"660\":1,\"698\":1,\"734\":1},\"2\":{\"113\":1,\"382\":1,\"660\":1,\"730\":1}}],[\"混合精度训练|混合精度训练\",{\"2\":{\"5\":1}}],[\"混合模型探索\",{\"2\":{\"327\":1}}],[\"混合专家系统革新\",{\"0\":{\"998\":1}}],[\"混合专家\",{\"0\":{\"389\":1},\"1\":{\"415\":1,\"440\":1,\"467\":1,\"495\":1},\"2\":{\"225\":1}}],[\"上单独做矩阵计算\",{\"2\":{\"2636\":1}}],[\"上的\",{\"2\":{\"2636\":1}}],[\"上进行\",{\"2\":{\"2468\":1}}],[\"上应用多任务学习\",{\"2\":{\"2424\":1}}],[\"上述第二种方式\",{\"2\":{\"2166\":1}}],[\"上述讨论仅在batchsize=1的情况下讨论\",{\"2\":{\"1843\":1}}],[\"上\",{\"2\":{\"2108\":1,\"2145\":1,\"2447\":1}}],[\"上与全量微调差异显著\",{\"2\":{\"1736\":1}}],[\"上都取得了良好效果\",{\"2\":{\"1665\":1}}],[\"上文及当前时刻前生成的所有token序列\",{\"2\":{\"1613\":1}}],[\"上限\",{\"2\":{\"1409\":1}}],[\"上执行完整旋转\",{\"2\":{\"290\":1}}],[\"上投影矩阵\",{\"2\":{\"283\":2}}],[\"上归一化\",{\"2\":{\"205\":2}}],[\"上下文缺失\",{\"0\":{\"2511\":1}}],[\"上下文压缩是一种解决方案\",{\"2\":{\"2154\":1}}],[\"上下文压缩\",{\"0\":{\"2154\":1}}],[\"上下文词选择\",{\"2\":{\"2069\":1}}],[\"上下文词的指定\",{\"2\":{\"1796\":1}}],[\"上下文设计直接影响到模型生成结果的质量\",{\"2\":{\"1550\":1}}],[\"上下文相关性\",{\"0\":{\"2582\":1},\"2\":{\"1514\":1,\"2257\":1}}],[\"上下文割裂\",{\"0\":{\"1457\":1}}],[\"上下文学习\",{\"0\":{\"1772\":1},\"2\":{\"1333\":1}}],[\"上下文少样本学习蒸馏\",{\"0\":{\"1175\":1}}],[\"上下文长度扩展到了8k\",{\"2\":{\"1071\":1}}],[\"上下文长度\",{\"2\":{\"1071\":1,\"1204\":1,\"1360\":1,\"1398\":1,\"2699\":1}}],[\"上下文长度分组与注意力计算\",{\"0\":{\"197\":1}}],[\"上下文窗口从\",{\"2\":{\"1069\":1}}],[\"上下文窗口延长\",{\"2\":{\"1069\":1}}],[\"上下文窗口扩展的倍数\",{\"2\":{\"346\":1}}],[\"上下文进行训练\",{\"2\":{\"889\":1}}],[\"上下文提供\",{\"0\":{\"708\":1}}],[\"上下文依赖\",{\"0\":{\"536\":1}}],[\"上下文解码问题\",{\"2\":{\"417\":1}}],[\"上下文扩展比例\",{\"2\":{\"346\":1}}],[\"上下文扩展\",{\"2\":{\"139\":1,\"160\":1}}],[\"旋转式位置编码\",{\"2\":{\"203\":1}}],[\"旋转位置编码\",{\"2\":{\"163\":1,\"252\":1,\"502\":1,\"889\":1,\"1358\":1}}],[\"旋转位置编码与alibi\",{\"0\":{\"182\":1},\"1\":{\"203\":1,\"224\":1,\"247\":1,\"270\":1,\"293\":1,\"315\":1,\"338\":1,\"362\":1,\"388\":1,\"414\":1},\"2\":{\"5\":1,\"84\":1}}],[\"π∗表达式解出r\",{\"2\":{\"1994\":1}}],[\"π∗\",{\"0\":{\"1889\":2},\"2\":{\"1889\":2,\"1994\":1,\"2046\":3}}],[\"πmin​ex∼d​​ey∼π\",{\"2\":{\"1830\":1}}],[\"πmin​ex∼d​\",{\"2\":{\"1712\":1,\"1944\":1}}],[\"πmax⁡ex∼d\",{\"2\":{\"1666\":1,\"1720\":1}}],[\"πmax​ex∼d​\",{\"2\":{\"1657\":1}}],[\"πmax​ex∼d​ey∼π\",{\"2\":{\"614\":1}}],[\"πmax​ex∼d\",{\"2\":{\"614\":1,\"1552\":1,\"1666\":1,\"1720\":1}}],[\"πmaxex∼dey∼π\",{\"2\":{\"614\":1}}],[\"πmaxex∼d\",{\"2\":{\"614\":1}}],[\"πϕrl​\",{\"2\":{\"1685\":2}}],[\"πϕrl\",{\"2\":{\"1685\":2}}],[\"πsft\",{\"2\":{\"1685\":1}}],[\"πsft​\",{\"2\":{\"537\":1,\"1685\":1}}],[\"πref\",{\"2\":{\"1657\":2,\"1712\":1,\"1795\":3,\"1830\":1,\"1889\":1,\"1994\":1}}],[\"πref​的偏离程度\",{\"2\":{\"1552\":1}}],[\"πref​\",{\"2\":{\"614\":1,\"1732\":2,\"1795\":2,\"2046\":3}}],[\"πold​\",{\"2\":{\"1622\":2}}],[\"πold\",{\"2\":{\"1622\":2}}],[\"πθ∥πref\",{\"2\":{\"2577\":1}}],[\"πθ∣∣πref\",{\"2\":{\"1628\":1,\"2485\":1}}],[\"πθold​​\",{\"2\":{\"1628\":2}}],[\"πθold\",{\"2\":{\"1628\":2}}],[\"πθk​​\",{\"2\":{\"590\":2,\"2044\":2,\"2097\":2}}],[\"πθk\",{\"2\":{\"590\":2,\"2044\":2,\"2097\":2}}],[\"πθ​∥πref​\",{\"2\":{\"2577\":1}}],[\"πθ​∣∣πref​\",{\"2\":{\"1628\":1,\"2485\":1}}],[\"πθ​为actor的策略\",{\"2\":{\"590\":1}}],[\"πθ​\",{\"2\":{\"537\":1,\"590\":2,\"1628\":2,\"1795\":3,\"2044\":2,\"2097\":2,\"2357\":1,\"2485\":2}}],[\"πθ\",{\"2\":{\"537\":1,\"590\":3,\"1628\":2,\"1795\":2,\"2044\":2,\"2097\":2,\"2357\":1,\"2485\":6}}],[\"π\",{\"2\":{\"199\":1,\"581\":2,\"614\":1,\"647\":2,\"1552\":2,\"1566\":2,\"1613\":2,\"1622\":4,\"1657\":2,\"1712\":1,\"1720\":2,\"1732\":2,\"1830\":1,\"1944\":4}}],[\"√\",{\"2\":{\"199\":1}}],[\"√σ²\",{\"2\":{\"190\":1}}],[\"≈\",{\"2\":{\"199\":1}}],[\"平滑系数\",{\"2\":{\"2033\":1}}],[\"平滑且具备非线性增强能力\",{\"2\":{\"199\":1}}],[\"平均倒数排名\",{\"2\":{\"1590\":1}}],[\"平台上的模型\",{\"2\":{\"1439\":1}}],[\"平台上免费体验\",{\"2\":{\"1347\":1}}],[\"平台\",{\"2\":{\"559\":1}}],[\"平衡理解与生成能力\",{\"2\":{\"595\":1}}],[\"平衡质量与多样性\",{\"2\":{\"400\":1}}],[\"平衡了缓存需求与模型性能\",{\"2\":{\"191\":1}}],[\"平衡树\",{\"2\":{\"41\":1}}],[\"⋅φ\",{\"2\":{\"2308\":2}}],[\"⋅w\",{\"2\":{\"2033\":2}}],[\"⋅at​\",{\"2\":{\"1622\":1}}],[\"⋅at\",{\"2\":{\"1622\":2}}],[\"⋅η\",{\"2\":{\"1344\":2}}],[\"⋅∣s\",{\"2\":{\"590\":2,\"2044\":2,\"2097\":2}}],[\"⋅\",{\"2\":{\"199\":1,\"2033\":2,\"2046\":4}}],[\"总通信量也是\",{\"2\":{\"2641\":1}}],[\"总的来说\",{\"2\":{\"2609\":1}}],[\"总答案数\",{\"2\":{\"2566\":1}}],[\"总体来说flash\",{\"2\":{\"2653\":1}}],[\"总体流程\",{\"0\":{\"2314\":1}}],[\"总体而言\",{\"2\":{\"1233\":1}}],[\"总计需求高达\",{\"2\":{\"2281\":1}}],[\"总计40gb\",{\"2\":{\"1104\":1}}],[\"总延迟可表示为\",{\"2\":{\"2228\":1}}],[\"总延迟时间包括两个阶段\",{\"2\":{\"2228\":1}}],[\"总延迟时间\",{\"2\":{\"2228\":1}}],[\"总数​\",{\"2\":{\"2228\":1}}],[\"总数\",{\"2\":{\"2228\":1}}],[\"总数总延迟时间\",{\"2\":{\"2228\":1}}],[\"总行动数\",{\"2\":{\"1594\":1}}],[\"总预算=210×1012×100×30×24×3600=5\",{\"2\":{\"1232\":2}}],[\"总tokens量\",{\"2\":{\"803\":1}}],[\"总上下文长度\",{\"2\":{\"197\":1}}],[\"总结生成的长度分析\",{\"0\":{\"2588\":1}}],[\"总结展望\",{\"2\":{\"72\":1}}],[\"总结\",{\"0\":{\"185\":1,\"578\":1,\"2325\":1},\"2\":{\"20\":1}}],[\"值迭代\",{\"2\":{\"2378\":1}}],[\"值对模型输出的影响\",{\"2\":{\"1907\":1}}],[\"值也会较低\",{\"2\":{\"1698\":1}}],[\"值越高\",{\"2\":{\"1698\":1}}],[\"值得在其他强化学习应用中借鉴\",{\"2\":{\"2190\":1,\"2230\":1}}],[\"值得在其他领域探索应用\",{\"2\":{\"1898\":1}}],[\"值得在其他适配器中尝试\",{\"2\":{\"1832\":1}}],[\"值得在自然语言处理领域进一步探索和应用\",{\"2\":{\"1462\":1}}],[\"值得进一步研究和应用\",{\"2\":{\"846\":1}}],[\"值域\",{\"2\":{\"1258\":1}}],[\"值过大可能引入低质量候选词\",{\"2\":{\"630\":1}}],[\"值过小可能导致生成内容单一\",{\"2\":{\"630\":1}}],[\"值放大\",{\"2\":{\"553\":1}}],[\"值可能导致模型无法有效学习\",{\"2\":{\"338\":1}}],[\"值\",{\"2\":{\"197\":1,\"293\":1,\"1483\":1,\"1698\":1}}],[\"值提升\",{\"2\":{\"49\":1}}],[\"能与外部数据有效集成\",{\"0\":{\"1664\":1}}],[\"能在unseen样本上达到较好的生成效果\",{\"2\":{\"1368\":1}}],[\"能在保持随机性的同时提高生成质量\",{\"2\":{\"468\":1}}],[\"能显著降低计算成本\",{\"2\":{\"495\":1}}],[\"能为多种分词结果赋予概率\",{\"2\":{\"419\":1}}],[\"能否结合深度学习模型进一步优化ulm的分词效果\",{\"2\":{\"563\":1}}],[\"能否开发一种预训练模型\",{\"2\":{\"337\":1}}],[\"能否进一步改进\",{\"2\":{\"299\":1}}],[\"能更好地平衡词表大小和oov\",{\"2\":{\"308\":1}}],[\"能更好地保留上下文语义\",{\"2\":{\"205\":1}}],[\"能力进行了分析和评估\",{\"2\":{\"1500\":1}}],[\"能力优化\",{\"0\":{\"1252\":1}}],[\"能力有限\",{\"2\":{\"1238\":1}}],[\"能力\",{\"2\":{\"294\":1,\"1759\":1}}],[\"能处理训练过程中未见过的句子长度\",{\"2\":{\"239\":1}}],[\"能够适应不同类型的信息密度\",{\"2\":{\"2613\":1}}],[\"能够更有效地从长样本中学习关键推理模式\",{\"2\":{\"2605\":1,\"2662\":1}}],[\"能够更好地保留语义完整性\",{\"2\":{\"2592\":1}}],[\"能够更灵活地实现分治策略\",{\"2\":{\"2188\":1}}],[\"能够帮助我们根据实际需求选择最优的解决方案\",{\"2\":{\"2663\":1}}],[\"能够帮助我们快速定位关键信息\",{\"2\":{\"2196\":1}}],[\"能够帮助语言模型\",{\"2\":{\"1514\":1}}],[\"能够无缝地将\",{\"2\":{\"2188\":1}}],[\"能够捕捉句子的上下文关系和核心含义\",{\"2\":{\"2155\":1}}],[\"能够有效减少模型生成主观性内容的可能性\",{\"2\":{\"2690\":1}}],[\"能够有效处理特定格式的文档\",{\"2\":{\"2645\":1}}],[\"能够有效避免过拟合问题\",{\"2\":{\"1875\":1}}],[\"能够有效地传达人类的期望\",{\"2\":{\"1801\":1}}],[\"能够有效地减少模型参数量\",{\"2\":{\"860\":1}}],[\"能够根据文档的组织特征\",{\"2\":{\"1773\":1}}],[\"能够扩展到大型问题\",{\"2\":{\"1687\":1}}],[\"能够解决那些人类只能识别期望行为\",{\"2\":{\"1687\":1}}],[\"能够解决复杂的问题\",{\"2\":{\"1289\":1}}],[\"能够自主探索和改进工具使用策略\",{\"2\":{\"1684\":1}}],[\"能够提供更精确的答案\",{\"2\":{\"1664\":1}}],[\"能够提升整体任务执行效率\",{\"2\":{\"1300\":1}}],[\"能够很好地接入和利用外部数据库中的数据资源\",{\"2\":{\"1664\":1}}],[\"能够显著提升工作效率\",{\"2\":{\"1439\":1}}],[\"能够以更加简洁的形式表达复杂的信息\",{\"2\":{\"1412\":1}}],[\"能够以简明扼要的方式表达文本中的独特事实或特定概念\",{\"2\":{\"1367\":1}}],[\"能够在大规模数据集上实现高效搜索\",{\"2\":{\"2234\":1}}],[\"能够在规避复杂计算的同时高效裁剪不重要的奇异值\",{\"2\":{\"1824\":1}}],[\"能够在保证策略更新稳定性的同时提高学习效率\",{\"2\":{\"1523\":1}}],[\"能够在数天内完成多种任务\",{\"2\":{\"1336\":1}}],[\"能够在词汇表大小和编码效率之间取得平衡\",{\"2\":{\"319\":1}}],[\"能够找到用户提问最相关的知识或者是相关的对话历史\",{\"2\":{\"1333\":1}}],[\"能够理解上下文和意义\",{\"2\":{\"1321\":1}}],[\"能够直接通过训练优化\",{\"2\":{\"1281\":1}}],[\"能够高效地管理和调用数据资源\",{\"2\":{\"1250\":1}}],[\"能够处理最多1m个token\",{\"2\":{\"1256\":1}}],[\"能够处理更长的文本输入\",{\"2\":{\"1069\":1}}],[\"能够处理稀有词\",{\"2\":{\"529\":1}}],[\"能够标识每个token在序列中的具体位置\",{\"2\":{\"239\":1}}],[\"能够将输入值映射到\",{\"2\":{\"194\":1}}],[\"能源消耗预测\",{\"2\":{\"39\":1}}],[\"显式\",{\"2\":{\"2578\":1}}],[\"显式输出中间逐步的推理步骤\",{\"2\":{\"1708\":1}}],[\"显性记忆是对事实和事件的记忆\",{\"2\":{\"2049\":1}}],[\"显性\",{\"2\":{\"2049\":1}}],[\"显存效率\",{\"2\":{\"2709\":1}}],[\"显存和通信效率比较\",{\"0\":{\"2709\":1}}],[\"显存限制\",{\"0\":{\"2281\":1}}],[\"显存估算时需考虑未知数据的影响\",{\"2\":{\"2249\":1}}],[\"显存估算与实际测量差异\",{\"0\":{\"2170\":1}}],[\"显存计算公式为\",{\"2\":{\"2192\":1}}],[\"显存消耗包括以下几部分\",{\"2\":{\"2123\":1}}],[\"显存消耗内容概述\",{\"0\":{\"2123\":1}}],[\"显存消耗是一个重要的考量因素\",{\"2\":{\"2021\":1}}],[\"显存乱申请\",{\"2\":{\"2118\":1}}],[\"显存分析\",{\"2\":{\"2047\":1}}],[\"显存的消耗主要由模型参数\",{\"2\":{\"2021\":1}}],[\"显存的分配不仅涉及ai框架\",{\"2\":{\"2021\":1}}],[\"显存复杂度从\",{\"2\":{\"2008\":1}}],[\"显存管理\",{\"2\":{\"1969\":1,\"2073\":1}}],[\"显存节省\",{\"0\":{\"2008\":1},\"2\":{\"1785\":1}}],[\"显存占用成比例地减少\",{\"2\":{\"2706\":1}}],[\"显存占用\",{\"2\":{\"1178\":1}}],[\"显存占用与数据类型的影响\",{\"0\":{\"488\":1}}],[\"显存\",{\"0\":{\"2648\":1},\"2\":{\"488\":2}}],[\"显存优化方法包括\",{\"2\":{\"2073\":1}}],[\"显存优化方法\",{\"0\":{\"2073\":1}}],[\"显存优化可以通过提高算法效率或扩大显存空间来实现\",{\"2\":{\"1972\":1}}],[\"显存优化变得尤为重要\",{\"2\":{\"1972\":1}}],[\"显存优化\",{\"2\":{\"405\":1,\"462\":1,\"1389\":1,\"1919\":1}}],[\"显存优化与推理显存分析\",{\"0\":{\"1862\":1},\"1\":{\"1919\":1,\"1972\":1,\"2023\":1,\"2073\":1,\"2125\":1,\"2172\":1,\"2214\":1},\"2\":{\"193\":1}}],[\"显示出语言建模能力的稳步提升\",{\"2\":{\"245\":1}}],[\"显著降低了模型的内存使用\",{\"2\":{\"1679\":1}}],[\"显著降低推理阶段的显存需求\",{\"2\":{\"212\":1}}],[\"显著提升了模型的广泛适用性\",{\"2\":{\"1446\":1}}],[\"显著提升了模型在代码能力和逻辑推理能力方面的表现\",{\"2\":{\"1117\":1}}],[\"显著提升了生成内容的真实性和处理更长输入序列的能力\",{\"2\":{\"1082\":1}}],[\"显著提升了性能\",{\"2\":{\"1041\":1}}],[\"显著提升32k\",{\"2\":{\"502\":1}}],[\"显著提高了计算效率\",{\"2\":{\"941\":1}}],[\"显著地提升吞吐量\",{\"2\":{\"750\":1}}],[\"显著减少lora\",{\"2\":{\"1636\":1}}],[\"显著减少显存占用\",{\"2\":{\"462\":1}}],[\"显著减少了稀有字符对词汇表的占用\",{\"2\":{\"318\":1}}],[\"显著减少计算量\",{\"2\":{\"116\":1}}],[\"显著增加\",{\"2\":{\"222\":1}}],[\"过多的碎片化信息可能会干扰模型的判断\",{\"2\":{\"2533\":1}}],[\"过短的文本块可能只包含片段信息\",{\"2\":{\"2522\":1}}],[\"过短的文本块也会对大模型输出产生不利影响\",{\"2\":{\"2498\":1}}],[\"过短的块容易需要多个块才能拼凑完整答案\",{\"2\":{\"1763\":1}}],[\"过长的文本块会占据更多输入空间\",{\"2\":{\"2483\":1}}],[\"过长的文本块会带来一系列问题\",{\"2\":{\"2419\":1}}],[\"过长的文本块可能涵盖多个主题或观点\",{\"2\":{\"2465\":1}}],[\"过长的块可能包含无关信息\",{\"2\":{\"1763\":1}}],[\"过长的chunk\",{\"2\":{\"1513\":1}}],[\"过拟合\",{\"2\":{\"1414\":1}}],[\"过早冻结共享专家参数\",{\"2\":{\"1324\":1}}],[\"过gate后\",{\"2\":{\"1119\":1}}],[\"过大\",{\"2\":{\"1297\":1}}],[\"过大则增加计算复杂度\",{\"2\":{\"1109\":1}}],[\"过大则增加计算成本\",{\"2\":{\"348\":1}}],[\"过大的词向量维度\",{\"2\":{\"1079\":1}}],[\"过小\",{\"2\":{\"1297\":1}}],[\"过小的词向量维度\",{\"2\":{\"1079\":1}}],[\"过小可能导致生成结果质量下降\",{\"2\":{\"348\":1}}],[\"过程奖励模型\",{\"2\":{\"2647\":1}}],[\"过程\",{\"2\":{\"2366\":1}}],[\"过程中\",{\"2\":{\"2180\":1}}],[\"过程中不存在显式的策略\",{\"2\":{\"724\":1}}],[\"过程建模两种方式\",{\"0\":{\"1991\":1}}],[\"过程涉及两个单独的提示\",{\"2\":{\"1885\":1}}],[\"过程编程关注步骤和功能\",{\"2\":{\"20\":1}}],[\"过程编程侧重函数和操作的顺序\",{\"2\":{\"20\":1}}],[\"过程编程是以函数为中心的编程范式\",{\"2\":{\"12\":1}}],[\"过程编程\",{\"0\":{\"12\":1},\"2\":{\"20\":3}}],[\"过度依赖单一模型的采样概率进行调整\",{\"2\":{\"2018\":1}}],[\"过度依赖训练集上的表现而忽视测试集的效果可能导致模型无法泛化\",{\"2\":{\"1601\":1}}],[\"过度依赖默认参数\",{\"2\":{\"1066\":1}}],[\"过度依赖模板生成的响应可能会导致对齐质量下降\",{\"2\":{\"967\":1}}],[\"过度依赖打分器的准确率\",{\"2\":{\"718\":1}}],[\"过度过滤导致数据量不足\",{\"2\":{\"582\":1}}],[\"过滤准确率为1和0的样本\",{\"2\":{\"2519\":1}}],[\"过滤掉包含英语和中文数学基准测试题目或答案的网页\",{\"2\":{\"1190\":1}}],[\"过滤掉出现次数较少的单词\",{\"2\":{\"1021\":1}}],[\"过滤掉长度小于10且符合特定模板\",{\"2\":{\"548\":1}}],[\"过滤\",{\"0\":{\"456\":1,\"2282\":1}}],[\"过于集中某些节点信息会影响学习效果\",{\"2\":{\"192\":1}}],[\"×oi​+li​\",{\"2\":{\"2618\":1}}],[\"×oi+torch\",{\"2\":{\"2618\":1}}],[\"×li​+torch\",{\"2\":{\"2604\":1}}],[\"×li+torch\",{\"2\":{\"2604\":1}}],[\"×l\",{\"2\":{\"2604\":2}}],[\"×params​\",{\"2\":{\"2192\":1}}],[\"×params1024×1024×1024\",{\"2\":{\"2192\":1}}],[\"×模型尺寸\",{\"2\":{\"1232\":2}}],[\"×capacity\",{\"2\":{\"1229\":2}}],[\"×\",{\"2\":{\"190\":4,\"199\":1}}],[\"βlogπ∗\",{\"2\":{\"2046\":2}}],[\"βlogπref​\",{\"2\":{\"1795\":1}}],[\"βlog⁡πref\",{\"2\":{\"2046\":2}}],[\"βlog⁡πθ\",{\"2\":{\"1795\":1}}],[\"β2=0\",{\"2\":{\"1204\":1}}],[\"β2\",{\"2\":{\"1162\":1}}],[\"β1​r\",{\"2\":{\"1830\":2,\"1889\":2}}],[\"β1=0\",{\"2\":{\"1204\":1}}],[\"β1\",{\"2\":{\"1162\":1}}],[\"β\",{\"2\":{\"190\":2,\"199\":1,\"709\":1,\"911\":1,\"1033\":1,\"1123\":1,\"1323\":1,\"1552\":1,\"1789\":1,\"1907\":1,\"1960\":1,\"2098\":1,\"2215\":1,\"2524\":1}}],[\"γ\",{\"2\":{\"190\":2,\"643\":1,\"856\":1,\"876\":1,\"965\":1,\"1076\":2,\"1123\":1,\"1323\":1,\"2124\":1}}],[\"ε\",{\"2\":{\"190\":2}}],[\"²\",{\"2\":{\"190\":1}}],[\"μ\",{\"2\":{\"190\":3}}],[\"未知\",{\"2\":{\"2338\":2}}],[\"未知数据\",{\"2\":{\"2123\":1}}],[\"未知的utf\",{\"2\":{\"1112\":1}}],[\"未明确\",{\"2\":{\"1487\":1}}],[\"未指定\",{\"2\":{\"1341\":1}}],[\"未能正确缩小词表大小可能导致加载速度减慢\",{\"2\":{\"1192\":1}}],[\"未绑定嵌入\",{\"2\":{\"1155\":1,\"1490\":1}}],[\"未根据实验数据调整模型参数\",{\"2\":{\"1329\":1}}],[\"未根据任务调整参数可能导致无法达到预期效果\",{\"2\":{\"1066\":1}}],[\"未根据具体任务选择适合的注意力机制优化方法\",{\"2\":{\"378\":1}}],[\"未对测试集和训练集进行严格去重\",{\"2\":{\"718\":1}}],[\"未对注意力掩码进行微调可能导致跨组信息泄漏\",{\"2\":{\"241\":1}}],[\"未删除\",{\"2\":{\"657\":1}}],[\"未分开监控不同类别数据的loss可能遮蔽问题来源\",{\"2\":{\"627\":1}}],[\"未携带必要参数\",{\"2\":{\"594\":1}}],[\"未充分考虑目标网站的反爬机制\",{\"2\":{\"594\":1}}],[\"未充分考虑多语言数据的多样性\",{\"2\":{\"582\":1}}],[\"未充分微调可能导致扩展后的上下文窗口性能未达到预期\",{\"2\":{\"313\":1}}],[\"未考虑语料质量\",{\"2\":{\"461\":1}}],[\"未处理dead\",{\"2\":{\"354\":1}}],[\"未正确初始化可训练向量\",{\"2\":{\"1452\":1}}],[\"未正确初始化缓存\",{\"2\":{\"231\":1}}],[\"未正确理解公式中各项的作用\",{\"2\":{\"1335\":1}}],[\"未正确实施学习率调度策略\",{\"2\":{\"1262\":1}}],[\"未正确实现上下文信息融合可能导致解码结果不准确\",{\"2\":{\"417\":1}}],[\"未正确设置n\",{\"2\":{\"1109\":1}}],[\"未正确设置预分词器或模型参数会影响最终分词效果\",{\"2\":{\"576\":1}}],[\"未正确设置频率范围\",{\"2\":{\"309\":1}}],[\"未登录词\",{\"2\":{\"308\":1}}],[\"未来在多轮对话数据的自动构造和优化方面将会有更多创新技术出现\",{\"2\":{\"2435\":1}}],[\"未来将有更多针对特定业务需求的数据优化策略出现\",{\"2\":{\"2426\":1}}],[\"未来sft训练和评估将更加依赖于自动化工具和更智能的评估指标\",{\"2\":{\"2362\":1}}],[\"未来展望与问题\",{\"0\":{\"2350\":1}}],[\"未来transformer中的位置编码可能进一步朝以下方向发展\",{\"2\":{\"1543\":1}}],[\"未来预训练策略可能会更加注重以下方向\",{\"2\":{\"1526\":1}}],[\"未来预训练中的scaling\",{\"2\":{\"1464\":1}}],[\"未来速度将进一步提升\",{\"2\":{\"1451\":1}}],[\"未来或将进一步优化树构建策略\",{\"2\":{\"980\":1}}],[\"未来或需更复杂的模糊匹配算法\",{\"2\":{\"753\":1}}],[\"未来llm将更广泛地应用于复杂文档处理和实时数据分析领域\",{\"2\":{\"940\":1}}],[\"未来数据解析将更加智能化\",{\"2\":{\"701\":1}}],[\"未来\",{\"2\":{\"535\":1,\"648\":1,\"788\":1,\"1036\":1,\"1427\":1,\"1700\":1,\"2321\":1,\"2437\":1,\"2473\":1,\"2497\":1}}],[\"未来解码策略将更注重结合概率分布与上下文语义\",{\"2\":{\"481\":1}}],[\"未来研究可能集中在如何自动选择最优进制或动态调整基数\",{\"2\":{\"314\":1}}],[\"未来趋势预测\",{\"0\":{\"598\":1}}],[\"未来趋势\",{\"2\":{\"289\":1}}],[\"未来可能出现\",{\"2\":{\"1742\":1}}],[\"未来可能出现基于任务自动调整采样参数的技术\",{\"2\":{\"703\":1}}],[\"未来可能会出现专门针对超大规模模型的自动容灾与优化工具\",{\"2\":{\"700\":1}}],[\"未来可能会出现更加智能的自动化调参工具\",{\"2\":{\"2488\":1}}],[\"未来可能会出现更加智能化的数据筛选算法\",{\"2\":{\"598\":1}}],[\"未来可能会出现更多结合深度学习和传统方法的新型分词工具\",{\"2\":{\"680\":1}}],[\"未来可能会出现更多\",{\"2\":{\"664\":1}}],[\"未来可能会出现更高效\",{\"2\":{\"239\":1}}],[\"未来可能会\",{\"2\":{\"412\":1}}],[\"未来可以探索更多场景适配\",{\"2\":{\"189\":1}}],[\"未调整初始化或未使用warmup策略\",{\"2\":{\"211\":1}}],[\"未优化矩阵运算可能导致性能反而下降\",{\"2\":{\"210\":1}}],[\"未优化qkv矩阵计算性能\",{\"2\":{\"209\":1}}],[\"未命名数据\",{\"2\":{\"2123\":1}}],[\"未命名\",{\"2\":{\"172\":1}}],[\"核函数形式值得探索更广泛应用场景\",{\"2\":{\"257\":1}}],[\"核函数形式的attention能否在自然语言处理领域进一步推广\",{\"2\":{\"233\":1}}],[\"核函数形式的attention机制在cv领域已有应用\",{\"2\":{\"189\":1}}],[\"核心代码解析\",{\"0\":{\"1731\":1,\"1883\":1}}],[\"核心代码示例\",{\"2\":{\"515\":1}}],[\"核心理念\",{\"0\":{\"1684\":1,\"1860\":1}}],[\"核心流程包括sft训练\",{\"2\":{\"1530\":1}}],[\"核心目标函数推导\",{\"0\":{\"1506\":1},\"1\":{\"1552\":1,\"1602\":1,\"1657\":1,\"1712\":1,\"1769\":1,\"1830\":1,\"1889\":1,\"1944\":1,\"1994\":1,\"2046\":1}}],[\"核心目标\",{\"0\":{\"1361\":1}}],[\"核心目标是降低传统self\",{\"2\":{\"109\":1}}],[\"核心公式展开\",{\"0\":{\"1359\":1}}],[\"核心权重使用\",{\"2\":{\"1298\":1}}],[\"核心权重采用\",{\"2\":{\"1248\":1}}],[\"核心架构演进\",{\"0\":{\"957\":1},\"1\":{\"998\":1,\"1038\":1}}],[\"核心特性\",{\"0\":{\"918\":1}}],[\"核心数据筛选方法\",{\"0\":{\"395\":1},\"1\":{\"421\":1,\"446\":1,\"473\":1}}],[\"核心机制\",{\"0\":{\"750\":1},\"2\":{\"324\":1}}],[\"核心模块解析材料\",{\"2\":{\"299\":1}}],[\"核心解决方案\",{\"2\":{\"212\":1}}],[\"核心观点是使用不同的学习率策略\",{\"2\":{\"1660\":1}}],[\"核心观点与实现步骤\",{\"0\":{\"331\":1},\"1\":{\"355\":1,\"381\":1,\"407\":1}}],[\"核心观点概述\",{\"0\":{\"319\":1,\"1166\":1}}],[\"核心观点\",{\"0\":{\"180\":1,\"184\":1,\"492\":1,\"521\":1,\"574\":1,\"592\":1,\"611\":1,\"612\":1,\"652\":1,\"676\":1,\"699\":1,\"713\":1,\"911\":1,\"932\":1,\"933\":1,\"1460\":1,\"1539\":1,\"1566\":1,\"1572\":1,\"1636\":1,\"1653\":1,\"1659\":1,\"1681\":1,\"1692\":1,\"1735\":1,\"1853\":1,\"1899\":1,\"2327\":1,\"2689\":1},\"1\":{\"646\":1,\"681\":1,\"720\":1,\"1954\":1,\"2004\":1}}],[\"核心观点总结\",{\"0\":{\"99\":1,\"101\":1,\"129\":1,\"159\":1,\"253\":1,\"343\":1,\"368\":1,\"403\":1,\"411\":1,\"422\":1,\"423\":1,\"425\":1,\"449\":1,\"464\":1,\"514\":1,\"518\":1,\"587\":1,\"621\":1,\"989\":1,\"1031\":1,\"1046\":1,\"1060\":1,\"1061\":1,\"1072\":1,\"1088\":1,\"1108\":1,\"1131\":1,\"1132\":1,\"1150\":1,\"1197\":1,\"1491\":1,\"1515\":1,\"1522\":1,\"1533\":1,\"1541\":1,\"1668\":1,\"1673\":1,\"1680\":1,\"1745\":1,\"1747\":1,\"1752\":1,\"1783\":1,\"1846\":1,\"1875\":1,\"1955\":1,\"2021\":1,\"2099\":1,\"2151\":1,\"2165\":1,\"2180\":1,\"2181\":1,\"2260\":1,\"2267\":1,\"2273\":1,\"2311\":1,\"2328\":1,\"2359\":1,\"2429\":1,\"2507\":1,\"2545\":1,\"2575\":1,\"2603\":1,\"2637\":1,\"2644\":1},\"1\":{\"149\":1,\"170\":1,\"191\":1,\"212\":1,\"1199\":1}}],[\"核心原理\",{\"0\":{\"136\":1},\"2\":{\"247\":1}}],[\"核心概念\",{\"0\":{\"295\":1,\"340\":1,\"416\":1,\"468\":1,\"504\":1},\"1\":{\"536\":1,\"569\":1,\"602\":1},\"2\":{\"125\":1}}],[\"核心内容解析\",{\"0\":{\"493\":1},\"1\":{\"525\":1,\"558\":1,\"593\":1}}],[\"核心内容概述\",{\"0\":{\"138\":1}}],[\"核心内容总结\",{\"0\":{\"121\":1,\"174\":1,\"248\":1,\"373\":1,\"433\":1,\"1147\":1,\"1153\":1,\"1265\":1}}],[\"核心内容\",{\"0\":{\"108\":1,\"127\":1,\"148\":1,\"224\":1,\"1183\":1,\"1714\":1},\"1\":{\"126\":1,\"146\":1,\"147\":1,\"167\":1,\"168\":1,\"169\":1,\"188\":1,\"189\":1,\"190\":1,\"209\":1,\"211\":1,\"232\":1,\"247\":1,\"1232\":1,\"1282\":1,\"1329\":1,\"1771\":1,\"1832\":1,\"1891\":1}}],[\"核心思想与实现\",{\"0\":{\"100\":1},\"1\":{\"116\":1,\"135\":1,\"155\":1}}],[\"核心思想\",{\"0\":{\"97\":1,\"221\":1,\"290\":1,\"1217\":1,\"1559\":1},\"2\":{\"189\":1,\"983\":1}}],[\"核心思路与实践\",{\"0\":{\"298\":1},\"1\":{\"320\":1,\"343\":1,\"367\":1,\"393\":1,\"419\":1,\"444\":1,\"471\":1,\"498\":1,\"530\":1,\"563\":1},\"2\":{\"5\":1}}],[\"核心思路与实践|使用unigram语言模型\",{\"2\":{\"5\":1}}],[\"核心功能实现\",{\"2\":{\"62\":1}}],[\"核心挑战\",{\"2\":{\"57\":1}}],[\"核心组件\",{\"2\":{\"34\":1}}],[\"核心\",{\"2\":{\"21\":4}}],[\"键\",{\"2\":{\"188\":1}}],[\"键值缓存技术详解\",{\"2\":{\"303\":1}}],[\"键值缓存\",{\"2\":{\"107\":1}}],[\"推导出一系列步骤来完成特定目标\",{\"2\":{\"1439\":1}}],[\"推动科学技术的突破\",{\"2\":{\"1382\":1}}],[\"推算大模型上的效果\",{\"2\":{\"533\":1}}],[\"推荐参考\",{\"2\":{\"2663\":1}}],[\"推荐系统\",{\"2\":{\"1876\":1}}],[\"推荐\",{\"2\":{\"1542\":1}}],[\"推荐采用\",{\"2\":{\"1358\":1}}],[\"推荐使用\",{\"2\":{\"2235\":1}}],[\"推荐使用openrlhf框架\",{\"2\":{\"2177\":1}}],[\"推荐使用llama架构\",{\"2\":{\"1265\":1}}],[\"推荐使用开源平台opencompass进行benchmark评估\",{\"2\":{\"549\":1}}],[\"推荐算法\",{\"2\":{\"605\":1}}],[\"推荐工具\",{\"2\":{\"485\":1}}],[\"推荐公式\",{\"2\":{\"184\":1}}],[\"推理成本\",{\"2\":{\"2699\":1}}],[\"推理数据\",{\"2\":{\"2564\":1}}],[\"推理数据通过设计推理提示和拒绝采样生成\",{\"2\":{\"2504\":1}}],[\"推理优化\",{\"2\":{\"2225\":1}}],[\"推理吞吐高的特点\",{\"2\":{\"2129\":1}}],[\"推理时\",{\"2\":{\"2118\":1}}],[\"推理时可扩展至8192\",{\"2\":{\"1204\":1}}],[\"推理加速方案\",{\"2\":{\"2081\":1}}],[\"推理阶段不使用\",{\"2\":{\"2069\":1}}],[\"推理阶段的显存占用可以通过以下公式估算\",{\"2\":{\"2023\":1}}],[\"推理阶段的显存占用可以通过公式估算\",{\"2\":{\"1972\":1}}],[\"推理阶段显存分析\",{\"0\":{\"2023\":1},\"2\":{\"2214\":1}}],[\"推理步骤\",{\"2\":{\"2011\":1}}],[\"推理能力的技术\",{\"2\":{\"1990\":1}}],[\"推理驱动的交互优化框架\",{\"0\":{\"1970\":1},\"1\":{\"2022\":1,\"2072\":1,\"2124\":1,\"2171\":1,\"2213\":1,\"2250\":1}}],[\"推理模型探索\",{\"2\":{\"1917\":1}}],[\"推理任务\",{\"0\":{\"1842\":1}}],[\"推理框架一般会将第1次推理\",{\"2\":{\"1782\":1}}],[\"推理\",{\"0\":{\"2171\":1,\"2189\":1},\"1\":{\"2228\":1},\"2\":{\"1608\":1,\"2022\":1,\"2081\":2}}],[\"推理效率\",{\"2\":{\"990\":1}}],[\"推理性能\",{\"2\":{\"899\":1,\"2404\":1}}],[\"推理和生成\",{\"0\":{\"742\":1}}],[\"推理过程的状态\",{\"2\":{\"2262\":1}}],[\"推理过程\",{\"2\":{\"2261\":1}}],[\"推理过程与答案\",{\"2\":{\"1766\":1}}],[\"推理过程中的语言一致性奖励\",{\"0\":{\"2491\":1}}],[\"推理过程中\",{\"2\":{\"1022\":1,\"1910\":1}}],[\"推理过程中需要缓存大量的key和value\",{\"2\":{\"149\":1}}],[\"推理过程主要包括\",{\"2\":{\"351\":1}}],[\"推理机制概述\",{\"0\":{\"351\":1},\"1\":{\"376\":1}}],[\"推理机制\",{\"0\":{\"1886\":1},\"1\":{\"1941\":1,\"1991\":1,\"2043\":1},\"2\":{\"328\":1}}],[\"推理耗时\",{\"0\":{\"328\":1,\"1827\":1},\"1\":{\"351\":1,\"376\":1,\"402\":1,\"429\":1,\"455\":1,\"483\":1,\"513\":1,\"546\":1,\"580\":1,\"613\":1,\"648\":1,\"683\":1,\"1886\":1,\"1941\":1,\"1991\":1,\"2043\":1,\"2095\":1,\"2145\":1,\"2189\":1,\"2228\":1,\"2263\":1},\"2\":{\"5\":1,\"113\":1,\"193\":1}}],[\"推理耗时|大语言模型学习\",{\"2\":{\"5\":1}}],[\"尤其适用于摘要生成任务\",{\"2\":{\"2292\":1}}],[\"尤其适用于搜索引擎或推荐系统等场景\",{\"2\":{\"1590\":1}}],[\"尤其适用于复杂环境中\",{\"2\":{\"717\":1}}],[\"尤其适用于超长输入场景\",{\"2\":{\"155\":1}}],[\"尤其当pdf中包含公式或表格时\",{\"2\":{\"465\":1}}],[\"尤其在处理自然语言时\",{\"2\":{\"1231\":1}}],[\"尤其在处理离散型数据时非常有效\",{\"2\":{\"871\":1}}],[\"尤其在需要处理复杂上下文的应用场景中\",{\"2\":{\"706\":1}}],[\"尤其在解决复杂数学问题和优化计算方面表现突出\",{\"2\":{\"675\":1}}],[\"尤其在支持\",{\"2\":{\"462\":1}}],[\"尤其在高质量数据的获取上\",{\"2\":{\"411\":1}}],[\"尤其对于大语言模型的预训练和微调\",{\"2\":{\"422\":1}}],[\"尤其是对于段落中间提供的信息\",{\"2\":{\"2582\":1}}],[\"尤其是transformer架构中\",{\"2\":{\"2547\":1}}],[\"尤其是\",{\"2\":{\"2323\":1}}],[\"尤其是其独特的分块计算方法\",{\"2\":{\"1750\":1}}],[\"尤其是复杂的数学题\",{\"2\":{\"1708\":1}}],[\"尤其是任务前缀声明部分\",{\"2\":{\"1157\":1}}],[\"尤其是多模态任务\",{\"2\":{\"362\":1}}],[\"尤其是在训练步数增加后\",{\"2\":{\"2530\":1}}],[\"尤其是在相互关联或关系数据中\",{\"2\":{\"2335\":1}}],[\"尤其是在不同轮次输出长度不一致的情况下\",{\"2\":{\"2267\":1}}],[\"尤其是在使用自举方法时\",{\"2\":{\"2107\":1}}],[\"尤其是在深度学习模型中涉及到概率分布的计算时\",{\"2\":{\"1925\":1}}],[\"尤其是在面对超大规模的\",{\"2\":{\"1813\":1}}],[\"尤其是在处理复杂文档或大规模数据时\",{\"2\":{\"2104\":1}}],[\"尤其是在处理自然语言处理任务时\",{\"2\":{\"1807\":1}}],[\"尤其是在处理不同批次数据时\",{\"2\":{\"1733\":1}}],[\"尤其是在处理人类反馈时的应用\",{\"2\":{\"1517\":1}}],[\"尤其是在主流的基于\",{\"2\":{\"1617\":1}}],[\"尤其是在低资源场景和实时推理任务中\",{\"2\":{\"1537\":1}}],[\"尤其是在多语言能力上表现出色\",{\"2\":{\"1102\":1}}],[\"尤其是在动态和不确定环境中\",{\"2\":{\"927\":1}}],[\"尤其是在复杂环境下的决策问题中\",{\"2\":{\"937\":1}}],[\"尤其是在复杂环境下的决策优化\",{\"2\":{\"745\":1}}],[\"尤其是在复杂环境中\",{\"2\":{\"857\":1}}],[\"尤其是在硬件逐步优化支持低精度计算的背景下\",{\"2\":{\"698\":1}}],[\"尤其是在计算资源有限的情况下\",{\"2\":{\"693\":1}}],[\"尤其是在微调\",{\"2\":{\"369\":1}}],[\"尤其是在微调后效果显著提升\",{\"2\":{\"180\":1}}],[\"尤其是在需要高效处理长文本任务时\",{\"2\":{\"346\":1}}],[\"尤其是在大规模上下文扩展时\",{\"2\":{\"336\":1}}],[\"尤其是在神经机器翻译\",{\"2\":{\"319\":1}}],[\"指在更新模型参数前\",{\"2\":{\"2217\":1}}],[\"指在不同层中使用相同的参数值\",{\"2\":{\"1866\":1}}],[\"指模型在训练过程中通过内部机制自动提升性能\",{\"2\":{\"2169\":1}}],[\"指的是高带宽内存的访问次数\",{\"2\":{\"2110\":1}}],[\"指的是在计算过程中优化输入输出操作以减少延迟\",{\"2\":{\"2110\":1}}],[\"指那些可以有意识地回忆起的内容\",{\"2\":{\"2049\":1}}],[\"指\",{\"2\":{\"1766\":1}}],[\"指一个token平均对应多少个汉字\",{\"2\":{\"1531\":1}}],[\"指令进化\",{\"2\":{\"2280\":1}}],[\"指令微调\",{\"2\":{\"2088\":1}}],[\"指令微调与强化学习\",{\"0\":{\"1240\":1}}],[\"指令\",{\"2\":{\"1766\":1}}],[\"指令遵循能力\",{\"2\":{\"2076\":1}}],[\"指令遵循训练\",{\"0\":{\"1976\":1}}],[\"指令遵循\",{\"0\":{\"1637\":1}}],[\"指令遵循和多轮对话\",{\"2\":{\"967\":1}}],[\"指令数据\",{\"2\":{\"1389\":1}}],[\"指令的补充内容\",{\"2\":{\"1368\":1}}],[\"指定平台爬虫id列表示例\",{\"0\":{\"559\":1}}],[\"指导模型更新\",{\"2\":{\"1614\":1}}],[\"指导模型生成准确输出\",{\"2\":{\"1333\":1}}],[\"指导策略更新\",{\"2\":{\"619\":1}}],[\"指导策略更新的步长和方向\",{\"2\":{\"518\":1}}],[\"指导思想\",{\"2\":{\"474\":1}}],[\"指数运算效率低\",{\"2\":{\"330\":1}}],[\"指数运算耗费资源\",{\"2\":{\"330\":1}}],[\"指数运算耗费计算资源\",{\"2\":{\"194\":1}}],[\"指数运算导致计算效率较低\",{\"2\":{\"285\":1}}],[\"指标\",{\"2\":{\"180\":1,\"1178\":1,\"2076\":1}}],[\"指向函数增长最快的方向\",{\"2\":{\"32\":1}}],[\"通俗解读\",{\"0\":{\"2331\":1}}],[\"通俗解释\",{\"2\":{\"1232\":1}}],[\"通俗来说\",{\"2\":{\"2145\":1}}],[\"通俗化说明\",{\"0\":{\"1418\":1}}],[\"通俗语言转述\",{\"0\":{\"1073\":1}}],[\"通俗地说\",{\"2\":{\"811\":1}}],[\"通信量与流水线各个阶段边界的激活值大小成正相关\",{\"2\":{\"2708\":1}}],[\"通信量分析\",{\"0\":{\"2486\":1,\"2621\":1,\"2641\":1}}],[\"通信\",{\"2\":{\"2708\":1}}],[\"通信成本最低\",{\"0\":{\"2708\":1}}],[\"通信涉及到\",{\"2\":{\"2486\":1}}],[\"通信效率\",{\"2\":{\"2709\":1}}],[\"通信效率提升了\",{\"2\":{\"2369\":1}}],[\"通信效率分析\",{\"0\":{\"2369\":1}}],[\"通信数据量是\",{\"2\":{\"2308\":2}}],[\"通信将\",{\"2\":{\"2129\":1}}],[\"通信有明显精度损失\",{\"2\":{\"2118\":1}}],[\"通信优化机制\",{\"0\":{\"1038\":1}}],[\"通信平衡损失\",{\"2\":{\"1030\":1,\"1073\":1}}],[\"通信阻塞\",{\"2\":{\"908\":1}}],[\"通用人工智能\",{\"2\":{\"1136\":1}}],[\"通用数据的采样策略对模型性能影响显著\",{\"2\":{\"772\":1}}],[\"通用语料的困惑度变化规律\",{\"2\":{\"558\":1}}],[\"通用模型需覆盖中英文\",{\"2\":{\"535\":1}}],[\"通常是gelu\",{\"2\":{\"2579\":1}}],[\"通常是训练集\",{\"2\":{\"1222\":1}}],[\"通常不需要进行额外的设计\",{\"2\":{\"2526\":1}}],[\"通常不设置\",{\"2\":{\"2252\":1}}],[\"通常通过调用外部数据库或向量库作为工具来实现信息的补充与增强\",{\"2\":{\"2469\":1}}],[\"通常设置为1个epoch\",{\"2\":{\"2217\":1}}],[\"通常设为4k\",{\"2\":{\"2252\":1}}],[\"通常设为\",{\"2\":{\"261\":3}}],[\"通常我们不会对损失函数和训练策略进行大幅修改\",{\"2\":{\"2177\":1}}],[\"通常采用\",{\"2\":{\"2081\":1}}],[\"通常仍选择全量微调\",{\"2\":{\"1932\":1}}],[\"通常需要多个模型之间进行交互通信\",{\"2\":{\"2081\":1}}],[\"通常需要四个模型\",{\"2\":{\"1899\":1}}],[\"通常需要通过实验确定模型表现较好的kl变化\",{\"2\":{\"1033\":1}}],[\"通常\",{\"2\":{\"1833\":1,\"2560\":1}}],[\"通常用于自然语言处理任务\",{\"2\":{\"1589\":1}}],[\"通常希望每个输入对应一个唯一的输出值\",{\"2\":{\"1559\":1}}],[\"通常会对相对位置向量进行截断\",{\"2\":{\"1266\":1}}],[\"通常会使用一个固定长度的输入序列\",{\"2\":{\"782\":1}}],[\"通常包括记忆和规划功能\",{\"2\":{\"1233\":1}}],[\"通常一万个样本足以达到标注员水平\",{\"2\":{\"1213\":1}}],[\"通常使用线性量化\",{\"2\":{\"868\":1}}],[\"通常只能访问教师模型的输出\",{\"2\":{\"677\":1}}],[\"通常情况下\",{\"2\":{\"570\":1,\"715\":1,\"1718\":1,\"2051\":1,\"2372\":1,\"2386\":1}}],[\"通常以pdf格式存在\",{\"2\":{\"568\":1}}],[\"通常作为ffn的默认激活函数\",{\"2\":{\"178\":1}}],[\"通道数很大的卷积运算\",{\"2\":{\"2027\":1}}],[\"通道归一化\",{\"2\":{\"227\":1}}],[\"通道维度\",{\"2\":{\"227\":1}}],[\"通过修改提示词\",{\"2\":{\"2687\":1}}],[\"通过关键词标注\",{\"2\":{\"2675\":1}}],[\"通过关键词过滤目标内容\",{\"2\":{\"494\":1}}],[\"通过奖励机制来训练模型\",{\"2\":{\"2647\":1}}],[\"通过奖励机制优化生成质量\",{\"2\":{\"703\":1}}],[\"通过简单的输出提取和强化学习应用\",{\"2\":{\"2627\":1}}],[\"通过简单提取输出就能全面优于\",{\"2\":{\"2617\":1}}],[\"通过简单提取\",{\"2\":{\"2603\":1}}],[\"通过token\",{\"2\":{\"2612\":1,\"2665\":1}}],[\"通过td\",{\"2\":{\"1541\":1}}],[\"通过爱因斯坦求和约定计算相似度矩阵\",{\"2\":{\"2581\":1}}],[\"通过添加一些同步通信操作来创建一个简单的模型并行实现\",{\"2\":{\"2579\":1}}],[\"通过添加价值头\",{\"2\":{\"1582\":1}}],[\"通过实验不断调整分块策略\",{\"2\":{\"2543\":1}}],[\"通过实验对比\",{\"2\":{\"2311\":1}}],[\"通过拒绝采样确保推理数据质量\",{\"2\":{\"2527\":1}}],[\"通过过滤\",{\"2\":{\"2519\":1}}],[\"通过过滤掉准确率为1和0的样本\",{\"2\":{\"2507\":1}}],[\"通过上述优化\",{\"2\":{\"2676\":1}}],[\"通过上述机制\",{\"2\":{\"846\":1}}],[\"通过上下文筛选与压缩的方法缩短窗口长度\",{\"2\":{\"2484\":1}}],[\"通过更精细的数据清洗\",{\"2\":{\"2484\":1}}],[\"通过预算约束来限制某些动作的选择\",{\"2\":{\"2455\":1}}],[\"通过后处理算法简化输出语言结构\",{\"2\":{\"2346\":1}}],[\"通过后续训练\",{\"2\":{\"1578\":1}}],[\"通过后续状态的价值估计来更新当前状态的价值估计\",{\"2\":{\"608\":1}}],[\"通过限制每个token仅与其前w个token做注意力计算\",{\"2\":{\"2326\":1}}],[\"通过限制策略更新的变化幅度\",{\"2\":{\"521\":1}}],[\"通过本文介绍的两种工作流\",{\"2\":{\"2325\":1}}],[\"通过本文的分析\",{\"2\":{\"2182\":1}}],[\"通过禁用默认的平均机制并调整分母为全局批次的对话轮数\",{\"2\":{\"2300\":1}}],[\"通过第一轮的数据构造第二轮的提示\",{\"2\":{\"2291\":1}}],[\"通过传统的orm\",{\"2\":{\"2273\":1}}],[\"通过构建和收集少量高质量的长思维链\",{\"2\":{\"2474\":1}}],[\"通过构建具有多条输入边的顶点\",{\"2\":{\"2188\":1}}],[\"通过构建模型间通信和模型内通信的层次化通信平面\",{\"2\":{\"2081\":1}}],[\"通过合并多轮对话样本\",{\"2\":{\"2300\":1}}],[\"通过合成数据和适量的预训练数据\",{\"2\":{\"2180\":1}}],[\"通过合理设置\",{\"2\":{\"2319\":1}}],[\"通过合理利用gpu的不同内存层级和优化kernel执行策略\",{\"2\":{\"2175\":1}}],[\"通过合理配置gpu和专家数量\",{\"2\":{\"1597\":1}}],[\"通过合理缩小词表大小和优化位置编码\",{\"2\":{\"1242\":1}}],[\"通过各种启发式规则收集不同任务类型的数据集\",{\"2\":{\"2168\":1}}],[\"通过优化索引\",{\"2\":{\"2366\":1}}],[\"通过优化数据的多样性\",{\"2\":{\"2165\":1}}],[\"通过优化显存管理减少碎片\",{\"2\":{\"2073\":1}}],[\"通过消融实验验证\",{\"2\":{\"2173\":1}}],[\"通过消去z\",{\"2\":{\"2148\":1}}],[\"通过消歧技术确保引用的一致性\",{\"2\":{\"1376\":1}}],[\"通过计算公式\",{\"2\":{\"2099\":1}}],[\"通过保留$$1\",{\"2\":{\"2085\":1}}],[\"通过保持额外的两个统计量可以实现softmax的分块计算\",{\"2\":{\"2030\":1}}],[\"通过衡量向量夹角的相似性来判断内容的相关性\",{\"2\":{\"2051\":1}}],[\"通过剪辑机制来稳定训练过程\",{\"2\":{\"2044\":1,\"2097\":1}}],[\"通过工具如nvidia的nvidia\",{\"2\":{\"2021\":1}}],[\"通过累积折扣奖励来估计\",{\"2\":{\"1992\":1,\"2045\":1}}],[\"通过累积概率设定一个阈值\",{\"2\":{\"340\":1}}],[\"通过显式构建离散字符的模板\",{\"2\":{\"1981\":1}}],[\"通过显式处理空格并用特殊符号\",{\"2\":{\"426\":1}}],[\"通过重复应用分块规则\",{\"2\":{\"2606\":1}}],[\"通过重复随机抽样和概率统计方法\",{\"2\":{\"675\":1}}],[\"通过重新评估初始方法\",{\"2\":{\"2248\":1}}],[\"通过重新定义优势函数来实现策略优化的新方向\",{\"2\":{\"2156\":1}}],[\"通过重新定义优势函数来实现\",{\"2\":{\"1954\":1}}],[\"通过提供示例让模型\",{\"2\":{\"1940\":1}}],[\"通过提示语\",{\"2\":{\"1885\":1}}],[\"通过提示词\",{\"2\":{\"1608\":1}}],[\"通过强化学习获得强大的推理能力\",{\"2\":{\"1915\":1}}],[\"通过pagedattention高效地管理attention中缓存的张量\",{\"2\":{\"1808\":1}}],[\"通过prompt\",{\"2\":{\"1154\":1}}],[\"通过差异化处理来增强模型的表现\",{\"2\":{\"1795\":1}}],[\"通过低秩分解来更新参数矩阵\",{\"2\":{\"1792\":1}}],[\"通过低秩矩阵更新大模型参数\",{\"2\":{\"57\":1}}],[\"通过少样本的方式为大模型提供输入输出对的基本格式\",{\"2\":{\"1766\":1}}],[\"通过迭代训练不断优化模型输出\",{\"2\":{\"1747\":1}}],[\"通过零初始化注意力机制和门控机制改善微调稳定性\",{\"2\":{\"1722\":1}}],[\"通过让大模型逐步参与将一个复杂问题分解为一步一步的子问题并依次进行求解\",{\"2\":{\"1708\":1}}],[\"通过要求模型在输出最终答案之前\",{\"2\":{\"1708\":1}}],[\"通过为模型提供正确的奖励信号\",{\"2\":{\"2283\":1}}],[\"通过为矩阵a和b设置不同的学习率来提高训练效率\",{\"2\":{\"1660\":1}}],[\"通过为输入序列中的不同部分分配权重\",{\"2\":{\"97\":1}}],[\"通过比较预期收益与实际收益来调整\",{\"2\":{\"1645\":1}}],[\"通过当前状态和动作的token序列确定下一个状态\",{\"2\":{\"1613\":1}}],[\"通过裁剪操作来对values进行处理\",{\"2\":{\"1591\":1}}],[\"通过试错和反馈机制优化决策策略\",{\"2\":{\"1567\":1}}],[\"通过神经网络从大量数据中提取特征并进行推断\",{\"2\":{\"1567\":1}}],[\"通过最大值归一化和指数函数计算权重矩阵\",{\"2\":{\"2597\":1}}],[\"通过最大化多轮交互中的累计奖励来优化表现\",{\"2\":{\"2124\":1}}],[\"通过最大化期望回报来更新状态价值\",{\"2\":{\"647\":1}}],[\"通过最小化损失函数来实现目标\",{\"2\":{\"1566\":1}}],[\"通过结合非量化和量化评估\",{\"2\":{\"2292\":1}}],[\"通过结合机评和人评\",{\"2\":{\"2151\":1}}],[\"通过结合传统强化学习中的奖励设计方法\",{\"2\":{\"1884\":1}}],[\"通过结合ppo算法\",{\"2\":{\"1530\":1}}],[\"通过结合多种优化技术\",{\"2\":{\"1287\":1}}],[\"通过冻结sft模型参数并在ppo训练中加入per\",{\"2\":{\"1522\":1}}],[\"通过麦克风接收声音\",{\"2\":{\"1518\":1}}],[\"通过摄像头捕捉图像\",{\"2\":{\"1518\":1}}],[\"通过感知\",{\"2\":{\"1518\":1}}],[\"通过明确定义代理\",{\"2\":{\"1515\":1}}],[\"通过收集用户在实际使用中的反馈\",{\"2\":{\"1510\":1}}],[\"通过人类反馈的强化学习\",{\"2\":{\"1495\":1,\"1589\":1}}],[\"通过扩充词表\",{\"2\":{\"1487\":1}}],[\"通过扩展词表和上下文长度\",{\"2\":{\"1071\":1}}],[\"通过生成式\",{\"2\":{\"1485\":1}}],[\"通过生成多个推理路径\",{\"2\":{\"596\":1}}],[\"通过以上内容\",{\"2\":{\"1880\":1}}],[\"通过以上分析\",{\"2\":{\"1462\":1,\"2263\":1}}],[\"通过以更少的位数表示浮点数据\",{\"2\":{\"733\":1}}],[\"通过与用户沟通\",{\"2\":{\"1501\":1}}],[\"通过与\",{\"2\":{\"1458\":1}}],[\"通过与生成式人工智能\",{\"2\":{\"1184\":1}}],[\"通过ep\",{\"2\":{\"1456\":2}}],[\"通过渐进式训练方法和先进的数据过滤技术\",{\"2\":{\"1446\":1}}],[\"通过设计新的参数来降低显存消耗\",{\"2\":{\"2073\":1}}],[\"通过设计多样化的任务场景\",{\"2\":{\"1453\":1}}],[\"通过设计不同的\",{\"2\":{\"1439\":1}}],[\"通过设计复杂逻辑问题\",{\"2\":{\"524\":1,\"869\":1}}],[\"通过训练获得更灵活的位置信息表示\",{\"2\":{\"1388\":1}}],[\"通过训练一个较小的\",{\"2\":{\"763\":1}}],[\"通过递归方式生成每个位置对应的位置编码\",{\"2\":{\"1328\":1}}],[\"通过大量数据和参数\",{\"2\":{\"1303\":1}}],[\"通过大量样本的期望值来逼近系统的真实值\",{\"2\":{\"713\":1}}],[\"通过位置编码优化提升长度外推能力\",{\"2\":{\"1255\":1}}],[\"通过位置编码扩展以及长文本对齐\",{\"2\":{\"929\":1}}],[\"通过多次更新epoch可以显著提高样本效率\",{\"2\":{\"2600\":1}}],[\"通过多次采样确保质量\",{\"2\":{\"2516\":1}}],[\"通过多次优化达到更高质量的输出\",{\"2\":{\"2259\":1}}],[\"通过多智能体互动解决问题\",{\"2\":{\"1485\":1}}],[\"通过多个智能体之间的交互\",{\"2\":{\"1485\":1}}],[\"通过多任务学习框架\",{\"2\":{\"1224\":1}}],[\"通过多层筛选\",{\"2\":{\"468\":1}}],[\"通过通信平衡损失解决设备间数据不均衡问题\",{\"2\":{\"1220\":1}}],[\"通过用相对位置向量替代传统的位置编码\",{\"2\":{\"1215\":1}}],[\"通过解耦输入信息与位置信息\",{\"2\":{\"1207\":1}}],[\"通过动态调整正则化系数\",{\"2\":{\"2068\":1}}],[\"通过动态分配秩和使用svd参数化\",{\"2\":{\"1653\":1}}],[\"通过动态ntk插值和logn\",{\"2\":{\"1204\":1}}],[\"通过动态规划或树搜索等方法直接求解最优策略\",{\"2\":{\"688\":1}}],[\"通过相对位置编码来捕捉词与词之间的相对关系\",{\"2\":{\"1187\":1}}],[\"通过编译和执行生成的解决方案来评估其有效性\",{\"2\":{\"1181\":1}}],[\"通过随机采样从\",{\"2\":{\"1224\":1}}],[\"通过随机噪声影响选择第二个专家\",{\"2\":{\"1170\":1}}],[\"通过随机抽样200个样本作为监控基准\",{\"2\":{\"558\":1}}],[\"通过逐渐减少学习率来改善收敛性\",{\"2\":{\"1162\":1}}],[\"通过逐步优化词表\",{\"2\":{\"343\":1}}],[\"通过逐步合并频率最高的字符对\",{\"2\":{\"319\":1}}],[\"通过改进过滤算法\",{\"2\":{\"1130\":1}}],[\"通过改变参数量而不增加计算负担\",{\"2\":{\"1040\":1}}],[\"通过改变缺失spans的数量和长度\",{\"2\":{\"1004\":1}}],[\"通过加速计算和节省显存来优化transformer模型\",{\"2\":{\"1846\":1}}],[\"通过加噪处理和mask操作来确定最终的top2expert\",{\"2\":{\"1119\":1}}],[\"通过加入基线\",{\"2\":{\"654\":1,\"1992\":1,\"2045\":1}}],[\"通过加入基线降低估计方差\",{\"2\":{\"518\":1}}],[\"通过加入特定领域的数据\",{\"2\":{\"475\":1}}],[\"通过减少输入与位置之间的交互项\",{\"2\":{\"1108\":1}}],[\"通过减少不必要的计算和存储需求\",{\"2\":{\"825\":1}}],[\"通过根据前面k个词预测下一个词来进行预训练\",{\"2\":{\"1093\":1}}],[\"通过评估模型输出的概率大小来判断当前示例的好坏\",{\"2\":{\"1075\":1}}],[\"通过评分机制\",{\"2\":{\"528\":1}}],[\"通过条件计算和自动分片实现高效的模型训练\",{\"2\":{\"1072\":1}}],[\"通过一系列技术优化\",{\"2\":{\"1060\":1}}],[\"通过混合不同的预训练目标来增强模型对语言的理解\",{\"2\":{\"1057\":1}}],[\"通过冷启动数据和多阶段训练解决\",{\"2\":{\"1053\":1}}],[\"通过去除某个组件来评估其对系统整体性能的影响\",{\"2\":{\"2024\":1}}],[\"通过去除不重要的神经元连接来减少模型的复杂性\",{\"2\":{\"763\":1}}],[\"通过去掉nsp任务和采用动态掩码策略\",{\"2\":{\"1052\":1}}],[\"通过长上下文对齐来改善大语言模型的长文本处理能力\",{\"2\":{\"1008\":1}}],[\"通过可学习偏置项β\",{\"2\":{\"998\":1}}],[\"通过查表\",{\"2\":{\"996\":1}}],[\"通过特殊的mask实现了文本的双向和单向attention\",{\"2\":{\"961\":1}}],[\"通过这样的更新方法\",{\"2\":{\"2528\":1}}],[\"通过这样的处理\",{\"2\":{\"1925\":1}}],[\"通过这个示例\",{\"2\":{\"2433\":1}}],[\"通过这个提示\",{\"2\":{\"2042\":1}}],[\"通过这种分层结构\",{\"2\":{\"2234\":1}}],[\"通过这种递归切分方法\",{\"2\":{\"2141\":1}}],[\"通过这种更高层次的问题\",{\"2\":{\"1774\":1}}],[\"通过这种方法\",{\"2\":{\"1448\":1,\"1811\":1}}],[\"通过这种方式\",{\"2\":{\"1035\":1,\"1332\":1,\"2026\":1,\"2436\":1,\"2537\":1,\"2659\":1,\"2685\":1}}],[\"通过这种方式可以生成更小\",{\"2\":{\"954\":1}}],[\"通过这种格式化的设计\",{\"2\":{\"1368\":1}}],[\"通过这些步骤\",{\"2\":{\"2216\":1}}],[\"通过这些统计量\",{\"2\":{\"1980\":1}}],[\"通过这些对比分析\",{\"2\":{\"1819\":1}}],[\"通过这些任务示例\",{\"2\":{\"1175\":1}}],[\"通过这些技术\",{\"2\":{\"433\":1}}],[\"通过自我奖励训练\",{\"2\":{\"2076\":1}}],[\"通过自定义熵指标对示例进行重排\",{\"2\":{\"1413\":1}}],[\"通过自回归填空任务实现高效的语言模型预训练\",{\"2\":{\"923\":1}}],[\"通过自注意力层\",{\"2\":{\"34\":1}}],[\"通过两个核心任务\",{\"2\":{\"919\":1}}],[\"通过稠密向量表征高维数据\",{\"2\":{\"918\":1}}],[\"通过增加预训练损失\",{\"2\":{\"875\":1}}],[\"通过增量更新公式优化状态价值估计\",{\"2\":{\"747\":1}}],[\"通过将每封电子邮件的日期作为元数据附加到其嵌入向量中\",{\"2\":{\"2672\":1}}],[\"通过将sample\",{\"2\":{\"2605\":1,\"2662\":1}}],[\"通过将模型的训练任务分散到多个计算单元上来提高效率和加速训练过程\",{\"2\":{\"2344\":1}}],[\"通过将多个kernel操作融合为一个\",{\"2\":{\"2175\":1}}],[\"通过将预训练的权重矩阵拆分为大小向量和方向矩阵两部分\",{\"2\":{\"1659\":1}}],[\"通过将量化感知整合到微调中\",{\"2\":{\"1494\":1}}],[\"通过将专家模块分割成更细的粒度\",{\"2\":{\"1030\":1}}],[\"通过将单词映射到高效的低维空间\",{\"2\":{\"870\":1}}],[\"通过将未见过的位置映射到模型训练时见过的位置\",{\"2\":{\"180\":1}}],[\"通过应用上述模型压缩技术\",{\"2\":{\"794\":1}}],[\"通过不同的\",{\"2\":{\"2373\":1}}],[\"通过不同的分类方法\",{\"2\":{\"790\":1}}],[\"通过不断调整策略改变数据分布\",{\"2\":{\"726\":1}}],[\"通过不断合并子词生成最终的词表\",{\"2\":{\"355\":1}}],[\"通过块表可以自然地实现内存共享\",{\"2\":{\"750\":1}}],[\"通过引入图\",{\"2\":{\"2144\":1}}],[\"通过引入统计量\",{\"2\":{\"2008\":1}}],[\"通过引入kl约束\",{\"2\":{\"1908\":1}}],[\"通过引入行为约束项和pretrain数据梯度\",{\"2\":{\"1685\":1}}],[\"通过引入4\",{\"2\":{\"1679\":1}}],[\"通过引入正则项来调整答案采样的概率\",{\"2\":{\"1626\":1}}],[\"通过引入基线降低方差是一个关键创新\",{\"2\":{\"725\":1}}],[\"通过引入温度\",{\"2\":{\"228\":1}}],[\"通过引入温度参数\",{\"2\":{\"163\":1}}],[\"通过知识蒸馏的方法将教师网络的知识转移到学生网络\",{\"2\":{\"715\":1}}],[\"通过维护一个replay\",{\"2\":{\"712\":1}}],[\"通过维护多个候选序列\",{\"2\":{\"324\":1}}],[\"通过准备prompt和ground\",{\"2\":{\"699\":1}}],[\"通过代理与环境交互采样来学习策略\",{\"2\":{\"688\":1}}],[\"通过策略评估和策略提升交替进行\",{\"2\":{\"656\":1}}],[\"通过对初始检索结果进行更深入的相关性评估和排序\",{\"2\":{\"2394\":1}}],[\"通过对同一问题的多组输出进行采样\",{\"2\":{\"2273\":1}}],[\"通过对首token时延和system\",{\"2\":{\"2166\":1}}],[\"通过对数据进行两次量化来进一步减少存储需求\",{\"2\":{\"1793\":1}}],[\"通过对相同问题产生的多个采样输出的平均奖励作为value的估计值\",{\"2\":{\"1576\":1}}],[\"通过对比可以看出\",{\"2\":{\"2129\":1}}],[\"通过对比学习最大化概率差值\",{\"2\":{\"1789\":1}}],[\"通过对比学习\",{\"2\":{\"1566\":1}}],[\"通过对比chinese\",{\"2\":{\"1442\":1}}],[\"通过对比验证集标签与llms输出结果\",{\"2\":{\"1222\":1}}],[\"通过对长度为100\",{\"2\":{\"1296\":1}}],[\"通过对不同规模的模型和参数样本进行训练\",{\"2\":{\"1152\":1}}],[\"通过对gpt模型进行若干改动\",{\"2\":{\"1067\":1}}],[\"通过对策略参数化并使用神经网络建模\",{\"2\":{\"652\":1}}],[\"通过对注意力掩码的微调\",{\"2\":{\"136\":1}}],[\"通过硬件和算法的协同优化实现更快的响应时间\",{\"2\":{\"648\":1}}],[\"通过分析显存消耗的细节\",{\"2\":{\"2316\":1}}],[\"通过分析代理执行过程中的潜在危险操作\",{\"2\":{\"1407\":1}}],[\"通过分析上下文中的示例或指示来生成合适的输出\",{\"2\":{\"602\":1}}],[\"通过分解问题并保存子问题的解来避免重复计算\",{\"2\":{\"656\":1}}],[\"通过分块矩阵拼接\",{\"2\":{\"125\":1}}],[\"通过指定id列表\",{\"2\":{\"559\":1}}],[\"通过actor与环境交互采样轨迹\",{\"2\":{\"518\":1}}],[\"通过在计算和通信之间取得平衡来提高效率\",{\"2\":{\"2688\":1}}],[\"通过在同一任务上训练多个\",{\"2\":{\"1930\":1}}],[\"通过在输入文本前添加一系列特殊\",{\"2\":{\"1873\":1}}],[\"通过在训练过程中插入\",{\"2\":{\"1813\":1}}],[\"通过在深度学习模型中添加适配器来优化内存使用\",{\"2\":{\"1793\":1}}],[\"通过在每一层加入提示\",{\"2\":{\"1680\":1}}],[\"通过在序列前后添加特殊标识符如\",{\"2\":{\"1193\":1}}],[\"通过在正方形内随机投点\",{\"2\":{\"747\":1}}],[\"通过在大规模数据集上学习\",{\"2\":{\"503\":1}}],[\"通过在softmax之前对attention分数进行线性偏置调整来引入位置信息\",{\"2\":{\"293\":1}}],[\"通过在softmax操作前引入温度参数\",{\"2\":{\"184\":1}}],[\"通过使用低秩矩阵来编码参数增量\",{\"2\":{\"1792\":1}}],[\"通过使用一系列以指令形式表达的任务进行微调\",{\"2\":{\"1275\":1}}],[\"通过使用时间差分\",{\"2\":{\"577\":1}}],[\"通过使用\",{\"2\":{\"462\":1}}],[\"通过制定url黑名单\",{\"2\":{\"456\":1}}],[\"通过模型规模\",{\"2\":{\"898\":1}}],[\"通过模型压缩\",{\"2\":{\"693\":1}}],[\"通过模型打分和数据去重\",{\"2\":{\"425\":1}}],[\"通过模板实现代码复用和类型独立\",{\"2\":{\"20\":1}}],[\"通过模板推导机制\",{\"2\":{\"15\":1}}],[\"通过kernel融合将多个操作融合为一个操作\",{\"2\":{\"2080\":1}}],[\"通过kernel融合\",{\"2\":{\"2080\":1}}],[\"通过kernel融合的方式\",{\"2\":{\"1810\":1}}],[\"通过knn或欧式距离等算法\",{\"2\":{\"910\":1}}],[\"通过k\",{\"2\":{\"421\":1}}],[\"通过kv\",{\"2\":{\"351\":1}}],[\"通过调整奖励机制\",{\"2\":{\"2692\":1}}],[\"通过调整提示词的形式\",{\"2\":{\"2687\":1}}],[\"通过调整损失函数的计算方式\",{\"2\":{\"2331\":1}}],[\"通过调整损失计算的方法\",{\"2\":{\"2267\":1}}],[\"通过调整裁剪阈值\",{\"2\":{\"2296\":1,\"2439\":1}}],[\"通过调整基线值\",{\"2\":{\"2109\":1}}],[\"通过调整输入文本中的提示模板来优化模型\",{\"2\":{\"2032\":1}}],[\"通过调整少量模型参数来适应新任务\",{\"2\":{\"1983\":1}}],[\"通过调整策略改变数据分布以最大化奖励\",{\"2\":{\"858\":1}}],[\"通过调整\",{\"2\":{\"416\":1}}],[\"通过调整温度参数\",{\"2\":{\"228\":1}}],[\"通过聚类方法筛选核心样本是一种有效的解决方案\",{\"2\":{\"369\":1}}],[\"通过基础词表使用256字节集\",{\"2\":{\"318\":1}}],[\"通过旋转矩阵引入相对位置信息\",{\"2\":{\"315\":1}}],[\"通过互信息优化子词合并\",{\"2\":{\"308\":1}}],[\"通过移位机制实现跨组信息流动\",{\"2\":{\"264\":1}}],[\"通过概率平衡质量与多样性\",{\"2\":{\"253\":1}}],[\"通过绝对位置编码的方式实现了相对位置编码\",{\"2\":{\"247\":1}}],[\"通过进制转换提高模型扩展性\",{\"2\":{\"246\":1}}],[\"通过内插\",{\"2\":{\"221\":1}}],[\"通过外推\",{\"2\":{\"221\":1}}],[\"通过降采样和上投影矩阵减少缓存需求\",{\"2\":{\"212\":1}}],[\"通过session\",{\"2\":{\"2166\":1}}],[\"通过scaling\",{\"2\":{\"1132\":1}}],[\"通过sigmoid选择哪些信号通过\",{\"2\":{\"199\":1}}],[\"通过s型函数转换\",{\"2\":{\"164\":1}}],[\"通过s型函数转换概率\",{\"0\":{\"90\":1}}],[\"通过直接加法操作\",{\"2\":{\"183\":1}}],[\"通过非线性变换进一步提取特征\",{\"2\":{\"162\":1}}],[\"通过缩放权重\",{\"2\":{\"150\":1}}],[\"通过双向编码器架构实现上下文信息的捕捉\",{\"2\":{\"115\":1}}],[\"通过\",{\"2\":{\"49\":1,\"440\":1,\"462\":1,\"1306\":1,\"1578\":1,\"2022\":1,\"2578\":1}}],[\"通过患者的病史\",{\"2\":{\"39\":1}}],[\"通过正弦和余弦函数嵌入位置信息\",{\"2\":{\"222\":1}}],[\"通过正弦\",{\"2\":{\"34\":1}}],[\"通过确定参数\",{\"2\":{\"32\":1}}],[\"通过类和对象管理代码\",{\"2\":{\"20\":1}}],[\"通过继承\",{\"2\":{\"12\":1}}],[\"简称\",{\"2\":{\"2167\":1}}],[\"简称bbpe\",{\"2\":{\"296\":1}}],[\"简化后\",{\"2\":{\"2046\":1}}],[\"简化公式\",{\"2\":{\"1353\":1}}],[\"简化认证和集成\",{\"2\":{\"198\":1}}],[\"简而言之就是选取优化策略中的部分交给一个智能代理合并使用\",{\"2\":{\"2335\":1}}],[\"简而言之\",{\"2\":{\"1184\":1}}],[\"简单来说\",{\"2\":{\"1684\":1,\"2331\":1}}],[\"简单和困难任务区分\",{\"0\":{\"1648\":1}}],[\"简单按照固定字符数截断文本\",{\"2\":{\"1457\":1}}],[\"简单易实现\",{\"2\":{\"943\":1}}],[\"简单易用\",{\"2\":{\"315\":1,\"330\":1,\"2177\":1,\"2568\":1}}],[\"简单易懂\",{\"2\":{\"292\":1}}],[\"简单高效\",{\"2\":{\"301\":1,\"400\":1}}],[\"简单但可能导致生成结果单调重复\",{\"2\":{\"253\":1}}],[\"简单但高效\",{\"2\":{\"178\":1}}],[\"简介\",{\"0\":{\"111\":1}}],[\"因模型结构而异\",{\"0\":{\"2706\":1}}],[\"因果链保持的多token预测\",{\"2\":{\"1277\":1}}],[\"因其决策会带来后果\",{\"2\":{\"572\":1}}],[\"因此显存效率不高\",{\"2\":{\"2704\":1}}],[\"因此选择合适的模型对于具体任务至关重要\",{\"2\":{\"2663\":1}}],[\"因此有\",{\"2\":{\"2653\":1}}],[\"因此我们暂时忽略它们\",{\"2\":{\"2653\":1}}],[\"因此这里最终的io复杂度为\",{\"2\":{\"2653\":1}}],[\"因此这里的io复杂度为\",{\"2\":{\"2653\":1}}],[\"因此这种编码方式能够在一定程度上支持模型的外推能力\",{\"2\":{\"1246\":1}}],[\"因此每个gpu上都拷贝一份\",{\"2\":{\"2651\":1}}],[\"因此每个位置分配独立编码\",{\"2\":{\"1306\":1}}],[\"因此每个位置靠前的token大约需要14\",{\"2\":{\"483\":1}}],[\"因此一种更直接的解决方案是将同一文档按照从大到小的所有尺寸进行分块\",{\"2\":{\"2625\":1}}],[\"因此不需要clip操作\",{\"2\":{\"2577\":1}}],[\"因此不需要进行clip操作\",{\"2\":{\"2545\":1}}],[\"因此不能一概而论\",{\"2\":{\"1775\":1,\"1895\":1}}],[\"因此中间的奖励被视为0\",{\"2\":{\"2415\":1,\"2441\":1}}],[\"因此性能相对一般\",{\"2\":{\"2381\":1}}],[\"因此非常适合使用\",{\"2\":{\"2081\":1}}],[\"因此通常建议保留\",{\"2\":{\"1954\":1}}],[\"因此它不能像prefill阶段那样能做大段prompt的并行计算\",{\"2\":{\"1927\":1}}],[\"因此它有时会出现所谓的\",{\"2\":{\"1468\":1}}],[\"因此必须进行分块计算\",{\"2\":{\"1810\":1}}],[\"因此可以看出\",{\"2\":{\"2653\":1}}],[\"因此可以得到\",{\"2\":{\"2183\":1}}],[\"因此可以预期对于位置靠前的\",{\"2\":{\"2145\":1}}],[\"因此可以将历史信息和用户提问一并交给\",{\"2\":{\"1663\":1}}],[\"因此可以直接应用于任何已经训练好的模型\",{\"2\":{\"1260\":1}}],[\"因此在每层都加了prompt的参数\",{\"2\":{\"1974\":1,\"2173\":1}}],[\"因此在大规模数据集或需要高并发处理时\",{\"2\":{\"1463\":1}}],[\"因此在处理长文本时需要特别注意上下文窗口的限制\",{\"2\":{\"1321\":1}}],[\"因此需要选择支持较长上下文长度的模型\",{\"2\":{\"2699\":1}}],[\"因此需要对其进行详细评估\",{\"2\":{\"2323\":1}}],[\"因此需要设计能够代表整个句子的奖励值\",{\"2\":{\"1905\":1}}],[\"因此需要设计一个机制来动态处理这些late\",{\"2\":{\"1843\":1}}],[\"因此需要用户自行训练\",{\"2\":{\"1719\":1}}],[\"因此需要采用代表整个句子的奖励值\",{\"2\":{\"1673\":1}}],[\"因此需要找到一个平衡点\",{\"2\":{\"1302\":1}}],[\"因此需要通过位置编码来显式传递这些信息\",{\"2\":{\"174\":1}}],[\"因此训练时间通常较短\",{\"2\":{\"1209\":1}}],[\"因此黑盒知识蒸馏又被称为\",{\"2\":{\"1124\":1}}],[\"因此ffn的隐藏层维度增加到了原来的10\",{\"2\":{\"894\":1}}],[\"因此理论上使用非线性量化导致的精度损失更小\",{\"2\":{\"868\":1}}],[\"因此dqn采用神经网络来拟合q值函数\",{\"2\":{\"606\":1}}],[\"因此推荐使用bert类型模型进行微调\",{\"2\":{\"479\":1}}],[\"因此rope不会破坏模型的稳定性\",{\"0\":{\"270\":1},\"1\":{\"293\":1,\"315\":1}}],[\"因此\",{\"2\":{\"205\":1,\"646\":1,\"715\":1,\"881\":1,\"1118\":1,\"1222\":1,\"1284\":1,\"1377\":1,\"1392\":1,\"1423\":1,\"1496\":1,\"1504\":1,\"1611\":1,\"1617\":1,\"1718\":1,\"1807\":1,\"1841\":1,\"2000\":1,\"2077\":1,\"2094\":1,\"2139\":1,\"2235\":1,\"2334\":1,\"2458\":1,\"2505\":1,\"2575\":1,\"2636\":1,\"2643\":1,\"2644\":1,\"2655\":1,\"2687\":1}}],[\"因此yarn在推理和训练阶段不会增加额外计算成本\",{\"2\":{\"184\":1}}],[\"因为来自不同文本的同一索引位置的句子的事实相关实体通常不同\",{\"2\":{\"2608\":1}}],[\"因为当前策略与旧策略相同\",{\"2\":{\"2561\":1}}],[\"因为分块的原因\",{\"2\":{\"2492\":1}}],[\"因为这可能削弱模型对短查询和短答案的拟合能力\",{\"2\":{\"2278\":1}}],[\"因为这些任务的答案较为固定\",{\"2\":{\"2163\":1}}],[\"因为其效果较差\",{\"2\":{\"2235\":1}}],[\"因为我们可以几乎下断言\",{\"2\":{\"2145\":1}}],[\"因为传统的强化学习方法需要大量的训练样本和昂贵的模型微调\",{\"2\":{\"2113\":1}}],[\"因为dpo仅约束差值\",{\"2\":{\"1850\":1}}],[\"因为用户可以定义并利用插件来完成任务\",{\"2\":{\"1849\":1}}],[\"因为第一个相关结果更可能出现在较高的排名位置\",{\"2\":{\"1698\":1}}],[\"因为代码解释器等工具本身可以看作是\",{\"2\":{\"1674\":1}}],[\"因为仅需进行前向传播来学习大量样本\",{\"2\":{\"1667\":1}}],[\"因为输出分布已聚集到一个局部分布上\",{\"2\":{\"1650\":1}}],[\"因为模型是从自身生成的数据中学习\",{\"2\":{\"1614\":1}}],[\"因为模型在训练过程中没有机会适应量化引入的噪声\",{\"2\":{\"1260\":1}}],[\"因为它依赖于模型的具体结构\",{\"2\":{\"2706\":1}}],[\"因为它不受向量长度的影响\",{\"2\":{\"2051\":1}}],[\"因为它们过于关注flops\",{\"2\":{\"1869\":1}}],[\"因为它们的预训练主要基于英文语料\",{\"2\":{\"1349\":1}}],[\"因为它引入了四个模型\",{\"2\":{\"1539\":1}}],[\"因为它要求使用者自身具有相应领域的知识\",{\"2\":{\"1468\":1}}],[\"因为它能够显著提高训练速度\",{\"2\":{\"2537\":1}}],[\"因为它能够提供细粒度的奖励\",{\"2\":{\"2054\":1}}],[\"因为它能有效平衡输入维度与模型性能\",{\"2\":{\"314\":1}}],[\"因为它能较好地控制梯度爆炸问题\",{\"2\":{\"169\":1}}],[\"因为省去了单独训练完整模型的步骤\",{\"2\":{\"826\":1}}],[\"因为主要用于训练\",{\"2\":{\"799\":1}}],[\"因为先训练完整模型可以确保初始性能较优\",{\"2\":{\"795\":1}}],[\"因为tokenizer压缩率不同\",{\"2\":{\"686\":1}}],[\"因为使用下一个状态的估计值而非真实值\",{\"2\":{\"672\":1}}],[\"因为每一步状态转移的奖励不确定性较高\",{\"2\":{\"672\":1}}],[\"因为不同的tokenizer压缩率会影响loss的可比性\",{\"2\":{\"516\":1}}],[\"因为新增维度未经过训练\",{\"2\":{\"223\":1}}],[\"因为0\",{\"2\":{\"164\":1}}],[\"由\",{\"2\":{\"1594\":2}}],[\"由使用者直接输入明确的任务需求\",{\"2\":{\"1420\":1}}],[\"由不同的智能体分别完成\",{\"2\":{\"1384\":1}}],[\"由于gelu是非线性计算\",{\"2\":{\"2602\":1}}],[\"由于处理长篇上下文信息的成本较高\",{\"2\":{\"2582\":1}}],[\"由于新旧策略相同\",{\"2\":{\"2545\":1}}],[\"由于附件不支持打印\",{\"2\":{\"2188\":1}}],[\"由于文档可能存在过长的问题\",{\"2\":{\"2105\":1}}],[\"由于文本块可能包含不完整的句子或思想\",{\"2\":{\"1503\":1}}],[\"由于其为思维过程强加了严格的树结构\",{\"2\":{\"2094\":1}}],[\"由于其基于预训练模型进行微调\",{\"2\":{\"1209\":1}}],[\"由于生成环节不需要保存模型前向过程中的激活值\",{\"2\":{\"2079\":1}}],[\"由于推理所生成的序列长度大小是无法事先预知的\",{\"2\":{\"1978\":1}}],[\"由于decode阶段的是逐一生成token的\",{\"2\":{\"1927\":1}}],[\"由于demonstrations的可选空间与样本库\",{\"2\":{\"1222\":1}}],[\"由于奖励过度利用问题\",{\"2\":{\"1797\":1}}],[\"由于偏好标签是基于句子级别的\",{\"2\":{\"1673\":1,\"1905\":1}}],[\"由于tdpo使用forward\",{\"2\":{\"1650\":1}}],[\"由于transformer的attention机制本身是无向的\",{\"2\":{\"174\":1}}],[\"由于需要计算余弦相似度和多次迭代\",{\"2\":{\"1562\":1}}],[\"由于需要在训练过程中进行额外的模拟计算\",{\"2\":{\"1160\":1}}],[\"由于多个智能体彼此协作\",{\"2\":{\"1384\":1}}],[\"由于向量数据量庞大且复杂\",{\"2\":{\"1377\":1}}],[\"由于位置编码的点积无向性\",{\"2\":{\"1343\":1}}],[\"由于单个智能体不需要处理复杂的交互逻辑\",{\"2\":{\"1241\":1}}],[\"由于单字符子词是语料覆盖的基础\",{\"2\":{\"498\":1}}],[\"由于在线环境下难以获得参数量大且精度性能高的教师模型\",{\"2\":{\"995\":1}}],[\"由于\",{\"2\":{\"881\":1,\"1321\":1,\"1463\":1,\"2505\":1,\"2651\":1,\"2653\":1}}],[\"由于碎片化和过度预留\",{\"2\":{\"750\":1}}],[\"由于旋转矩阵\",{\"0\":{\"270\":1},\"1\":{\"293\":1,\"315\":1}}],[\"由openai开发\",{\"2\":{\"115\":1}}],[\"所说\",{\"2\":{\"2408\":1}}],[\"所以这种方案需要在gelu函数之前加上一个同步点\",{\"2\":{\"2602\":1}}],[\"所以\",{\"2\":{\"2228\":1,\"2379\":1,\"2653\":1}}],[\"所以大部分框架会按照\",{\"2\":{\"1978\":1}}],[\"所以在llm推理过程中\",{\"2\":{\"1927\":1}}],[\"所以分块计算很难\",{\"2\":{\"1872\":1}}],[\"所以如果没有一个将新请求插入到推理batch的机制\",{\"2\":{\"1843\":1}}],[\"所以预测这个人会购买产品\",{\"2\":{\"164\":1}}],[\"所连接的私有数据库不会参与到大模型的数据集中训练\",{\"2\":{\"1718\":1}}],[\"所需要的数据量\",{\"0\":{\"2145\":1}}],[\"所需的平均时间\",{\"2\":{\"2228\":1}}],[\"所需的信息\",{\"2\":{\"1998\":1}}],[\"所需的token长度\",{\"2\":{\"290\":1}}],[\"所需信息类型等\",{\"2\":{\"1332\":1}}],[\"所用的常见知识\",{\"2\":{\"1124\":1}}],[\"所有内循环结束后\",{\"2\":{\"2653\":1}}],[\"所有外循环结束后\",{\"2\":{\"2653\":1}}],[\"所有尺寸保持一致\",{\"2\":{\"2386\":1}}],[\"所有公式或公式字母\",{\"2\":{\"2215\":1}}],[\"所有通过embedding模型生成的向量都会被存储在这样的数据库中\",{\"2\":{\"2198\":1}}],[\"所有模型在处理困难任务时的能力显著低于简单任务\",{\"2\":{\"1648\":1}}],[\"所有\",{\"2\":{\"1468\":1}}],[\"所有序列在分块之后\",{\"2\":{\"750\":1}}],[\"所有query共享同一组kv\",{\"2\":{\"170\":1}}],[\"目的是约束策略在距离行为\",{\"2\":{\"1720\":1}}],[\"目的是使策略更接近正样本而远离负样本\",{\"2\":{\"1566\":1}}],[\"目的\",{\"0\":{\"1375\":1}}],[\"目前主流的流水线并行方法包括gpipe和pipedream\",{\"2\":{\"2688\":1}}],[\"目前没有具体数据内容需要转换\",{\"2\":{\"2614\":1}}],[\"目前为止\",{\"2\":{\"2349\":1}}],[\"目前常用的embedding模型包括\",{\"2\":{\"2155\":1}}],[\"目前并没有一个统一的说法\",{\"2\":{\"1617\":1}}],[\"目前针对模型输出内容的可控性尚未达到理想水平\",{\"2\":{\"1540\":1}}],[\"目前最新的实现方式新增了对\",{\"2\":{\"917\":1}}],[\"目前\",{\"2\":{\"845\":1,\"1412\":1,\"1813\":1,\"1999\":1}}],[\"目前大规模模型更倾向于使用pre\",{\"2\":{\"169\":1}}],[\"目标以及回答依据\",{\"2\":{\"2690\":1}}],[\"目标函数简化为\",{\"2\":{\"1944\":1}}],[\"目标函数变形\",{\"0\":{\"1602\":1},\"1\":{\"1657\":1,\"1712\":1}}],[\"目标创新\",{\"2\":{\"1277\":1}}],[\"目标通常是单一且明确的\",{\"2\":{\"1241\":1}}],[\"目标稳定性\",{\"2\":{\"746\":1}}],[\"目标网络\",{\"0\":{\"746\":1}}],[\"目标网络更新频率\",{\"2\":{\"640\":1}}],[\"目标\",{\"2\":{\"503\":1,\"1263\":1}}],[\"目标是通过最小化参数调整来实现最大化的模型性能改进\",{\"2\":{\"1695\":1}}],[\"目标是通过动态环境交互\",{\"2\":{\"655\":1}}],[\"目标是找到一个最优模型\",{\"2\":{\"655\":1}}],[\"目标是最大化多轮交互中累积奖励的期望\",{\"2\":{\"639\":1}}],[\"目标是发现未知的类别\",{\"2\":{\"39\":1}}],[\"目标是预测输入数据属于哪一类\",{\"2\":{\"39\":1}}],[\"目标变量是连续的数值\",{\"2\":{\"39\":1}}],[\"趋势预测\",{\"0\":{\"306\":1,\"314\":1,\"629\":1,\"650\":1,\"680\":1,\"700\":1,\"745\":1,\"753\":1,\"953\":1,\"1427\":1,\"1464\":1,\"1526\":1,\"1537\":1,\"1543\":1,\"2473\":1},\"2\":{\"169\":1,\"187\":1,\"239\":1,\"346\":1,\"365\":1,\"414\":1,\"420\":1,\"471\":1,\"481\":1,\"535\":1,\"555\":1,\"698\":1,\"730\":1,\"912\":1,\"980\":1,\"985\":1,\"1021\":1,\"1036\":1,\"1296\":1}}],[\"有几块gpu\",{\"2\":{\"2641\":1}}],[\"有多个针对检索增强生成\",{\"2\":{\"2550\":1}}],[\"有的tensor\",{\"2\":{\"2515\":1}}],[\"有偏的奖励函数会导致智能体过分利用奖励函数\",{\"2\":{\"1633\":1}}],[\"有哪些新的方法可以自动识别和合成多轮对话\",{\"2\":{\"2476\":1}}],[\"有哪些可能的局限性\",{\"2\":{\"1472\":1}}],[\"有哪些方法可以降低动态规划的计算复杂度\",{\"2\":{\"727\":1}}],[\"有时甚至不可行\",{\"2\":{\"1377\":1}}],[\"有时如果存在键值\",{\"2\":{\"917\":1}}],[\"有些章节可能较长\",{\"2\":{\"1513\":1}}],[\"有些则擅长执行具体任务\",{\"2\":{\"1338\":1}}],[\"有些机器人可能擅长感知环境\",{\"2\":{\"1338\":1}}],[\"有效解决了传统reinforce方法中的高方差问题\",{\"2\":{\"2495\":1,\"2509\":1}}],[\"有效利用更高速的sram进行计算非常重要\",{\"2\":{\"2077\":1}}],[\"有效且高效的强化学习方法\",{\"2\":{\"1887\":1,\"1943\":1}}],[\"有效地提高了示例选择的效率和质量\",{\"2\":{\"1075\":1}}],[\"有效控制激活值范围\",{\"2\":{\"169\":1}}],[\"有显著不同\",{\"2\":{\"926\":1}}],[\"有显著改善\",{\"2\":{\"245\":1}}],[\"有助于用户快速定位相关内容\",{\"2\":{\"2675\":1}}],[\"有助于\",{\"2\":{\"2000\":1}}],[\"有助于在知识库中寻找类似的文档\",{\"2\":{\"1717\":1}}],[\"有助于提升模型拟合能力\",{\"2\":{\"2278\":1}}],[\"有助于提升ai决策的合理性\",{\"2\":{\"1693\":1}}],[\"有助于提高回答的准确性和可靠性\",{\"2\":{\"1619\":1}}],[\"有助于提高算法稳定性和效率\",{\"2\":{\"725\":1}}],[\"有助于上下文理解\",{\"2\":{\"1514\":1}}],[\"有助于减少前向传播的变异\",{\"2\":{\"285\":1}}],[\"有监督学习将继续主导传统分类和回归任务\",{\"2\":{\"893\":1}}],[\"有监督学习依赖标注数据集\",{\"2\":{\"858\":1}}],[\"有监督学习的静态数据依赖性限制了其在实时决策场景中的应用\",{\"2\":{\"823\":1}}],[\"有监督学习\",{\"2\":{\"552\":1,\"655\":1,\"690\":1,\"726\":1,\"858\":1}}],[\"有三种模式\",{\"2\":{\"440\":1}}],[\"有界性增强正则化能力\",{\"2\":{\"307\":1}}],[\"有大量的标注数据\",{\"2\":{\"39\":1}}],[\"牺牲了模型深度\",{\"2\":{\"169\":1}}],[\"更清楚地知道它正在执行的任务\",{\"2\":{\"2687\":1}}],[\"更贴近任务目标的奖励信号\",{\"2\":{\"2346\":1}}],[\"更关注任务的迭代优化\",{\"2\":{\"2224\":1}}],[\"更关注对象之间的交互和状态管理\",{\"2\":{\"12\":1}}],[\"更具体的\",{\"2\":{\"2145\":1}}],[\"更好地理解问题的上下文和隐含细节\",{\"2\":{\"2000\":1}}],[\"更好地控制策略更新方向\",{\"2\":{\"721\":1}}],[\"更被偏好或两者同等偏好\",{\"2\":{\"1536\":1}}],[\"更被偏好\",{\"2\":{\"1536\":1}}],[\"更智能的数据采样方法\",{\"2\":{\"1526\":1}}],[\"更智能的自动化过滤工具\",{\"2\":{\"650\":1}}],[\"更相关的回应\",{\"2\":{\"1514\":1}}],[\"更加精准地调动模型中最擅长规划\",{\"2\":{\"1420\":1}}],[\"更加详细地描述指令的具体执行细节\",{\"2\":{\"1368\":1}}],[\"更加灵活\",{\"2\":{\"1328\":1}}],[\"更易于管理的子目标\",{\"2\":{\"1330\":1}}],[\"更远距离\",{\"2\":{\"1306\":1}}],[\"更大模型\",{\"2\":{\"1282\":1}}],[\"更大的batch\",{\"2\":{\"898\":1}}],[\"更多细节可以参考\",{\"2\":{\"2178\":1}}],[\"更多的结果提供了丰富的语境\",{\"2\":{\"2000\":1}}],[\"更多的训练数据以及改进的训练方法\",{\"2\":{\"898\":1}}],[\"更多数据\",{\"2\":{\"1282\":1}}],[\"更高的灵活性\",{\"2\":{\"1384\":1}}],[\"更高的量化精度\",{\"2\":{\"981\":1}}],[\"更高层次的智能\",{\"2\":{\"1382\":1}}],[\"更高效的中文tokenizer算法\",{\"2\":{\"1742\":1}}],[\"更高效的动态位置编码方法\",{\"2\":{\"1543\":1}}],[\"更高效的硬件\",{\"2\":{\"1464\":1}}],[\"更高效的模型\",{\"2\":{\"954\":1}}],[\"更高效的多语言支持\",{\"2\":{\"650\":1}}],[\"更高效的稀疏门控机制可能会被开发\",{\"2\":{\"629\":1}}],[\"更高效\",{\"2\":{\"555\":1,\"2055\":1}}],[\"更重要的是\",{\"2\":{\"799\":1}}],[\"更为简便\",{\"2\":{\"658\":1}}],[\"更换checkpoint\",{\"2\":{\"593\":1}}],[\"更通用的分词算法将成为研究热点\",{\"2\":{\"555\":1}}],[\"更新块信息\",{\"0\":{\"2623\":1}}],[\"更新输出块\",{\"0\":{\"2618\":1},\"2\":{\"2618\":1}}],[\"更新最大值和权重\",{\"0\":{\"2604\":1}}],[\"更新幅度和方向一致\",{\"2\":{\"2306\":1}}],[\"更新阶段\",{\"2\":{\"2171\":1}}],[\"更新模型\",{\"2\":{\"1721\":1}}],[\"更新机制\",{\"2\":{\"1558\":1}}],[\"更新数据库\",{\"2\":{\"1510\":1}}],[\"更新状态\",{\"2\":{\"778\":2}}],[\"更新状态信息和估计状态价值\",{\"2\":{\"747\":1}}],[\"更新\",{\"2\":{\"775\":1,\"2082\":1,\"2308\":1,\"2604\":1}}],[\"更新答案\",{\"2\":{\"769\":1}}],[\"更新q值并根据环境反馈调整状态和动作\",{\"2\":{\"681\":1}}],[\"更新公式\",{\"0\":{\"2528\":1}}],[\"更新公式为\",{\"2\":{\"672\":1}}],[\"更新公式如下\",{\"2\":{\"640\":1}}],[\"更新目标网络\",{\"2\":{\"640\":1}}],[\"更新策略参数\",{\"2\":{\"2171\":1}}],[\"更新策略梯度\",{\"2\":{\"2007\":2}}],[\"更新策略\",{\"2\":{\"639\":1,\"695\":1}}],[\"更新策略网络的参数\",{\"2\":{\"619\":1}}],[\"更新价值网络的参数\",{\"2\":{\"619\":1}}],[\"更新当前状态的价值估计\",{\"2\":{\"574\":1}}],[\"更新权重\",{\"2\":{\"553\":1}}],[\"更新后的字符频次表\",{\"2\":{\"497\":1}}],[\"更新后的频次为9\",{\"2\":{\"497\":1}}],[\"更新词汇表和合并列表\",{\"2\":{\"391\":1}}],[\"更强大的模型蒸馏成更小的模型会产生优异的结果\",{\"2\":{\"2642\":1}}],[\"更强调在训练和推理阶段的灵活切换\",{\"2\":{\"2129\":1}}],[\"更强\",{\"2\":{\"365\":1}}],[\"更小\",{\"2\":{\"365\":1}}],[\"更语义化的位置编码方法\",{\"2\":{\"239\":1}}],[\"更适合文本生成\",{\"2\":{\"932\":1}}],[\"更适合应对概率分布变化较大的场景\",{\"2\":{\"340\":1}}],[\"更适合自然语言处理任务\",{\"2\":{\"205\":1}}],[\"更适合深层网络\",{\"2\":{\"199\":1}}],[\"更突出残差分支\",{\"2\":{\"169\":1}}],[\"削弱恒等分支的权重\",{\"2\":{\"169\":1}}],[\"缺陷\",{\"2\":{\"941\":1}}],[\"缺乏上下文的信息会让模型难以准确理解文本内容\",{\"2\":{\"2511\":1}}],[\"缺乏模型参数规模和任务通用性\",{\"2\":{\"1736\":1}}],[\"缺乏多轮交互能力评估\",{\"2\":{\"1453\":1}}],[\"缺乏长度外推性\",{\"2\":{\"1281\":1,\"1373\":1}}],[\"缺乏语义信息\",{\"2\":{\"985\":1}}],[\"缺乏对序列时序的天然感知能力\",{\"2\":{\"216\":1}}],[\"缺乏灵活性\",{\"2\":{\"168\":1,\"2576\":1}}],[\"缺点是增加了训练和推理成本\",{\"2\":{\"1722\":1}}],[\"缺点是不能进行时间维度的效用分配\",{\"2\":{\"654\":1}}],[\"缺点与局限性\",{\"0\":{\"1343\":1}}],[\"缺点\",{\"0\":{\"244\":1,\"312\":1,\"985\":1,\"1010\":1,\"1834\":1,\"2466\":1,\"2512\":1,\"2544\":1,\"2576\":1,\"2599\":1,\"2620\":1,\"2635\":1,\"2650\":1},\"2\":{\"169\":3,\"170\":1,\"194\":1,\"215\":1,\"238\":1,\"246\":1,\"261\":1,\"285\":1,\"292\":1,\"307\":1,\"330\":1,\"421\":1,\"434\":1,\"446\":1,\"529\":1,\"1023\":1,\"1281\":1,\"1328\":1,\"1373\":1}}],[\"主内存也难以容纳这些模型的参数\",{\"2\":{\"2281\":1}}],[\"主会议论文\",{\"2\":{\"1658\":1}}],[\"主题信息丢失\",{\"0\":{\"2522\":1}}],[\"主题不变的真多轮数据直接加入训练\",{\"2\":{\"2256\":1}}],[\"主题涉及\",{\"2\":{\"1606\":1}}],[\"主题的组织方式\",{\"2\":{\"1421\":1}}],[\"主动行动和学习进化的\",{\"2\":{\"1474\":1}}],[\"主动学习的目标是从样本库中选择适合的样本提供给标注者标注\",{\"2\":{\"1173\":1}}],[\"主动学习思路\",{\"0\":{\"1173\":1}}],[\"主权重\",{\"2\":{\"591\":1}}],[\"主权重和损失缩放策略\",{\"2\":{\"462\":1}}],[\"主要原因在于它经过安全强化学习\",{\"2\":{\"2580\":1}}],[\"主要原理\",{\"2\":{\"168\":1}}],[\"主要特性包括\",{\"2\":{\"2523\":1}}],[\"主要的方式分为流水线并行和张量并行\",{\"2\":{\"2503\":1}}],[\"主要的创新包括\",{\"2\":{\"1041\":1}}],[\"主要针对以下几个方面进行优化\",{\"2\":{\"2484\":1}}],[\"主要研究问题包括利用少量高质量数据加速模型训练\",{\"2\":{\"2429\":1}}],[\"主要包含以下三个步骤\",{\"2\":{\"2420\":1}}],[\"主要包括以下几种\",{\"2\":{\"1413\":1}}],[\"主要涉及\",{\"2\":{\"2366\":1}}],[\"主要采用数据并行的方法\",{\"2\":{\"2241\":1}}],[\"主要受\",{\"2\":{\"2228\":1}}],[\"主要用途\",{\"2\":{\"2223\":1}}],[\"主要用于评估生成文本与参考文本之间的重叠程度\",{\"2\":{\"2292\":1}}],[\"主要用于全局存储\",{\"2\":{\"2077\":1}}],[\"主要用于缓存\",{\"2\":{\"2077\":1}}],[\"主要用于指导如何将负例改成正例\",{\"2\":{\"1368\":1}}],[\"主要用于为输入序列的每个位置注入位置信息\",{\"2\":{\"1147\":1}}],[\"主要用于替代传统的word2vec\",{\"2\":{\"919\":1}}],[\"主要用于提取文本特征\",{\"2\":{\"316\":1}}],[\"主要关注数据用途\",{\"2\":{\"2165\":1}}],[\"主要关注模型的知识掌握程度\",{\"2\":{\"457\":1}}],[\"主要目标是减少llm的存储和计算复杂性\",{\"2\":{\"1874\":1}}],[\"主要观点\",{\"0\":{\"1796\":1}}],[\"主要取决于\",{\"2\":{\"1672\":1}}],[\"主要是欧洲语言\",{\"2\":{\"1665\":1}}],[\"主要思想是多任务学习\",{\"2\":{\"1059\":1}}],[\"主要技术包括\",{\"2\":{\"967\":1}}],[\"主要优化点\",{\"0\":{\"964\":1},\"1\":{\"1007\":1,\"1048\":1,\"1092\":1}}],[\"主要步骤\",{\"0\":{\"567\":1}}],[\"主要内容\",{\"0\":{\"459\":1,\"1312\":1},\"1\":{\"488\":1,\"520\":1,\"553\":1,\"589\":1,\"622\":1,\"657\":1,\"1358\":1,\"1404\":1,\"1451\":1}}],[\"主成分分析\",{\"2\":{\"39\":1}}],[\"唱\",{\"2\":{\"166\":1,\"187\":1}}],[\"唱跳篮球\",{\"2\":{\"166\":1}}],[\"7层放到device4\",{\"2\":{\"2697\":1}}],[\"7层放device2\",{\"2\":{\"2697\":1}}],[\"71612\",{\"2\":{\"2347\":1}}],[\"75\",{\"2\":{\"2161\":1}}],[\"780gb\",{\"2\":{\"2065\":1}}],[\"780gb降低到\",{\"2\":{\"1735\":1}}],[\"7=0\",{\"2\":{\"1756\":2}}],[\"768\",{\"2\":{\"1225\":2,\"1281\":1}}],[\"700gb\",{\"2\":{\"2281\":2}}],[\"700亿参数\",{\"2\":{\"1282\":1}}],[\"70b\",{\"2\":{\"1282\":1,\"1360\":1,\"1867\":1,\"2603\":1,\"2622\":1}}],[\"70亿参数\",{\"2\":{\"1282\":1}}],[\"703\",{\"2\":{\"1225\":1}}],[\"70\",{\"2\":{\"803\":1}}],[\"7gb内存\",{\"2\":{\"750\":1}}],[\"72b\",{\"2\":{\"1398\":1,\"2210\":1}}],[\"7202432992642387233\",{\"2\":{\"559\":1}}],[\"7280854932641664319\",{\"2\":{\"559\":1}}],[\"7\",{\"0\":{\"401\":1,\"847\":1,\"881\":1,\"896\":1,\"1225\":1,\"2046\":1},\"1\":{\"428\":1,\"454\":1,\"931\":1,\"969\":1,\"1010\":1,\"1050\":1,\"1094\":1,\"1143\":1},\"2\":{\"164\":4,\"246\":1,\"470\":2,\"497\":2,\"508\":1,\"1324\":1,\"1756\":1,\"1998\":1,\"2059\":1,\"2145\":2,\"2539\":1}}],[\"7b模型\",{\"2\":{\"220\":1}}],[\"7b\",{\"2\":{\"138\":1,\"1121\":1,\"1186\":1,\"1282\":1,\"1419\":1,\"2090\":1,\"2603\":2,\"2617\":1}}],[\"浏览时长\",{\"2\":{\"164\":2}}],[\"收尾退火阶段\",{\"2\":{\"1436\":1}}],[\"收敛步数\",{\"2\":{\"1178\":1}}],[\"收敛性更好\",{\"2\":{\"169\":1}}],[\"收集多样化的任务数据以丰富模型训练集\",{\"2\":{\"2401\":1}}],[\"收集多种回答的排序信息\",{\"2\":{\"1631\":1}}],[\"收集与当前模型水平相当的数据集以优化离线训练\",{\"2\":{\"1839\":1}}],[\"收集优质数据集\",{\"2\":{\"1721\":1}}],[\"收集更大规模的中文数据集以支持tokenizer训练\",{\"2\":{\"1686\":1}}],[\"收集更多关于正则化对模型影响的数据\",{\"2\":{\"2120\":1}}],[\"收集更多实验数据验证scaling\",{\"2\":{\"1607\":1}}],[\"收集更多多样化的中英文指令数据以提升模型泛化能力\",{\"2\":{\"1287\":1}}],[\"收集更多领域数据\",{\"2\":{\"668\":1}}],[\"收集到的人类偏好标签可以通过二分类思路来学习奖励函数\",{\"2\":{\"1536\":1}}],[\"收集通用大规模数据集和业务场景相关数据\",{\"2\":{\"1302\":1}}],[\"收集并筛选高质量的训练数据\",{\"2\":{\"1264\":1}}],[\"收集并清洗通用语料\",{\"2\":{\"567\":1}}],[\"收集数据\",{\"2\":{\"1203\":1,\"1337\":1}}],[\"收集了更大容量的高质量代码\",{\"2\":{\"1130\":1}}],[\"收集了1\",{\"2\":{\"1087\":1}}],[\"收集标注数据并增强\",{\"2\":{\"40\":1}}],[\"收入\",{\"2\":{\"164\":2}}],[\"且不一定能超越蒸馏策略的效果\",{\"2\":{\"2637\":1}}],[\"且会将许多公式误识别为标题\",{\"2\":{\"2235\":1}}],[\"且\",{\"2\":{\"2013\":1}}],[\"且最终会被\",{\"2\":{\"1258\":1}}],[\"且缺少丰富的针对场景的基准\",{\"2\":{\"1118\":1}}],[\"且与预训练模型大小和原始数据比例密切相关\",{\"2\":{\"501\":1}}],[\"且比较规则一致\",{\"2\":{\"246\":1}}],[\"且适用于扩展上下文窗口的场景\",{\"2\":{\"163\":1}}],[\"且标注成本高\",{\"2\":{\"39\":1}}],[\"该排行榜提供了关于各种嵌入模型性能的详细对比\",{\"2\":{\"2663\":1}}],[\"该结果是所有节点数据的汇总\",{\"2\":{\"2452\":1}}],[\"该类通过拷贝原始的nn\",{\"2\":{\"2400\":1}}],[\"该数据集用于多轮对话训练\",{\"2\":{\"2184\":1}}],[\"该函数能够最大限度地将相似的输入项映射到同一个桶中\",{\"2\":{\"2152\":1}}],[\"该算法已经过实战测试\",{\"2\":{\"2081\":1}}],[\"该算法在训练中使用了价值模型\",{\"2\":{\"1955\":1}}],[\"该模块专门用于模拟可能导致大模型代理\",{\"2\":{\"1407\":1}}],[\"该模型的核心特性在于其参数量可以独立于计算量进行调整\",{\"2\":{\"1040\":1}}],[\"该模型的创新在于使用门控机制动态选择专家组合\",{\"2\":{\"1031\":1}}],[\"该模型还引入了通信平衡损失来解决设备间数据分发不均衡的问题\",{\"2\":{\"989\":1}}],[\"该矩阵作为位置向量\",{\"2\":{\"1281\":1}}],[\"该度量用于线性层输出内的局部比较\",{\"2\":{\"1050\":1}}],[\"该度量根据每个权重的大小以及相应输入激活的范数的乘积进行评估\",{\"2\":{\"1050\":1}}],[\"该标准使用了来自\",{\"2\":{\"1050\":1}}],[\"该系列模型在多语言处理\",{\"2\":{\"1028\":1}}],[\"该如何设计通用型爬虫框架\",{\"2\":{\"628\":1}}],[\"该方法在数学任务aime2024上的表现\",{\"2\":{\"2692\":1}}],[\"该方法在推理和训练阶段没有额外开销\",{\"2\":{\"163\":1}}],[\"该方法仅用50\",{\"2\":{\"2689\":1}}],[\"该方法通过模拟实际场景中的工具调用\",{\"2\":{\"2384\":1}}],[\"该方法通过将prompt转换为可学习的embedding层\",{\"2\":{\"1738\":1}}],[\"该方法通过将action\",{\"2\":{\"1608\":1}}],[\"该方法的核心思想是\",{\"2\":{\"2197\":1}}],[\"该方法能够处理复杂排版\",{\"2\":{\"2103\":1}}],[\"该方法支持外部工具的访问\",{\"2\":{\"2011\":1}}],[\"该方法直接利用\",{\"2\":{\"1948\":1}}],[\"该方法主要分为\",{\"2\":{\"1752\":1}}],[\"该方法利用预训练语言模型及少量标注数据\",{\"2\":{\"1747\":1}}],[\"该方法综合考虑了一阶信息和近似\",{\"2\":{\"1143\":1}}],[\"该方法将剪枝视为一个广泛的稀疏回归问题\",{\"2\":{\"1050\":1}}],[\"该方法设计简洁\",{\"2\":{\"867\":1}}],[\"该方法尤其适用于处理噪声文本和字符丰富的语言\",{\"2\":{\"296\":1}}],[\"该技术通过分组计算注意力并引入移位机制\",{\"2\":{\"101\":1}}],[\"$\",{\"2\":{\"647\":3}}],[\"$v\",{\"2\":{\"647\":1}}],[\"$$的显著权重可以大大减少量化误差\",{\"2\":{\"2085\":1}}],[\"$$p\",{\"2\":{\"1499\":2}}],[\"$$p$$\",{\"2\":{\"340\":1}}],[\"$$u\",{\"2\":{\"1405\":1,\"1452\":1,\"1593\":1}}],[\"$$u$$\",{\"2\":{\"1313\":1,\"1359\":1}}],[\"$$0\",{\"2\":{\"1344\":1}}],[\"$$a=0\",{\"2\":{\"1329\":1}}],[\"$$a$$\",{\"2\":{\"779\":1}}],[\"$$到$$10\",{\"2\":{\"1329\":1}}],[\"$$6\",{\"2\":{\"1329\":1,\"1419\":1}}],[\"$$f\",{\"2\":{\"1258\":1}}],[\"$$i\",{\"2\":{\"1207\":1,\"1258\":3,\"1353\":1}}],[\"$$x\",{\"2\":{\"1187\":1}}],[\"$$x$$是生成token的总数量\",{\"2\":{\"513\":1}}],[\"$$m\",{\"2\":{\"778\":1}}],[\"$$m$$\",{\"2\":{\"247\":1,\"291\":1}}],[\"$$n^\",{\"2\":{\"1329\":1}}],[\"$$n\",{\"2\":{\"778\":1,\"2322\":1}}],[\"$$n$$\",{\"2\":{\"560\":1}}],[\"$$v$$\",{\"2\":{\"1313\":1,\"1359\":1}}],[\"$$v\",{\"2\":{\"732\":1,\"748\":1}}],[\"$$c$$\",{\"2\":{\"622\":1,\"1329\":1}}],[\"$$b$$是首个token的耗时\",{\"2\":{\"513\":1}}],[\"$$4\",{\"2\":{\"488\":1}}],[\"$$t\",{\"2\":{\"416\":2}}],[\"$$t$$\",{\"2\":{\"163\":1,\"184\":1,\"228\":2,\"346\":1,\"778\":1}}],[\"$$g\",{\"2\":{\"291\":1}}],[\"$$s\",{\"2\":{\"291\":1}}],[\"$$s$$\",{\"2\":{\"244\":1,\"276\":3,\"312\":1,\"335\":1,\"346\":1,\"359\":1,\"439\":1,\"748\":1,\"778\":3,\"779\":1,\"1344\":1}}],[\"$$l\",{\"2\":{\"291\":1,\"2322\":1}}],[\"$$l$$\",{\"2\":{\"290\":1}}],[\"$$2^\",{\"2\":{\"553\":2,\"556\":1,\"589\":1,\"591\":1}}],[\"$$20\",{\"2\":{\"488\":1}}],[\"$$2\",{\"2\":{\"290\":1,\"488\":1}}],[\"$$j$$\",{\"2\":{\"290\":1}}],[\"$$r\",{\"0\":{\"270\":1},\"1\":{\"293\":1,\"315\":1},\"2\":{\"611\":1,\"1266\":1,\"1405\":1}}],[\"$$d$$\",{\"2\":{\"1499\":1}}],[\"$$d\",{\"2\":{\"228\":1}}],[\"$$k$$是后续每个token的耗时\",{\"2\":{\"513\":1}}],[\"$$k$$\",{\"2\":{\"247\":2,\"324\":3,\"348\":1}}],[\"$$k\",{\"2\":{\"228\":1}}],[\"$$q$$\",{\"2\":{\"247\":2}}],[\"$$q\",{\"2\":{\"228\":1,\"732\":1,\"779\":1}}],[\"$$\",{\"2\":{\"221\":3,\"222\":1,\"247\":1,\"291\":2,\"293\":1,\"338\":1,\"346\":3,\"359\":1,\"439\":1,\"502\":1,\"553\":2,\"556\":1,\"589\":7,\"591\":1,\"593\":1,\"608\":1,\"611\":2,\"656\":1,\"676\":2,\"732\":2,\"748\":2,\"767\":2,\"778\":1,\"779\":1,\"879\":1,\"1207\":2,\"1258\":1,\"1266\":1,\"1329\":3,\"1344\":1,\"1353\":2,\"1405\":3,\"1419\":1,\"1499\":2}}],[\"$$100\",{\"2\":{\"1419\":1}}],[\"$$10\",{\"2\":{\"1419\":1}}],[\"$$10^\",{\"2\":{\"1419\":1}}],[\"$$18\",{\"2\":{\"488\":1}}],[\"$$1\",{\"2\":{\"184\":1,\"276\":1}}],[\"$1\",{\"2\":{\"18\":1}}],[\"$12\",{\"2\":{\"18\":1}}],[\"$1600\",{\"2\":{\"18\":1}}],[\"还通过更精细的损失计算方法\",{\"2\":{\"2624\":1,\"2671\":1}}],[\"还通过模型深度实现了信息传递的完整性\",{\"2\":{\"2460\":1}}],[\"还通过sparse\",{\"2\":{\"1462\":1}}],[\"还支持安全性增强版本\",{\"2\":{\"2455\":1}}],[\"还促进了复杂推理过程的学习\",{\"2\":{\"2439\":1}}],[\"还体现了强化学习在复杂任务中的潜力\",{\"2\":{\"2283\":1}}],[\"还需根据需求制定其他指标\",{\"2\":{\"2194\":1}}],[\"还需一份模型参数副本\",{\"2\":{\"2192\":1}}],[\"还需要配套加入多级路由机制\",{\"2\":{\"1285\":1}}],[\"还介绍了通过样本拆分和合并来加速计算的策略\",{\"2\":{\"2181\":1}}],[\"还可用于其他领域的数据优化\",{\"2\":{\"2352\":1}}],[\"还可能提高计算效率\",{\"2\":{\"2073\":1}}],[\"还可以添加以下类型的元数据\",{\"2\":{\"2675\":1}}],[\"还可以处理视觉\",{\"2\":{\"2443\":1}}],[\"还可以通过调用特定功能\",{\"2\":{\"2323\":1}}],[\"还可以包括该文档的摘要\",{\"2\":{\"2304\":1}}],[\"还可以使用少量样本\",{\"2\":{\"2693\":1}}],[\"还可以使用模型并行来划分模型的不同阶段\",{\"2\":{\"2503\":1}}],[\"还可以使\",{\"2\":{\"2055\":1}}],[\"还可以在不显著增加计算成本的情况下\",{\"2\":{\"1979\":1}}],[\"还可以充当奖励函数\",{\"2\":{\"1578\":1}}],[\"还可以量化kv缓存\",{\"2\":{\"1448\":1}}],[\"还会增加系统的时间和资源成本\",{\"2\":{\"2000\":1}}],[\"还会辅以一个由\",{\"2\":{\"917\":1}}],[\"还简化了优化过程\",{\"2\":{\"1660\":1}}],[\"还要特别注意测试集的效果\",{\"2\":{\"1656\":1}}],[\"还提高了模型的效率\",{\"2\":{\"1746\":1}}],[\"还提出了一个名为\",{\"2\":{\"1544\":1}}],[\"还提供了针对特定平台\",{\"2\":{\"411\":1}}],[\"还在一定程度上保留了模型精度\",{\"2\":{\"1448\":1}}],[\"还为团队协作提供了新的可能性\",{\"2\":{\"1485\":1}}],[\"还为检索优化提供了巨大的潜力\",{\"2\":{\"1377\":1}}],[\"还为长序列生成提供了可能性\",{\"2\":{\"255\":1}}],[\"还加上了cp\",{\"2\":{\"2711\":1}}],[\"还加速了训练过程\",{\"2\":{\"1340\":1}}],[\"还加快了收敛速度\",{\"2\":{\"1142\":1}}],[\"还优化了资源分配和使用\",{\"2\":{\"1332\":1}}],[\"还是还像之前场景那样等前面的请求都推理结束后才进行推理\",{\"2\":{\"1843\":1}}],[\"还是\",{\"2\":{\"1282\":1,\"1982\":1}}],[\"还是需要指定命名空间\",{\"2\":{\"10\":1}}],[\"还直接影响用户体验和系统性能\",{\"2\":{\"1235\":1}}],[\"还直接影响训练效率\",{\"2\":{\"406\":1}}],[\"还减少了对不同任务进行个性化调整的需求\",{\"2\":{\"1206\":1}}],[\"还使用了一种辅助损失函数\",{\"2\":{\"1072\":1}}],[\"还包括补充搜索的效率和效果\",{\"2\":{\"2518\":1}}],[\"还包括将部分计算任务转移到\",{\"2\":{\"2397\":1}}],[\"还包括系统的需求\",{\"2\":{\"2021\":1}}],[\"还包括n\",{\"2\":{\"938\":1}}],[\"还包括电力消耗的减少和响应时间的改善\",{\"2\":{\"794\":1}}],[\"还改善了模型的长度外推性\",{\"2\":{\"894\":1}}],[\"还进一步探索了各网络层输出之间的关系或样本之间的关系\",{\"2\":{\"880\":1}}],[\"还没有成熟统一的解决方案\",{\"2\":{\"845\":1}}],[\"还有哪些潜在的高效预训练框架值得探索\",{\"2\":{\"1758\":1}}],[\"还有哪些位置编码方法适合长文本优化\",{\"2\":{\"740\":1}}],[\"还有哪些新型正则化方法可以应用于大规模模型训练\",{\"2\":{\"736\":1}}],[\"还有哪些优化空间\",{\"2\":{\"616\":1}}],[\"还有哪些归一化方法可以优化\",{\"2\":{\"299\":1}}],[\"还能显著提升其在特定情境下的实用性\",{\"2\":{\"2693\":1}}],[\"还能减少生成回答过程中的不确定性\",{\"2\":{\"2687\":1}}],[\"还能减少冗余数据对训练效率的影响\",{\"2\":{\"369\":1}}],[\"还能为最终用户提供更加丰富和精确的搜索体验\",{\"2\":{\"2675\":1}}],[\"还能有效避免因某些样本过于简单而导致的模型退化问题\",{\"2\":{\"2541\":1}}],[\"还能有效保护这些私有数据的隐私性和安全性\",{\"2\":{\"1718\":1}}],[\"还能通过调用函数或api\",{\"2\":{\"2443\":1}}],[\"还能通过决策直接改变环境\",{\"2\":{\"711\":1,\"760\":1}}],[\"还能提升大模型生成回答的质量\",{\"2\":{\"2364\":1}}],[\"还能提升模型的推理能力\",{\"2\":{\"1224\":1}}],[\"还能在执行过程中\",{\"2\":{\"1904\":1}}],[\"还能在多任务环境中灵活应用\",{\"2\":{\"1695\":1}}],[\"还能在一定程度上提高模型的生成效果\",{\"2\":{\"1273\":1}}],[\"还能推动领域内的创新\",{\"2\":{\"1382\":1}}],[\"还能更好地保持内容语义的完整性和连贯性\",{\"2\":{\"1334\":1}}],[\"还能够生成解释\",{\"2\":{\"1224\":1}}],[\"还能处理更长的输入序列\",{\"2\":{\"1179\":1}}],[\"还能使用其他形式如轨迹总回报\",{\"2\":{\"518\":1}}],[\"还能保留sft模型的既有能力\",{\"2\":{\"505\":1}}],[\"还能扩展到代码\",{\"2\":{\"503\":1}}],[\"还能\",{\"2\":{\"162\":1}}],[\"让过时的文档自动失效\",{\"2\":{\"1558\":1}}],[\"让\",{\"2\":{\"1447\":1}}],[\"让众包人员尽量避免\",{\"2\":{\"1368\":1}}],[\"让用户通过拖拽组件或简单配置即可完成智能体系统的搭建\",{\"2\":{\"1347\":1}}],[\"让llms预测最终结果\",{\"2\":{\"1273\":1}}],[\"让llms生成\",{\"2\":{\"1273\":1}}],[\"让llm完成与网页相关的任务\",{\"2\":{\"1217\":1}}],[\"让llm扮演游戏角色\",{\"2\":{\"1217\":1}}],[\"让llm生成代码\",{\"2\":{\"1217\":1}}],[\"让其生成合适的demonstration\",{\"2\":{\"1032\":1}}],[\"让这些动作均分概率\",{\"2\":{\"647\":1}}],[\"让模型适应长文本任务\",{\"2\":{\"1436\":1}}],[\"让模型输出多个答案\",{\"2\":{\"561\":1}}],[\"让模型生成\",{\"2\":{\"528\":1}}],[\"让模型自适应生成更有效的位置表示\",{\"2\":{\"356\":1}}],[\"让模型不仅能看\",{\"2\":{\"162\":1}}],[\"让代码看起来更简洁\",{\"2\":{\"27\":1}}],[\"交叉熵法\",{\"2\":{\"2378\":1}}],[\"交叉熵损失\",{\"2\":{\"40\":1,\"980\":1}}],[\"交互模式灵活性要求高的特点\",{\"2\":{\"2081\":1}}],[\"交互链优化\",{\"0\":{\"2171\":1},\"2\":{\"2022\":1}}],[\"交互生成\",{\"2\":{\"1458\":1}}],[\"交互生成结果\",{\"2\":{\"1412\":1}}],[\"交流与相互作用\",{\"2\":{\"1338\":1}}],[\"交流之后的个人思考\",{\"2\":{\"162\":1}}],[\"增量更新算法\",{\"2\":{\"747\":1}}],[\"增量更新公式为\",{\"2\":{\"608\":1}}],[\"增量更新公式\",{\"2\":{\"608\":1}}],[\"增加功能模块\",{\"2\":{\"2534\":1}}],[\"增加检索和处理的复杂度\",{\"2\":{\"2533\":1}}],[\"增加了计算和存储的开销\",{\"2\":{\"2533\":1}}],[\"增加了语义的复杂性\",{\"2\":{\"2465\":1}}],[\"增加了聚合操作\",{\"2\":{\"2188\":1}}],[\"增加其影响\",{\"2\":{\"2087\":1}}],[\"增加文本长度\",{\"2\":{\"1436\":1}}],[\"增加更多语言的数据集\",{\"2\":{\"1327\":1}}],[\"增加计算成本\",{\"2\":{\"1079\":1}}],[\"增加到\",{\"2\":{\"889\":1,\"1069\":1}}],[\"增加指数位\",{\"2\":{\"768\":1}}],[\"增加基数会导致维度增加\",{\"2\":{\"292\":1}}],[\"增加不必要的开销\",{\"2\":{\"276\":1}}],[\"增加缩放比例\",{\"2\":{\"221\":1}}],[\"增加开发和维护成本\",{\"2\":{\"157\":1}}],[\"增强了模型对长样本的学习能力\",{\"2\":{\"2624\":1,\"2671\":1}}],[\"增强了模型的上下文感知能力\",{\"2\":{\"1215\":1}}],[\"增强了模型的表达能力\",{\"2\":{\"1155\":1}}],[\"增强了模型的泛化能力\",{\"2\":{\"1069\":1}}],[\"增强过程中的集成挑战较多\",{\"2\":{\"2466\":1}}],[\"增强任务相关性\",{\"2\":{\"2143\":1}}],[\"增强可解释性\",{\"2\":{\"1543\":1}}],[\"增强表达能力\",{\"2\":{\"1490\":1}}],[\"增强对推理能力的具体影响\",{\"2\":{\"1403\":1}}],[\"增强型\",{\"0\":{\"1362\":1}}],[\"增强其处理由量化引起的精度损失的能力\",{\"2\":{\"1355\":1}}],[\"增强和\",{\"2\":{\"1264\":1}}],[\"增强掩码解码器\",{\"2\":{\"1237\":1}}],[\"增强特定任务的效果\",{\"2\":{\"1237\":1}}],[\"增强训练稳定性\",{\"2\":{\"1112\":1,\"2157\":1}}],[\"增强\",{\"2\":{\"1069\":1}}],[\"增强深度学习模型的推理能力\",{\"2\":{\"934\":1}}],[\"增强dca在长文本上的表现\",{\"2\":{\"217\":1}}],[\"增强灵活性和扩展性\",{\"2\":{\"12\":1}}],[\"挑战\",{\"2\":{\"157\":1,\"419\":1,\"2103\":1}}],[\"挑战与前沿技术\",{\"0\":{\"57\":1}}],[\"重排模型\",{\"0\":{\"2394\":1},\"2\":{\"2394\":1}}],[\"重计算策略\",{\"2\":{\"2231\":1}}],[\"重写trainer类的create\",{\"2\":{\"1832\":1}}],[\"重参数化\",{\"2\":{\"1796\":1,\"2069\":1}}],[\"重叠\",{\"2\":{\"1763\":2}}],[\"重叠部分也可能帮助捕获完整答案\",{\"2\":{\"1598\":1}}],[\"重算\",{\"2\":{\"1389\":1}}],[\"重要性权重始终为1\",{\"2\":{\"2545\":1}}],[\"重要性权重\",{\"2\":{\"2357\":1}}],[\"重要性采样直接使用了公式\",{\"2\":{\"2561\":1}}],[\"重要性采样的不足\",{\"0\":{\"2561\":1}}],[\"重要性采样的应用显著提升了样本利用效率\",{\"2\":{\"766\":1}}],[\"重要性采样技术\",{\"0\":{\"623\":1}}],[\"重要性越高的子词对loss的影响越大\",{\"2\":{\"393\":1}}],[\"重复递归\",{\"2\":{\"2141\":1}}],[\"重复以下流程\",{\"2\":{\"2011\":1}}],[\"重复decode流程持续生成token直到模型输出\",{\"2\":{\"1782\":1}}],[\"重复\",{\"2\":{\"400\":1}}],[\"重复上述步骤\",{\"2\":{\"393\":1,\"2570\":1}}],[\"重复迭代\",{\"2\":{\"392\":1}}],[\"重复合并\",{\"2\":{\"381\":1}}],[\"重复的文本\",{\"2\":{\"301\":1}}],[\"重新定义奖励机制\",{\"2\":{\"2346\":1}}],[\"重新表述\",{\"2\":{\"1663\":1}}],[\"重新表述问题来进行尝试\",{\"2\":{\"1663\":1}}],[\"重新训练模型\",{\"2\":{\"593\":1}}],[\"重新归一化剩余概率\",{\"2\":{\"364\":1}}],[\"重新计算所有前序token的k\",{\"2\":{\"166\":1}}],[\"重塑为批量维度\",{\"2\":{\"156\":1}}],[\"重点分析\",{\"0\":{\"2342\":1},\"1\":{\"2372\":1,\"2400\":1,\"2425\":1}}],[\"重点分析了模型参数\",{\"2\":{\"2099\":1}}],[\"重点数据集\",{\"0\":{\"2184\":1}}],[\"重点在于如何判断和利用真多轮与伪多轮数据\",{\"2\":{\"2181\":1}}],[\"重点在于观察指标变化趋势而非绝对大小\",{\"2\":{\"592\":1}}],[\"重点降低坏答案的采样概率\",{\"2\":{\"1966\":1}}],[\"重点介绍了分布式初始化和fwd与bwd过程中的关键步骤\",{\"2\":{\"1365\":1}}],[\"重点介绍了数据处理过程\",{\"2\":{\"1046\":1}}],[\"重点步骤\",{\"0\":{\"1299\":1}}],[\"重点关注attention模块\",{\"2\":{\"256\":1}}],[\"重点内容解析\",{\"0\":{\"367\":1,\"394\":1,\"438\":1,\"476\":1,\"1135\":1,\"1196\":1,\"1202\":1},\"1\":{\"393\":1,\"419\":1,\"420\":1,\"444\":1,\"445\":1,\"465\":1,\"471\":1,\"472\":1,\"494\":1,\"498\":1,\"503\":1,\"526\":1,\"535\":1,\"559\":1,\"568\":1,\"1187\":1,\"1237\":1,\"1246\":1,\"1253\":1,\"1288\":1,\"1296\":1,\"1302\":1,\"1343\":1,\"1349\":1,\"1388\":1,\"1394\":1,\"1442\":1,\"1487\":1}}],[\"重点内容提取\",{\"0\":{\"342\":1,\"430\":1,\"447\":1,\"620\":1,\"1158\":1},\"1\":{\"366\":1,\"392\":1,\"418\":1,\"443\":1,\"456\":1,\"470\":1,\"474\":1,\"485\":1,\"497\":1,\"501\":1,\"515\":1,\"529\":1,\"533\":1,\"548\":1,\"655\":1,\"690\":1,\"726\":1,\"760\":1,\"1207\":1,\"1258\":1,\"1306\":1}}],[\"重点内容\",{\"0\":{\"201\":1,\"399\":1,\"448\":1,\"486\":1,\"551\":1,\"1016\":1,\"1247\":1,\"1571\":1,\"1749\":1,\"2692\":1},\"1\":{\"222\":1,\"245\":1,\"268\":1,\"291\":1,\"426\":1,\"452\":1,\"475\":1,\"480\":1,\"502\":1,\"508\":1,\"516\":1,\"534\":1,\"542\":1,\"549\":1,\"567\":1,\"576\":1,\"583\":1,\"586\":1,\"619\":1,\"654\":1,\"1059\":1,\"1104\":1,\"1154\":1,\"1297\":1,\"1344\":1,\"1389\":1,\"1621\":1,\"1676\":1,\"1732\":1,\"1809\":1,\"1871\":1,\"1928\":1,\"1979\":1}}],[\"重点段落与数据\",{\"0\":{\"1074\":1,\"1090\":1,\"1722\":1,\"1903\":1,\"2071\":1,\"2220\":1,\"2610\":1},\"1\":{\"1121\":1,\"1138\":1,\"1190\":1,\"1240\":1,\"1957\":1,\"2008\":1,\"2057\":1,\"2123\":1,\"2170\":1,\"2617\":1,\"2622\":1}}],[\"重点段落提取\",{\"0\":{\"1030\":1,\"1119\":1,\"2208\":1},\"1\":{\"2245\":1,\"2280\":1,\"2312\":1}}],[\"重点段落\",{\"0\":{\"115\":1,\"524\":1,\"547\":1,\"554\":1,\"608\":1,\"626\":1,\"646\":1,\"647\":1,\"656\":1,\"687\":1,\"714\":1,\"735\":1,\"747\":1,\"950\":1,\"971\":1,\"1105\":1,\"1106\":1,\"1199\":1,\"1505\":1,\"1525\":1,\"1536\":1,\"1563\":1,\"1591\":1,\"1616\":1,\"1622\":1,\"1690\":1,\"1706\":1,\"1713\":1,\"1729\":1,\"1736\":1,\"1737\":1,\"1803\":1,\"1812\":1,\"1844\":1,\"1909\":1,\"1932\":1,\"1954\":1,\"1992\":1,\"2005\":1,\"2045\":1,\"2149\":1,\"2194\":1,\"2221\":1,\"2295\":1,\"2300\":1,\"2306\":1,\"2310\":1,\"2358\":1,\"2389\":1,\"2454\":1,\"2553\":1,\"2583\":1,\"2642\":1,\"2649\":1},\"1\":{\"581\":1,\"590\":1,\"614\":1,\"623\":1,\"649\":1,\"658\":1,\"723\":1,\"748\":1,\"757\":1,\"779\":1,\"789\":1,\"810\":1,\"992\":1,\"1012\":1,\"1033\":1,\"1052\":1,\"1076\":1,\"1096\":1,\"1155\":1,\"1156\":1,\"1204\":1,\"1205\":1,\"1255\":1,\"1256\":1,\"1576\":1,\"1613\":1,\"1628\":1,\"1666\":1,\"1671\":1,\"1683\":1,\"1720\":1,\"1727\":1,\"1746\":1,\"1764\":1,\"1770\":1,\"1787\":1,\"1795\":1,\"1804\":1,\"1824\":1,\"1831\":1,\"1848\":1,\"1857\":1,\"1865\":1,\"1866\":1,\"1873\":1,\"1883\":1,\"1890\":1,\"1901\":1,\"1905\":1,\"1913\":1,\"1922\":1,\"1930\":1,\"1956\":1,\"1962\":1,\"1974\":1,\"1981\":1,\"2013\":1,\"2054\":1,\"2062\":1,\"2107\":1,\"2157\":1,\"2192\":1,\"2231\":1,\"2256\":1,\"2291\":1,\"2322\":1,\"2326\":1,\"2356\":1,\"2386\":1,\"2388\":1,\"2415\":1,\"2416\":1,\"2440\":1,\"2441\":1,\"2463\":1,\"2474\":1,\"2491\":1,\"2504\":1,\"2561\":1,\"2569\":1,\"2577\":1,\"2591\":1,\"2598\":1,\"2605\":1,\"2654\":1,\"2658\":1,\"2662\":1}}],[\"重点解决了传统注意力机制在处理长文本时的计算效率和内存占用问题\",{\"2\":{\"86\":1}}],[\"重点是怎么把前面的n组长度比后面的大\",{\"2\":{\"47\":1}}],[\"8tb\",{\"2\":{\"2281\":1}}],[\"8bit\",{\"2\":{\"2145\":1}}],[\"8b\",{\"2\":{\"1360\":1,\"2233\":2}}],[\"8b和70b模型均采用了gqa技术\",{\"2\":{\"1071\":1}}],[\"848mib\",{\"2\":{\"2347\":1}}],[\"84\",{\"2\":{\"1329\":2}}],[\"8~11\",{\"2\":{\"1306\":1}}],[\"8~15\",{\"2\":{\"1258\":1}}],[\"8x\",{\"2\":{\"1178\":1}}],[\"8字符回退到字节分解\",{\"2\":{\"1112\":1}}],[\"8k\",{\"2\":{\"889\":1,\"1360\":2}}],[\"8位整数\",{\"2\":{\"768\":1}}],[\"804\",{\"2\":{\"837\":1}}],[\"80\",{\"2\":{\"750\":1,\"997\":1}}],[\"8编码\",{\"2\":{\"318\":1}}],[\"874在10进制和16进制下均成立\",{\"2\":{\"246\":1}}],[\"8\",{\"0\":{\"482\":1,\"2573\":1},\"1\":{\"511\":1,\"544\":1},\"2\":{\"246\":1,\"391\":1,\"470\":1,\"497\":1,\"729\":1,\"763\":1,\"996\":1,\"1076\":1,\"1110\":1,\"1119\":3,\"1204\":1,\"1258\":1,\"1324\":1,\"1409\":1,\"2090\":1,\"2539\":1,\"2697\":1}}],[\"81928192×8192\",{\"2\":{\"1991\":1}}],[\"8192×81928192\",{\"2\":{\"1991\":1}}],[\"8192\",{\"2\":{\"197\":1,\"218\":1}}],[\"8行表示token数量\",{\"2\":{\"156\":1}}],[\"89x≥89\",{\"2\":{\"1925\":1}}],[\"89\",{\"2\":{\"49\":1,\"1324\":1}}],[\"沿着缩小搜索范围的思路\",{\"2\":{\"1559\":1}}],[\"沿着坡度最陡的方向下降\",{\"2\":{\"32\":1}}],[\"沿头部维度将特征分为两大块\",{\"2\":{\"156\":1}}],[\"描述教师模型与学生模型之间的关系及其结构\",{\"2\":{\"715\":1}}],[\"描述\",{\"2\":{\"155\":1,\"197\":1,\"346\":1,\"1226\":1,\"1318\":1,\"1326\":1,\"1490\":1,\"1960\":1,\"2069\":1,\"2092\":1,\"2143\":1,\"2254\":1,\"2520\":1,\"2532\":1}}],[\"链接\",{\"2\":{\"153\":1,\"631\":1,\"1839\":1,\"1971\":1,\"2368\":1}}],[\"链表反转\",{\"2\":{\"35\":1}}],[\"链表基础\",{\"2\":{\"35\":1}}],[\"链表\",{\"0\":{\"35\":1}}],[\"保证\",{\"2\":{\"2308\":1}}],[\"保存回对应的块中\",{\"2\":{\"2623\":1}}],[\"保存路径等\",{\"2\":{\"2194\":1}}],[\"保存在cache\",{\"2\":{\"1870\":1}}],[\"保守\",{\"2\":{\"400\":1}}],[\"保持语义清晰\",{\"2\":{\"2364\":1}}],[\"保持预训练模型参数固定\",{\"2\":{\"2082\":1}}],[\"保持llm其他部分参数固定\",{\"2\":{\"1865\":1}}],[\"保持文档逻辑\",{\"2\":{\"1424\":1}}],[\"保持最大学习率\",{\"2\":{\"1344\":1}}],[\"保持1个token约对应1\",{\"2\":{\"1302\":1}}],[\"保持模型的通用性\",{\"2\":{\"1299\":1}}],[\"保持精度\",{\"2\":{\"462\":1}}],[\"保持输入维度不变\",{\"2\":{\"292\":1}}],[\"保持技术前沿\",{\"2\":{\"153\":1}}],[\"保留了文档原有的结构信息\",{\"2\":{\"2645\":1}}],[\"保留和随后检索信息的过程\",{\"2\":{\"1892\":1}}],[\"保留注意力qkv层偏置以增强外推能力\",{\"2\":{\"1304\":1}}],[\"保留并强化了第2\",{\"2\":{\"1187\":1}}],[\"保留对整体损失影响较大的子词\",{\"2\":{\"343\":1}}],[\"保留总概率最高的\",{\"2\":{\"324\":1}}],[\"保留区域需人工选择\",{\"2\":{\"168\":1}}],[\"保留数据的主要特征\",{\"2\":{\"39\":1}}],[\"行切割\",{\"2\":{\"2609\":1}}],[\"行并行的方法如下\",{\"2\":{\"2602\":1}}],[\"行并行\",{\"0\":{\"2602\":1}}],[\"行动\",{\"2\":{\"1608\":1}}],[\"行动和学习\",{\"2\":{\"1474\":1}}],[\"行动清单\",{\"0\":{\"153\":1,\"196\":1,\"234\":1,\"242\":1,\"256\":1,\"275\":1,\"281\":1,\"284\":1,\"288\":1,\"303\":1,\"311\":1,\"322\":1,\"329\":1,\"361\":1,\"380\":1,\"383\":1,\"387\":1,\"388\":1,\"439\":1,\"442\":1,\"481\":1,\"522\":1,\"530\":1,\"531\":1,\"597\":1,\"599\":1,\"613\":1,\"615\":1,\"645\":1,\"662\":1,\"663\":1,\"666\":1,\"668\":1,\"669\":1,\"698\":1,\"709\":1,\"730\":1,\"738\":1,\"739\":1,\"752\":1,\"755\":1,\"756\":1,\"759\":1,\"761\":1,\"796\":1,\"807\":1,\"816\":1,\"817\":1,\"821\":1,\"842\":1,\"902\":1,\"905\":1,\"912\":1,\"914\":1,\"928\":1,\"1034\":1,\"1125\":1,\"1140\":1,\"1144\":1,\"1161\":1,\"1177\":1,\"1212\":1,\"1239\":1,\"1257\":1,\"1271\":1,\"1274\":1,\"1287\":1,\"1294\":1,\"1307\":1,\"1310\":1,\"1327\":1,\"1339\":1,\"1350\":1,\"1363\":1,\"1370\":1,\"1381\":1,\"1385\":1,\"1387\":1,\"1403\":1,\"1406\":1,\"1417\":1,\"1438\":1,\"1441\":1,\"1444\":1,\"1475\":1,\"1492\":1,\"1493\":1,\"1527\":1,\"1555\":1,\"1556\":1,\"1629\":1,\"1647\":1,\"1651\":1,\"1686\":1,\"1709\":1,\"1751\":1,\"1814\":1,\"1818\":1,\"1839\":1,\"1852\":1,\"1861\":1,\"1863\":1,\"1880\":1,\"1902\":1,\"1907\":1,\"1921\":1,\"1934\":1,\"1952\":1,\"1953\":1,\"1961\":1,\"1997\":1,\"2015\":1,\"2017\":1,\"2019\":1,\"2038\":1,\"2040\":1,\"2048\":1,\"2075\":1,\"2078\":1,\"2093\":1,\"2111\":1,\"2120\":1,\"2159\":1,\"2174\":1,\"2182\":1,\"2199\":1,\"2214\":1,\"2215\":1,\"2219\":1,\"2229\":1,\"2244\":1,\"2265\":1,\"2275\":1,\"2307\":1,\"2332\":1,\"2360\":1,\"2377\":1,\"2380\":1,\"2401\":1,\"2409\":1,\"2410\":1,\"2412\":1,\"2421\":1,\"2453\":1,\"2461\":1,\"2464\":1,\"2470\":1,\"2471\":1,\"2478\":1,\"2508\":1,\"2521\":1,\"2524\":1,\"2551\":1,\"2556\":1,\"2607\":1,\"2629\":1,\"2674\":1,\"2701\":1},\"1\":{\"353\":1,\"378\":1,\"1704\":1,\"1762\":1},\"2\":{\"647\":1,\"1008\":1}}],[\"行为约束是否可以应用于其他领域的强化学习任务\",{\"2\":{\"1897\":1}}],[\"行为约束在强化学习中的应用如何影响模型的稳定性\",{\"2\":{\"1838\":1}}],[\"行为约束优化目标\",{\"0\":{\"1720\":1}}],[\"行为约束\",{\"2\":{\"1471\":1}}],[\"行为约束可以通过参考策略来实现\",{\"2\":{\"721\":1}}],[\"行激活值或\",{\"2\":{\"1022\":1}}],[\"行业普遍认为仅需高质量且多样性的少量数据\",{\"2\":{\"369\":1}}],[\"行业最佳实践\",{\"2\":{\"49\":1}}],[\"公式说明\",{\"0\":{\"2030\":1}}],[\"公式在代码中使用\",{\"2\":{\"2012\":1}}],[\"公式更新过程如下\",{\"2\":{\"1891\":1}}],[\"公式调整\",{\"0\":{\"1891\":1}}],[\"公式调整如下\",{\"2\":{\"1266\":1}}],[\"公式推导\",{\"2\":{\"1461\":1}}],[\"公式显示\",{\"0\":{\"1364\":1,\"1455\":1,\"1535\":1,\"2012\":1,\"2121\":1,\"2140\":1,\"2142\":1,\"2187\":1,\"2289\":1,\"2531\":1,\"2542\":1}}],[\"公式表明\",{\"2\":{\"1232\":1}}],[\"公式表达\",{\"2\":{\"293\":1}}],[\"公式与设定\",{\"0\":{\"1229\":1}}],[\"公式为\",{\"2\":{\"655\":2,\"748\":1,\"1093\":1,\"2306\":1,\"2322\":1}}],[\"公式总结\",{\"0\":{\"513\":1}}],[\"公式示例\",{\"0\":{\"427\":1},\"2\":{\"704\":3}}],[\"公式变为\",{\"2\":{\"228\":1}}],[\"公式描述\",{\"2\":{\"222\":1}}],[\"公式\",{\"0\":{\"1437\":1,\"2137\":1},\"2\":{\"194\":1,\"199\":1,\"215\":1,\"238\":1,\"261\":1,\"285\":1,\"307\":1,\"346\":1,\"622\":1,\"1685\":1}}],[\"公式以及适用场景\",{\"2\":{\"152\":1}}],[\"公式如下\",{\"2\":{\"130\":1,\"190\":1,\"268\":1,\"723\":1,\"732\":1,\"1229\":1,\"1594\":1,\"1901\":1}}],[\"参与训练优化\",{\"2\":{\"2254\":1}}],[\"参与模型训练\",{\"2\":{\"1281\":1}}],[\"参考来源\",{\"2\":{\"2145\":1}}],[\"参考策略不太远的范围内更新\",{\"2\":{\"1720\":1}}],[\"参考datalearner关于ul2的模型卡信息\",{\"2\":{\"1441\":1}}],[\"参考scaling\",{\"2\":{\"1374\":1}}],[\"参考开源项目\",{\"2\":{\"511\":1}}],[\"参考文献\",{\"0\":{\"1603\":1,\"1658\":1},\"1\":{\"1658\":1},\"2\":{\"151\":1}}],[\"参数服务器根据不同模式存储着优化器参数\",{\"2\":{\"2288\":1}}],[\"参数设置与注意事项\",{\"0\":{\"2217\":1}}],[\"参数设置不当以及未充分考虑数据集特点等\",{\"2\":{\"2268\":1}}],[\"参数设置不当\",{\"2\":{\"630\":1}}],[\"参数总量\",{\"2\":{\"2090\":1}}],[\"参数模型\",{\"2\":{\"2065\":1}}],[\"参数需设置为\",{\"2\":{\"2050\":1}}],[\"参数更新与内在秩\",{\"0\":{\"2013\":1}}],[\"参数更新量小于\",{\"2\":{\"57\":1}}],[\"参数时\",{\"2\":{\"2000\":1}}],[\"参数说明\",{\"0\":{\"1882\":1},\"1\":{\"1937\":1,\"1987\":1,\"2039\":1,\"2091\":1}}],[\"参数分组\",{\"2\":{\"1771\":1}}],[\"参数的大小\",{\"2\":{\"1636\":1}}],[\"参数优化\",{\"0\":{\"1755\":1},\"2\":{\"1583\":1}}],[\"参数名称\",{\"2\":{\"1499\":1}}],[\"参数清晰可控\",{\"2\":{\"1451\":1}}],[\"参数清晰度和加载效率的优势\",{\"2\":{\"1265\":1}}],[\"参数规模\",{\"2\":{\"1398\":1}}],[\"参数数量\",{\"2\":{\"1232\":3,\"1416\":1,\"1419\":1}}],[\"参数与令牌的关系被进一步阐述\",{\"2\":{\"1201\":1}}],[\"参数初始化服从正态分布\",{\"2\":{\"932\":1}}],[\"参数只能取0或1\",{\"2\":{\"768\":1}}],[\"参数调整过于激进可能引发模型不稳定性\",{\"2\":{\"600\":1}}],[\"参数调整\",{\"2\":{\"502\":1,\"567\":1}}],[\"参数量更大\",{\"2\":{\"933\":1}}],[\"参数量平衡与性能优化的权衡\",{\"2\":{\"289\":1}}],[\"参数量减少\",{\"2\":{\"40\":1}}],[\"参数\",{\"2\":{\"190\":1,\"197\":1,\"261\":1,\"346\":1,\"1162\":1,\"1318\":1,\"1323\":1,\"1326\":1,\"1360\":1,\"1393\":1,\"1483\":1,\"1960\":1,\"2000\":1,\"2092\":1,\"2479\":1,\"2482\":1,\"2520\":1,\"2532\":1}}],[\"参数高效微调\",{\"0\":{\"1695\":1},\"2\":{\"1875\":1,\"1983\":1}}],[\"参数高效\",{\"2\":{\"40\":1}}],[\"策略基于预训练的大语言模型\",{\"2\":{\"2443\":1}}],[\"策略通常由简单的神经网络结构初始化\",{\"2\":{\"2418\":1}}],[\"策略概率\",{\"2\":{\"2357\":1}}],[\"策略模型的拟合\",{\"0\":{\"1913\":1}}],[\"策略距离\",{\"2\":{\"1473\":1}}],[\"策略与价值函数的关系\",{\"0\":{\"810\":1}}],[\"策略初始化\",{\"2\":{\"695\":1}}],[\"策略如何在不同模型和任务中自动调节\",{\"2\":{\"694\":1}}],[\"策略截断与稳定性\",{\"0\":{\"658\":1}}],[\"策略改进\",{\"2\":{\"656\":1}}],[\"策略提升完成\",{\"2\":{\"656\":1}}],[\"策略提升\",{\"2\":{\"656\":1}}],[\"策略的占用度量\",{\"2\":{\"655\":1}}],[\"策略价值\",{\"2\":{\"642\":1}}],[\"策略网络优化器\",{\"2\":{\"619\":1}}],[\"策略网络\",{\"2\":{\"619\":1}}],[\"策略迭代主循环\",{\"2\":{\"656\":1}}],[\"策略迭代的过程\",{\"2\":{\"656\":1}}],[\"策略迭代通过交替进行策略评估和策略提升来获得最优策略\",{\"2\":{\"621\":1}}],[\"策略迭代\",{\"2\":{\"588\":1}}],[\"策略迭代算法\",{\"0\":{\"588\":1},\"1\":{\"621\":1,\"656\":1,\"691\":1,\"727\":1,\"761\":1,\"793\":1,\"824\":1},\"2\":{\"151\":1,\"656\":1}}],[\"策略迭代算法|策略迭代算法\",{\"2\":{\"5\":1}}],[\"策略采样与更新\",{\"2\":{\"585\":1}}],[\"策略\",{\"2\":{\"581\":1,\"655\":1,\"676\":1,\"730\":1,\"1566\":1,\"1613\":1,\"2055\":1,\"2308\":1,\"2418\":1,\"2443\":1}}],[\"策略评估完成\",{\"2\":{\"656\":1}}],[\"策略评估收敛阈值\",{\"2\":{\"656\":1}}],[\"策略评估和提升的终止条件\",{\"2\":{\"656\":1}}],[\"策略评估\",{\"2\":{\"545\":1,\"647\":1,\"656\":2}}],[\"策略梯度方法通过奖励估计值\",{\"2\":{\"1942\":1,\"1993\":1}}],[\"策略梯度与ppo回顾\",{\"0\":{\"1942\":1,\"1993\":1},\"1\":{\"1992\":1,\"2044\":1,\"2045\":1,\"2097\":1}}],[\"策略梯度与q值函数\",{\"0\":{\"586\":1}}],[\"策略梯度公式为\",{\"2\":{\"586\":1,\"1901\":1}}],[\"策略梯度\",{\"2\":{\"487\":1,\"617\":1,\"1767\":1,\"1829\":1,\"1954\":1,\"2297\":1,\"2329\":1,\"2520\":1,\"2532\":1}}],[\"策略梯度算法通过直接优化策略分布\",{\"2\":{\"891\":1}}],[\"策略梯度算法通过对策略参数化\",{\"2\":{\"723\":1}}],[\"策略梯度算法是一种基于策略的方法\",{\"2\":{\"652\":1}}],[\"策略梯度算法\",{\"0\":{\"584\":1,\"723\":1},\"1\":{\"617\":1,\"652\":1,\"687\":1,\"723\":1,\"757\":1,\"789\":1,\"820\":1,\"856\":1,\"891\":1,\"927\":1,\"965\":1},\"2\":{\"151\":1}}],[\"策略优化的分类是一个重要的研究方向\",{\"2\":{\"585\":1}}],[\"策略优化\",{\"2\":{\"484\":1,\"489\":1,\"550\":1,\"1461\":1,\"2467\":1,\"2567\":1,\"2639\":1}}],[\"马尔可夫决策过程\",{\"0\":{\"642\":1},\"1\":{\"676\":1,\"714\":1,\"748\":1,\"779\":1,\"810\":1,\"844\":1,\"879\":1,\"915\":1,\"953\":1,\"994\":1,\"1034\":1,\"1077\":1},\"2\":{\"151\":1,\"484\":1,\"642\":1,\"676\":1,\"994\":1,\"2124\":1}}],[\"马尔可夫决策过程|马尔可夫决策过程\",{\"2\":{\"5\":1}}],[\"📌\",{\"2\":{\"530\":3}}],[\"📋\",{\"0\":{\"275\":1,\"559\":1,\"1307\":1},\"2\":{\"555\":1}}],[\"💭\",{\"0\":{\"260\":1}}],[\"📘\",{\"2\":{\"256\":1}}],[\"🛠️\",{\"2\":{\"240\":1}}],[\"📚\",{\"2\":{\"240\":1}}],[\"📊\",{\"0\":{\"197\":1,\"714\":1,\"1487\":1},\"1\":{\"748\":1,\"779\":1,\"810\":1}}],[\"🚀\",{\"0\":{\"676\":1},\"2\":{\"196\":1}}],[\"🔍\",{\"2\":{\"196\":1,\"414\":1}}],[\"📈趋势预测\",{\"0\":{\"360\":1,\"412\":1,\"633\":1,\"648\":1,\"701\":1,\"703\":1,\"706\":1,\"784\":1,\"787\":1,\"788\":1,\"791\":1,\"793\":1,\"829\":1,\"852\":1,\"857\":1,\"877\":1,\"893\":1,\"927\":1,\"937\":1,\"940\":1,\"952\":1,\"1484\":1,\"1700\":1,\"1742\":1,\"2321\":1,\"2362\":1,\"2407\":1,\"2426\":1,\"2435\":1,\"2437\":1,\"2488\":1,\"2497\":1},\"2\":{\"168\":1,\"647\":1}}],[\"📈\",{\"0\":{\"150\":1,\"155\":1,\"212\":1,\"227\":1,\"306\":1,\"314\":1,\"385\":1,\"598\":1,\"629\":1,\"650\":1,\"680\":1,\"700\":1,\"745\":1,\"753\":1,\"953\":1,\"1261\":1,\"1427\":1,\"1464\":1,\"1526\":1,\"1537\":1,\"1543\":1,\"2473\":1},\"2\":{\"169\":1,\"187\":1,\"220\":1,\"239\":1,\"256\":1,\"289\":1,\"346\":1,\"365\":1,\"414\":1,\"420\":1,\"471\":1,\"481\":1,\"535\":1,\"555\":1,\"698\":1,\"730\":1,\"912\":1,\"941\":1,\"980\":1,\"985\":1,\"1021\":1,\"1036\":1,\"1296\":1}}],[\"💡这使得提示优化在较小模型和多任务学习中表现更为优异\",{\"2\":{\"1680\":1}}],[\"💡启发点\",{\"0\":{\"255\":1,\"336\":1,\"386\":1,\"580\":1,\"625\":1,\"634\":1,\"665\":1,\"717\":1,\"721\":1,\"722\":1,\"725\":1,\"766\":1,\"786\":1,\"790\":1,\"808\":1,\"823\":1,\"869\":1,\"878\":1,\"891\":1,\"1095\":1,\"1126\":1,\"1206\":1,\"1220\":1,\"1223\":1,\"1242\":1,\"1244\":1,\"1317\":1,\"1340\":1,\"1342\":1,\"1391\":1,\"1430\":1,\"1446\":1,\"1597\":1,\"1754\":1,\"1791\":1,\"1799\":1,\"1801\":1,\"1838\":1,\"1864\":1,\"1877\":1,\"1898\":1,\"1964\":1,\"1967\":1,\"1986\":1,\"1996\":1,\"2025\":1,\"2068\":1,\"2156\":1,\"2173\":1,\"2179\":1,\"2190\":1,\"2211\":1,\"2230\":1,\"2274\":1,\"2301\":1,\"2316\":1,\"2319\":1,\"2352\":1,\"2373\":1,\"2383\":1,\"2385\":1,\"2439\":1,\"2442\":1,\"2460\":1,\"2548\":1,\"2627\":1,\"2661\":1},\"2\":{\"189\":1,\"228\":1,\"465\":1,\"526\":1,\"559\":1,\"647\":1,\"929\":1,\"961\":1,\"1040\":1,\"1071\":1,\"1179\":1,\"1229\":1,\"1287\":1,\"1302\":1,\"1451\":1,\"1487\":1,\"1653\":1,\"1675\":1,\"2073\":1,\"2372\":1,\"2692\":1}}],[\"💡\",{\"0\":{\"97\":1,\"232\":1,\"264\":1,\"270\":1,\"404\":1,\"420\":1,\"445\":1,\"664\":1,\"711\":1,\"915\":1,\"1303\":1,\"1348\":1,\"1357\":1,\"1372\":1,\"1397\":1,\"1656\":1,\"1693\":1,\"1908\":1,\"1979\":1,\"2058\":1,\"2109\":1,\"2136\":1,\"2148\":1,\"2207\":1,\"2240\":1,\"2330\":1,\"2396\":1,\"2428\":1,\"2495\":1,\"2509\":1,\"2541\":1,\"2624\":1,\"2671\":1},\"1\":{\"293\":1,\"315\":1},\"2\":{\"125\":1,\"155\":1,\"157\":1,\"162\":1,\"183\":1,\"190\":1,\"199\":2,\"205\":1,\"216\":1,\"246\":1,\"263\":1,\"293\":1,\"301\":1,\"308\":1,\"318\":1,\"319\":1,\"324\":1,\"369\":1,\"406\":1,\"419\":1,\"434\":1,\"456\":1,\"473\":1,\"488\":1,\"501\":1,\"503\":1,\"507\":1,\"532\":1,\"537\":1,\"548\":1,\"558\":1,\"568\":1,\"589\":1,\"610\":1,\"622\":1,\"656\":1,\"741\":1,\"840\":1,\"867\":1,\"882\":1,\"941\":1,\"983\":1,\"996\":1,\"1006\":1,\"1025\":1,\"1187\":1,\"1198\":1,\"1207\":1,\"1246\":1,\"1262\":1,\"1277\":1,\"1282\":1,\"1306\":1,\"1359\":1,\"1507\":1,\"1517\":1,\"1614\":1,\"1650\":1,\"1667\":1,\"1825\":1,\"1832\":1,\"2026\":3,\"2248\":1,\"2485\":1,\"2600\":1}}],[\"限制\",{\"0\":{\"2402\":1}}],[\"限制了低概率token的生成概率增长\",{\"2\":{\"2296\":1}}],[\"限制了其适用性\",{\"2\":{\"1736\":1}}],[\"限制了模型的创造力\",{\"2\":{\"295\":1}}],[\"限制了模型的最大序列长度和批量大小\",{\"2\":{\"149\":1}}],[\"限制注意力范围\",{\"2\":{\"1255\":1}}],[\"限制被mask的span必须是完整句子\",{\"2\":{\"1089\":1}}],[\"限制每个设备发送和接收数据的数量以避免通信拥堵\",{\"2\":{\"1073\":1}}],[\"限制更新幅度在一个安全范围内\",{\"2\":{\"590\":1}}],[\"限制外部直接访问\",{\"2\":{\"12\":1}}],[\"及其相关量\",{\"2\":{\"2597\":1}}],[\"及其变体\",{\"2\":{\"144\":1}}],[\"及相关知乎文章\",{\"2\":{\"2275\":1}}],[\"及少量特殊存储单元\",{\"2\":{\"2077\":1}}],[\"及代码仓库https\",{\"2\":{\"469\":1}}],[\"及本地数据源通信\",{\"2\":{\"118\":1}}],[\"告诉我们这个病人患病的可能性有多大\",{\"2\":{\"143\":1}}],[\"当增加并行度时\",{\"2\":{\"2704\":1}}],[\"当gpu1在进行\",{\"2\":{\"2688\":1}}],[\"当gpu0在进行\",{\"2\":{\"2688\":1}}],[\"当词表vvv很大时\",{\"2\":{\"2660\":1}}],[\"当词汇表较大时\",{\"2\":{\"985\":1}}],[\"当num\",{\"0\":{\"2636\":1}}],[\"当上下文段落过长时\",{\"2\":{\"2582\":1}}],[\"当系统无法找到任何好结果时\",{\"2\":{\"2540\":1}}],[\"当系统能够自主构建工具\",{\"2\":{\"1904\":1}}],[\"当检索到的文档没有一篇强相关\",{\"2\":{\"2506\":1}}],[\"当我们遍历到最后一块时\",{\"2\":{\"2505\":1}}],[\"当文本块过长时\",{\"2\":{\"2444\":1}}],[\"当文档文块过大时\",{\"2\":{\"2154\":1}}],[\"当反向传播过程结束\",{\"2\":{\"2308\":1}}],[\"当某个父节点下的多数叶子节点都与问题匹配上则将该父节点作为结果返回\",{\"2\":{\"2271\":1}}],[\"当某个答案在policy模型中的采样概率较高时\",{\"2\":{\"1681\":1}}],[\"当某个答案在sft模型中的采样概率高于policy模型时\",{\"2\":{\"1681\":1}}],[\"当人类提供反馈时\",{\"2\":{\"2259\":1}}],[\"当用户提问匹配到某个分块后\",{\"2\":{\"2197\":1}}],[\"当llm推理再次遇到相同的\",{\"2\":{\"2064\":1}}],[\"当每个因素由独立的\",{\"2\":{\"2037\":1}}],[\"当将任务分解后\",{\"2\":{\"2037\":1}}],[\"当结果数量过多时可能会导致信息过载\",{\"2\":{\"2000\":1}}],[\"当计算期望时\",{\"2\":{\"1942\":1,\"1993\":1}}],[\"当policy模型对某个答案的拟合较充分时\",{\"2\":{\"1913\":1}}],[\"当应用于大规模语言模型\",{\"2\":{\"1841\":1}}],[\"当一个系统能够在某些步骤中决定是继续执行还是终止任务时\",{\"2\":{\"1847\":1}}],[\"当一个系统使用\",{\"2\":{\"1728\":1}}],[\"当一个任务可以被拆解为顺序执行的子步骤时\",{\"2\":{\"1760\":1}}],[\"当t=tt\",{\"2\":{\"1732\":1}}],[\"当t≠tt\",{\"2\":{\"1732\":1}}],[\"当训练集上的奖励增长时\",{\"2\":{\"1505\":1}}],[\"当余弦相似度显著下降时\",{\"2\":{\"1470\":1}}],[\"当位置编码与输入嵌入\",{\"2\":{\"1343\":1}}],[\"当需要在多个信息源中搜索并分析可能相关的信息以完成搜索任务时\",{\"2\":{\"2185\":1}}],[\"当需要多个智能体协作完成任务时\",{\"2\":{\"1300\":1}}],[\"当需要扩展范围\",{\"2\":{\"223\":1}}],[\"当\",{\"0\":{\"2456\":1,\"2475\":1},\"2\":{\"1022\":2,\"1578\":1,\"1925\":1,\"2308\":1}}],[\"当模型参数大到单张卡放不下时候\",{\"2\":{\"2108\":1}}],[\"当模型的容量和数据量足够大时\",{\"2\":{\"975\":1}}],[\"当模型训练好后\",{\"2\":{\"143\":1}}],[\"当然数据在不同卡上流转的时候\",{\"2\":{\"2108\":1}}],[\"当然\",{\"2\":{\"847\":1,\"2693\":1}}],[\"当两个sample生成的token不一致时\",{\"2\":{\"846\":1}}],[\"当提示层和引导层的大小存在差异时\",{\"2\":{\"845\":1}}],[\"当当前迭代与上一轮的状态价值函数差小于阈值\",{\"2\":{\"656\":1}}],[\"当前最新结果\",{\"2\":{\"2517\":1}}],[\"当前的实时信息\",{\"2\":{\"2269\":1}}],[\"当前秩\",{\"2\":{\"2092\":1}}],[\"当前领域相关文献\",{\"2\":{\"1658\":1}}],[\"当前状态生成动作token的概率\",{\"2\":{\"1613\":1}}],[\"当前状态的预估收益对齐即时奖励加上下一步状态预估收益\",{\"2\":{\"1591\":1}}],[\"当前状态与动作的token序列组合为下一个状态\",{\"2\":{\"581\":1}}],[\"当前大多数评估主要依赖最终成功率\",{\"2\":{\"1453\":1}}],[\"当前时刻的demonstration\",{\"2\":{\"1222\":1}}],[\"当前位置的token只与其之前的token计算\",{\"2\":{\"167\":1}}],[\"当前位置的token与整个序列中的所有token进行计算\",{\"2\":{\"146\":1}}],[\"当梯度从\",{\"2\":{\"488\":1}}],[\"当输入为负时\",{\"2\":{\"238\":1}}],[\"当输入值较大或较小时\",{\"2\":{\"194\":1}}],[\"当序列长度过长时\",{\"2\":{\"231\":1}}],[\"当生成后续token时\",{\"2\":{\"125\":1}}],[\"信息稀疏的部分可以使用更大的块\",{\"2\":{\"2613\":1}}],[\"信息密集的部分可以更细致地分割\",{\"2\":{\"2613\":1}}],[\"信息损失\",{\"2\":{\"1539\":1}}],[\"信息丢失风险\",{\"2\":{\"1513\":1}}],[\"信息\",{\"2\":{\"1143\":1,\"2286\":3}}],[\"信息检索\",{\"2\":{\"436\":1}}],[\"信息泄漏未处理\",{\"2\":{\"241\":1}}],[\"信息泄漏控制\",{\"2\":{\"136\":1}}],[\"信息流动机制\",{\"2\":{\"197\":1}}],[\"信息流动优化\",{\"2\":{\"156\":1}}],[\"信用卡欺诈检测\",{\"2\":{\"39\":1}}],[\"展示了深度学习推理的新可能性\",{\"2\":{\"1342\":1}}],[\"展示了如何实现两个块之间的跨块注意力\",{\"2\":{\"135\":1}}],[\"展示self\",{\"2\":{\"1146\":1}}],[\"展开kl散度\",{\"0\":{\"1657\":1}}],[\"展开讨论\",{\"2\":{\"1617\":1}}],[\"展开\",{\"2\":{\"548\":1}}],[\"展现了强大的文本生成能力\",{\"2\":{\"115\":1}}],[\"❗将长prompt切割成chunk以优化显存使用\",{\"2\":{\"2413\":1}}],[\"❗根据项目需求进行预处理\",{\"2\":{\"2324\":1}}],[\"❗️解决方法\",{\"0\":{\"1159\":1}}],[\"❗️\",{\"0\":{\"191\":1,\"192\":1,\"205\":1,\"542\":1},\"2\":{\"281\":1,\"392\":1,\"417\":1,\"645\":1,\"1125\":1}}],[\"❗\",{\"0\":{\"575\":1},\"2\":{\"133\":1,\"157\":1,\"359\":1,\"501\":1,\"532\":1,\"560\":1,\"567\":1,\"637\":1,\"639\":1,\"647\":1,\"649\":1,\"651\":1,\"669\":1,\"681\":1,\"695\":1,\"712\":1,\"775\":4,\"778\":1,\"789\":1,\"800\":1,\"831\":1,\"929\":1,\"997\":1,\"1107\":1,\"1120\":1,\"1123\":1,\"1137\":1,\"1141\":1,\"1145\":1,\"1203\":1,\"1219\":2,\"1243\":1,\"1245\":1,\"1264\":1,\"1267\":1,\"1287\":1,\"1298\":1,\"1299\":1,\"1304\":1,\"1305\":1,\"1324\":1,\"1337\":1,\"1370\":1,\"1405\":1,\"1502\":1,\"1542\":1,\"1551\":1,\"1586\":1,\"1631\":1,\"1642\":1,\"1677\":1,\"1687\":1,\"1699\":1,\"1744\":1,\"1761\":1,\"1779\":1,\"1784\":1,\"1789\":1,\"1790\":1,\"1822\":1,\"1832\":1,\"1855\":1,\"1856\":1,\"1858\":1,\"1890\":1,\"1923\":1,\"1938\":1,\"1958\":1,\"1966\":1,\"1976\":2,\"1989\":1,\"2007\":1,\"2034\":1,\"2053\":1,\"2074\":1,\"2082\":1,\"2096\":1,\"2115\":1,\"2125\":1,\"2147\":1,\"2160\":1,\"2200\":1,\"2206\":1,\"2212\":1,\"2233\":1,\"2255\":1,\"2266\":1,\"2280\":1,\"2312\":1,\"2337\":1,\"2346\":1,\"2361\":1,\"2375\":1,\"2387\":1,\"2462\":1,\"2481\":1,\"2519\":1,\"2524\":1,\"2527\":1,\"2585\":1,\"2612\":1,\"2652\":1,\"2665\":1,\"2695\":1}}],[\"进入窗口\",{\"2\":{\"769\":1}}],[\"进而影响模型推理时的吞吐量\",{\"2\":{\"1978\":1}}],[\"进而减少在推理时的内存消耗\",{\"2\":{\"733\":1}}],[\"进而优化目标函数\",{\"2\":{\"726\":1}}],[\"进一步的实验表明\",{\"2\":{\"2603\":1}}],[\"进一步简化为\",{\"2\":{\"2528\":1}}],[\"进一步探索自我指导的方式来评估指令难度\",{\"2\":{\"2490\":1}}],[\"进一步加速生成\",{\"2\":{\"2079\":1}}],[\"进一步提高了模型训练的效率\",{\"2\":{\"2711\":1}}],[\"进一步提高效率\",{\"2\":{\"2048\":1}}],[\"进一步提升系统性能\",{\"2\":{\"2534\":1}}],[\"进一步提升了策略优化的效率\",{\"2\":{\"1884\":1}}],[\"进一步提升\",{\"2\":{\"1578\":1}}],[\"进一步提升效率\",{\"2\":{\"279\":1}}],[\"进一步提升性能\",{\"2\":{\"260\":1}}],[\"进一步增强了模型的灵活性和适应性\",{\"2\":{\"1849\":1}}],[\"进一步解决chunk长度不均的问题\",{\"2\":{\"1561\":1}}],[\"进一步递归地将其拆分为更小的部分\",{\"2\":{\"1561\":1}}],[\"进一步研究如何在不同的数据集上优化多任务学习策略\",{\"2\":{\"2502\":1}}],[\"进一步研究不同初始化策略对其他模型结构的影响\",{\"2\":{\"2471\":1}}],[\"进一步研究不同领域中人类偏好的适用性\",{\"2\":{\"1751\":1}}],[\"进一步研究价值模型在其他数据集上的表现\",{\"2\":{\"2307\":1}}],[\"进一步研究dpop算法在不同数据集上的表现\",{\"2\":{\"2120\":1}}],[\"进一步研究qwen2\",{\"2\":{\"1492\":1}}],[\"进一步研究\",{\"2\":{\"1441\":1}}],[\"进一步研究多智能体系统中的mdp应用\",{\"2\":{\"1077\":1}}],[\"进一步研究sarsa\",{\"2\":{\"951\":1}}],[\"进一步研究动态规划在不同类型问题中的应用\",{\"2\":{\"761\":1}}],[\"进一步考虑不同demonstration之间的差异性\",{\"2\":{\"949\":1}}],[\"进一步减少位数\",{\"2\":{\"768\":1}}],[\"进一步微调\",{\"2\":{\"535\":1}}],[\"进一步优化输出结果\",{\"2\":{\"1288\":1}}],[\"进一步优化算法效果\",{\"2\":{\"434\":1}}],[\"进一步优化\",{\"2\":{\"413\":1}}],[\"进一步优化了训练效率和性能\",{\"2\":{\"115\":1}}],[\"进一步对rope嵌入进行按比例缩放\",{\"2\":{\"252\":1}}],[\"进制表示\",{\"2\":{\"223\":1,\"292\":1}}],[\"进制转换可能成为主流解决方案\",{\"2\":{\"314\":1}}],[\"进制转换\",{\"2\":{\"181\":1,\"246\":1,\"292\":1}}],[\"进行列切割\",{\"2\":{\"2616\":1}}],[\"进行更精确的分块\",{\"2\":{\"2584\":1}}],[\"进行检索\",{\"2\":{\"2578\":1}}],[\"进行拆分\",{\"2\":{\"2549\":1}}],[\"进行一次allreduce\",{\"2\":{\"2616\":1}}],[\"进行一次\",{\"2\":{\"2308\":1}}],[\"进行奖励监督强化学习\",{\"2\":{\"2273\":1}}],[\"进行\",{\"2\":{\"2218\":2}}],[\"进行消融实验以评估各组件对系统性能的影响\",{\"2\":{\"2215\":1}}],[\"进行观察\",{\"2\":{\"2163\":1}}],[\"进行计算\",{\"2\":{\"2130\":1,\"2573\":1}}],[\"进行建模\",{\"0\":{\"2124\":1}}],[\"进行并行生成\",{\"2\":{\"2079\":1}}],[\"进行参数的重分片\",{\"2\":{\"2079\":1}}],[\"进行多级路由决策\",{\"2\":{\"1786\":1}}],[\"进行训练\",{\"2\":{\"1582\":1,\"2608\":1}}],[\"进行初步分割\",{\"2\":{\"2606\":1}}],[\"进行初步研究\",{\"2\":{\"133\":1}}],[\"进行初次分块\",{\"2\":{\"1561\":1}}],[\"进行量化的主要目标是确保经过微调的llm在量化为较低位宽后仍保持性能\",{\"2\":{\"1494\":1}}],[\"进行离散化处理并映射到对应的桶\",{\"2\":{\"1353\":1}}],[\"进行文本处理时\",{\"2\":{\"1321\":1}}],[\"进行了\",{\"2\":{\"1258\":1}}],[\"进行大规模强化学习训练\",{\"2\":{\"1245\":1}}],[\"进行大量的再训练以恢复准确性\",{\"2\":{\"931\":1}}],[\"进行预训练\",{\"2\":{\"1114\":1}}],[\"进行区分\",{\"2\":{\"917\":1}}],[\"进行剪枝\",{\"0\":{\"860\":1}}],[\"进行模仿\",{\"2\":{\"845\":1}}],[\"进行模型训练\",{\"2\":{\"408\":1}}],[\"进行以下操作\",{\"2\":{\"778\":1}}],[\"进行效果对比\",{\"2\":{\"663\":1}}],[\"进行去重\",{\"2\":{\"644\":1}}],[\"进行推理\",{\"2\":{\"536\":1,\"1184\":1,\"1843\":1,\"1991\":1}}],[\"进行缩放\",{\"2\":{\"221\":1}}],[\"进行扩展的方法\",{\"2\":{\"163\":1}}],[\"操作将每个节点上的数据在所有节点之间进行相加或其他类型的归约操作\",{\"2\":{\"2452\":1}}],[\"操作简单\",{\"2\":{\"2445\":1}}],[\"操作\",{\"0\":{\"2427\":1},\"1\":{\"2452\":1},\"2\":{\"2308\":2,\"2344\":1}}],[\"操作来计算梯度均值\",{\"2\":{\"2276\":1}}],[\"操作图\",{\"2\":{\"2262\":1}}],[\"操作系统\",{\"2\":{\"1217\":1}}],[\"操作步骤\",{\"0\":{\"133\":1,\"156\":1,\"359\":1,\"560\":1,\"637\":1,\"644\":1,\"651\":1,\"681\":1,\"695\":1,\"778\":1,\"800\":1,\"831\":1,\"844\":1,\"858\":1,\"1011\":1,\"1107\":1,\"1120\":1,\"1123\":1,\"1137\":1,\"1141\":1,\"1145\":1,\"1203\":1,\"1219\":1,\"1243\":1,\"1245\":1,\"1264\":1,\"1298\":1,\"1304\":1,\"1305\":1,\"1337\":1,\"1353\":1,\"1374\":1,\"1405\":1,\"1498\":1,\"1551\":1,\"1586\":1,\"1642\":1,\"1677\":1,\"1699\":1,\"1744\":1,\"1761\":1,\"1779\":1,\"1784\":1,\"1789\":1,\"1790\":1,\"1822\":1,\"1855\":1,\"1858\":1,\"1890\":1,\"1923\":1,\"1938\":1,\"1958\":1,\"1966\":1,\"1989\":1,\"2007\":1,\"2034\":1,\"2053\":1,\"2074\":1,\"2082\":1,\"2096\":1,\"2115\":1,\"2125\":1,\"2147\":1,\"2160\":1,\"2200\":1,\"2212\":1,\"2233\":1,\"2255\":1,\"2266\":1,\"2324\":1,\"2337\":1,\"2346\":1,\"2361\":1,\"2375\":1,\"2387\":1,\"2462\":1,\"2481\":1,\"2527\":1,\"2585\":1,\"2612\":1,\"2652\":1,\"2665\":1,\"2695\":1},\"1\":{\"1542\":1},\"2\":{\"276\":1,\"532\":1,\"647\":1,\"656\":1,\"1288\":1}}],[\"操作说明\",{\"2\":{\"40\":1}}],[\"为每段文本附加标题或关键词\",{\"2\":{\"2675\":1}}],[\"为每个类型准备一些种子提示\",{\"2\":{\"2168\":1}}],[\"为每个分段创建\",{\"2\":{\"1470\":1}}],[\"为用户提供了更精准的搜索体验\",{\"2\":{\"2672\":1}}],[\"为向量添加元数据标注是一种有效的策略\",{\"2\":{\"2669\":1}}],[\"为答案\",{\"2\":{\"2578\":1}}],[\"为此\",{\"2\":{\"2570\":1}}],[\"为大模型强化学习提供了新的思路\",{\"2\":{\"2495\":1,\"2509\":1}}],[\"为大规模长文本预训练提供了工程上的可行性\",{\"2\":{\"634\":1}}],[\"为我们提供了解决这些棘手问题的动力\",{\"2\":{\"2408\":1}}],[\"为解决世界上最复杂和要求苛刻的计算问题提供了强大的支持\",{\"2\":{\"2408\":1}}],[\"为解决这一问题\",{\"2\":{\"875\":1,\"1349\":1}}],[\"为研究人员提供了一个全面的框架\",{\"2\":{\"2317\":1}}],[\"为问题分配更多思考时间\",{\"2\":{\"2248\":1}}],[\"为后续回答生成奠定了基础\",{\"2\":{\"2272\":1}}],[\"为后续研究提供了方向\",{\"2\":{\"2182\":1}}],[\"为后续检索和生成提供了坚实基础\",{\"2\":{\"2155\":1}}],[\"为后续决策提供依据\",{\"2\":{\"1518\":1}}],[\"为奖励机制设计提供了新的思路\",{\"2\":{\"2058\":1}}],[\"为奖励值\",{\"2\":{\"1666\":1}}],[\"为参数优化提供了新的思路\",{\"2\":{\"2025\":1}}],[\"为一个任务创建多个模型\",{\"2\":{\"1930\":1}}],[\"为response\",{\"2\":{\"1787\":1}}],[\"为prompt\",{\"2\":{\"1787\":1}}],[\"为全面了解模型性能提供了依据\",{\"2\":{\"1759\":1}}],[\"为智能体定义了以下几项关键子能力\",{\"2\":{\"1759\":1}}],[\"为语言模型提供更好的奖励对齐方式\",{\"2\":{\"1754\":1}}],[\"为现有内容添加同义词或释义版本\",{\"2\":{\"1466\":1}}],[\"为模型提供更明确\",{\"2\":{\"2346\":1}}],[\"为模型提供更多信息\",{\"2\":{\"943\":1}}],[\"为模型训练提供了更稳定的优化路径\",{\"2\":{\"1799\":1}}],[\"为模型的公平评估奠定了基础\",{\"2\":{\"1430\":1}}],[\"为未来的模型训练提供了新的思路\",{\"2\":{\"1372\":1}}],[\"为agent执行提供了一个高效的沙盒环境\",{\"2\":{\"1361\":1}}],[\"为生成式模型提供了与外部世界互动的一个很有前景的解决方案\",{\"2\":{\"1333\":1}}],[\"为复杂查询场景提供了高效\",{\"2\":{\"1332\":1}}],[\"为优化人类偏好提供了新的视角\",{\"2\":{\"1223\":1}}],[\"为条件生成和无条件生成任务提供了新的可能性\",{\"2\":{\"961\":1}}],[\"为0的时候为对称量化\",{\"2\":{\"868\":1}}],[\"为数据偏移\",{\"2\":{\"868\":1}}],[\"为数据量化的间隔\",{\"2\":{\"868\":1}}],[\"为截断\",{\"2\":{\"868\":1}}],[\"为量化后的整数\",{\"2\":{\"868\":1}}],[\"为量化前的浮点数\",{\"2\":{\"868\":1}}],[\"为快速处理大规模数据提供了解决方案\",{\"2\":{\"867\":1}}],[\"为其分配逻辑块和物理块\",{\"2\":{\"812\":1}}],[\"为浅层梯度更新值乘以一个缩放系数\",{\"2\":{\"593\":1}}],[\"为下游任务提供更多灵活性\",{\"2\":{\"445\":1}}],[\"为防止梯度下溢\",{\"2\":{\"435\":1}}],[\"为\",{\"2\":{\"307\":3,\"1436\":1,\"2108\":1}}],[\"为扩展后的目标长度\",{\"2\":{\"222\":1}}],[\"为原训练支持的上下文长度\",{\"2\":{\"222\":1}}],[\"为满足256的整数倍需求\",{\"2\":{\"220\":1}}],[\"为了防止\",{\"2\":{\"2688\":1}}],[\"为了防止直接更新prefix参数导致训练不稳定和性能下降\",{\"2\":{\"1974\":1}}],[\"为了减少模型产生主观回答和幻觉\",{\"2\":{\"2690\":1}}],[\"为了减少计算复杂度\",{\"2\":{\"1266\":1}}],[\"为了减轻幻觉事实对模型检索能力的影响\",{\"2\":{\"2608\":1}}],[\"为了取得最佳效果\",{\"2\":{\"2543\":1}}],[\"为了更高效地搭建\",{\"2\":{\"2702\":1}}],[\"为了更细致地分析模型在不同场景下的表现\",{\"2\":{\"2477\":1}}],[\"为了更好地理解分块计算softmax\",{\"2\":{\"2130\":1}}],[\"为了构建大语言模型分布式强化学习框架\",{\"2\":{\"2433\":1}}],[\"为了计算它这\",{\"2\":{\"2308\":1}}],[\"为了收集全面的信息\",{\"2\":{\"2294\":1}}],[\"为了弥补这一不足\",{\"2\":{\"2269\":1}}],[\"为了应对多难度任务下的学习稳定性问题\",{\"2\":{\"2213\":1}}],[\"为了应对这一挑战\",{\"2\":{\"1753\":1}}],[\"为了应对这些挑战\",{\"2\":{\"763\":1}}],[\"为了优化检索速度\",{\"2\":{\"2102\":1}}],[\"为了高效地实现这些通信\",{\"2\":{\"2081\":1}}],[\"为了让大语言模型能够理解这些知识源\",{\"2\":{\"2052\":1}}],[\"为了实现这一点\",{\"2\":{\"2529\":1}}],[\"为了实现softmax分块计算\",{\"2\":{\"1980\":1}}],[\"为了实现多重索引技术\",{\"2\":{\"1285\":1}}],[\"为了结合稀疏和稠密搜索\",{\"2\":{\"1949\":1}}],[\"为了提升代理的规划效率和推理鲁棒性\",{\"2\":{\"1917\":1}}],[\"为了提升语料库的多样性和覆盖范围\",{\"2\":{\"1466\":1}}],[\"为了全面评估推理能力\",{\"2\":{\"1917\":1}}],[\"为了处理伪标记的相互依赖关系\",{\"2\":{\"1796\":1}}],[\"为了处理token溢出\",{\"2\":{\"1072\":1}}],[\"为了平衡训练效率\",{\"2\":{\"1740\":1}}],[\"为了解决这个问题\",{\"2\":{\"2517\":1}}],[\"为了解决这一问题\",{\"2\":{\"2514\":1,\"2546\":1}}],[\"为了解决这些问题\",{\"2\":{\"2011\":1}}],[\"为了解决没有明确定义奖励函数的强化学习问题\",{\"2\":{\"1687\":1}}],[\"为了解决上述问题\",{\"2\":{\"1548\":1}}],[\"为了解决数据接受侧可能出现的通信阻塞问题\",{\"2\":{\"1030\":1}}],[\"为了适配模型上下文长度\",{\"2\":{\"1513\":1}}],[\"为了适配swiglu带来的额外计算开销\",{\"2\":{\"220\":1}}],[\"为了克服上述缺点\",{\"2\":{\"1388\":1}}],[\"为了在不确定性较高的环境中确保决策安全性\",{\"2\":{\"2405\":1}}],[\"为了在不显著损失模型准确率的前提下减小模型大小并加快推理速度\",{\"2\":{\"1110\":1}}],[\"为了在这两者之间取得平衡\",{\"2\":{\"1308\":1}}],[\"为了确保模型能够高效\",{\"2\":{\"1185\":1}}],[\"为了确保安全共享\",{\"2\":{\"750\":1}}],[\"为了降低因数据集过大而导致的计算成本\",{\"2\":{\"1075\":1}}],[\"为了保证数据的准确性\",{\"2\":{\"1284\":1}}],[\"为了保证数值的稳定性\",{\"2\":{\"130\":1}}],[\"为了保证专家负载均衡\",{\"2\":{\"1072\":1}}],[\"为了避免语义上下文在块之间丢失\",{\"2\":{\"2560\":1}}],[\"为了避免数值溢出并保证数值稳定性\",{\"2\":{\"1925\":1}}],[\"为了避免歧义\",{\"2\":{\"1376\":1}}],[\"为了避免通信频率过高\",{\"2\":{\"1030\":1}}],[\"为了避免模型过于依赖某些特定数据源\",{\"2\":{\"456\":1}}],[\"为了完成基于智能阅读模型的毕业论文\",{\"2\":{\"578\":1}}],[\"为什么要处理多级标题\",{\"0\":{\"2196\":1}}],[\"为什么需要独热编码\",{\"0\":{\"1068\":1}}],[\"为什么需要位置编码\",{\"0\":{\"216\":1}}],[\"为什么选择\",{\"0\":{\"1006\":1}}],[\"为什么swiglu和gelu在大模型中表现更优\",{\"2\":{\"289\":1}}],[\"为什么用梯度优化参数\",{\"2\":{\"32\":1}}],[\"为什么是梯度\",{\"2\":{\"32\":1}}],[\"无packing时的梯度集中性\",{\"2\":{\"2310\":1}}],[\"无packing情况下\",{\"2\":{\"2278\":1,\"2310\":1}}],[\"无害性\",{\"2\":{\"2194\":1}}],[\"无人机群进行货物配送\",{\"2\":{\"1431\":1}}],[\"无论是cot还是tot\",{\"2\":{\"1420\":1}}],[\"无论是工作流还是自主智能体\",{\"2\":{\"1362\":1}}],[\"无截断处理\",{\"2\":{\"1359\":1}}],[\"无方向性\",{\"2\":{\"1343\":1}}],[\"无token丢弃设计\",{\"2\":{\"1038\":1}}],[\"无缝集成\",{\"2\":{\"719\":1}}],[\"无参数更新\",{\"0\":{\"569\":1}}],[\"无模型方法\",{\"2\":{\"540\":1}}],[\"无界性防止梯度饱和\",{\"2\":{\"330\":1}}],[\"无界性防止训练过程中梯度过早饱和\",{\"2\":{\"307\":1}}],[\"无需单独建模奖励函数\",{\"2\":{\"2148\":1}}],[\"无需更改代码\",{\"2\":{\"2055\":1}}],[\"无需训练的方法\",{\"2\":{\"1413\":1}}],[\"无需监督\",{\"2\":{\"1336\":1}}],[\"无需外部工具\",{\"2\":{\"1289\":1}}],[\"无需与其他智能体协作\",{\"2\":{\"1241\":1}}],[\"无需对输入进行额外预处理或分词\",{\"2\":{\"1096\":1}}],[\"无需重新训练\",{\"2\":{\"1050\":1}}],[\"无需重新计算\",{\"2\":{\"125\":1}}],[\"无需额外训练模型\",{\"2\":{\"1413\":1}}],[\"无需额外预处理\",{\"2\":{\"933\":1}}],[\"无需额外计算\",{\"2\":{\"276\":1}}],[\"无需预分词\",{\"2\":{\"373\":1,\"426\":1}}],[\"无需新增维度\",{\"2\":{\"246\":1}}],[\"无微调\",{\"2\":{\"245\":1}}],[\"无法完整传达主要观点或核心概念\",{\"2\":{\"2522\":1}}],[\"无法处理复杂排版\",{\"2\":{\"1834\":1}}],[\"无法深入了解模型在任务处理过程中的表现和能力\",{\"2\":{\"1453\":1}}],[\"无法并行\",{\"2\":{\"1941\":1}}],[\"无法并行处理\",{\"2\":{\"1373\":1}}],[\"无法并行化处理\",{\"2\":{\"351\":1}}],[\"无法区分前后关系\",{\"2\":{\"1343\":1}}],[\"无法执行复杂的问题求解任务\",{\"2\":{\"1238\":1}}],[\"无法体现词与词之间的相似关系是其主要缺点\",{\"2\":{\"1163\":1}}],[\"无法生成带概率的多种分词结果\",{\"2\":{\"529\":1}}],[\"无法准确描述真实上下文扩展尺度\",{\"2\":{\"244\":1}}],[\"无法更新参数\",{\"2\":{\"238\":1}}],[\"无法捕捉序列中词语的顺序信息\",{\"2\":{\"174\":1}}],[\"无额外开销\",{\"2\":{\"184\":1}}],[\"无形中增加了模型宽度\",{\"2\":{\"169\":1}}],[\"无监督学习方法\",{\"2\":{\"39\":1}}],[\"无监督学习的适用场景\",{\"2\":{\"39\":1}}],[\"无监督学习的特点是数据没有标注\",{\"2\":{\"39\":1}}],[\"无监督学习\",{\"2\":{\"37\":1,\"39\":1,\"935\":1}}],[\"缓解专家数量倍增带来的激活冲突\",{\"2\":{\"998\":1}}],[\"缓解深层网络中的梯度消失问题\",{\"2\":{\"121\":1}}],[\"缓存\",{\"2\":{\"917\":1}}],[\"缓存对于提高长序列生成的吞吐量至关重要\",{\"2\":{\"799\":1}}],[\"缓存需求\",{\"2\":{\"259\":1}}],[\"缓存占用内存可能过高\",{\"2\":{\"231\":1}}],[\"缓存溢出问题\",{\"2\":{\"231\":1}}],[\"缓存初始化\",{\"2\":{\"125\":1}}],[\"来生成\",{\"2\":{\"2578\":1}}],[\"来生成答案是优选方案\",{\"2\":{\"2210\":1}}],[\"来更新\",{\"2\":{\"2517\":1}}],[\"来避免梯度消失和提高训练稳定性的方法\",{\"2\":{\"2507\":1}}],[\"来避免策略遗忘预训练阶段学习到的知识\",{\"2\":{\"875\":1}}],[\"来衡量模型的表现\",{\"2\":{\"2458\":1}}],[\"来判断\",{\"2\":{\"2436\":1}}],[\"来判断类别\",{\"2\":{\"105\":1}}],[\"来指导策略更新\",{\"2\":{\"2430\":1}}],[\"来满足复杂需求\",{\"2\":{\"2323\":1}}],[\"来训练拥有\",{\"2\":{\"2313\":1}}],[\"来说\",{\"2\":{\"2308\":1,\"2616\":1}}],[\"来表示gpu的数量\",{\"2\":{\"2641\":1}}],[\"来表示切完后的某块矩阵\",{\"2\":{\"2286\":1}}],[\"来表示开始和结束\",{\"2\":{\"1193\":1}}],[\"来计算模型参数的显存消耗\",{\"2\":{\"2266\":1}}],[\"来大幅减少\",{\"2\":{\"2161\":1}}],[\"来执行\",{\"2\":{\"2089\":1}}],[\"来评估模型在某个方面的表现\",{\"2\":{\"2037\":1}}],[\"来评估自身进度\",{\"2\":{\"1454\":1}}],[\"来激励模型生成答案\",{\"2\":{\"1885\":1}}],[\"来模拟量化效果\",{\"2\":{\"1813\":1}}],[\"来优化模型表现\",{\"2\":{\"1752\":1}}],[\"来进行解耦\",{\"2\":{\"1980\":1}}],[\"来进行信息检索和生成\",{\"2\":{\"1611\":1}}],[\"来进行强化学习训练\",{\"2\":{\"1578\":1}}],[\"来量化风险的严重性\",{\"2\":{\"1407\":1}}],[\"来增强灵活性\",{\"2\":{\"1313\":1}}],[\"来实现\",{\"2\":{\"2433\":1}}],[\"来实现对语言模型的微调\",{\"2\":{\"1873\":1}}],[\"来实现这一目标\",{\"2\":{\"1110\":1}}],[\"来实现词嵌入\",{\"2\":{\"996\":1}}],[\"来提供更新幅度和方向\",{\"2\":{\"1942\":1,\"1993\":1}}],[\"来提升模型训练效率\",{\"2\":{\"1197\":1}}],[\"来提升计算效率的模型架构\",{\"2\":{\"415\":1}}],[\"来提高模型的泛化性和加速训练收敛\",{\"2\":{\"968\":1}}],[\"来帮助我们在模型训练中更高效地利用计算资源\",{\"2\":{\"751\":1}}],[\"来降低方差\",{\"2\":{\"654\":1}}],[\"来平衡生成内容的随机性与稳定性\",{\"2\":{\"249\":1}}],[\"来自稠密搜索\",{\"2\":{\"1949\":1}}],[\"来自arxiv\",{\"2\":{\"1138\":1}}],[\"来自algebraicstack\",{\"2\":{\"1138\":1}}],[\"来自deepseekmath语料库\",{\"2\":{\"1138\":1}}],[\"来自编码器输出序列\",{\"2\":{\"188\":1}}],[\"来自解码器输入序列\",{\"2\":{\"188\":1}}],[\"来源未提供\",{\"2\":{\"2111\":1,\"2182\":1}}],[\"来源c\",{\"2\":{\"1211\":1}}],[\"来源b\",{\"2\":{\"1211\":1}}],[\"来源a\",{\"2\":{\"1211\":1}}],[\"来源于\",{\"2\":{\"660\":1}}],[\"来源标注\",{\"0\":{\"358\":1,\"1276\":1,\"1369\":1,\"1386\":1,\"1462\":1,\"2061\":1,\"2368\":1},\"2\":{\"1008\":1}}],[\"来源\",{\"0\":{\"2202\":1},\"2\":{\"153\":1,\"219\":1,\"282\":1,\"327\":1,\"406\":1,\"432\":1,\"453\":1,\"469\":1,\"490\":1,\"563\":1,\"564\":1,\"616\":1,\"631\":1,\"632\":1,\"635\":1,\"647\":1,\"683\":1,\"709\":1,\"736\":1,\"738\":1,\"754\":1,\"770\":1,\"771\":1,\"797\":1,\"822\":1,\"824\":1,\"850\":1,\"892\":1,\"965\":1,\"966\":1,\"993\":1,\"1144\":1,\"1257\":1,\"1263\":1,\"1287\":1,\"1354\":1,\"1417\":1,\"1472\":1,\"1492\":1,\"1527\":1,\"1528\":1,\"1535\":1,\"1587\":1,\"1709\":1,\"1839\":1,\"1878\":1,\"1934\":1,\"1971\":1,\"2017\":1,\"2065\":1,\"2121\":1,\"2275\":1,\"2350\":1,\"2449\":1,\"2471\":1,\"2531\":1,\"2542\":1,\"2551\":1,\"2564\":1}}],[\"来不断调整\",{\"2\":{\"123\":1}}],[\"场景中\",{\"2\":{\"1819\":3}}],[\"场景\",{\"2\":{\"121\":1}}],[\"后向\",{\"2\":{\"2688\":2}}],[\"后面是激活函数gelu\",{\"2\":{\"2587\":1}}],[\"后面这一项被称为时序差分误差\",{\"2\":{\"608\":1}}],[\"后端采用\",{\"2\":{\"2079\":1,\"2129\":1}}],[\"后端\",{\"0\":{\"2079\":1,\"2129\":1}}],[\"后得到的\",{\"2\":{\"1870\":1}}],[\"后微调\",{\"0\":{\"1813\":1}}],[\"后期适应阶段\",{\"2\":{\"1436\":1}}],[\"后2层加入绝对位置信息\",{\"2\":{\"1288\":1}}],[\"后2层为decoder\",{\"2\":{\"1088\":1}}],[\"后两层引入绝对位置信息\",{\"2\":{\"1237\":1}}],[\"后续每个token的推理延迟≥模型参数量\",{\"2\":{\"2014\":1}}],[\"后续每个token的推理延迟≥gpu\",{\"2\":{\"2014\":1}}],[\"后续每个token的推理延迟\",{\"0\":{\"2014\":1},\"2\":{\"2014\":1}}],[\"后续研究计划包括探索如何在更复杂的环境中应用该方法\",{\"2\":{\"1811\":1}}],[\"后续策略可能会次优\",{\"2\":{\"1539\":1}}],[\"后续工作探索test\",{\"2\":{\"1013\":1}}],[\"后续的内容无法被访问\",{\"2\":{\"881\":1}}],[\"后续概率计算将失败\",{\"2\":{\"498\":1}}],[\"后续追踪方向\",{\"0\":{\"1800\":1}}],[\"后续追踪计划\",{\"0\":{\"282\":1,\"555\":1,\"704\":1}}],[\"后续追踪\",{\"0\":{\"265\":1,\"372\":1,\"385\":1,\"409\":1,\"414\":1,\"510\":1,\"667\":1,\"683\":1,\"707\":1,\"734\":1,\"737\":1,\"740\":1,\"765\":1,\"815\":1,\"818\":1,\"819\":1,\"822\":1,\"824\":1,\"841\":1,\"851\":1,\"864\":1,\"886\":1,\"892\":1,\"913\":1,\"951\":1,\"979\":1,\"982\":1,\"993\":1,\"1077\":1,\"1261\":1,\"1528\":1,\"1587\":1,\"1607\":1,\"1811\":1,\"1878\":1,\"1918\":1,\"1920\":1,\"2003\":1,\"2391\":1,\"2432\":1,\"2434\":1,\"2451\":1,\"2457\":1,\"2459\":1,\"2490\":1,\"2502\":1,\"2510\":1},\"2\":{\"647\":1}}],[\"后续追踪研究计划\",{\"0\":{\"240\":1,\"327\":1,\"334\":1,\"350\":1,\"1225\":1,\"1263\":1}}],[\"后生成新子词\",{\"2\":{\"355\":1}}],[\"后\",{\"2\":{\"121\":1,\"2580\":1}}],[\"后训练策略\",{\"2\":{\"1917\":1}}],[\"后训练阶段包括监督式微调\",{\"2\":{\"1267\":1}}],[\"后训练总结\",{\"0\":{\"1213\":1}}],[\"后训练数据合成\",{\"0\":{\"1181\":1}}],[\"后训练\",{\"0\":{\"131\":1},\"2\":{\"5\":10,\"2476\":1}}],[\"后训练|后训练\",{\"2\":{\"5\":1}}],[\"导致存储空间需求显著增加\",{\"2\":{\"2635\":1}}],[\"导致策略偏离高质量样本的关键推理模式\",{\"2\":{\"2619\":1,\"2668\":1}}],[\"导致策略偏离或不稳定\",{\"2\":{\"2106\":1}}],[\"导致无法查询到相关细节内容\",{\"2\":{\"2570\":1}}],[\"导致无法精准捕捉文本的核心主题和关键细节\",{\"2\":{\"2444\":1}}],[\"导致重要性权重为1\",{\"2\":{\"2561\":1}}],[\"导致样本效率较低\",{\"2\":{\"2545\":1}}],[\"导致检索模型难以准确匹配用户的查询意图\",{\"2\":{\"2465\":1}}],[\"导致信息无法充分流动\",{\"2\":{\"2438\":1}}],[\"导致低概率token生成受限\",{\"2\":{\"2414\":1}}],[\"导致低概率token几乎没有增长\",{\"2\":{\"2327\":1}}],[\"导致生成的回答缺乏连贯性或深度\",{\"2\":{\"2334\":1}}],[\"导致缓存与序列长度正相关\",{\"2\":{\"2326\":1}}],[\"导致资源需求增加\",{\"2\":{\"1954\":1}}],[\"导致智能体行为偏离期望\",{\"2\":{\"1743\":1}}],[\"导致reward方差小于sft\",{\"2\":{\"1650\":1}}],[\"导致难以将人类实际目标传达给智能体\",{\"2\":{\"1633\":1}}],[\"导致泛化问题\",{\"2\":{\"1505\":1}}],[\"导致的\",{\"2\":{\"1460\":1}}],[\"导致实现偏差\",{\"2\":{\"1335\":1}}],[\"导致过拟合和坍塌\",{\"2\":{\"1033\":1}}],[\"导致计算效率很低\",{\"2\":{\"2706\":1}}],[\"导致计算资源浪费\",{\"2\":{\"1452\":1}}],[\"导致计算资源和时间的消耗增加\",{\"2\":{\"985\":1}}],[\"导致计算结果偏差\",{\"2\":{\"192\":1}}],[\"导致训练资源浪费\",{\"2\":{\"2657\":1}}],[\"导致训练不稳定\",{\"2\":{\"777\":1}}],[\"导致训练效率低下\",{\"2\":{\"194\":1}}],[\"导致探索不足或过度探索\",{\"2\":{\"720\":1}}],[\"导致评估结果失真\",{\"2\":{\"718\":1}}],[\"导致后续策略优化出现偏差\",{\"2\":{\"684\":1}}],[\"导致局部最优而非全局最优\",{\"2\":{\"673\":1}}],[\"导致显存占用过高\",{\"2\":{\"657\":1}}],[\"导致显存需求高\",{\"2\":{\"149\":1}}],[\"导致小红书笔记爬取失败\",{\"2\":{\"594\":1}}],[\"导致小梯度可能被舍入为零\",{\"2\":{\"556\":1}}],[\"导致错误评估性能瓶颈\",{\"2\":{\"546\":1}}],[\"导致缺乏创造性生成\",{\"2\":{\"348\":1}}],[\"导致标记之间的向量方向更加趋同\",{\"2\":{\"312\":1}}],[\"导致模型跟框架无法解耦\",{\"2\":{\"2118\":1}}],[\"导致模型性能下降\",{\"2\":{\"1988\":1}}],[\"导致模型的通用能力下降\",{\"2\":{\"1346\":1}}],[\"导致模型无法处理训练集中未见过的长句子\",{\"2\":{\"309\":1}}],[\"导致模型参数量增加过多\",{\"2\":{\"243\":1}}],[\"导致不同位置的编码值重叠\",{\"2\":{\"309\":1}}],[\"导致嵌入在旋转域中分布不均匀\",{\"2\":{\"290\":1}}],[\"导致缩放因子不准确\",{\"2\":{\"276\":1}}],[\"导致深层网络难以优化\",{\"2\":{\"251\":1}}],[\"导致上下文信息丢失\",{\"2\":{\"251\":1,\"1457\":1}}],[\"导致微调效果不如传统pi方法\",{\"2\":{\"244\":1}}],[\"导致梯度计算不准确\",{\"2\":{\"243\":1}}],[\"导致神经元\",{\"2\":{\"238\":1}}],[\"导致post\",{\"2\":{\"211\":1}}],[\"导致集成失败\",{\"2\":{\"118\":1}}],[\"导航\",{\"0\":{\"16\":1,\"28\":1,\"30\":1,\"37\":1,\"45\":1,\"46\":1,\"60\":1}}],[\"忽视动态采样可能导致梯度消失问题\",{\"2\":{\"2530\":1}}],[\"忽视多样性可能导致模型过拟合\",{\"2\":{\"2403\":1}}],[\"忽视kl约束可能导致策略偏离预期结果\",{\"2\":{\"1851\":1}}],[\"忽视无监督目标函数可能导致模型泛化能力不足\",{\"2\":{\"1293\":1}}],[\"忽视优化器参数对收敛性的影响\",{\"2\":{\"1262\":1}}],[\"忽视折扣因子\",{\"2\":{\"879\":1}}],[\"忽视强化学习中\",{\"2\":{\"792\":1}}],[\"忽视单元内部质量\",{\"2\":{\"718\":1}}],[\"忽视\",{\"2\":{\"251\":1,\"1482\":1}}],[\"忽视任务需求\",{\"2\":{\"210\":1}}],[\"忽视不同服务间的认证差异\",{\"2\":{\"118\":1}}],[\"忽略dropout\",{\"2\":{\"1868\":1}}],[\"忽略\",{\"2\":{\"1592\":1}}],[\"忽略相对位置信息的截断范围\",{\"2\":{\"1452\":1}}],[\"忽略远距离位置的影响可能导致长文本理解能力下降\",{\"2\":{\"1399\":1}}],[\"忽略绝对位置信息在某些任务中的重要性\",{\"2\":{\"1335\":1}}],[\"忽略了数据类型对结果的影响\",{\"2\":{\"2299\":1}}],[\"忽略了对任务特定需求的分析\",{\"2\":{\"2086\":1}}],[\"忽略了预算对token数量和模型大小的限制\",{\"2\":{\"1329\":1}}],[\"忽略了动态环境下策略改变对数据分布的影响\",{\"2\":{\"792\":1}}],[\"忽略专家间的设备通信开销\",{\"2\":{\"1324\":1}}],[\"忽略语义信息\",{\"2\":{\"1113\":1}}],[\"忽略低频单词过滤\",{\"2\":{\"1109\":1}}],[\"忽略负样本质量\",{\"2\":{\"1066\":1}}],[\"忽略其实际应用价值\",{\"2\":{\"718\":1}}],[\"忽略采样方法组合\",{\"2\":{\"630\":1}}],[\"忽略loss\",{\"2\":{\"627\":1}}],[\"忽略layer\",{\"2\":{\"211\":1}}],[\"忽略请求间隔设置\",{\"2\":{\"594\":1}}],[\"忽略版权或数据合法性问题\",{\"2\":{\"582\":1}}],[\"忽略文本标准化步骤可能导致编码不一致\",{\"2\":{\"576\":1}}],[\"忽略ulm输出的多样性\",{\"2\":{\"472\":1}}],[\"忽略基础词表的重要性\",{\"2\":{\"461\":1}}],[\"忽略kv压缩可能导致性能下降\",{\"2\":{\"378\":1}}],[\"忽略激活函数选择对模型性能的影响\",{\"2\":{\"354\":1}}],[\"忽略外推能力\",{\"2\":{\"309\":1}}],[\"忽略上下文窗口扩展比例\",{\"2\":{\"276\":1}}],[\"忽略残差连接的重要性\",{\"2\":{\"251\":1}}],[\"忽略中间层维度调整\",{\"2\":{\"243\":1}}],[\"忽略masked\",{\"2\":{\"209\":1}}],[\"忽略不重要的部分\",{\"2\":{\"97\":1}}],[\"⚠使用rolling\",{\"2\":{\"2413\":1}}],[\"⚠检查数据格式和完整性\",{\"2\":{\"2324\":1}}],[\"⚠️\",{\"0\":{\"130\":1,\"156\":1,\"170\":1,\"183\":1,\"209\":1,\"241\":1,\"378\":1,\"472\":1,\"508\":1,\"594\":1,\"630\":1,\"985\":1,\"1066\":1,\"1109\":1,\"1262\":1},\"2\":{\"175\":2,\"210\":1,\"231\":2,\"251\":1,\"276\":1,\"281\":1,\"341\":1,\"354\":1,\"392\":1,\"419\":1,\"461\":3,\"546\":1,\"562\":2,\"576\":1,\"645\":1,\"689\":1,\"778\":1,\"789\":1,\"938\":1,\"1079\":1,\"1113\":1,\"1227\":1,\"1280\":1,\"1744\":1,\"1771\":1,\"1778\":1,\"2028\":1,\"2353\":1,\"2450\":1,\"2462\":1,\"2480\":1,\"2481\":1,\"2496\":1}}],[\"⚠\",{\"0\":{\"246\":1,\"507\":1,\"523\":1,\"556\":1,\"718\":1,\"879\":1,\"1394\":1,\"1482\":1,\"2098\":1},\"2\":{\"118\":1,\"133\":1,\"211\":1,\"223\":1,\"243\":1,\"287\":1,\"301\":1,\"309\":3,\"313\":2,\"335\":1,\"338\":2,\"348\":1,\"421\":1,\"435\":1,\"446\":1,\"474\":1,\"485\":1,\"494\":1,\"525\":1,\"527\":1,\"533\":1,\"553\":1,\"565\":1,\"567\":1,\"568\":1,\"582\":1,\"601\":1,\"637\":1,\"639\":1,\"647\":1,\"649\":1,\"651\":1,\"657\":1,\"681\":1,\"691\":1,\"695\":1,\"720\":1,\"746\":1,\"775\":4,\"792\":1,\"800\":1,\"831\":1,\"929\":1,\"967\":1,\"997\":1,\"1011\":1,\"1051\":1,\"1080\":1,\"1091\":1,\"1107\":1,\"1120\":1,\"1123\":1,\"1137\":1,\"1141\":1,\"1145\":1,\"1203\":1,\"1219\":1,\"1236\":1,\"1237\":1,\"1243\":1,\"1245\":1,\"1254\":1,\"1258\":1,\"1264\":1,\"1267\":1,\"1293\":1,\"1295\":1,\"1298\":1,\"1299\":1,\"1301\":1,\"1304\":1,\"1305\":1,\"1325\":1,\"1329\":1,\"1335\":1,\"1337\":1,\"1343\":1,\"1351\":1,\"1370\":1,\"1371\":1,\"1405\":1,\"1463\":2,\"1502\":1,\"1542\":1,\"1551\":1,\"1586\":1,\"1592\":2,\"1631\":1,\"1632\":1,\"1639\":1,\"1642\":1,\"1677\":1,\"1687\":1,\"1699\":1,\"1757\":1,\"1761\":1,\"1779\":1,\"1784\":1,\"1789\":1,\"1790\":1,\"1822\":1,\"1840\":1,\"1845\":1,\"1851\":1,\"1855\":1,\"1856\":1,\"1858\":1,\"1890\":1,\"1911\":1,\"1923\":1,\"1924\":3,\"1938\":1,\"1945\":1,\"1958\":1,\"1965\":1,\"1966\":1,\"1988\":1,\"1989\":1,\"2007\":1,\"2034\":1,\"2041\":1,\"2053\":1,\"2056\":1,\"2074\":1,\"2082\":1,\"2096\":1,\"2106\":1,\"2115\":1,\"2125\":1,\"2147\":1,\"2160\":1,\"2200\":1,\"2206\":1,\"2212\":1,\"2233\":1,\"2245\":1,\"2255\":2,\"2266\":1,\"2280\":1,\"2287\":1,\"2299\":1,\"2337\":1,\"2346\":1,\"2361\":1,\"2367\":1,\"2375\":1,\"2387\":1,\"2513\":1,\"2519\":1,\"2524\":1,\"2527\":1,\"2585\":1,\"2612\":1,\"2619\":1,\"2652\":1,\"2665\":1,\"2668\":1,\"2695\":1,\"2698\":1}}],[\"例如知识图谱构建和复杂问题解答\",{\"2\":{\"2635\":1}}],[\"例如问答系统和摘要生成\",{\"2\":{\"2599\":1}}],[\"例如relu\",{\"2\":{\"2526\":1}}],[\"例如激活函数层\",{\"2\":{\"2526\":1}}],[\"例如游戏ai\",{\"2\":{\"2418\":1}}],[\"例如移动\",{\"2\":{\"2418\":1}}],[\"例如通过在主机内存和设备内存之间进行参数交换\",{\"2\":{\"2313\":1}}],[\"例如翻译和\",{\"2\":{\"2245\":1}}],[\"例如社交网络中的\",{\"2\":{\"2234\":1}}],[\"例如估算显存为50gb\",{\"2\":{\"2170\":1}}],[\"例如反思行为\",{\"2\":{\"2122\":1}}],[\"例如一个返回的网页\",{\"2\":{\"2087\":1}}],[\"例如hbm\",{\"2\":{\"2077\":1}}],[\"例如hello被拆分为h\",{\"2\":{\"381\":1}}],[\"例如sram\",{\"2\":{\"2077\":1}}],[\"例如swiglu和geglu\",{\"2\":{\"138\":1}}],[\"例如texture\",{\"2\":{\"2077\":1}}],[\"例如top\",{\"2\":{\"481\":1}}],[\"例如骑自行车或在键盘上打字\",{\"2\":{\"2049\":1}}],[\"例如逐点运算的操作\",{\"2\":{\"2027\":1}}],[\"例如大矩阵乘法\",{\"2\":{\"2027\":1}}],[\"例如无法很好地处理关键字匹配问题\",{\"2\":{\"1949\":1}}],[\"例如算术推理\",{\"2\":{\"1708\":1}}],[\"例如前几位\",{\"2\":{\"1698\":1}}],[\"例如与actor共享部分参数或从reward\",{\"2\":{\"1591\":1}}],[\"例如新闻\",{\"2\":{\"1558\":1}}],[\"例如最大迭代次数\",{\"2\":{\"1545\":1}}],[\"例如具身智能\",{\"2\":{\"1453\":1}}],[\"例如标题\",{\"2\":{\"1379\":1}}],[\"例如显卡数量\",{\"2\":{\"1374\":1}}],[\"例如自动驾驶中的单车导航\",{\"2\":{\"1241\":1}}],[\"例如回答问题\",{\"2\":{\"1238\":1}}],[\"例如机器翻译时构造输入为\",{\"2\":{\"1154\":1}}],[\"例如输出分布和特征信息\",{\"2\":{\"1124\":1}}],[\"例如语法或语义\",{\"2\":{\"1121\":1}}],[\"例如三轮对话\",{\"2\":{\"1047\":1}}],[\"例如判断句子b是否为句子a的后续部分\",{\"2\":{\"956\":1}}],[\"例如因果解码\",{\"2\":{\"917\":1}}],[\"例如生成与理解任务\",{\"2\":{\"560\":1}}],[\"例如用transformer预测子词合并\",{\"2\":{\"555\":1}}],[\"例如同一输入可对应多种分词方式\",{\"2\":{\"529\":1}}],[\"例如脏数据或乱码\",{\"2\":{\"525\":1}}],[\"例如单词或子词\",{\"2\":{\"508\":1}}],[\"例如英文中包含26个字母及符号\",{\"2\":{\"392\":1}}],[\"例如结合深度学习的动态聚类方法\",{\"2\":{\"598\":1}}],[\"例如结合视觉和语言信息\",{\"2\":{\"350\":1}}],[\"例如结合图像和文本信息\",{\"2\":{\"232\":1}}],[\"例如时间序列预测\",{\"2\":{\"304\":1}}],[\"例如图像到文本生成\",{\"2\":{\"304\":1}}],[\"例如将2000以内的数除以2\",{\"2\":{\"246\":1}}],[\"例如块大小选择不当可能导致计算效率下降或信息丢失\",{\"2\":{\"175\":1}}],[\"例如\",{\"2\":{\"116\":1,\"156\":1,\"216\":1,\"220\":1,\"223\":1,\"246\":1,\"455\":1,\"495\":1,\"501\":1,\"507\":1,\"562\":1,\"653\":2,\"708\":2,\"729\":1,\"750\":1,\"765\":1,\"794\":1,\"847\":1,\"880\":1,\"954\":1,\"956\":1,\"985\":1,\"1118\":1,\"1238\":1,\"1268\":1,\"1282\":2,\"1284\":1,\"1285\":1,\"1332\":1,\"1338\":3,\"1343\":1,\"1375\":1,\"1376\":1,\"1377\":1,\"1420\":2,\"1427\":1,\"1454\":1,\"1513\":1,\"1544\":1,\"1567\":1,\"1598\":1,\"1664\":1,\"1774\":1,\"1813\":1,\"1819\":1,\"1847\":1,\"1885\":1,\"1910\":1,\"1937\":1,\"1949\":1,\"1987\":1,\"1991\":1,\"2001\":1,\"2002\":1,\"2052\":1,\"2064\":1,\"2091\":1,\"2139\":1,\"2185\":2,\"2218\":1,\"2235\":1,\"2253\":1,\"2270\":1,\"2304\":1,\"2354\":1,\"2427\":1,\"2436\":1,\"2443\":1,\"2452\":1,\"2455\":1,\"2493\":1,\"2584\":1,\"2606\":1,\"2613\":1,\"2640\":1,\"2655\":1,\"2672\":1,\"2675\":1,\"2687\":1,\"2690\":1,\"2702\":1}}],[\"块之间通过全局交互捕捉上下文关系\",{\"2\":{\"116\":1}}],[\"块间注意力确保模型仍能理解整体上下文关系\",{\"2\":{\"155\":1}}],[\"块间注意力\",{\"2\":{\"116\":1}}],[\"块内注意力显著减少计算复杂度\",{\"2\":{\"155\":1}}],[\"块内注意力\",{\"2\":{\"116\":1}}],[\"块\",{\"2\":{\"116\":1,\"2286\":3}}],[\"与这两者相比\",{\"2\":{\"2688\":1}}],[\"与外部世界互动\",{\"2\":{\"2443\":1}}],[\"与强化学习智能体的区别\",{\"0\":{\"2392\":1},\"1\":{\"2418\":1,\"2443\":1}}],[\"与agent的交互方式\",{\"0\":{\"2363\":1}}],[\"与大语言模型\",{\"2\":{\"2333\":1}}],[\"与数据并行一致\",{\"2\":{\"2308\":1}}],[\"与环境交互并执行动作\",{\"2\":{\"2277\":1}}],[\"与环境交互的核心作用\",{\"2\":{\"792\":1}}],[\"与上下文压缩相反\",{\"2\":{\"2197\":1}}],[\"与并行化操作相比\",{\"2\":{\"2139\":1}}],[\"与人类评级相关性提高\",{\"2\":{\"2076\":1}}],[\"与全量微调结果进行比较\",{\"2\":{\"2034\":1}}],[\"与触觉相关的记忆\",{\"2\":{\"1947\":1}}],[\"与听觉相关的记忆\",{\"2\":{\"1947\":1}}],[\"与视觉相关的记忆\",{\"2\":{\"1947\":1}}],[\"与prompt长度直接相关\",{\"2\":{\"1910\":1}}],[\"与其争论某个系统是否属于智能体\",{\"2\":{\"1617\":1}}],[\"与其讨论\",{\"0\":{\"1617\":1},\"1\":{\"1672\":1,\"1728\":1,\"1786\":1,\"1847\":1,\"1904\":1}}],[\"与其他逻辑分开\",{\"2\":{\"11\":1}}],[\"与智能体\",{\"2\":{\"1578\":1,\"2363\":1}}],[\"与embedding相同\",{\"2\":{\"1499\":1}}],[\"与单智能体不同\",{\"2\":{\"1485\":1}}],[\"与响应\",{\"2\":{\"1392\":1}}],[\"与传统数据并行类似\",{\"2\":{\"2308\":1}}],[\"与传统注意力机制不同\",{\"2\":{\"1846\":1}}],[\"与传统\",{\"2\":{\"1708\":1}}],[\"与传统方法不同\",{\"2\":{\"1636\":1}}],[\"与传统强化学习的对比\",{\"0\":{\"1634\":1}}],[\"与传统词向量技术进行任务优化\",{\"2\":{\"1261\":1}}],[\"与传统的transformer结构不同\",{\"2\":{\"1009\":1}}],[\"与独热编码的结合应用\",{\"2\":{\"1212\":1}}],[\"与前代模型一致\",{\"2\":{\"1156\":1}}],[\"与前两种方法不同\",{\"2\":{\"880\":1}}],[\"与优化\",{\"0\":{\"1152\":1},\"1\":{\"1201\":1}}],[\"与预训练\",{\"2\":{\"1150\":1}}],[\"与llm的交互方式\",{\"0\":{\"2333\":1}}],[\"与llm\",{\"2\":{\"1118\":1}}],[\"与元学习相关联\",{\"2\":{\"1082\":1}}],[\"与gpt\",{\"0\":{\"1278\":1},\"2\":{\"1082\":1}}],[\"与gpt类似\",{\"2\":{\"932\":1}}],[\"与输入一起输入模型\",{\"2\":{\"1075\":1}}],[\"与之前的llama2相比\",{\"2\":{\"1071\":1}}],[\"与之前的qwen版本相比\",{\"2\":{\"1041\":1}}],[\"与静态量化\",{\"2\":{\"1022\":1}}],[\"与社会价值对齐\",{\"2\":{\"1013\":1}}],[\"与bert相似\",{\"2\":{\"1062\":1}}],[\"与bert的区别\",{\"2\":{\"932\":1}}],[\"与bpe类似\",{\"2\":{\"355\":1}}],[\"与量化相比\",{\"2\":{\"729\":1}}],[\"与策略迭代不同\",{\"2\":{\"612\":1}}],[\"与总数据量14\",{\"2\":{\"455\":1}}],[\"与一个向量相乘\",{\"2\":{\"351\":1}}],[\"与进制转换来优化模型性能\",{\"2\":{\"337\":1}}],[\"与\",{\"0\":{\"1578\":1,\"1826\":1,\"1981\":1,\"2320\":1,\"2339\":1},\"1\":{\"1885\":1,\"1940\":1,\"2351\":1,\"2369\":1,\"2381\":1,\"2397\":1,\"2408\":1,\"2422\":1,\"2433\":1,\"2447\":1,\"2468\":1,\"2486\":1},\"2\":{\"205\":1,\"995\":1,\"1209\":1,\"1224\":1,\"1258\":1,\"1275\":1,\"2224\":1,\"2312\":1}}],[\"与各种远程服务\",{\"2\":{\"118\":1}}],[\"与key类似\",{\"2\":{\"112\":1}}],[\"✅限制每个token只与其前w个token进行注意力计算\",{\"2\":{\"2413\":1}}],[\"✅下载相关数据集\",{\"2\":{\"2324\":1}}],[\"✅\",{\"0\":{\"112\":1,\"126\":1,\"136\":1,\"149\":1,\"162\":1,\"188\":1,\"223\":1,\"284\":1,\"353\":1,\"465\":1,\"479\":1,\"480\":1,\"494\":1,\"644\":1,\"844\":1,\"938\":1,\"943\":1,\"980\":1,\"1021\":1,\"1161\":1,\"1302\":1,\"1436\":1},\"1\":{\"146\":1,\"167\":1},\"2\":{\"116\":3,\"118\":3,\"125\":1,\"133\":1,\"234\":3,\"245\":2,\"247\":3,\"276\":1,\"281\":1,\"287\":3,\"291\":4,\"293\":1,\"301\":1,\"303\":3,\"311\":3,\"324\":3,\"359\":4,\"380\":3,\"381\":5,\"392\":1,\"393\":4,\"421\":1,\"435\":4,\"442\":3,\"445\":1,\"446\":1,\"473\":1,\"474\":1,\"531\":3,\"533\":1,\"553\":2,\"560\":3,\"567\":1,\"568\":2,\"589\":3,\"593\":5,\"637\":1,\"639\":2,\"645\":1,\"647\":1,\"649\":1,\"651\":1,\"656\":1,\"669\":2,\"681\":1,\"695\":2,\"712\":1,\"775\":1,\"778\":1,\"789\":1,\"800\":1,\"831\":1,\"858\":3,\"929\":1,\"997\":1,\"1011\":2,\"1107\":1,\"1120\":1,\"1123\":1,\"1125\":2,\"1137\":1,\"1141\":1,\"1145\":2,\"1203\":1,\"1212\":3,\"1219\":2,\"1243\":1,\"1245\":2,\"1264\":1,\"1267\":1,\"1287\":2,\"1288\":1,\"1298\":1,\"1299\":1,\"1304\":1,\"1305\":1,\"1324\":1,\"1337\":1,\"1353\":3,\"1370\":1,\"1374\":3,\"1405\":1,\"1502\":2,\"1542\":2,\"1551\":1,\"1586\":1,\"1631\":2,\"1642\":1,\"1677\":1,\"1687\":1,\"1699\":1,\"1721\":2,\"1744\":1,\"1761\":1,\"1771\":1,\"1779\":1,\"1784\":2,\"1789\":1,\"1790\":1,\"1822\":1,\"1855\":1,\"1856\":2,\"1858\":1,\"1867\":2,\"1890\":1,\"1923\":1,\"1938\":1,\"1958\":1,\"1966\":1,\"1989\":1,\"2007\":1,\"2034\":2,\"2053\":2,\"2074\":1,\"2082\":1,\"2096\":1,\"2115\":2,\"2125\":1,\"2147\":1,\"2160\":1,\"2200\":1,\"2206\":1,\"2212\":1,\"2233\":1,\"2245\":2,\"2255\":2,\"2256\":1,\"2266\":1,\"2280\":1,\"2291\":1,\"2312\":1,\"2322\":1,\"2337\":1,\"2346\":1,\"2361\":1,\"2375\":1,\"2387\":1,\"2462\":1,\"2481\":1,\"2519\":1,\"2524\":1,\"2527\":1,\"2585\":1,\"2612\":1,\"2652\":1,\"2665\":1,\"2695\":1}}],[\"逐层寻找最优的量化权重\",{\"2\":{\"2085\":1}}],[\"逐层量化\",{\"0\":{\"939\":1}}],[\"逐\",{\"2\":{\"1941\":1}}],[\"逐组量化与逐通道量化等价\",{\"2\":{\"1022\":1}}],[\"逐组量化与逐层量化等价\",{\"2\":{\"1022\":1}}],[\"逐组量化\",{\"0\":{\"1022\":1}}],[\"逐通道量化\",{\"0\":{\"981\":1}}],[\"逐步剖析\",{\"2\":{\"1672\":1}}],[\"逐步扩大共用范围\",{\"2\":{\"1306\":1}}],[\"逐步探讨智能体的定义与发展\",{\"2\":{\"1136\":1}}],[\"逐步逼近最优策略\",{\"2\":{\"656\":1}}],[\"逐步进行采样以提升生成效果\",{\"2\":{\"468\":1}}],[\"逐步生成新的子词单元\",{\"2\":{\"366\":1}}],[\"逐步生成输出序列\",{\"2\":{\"34\":1}}],[\"逐渐暴露出在推理阶段显存需求过高的问题\",{\"2\":{\"111\":1}}],[\"现象\",{\"2\":{\"2466\":1,\"2484\":1}}],[\"现在网络上存在不同结构的多代理检索\",{\"2\":{\"2335\":1}}],[\"现在我们可以直接使用\",{\"2\":{\"10\":1}}],[\"现实中的知识源可能包括多种格式\",{\"2\":{\"2001\":1}}],[\"现实世界用户的反馈是优化知识库的重要依据\",{\"2\":{\"1510\":1}}],[\"现有的一些工作简单地将检索模块\",{\"2\":{\"2546\":1}}],[\"现有的评估框架往往缺乏对不同类型智能体任务的覆盖\",{\"2\":{\"1453\":1}}],[\"现有的系统浪费了60\",{\"2\":{\"750\":1}}],[\"现代深度学习模型中\",{\"2\":{\"111\":1}}],[\"残差分支\",{\"2\":{\"211\":1}}],[\"残差分支与恒等分支\",{\"2\":{\"211\":1}}],[\"残差块逐渐增强其作用\",{\"2\":{\"183\":1}}],[\"残差块影响较小\",{\"2\":{\"183\":1}}],[\"残差网络\",{\"2\":{\"110\":1}}],[\"残差连接是否适用于任何类型的深度学习模型\",{\"2\":{\"299\":1}}],[\"残差连接是深层网络训练成功的关键之一\",{\"2\":{\"183\":1}}],[\"残差连接\",{\"0\":{\"183\":1},\"2\":{\"104\":1,\"121\":2}}],[\"状态是问题\",{\"2\":{\"2306\":1}}],[\"状态为当前动作与之前token的序列\",{\"2\":{\"1848\":1}}],[\"状态机的核心特性在于\",{\"2\":{\"1847\":1}}],[\"状态机\",{\"0\":{\"1847\":1},\"2\":{\"1786\":1}}],[\"状态则由当前动作和之前所有token拼接而成\",{\"2\":{\"1673\":1}}],[\"状态更新\",{\"2\":{\"775\":1}}],[\"状态价值估计\",{\"2\":{\"747\":1,\"778\":1}}],[\"状态价值函数与动作价值函数的关系如下\",{\"2\":{\"810\":1}}],[\"状态价值函数和动作价值函数用于衡量策略的优劣\",{\"2\":{\"676\":1}}],[\"状态价值函数初始化\",{\"2\":{\"656\":1}}],[\"状态价值函数\",{\"0\":{\"748\":1},\"2\":{\"647\":1,\"732\":1,\"748\":1}}],[\"状态和动作\",{\"2\":{\"649\":1,\"1515\":1}}],[\"状态和动作都需明确定义\",{\"2\":{\"514\":1}}],[\"状态转移函数\",{\"2\":{\"676\":1}}],[\"状态转移\",{\"2\":{\"581\":1,\"1613\":1}}],[\"状态\",{\"2\":{\"581\":1,\"655\":6,\"1613\":1,\"2161\":1}}],[\"状态值\",{\"2\":{\"107\":1}}],[\"状态压缩\",{\"2\":{\"50\":1}}],[\"西瓜书\",{\"2\":{\"106\":1}}],[\"周志华\",{\"2\":{\"106\":1}}],[\"≥\",{\"2\":{\"105\":1}}],[\"设想一下\",{\"2\":{\"2688\":1}}],[\"设每个阶段的通信量为\",{\"2\":{\"2621\":1}}],[\"设为w\",{\"2\":{\"2386\":1}}],[\"设为27\",{\"2\":{\"1076\":1}}],[\"设备之间的点对点通信次数\",{\"2\":{\"2697\":1}}],[\"设备数量受到批量大小的限制\",{\"2\":{\"2402\":1}}],[\"设备数限制\",{\"2\":{\"2402\":1}}],[\"设备限制路由\",{\"2\":{\"1073\":1}}],[\"设备限制路由机制\",{\"2\":{\"1030\":1}}],[\"设备间通信并行加速\",{\"2\":{\"1038\":1}}],[\"设备故障检测\",{\"2\":{\"39\":1}}],[\"设置降维和升维矩阵\",{\"0\":{\"2425\":1}}],[\"设置低秩矩阵\",{\"2\":{\"2115\":1}}],[\"设置为\",{\"2\":{\"1937\":1,\"1987\":1}}],[\"设置virtual\",{\"2\":{\"1912\":1}}],[\"设置终止条件\",{\"0\":{\"1545\":1}}],[\"设置损失函数时\",{\"2\":{\"1298\":1}}],[\"设置expert\",{\"2\":{\"1119\":1,\"1219\":1}}],[\"设置gae参数以优化奖励估计\",{\"2\":{\"637\":1}}],[\"设置相对距离超过k或为k的倍数的注意力为0\",{\"2\":{\"168\":1}}],[\"设计文档结构和添加元数据等方法\",{\"2\":{\"2484\":1}}],[\"设计来满足大模型在不同专项能力上的需求\",{\"2\":{\"2119\":1}}],[\"设计中\",{\"2\":{\"1617\":1}}],[\"设计实验验证绝对位置编码在不同场景中的效果差异\",{\"2\":{\"1381\":1}}],[\"设计实验验证不同神经网络结构在强化学习中的表现\",{\"2\":{\"807\":1}}],[\"设计思想的直观性\",{\"0\":{\"1306\":1}}],[\"设计跨语种数据筛选方案\",{\"2\":{\"704\":1}}],[\"设计\",{\"2\":{\"560\":1}}],[\"设计出既高效又多样化的生成算法\",{\"2\":{\"453\":1}}],[\"设计更高效的混合模型\",{\"2\":{\"327\":1}}],[\"设计新的归一化方法\",{\"2\":{\"258\":1}}],[\"设定chunk\",{\"2\":{\"2386\":1}}],[\"设定值\",{\"2\":{\"1323\":1}}],[\"设定kl\",{\"2\":{\"1123\":1}}],[\"设定初始策略参数θ\",{\"2\":{\"695\":1}}],[\"设定强化学习的奖励函数和策略优化目标\",{\"2\":{\"649\":1}}],[\"设定扩展后的长度\",{\"2\":{\"291\":1}}],[\"设定阈值进行分类\",{\"0\":{\"105\":1}}],[\"也等于\",{\"2\":{\"2431\":1}}],[\"也是我们需要关注的细节\",{\"2\":{\"2379\":1}}],[\"也是用户体验的重要体现\",{\"2\":{\"2305\":1}}],[\"也为复杂问题的分解与优化提供了新的思路\",{\"2\":{\"2325\":1}}],[\"也没有太多抽象设计\",{\"2\":{\"2118\":1}}],[\"也会报显存不足的情况\",{\"2\":{\"2108\":1}}],[\"也会有中间过程的偏好标签\",{\"2\":{\"1905\":1}}],[\"也不过长引入多余噪声\",{\"2\":{\"2543\":1}}],[\"也不需要计算梯度\",{\"2\":{\"2079\":1}}],[\"也不应该要求用户提出的每一个问题都是高质量问题\",{\"2\":{\"1496\":1}}],[\"也能反过来帮助\",{\"2\":{\"1578\":1}}],[\"也能在未见过的数据上保持良好的性能\",{\"2\":{\"1505\":1}}],[\"也就是执行了多少次内循环\",{\"2\":{\"2643\":1}}],[\"也就是在\",{\"2\":{\"2228\":2}}],[\"也就是同一个\",{\"2\":{\"1559\":1}}],[\"也就无法具备这部分知识\",{\"2\":{\"1423\":1}}],[\"也可能需要解决更复杂的路由问题\",{\"2\":{\"1233\":1}}],[\"也可以略去不表达\",{\"2\":{\"2643\":1}}],[\"也可以把多个head放到一块gpu上\",{\"2\":{\"2636\":1}}],[\"也可以设置停止条件\",{\"2\":{\"1545\":1}}],[\"也可以按照模型最长输入长度填充\",{\"2\":{\"813\":1}}],[\"也可以减少反向传播时的开销\",{\"2\":{\"799\":1}}],[\"也可以是额外的数据集\",{\"2\":{\"715\":1}}],[\"也可以扩展到图像处理等领域\",{\"2\":{\"232\":1}}],[\"也叫标准kd\",{\"2\":{\"1124\":1}}],[\"也叫sigmoid函数\",{\"2\":{\"90\":1}}],[\"也增强了多语言处理能力\",{\"2\":{\"1117\":1}}],[\"也成为面试中的常见考点\",{\"2\":{\"99\":1}}],[\"内层循环\",{\"0\":{\"2573\":1}}],[\"内的拆分\",{\"2\":{\"2218\":1}}],[\"内的所有参数逐个量化\",{\"2\":{\"2085\":1}}],[\"内部反馈是evaluator给出的反馈\",{\"2\":{\"2205\":1}}],[\"内部反馈与外部反馈\",{\"0\":{\"2205\":1}}],[\"内部数据\",{\"2\":{\"535\":2}}],[\"内在维度与低秩\",{\"2\":{\"1853\":1}}],[\"内最长句子填充\",{\"2\":{\"813\":1}}],[\"内存越小\",{\"2\":{\"2077\":1}}],[\"内存带宽\",{\"2\":{\"1977\":1}}],[\"内存优化\",{\"2\":{\"1624\":1}}],[\"内存使用量\",{\"2\":{\"750\":1}}],[\"内存共享减少了55\",{\"2\":{\"750\":1}}],[\"内存占用\",{\"2\":{\"155\":1}}],[\"内存管理\",{\"2\":{\"21\":2}}],[\"内容分块是根据文档的具体内容进行分割\",{\"2\":{\"2584\":1}}],[\"内容分块\",{\"0\":{\"2584\":1},\"1\":{\"2592\":1,\"2599\":1}}],[\"内容基于选取文本进行总结与重构\",{\"2\":{\"2564\":1}}],[\"内容来源于grpo相关技术文档\",{\"2\":{\"2446\":1}}],[\"内容准确性和安全性\",{\"2\":{\"2194\":1}}],[\"内容总结\",{\"0\":{\"1972\":1},\"1\":{\"2023\":1,\"2073\":1}}],[\"内容更丰富\",{\"2\":{\"1514\":1}}],[\"内容类型等维度对文档进行分类\",{\"2\":{\"1421\":1}}],[\"内容详解\",{\"0\":{\"1182\":1},\"1\":{\"1231\":1,\"1281\":1,\"1328\":1}}],[\"内容经过处理和总结\",{\"2\":{\"1144\":1}}],[\"内容简介\",{\"0\":{\"898\":1}}],[\"内容处理\",{\"0\":{\"579\":1,\"696\":1,\"919\":1,\"947\":1,\"1029\":1,\"1116\":1,\"2138\":1,\"2296\":1},\"1\":{\"612\":1,\"647\":1,\"732\":1,\"767\":1,\"956\":1,\"989\":1,\"997\":1,\"1030\":1,\"1037\":1,\"1072\":1,\"1073\":1,\"1119\":1,\"1166\":1,\"1170\":1,\"1215\":1,\"1266\":1,\"1313\":1,\"1359\":1,\"1405\":1,\"1452\":1,\"1499\":1,\"2184\":1,\"2223\":1,\"2327\":1,\"2357\":1}}],[\"内容提取\",{\"0\":{\"485\":1},\"2\":{\"403\":1}}],[\"内容概要\",{\"0\":{\"163\":1,\"585\":1,\"1026\":1,\"1620\":1},\"1\":{\"184\":1,\"618\":1,\"653\":1,\"688\":1,\"724\":1}}],[\"内容概述\",{\"0\":{\"93\":1,\"109\":1,\"577\":1,\"638\":1,\"675\":1,\"875\":1,\"897\":1,\"901\":1,\"923\":1,\"926\":1,\"934\":1,\"960\":1,\"975\":1,\"1028\":1,\"1057\":1,\"1082\":1,\"1149\":1,\"1365\":1,\"1495\":1,\"1517\":1,\"1530\":1,\"1618\":1,\"1626\":1,\"1738\":1,\"1765\":1},\"1\":{\"672\":1,\"710\":1,\"744\":1,\"775\":1,\"806\":1,\"840\":1,\"932\":1,\"961\":1,\"970\":1,\"1004\":1,\"1045\":1,\"1102\":1,\"1152\":1,\"1201\":1,\"1252\":1,\"1825\":1,\"1884\":1}}],[\"内容摘要\",{\"0\":{\"128\":1,\"152\":1,\"968\":1,\"1660\":1,\"1679\":1,\"1887\":1,\"1943\":1}}],[\"σ−\",{\"2\":{\"1634\":2}}],[\"σ+\",{\"2\":{\"1634\":2}}],[\"σ2​≻σ1​\",{\"2\":{\"1536\":2}}],[\"σ2​\",{\"2\":{\"1536\":1}}],[\"σ2≻σ1\",{\"2\":{\"1536\":2}}],[\"σ2\",{\"2\":{\"1536\":4}}],[\"σ1​\",{\"2\":{\"1536\":1}}],[\"σ1​≻σ2​\",{\"2\":{\"1536\":3}}],[\"σ1≻σ2\",{\"2\":{\"1536\":3}}],[\"σ1\",{\"2\":{\"1536\":4}}],[\"σ²\",{\"2\":{\"190\":1}}],[\"σ\",{\"2\":{\"90\":2,\"164\":2,\"190\":2,\"199\":1,\"307\":2}}],[\"于是\",{\"2\":{\"90\":1}}],[\"软件开发\",{\"2\":{\"88\":1}}],[\"其计算效率得益于成本更低的点对点\",{\"2\":{\"2708\":1}}],[\"其显存需求为\",{\"2\":{\"2648\":2}}],[\"其显存分类如下\",{\"2\":{\"2161\":1}}],[\"其性能与qwq\",{\"2\":{\"2642\":1}}],[\"其具体表现为\",{\"2\":{\"2498\":1}}],[\"其具体步骤如下\",{\"2\":{\"2236\":1}}],[\"其持有一张\",{\"2\":{\"2433\":1}}],[\"其去中心化的构建思想体现在分布式共享内存\",{\"2\":{\"2408\":1}}],[\"其最大的优势在于无缝支持\",{\"2\":{\"2381\":1}}],[\"其与传统rag最大的区别在于通过检索评分和反思评分来提高质量\",{\"2\":{\"2365\":1}}],[\"其优缺点\",{\"2\":{\"2344\":1}}],[\"其优化效率将不断提升\",{\"2\":{\"912\":1}}],[\"其优化目标如下\",{\"2\":{\"590\":1}}],[\"其指定了对给定任务的图分解\",{\"2\":{\"2262\":1}}],[\"其原理是保存模型每个函数的输入元组\",{\"2\":{\"2252\":1}}],[\"其原理是基于pagedattention的\",{\"2\":{\"1808\":1}}],[\"其思想与\",{\"2\":{\"2195\":1}}],[\"其整体结构如下图所示\",{\"2\":{\"2188\":1}}],[\"其损失通常比其他任务更高\",{\"2\":{\"2163\":1}}],[\"其前向\",{\"2\":{\"2081\":1}}],[\"其存储空间有40gb\",{\"2\":{\"2077\":1}}],[\"其存储空间只有20mb\",{\"2\":{\"2077\":1}}],[\"其存储容量基本上是无限的\",{\"2\":{\"2049\":1}}],[\"其进阶奖励归一化策略进一步增强了模型在不同复杂任务中的稳定性和表现\",{\"2\":{\"2022\":1}}],[\"其在aime\",{\"2\":{\"1915\":1}}],[\"其在强化学习中的应用主要体现在策略迭代和价值迭代两种算法中\",{\"2\":{\"621\":1}}],[\"其智能体属性已接近真正意义上的自主智能体\",{\"2\":{\"1904\":1}}],[\"其对应的第一个相关结果排名如下\",{\"2\":{\"1756\":1}}],[\"其向量大小并不一定很相似\",{\"2\":{\"1663\":1}}],[\"其模型在输出多样性上更为自由\",{\"2\":{\"1650\":1}}],[\"其模型结构与\",{\"2\":{\"926\":1}}],[\"其\",{\"2\":{\"1612\":1}}],[\"其能力会受到限制\",{\"2\":{\"1611\":1}}],[\"其能力远超人类在复杂任务中的表现\",{\"2\":{\"1429\":1}}],[\"其全称为reason+act\",{\"2\":{\"1608\":1}}],[\"其全面性\",{\"2\":{\"1540\":1}}],[\"其背后依赖于复杂的算法和模型\",{\"2\":{\"1567\":1}}],[\"其效率优势将更加突出\",{\"2\":{\"1537\":1}}],[\"其输出本质上是一系列数值运算\",{\"2\":{\"1468\":1}}],[\"其特点是引入了更多功能模块\",{\"2\":{\"2523\":1}}],[\"其特点是\",{\"2\":{\"2077\":2}}],[\"其特点是通过在每一层的transformer中加入adapter模块进行微调\",{\"2\":{\"1668\":1}}],[\"其特点包括\",{\"2\":{\"1429\":1}}],[\"其特点在于\",{\"2\":{\"1289\":1}}],[\"其本质都是通过精心设计的prompt\",{\"2\":{\"1420\":1}}],[\"其主要原理是根据pdf页面中的文本对象的坐标和布局信息\",{\"2\":{\"1716\":1}}],[\"其主要创新是通过零初始化的注意力机制和门控机制来解决随机初始化可能损害预训练知识的问题\",{\"2\":{\"1668\":1}}],[\"其主要特点包括\",{\"2\":{\"1382\":1}}],[\"其主要作用类似于搜索引擎\",{\"2\":{\"1333\":1}}],[\"其格式包含以下几个部分\",{\"2\":{\"1368\":1}}],[\"其量化目标无缝地集成到模型的训练过程中\",{\"2\":{\"1355\":1}}],[\"其次\",{\"2\":{\"1321\":1}}],[\"其映射范围越宽\",{\"2\":{\"1258\":1}}],[\"其学习率根据参数矩阵的均方根进行缩放\",{\"2\":{\"1248\":1}}],[\"其设计和实现相对简单\",{\"2\":{\"1241\":1}}],[\"其设计理念与cbow\",{\"2\":{\"867\":1}}],[\"其8种实际场景可以归为三类\",{\"2\":{\"1217\":1}}],[\"其训练配置详细描述如下\",{\"2\":{\"1162\":1}}],[\"其训练范式结合了预训练与in\",{\"2\":{\"1082\":1}}],[\"其结构采用swiglu\",{\"2\":{\"1156\":1}}],[\"其结构确保每个\",{\"2\":{\"881\":1}}],[\"其预训练数据经过精细过滤\",{\"2\":{\"1061\":1}}],[\"其关键特点包括未绑定的嵌入方式\",{\"2\":{\"1060\":1}}],[\"其他元数据类型\",{\"0\":{\"2675\":1}}],[\"其他\",{\"2\":{\"2123\":1}}],[\"其他操作如计算softmax\",{\"2\":{\"2027\":1}}],[\"其他类似提示效果通常不如这一句\",{\"2\":{\"1885\":1}}],[\"其他智能体仍然可以继续完成任务\",{\"2\":{\"1384\":1}}],[\"其他优化\",{\"2\":{\"1198\":1}}],[\"其他词作为负样本\",{\"2\":{\"983\":1}}],[\"其他指导策略更新的方法\",{\"0\":{\"654\":1}}],[\"其过程主要包括两个步骤\",{\"2\":{\"954\":1}}],[\"其余10\",{\"2\":{\"1138\":1}}],[\"其余部分都移除了bias\",{\"2\":{\"894\":1}}],[\"其余位置为0\",{\"2\":{\"871\":1}}],[\"其余标记整体向下移一行\",{\"2\":{\"156\":1}}],[\"其实我们允许部分过长的文本在预训练前期\",{\"2\":{\"847\":1}}],[\"其更新公式为\",{\"2\":{\"710\":1}}],[\"其应用范围将进一步拓展\",{\"2\":{\"698\":1}}],[\"其应用范围广泛\",{\"2\":{\"675\":1}}],[\"其目标是让\",{\"2\":{\"1684\":1}}],[\"其目标是尽量保证每个分块的语义独立完整\",{\"2\":{\"1425\":1}}],[\"其目标是通过模拟多样化的工具集\",{\"2\":{\"1361\":1}}],[\"其目标是最大化当前策略在初始状态价值函数的期望\",{\"2\":{\"652\":1}}],[\"其目标是在子词粒度和词汇表大小之间找到平衡\",{\"2\":{\"366\":1}}],[\"其公式为\",{\"2\":{\"503\":1,\"1942\":1,\"1993\":1}}],[\"其公式如下\",{\"2\":{\"263\":1}}],[\"其核心评估指标包括\",{\"2\":{\"2558\":1}}],[\"其核心目标是近似以下公式\",{\"2\":{\"2430\":1}}],[\"其核心目标是通过以下公式最大化累计奖励\",{\"2\":{\"2124\":1}}],[\"其核心流程包括以下几个步骤\",{\"2\":{\"1619\":1}}],[\"其核心基础模块都是增强型\",{\"2\":{\"1362\":1}}],[\"其核心组件包括\",{\"2\":{\"1358\":1}}],[\"其核心特点包括\",{\"2\":{\"1336\":1}}],[\"其核心理念是将所有自然语言处理任务转化为文本到文本的形式\",{\"2\":{\"901\":1}}],[\"其核心公式为\",{\"2\":{\"757\":1}}],[\"其核心在于如何编写一个完备的prompt\",{\"2\":{\"1948\":1}}],[\"其核心在于对模型进行训练\",{\"2\":{\"1541\":1}}],[\"其核心在于使用gate来判断每个token应该发送到哪个expert\",{\"2\":{\"1072\":1}}],[\"其核心在于使用transformer的decoder结构\",{\"2\":{\"968\":1}}],[\"其核心在于\",{\"2\":{\"475\":1}}],[\"其核心思想简化为\",{\"2\":{\"2044\":1,\"2097\":1}}],[\"其核心思想与bpe\",{\"2\":{\"308\":1}}],[\"其核心思想是根据sft模型和policy模型的采样概率差异\",{\"2\":{\"1626\":1}}],[\"其核心思想是根据输入特征选择性地激活部分专家网络参与计算\",{\"2\":{\"415\":1}}],[\"其核心思想是通过\",{\"2\":{\"2154\":1}}],[\"其核心思想是通过对比学习的方式\",{\"2\":{\"1620\":1}}],[\"其核心思想是通过迭代不断调整簇中心的位置\",{\"2\":{\"1467\":1}}],[\"其核心思想是通过教师模型\",{\"2\":{\"749\":1}}],[\"其核心思想是按照预先设定的固定长度\",{\"2\":{\"1366\":1}}],[\"其核心思想是认为任何有监督任务都是语言模型的一部分\",{\"2\":{\"975\":1}}],[\"其核心思想是利用语言模型的概率分布来衡量子词的重要性\",{\"2\":{\"343\":1}}],[\"其核心思想是缓存attention机制中的key\",{\"2\":{\"107\":1}}],[\"其核心思想是让模型关注输入中的重要部分\",{\"2\":{\"97\":1}}],[\"其核心思想是将长文本拆分为多个小块\",{\"2\":{\"86\":1}}],[\"其概率分别为\",{\"2\":{\"444\":1}}],[\"其步骤如下\",{\"2\":{\"247\":1}}],[\"其局限性在哪里\",{\"2\":{\"217\":1}}],[\"其变体包括roberta\",{\"2\":{\"115\":1}}],[\"其中线性层涉及矩阵乘法和加法\",{\"2\":{\"2526\":1}}],[\"其中矩阵乘法涉及到权重矩阵和输入数据之间的乘法\",{\"2\":{\"2526\":1}}],[\"其中底层包含实际的数据点\",{\"2\":{\"2234\":1}}],[\"其中system\",{\"2\":{\"2117\":1}}],[\"其中ttt表示终止状态时间\",{\"2\":{\"1732\":1}}],[\"其中x\",{\"2\":{\"1666\":1}}],[\"其中b的学习率是a的6倍\",{\"2\":{\"1660\":1}}],[\"其中正负样本的数量都为一\",{\"2\":{\"1517\":1,\"1566\":1}}],[\"其中包括\",{\"2\":{\"1331\":1}}],[\"其中包含任务描述和一些示例\",{\"2\":{\"1175\":1}}],[\"其中包含状态集合\",{\"2\":{\"676\":1}}],[\"其中前11层仅用相对位置\",{\"2\":{\"1288\":1}}],[\"其中eee表示expert数量\",{\"2\":{\"1119\":1}}],[\"其中只有一个位置为1\",{\"2\":{\"871\":1}}],[\"其中a1和a2的block0和block1是共享的\",{\"2\":{\"812\":1}}],[\"其中ppo\",{\"2\":{\"521\":1}}],[\"其中\",{\"2\":{\"76\":1,\"130\":1,\"222\":1,\"223\":1,\"247\":1,\"263\":1,\"276\":1,\"293\":1,\"307\":3,\"355\":1,\"474\":1,\"513\":1,\"537\":1,\"590\":1,\"608\":1,\"611\":1,\"622\":1,\"773\":1,\"868\":1,\"981\":1,\"1153\":1,\"1207\":1,\"1224\":1,\"1246\":1,\"1552\":1,\"1582\":1,\"1622\":1,\"1644\":1,\"1671\":1,\"1676\":1,\"1830\":1,\"2013\":1,\"2033\":1,\"2124\":1,\"2137\":1,\"2145\":1,\"2161\":1,\"2217\":1,\"2322\":1,\"2528\":1,\"2621\":1,\"2641\":1,\"2643\":2}}],[\"发送请求\",{\"2\":{\"2408\":1}}],[\"发送+接收\",{\"2\":{\"2308\":2}}],[\"发送+接受\",{\"2\":{\"2276\":1}}],[\"发展历史\",{\"0\":{\"85\":1},\"1\":{\"99\":1,\"115\":1,\"133\":1,\"153\":1},\"2\":{\"172\":1}}],[\"发现不同的初始化策略会影响特征学习效率和训练稳定性\",{\"2\":{\"2311\":1}}],[\"发现问题时进行标记\",{\"2\":{\"2037\":1}}],[\"发现101种语言效果普遍提升\",{\"2\":{\"1083\":1}}],[\"发现潜在的生物学模式\",{\"2\":{\"39\":1}}],[\"发现潜在的网络攻击\",{\"2\":{\"39\":1}}],[\"发现与正常模式有显著不同的数据点\",{\"2\":{\"39\":1}}],[\"发现商品之间的关联\",{\"2\":{\"39\":1}}],[\"运算速度更快\",{\"2\":{\"462\":1}}],[\"运算符进行初始化\",{\"2\":{\"14\":1}}],[\"运维指南\",{\"2\":{\"79\":1}}],[\"zhihu\",{\"2\":{\"2275\":3}}],[\"zhou\",{\"2\":{\"1658\":1}}],[\"zhangyang\",{\"2\":{\"1658\":1}}],[\"zhuanlan\",{\"2\":{\"2275\":3}}],[\"zhu\",{\"2\":{\"1658\":1}}],[\"zzz\",{\"0\":{\"904\":1},\"1\":{\"939\":1,\"981\":1,\"1022\":1},\"2\":{\"868\":2,\"1022\":1}}],[\"zw\",{\"2\":{\"837\":1}}],[\"zip\",{\"2\":{\"324\":1,\"391\":1,\"1936\":1}}],[\"zero也存在以下问题\",{\"2\":{\"2315\":1}}],[\"zero1\",{\"0\":{\"2308\":1},\"2\":{\"2308\":1}}],[\"zero无需明确指导\",{\"2\":{\"2283\":1}}],[\"zero无需sft\",{\"2\":{\"934\":1}}],[\"zero2\",{\"2\":{\"2252\":1,\"2308\":1}}],[\"zero的使用\",{\"0\":{\"2346\":1}}],[\"zero的缺点与局限性\",{\"0\":{\"2315\":1}}],[\"zero的aha\",{\"0\":{\"2248\":1},\"1\":{\"2283\":1,\"2315\":1,\"2346\":1}}],[\"zero的显存分类\",{\"0\":{\"2161\":1}}],[\"zero通过自我进化展现了深度学习模型在复杂环境中自动提升性能的潜力\",{\"2\":{\"2211\":1}}],[\"zero3\",{\"0\":{\"2339\":1},\"1\":{\"2369\":1,\"2397\":1,\"2422\":1,\"2447\":1,\"2468\":1,\"2486\":1},\"2\":{\"2079\":3,\"2081\":1,\"2339\":1,\"2369\":1}}],[\"zero在训练过程中表现出自我进化能力\",{\"2\":{\"2070\":1}}],[\"zero在无需监督微调数据的情况下\",{\"2\":{\"1915\":1}}],[\"zero出现可读性低\",{\"2\":{\"1053\":1}}],[\"zero模型在优化过程中\",{\"2\":{\"2248\":1}}],[\"zero模型\",{\"2\":{\"934\":1}}],[\"zeros\",{\"2\":{\"324\":3,\"332\":1,\"646\":1,\"840\":1,\"1435\":1,\"1928\":1,\"2539\":2}}],[\"zero\",{\"0\":{\"1154\":1,\"1826\":1,\"1885\":1,\"2112\":1,\"2204\":1,\"2288\":2},\"1\":{\"1885\":1,\"1940\":1,\"2161\":1,\"2204\":1,\"2241\":2,\"2276\":2,\"2308\":2,\"2339\":2,\"2369\":2,\"2397\":2,\"2422\":2,\"2447\":2,\"2468\":2,\"2486\":2},\"2\":{\"294\":1,\"619\":2,\"640\":1,\"820\":1,\"935\":1,\"1170\":1,\"1826\":1,\"1885\":3,\"1955\":1,\"2055\":1,\"2081\":1,\"2161\":1,\"2201\":1,\"2233\":1,\"2241\":1,\"2252\":1,\"2288\":1,\"2338\":1,\"2642\":1}}],[\"zebra\",{\"2\":{\"18\":1}}],[\"z=0\",{\"2\":{\"164\":2}}],[\"z=w1​⋅x1​+w2​⋅x2​+⋯+wn​⋅xn​+b\",{\"2\":{\"76\":1}}],[\"z=w1⋅x1+w2⋅x2+⋯+wn⋅xn+bz\",{\"2\":{\"76\":1}}],[\"z\",{\"0\":{\"1769\":3},\"1\":{\"1830\":3},\"2\":{\"76\":1,\"90\":6,\"164\":4,\"185\":2,\"355\":2,\"868\":1,\"1830\":5,\"1889\":2,\"1922\":2,\"1944\":1,\"1994\":1,\"2046\":3,\"2148\":2}}],[\"第\",{\"2\":{\"1644\":1}}],[\"第五层级是组织者\",{\"2\":{\"1429\":1}}],[\"第五步\",{\"0\":{\"123\":1}}],[\"第四层级是创新者\",{\"2\":{\"1382\":1}}],[\"第四步\",{\"0\":{\"105\":1}}],[\"第三个查询的第一个相关结果排在第\",{\"2\":{\"1756\":1}}],[\"第三层级是智能体\",{\"2\":{\"1336\":1}}],[\"第三步\",{\"0\":{\"90\":1}}],[\"第1000个token需要读取130mb的数据\",{\"2\":{\"455\":1}}],[\"第几个词\",{\"2\":{\"216\":1}}],[\"第二层是维度从\",{\"2\":{\"2579\":1}}],[\"第二层级是推理型\",{\"2\":{\"1289\":1}}],[\"第二种形式\",{\"0\":{\"2166\":1}}],[\"第二阶段\",{\"2\":{\"1588\":1}}],[\"第二个提示接收第一个提示\",{\"2\":{\"1885\":1}}],[\"第二个查询的第一个相关结果排在第\",{\"2\":{\"1756\":1}}],[\"第二个结果匹配分数为\",{\"2\":{\"1644\":1}}],[\"第二个位置id表示span内部的相对位置\",{\"2\":{\"1045\":1}}],[\"第二个token生成\",{\"2\":{\"166\":1,\"187\":1}}],[\"第二步\",{\"0\":{\"76\":1}}],[\"第8个token的后一半表示移动到第2块的第1行\",{\"2\":{\"156\":1}}],[\"第一层是维度从\",{\"2\":{\"2579\":1}}],[\"第一层级是对话型人工智能\",{\"2\":{\"1238\":1}}],[\"第一种形式\",{\"0\":{\"2117\":1}}],[\"第一阶段\",{\"2\":{\"1588\":1}}],[\"第一次迭代\",{\"0\":{\"497\":1}}],[\"第一个提示生成一个思维链\",{\"2\":{\"1885\":1}}],[\"第一个查询的第一个相关结果排在第\",{\"2\":{\"1756\":1}}],[\"第一个结果匹配分数为\",{\"2\":{\"1644\":1}}],[\"第一个位置id标记part\",{\"2\":{\"1045\":1}}],[\"第一个token生成\",{\"2\":{\"166\":1,\"187\":1}}],[\"第一个块的部分标记按组大小的一半移位\",{\"2\":{\"156\":1}}],[\"第一步需要使用专门的文档加载器或多模态模型将其转换为纯文本数据\",{\"2\":{\"2052\":1}}],[\"第一步\",{\"0\":{\"66\":1}}],[\"第六步\",{\"0\":{\"143\":1}}],[\"论文中提过\",{\"2\":{\"2653\":1}}],[\"论文instructgpt\",{\"2\":{\"1369\":1}}],[\"论文原文\",{\"2\":{\"432\":1}}],[\"论文写作与学术规范\",{\"0\":{\"401\":1},\"1\":{\"428\":1,\"454\":1},\"2\":{\"578\":1}}],[\"论文链接\",{\"2\":{\"353\":1,\"358\":1}}],[\"论文\",{\"2\":{\"101\":1,\"153\":1,\"230\":1,\"300\":1,\"490\":1,\"1239\":1,\"1364\":1,\"1455\":1,\"2140\":1,\"2174\":1,\"2275\":1}}],[\"论文结构\",{\"2\":{\"72\":1}}],[\"论文撰写\",{\"0\":{\"72\":1},\"2\":{\"4\":1}}],[\"书籍\",{\"2\":{\"67\":1,\"106\":1,\"165\":1,\"302\":1,\"454\":1,\"568\":1,\"929\":1}}],[\"血糖等特征\",{\"2\":{\"66\":1}}],[\"血压等特征\",{\"2\":{\"143\":1}}],[\"血压等\",{\"2\":{\"76\":1}}],[\"血压\",{\"2\":{\"66\":1}}],[\"假设网络共有16层\",{\"2\":{\"2697\":1}}],[\"假设模型有8层\",{\"2\":{\"2688\":1}}],[\"假设模型有三层\",{\"2\":{\"2526\":1}}],[\"假设模型参数量为\",{\"2\":{\"2161\":1}}],[\"假设有\",{\"2\":{\"2374\":1}}],[\"假设有一个提议分布q\",{\"2\":{\"623\":1}}],[\"假设一个对话中有3轮user和bot的交互\",{\"2\":{\"2322\":1}}],[\"假设\",{\"2\":{\"1868\":1,\"2431\":1}}],[\"假设batchsize=1\",{\"2\":{\"1782\":1}}],[\"假设prompt的长度为\",{\"2\":{\"1782\":1}}],[\"假设文档嵌入\",{\"0\":{\"1717\":1}}],[\"假设人类偏好一个片段的概率与潜在奖励在该片段长度上的总和呈指数关系\",{\"2\":{\"1536\":1}}],[\"假设最大序列长度为\",{\"2\":{\"1281\":1}}],[\"假设是7b大小的llm\",{\"2\":{\"455\":1}}],[\"假设前三种分词方式在初始词表中\",{\"2\":{\"444\":1}}],[\"假设合并子词\",{\"2\":{\"355\":1}}],[\"假设k\",{\"2\":{\"208\":1}}],[\"假设目标输出为\",{\"2\":{\"166\":1}}],[\"假设我们正在开发一款允许用户查询电子邮件历史记录的应用程序\",{\"2\":{\"2672\":1}}],[\"假设我们有一个已验证事实的数据库\",{\"2\":{\"2436\":1}}],[\"假设我们有一组数据\",{\"2\":{\"66\":1}}],[\"假设我们有\",{\"2\":{\"1756\":1}}],[\"假设我们用逻辑回归预测一个人是否会购买某款产品\",{\"2\":{\"164\":1}}],[\"假设你有多个库\",{\"2\":{\"10\":1}}],[\"环境需求\",{\"2\":{\"1302\":1}}],[\"环境会反馈奖励或惩罚信号\",{\"2\":{\"690\":1}}],[\"环境发生变化并反馈即时奖励及新状态\",{\"2\":{\"639\":1}}],[\"环境反馈\",{\"2\":{\"639\":1}}],[\"环境动态未知\",{\"2\":{\"688\":1}}],[\"环境动态已知或通过学习得到环境模型\",{\"2\":{\"688\":1}}],[\"环境动态的需求以及策略学习的方法\",{\"2\":{\"585\":1}}],[\"环境动态\",{\"2\":{\"550\":1}}],[\"环境配置\",{\"2\":{\"69\":1}}],[\"环境\",{\"2\":{\"65\":1,\"514\":1,\"649\":1,\"1515\":1}}],[\"免费gpu环境\",{\"2\":{\"544\":1}}],[\"免费\",{\"2\":{\"65\":1}}],[\"五级分类中对于\",{\"0\":{\"1188\":1},\"1\":{\"1238\":1,\"1289\":1,\"1336\":1,\"1382\":1,\"1429\":1}}],[\"五级分类的角度\",{\"2\":{\"1136\":1}}],[\"五\",{\"0\":{\"65\":1}}],[\"开放模型与专有模型\",{\"2\":{\"2699\":1}}],[\"开放网页数据平台\",{\"2\":{\"535\":1}}],[\"开箱即用\",{\"2\":{\"2055\":1}}],[\"开始训练\",{\"2\":{\"1646\":1}}],[\"开始一个新的片段\",{\"2\":{\"1470\":1}}],[\"开始计算状态s下的所有q\",{\"2\":{\"647\":1}}],[\"开展对比实验\",{\"2\":{\"555\":1}}],[\"开展实验分析\",{\"2\":{\"282\":1}}],[\"开头或以\",{\"2\":{\"548\":1}}],[\"开源rag评估框架\",{\"0\":{\"2550\":1},\"1\":{\"2558\":1,\"2566\":1,\"2574\":1,\"2582\":1,\"2590\":1}}],[\"开源推理引擎\",{\"2\":{\"2129\":1}}],[\"开源工具如\",{\"2\":{\"2081\":1}}],[\"开源\",{\"2\":{\"1347\":2}}],[\"开源模型\",{\"2\":{\"922\":1}}],[\"开源项目\",{\"2\":{\"544\":1}}],[\"开源数据集将更加细分化\",{\"2\":{\"2437\":1}}],[\"开源数据集的多样性为ai研究提供了丰富的素材\",{\"2\":{\"2385\":1}}],[\"开源数据集在促进ai研究方面有哪些挑战\",{\"2\":{\"2258\":1}}],[\"开源数据集\",{\"0\":{\"2036\":1},\"1\":{\"2088\":1,\"2138\":1,\"2184\":1,\"2223\":1,\"2258\":1,\"2293\":1,\"2324\":1,\"2355\":1,\"2385\":1,\"2412\":1,\"2437\":1,\"2459\":1},\"2\":{\"131\":1,\"2088\":1}}],[\"开源数据集|开源数据集\",{\"2\":{\"5\":1}}],[\"开发框架\",{\"2\":{\"2702\":1}}],[\"开发新的推理范式以进一步提升模型能力\",{\"2\":{\"2461\":1}}],[\"开发新型概率探针以细化知识监控\",{\"2\":{\"982\":1}}],[\"开发者可以通过调整块大小和重叠长度\",{\"2\":{\"1763\":1}}],[\"开发者将大语言模型\",{\"2\":{\"1578\":1}}],[\"开发者们实现了以下功能\",{\"2\":{\"1439\":1}}],[\"开发原创方案\",{\"2\":{\"1382\":1}}],[\"开发适用于高维稀疏数据的高效解决方案\",{\"2\":{\"1263\":1}}],[\"开发实时策略调整算法以应对动态环境\",{\"2\":{\"1077\":1}}],[\"开发实时监控工具以追踪模型知识更新\",{\"2\":{\"905\":1}}],[\"开发agenttuning框架\",{\"2\":{\"1008\":1}}],[\"开发通用型打分器以适配多类型数据集\",{\"2\":{\"851\":1}}],[\"开发中文领域分类器并评估其准确率\",{\"2\":{\"704\":1}}],[\"开发自动化工具\",{\"2\":{\"667\":1}}],[\"开发自动化工具整合关键词挖掘与人工筛选流程\",{\"2\":{\"666\":1}}],[\"开发自动化流程\",{\"2\":{\"530\":1}}],[\"开发可视化工具展示嵌入分布与波长关系\",{\"2\":{\"439\":1}}],[\"开发更精确的llm\",{\"2\":{\"2174\":1}}],[\"开发更精细化的插值方法\",{\"2\":{\"412\":1}}],[\"开发更有效的奖励函数以提高模型性能\",{\"2\":{\"1952\":1}}],[\"开发更有效的奖励函数模型对齐技术\",{\"2\":{\"1814\":1}}],[\"开发更高效的数据质量过滤算法\",{\"2\":{\"2490\":1}}],[\"开发更高效的数据过滤技术以提升数据质量\",{\"2\":{\"1406\":1}}],[\"开发更高效的用户反馈机制\",{\"2\":{\"1920\":1}}],[\"开发更高效的dca实现\",{\"2\":{\"240\":1}}],[\"开发更灵活的注意力掩码微调方法以提升鲁棒性\",{\"2\":{\"385\":1}}],[\"开发一种工具\",{\"2\":{\"361\":1}}],[\"开发动态调整注意力区域的算法\",{\"2\":{\"327\":1}}],[\"开发规范\",{\"2\":{\"69\":1}}],[\"开发文档\",{\"0\":{\"69\":1}}],[\"开发环境\",{\"2\":{\"62\":1}}],[\"技术融合\",{\"2\":{\"2523\":1}}],[\"技术通过生成可解释的推理链来提升复杂推理任务的性能\",{\"2\":{\"2514\":1}}],[\"技术以及\",{\"2\":{\"2339\":1}}],[\"技术改进\",{\"2\":{\"2261\":1}}],[\"技术改进项\",{\"2\":{\"2143\":1}}],[\"技术能够识别并转换其中的文字信息\",{\"2\":{\"2052\":1}}],[\"技术发展日新月异\",{\"2\":{\"1617\":1}}],[\"技术发展动态\",{\"2\":{\"738\":1}}],[\"技术的总结与分析\",{\"2\":{\"2017\":1}}],[\"技术的一个重要里程碑\",{\"2\":{\"1530\":1}}],[\"技术的系统时\",{\"2\":{\"1185\":1}}],[\"技术报告\",{\"2\":{\"1658\":1,\"2187\":1}}],[\"技术报告分析\",{\"2\":{\"1441\":1}}],[\"技术报告中\",{\"2\":{\"1065\":1}}],[\"技术报告中提供的\",{\"0\":{\"1065\":1}}],[\"技术进行并行训练的方法\",{\"2\":{\"1365\":1}}],[\"技术对比表格\",{\"0\":{\"1023\":1}}],[\"技术创新\",{\"2\":{\"859\":1}}],[\"技术将成为主流\",{\"2\":{\"730\":1}}],[\"技术术语通俗转述\",{\"0\":{\"1794\":1}}],[\"技术术语通俗解读\",{\"0\":{\"499\":1}}],[\"技术术语通俗解释\",{\"0\":{\"211\":1,\"1249\":1,\"1531\":1,\"1589\":1,\"1793\":1,\"1983\":1,\"2024\":1,\"2110\":1}}],[\"技术术语转换\",{\"2\":{\"1722\":1}}],[\"技术术语转述\",{\"0\":{\"643\":1,\"1170\":1,\"1645\":1,\"2004\":1,\"2032\":1,\"2357\":1,\"2516\":1}}],[\"技术术语简化\",{\"0\":{\"970\":1,\"1939\":1}}],[\"技术术语解释\",{\"0\":{\"583\":1,\"1866\":1,\"2169\":1,\"2647\":1},\"2\":{\"647\":1}}],[\"技术\",{\"2\":{\"502\":1,\"1490\":1,\"1708\":1}}],[\"技术名称\",{\"2\":{\"305\":1,\"1023\":1}}],[\"技术实现步骤\",{\"0\":{\"287\":1}}],[\"技术实现示例\",{\"0\":{\"208\":1}}],[\"技术细节与优化点\",{\"0\":{\"903\":1},\"1\":{\"938\":1,\"980\":1,\"1021\":1}}],[\"技术细节\",{\"0\":{\"206\":1,\"2252\":1},\"1\":{\"228\":1,\"252\":1,\"276\":1}}],[\"技术细节示例\",{\"2\":{\"40\":1}}],[\"技术趋势与优化点\",{\"0\":{\"150\":1}}],[\"技术解析\",{\"0\":{\"117\":1},\"1\":{\"136\":1,\"156\":1}}],[\"技术栈\",{\"2\":{\"60\":1}}],[\"语音等信息\",{\"2\":{\"2443\":1}}],[\"语音识别\",{\"2\":{\"39\":1,\"327\":1}}],[\"语言一致性\",{\"2\":{\"2404\":1}}],[\"语言混合问题\",{\"2\":{\"1295\":1,\"2315\":1}}],[\"语言混合的问题\",{\"2\":{\"1053\":1}}],[\"语言等\",{\"2\":{\"882\":1}}],[\"语言分布\",{\"2\":{\"803\":1}}],[\"语言前缀\",{\"2\":{\"631\":1}}],[\"语言识别\",{\"0\":{\"515\":1}}],[\"语言识别及低质内容过滤\",{\"2\":{\"403\":1}}],[\"语言模型展现出能够准确执行以前未见过的指令描述任务的能力\",{\"2\":{\"1275\":1}}],[\"语言模型优化\",{\"2\":{\"1103\":1}}],[\"语言模型\",{\"0\":{\"1637\":1},\"2\":{\"59\":1,\"160\":1,\"226\":1,\"377\":1,\"499\":1,\"908\":1,\"922\":1,\"930\":1,\"935\":1,\"1694\":1,\"2116\":1}}],[\"语种及数据来源的多样性\",{\"2\":{\"369\":1}}],[\"语义模糊\",{\"0\":{\"2444\":1}}],[\"语义独立性\",{\"2\":{\"2364\":1}}],[\"语义记忆\",{\"2\":{\"2049\":1}}],[\"语义完整性受损\",{\"0\":{\"1503\":1}}],[\"语义切分\",{\"2\":{\"1470\":1}}],[\"语义上更加连贯\",{\"2\":{\"1424\":1}}],[\"语义重复数据删除技术及预测数据质量的文本分类器\",{\"2\":{\"1167\":1}}],[\"语义最近的10个训练样本\",{\"2\":{\"910\":1}}],[\"语义\",{\"2\":{\"369\":1}}],[\"语义差别巨大\",{\"2\":{\"216\":1}}],[\"词汇的多重语义\",{\"2\":{\"2394\":1}}],[\"词汇表\",{\"2\":{\"933\":1,\"1025\":1,\"1096\":1}}],[\"词汇表生成效率\",{\"2\":{\"417\":1}}],[\"词汇表大小为102400\",{\"2\":{\"1002\":1}}],[\"词汇表大小\",{\"2\":{\"365\":1,\"1341\":1}}],[\"词汇表更紧凑\",{\"2\":{\"318\":1}}],[\"词粒度更适合语义表达\",{\"2\":{\"1259\":1}}],[\"词粒度n\",{\"2\":{\"1021\":1}}],[\"词表的大小较大\",{\"2\":{\"2651\":1}}],[\"词表中敏感或脏token未移除\",{\"2\":{\"1394\":1}}],[\"词表扩充时需确保覆盖足够的中英词汇\",{\"2\":{\"1632\":1}}],[\"词表扩充实例对比\",{\"0\":{\"1442\":1},\"1\":{\"1487\":1}}],[\"词表扩充\",{\"2\":{\"1302\":1,\"1531\":1}}],[\"词表扩展\",{\"2\":{\"1071\":1}}],[\"词表外\",{\"2\":{\"1125\":1}}],[\"词表外词汇问题\",{\"2\":{\"1079\":1}}],[\"词表与编码器\",{\"2\":{\"1041\":1}}],[\"词表大小为32k\",{\"2\":{\"1112\":1}}],[\"词表大小为151643\",{\"2\":{\"1041\":1,\"1156\":1}}],[\"词表大小从32k扩展到128k\",{\"2\":{\"1071\":1}}],[\"词表大小调整\",{\"0\":{\"1007\":1}}],[\"词表大小\",{\"2\":{\"996\":1,\"1292\":1,\"1483\":1}}],[\"词表构建策略\",{\"2\":{\"445\":1}}],[\"词向量的维度\",{\"2\":{\"996\":1}}],[\"词向量\",{\"2\":{\"835\":1,\"848\":1}}],[\"词频\",{\"2\":{\"443\":1}}],[\"词与词之间的距离\",{\"2\":{\"216\":1}}],[\"词袋模型\",{\"2\":{\"59\":1}}],[\"词性标注等\",{\"2\":{\"59\":1}}],[\"词嵌入技术\",{\"2\":{\"144\":1}}],[\"词嵌入|词嵌入\",{\"2\":{\"5\":1}}],[\"词嵌入\",{\"0\":{\"55\":1},\"2\":{\"5\":5,\"59\":1,\"882\":1}}],[\"绿色\",{\"2\":{\"57\":1}}],[\"需根据具体任务调整\",{\"2\":{\"2698\":1}}],[\"需通过基线值调整来解决\",{\"2\":{\"2480\":1,\"2496\":1}}],[\"需精心设计prompt以减少偏差\",{\"2\":{\"2194\":1}}],[\"需进行mdp建模\",{\"2\":{\"1613\":1}}],[\"需进一步提取有效文本信息\",{\"2\":{\"485\":1}}],[\"需确保kl散度的无偏估计准确\",{\"2\":{\"2513\":1}}],[\"需确保对话上下文的一致性\",{\"2\":{\"2355\":1}}],[\"需确保策略不会过于偏离合理范围\",{\"2\":{\"2041\":1}}],[\"需确保边界条件\",{\"2\":{\"1399\":1}}],[\"需确保旋转矩阵与输入向量维度一致\",{\"2\":{\"338\":1}}],[\"需特别小心\",{\"2\":{\"1383\":1}}],[\"需谨慎使用\",{\"2\":{\"2146\":1,\"2191\":1}}],[\"需谨慎选择初始化方法\",{\"2\":{\"1840\":1}}],[\"需谨慎设置\",{\"2\":{\"1371\":1}}],[\"需谨慎处理状态转移和动作选择\",{\"2\":{\"806\":1}}],[\"需避免过度代表的领域影响整体数据质量\",{\"2\":{\"1352\":1}}],[\"需长期自主规划的场景\",{\"2\":{\"1316\":1}}],[\"需权衡计算和通讯压力\",{\"2\":{\"1229\":1}}],[\"需拼接\",{\"2\":{\"1199\":1}}],[\"需注意token\",{\"2\":{\"2353\":1}}],[\"需注意评估机制的准确性\",{\"2\":{\"2127\":1}}],[\"需注意\",{\"2\":{\"2050\":1}}],[\"需注意优势函数的准确计算\",{\"2\":{\"1733\":1}}],[\"需注意初始化策略的选择\",{\"2\":{\"2450\":1}}],[\"需注意初始化策略\",{\"2\":{\"1405\":1}}],[\"需注意内存消耗可能增加\",{\"2\":{\"1351\":1}}],[\"需注意使用真实数据进行训练\",{\"2\":{\"967\":1}}],[\"需注意行为策略与目标策略的区别\",{\"2\":{\"758\":1}}],[\"需注意clip范围的设置不宜过大\",{\"2\":{\"731\":1}}],[\"需注意选择合适的步长参数$$\",{\"2\":{\"678\":1}}],[\"需注意以下问题\",{\"2\":{\"417\":1}}],[\"需提前清洗数据\",{\"2\":{\"565\":1}}],[\"需在小模型上先实验再应用于大模型\",{\"2\":{\"422\":1}}],[\"需在实践中调整尺度因子\",{\"2\":{\"335\":1}}],[\"需针对不同维度优化缩放方式\",{\"2\":{\"335\":1}}],[\"需微调模型以适应新的映射\",{\"2\":{\"246\":1}}],[\"需设置高于预期值\",{\"2\":{\"244\":1}}],[\"需求\",{\"2\":{\"239\":1}}],[\"需结合目标kl进行实验\",{\"2\":{\"1123\":1}}],[\"需结合目标kl来确定\",{\"2\":{\"911\":1}}],[\"需结合多种策略\",{\"2\":{\"630\":1}}],[\"需结合具体场景选择\",{\"2\":{\"210\":1}}],[\"需结合领域自适应\",{\"2\":{\"57\":1}}],[\"需单独处理认证和授权过程\",{\"2\":{\"137\":1}}],[\"需采用稀疏注意力或分块计算\",{\"2\":{\"57\":1}}],[\"需要将word\",{\"2\":{\"2651\":1}}],[\"需要针对不同格式设计专用算法\",{\"2\":{\"2650\":1}}],[\"需要存储大量重复内容\",{\"2\":{\"2635\":1}}],[\"需要制定精细的规则\",{\"2\":{\"2620\":1}}],[\"需要依赖额外的工具库\",{\"2\":{\"2599\":1}}],[\"需要依赖性能优越的语言模型支持\",{\"2\":{\"1611\":1}}],[\"需要仔细管理以确保模块间的协调和一致性\",{\"2\":{\"2544\":1}}],[\"需要重点关注其事实性和信息有效性\",{\"2\":{\"2411\":1}}],[\"需要进行一次gelu的计算\",{\"2\":{\"2616\":1}}],[\"需要进行一次\",{\"2\":{\"2276\":1,\"2308\":1}}],[\"需要进行马尔可夫决策过程\",{\"2\":{\"1515\":1}}],[\"需要使用不同的损失函数\",{\"2\":{\"2163\":1}}],[\"需要使用warmup策略\",{\"2\":{\"169\":1}}],[\"需要读取\",{\"2\":{\"2145\":1}}],[\"需要约\",{\"2\":{\"2145\":1}}],[\"需要手动切割模型并且适配\",{\"2\":{\"2118\":1}}],[\"需要手动调整\",{\"2\":{\"1562\":1}}],[\"需要设计合理的prompt\",{\"2\":{\"2103\":1}}],[\"需要设计高效的清理策略\",{\"2\":{\"231\":1}}],[\"需要适当调整这个块内其他未量化的参数\",{\"2\":{\"2085\":1}}],[\"需要先下载对应语言的模型\",{\"2\":{\"2002\":1}}],[\"需要一个预训练的基础语言模型\",{\"2\":{\"1867\":1}}],[\"需要一些大模型压缩技术\",{\"0\":{\"763\":1}}],[\"需要满足以下几点\",{\"2\":{\"1687\":1}}],[\"需要更多的定制和调优以提高效率和相关性\",{\"2\":{\"2512\":1}}],[\"需要更多的计算资源\",{\"2\":{\"1562\":1}}],[\"需要更精细的区分\",{\"2\":{\"1306\":1}}],[\"需要增加输出值碰撞的概率\",{\"2\":{\"1559\":1}}],[\"需要对输出层的y1y\",{\"2\":{\"2660\":1}}],[\"需要对过长chunk进行截断或进一步处理\",{\"2\":{\"1513\":1}}],[\"需要对序列中的任意两个向量计算相关性\",{\"2\":{\"147\":1}}],[\"需要额外初始化超长部分的位置向量\",{\"2\":{\"1463\":1}}],[\"需要根据实际应用场景权衡\",{\"2\":{\"2699\":1}}],[\"需要根据实际需求权衡其优缺点\",{\"2\":{\"1392\":1}}],[\"需要根据难度动态调整数据量\",{\"2\":{\"2245\":1}}],[\"需要根据具体应用场景权衡覆盖范围与系统性能\",{\"2\":{\"2000\":1}}],[\"需要根据任务的需求选择\",{\"2\":{\"1282\":1}}],[\"需要内存较大的cpu机器\",{\"2\":{\"1302\":1}}],[\"需要通过适当的数据处理和训练策略解决\",{\"2\":{\"1295\":1}}],[\"需要通过实践不断调整\",{\"2\":{\"501\":1}}],[\"需要构建的样本\",{\"2\":{\"1047\":1}}],[\"需要构造多个数据来训练\",{\"2\":{\"1006\":1}}],[\"需要专门的压缩技术来存储和计算被剪枝的模型\",{\"2\":{\"931\":1}}],[\"需要注意的是\",{\"2\":{\"715\":1,\"1885\":1,\"2000\":1,\"2051\":1,\"2335\":1}}],[\"需要良好编程基础\",{\"2\":{\"610\":1}}],[\"需要分别监控loss值\",{\"2\":{\"525\":1}}],[\"需要首先进行马尔可夫决策过程\",{\"2\":{\"514\":1}}],[\"需要大量计算资源\",{\"2\":{\"419\":1}}],[\"需要采用不同的技术手段\",{\"2\":{\"411\":1}}],[\"需要结合上下文信息和动态规划来确保解码结果的有效性\",{\"2\":{\"341\":1}}],[\"需要人工设置\",{\"2\":{\"261\":1}}],[\"需要加权的值\",{\"2\":{\"112\":1}}],[\"需要学习的知识\",{\"0\":{\"59\":1,\"91\":1,\"144\":1,\"207\":1,\"278\":1,\"349\":1,\"428\":1,\"511\":1}}],[\"需要探索数据的内部结构\",{\"2\":{\"39\":1}}],[\"需要在模型训练过程中监控测试集的表现\",{\"2\":{\"1505\":1}}],[\"需要在霍夫曼树中进行较长路径的计算\",{\"2\":{\"941\":1}}],[\"需要在未来时间点做出进一步决策\",{\"2\":{\"572\":1}}],[\"需要在\",{\"2\":{\"11\":1}}],[\"四路流水线并行\",{\"2\":{\"2710\":1}}],[\"四阶段预训练设置流程\",{\"0\":{\"1436\":1}}],[\"四个动作方向\",{\"2\":{\"656\":1}}],[\"四个动作\",{\"2\":{\"656\":1}}],[\"四\",{\"0\":{\"57\":1,\"2270\":1}}],[\"力扣刷完数组这一章\",{\"2\":{\"56\":1}}],[\"我将结合工业界实习中的一些实际经验\",{\"2\":{\"1309\":1}}],[\"我\",{\"2\":{\"1111\":1}}],[\"我欠他100万\",{\"2\":{\"216\":1}}],[\"我们也可以适当让模型的回答融入一些主观性或其对知识的理解\",{\"2\":{\"2693\":1}}],[\"我们把原先的通讯量从\",{\"2\":{\"2676\":1}}],[\"我们把整段prompt喂给模型做forward计算\",{\"2\":{\"1870\":1}}],[\"我们在输出层对word\",{\"2\":{\"2656\":1}}],[\"我们相当于完整遍历了\",{\"2\":{\"2653\":1}}],[\"我们都加载了部分\",{\"2\":{\"2653\":1}}],[\"我们都会加载\",{\"2\":{\"2653\":1}}],[\"我们来看伪代码的第六行\",{\"2\":{\"2653\":1}}],[\"我们来看一个简单的例子\",{\"2\":{\"2130\":1}}],[\"我们有\",{\"2\":{\"2643\":2}}],[\"我们有一个正样本\",{\"2\":{\"1566\":1}}],[\"我们沿着列方向维度切割一刀\",{\"2\":{\"2636\":1}}],[\"我们必须在进行gelu前\",{\"2\":{\"2616\":1}}],[\"我们要尽量保证各gpu上的计算相互独立\",{\"2\":{\"2616\":1}}],[\"我们遍历\",{\"2\":{\"2573\":1}}],[\"我们开始遍历\",{\"2\":{\"2565\":1}}],[\"我们直接设定每个块中包含的字数\",{\"2\":{\"2560\":1}}],[\"我们能够确保在遍历完所有块后\",{\"2\":{\"2528\":1}}],[\"我们能够更好地理解和应用人类偏好\",{\"2\":{\"1811\":1}}],[\"我们得到完整的更新公式\",{\"2\":{\"2528\":1}}],[\"我们希望构造形如下面这样的更新等式\",{\"2\":{\"2517\":1}}],[\"我们希望学习一种表示\",{\"2\":{\"1566\":1}}],[\"我们仍然可以通过不断使用当前最新的\",{\"2\":{\"2517\":1}}],[\"我们根本无法算出最终的\",{\"2\":{\"2505\":1}}],[\"我们根据prompt的prefill结果\",{\"2\":{\"1927\":1}}],[\"我们只保留\",{\"2\":{\"2505\":1}}],[\"我们只关注attention的计算部分\",{\"2\":{\"1868\":1}}],[\"我们定义\",{\"0\":{\"2505\":1}}],[\"我们假设标准场景下\",{\"2\":{\"2492\":1}}],[\"我们抽象出\",{\"2\":{\"2433\":1}}],[\"我们正在解决世界上一些最复杂和要求苛刻的计算问题\",{\"2\":{\"2408\":1}}],[\"我们同样放在后文详说\",{\"2\":{\"2379\":1}}],[\"我们会让相邻的块之间保持一定程度的重叠\",{\"2\":{\"2560\":1}}],[\"我们会详细说这点\",{\"2\":{\"2349\":1}}],[\"我们会采用一些技巧来优化模型的性能\",{\"2\":{\"505\":1}}],[\"我们最大化生成文本\",{\"2\":{\"2289\":1}}],[\"我们采用\",{\"2\":{\"2129\":1}}],[\"我们采用了\",{\"2\":{\"2081\":1}}],[\"我们引入了\",{\"2\":{\"2129\":1}}],[\"我们总结了tdpo算法的核心概念及其与ppo的区别\",{\"2\":{\"1880\":1}}],[\"我们就不需要对前面的token重复计算\",{\"2\":{\"1870\":1}}],[\"我们就来聊一聊目前有哪些主流的pdf解析手段\",{\"2\":{\"1609\":1}}],[\"我们先对文档进行结构切割\",{\"2\":{\"2271\":1}}],[\"我们先定义几个基本变量\",{\"2\":{\"1868\":1}}],[\"我们先确定使用几块gpu来装载一套专家\",{\"2\":{\"1410\":1}}],[\"我们的目标恰恰相反\",{\"2\":{\"1559\":1}}],[\"我们的目标是通过这些特征预测一个新病人是否患病\",{\"2\":{\"66\":1}}],[\"我们将输出定义为\",{\"2\":{\"2505\":1}}],[\"我们将总结多个开源数据集的核心信息\",{\"2\":{\"2138\":1}}],[\"我们将逐步解析每个步骤的具体内容和实现方式\",{\"2\":{\"1950\":1}}],[\"我们将深入探讨flashattention的前向流程\",{\"2\":{\"1750\":1}}],[\"我们将通过几个典型的层级\",{\"2\":{\"1672\":1}}],[\"我们将探讨如何在强化学习中使用ppo\",{\"2\":{\"1523\":1}}],[\"我们将复杂的技术术语转化为通俗易懂的语言\",{\"2\":{\"1365\":1}}],[\"我们无法直接判断这些邮件与用户查询之间的相似度\",{\"2\":{\"2672\":1}}],[\"我们无法\",{\"2\":{\"1496\":1}}],[\"我们不仅可以量化模型的权重和激活\",{\"2\":{\"1448\":1}}],[\"我们通常采用\",{\"2\":{\"2458\":1}}],[\"我们通常会经历检索召回和重排两个步骤\",{\"2\":{\"1235\":1}}],[\"我们通常使用bert类模型作为编码器\",{\"2\":{\"910\":1}}],[\"我们需要将输入的数据张量\",{\"2\":{\"2549\":1}}],[\"我们需要评估模型在链路中的相关能力\",{\"2\":{\"2518\":1}}],[\"我们需要换个思路\",{\"2\":{\"2517\":1}}],[\"我们需要确保分块计算中的结果与标准场景下的结果完全一致\",{\"2\":{\"2505\":1}}],[\"我们需要设计一套机制来管理时间敏感的数据\",{\"2\":{\"1558\":1}}],[\"我们需要设定一个阈值\",{\"2\":{\"105\":1}}],[\"我们需要思考以下问题\",{\"2\":{\"1421\":1}}],[\"我们需要对其进行切片处理\",{\"2\":{\"2105\":1}}],[\"我们需要对实体和术语进行标准化处理\",{\"2\":{\"1376\":1}}],[\"我们需要对原始数据进行清洗\",{\"2\":{\"1185\":1}}],[\"我们需要引入额外的机制\",{\"2\":{\"1284\":1}}],[\"我们需要优化文档读取器和多模态模型\",{\"2\":{\"1284\":1}}],[\"我们需要关注以下几个方面\",{\"2\":{\"1234\":1}}],[\"我们管这个场景叫parallel\",{\"2\":{\"781\":1}}],[\"我们可以在检索过程中优先考虑日期最近的邮件\",{\"2\":{\"2672\":1}}],[\"我们可以在一次前向计算中获取整个多轮对话中所有\",{\"2\":{\"881\":1}}],[\"我们可以先按行求和\",{\"2\":{\"2667\":1}}],[\"我们可以把每个头的参数放到一块gpu上\",{\"2\":{\"2636\":1}}],[\"我们可以表示为\",{\"2\":{\"2528\":1}}],[\"我们可以通过以下公式进行更新\",{\"2\":{\"2528\":1}}],[\"我们可以通过调用\",{\"2\":{\"2408\":1}}],[\"我们可以从以下几个专项能力进行评估\",{\"2\":{\"2477\":1}}],[\"我们可以定义一个比较函数\",{\"2\":{\"2436\":1}}],[\"我们可以看到\",{\"2\":{\"2433\":1}}],[\"我们可以发现它们分别适用于不同类型的任务\",{\"2\":{\"2325\":1}}],[\"我们可以更好地理解推理过程中各个阶段的性能瓶颈\",{\"2\":{\"2263\":1}}],[\"我们可以更好地理解peft方法在大模型微调中的重要性及其应用场景\",{\"2\":{\"2182\":1}}],[\"我们可以考虑以下问题\",{\"2\":{\"2258\":1}}],[\"我们可以有效地进行分块计算softmax\",{\"2\":{\"2216\":1}}],[\"我们可以估算不同数据类型和优化器配置下的显存需求\",{\"2\":{\"2099\":1}}],[\"我们可以实现以下目标\",{\"2\":{\"2081\":1}}],[\"我们可以首先通过一次\",{\"2\":{\"2079\":1}}],[\"我们可以对两者的得分设置权重比例\",{\"2\":{\"1949\":1}}],[\"我们可以对其进行分类\",{\"2\":{\"1139\":1}}],[\"我们可以\",{\"2\":{\"1510\":1}}],[\"我们可以用以下公式来表示\",{\"2\":{\"1333\":1}}],[\"我们可以用它对新的数据进行预测\",{\"2\":{\"143\":1}}],[\"我们可以加入额外的监督下一个token预测损失\",{\"2\":{\"603\":1}}],[\"我们设置\",{\"2\":{\"570\":1}}],[\"我们分步骤分析\",{\"2\":{\"166\":1}}],[\"我们用s型函数\",{\"2\":{\"90\":1}}],[\"我也不知道python的解释器是干什么的\",{\"2\":{\"56\":1}}],[\"我不知道python的虚拟环境\",{\"2\":{\"56\":1}}],[\"我仔细想了想\",{\"2\":{\"56\":1}}],[\"我在思考应该在什么应用场景下选择什么样的算法\",{\"2\":{\"39\":1}}],[\"突然想到了每次配置环境的时候都会或多或少的出现一点差错\",{\"2\":{\"56\":1}}],[\"突然想到要学习好多内容\",{\"2\":{\"56\":1}}],[\"加上\",{\"2\":{\"2118\":1}}],[\"加入更多指令数据有助于提升模型性能\",{\"2\":{\"1389\":1}}],[\"加入1层decoder\",{\"2\":{\"1288\":1}}],[\"加入第一阶段生成的示例\",{\"2\":{\"1273\":1}}],[\"加入了专门的数学与代码数据\",{\"2\":{\"1205\":1}}],[\"加入到输入token的embedding表达中\",{\"2\":{\"1045\":1}}],[\"加入基线的改进版本\",{\"2\":{\"654\":1}}],[\"加权和\",{\"2\":{\"1688\":1}}],[\"加权采样\",{\"0\":{\"446\":1}}],[\"加权求和\",{\"2\":{\"213\":1}}],[\"加快学习速度\",{\"2\":{\"285\":1,\"330\":1}}],[\"加速参数重分片同步的过程\",{\"2\":{\"2129\":1}}],[\"加速适应新任务\",{\"2\":{\"503\":1}}],[\"加速计算\",{\"0\":{\"1957\":1,\"2193\":1},\"2\":{\"462\":1}}],[\"加速模型收敛\",{\"2\":{\"121\":1}}],[\"加速\",{\"2\":{\"65\":1,\"2081\":1}}],[\"加油\",{\"2\":{\"56\":1}}],[\"加载并初始化预训练模型参数\",{\"2\":{\"2115\":1}}],[\"加载效率高\",{\"2\":{\"1451\":1}}],[\"加载\",{\"2\":{\"49\":1}}],[\"斯坦福的ml\",{\"2\":{\"56\":1}}],[\"任重而道远哇\",{\"2\":{\"56\":1}}],[\"任务的拆解与分配需要具备高度的灵活性\",{\"2\":{\"2139\":1}}],[\"任务多样性不足\",{\"2\":{\"1453\":1}}],[\"任务排序\",{\"2\":{\"1439\":1}}],[\"任务执行\",{\"2\":{\"1439\":1}}],[\"任务规划\",{\"2\":{\"1439\":1}}],[\"任务分解的实现方式\",{\"0\":{\"1420\":1}}],[\"任务分解与并行处理\",{\"2\":{\"1384\":1}}],[\"任务复杂度相对较低\",{\"2\":{\"1241\":1}}],[\"任务清晰\",{\"2\":{\"1241\":1}}],[\"任务提供了新视角\",{\"2\":{\"1088\":1}}],[\"任务与数据集\",{\"0\":{\"1019\":1}}],[\"任务描述用于告诉模型要完成的任务\",{\"2\":{\"708\":1}}],[\"任务是跨语言迁移\",{\"2\":{\"631\":1}}],[\"任务中应用强化学习\",{\"2\":{\"1515\":1}}],[\"任务中尤为重要\",{\"2\":{\"205\":1}}],[\"任务中\",{\"2\":{\"93\":1,\"319\":1,\"1618\":1,\"2222\":1}}],[\"任务\",{\"2\":{\"49\":2,\"56\":4}}],[\"任务示例\",{\"2\":{\"34\":1}}],[\"耐下性子来好吗\",{\"2\":{\"56\":1}}],[\"先生成一个临时句子\",{\"2\":{\"2570\":1}}],[\"先生成市场营销文案\",{\"2\":{\"1820\":1}}],[\"先分析row\",{\"2\":{\"2537\":1}}],[\"先做一个矩阵分解\",{\"2\":{\"1982\":1}}],[\"先让子问题查询代理把用户提问拆解为多个小问题\",{\"2\":{\"2335\":1}}],[\"先让\",{\"2\":{\"1717\":1}}],[\"先训练模型\",{\"0\":{\"795\":1}}],[\"先学习值函数\",{\"2\":{\"724\":1}}],[\"先学习简单内容\",{\"2\":{\"533\":1}}],[\"先升后降\",{\"2\":{\"558\":1}}],[\"先将语料拆分为最小单位\",{\"2\":{\"420\":1}}],[\"先计算\",{\"2\":{\"189\":1}}],[\"先把书看好吧\",{\"2\":{\"56\":1}}],[\"先用一条直线\",{\"2\":{\"51\":1}}],[\"随后\",{\"2\":{\"2089\":1,\"2305\":1,\"2374\":1}}],[\"随后在计算\",{\"2\":{\"881\":1}}],[\"随着并行度增加\",{\"2\":{\"2706\":1}}],[\"随着对话系统复杂度的增加\",{\"2\":{\"2497\":1}}],[\"随着对话系统需求的增加\",{\"2\":{\"2435\":1}}],[\"随着语言模型应用场景的扩展\",{\"2\":{\"2426\":1}}],[\"随着深度学习框架的不断发展\",{\"2\":{\"2407\":1}}],[\"随着用户交互数据的不断积累\",{\"2\":{\"2321\":1}}],[\"随着测试时间的增加\",{\"2\":{\"2122\":1}}],[\"随着训练的进行\",{\"2\":{\"2507\":1}}],[\"随着训练步数的增加\",{\"2\":{\"2070\":1}}],[\"随着训练进行\",{\"2\":{\"183\":1}}],[\"随着计算资源的普及和数据集的增大\",{\"2\":{\"2066\":1}}],[\"随着计算能力和算法研究的深入\",{\"2\":{\"857\":1}}],[\"随着计算能力的提升和大数据技术的发展\",{\"2\":{\"952\":1}}],[\"随着计算能力的提升和更多复杂环境模拟器的开发\",{\"2\":{\"793\":1}}],[\"随着计算能力的提升和数据采集技术的发展\",{\"2\":{\"784\":1}}],[\"随着计算能力的提升\",{\"2\":{\"647\":1,\"877\":1,\"937\":1,\"953\":1}}],[\"随着研究的深入\",{\"2\":{\"1990\":1}}],[\"随着中文语言模型需求的增加\",{\"2\":{\"1742\":1}}],[\"随着频率的降低\",{\"2\":{\"1296\":1}}],[\"随着技术的不断发展\",{\"2\":{\"1136\":1}}],[\"随着数据规模的增长\",{\"2\":{\"985\":1}}],[\"随着数据范围进一步扩大\",{\"2\":{\"314\":1}}],[\"随着机器学习的发展\",{\"2\":{\"912\":1}}],[\"随着人工智能技术的不断发展\",{\"2\":{\"1151\":1}}],[\"随着人工智能技术的快速发展\",{\"2\":{\"692\":1}}],[\"随着人工智能在自动驾驶\",{\"2\":{\"893\":1}}],[\"随着强化学习的深入研究\",{\"2\":{\"927\":1}}],[\"随着强化学习的发展\",{\"2\":{\"791\":1}}],[\"随着强化学习在自动驾驶\",{\"2\":{\"852\":1}}],[\"随着强化学习在各领域的应用扩展\",{\"2\":{\"829\":1}}],[\"随着更强大的模型和硬件支持\",{\"2\":{\"1036\":1}}],[\"随着更复杂的数据集和更高效的算法\",{\"2\":{\"788\":1}}],[\"随着更多上下文感知模型的引入\",{\"2\":{\"420\":1}}],[\"随着预训练模型规模扩大\",{\"2\":{\"753\":1}}],[\"随着ai技术的发展\",{\"2\":{\"701\":1}}],[\"随着\",{\"2\":{\"698\":1,\"1408\":1,\"1537\":1,\"1700\":1}}],[\"随着自然语言处理技术的发展\",{\"2\":{\"1484\":1}}],[\"随着自然语言处理技术的普及\",{\"2\":{\"680\":1}}],[\"随着自然语言处理任务对长上下文处理需求的增加\",{\"2\":{\"360\":1}}],[\"随着大模型训练技术的发展\",{\"2\":{\"2488\":1}}],[\"随着大模型需求的增加\",{\"2\":{\"2473\":1}}],[\"随着大模型参数的增长\",{\"2\":{\"1972\":1}}],[\"随着大模型和深度学习的发展\",{\"2\":{\"787\":1}}],[\"随着大模型的不断发展\",{\"2\":{\"2362\":1}}],[\"随着大模型的兴起\",{\"2\":{\"745\":1}}],[\"随着大模型的发展\",{\"2\":{\"598\":1}}],[\"随着大规模语言模型的普及\",{\"2\":{\"650\":1}}],[\"随着大语言模型的发展\",{\"2\":{\"633\":1}}],[\"随着nlp模型对多语言支持需求增加\",{\"2\":{\"555\":1}}],[\"随着迭代次数增加\",{\"2\":{\"471\":1}}],[\"随着硬件性能的提升和更大规模模型的出现\",{\"2\":{\"730\":1}}],[\"随着硬件性能提升\",{\"2\":{\"289\":1,\"1021\":1}}],[\"随着硬件发展\",{\"2\":{\"660\":1}}],[\"随着硬件技术进步\",{\"2\":{\"432\":1}}],[\"随着transformer模型在大规模预训练中的广泛应用\",{\"2\":{\"414\":1}}],[\"随着transformer架构的普及\",{\"2\":{\"111\":1}}],[\"随着上下文长度需求的增加\",{\"2\":{\"412\":1}}],[\"随着上下文窗口扩展需求的增加\",{\"2\":{\"346\":1}}],[\"随着多语言模型和大规模数据处理需求的增长\",{\"2\":{\"365\":1}}],[\"随着模型参数的增加\",{\"2\":{\"728\":1}}],[\"随着模型参数量的持续增长\",{\"2\":{\"629\":1}}],[\"随着模型规模的扩大\",{\"2\":{\"1314\":1}}],[\"随着模型规模的不断扩大\",{\"2\":{\"700\":1}}],[\"随着模型规模不断扩大\",{\"2\":{\"306\":1}}],[\"随着模型复杂度增加\",{\"2\":{\"239\":1}}],[\"随着模型复杂度和序列长度增加\",{\"2\":{\"187\":1}}],[\"随想\",{\"2\":{\"56\":4}}],[\"随机初始化virtual\",{\"2\":{\"1914\":1}}],[\"随机初始化可能导致预训练知识损害\",{\"2\":{\"1840\":1}}],[\"随机初始化状态价值函数\",{\"2\":{\"647\":2}}],[\"随机矩阵\",{\"2\":{\"1583\":1,\"1866\":1}}],[\"随机路由与辅助损失函数\",{\"2\":{\"1119\":1}}],[\"随机遮盖\",{\"2\":{\"40\":1}}],[\"随机森林\",{\"2\":{\"39\":1,\"91\":1}}],[\"接着\",{\"2\":{\"1465\":1,\"2272\":1,\"2365\":1,\"2660\":1}}],[\"接收一个观测\",{\"2\":{\"2011\":1}}],[\"接收\",{\"2\":{\"1409\":1}}],[\"接下来我们看一共计算了多少次\",{\"2\":{\"2643\":1}}],[\"接下来\",{\"2\":{\"1222\":1,\"1672\":1,\"1950\":1}}],[\"接近来构造均方误差损失函数形式\",{\"2\":{\"640\":1}}],[\"接近线性\",{\"2\":{\"305\":1}}],[\"接口设计\",{\"2\":{\"54\":1}}],[\"接受两个\",{\"2\":{\"11\":2}}],[\"系统需要处理更多的文本块\",{\"2\":{\"2533\":1}}],[\"系统需要根据用户的查询从向量数据库中检索相关文本\",{\"2\":{\"2465\":1}}],[\"系统成功的关键之一\",{\"2\":{\"2393\":1}}],[\"系统成为了一个热门的研究与应用领域\",{\"2\":{\"1151\":1}}],[\"系统将用户提问与上一阶段检索到的信息结合起来\",{\"2\":{\"2305\":1}}],[\"系统会在向量数据库中搜索与该问题向量语义上相似的知识文本或历史对话记录\",{\"2\":{\"2272\":1}}],[\"系统开始表现出一定程度的非线性行为\",{\"2\":{\"1786\":1}}],[\"系统之间可能存在较大的效果差异\",{\"2\":{\"1775\":1}}],[\"系统的构建来优化\",{\"2\":{\"2681\":1}}],[\"系统的行为是线性的\",{\"2\":{\"1728\":1}}],[\"系统的\",{\"0\":{\"1672\":1},\"1\":{\"1728\":1,\"1786\":1,\"1847\":1,\"1904\":1}}],[\"系统的基础\",{\"2\":{\"1450\":1}}],[\"系统中\",{\"2\":{\"1610\":1,\"2334\":1,\"2690\":1}}],[\"系统时\",{\"2\":{\"1609\":1,\"2303\":1,\"2419\":1}}],[\"系统遇到复杂输入时\",{\"2\":{\"1578\":1}}],[\"系统也需要具备将其转换并拓展为一系列高质量问题的能力\",{\"2\":{\"1496\":1}}],[\"系统不仅能够完成任务\",{\"2\":{\"1382\":1}}],[\"系统从工具型向自主型迈进的重要阶段\",{\"2\":{\"1336\":1}}],[\"系统可以根据当前状态和上下文信息\",{\"2\":{\"1847\":1}}],[\"系统可以在一个batch中同时输入更多的序列\",{\"2\":{\"750\":1}}],[\"系统可能会采取以下步骤\",{\"2\":{\"1332\":1}}],[\"系统则强调多样化的智能体特性\",{\"2\":{\"1291\":1}}],[\"系统\",{\"0\":{\"2702\":1},\"2\":{\"1289\":1,\"1429\":1,\"1578\":1,\"2000\":1,\"2702\":1}}],[\"系统能够迅速检索出与用户查询最相关的信息\",{\"2\":{\"2237\":1}}],[\"系统能够根据查询的性质和上下文\",{\"2\":{\"1285\":1}}],[\"系统能够与人类进行对话互动\",{\"2\":{\"1238\":1}}],[\"系统架构\",{\"2\":{\"54\":1}}],[\"系统设计\",{\"0\":{\"54\":1}}],[\"系列模型\",{\"2\":{\"2118\":1}}],[\"系列框架以确保训练效率\",{\"2\":{\"1542\":1}}],[\"系列的最新版本\",{\"2\":{\"926\":1}}],[\"系列\",{\"2\":{\"34\":1}}],[\"自反思搜索增强是一个全新rag框架\",{\"2\":{\"2365\":1}}],[\"自身也具备生成这类反馈的能力\",{\"2\":{\"2259\":1}}],[\"自我进化\",{\"2\":{\"2169\":1}}],[\"自我进化过程\",{\"0\":{\"2070\":1}}],[\"自我指令创建\",{\"0\":{\"1924\":1}}],[\"自我奖励模型的迭代训练结果显示胜率逐步提升\",{\"2\":{\"2076\":1}}],[\"自我奖励训练有效提高了模型的性能\",{\"2\":{\"1747\":1}}],[\"自我奖励语言模型\",{\"2\":{\"1747\":1}}],[\"自我训练\",{\"0\":{\"1637\":1}}],[\"自我反思\",{\"2\":{\"1557\":1}}],[\"自我批评与反思\",{\"0\":{\"1557\":1}}],[\"自适应算法\",{\"2\":{\"1464\":1}}],[\"自然语言理解\",{\"2\":{\"1625\":1}}],[\"自然语言翻译\",{\"2\":{\"1465\":1}}],[\"自然语言处理库\",{\"2\":{\"1612\":1}}],[\"自然语言处理基础\",{\"2\":{\"578\":1}}],[\"自然语言处理专项课程\",{\"2\":{\"67\":1}}],[\"自然语言处理综论\",{\"2\":{\"67\":1}}],[\"自然语言处理\",{\"0\":{\"52\":1},\"1\":{\"59\":1,\"67\":1},\"2\":{\"71\":1,\"74\":1,\"80\":1,\"96\":1,\"104\":1,\"139\":1,\"142\":1,\"154\":2,\"160\":1,\"226\":1,\"227\":1,\"229\":1,\"273\":1,\"286\":2,\"297\":2,\"320\":1,\"344\":1,\"347\":1,\"377\":1,\"484\":1,\"832\":1,\"835\":1,\"848\":1,\"861\":1,\"862\":1,\"865\":2,\"883\":1,\"887\":1,\"930\":1,\"935\":1,\"958\":1,\"1014\":1,\"1044\":1,\"1055\":1,\"1063\":1,\"1070\":1,\"1085\":2,\"1098\":1,\"1103\":1,\"1111\":2,\"1471\":2,\"1486\":1,\"1568\":1,\"1625\":1,\"1682\":1,\"2135\":1}}],[\"自然语义完整性\",{\"2\":{\"1424\":1}}],[\"自主\",{\"0\":{\"1904\":1},\"2\":{\"1904\":2}}],[\"自主学习何时以及如何调用工具\",{\"2\":{\"1684\":1}}],[\"自主决策\",{\"2\":{\"1474\":1}}],[\"自主规划任务的系统\",{\"2\":{\"1316\":1}}],[\"自主智能体通常在任务完成时终止\",{\"2\":{\"1545\":1}}],[\"自主智能体可以在特定检查点或遇到阻碍时暂停执行\",{\"2\":{\"1501\":1}}],[\"自主智能体需要根据环境中获得的\",{\"2\":{\"1454\":1}}],[\"自主智能体会独立规划并执行任务\",{\"2\":{\"1408\":1}}],[\"自主智能体的工作流程可能以用户的一次指令或与用户的互动开始\",{\"2\":{\"1408\":1}}],[\"自主智能体已经开始在实际生产中得到应用\",{\"2\":{\"1408\":1}}],[\"自主智能体是由\",{\"2\":{\"1316\":1}}],[\"自主智能体\",{\"0\":{\"1316\":1,\"1408\":1},\"1\":{\"1454\":1,\"1501\":1,\"1545\":1}}],[\"自编码思想\",{\"2\":{\"1004\":1}}],[\"自编码器\",{\"2\":{\"39\":1}}],[\"自回归架构模型\",{\"2\":{\"1922\":1}}],[\"自回归语言模型\",{\"2\":{\"1017\":1}}],[\"自回归思想\",{\"2\":{\"1004\":1}}],[\"自回归填空目标可以为条件生成和无条件生成任务预训练语言模型\",{\"2\":{\"1004\":1}}],[\"自回归填空任务结合了自编码和自回归思想\",{\"2\":{\"1004\":1}}],[\"自回归填空任务\",{\"0\":{\"1004\":1}}],[\"自回归填空\",{\"2\":{\"887\":1}}],[\"自回归\",{\"2\":{\"854\":1}}],[\"自回归生成\",{\"2\":{\"92\":1}}],[\"自动课程任务生成\",{\"2\":{\"2277\":1}}],[\"自动合并是在父文档搜索上更进一步的复杂解决方案\",{\"2\":{\"2271\":1}}],[\"自动合并\",{\"0\":{\"2271\":1}}],[\"自动梯度\",{\"2\":{\"2123\":1}}],[\"自动安全评估器\",{\"2\":{\"1407\":1}}],[\"自动分片\",{\"2\":{\"988\":1}}],[\"自动搜索最优的神经网络架构\",{\"2\":{\"763\":1}}],[\"自动化评估\",{\"2\":{\"2037\":1}}],[\"自动化调参工具的普及\",{\"2\":{\"1526\":1}}],[\"自动化显存管理和优化工具可能进一步简化开发者的工作流程\",{\"2\":{\"730\":1}}],[\"自动化参数优化\",{\"2\":{\"703\":1}}],[\"自动推断为技术博客\",{\"2\":{\"2535\":1}}],[\"自动推断为机器学习与强化学习\",{\"0\":{\"1723\":1}}],[\"自动推断\",{\"0\":{\"924\":1,\"1781\":1},\"2\":{\"538\":1,\"588\":1,\"641\":1,\"642\":1,\"659\":1,\"774\":1,\"1414\":1,\"1477\":1,\"1488\":1,\"1599\":1,\"1768\":1}}],[\"自动生成最优数字编码方案\",{\"2\":{\"361\":1}}],[\"自行训练ocr模型\",{\"2\":{\"465\":1}}],[\"自监督学习\",{\"0\":{\"1024\":1},\"2\":{\"424\":1,\"503\":1}}],[\"最多需要保存流水线阶段数份激活值\",{\"2\":{\"2694\":1}}],[\"最初的目的是解决复杂强化学习任务中环境奖励函数设计的问题\",{\"2\":{\"1633\":1}}],[\"最麻烦的莫过于构建知识库\",{\"2\":{\"1609\":1}}],[\"最新上映的科幻电影推荐\",{\"2\":{\"1332\":1}}],[\"最低分\",{\"2\":{\"1075\":1}}],[\"最简单直观的文本分块方法\",{\"0\":{\"1366\":1}}],[\"最简单\",{\"2\":{\"939\":1}}],[\"最后将计算结果concat起来\",{\"2\":{\"2636\":1}}],[\"最后将评分高的文档当作最终结果一并交给llm\",{\"2\":{\"2365\":1}}],[\"最后排名代理将所有检索的文档总结再交给llm\",{\"2\":{\"2335\":1}}],[\"最后一步是生成回答\",{\"2\":{\"2305\":1}}],[\"最后一个token位置的输出奖励值可视作聚合整个句子信息的transformer操作\",{\"2\":{\"1848\":1}}],[\"最后一个token位置的输出奖励值聚合了整个句子的信息\",{\"2\":{\"1673\":1}}],[\"最后奖励值的平均值作为value的估计\",{\"2\":{\"1576\":1}}],[\"最后\",{\"2\":{\"1465\":1,\"2628\":1}}],[\"最后微调\",{\"0\":{\"795\":1}}],[\"最后根据概率值判断类别\",{\"2\":{\"51\":1}}],[\"最优解直接为\",{\"2\":{\"1944\":1}}],[\"最优token数量\",{\"2\":{\"1329\":1}}],[\"最优\",{\"0\":{\"1297\":1}}],[\"最优动作价值函数\",{\"2\":{\"767\":2}}],[\"最优状态价值函数\",{\"2\":{\"767\":2}}],[\"最优策略与贝尔曼最优方程\",{\"0\":{\"767\":1}}],[\"最优策略=arg策略max​e\",{\"2\":{\"655\":1}}],[\"最优策略=arg⁡max⁡策略e\",{\"2\":{\"655\":1}}],[\"最优策略\",{\"2\":{\"655\":1,\"659\":1,\"767\":1}}],[\"最优模型=arg模型min​e\",{\"2\":{\"655\":1}}],[\"最优模型=arg⁡min⁡模型e\",{\"2\":{\"655\":1}}],[\"最优模型\",{\"2\":{\"655\":1}}],[\"最优贝尔曼方程\",{\"2\":{\"647\":1}}],[\"最大内部产品搜索\",{\"0\":{\"2102\":1},\"1\":{\"2152\":1,\"2195\":1,\"2234\":1},\"2\":{\"2102\":1}}],[\"最大截断范围\",{\"2\":{\"1499\":1}}],[\"最大参数数量\",{\"2\":{\"1395\":1}}],[\"最大学习率\",{\"2\":{\"1344\":1}}],[\"最大化gpu的显存节省\",{\"2\":{\"2422\":1}}],[\"最大化reward\",{\"2\":{\"1631\":1}}],[\"最大化\",{\"2\":{\"813\":1}}],[\"最大化智能体策略在奖励函数下的期望\",{\"2\":{\"655\":1}}],[\"最大化累积奖励期望值\",{\"2\":{\"614\":1}}],[\"最大似然估计\",{\"2\":{\"123\":1}}],[\"最小截断范围\",{\"2\":{\"1499\":1}}],[\"最小\",{\"2\":{\"471\":1}}],[\"最小化gpu\",{\"2\":{\"2422\":1}}],[\"最小化损失函数以优化策略\",{\"2\":{\"1784\":1}}],[\"最小化\",{\"2\":{\"32\":1}}],[\"最终\",{\"2\":{\"2528\":1}}],[\"最终我们得到\",{\"2\":{\"2528\":1}}],[\"最终方案\",{\"2\":{\"2300\":1}}],[\"最终可以覆盖所有前置tokens\",{\"2\":{\"2260\":1}}],[\"最终完成整个任务\",{\"2\":{\"2089\":1}}],[\"最终答案的计算过程基于\",{\"2\":{\"2042\":1}}],[\"最终得分为所有查询得分之和\",{\"2\":{\"1644\":1}}],[\"最终达到256k\",{\"2\":{\"1256\":1}}],[\"最终阶段扩展至32k\",{\"2\":{\"1256\":1,\"1305\":1}}],[\"最终进行加权采样\",{\"2\":{\"473\":1}}],[\"最终形成一个高效的紧凑型词表\",{\"2\":{\"471\":1}}],[\"最终构建一个高效且覆盖全面的词表\",{\"2\":{\"343\":1}}],[\"最终调整为11008\",{\"2\":{\"220\":1}}],[\"最终影响效果\",{\"2\":{\"170\":1}}],[\"最终效果通常不如post\",{\"2\":{\"169\":1}}],[\"对yyy的每一行做softmax运算\",{\"2\":{\"2660\":1}}],[\"对显存的压力不大\",{\"2\":{\"2651\":1}}],[\"对应计算\",{\"2\":{\"2609\":1}}],[\"对应的把xxx按照列切分成两部分\",{\"2\":{\"2537\":1}}],[\"对应的梯度约为\",{\"2\":{\"2281\":1}}],[\"对应的推理过程和答案\",{\"2\":{\"1940\":1}}],[\"对应的词向量\",{\"2\":{\"996\":1}}],[\"对蒸馏模型应用强化学习能够带来显著的进一步提升\",{\"2\":{\"2603\":1}}],[\"对数据集进行动态采样\",{\"2\":{\"2519\":1}}],[\"对数据进行划分\",{\"2\":{\"51\":1}}],[\"对这些信息进行增强\",{\"2\":{\"2514\":1}}],[\"对计算资源和处理能力有更高要求\",{\"2\":{\"2512\":1}}],[\"对检索出来的文档库进行重排序\",{\"2\":{\"2484\":1}}],[\"对输入长度有严格限制\",{\"2\":{\"2483\":1}}],[\"对输入序列长度进行切分\",{\"2\":{\"502\":1}}],[\"对话轮数\",{\"2\":{\"2482\":1}}],[\"对话系统训练\",{\"2\":{\"2223\":2}}],[\"对话系统\",{\"2\":{\"34\":1}}],[\"对人类来说仍然有意义\",{\"2\":{\"2364\":1}}],[\"对人类来说看似相同的两个问题\",{\"2\":{\"1663\":1}}],[\"对同一问题进行多组输出采样\",{\"2\":{\"2337\":1}}],[\"对同一任务进行多次执行\",{\"2\":{\"2037\":1}}],[\"对联\",{\"2\":{\"2223\":1}}],[\"对文档上下文的理解\",{\"2\":{\"2197\":1}}],[\"对文本进行初步切分\",{\"2\":{\"2141\":1}}],[\"对文本进行适当的分词处理\",{\"2\":{\"929\":1}}],[\"对文本进行清理和格式化\",{\"2\":{\"480\":1}}],[\"对向量\",{\"2\":{\"2130\":1}}],[\"对反馈内容进行反思\",{\"2\":{\"2113\":1}}],[\"对某个块\",{\"2\":{\"2085\":1}}],[\"对预训练的参数没有影响\",{\"2\":{\"2062\":1}}],[\"对平滑后的激活值和权重进行量化即可\",{\"2\":{\"2033\":1}}],[\"对其做高精度的矩阵乘法\",{\"2\":{\"1982\":1}}],[\"对其进行量化处理的一种方法\",{\"2\":{\"1260\":1}}],[\"对离群特征的几个维度保留16bit\",{\"2\":{\"1982\":1}}],[\"对绝大部分权重和激活用8比特量化\",{\"2\":{\"1982\":1}}],[\"对pdf信息进行抽取\",{\"2\":{\"1948\":1}}],[\"对硬件资源要求低\",{\"2\":{\"1932\":1}}],[\"对方向矩阵vvv应用lora处理\",{\"2\":{\"1890\":1}}],[\"对方向矩阵vvv应用lora技术\",{\"2\":{\"1770\":1}}],[\"对late\",{\"2\":{\"1843\":1}}],[\"对专家输出进行加权聚合\",{\"2\":{\"1822\":1}}],[\"对不同模型的探索能力进行了对比分析\",{\"2\":{\"1819\":1}}],[\"对整个模型进行参数调整以提高性能的方法\",{\"2\":{\"1794\":1}}],[\"对唯一的logit进行解码得到新生成的token\",{\"2\":{\"1782\":1}}],[\"对样本中的各个token分别进行路由\",{\"2\":{\"1762\":1}}],[\"对各个样本分别进行路由\",{\"2\":{\"1762\":1}}],[\"对系统行为决策的权重\",{\"2\":{\"1672\":1}}],[\"对一条轨迹中的所有状态动作对进行奖励加和\",{\"2\":{\"1634\":1}}],[\"对小模型的影响\",{\"2\":{\"1629\":1}}],[\"对任务的处理程度\",{\"2\":{\"1544\":1}}],[\"对训练效率的影响\",{\"2\":{\"1482\":1}}],[\"对训练顺序进行设计与验证\",{\"2\":{\"599\":1}}],[\"对抗性仿真器\",{\"2\":{\"1407\":1}}],[\"对知识文档进行基本的数据清理是必不可少的一步\",{\"2\":{\"1331\":1}}],[\"对语义的准确性具有很高的保障\",{\"2\":{\"1321\":1}}],[\"对候选示例集中的每个示例进行评估\",{\"2\":{\"1075\":1}}],[\"对负样本选择质量依赖较高\",{\"2\":{\"1023\":1}}],[\"对激活进行量化\",{\"2\":{\"1022\":1}}],[\"对多个开源数据集进行改造\",{\"2\":{\"1368\":1}}],[\"对多个词向量进行叠加平均\",{\"2\":{\"938\":1}}],[\"对多语言文本未使用unicode处理\",{\"2\":{\"576\":1}}],[\"对batch中每一条数据进行上面的操作\",{\"2\":{\"917\":1}}],[\"对长期收益的影响\",{\"2\":{\"879\":1}}],[\"对称量化可以避免量化算子在推理中计算\",{\"2\":{\"868\":1}}],[\"对齐问题和文档块之间的语义差异\",{\"2\":{\"2484\":1}}],[\"对齐训练是为了让大模型输出与人类的偏好保持一致\",{\"2\":{\"967\":1}}],[\"对齐训练技术\",{\"0\":{\"967\":1}}],[\"对齐训练\",{\"2\":{\"859\":1}}],[\"对齐税\",{\"2\":{\"805\":1,\"875\":1}}],[\"对回报的影响\",{\"2\":{\"856\":1}}],[\"对剪枝后的模型进行微调\",{\"2\":{\"795\":1}}],[\"对技术人员提出更高要求\",{\"2\":{\"701\":1}}],[\"对每个子问题进行回答\",{\"2\":{\"2546\":1}}],[\"对每个\",{\"2\":{\"2043\":2}}],[\"对每个特定下游任务的标量向量进行微调\",{\"2\":{\"1588\":1}}],[\"对每个序列进行迭代\",{\"2\":{\"646\":1}}],[\"对每个聚类簇计算权重\",{\"2\":{\"446\":1}}],[\"对低资源语言可能需要额外优化\",{\"2\":{\"610\":1}}],[\"对高质量\",{\"2\":{\"598\":1}}],[\"对高频和低频区域分别进行外推和内插优化\",{\"2\":{\"359\":1}}],[\"对召回数据进行人工标注\",{\"2\":{\"532\":1}}],[\"对字符串进行标准化\",{\"2\":{\"480\":1}}],[\"对损失值进行缩放处理\",{\"2\":{\"435\":1}}],[\"对前缀处理效果不佳\",{\"2\":{\"434\":1}}],[\"对拼写错误敏感\",{\"2\":{\"434\":1}}],[\"对模型进行了张量维度和流水线维度的分片\",{\"2\":{\"2129\":1}}],[\"对模型进行微调\",{\"2\":{\"826\":1}}],[\"对模型的所有参数进行重新训练\",{\"2\":{\"1983\":1}}],[\"对模型性能的影响\",{\"2\":{\"361\":1,\"597\":1}}],[\"对模型训练稳定性和性能的影响\",{\"2\":{\"128\":1}}],[\"对复杂激活函数的支持情况\",{\"2\":{\"334\":1}}],[\"对比按照行列切分权重的方法\",{\"0\":{\"2595\":1},\"1\":{\"2602\":1,\"2609\":1}}],[\"对比\",{\"2\":{\"1587\":1}}],[\"对比学习的损失函数\",{\"0\":{\"1671\":1}}],[\"对比学习的目标\",{\"2\":{\"1566\":1}}],[\"对比学习\",{\"2\":{\"1473\":1,\"1517\":1,\"1521\":1}}],[\"对比学习角度理解dpo\",{\"0\":{\"1428\":1},\"1\":{\"1473\":1,\"1517\":1,\"1566\":1,\"1616\":1,\"1671\":1,\"1727\":1,\"1784\":1,\"1845\":1,\"1902\":1},\"2\":{\"151\":1}}],[\"对比deberta与其他主流模型\",{\"2\":{\"1381\":1}}],[\"对比fasttext与其他深度学习模型\",{\"2\":{\"1307\":1}}],[\"对比独热编码与其他词向量表示方法\",{\"2\":{\"1212\":1}}],[\"对比value\",{\"2\":{\"821\":1}}],[\"对比多种pdf解析工具的性能\",{\"2\":{\"737\":1}}],[\"对比不同中文大模型在实际任务中的表现\",{\"2\":{\"1800\":1}}],[\"对比不同分词工具在特定任务上的性能\",{\"2\":{\"645\":1}}],[\"对比不同激活函数在transformer架构中的表现\",{\"2\":{\"334\":1}}],[\"对所有维度进行缩放时\",{\"2\":{\"312\":1}}],[\"对较小输入饱和至负值\",{\"2\":{\"285\":1}}],[\"对rope嵌入重复计算\",{\"2\":{\"276\":1}}],[\"对于社交媒体帖子等短文本\",{\"2\":{\"2655\":1}}],[\"对于positional\",{\"2\":{\"2651\":1}}],[\"对于第二个mlp使用行并行\",{\"2\":{\"2609\":1}}],[\"对于语义分析和上下文相关性要求较高的任务更为适合\",{\"2\":{\"2592\":1}}],[\"对于语义密集或结构复杂的文本\",{\"2\":{\"2576\":1}}],[\"对于具有强时效性的场景\",{\"2\":{\"2529\":1}}],[\"对于具身智能和游戏等场景\",{\"2\":{\"1701\":1}}],[\"对于每一个块\",{\"2\":{\"2565\":1,\"2573\":1}}],[\"对于每一块权重\",{\"2\":{\"2636\":1}}],[\"对于每一块\",{\"2\":{\"2528\":1}}],[\"对于每个生成答案\",{\"2\":{\"2436\":1}}],[\"对于每个response\",{\"2\":{\"2007\":1}}],[\"对于每个prompt\",{\"2\":{\"2007\":1}}],[\"对于每个问题\",{\"2\":{\"1576\":1}}],[\"对于每个序列\",{\"2\":{\"789\":1}}],[\"对于非线性层\",{\"2\":{\"2526\":1}}],[\"对于需要进行补充搜索或调用外部api工具的场景\",{\"2\":{\"2518\":1}}],[\"对于数据并行的限制\",{\"2\":{\"2489\":1}}],[\"对于数学问题\",{\"2\":{\"1797\":1}}],[\"对于生成答案的评估\",{\"2\":{\"2411\":1}}],[\"对于无法放进单个\",{\"2\":{\"2374\":1}}],[\"对于意图分流中的分类任务\",{\"2\":{\"2354\":1}}],[\"对于成本敏感或中文数据为主的场景\",{\"2\":{\"2210\":1}}],[\"对于多轮对话场景\",{\"2\":{\"2166\":1}}],[\"对于多语言任务\",{\"2\":{\"1210\":1}}],[\"对于多语言预训练模型\",{\"2\":{\"785\":1}}],[\"对于创作类任务\",{\"2\":{\"2163\":1}}],[\"对于输入token\",{\"2\":{\"2140\":1}}],[\"对于包含多个考虑因素的复杂任务\",{\"2\":{\"2037\":1}}],[\"对于self\",{\"2\":{\"2027\":1}}],[\"对于后续每个token的推理延迟\",{\"2\":{\"2014\":1}}],[\"对于预训练权重矩阵可以用一个低秩分解来表示参数更新\",{\"2\":{\"2013\":1}}],[\"对于中文处理\",{\"2\":{\"2002\":1}}],[\"对于nv新的a\",{\"2\":{\"1843\":1}}],[\"对于格式较为复杂的pdf文档\",{\"2\":{\"1834\":1}}],[\"对于权重而言\",{\"2\":{\"1813\":1}}],[\"对于结构化较好的文档\",{\"2\":{\"1773\":1}}],[\"对于复杂问题\",{\"2\":{\"1708\":1}}],[\"对于对比学习\",{\"2\":{\"1671\":1}}],[\"对于长篇文章或书籍\",{\"2\":{\"2655\":1}}],[\"对于长度超出限制的chunk\",{\"2\":{\"1561\":1}}],[\"对于长序列任务\",{\"2\":{\"362\":1}}],[\"对于一个gemms\",{\"2\":{\"2526\":1}}],[\"对于一个问题可能需要依赖多个子问题的情况\",{\"2\":{\"1835\":1}}],[\"对于一个锚样本\",{\"2\":{\"1566\":1}}],[\"对于一个任务\",{\"2\":{\"1544\":1}}],[\"对于一些高层次的问题\",{\"2\":{\"2196\":1}}],[\"对于一些经常更新的主题\",{\"2\":{\"1558\":1}}],[\"对于一些实时性的\",{\"2\":{\"1423\":1}}],[\"对于一些特定的应用场景\",{\"2\":{\"1260\":1}}],[\"对于模型生成的内容\",{\"2\":{\"1540\":1}}],[\"对于两个智能体轨迹片段\",{\"2\":{\"1536\":1}}],[\"对于企业而言\",{\"2\":{\"1512\":1}}],[\"对于写小说的任务\",{\"2\":{\"1420\":1}}],[\"对于不擅长编程或希望快速搭建系统的用户来说\",{\"2\":{\"1347\":1}}],[\"对于不同类别的数据\",{\"2\":{\"525\":1}}],[\"对于查询\",{\"2\":{\"1332\":1}}],[\"对于知识图谱场景\",{\"2\":{\"1268\":1}}],[\"对于操作系统\",{\"2\":{\"1268\":1}}],[\"对于llm的性能\",{\"2\":{\"2085\":1}}],[\"对于llm来说\",{\"2\":{\"1124\":1}}],[\"对于llama模型\",{\"2\":{\"184\":1,\"276\":1}}],[\"对于类别数量过多的数据直接使用独热编码会导致维度爆炸\",{\"2\":{\"1113\":1}}],[\"对于未在训练中出现的词汇\",{\"2\":{\"1079\":1}}],[\"对于激活值来说还有动态量化\",{\"2\":{\"1022\":1}}],[\"对于目标词\",{\"2\":{\"983\":1}}],[\"对于低频词\",{\"2\":{\"941\":1}}],[\"对于低资源语言\",{\"2\":{\"685\":1}}],[\"对于这些问题\",{\"2\":{\"845\":1}}],[\"对于这个prompt的计算和内存可以在输出序列之间共享\",{\"2\":{\"750\":1}}],[\"对于序列中的每一时间步\",{\"2\":{\"778\":1}}],[\"对于特定领域的垂直应用\",{\"2\":{\"635\":1}}],[\"对于\",{\"2\":{\"444\":1,\"1701\":1,\"2308\":1,\"2384\":1,\"2616\":1}}],[\"对于alibi\",{\"2\":{\"338\":1}}],[\"对于偶数维向量\",{\"2\":{\"247\":1}}],[\"对\",{\"2\":{\"247\":1,\"1136\":1,\"2081\":1,\"2349\":1,\"2609\":2,\"2611\":1}}],[\"对swish或gelu公式误解\",{\"2\":{\"243\":1}}],[\"对最低频项\",{\"2\":{\"221\":1}}],[\"对公式误解\",{\"2\":{\"192\":1}}],[\"对kv的压缩过于激进\",{\"2\":{\"170\":1}}],[\"对参数正则化效果更强\",{\"2\":{\"169\":1}}],[\"背包问题\",{\"2\":{\"50\":1}}],[\"医学\",{\"2\":{\"196\":1}}],[\"医学文献等\",{\"2\":{\"155\":1}}],[\"医学诊断\",{\"2\":{\"39\":1}}],[\"医疗领域\",{\"2\":{\"49\":1}}],[\"您的订单预计明天发出\",{\"2\":{\"49\":1}}],[\"您好\",{\"2\":{\"49\":1}}],[\"客服\",{\"2\":{\"49\":1}}],[\"客户细分\",{\"2\":{\"39\":1}}],[\"何时发货\",{\"2\":{\"49\":1}}],[\"订单号\",{\"2\":{\"49\":1}}],[\"用二元相对位置向量\",{\"2\":{\"1266\":1}}],[\"用来训练基于\",{\"2\":{\"2066\":1}}],[\"用来评估系统返回结果与查询的相关性\",{\"2\":{\"1590\":1}}],[\"用来标识不同角色或语义\",{\"2\":{\"1249\":1}}],[\"用来衡量两个词同时出现时的信息增益\",{\"2\":{\"499\":1}}],[\"用零填充未使用的缓存区位置\",{\"2\":{\"1170\":1}}],[\"用一个简单的比喻\",{\"2\":{\"1036\":1}}],[\"用以进一步优化性能\",{\"2\":{\"826\":1}}],[\"用以解决稀有词问题\",{\"2\":{\"319\":1}}],[\"用\",{\"2\":{\"775\":1,\"2286\":3}}],[\"用途\",{\"2\":{\"549\":1}}],[\"用简单的符号和标记描述\",{\"2\":{\"381\":1}}],[\"用于对过长的回答进行惩罚\",{\"2\":{\"2689\":1}}],[\"用于对齐大型语言模型\",{\"2\":{\"1956\":1}}],[\"用于在多个计算节点\",{\"2\":{\"2427\":1}}],[\"用于在切分文本时优先选择合适的位置\",{\"2\":{\"2091\":1}}],[\"用于解决不同类型的强化学习任务\",{\"2\":{\"2378\":1}}],[\"用于决定是否提高当前response中token的生成概率\",{\"2\":{\"2357\":1}}],[\"用于探索开放世界\",{\"2\":{\"2277\":1}}],[\"用于维持正在进行的\",{\"2\":{\"2262\":1}}],[\"用于直接与原始文本拼接\",{\"2\":{\"2032\":1}}],[\"用于处理复杂数据关系\",{\"2\":{\"2024\":1}}],[\"用于处理需要考虑时间维度的问题\",{\"2\":{\"1285\":1}}],[\"用于优化模型性能\",{\"2\":{\"2024\":1}}],[\"用于优化前向传播网络\",{\"2\":{\"467\":1}}],[\"用于衡量当前动作相对于平均动作价值的优劣\",{\"2\":{\"2004\":1}}],[\"用于衡量模型预测与真实标签的偏差\",{\"2\":{\"980\":1}}],[\"用于保持策略不偏离参考标准\",{\"2\":{\"2004\":1}}],[\"用于保留输入信息\",{\"2\":{\"211\":1}}],[\"用于大规模模型训练\",{\"2\":{\"1939\":1}}],[\"用于初始化模型参数\",{\"2\":{\"1866\":1}}],[\"用于避免后续decode过程重复计算这些k\",{\"2\":{\"1782\":1}}],[\"用于提取\",{\"2\":{\"2227\":1}}],[\"用于提高策略梯度方法的效率\",{\"2\":{\"1645\":1}}],[\"用于提升模型的非线性表达能力\",{\"2\":{\"1002\":1}}],[\"用于将原始输出映射为单一值\",{\"2\":{\"1591\":1}}],[\"用于将文本分词\",{\"2\":{\"1002\":1}}],[\"用于更新actor\",{\"2\":{\"1572\":1}}],[\"用于评估和指导模型推理过程的奖励机制\",{\"2\":{\"2647\":1}}],[\"用于评估生成的响应的质量\",{\"2\":{\"1533\":1}}],[\"用于评估模型性能的标准化测试集\",{\"2\":{\"583\":1}}],[\"用于构建tokenizer\",{\"2\":{\"1531\":1}}],[\"用于管理语言模型\",{\"2\":{\"1250\":1}}],[\"用于描述问题并告知大模型的输出格式\",{\"2\":{\"1766\":1}}],[\"用于描述人工智能系统的能力范围和层次\",{\"2\":{\"1188\":1}}],[\"用于描述状态和动作的价值函数之间的关系\",{\"2\":{\"696\":1}}],[\"用于数学任务\",{\"2\":{\"1181\":1}}],[\"用于存储待处理的token\",{\"2\":{\"1170\":1}}],[\"用于定位模型内部的相互依赖结构\",{\"2\":{\"1143\":1}}],[\"用于帮助神经网络学习复杂模式\",{\"2\":{\"970\":1}}],[\"用于区分两个句子\",{\"2\":{\"956\":1}}],[\"用于增强位置编码能力\",{\"2\":{\"889\":1}}],[\"用于实现和测试多种先进的强化学习算法\",{\"2\":{\"2317\":1}}],[\"用于实现知识转移的具体方法\",{\"2\":{\"715\":1}}],[\"用于实际训练\",{\"2\":{\"435\":1}}],[\"用于指导策略优化\",{\"2\":{\"690\":1}}],[\"用于动态调整数据配比和训练顺序\",{\"2\":{\"667\":1}}],[\"用于权衡当前奖励与未来奖励的重要性\",{\"2\":{\"643\":1}}],[\"用于进一步减少计算成本\",{\"2\":{\"629\":1}}],[\"用于小型语料库测试\",{\"2\":{\"597\":1}}],[\"用于子词概率估计\",{\"2\":{\"530\":1}}],[\"用于高效抓取网页内容\",{\"2\":{\"485\":1}}],[\"用于加载和处理数据集\",{\"2\":{\"375\":1}}],[\"用于控制位置偏移的权重\",{\"2\":{\"293\":1}}],[\"用于\",{\"2\":{\"251\":1}}],[\"用于bert等预训练模型\",{\"2\":{\"230\":1}}],[\"用于捕捉输入与输出之间的变化\",{\"2\":{\"211\":1}}],[\"用于展示kv\",{\"2\":{\"208\":1}}],[\"用于引入序列的位置信息\",{\"2\":{\"203\":1}}],[\"用于库存管理\",{\"2\":{\"39\":1}}],[\"用训练好的模型预测新数据\",{\"2\":{\"185\":1}}],[\"用s型函数将\",{\"2\":{\"185\":1}}],[\"用线性方程计算得分\",{\"2\":{\"185\":1}}],[\"用户查询长度及复杂性\",{\"2\":{\"2655\":1}}],[\"用户友好\",{\"2\":{\"2404\":1}}],[\"用户的历史行为等\",{\"2\":{\"2394\":1}}],[\"用户的问题会被输入到embedding模型中进行向量化处理\",{\"2\":{\"2272\":1}}],[\"用户的问题会与子文档进行匹配\",{\"2\":{\"2236\":1}}],[\"用户的查询问题通常被转化为向量\",{\"2\":{\"1610\":1}}],[\"用户设计的库\",{\"2\":{\"2055\":1}}],[\"用户增加排队的时间会很长\",{\"2\":{\"1843\":1}}],[\"用户可能提出的问题等等有助于检索的信息\",{\"2\":{\"2304\":1}}],[\"用户可以直接调用这些功能来实现文本切分\",{\"2\":{\"1776\":1}}],[\"用户可以基于自己的中文语料库训练分句模型\",{\"2\":{\"1719\":1}}],[\"用户可根据需求灵活调整\",{\"2\":{\"1451\":1}}],[\"用户提供的技术文档\",{\"2\":{\"2148\":1}}],[\"用户提问中的某个词可能会指代上文中的部分信息\",{\"2\":{\"1663\":1}}],[\"用户提出的问题质量是影响\",{\"2\":{\"1496\":1}}],[\"用户反馈循环\",{\"0\":{\"1510\":1}}],[\"用户输入\",{\"2\":{\"1420\":1}}],[\"用户通常不会关注每个推荐项目是否绝对最佳匹配\",{\"2\":{\"1377\":1}}],[\"用户\",{\"2\":{\"49\":1}}],[\"微调模型以作为初始策略\",{\"2\":{\"2474\":1}}],[\"微调核心代码\",{\"0\":{\"2400\":1}}],[\"微调的初始化影响与核心代码分析\",{\"0\":{\"2279\":1},\"1\":{\"2311\":1,\"2342\":1,\"2372\":1,\"2400\":1,\"2425\":1,\"2450\":1,\"2471\":1}}],[\"微调过程\",{\"0\":{\"1804\":1}}],[\"微调周期\",{\"2\":{\"1186\":1}}],[\"微调目标函数为\",{\"2\":{\"1142\":1}}],[\"微调7b参数模型进行4个epochs\",{\"2\":{\"1087\":1}}],[\"微调阶段结合了完整输入序列的有监督目标函数和无监督目标函数\",{\"2\":{\"1142\":1}}],[\"微调阶段\",{\"0\":{\"881\":1},\"2\":{\"1288\":1}}],[\"微调\",{\"0\":{\"1142\":1,\"1678\":1,\"1755\":1},\"2\":{\"795\":1,\"826\":1,\"1578\":1,\"1615\":1,\"1624\":1,\"1722\":1,\"1866\":1,\"2134\":1}}],[\"微调步骤是否可以进一步简化\",{\"2\":{\"413\":1}}],[\"微调是提升效果的关键\",{\"2\":{\"336\":1}}],[\"微调不足\",{\"2\":{\"313\":1}}],[\"微调后\",{\"2\":{\"245\":1}}],[\"微调对效果的影响\",{\"0\":{\"245\":1}}],[\"微调时采用提示工程\",{\"2\":{\"49\":1}}],[\"微调训练\",{\"2\":{\"40\":1}}],[\"服务\",{\"2\":{\"49\":1}}],[\"体现了agent在解决问题时的主动性和灵活性\",{\"2\":{\"2363\":1}}],[\"体现了peft的理念\",{\"2\":{\"1695\":1}}],[\"体育\",{\"2\":{\"49\":1}}],[\"体检数据预测疾病类型\",{\"2\":{\"39\":1}}],[\"政治\",{\"2\":{\"49\":1}}],[\"案例\",{\"2\":{\"49\":2}}],[\"整个流程如下\",{\"2\":{\"2636\":1}}],[\"整个过程被看作一个整体\",{\"2\":{\"1673\":1}}],[\"整体来看\",{\"2\":{\"2526\":1}}],[\"整体流程\",{\"0\":{\"1267\":1},\"2\":{\"2220\":1}}],[\"整体训练流程\",{\"2\":{\"934\":1}}],[\"整理自技术文档\",{\"2\":{\"738\":1}}],[\"整理自自然语言处理相关技术文档与代码示例\",{\"2\":{\"453\":1}}],[\"整理自深度学习技术文档和相关研究资料\",{\"2\":{\"282\":1}}],[\"整合说明\",{\"2\":{\"65\":1}}],[\"整合应用案例与最佳实践\",{\"0\":{\"49\":1}}],[\"整数类型\",{\"2\":{\"15\":1}}],[\"三个阶段\",{\"0\":{\"2366\":1}}],[\"三个阶段以及显存占用分析\",{\"0\":{\"2204\":1},\"1\":{\"2241\":1,\"2276\":1,\"2308\":1,\"2339\":1,\"2369\":1,\"2397\":1,\"2422\":1,\"2447\":1,\"2468\":1,\"2486\":1}}],[\"三阶突破架构\",{\"2\":{\"1277\":1}}],[\"三\",{\"0\":{\"49\":1,\"2153\":1},\"1\":{\"2196\":1,\"2235\":1}}],[\"尾节点的处理方法\",{\"2\":{\"48\":1}}],[\"注入特定领域知识或针对长文本进行优化的过程\",{\"2\":{\"475\":1}}],[\"注\",{\"2\":{\"48\":1,\"1619\":1,\"1788\":1,\"1849\":1,\"2188\":1}}],[\"注意调整阈值以提高探索能力\",{\"2\":{\"2414\":1}}],[\"注意初始损失水平\",{\"2\":{\"2206\":1}}],[\"注意避免在实现过程中忽略了io感知的重要性\",{\"2\":{\"2203\":1}}],[\"注意避免偏差\",{\"2\":{\"2200\":1}}],[\"注意区分flops和flops\",{\"0\":{\"1926\":1}}],[\"注意参数设置\",{\"2\":{\"1789\":1}}],[\"注意ppo引入的四个模型对计算资源的需求\",{\"2\":{\"1642\":1}}],[\"注意奖励模型可能被\",{\"2\":{\"1551\":1}}],[\"注意截断范围\",{\"2\":{\"1405\":1}}],[\"注意与word2vec\",{\"2\":{\"1337\":1}}],[\"注意学习率衰减策略\",{\"2\":{\"1298\":1}}],[\"注意在选择专家组合时\",{\"2\":{\"1881\":1}}],[\"注意在allreduce过程中确保所有gpu同步更新梯度\",{\"2\":{\"1547\":1}}],[\"注意在数据去重和召回过程中\",{\"2\":{\"1383\":1}}],[\"注意在实现sparse\",{\"2\":{\"1325\":1}}],[\"注意在强化学习过程中可能出现的可读性低\",{\"2\":{\"1295\":1}}],[\"注意在设置expert\",{\"2\":{\"1270\":1}}],[\"注意不要过度依赖损坏文本\",{\"2\":{\"1189\":1}}],[\"注意其方差较大\",{\"2\":{\"689\":1}}],[\"注意事项\",{\"2\":{\"335\":1,\"348\":1,\"566\":1,\"1632\":1,\"1771\":1,\"2233\":1}}],[\"注意\",{\"2\":{\"287\":1,\"485\":1,\"525\":1,\"568\":1,\"856\":1,\"938\":1,\"1237\":1,\"1258\":1,\"1371\":1,\"1777\":1,\"1821\":1,\"2126\":1,\"2146\":1,\"2191\":1,\"2215\":1,\"2249\":1,\"2355\":1,\"2480\":1,\"2496\":1}}],[\"注意两者的输入来源不同\",{\"2\":{\"209\":1}}],[\"注意力计算流程是矩阵乘法\",{\"2\":{\"1872\":1}}],[\"注意力计算范围\",{\"2\":{\"197\":1}}],[\"注意力头数量\",{\"2\":{\"259\":1}}],[\"注意力加权到值块上\",{\"2\":{\"135\":1}}],[\"注意力机制是核心组件之一\",{\"2\":{\"111\":1}}],[\"注意力机制\",{\"2\":{\"28\":1,\"34\":1,\"44\":1,\"74\":1,\"87\":1,\"96\":1,\"142\":1,\"595\":1,\"1017\":1,\"2225\":1}}],[\"注意链表遍历的写法\",{\"2\":{\"48\":1}}],[\"注意返回类型和接受类型在函数声明中\",{\"2\":{\"11\":1}}],[\"jpij​vj​\",{\"2\":{\"2611\":1}}],[\"jd−\",{\"2\":{\"2581\":2,\"2597\":2}}],[\"j−m\",{\"2\":{\"2528\":2}}],[\"j−1\",{\"2\":{\"290\":2}}],[\"j+e−m\",{\"2\":{\"2528\":3}}],[\"j+exp⁡\",{\"2\":{\"2528\":1}}],[\"j+1​\",{\"2\":{\"2528\":2}}],[\"j+1​=softmax\",{\"2\":{\"2528\":1}}],[\"j+1​v\",{\"2\":{\"2528\":1}}],[\"j+1o\",{\"2\":{\"2528\":1}}],[\"j+1=softmax\",{\"2\":{\"2528\":1}}],[\"j+1v\",{\"2\":{\"2528\":1}}],[\"j+1\",{\"2\":{\"2528\":63}}],[\"j++\",{\"2\":{\"47\":1}}],[\"j|\",{\"2\":{\"2033\":2}}],[\"jsj​\",{\"2\":{\"2033\":1}}],[\"json\",{\"2\":{\"1458\":1}}],[\"j=2\",{\"0\":{\"2475\":1}}],[\"j=1\",{\"0\":{\"2456\":1},\"2\":{\"1925\":1}}],[\"j=0\",{\"2\":{\"1901\":1}}],[\"j=softmax\",{\"2\":{\"1266\":1}}],[\"j∈m\",{\"2\":{\"1901\":1}}],[\"j∈mb\",{\"2\":{\"1901\":1}}],[\"joining\",{\"2\":{\"1843\":2}}],[\"jericho\",{\"2\":{\"1819\":1}}],[\"jgrpo​\",{\"2\":{\"1628\":1,\"2485\":1,\"2577\":1}}],[\"jgrpo\",{\"2\":{\"1628\":1,\"2485\":1,\"2577\":1}}],[\"judge评估机制以提高候选响应质量\",{\"2\":{\"2174\":1}}],[\"judge机制评估这些候选响应的质量\",{\"2\":{\"1924\":1}}],[\"judge\",{\"2\":{\"1309\":1}}],[\"jurafsky\",{\"2\":{\"67\":1}}],[\"jvj​\",{\"2\":{\"2286\":3,\"2565\":1}}],[\"jv​\",{\"2\":{\"1266\":1}}],[\"jv\",{\"2\":{\"1266\":1,\"2528\":1}}],[\"j$$\",{\"2\":{\"1207\":1,\"1258\":3,\"1353\":1}}],[\"j​v\",{\"2\":{\"2528\":1}}],[\"j​+e−m\",{\"2\":{\"2528\":3}}],[\"j​+exp\",{\"2\":{\"2528\":1}}],[\"j​−m\",{\"2\":{\"2528\":2}}],[\"j​=softmax\",{\"2\":{\"1266\":1}}],[\"j​\",{\"2\":{\"1207\":1,\"1266\":1,\"2528\":3}}],[\"j^t\",{\"2\":{\"2643\":2}}],[\"j^tkjt​\",{\"2\":{\"2286\":3}}],[\"j^i\",{\"2\":{\"1901\":3}}],[\"j^\",{\"2\":{\"1207\":1,\"1359\":3}}],[\"jx\",{\"2\":{\"1207\":1}}],[\"jkj​\",{\"2\":{\"2565\":1}}],[\"jk​\",{\"2\":{\"1266\":1}}],[\"jk​+rj\",{\"2\":{\"1187\":1}}],[\"jk\",{\"2\":{\"1266\":1}}],[\"jk+rj\",{\"2\":{\"1187\":1}}],[\"javascript\",{\"2\":{\"2640\":1}}],[\"java\",{\"2\":{\"2408\":1}}],[\"jaccard\",{\"2\":{\"2051\":1}}],[\"jake\",{\"2\":{\"302\":1}}],[\"james\",{\"2\":{\"67\":1}}],[\"jieba\",{\"2\":{\"278\":1}}],[\"j\",{\"2\":{\"47\":2,\"290\":3,\"586\":1,\"622\":1,\"723\":1,\"757\":1,\"1187\":4,\"1207\":2,\"1258\":1,\"1266\":9,\"1353\":1,\"1359\":2,\"1364\":2,\"1405\":1,\"1628\":1,\"1658\":1,\"1901\":3,\"1925\":1,\"2033\":1,\"2406\":1,\"2485\":1,\"2528\":34,\"2539\":5,\"2565\":3,\"2577\":1,\"2581\":2,\"2597\":2,\"2618\":2,\"2643\":2}}],[\">p\",{\"2\":{\"1912\":1}}],[\">prefix\",{\"2\":{\"1912\":1}}],[\">=\",{\"2\":{\"769\":1}}],[\">bne\",{\"2\":{\"189\":1}}],[\">bde\",{\"2\":{\"189\":1}}],[\">val\",{\"2\":{\"48\":4}}],[\">next\",{\"2\":{\"47\":4,\"48\":5}}],[\">\",{\"2\":{\"47\":2,\"647\":2,\"1225\":9,\"1622\":2,\"1731\":2,\"1817\":2,\"1883\":1,\"1928\":1,\"2500\":1,\"2539\":1}}],[\"研究多次更新epoch对样本效率的影响\",{\"2\":{\"2607\":1}}],[\"研究多卡并行策略以进一步降低显存消耗\",{\"2\":{\"2214\":1}}],[\"研究remax算法在不同大模型上的应用效果\",{\"2\":{\"2508\":1,\"2521\":1}}],[\"研究rl在多语言nlp任务中的应用\",{\"2\":{\"818\":1}}],[\"研究\",{\"2\":{\"2451\":1}}],[\"研究flashattention在不同模型中的应用效果\",{\"2\":{\"2275\":1}}],[\"研究fasttext与word2vec\",{\"2\":{\"1475\":1}}],[\"研究lora与其他微调方法\",{\"2\":{\"2244\":1}}],[\"研究llama1在特定任务中的表现\",{\"2\":{\"1310\":1}}],[\"研究人员可能需要从不同数据库中提取相关数据\",{\"2\":{\"2185\":1}}],[\"研究人员提出了多种模型压缩技术\",{\"2\":{\"763\":1}}],[\"研究peft方法在不同模型上的应用效果\",{\"2\":{\"2182\":1}}],[\"研究ppo在多智能体系统中的应用\",{\"2\":{\"864\":1}}],[\"研究deepspeed的最新更新与优化功能\",{\"2\":{\"2380\":1}}],[\"研究dapo在不同任务上的适用性\",{\"2\":{\"2093\":1}}],[\"研究dpo在不同任务中的应用效果\",{\"2\":{\"1814\":1}}],[\"研究vera在不同模型架构中的应用效果\",{\"2\":{\"2075\":1}}],[\"研究去掉critic\",{\"2\":{\"2053\":1}}],[\"研究adalora在不同任务中的表现\",{\"2\":{\"2040\":1}}],[\"研究actor\",{\"2\":{\"822\":1}}],[\"研究混合提示对其他语言模型的适用性\",{\"2\":{\"2019\":1}}],[\"研究qlora在其他类型模型中的应用潜力\",{\"2\":{\"2015\":1}}],[\"研究行为约束对长期策略稳定性的影响\",{\"2\":{\"2003\":1}}],[\"研究零初始化策略在其他机器学习模型中的应用潜力\",{\"2\":{\"1953\":1}}],[\"研究mdp建模与强化学习在其他领域的应用\",{\"2\":{\"1952\":1}}],[\"研究moe技术在不同应用场景中的表现\",{\"2\":{\"1651\":1}}],[\"研究了多种后训练方法\",{\"2\":{\"1917\":1}}],[\"研究了交互步骤数与处理率之间的关系\",{\"2\":{\"1701\":1}}],[\"研究选用了以下最先进的推理模型进行基准测试\",{\"2\":{\"1917\":1}}],[\"研究和应用更有效的防止过拟合的方法\",{\"2\":{\"1709\":1}}],[\"研究继续预训练策略对不同类型数据集的影响\",{\"2\":{\"1528\":1}}],[\"研究未绑定嵌入对不同任务性能的影响\",{\"2\":{\"1444\":1}}],[\"研究负载均衡损失对模型性能的影响\",{\"2\":{\"1417\":1}}],[\"研究蒸馏技术在其他领域的潜力\",{\"2\":{\"1387\":1}}],[\"研究位置编码可训练性的影响\",{\"2\":{\"1385\":1}}],[\"研究sparse\",{\"2\":{\"1370\":1}}],[\"研究gshard在不同任务上的性能表现\",{\"2\":{\"1363\":1}}],[\"研究glm1的应用场景\",{\"2\":{\"1239\":1}}],[\"研究者通常会对英文模型进行二次预训练\",{\"2\":{\"1349\":1}}],[\"研究更多启发式规则以优化\",{\"2\":{\"2453\":1}}],[\"研究更多关于token\",{\"2\":{\"2629\":1,\"2674\":1}}],[\"研究更多关于causal\",{\"2\":{\"2510\":1}}],[\"研究更多关于grpo的方法与应用\",{\"2\":{\"2199\":1}}],[\"研究更多关于sft模型在不同领域应用中的效果\",{\"2\":{\"1961\":1}}],[\"研究更多关于对比学习和dpo的文献\",{\"2\":{\"1902\":1}}],[\"研究更多关于对齐税的影响因素\",{\"2\":{\"1274\":1}}],[\"研究更多激活函数对模型性能的影响\",{\"2\":{\"1339\":1}}],[\"研究其他任务中soft\",{\"2\":{\"2701\":1}}],[\"研究其他领域的冷启动应用\",{\"2\":{\"2556\":1}}],[\"研究其他加速计算的方法\",{\"2\":{\"2464\":1}}],[\"研究其他可能影响token生成的参数\",{\"2\":{\"2461\":1}}],[\"研究其他moe模型的优化策略\",{\"2\":{\"2038\":1}}],[\"研究其他对比学习方法与dpo结合的效果\",{\"2\":{\"1907\":1}}],[\"研究其他预训练模型与bert的比较\",{\"2\":{\"1177\":1}}],[\"研究其他强化学习算法与其结合的可能性\",{\"2\":{\"912\":1}}],[\"研究结果显示\",{\"2\":{\"1152\":1}}],[\"研究结合深度学习的价值迭代方法\",{\"2\":{\"647\":1}}],[\"研究bart在其他nlp任务中的应用潜力\",{\"2\":{\"1144\":1}}],[\"研究贡献\",{\"0\":{\"1097\":1},\"1\":{\"1146\":1,\"1195\":1}}],[\"研究内容\",{\"0\":{\"1053\":1}}],[\"研究chatglm在长文本处理上的应用潜力\",{\"2\":{\"1008\":1}}],[\"研究蒙特卡洛方法在高维数据中的应用\",{\"2\":{\"993\":1}}],[\"研究贝尔曼方程在多智能体系统中的扩展\",{\"2\":{\"979\":1}}],[\"研究tdpo在不同任务中的表现\",{\"2\":{\"1880\":1}}],[\"研究target\",{\"2\":{\"842\":1}}],[\"研究top\",{\"2\":{\"510\":1}}],[\"研究并实现swiglu激活函数的具体应用\",{\"2\":{\"1527\":1}}],[\"研究并实施pre\",{\"2\":{\"1287\":1}}],[\"研究并尝试使用bert或fasttext进行打分器微调\",{\"2\":{\"816\":1}}],[\"研究并选择合适的api网关解决方案\",{\"2\":{\"242\":1}}],[\"研究不同任务下的最佳\",{\"2\":{\"2219\":1}}],[\"研究不同模型结构下prefix\",{\"2\":{\"2215\":1}}],[\"研究不同预训练语言模型对自我奖励训练效果的影响\",{\"2\":{\"2174\":1}}],[\"研究不同reward\",{\"2\":{\"1921\":1}}],[\"研究不同环境下的mdp建模方法\",{\"2\":{\"1034\":1}}],[\"研究不同参数设置对sarsa算法收敛性的影响\",{\"2\":{\"886\":1}}],[\"研究不同tokenizer对困惑度的影响\",{\"2\":{\"819\":1}}],[\"研究不同变体的td算法\",{\"2\":{\"815\":1}}],[\"研究不同类型的奖励机制对策略优化的影响\",{\"2\":{\"807\":1}}],[\"研究动态掩码策略对模型性能的影响\",{\"2\":{\"1294\":1}}],[\"研究动态规划在随机环境中的扩展\",{\"2\":{\"824\":1}}],[\"研究动态\",{\"2\":{\"765\":1}}],[\"研究如何更高效地实现多轮对话数据飞轮机制\",{\"2\":{\"2457\":1}}],[\"研究如何提高采样组的数量和质量\",{\"2\":{\"2421\":1}}],[\"研究如何结合更多数据源进行多维度评估\",{\"2\":{\"2391\":1}}],[\"研究如何结合预训练模型\",{\"2\":{\"1261\":1}}],[\"研究如何将rloo应用于其他类型的强化学习问题\",{\"2\":{\"2159\":1}}],[\"研究如何将dqn应用于实时决策系统\",{\"2\":{\"913\":1}}],[\"研究如何优化奖励机制以提高模型性能\",{\"2\":{\"2111\":1}}],[\"研究如何优化特殊标记符的使用以提升模型性能\",{\"2\":{\"1438\":1}}],[\"研究如何在不同领域应用数据飞轮\",{\"2\":{\"2434\":1}}],[\"研究如何在不同nlp任务中应用rl\",{\"2\":{\"755\":1}}],[\"研究如何在现有项目中集成\",{\"2\":{\"2017\":1}}],[\"研究如何降低人类反馈成本\",{\"2\":{\"1863\":1}}],[\"研究如何进一步优化偏好标签收集过程\",{\"2\":{\"1861\":1}}],[\"研究如何进一步优化多语言处理能力\",{\"2\":{\"1406\":1}}],[\"研究如何进一步优化prompt设计以提高zero\",{\"2\":{\"1350\":1}}],[\"研究如何进一步优化专家模块分割策略\",{\"2\":{\"1271\":1}}],[\"研究如何有效地结合不同类型的数据集以提升ai应用的广泛性\",{\"2\":{\"2459\":1}}],[\"研究如何有效地将其他自然语言处理任务转化为文本到文本形式\",{\"2\":{\"1257\":1}}],[\"研究如何有效设置kl散度的惩罚系数\",{\"2\":{\"709\":1}}],[\"研究如何动态调整行为和目标策略\",{\"2\":{\"892\":1}}],[\"研究如何选择合适的基线来降低方差\",{\"2\":{\"759\":1}}],[\"研究损失缩放算法的具体实现机制及其对不同任务的适配性\",{\"2\":{\"698\":1}}],[\"研究计划\",{\"2\":{\"385\":1,\"414\":1,\"555\":1}}],[\"研究新型硬件架构对推理速度的影响\",{\"2\":{\"683\":1}}],[\"研究新型硬件\",{\"2\":{\"334\":1}}],[\"研究新的认证协议以优化现有集成\",{\"2\":{\"265\":1}}],[\"研究趋势\",{\"2\":{\"256\":1}}],[\"研究方法与算法描述文档\",{\"2\":{\"1811\":1}}],[\"研究方向\",{\"2\":{\"240\":1,\"1263\":1}}],[\"研究方案\",{\"2\":{\"45\":1}}],[\"研究最新的llm论文\",{\"2\":{\"153\":1}}],[\"研究目标\",{\"0\":{\"1687\":1},\"2\":{\"45\":1}}],[\"研究背景与内容\",{\"0\":{\"972\":1},\"1\":{\"1013\":1,\"1053\":1}}],[\"研究背景\",{\"0\":{\"1013\":1,\"1633\":1},\"2\":{\"45\":1}}],[\"它能够帮助我们根据时间顺序对搜索结果进行筛选\",{\"2\":{\"2672\":1}}],[\"它能够获取更多信息或进行关键决策\",{\"2\":{\"1501\":1}}],[\"它包含以下三个组件\",{\"2\":{\"2601\":1}}],[\"它包括单一信息检索\",{\"2\":{\"492\":1}}],[\"它被我们切成了两部分\",{\"2\":{\"2492\":1}}],[\"它被广泛用于自然语言处理\",{\"2\":{\"319\":1}}],[\"它持有着多个\",{\"2\":{\"2433\":1}}],[\"它代表了一个模型整体\",{\"2\":{\"2433\":1}}],[\"它主要分为三个步骤\",{\"2\":{\"2365\":1}}],[\"它主要作用是在分布式计算中减少通信开销\",{\"2\":{\"799\":1}}],[\"它结合了reinforce方法和最大化策略\",{\"2\":{\"2328\":1,\"2359\":1}}],[\"它结合了蒙特卡洛和动态规划的思想\",{\"2\":{\"574\":1}}],[\"它需要为每个参数维护momentum和variance状态\",{\"2\":{\"2192\":1}}],[\"它只是分块计算\",{\"2\":{\"2057\":1}}],[\"它提供了一种简单且灵活的方式来加速和扩展您的\",{\"2\":{\"2055\":1}}],[\"它利用了模型在不同推理路径中的多样性\",{\"2\":{\"2042\":1}}],[\"它利用贝尔曼方程的思想\",{\"2\":{\"608\":1}}],[\"它是检索到的相关文档数量与数据库中相关文档的总数之比\",{\"2\":{\"1984\":1}}],[\"它指的是对原始刺激的感官印象\",{\"2\":{\"1947\":1}}],[\"它就达到了\",{\"2\":{\"1904\":1}}],[\"它就进入了状态机\",{\"2\":{\"1847\":1}}],[\"它直接影响策略学习的效率和效果\",{\"2\":{\"1765\":1}}],[\"它不仅仅是简单地生成回答\",{\"2\":{\"2363\":1}}],[\"它不仅决定了系统能否快速\",{\"2\":{\"1235\":1}}],[\"它不需要改变预训练模型的参数\",{\"2\":{\"1752\":1}}],[\"它在提高检索效率和优化搜索结果方面起着关键作用\",{\"2\":{\"2669\":1}}],[\"它在策略梯度的基础上进行改进\",{\"2\":{\"2388\":1,\"2416\":1}}],[\"它在训练过程中只更新prefix部分的参数\",{\"2\":{\"1745\":1}}],[\"它在文本生成任务中表现优异\",{\"2\":{\"897\":1}}],[\"它根据输入内容的特征\",{\"2\":{\"1728\":1}}],[\"它根据输入数据特性动态选择最优专家组合\",{\"2\":{\"1704\":1}}],[\"它具备了初步的\",{\"2\":{\"1728\":1}}],[\"它具备以下几个显著特点\",{\"2\":{\"1560\":1}}],[\"它还可以无缝集成\",{\"2\":{\"2590\":1}}],[\"它还能解决数据时效性问题\",{\"2\":{\"1664\":1}}],[\"它还实施了一种高效的重要性估计方法\",{\"2\":{\"1143\":1}}],[\"它采用了双阶段过程运行\",{\"2\":{\"1588\":1}}],[\"它采用prefix\",{\"2\":{\"923\":1}}],[\"它可以通过命令控制外部设备\",{\"2\":{\"2443\":1}}],[\"它可以通过通信将这一信息传递给其他智能体\",{\"2\":{\"1338\":1}}],[\"它可以在训练期间自动将部分批次发送到不同的设备\",{\"2\":{\"2055\":1}}],[\"它可以允许在非连续空间里存储连续的kv张量\",{\"2\":{\"750\":1}}],[\"它对计算资源的要求较高\",{\"2\":{\"1321\":1}}],[\"它促使\",{\"2\":{\"1275\":1}}],[\"它仅依赖于任务描述\",{\"2\":{\"1275\":1}}],[\"它以大语言模型\",{\"2\":{\"1184\":1}}],[\"它引入了一个依赖检测算法\",{\"2\":{\"1143\":1}}],[\"它引入了一种独特的参数重要性标准\",{\"2\":{\"1050\":1}}],[\"它通常促使教师大语言模型生成一个蒸馏数据集\",{\"2\":{\"1124\":1}}],[\"它通过算子融合和通信计算并行化等技术\",{\"2\":{\"2351\":1}}],[\"它通过生成多个思路链\",{\"2\":{\"2042\":1}}],[\"它通过动态调整不同层和参数类型的秩\",{\"2\":{\"1653\":1}}],[\"它通过工程化提示生成短语扰动\",{\"2\":{\"1224\":1}}],[\"它通过预训练和zero\",{\"2\":{\"975\":1}}],[\"它通过结合单词及其n\",{\"2\":{\"867\":1}}],[\"它通过结合不同的数值精度\",{\"2\":{\"408\":1}}],[\"它通过反复更新状态价值函数\",{\"2\":{\"612\":1}}],[\"它通过引入重要性采样和策略截断\",{\"2\":{\"521\":1}}],[\"它通过核心组件协调多个服务的交互\",{\"2\":{\"102\":1}}],[\"它使用一个由\",{\"2\":{\"917\":1}}],[\"它的出现显著提升了知识密集型任务的性能\",{\"2\":{\"2469\":1}}],[\"它的详细内容在3\",{\"2\":{\"1956\":1}}],[\"它的设计旨在解决随着序列长度\",{\"2\":{\"1846\":1}}],[\"它的主要目标是通过简化每次\",{\"2\":{\"1760\":1}}],[\"它的粒度处于\",{\"2\":{\"1022\":1}}],[\"它的核心功能是将计算机无法直接理解的物理量\",{\"2\":{\"882\":1}}],[\"它的核心思想是将每个类别映射为一个唯一的二进制向量\",{\"2\":{\"871\":1}}],[\"它的核心思想是利用神经网络训练词向量\",{\"2\":{\"870\":1}}],[\"它的特点是输出是一个概率值\",{\"2\":{\"42\":1}}],[\"它将流水线阶段进一步细分\",{\"2\":{\"2688\":1}}],[\"它将教师模型中间层的特征激活作为学生模型的学习目标\",{\"2\":{\"845\":1}}],[\"它将传统bpe从字符级别扩展到字节级别\",{\"2\":{\"296\":1}}],[\"它研究模型权重中的冗余部分\",{\"2\":{\"729\":1}}],[\"它允许agent通过完善过去的行动决策和纠正以前的错误来持续改进\",{\"2\":{\"1557\":1}}],[\"它允许高概率词语有更大的被选中机会\",{\"2\":{\"295\":1}}],[\"它允许序列中的每个部分关注序列中的其他部分\",{\"2\":{\"126\":1}}],[\"它针对每个样本的特定维度进行归一化\",{\"2\":{\"205\":1}}],[\"它决定了神经元的输出以及模型的学习能力\",{\"2\":{\"152\":1}}],[\"它们将进一步推动人工智能在各个领域中的应用与创新\",{\"2\":{\"2325\":1}}],[\"它们将计算复杂度降低到了序列长度的线性或亚线性\",{\"2\":{\"1869\":1}}],[\"它们的绝对值明显更大\",{\"2\":{\"1982\":1}}],[\"它们的使用场景和影响不同\",{\"2\":{\"17\":1}}],[\"它们事先是未知的\",{\"2\":{\"1813\":1}}],[\"它们为任务执行提供强大的语言处理能力\",{\"2\":{\"1362\":1}}],[\"它们适合开发者直接通过代码实现复杂的逻辑\",{\"2\":{\"1250\":1}}],[\"它们不能被移除\",{\"2\":{\"498\":1}}],[\"它们在数据处理和模型更新方式上有显著区别\",{\"2\":{\"1564\":1}}],[\"它们在不同场景下优化了位置嵌入的表现\",{\"2\":{\"203\":1}}],[\"它们在处理多任务和大规模数据集时表现出色\",{\"2\":{\"115\":1}}],[\"它们旨在优化嵌入的缩放方式\",{\"2\":{\"159\":1}}],[\"它们会互相冲突\",{\"2\":{\"10\":1}}],[\"它们帮助你管理代码的结构和简化代码中的命名问题\",{\"2\":{\"7\":1}}],[\"树非常相关\",{\"2\":{\"2195\":1}}],[\"树\",{\"0\":{\"41\":1}}],[\"全部拒答\",{\"2\":{\"2540\":1}}],[\"全面强化学习算法测试框架\",{\"0\":{\"2285\":1},\"1\":{\"2317\":1,\"2348\":1,\"2378\":1,\"2405\":1,\"2430\":1,\"2455\":1}}],[\"全面评估语言理解能力\",{\"2\":{\"549\":1}}],[\"全大写\",{\"2\":{\"1926\":1}}],[\"全量微调\",{\"2\":{\"1794\":1,\"1932\":1,\"1983\":1}}],[\"全代码框架是指需要开发者通过编写代码来实现智能体系统的搭建和功能扩展\",{\"2\":{\"1250\":1}}],[\"全代码框架\",{\"0\":{\"1250\":1}}],[\"全链路评估中较为简单的环节\",{\"2\":{\"457\":1}}],[\"全局来看\",{\"2\":{\"2308\":1}}],[\"全局批量大小计算公式\",{\"2\":{\"2217\":1}}],[\"全局信息捕捉\",{\"2\":{\"155\":1}}],[\"全局最小值或局部最小值\",{\"2\":{\"32\":1}}],[\"全模型微调\",{\"2\":{\"40\":1}}],[\"但流水线并行不会减少每层中间激活的显存占用\",{\"2\":{\"2708\":1}}],[\"但空泡比率降低了\",{\"2\":{\"2697\":1}}],[\"但virtual\",{\"2\":{\"2697\":1}}],[\"但通过合理安排前向和反向过程的顺序\",{\"2\":{\"2694\":1}}],[\"但超越智能的边界可能仍然需要更强大的基础模型和更大规模的强化学习\",{\"2\":{\"2642\":1}}],[\"但尽量保证head总数能被gpu个数整除\",{\"2\":{\"2636\":1}}],[\"但如果对\",{\"2\":{\"2616\":1}}],[\"但如何平衡领域数据与通用数据仍是核心挑战\",{\"2\":{\"633\":1}}],[\"但后续更新中旧策略保持不变\",{\"2\":{\"2569\":1}}],[\"但没有对ln和dropout进行并行化\",{\"2\":{\"2682\":1}}],[\"但没有\",{\"2\":{\"2505\":1}}],[\"但可以想象这是一个从分解到聚合的过程\",{\"2\":{\"2554\":1}}],[\"但可以通过结构化输出和提取实现\",{\"2\":{\"2443\":1}}],[\"但可能导致训练不稳定\",{\"2\":{\"2372\":1}}],[\"但可能导致模型在某些nlp基准上的性能下降\",{\"2\":{\"875\":1,\"992\":1}}],[\"但可能需要与强化学习结合以应对更复杂的场景\",{\"2\":{\"893\":1}}],[\"但可能生成单调\",{\"2\":{\"301\":1}}],[\"但可能显得保守\",{\"2\":{\"253\":1}}],[\"但存在两个限制\",{\"2\":{\"2374\":1}}],[\"但特征学习效果稍逊\",{\"2\":{\"2372\":1}}],[\"但往往缺乏深入的思考和迭代过程\",{\"2\":{\"2333\":1}}],[\"但要小心处理损失计算\",{\"2\":{\"2331\":1}}],[\"但deepseek\",{\"2\":{\"2315\":1}}],[\"但随着模型深度增加\",{\"2\":{\"2260\":1}}],[\"但具有更强的可扩展性\",{\"2\":{\"2195\":1}}],[\"但下降速度也很快\",{\"2\":{\"2163\":1}}],[\"但reflexion方法引入了三个不同的模型来解决这一问题\",{\"2\":{\"2113\":1}}],[\"但带宽相比于sram小得多\",{\"2\":{\"2077\":1}}],[\"但带宽小\",{\"2\":{\"2077\":1}}],[\"但带宽可以达到19tb\",{\"2\":{\"2077\":1}}],[\"但带宽大\",{\"2\":{\"2077\":1}}],[\"但方差较大\",{\"2\":{\"1992\":1,\"2045\":1}}],[\"但奖励在公式中仍然不可或缺\",{\"2\":{\"1954\":1}}],[\"但ptq可能会在量化过程中引入一定程度的精度损失\",{\"2\":{\"1874\":1}}],[\"但sram的内存大小有限\",{\"2\":{\"1810\":1}}],[\"但内存小很多\",{\"2\":{\"1810\":1}}],[\"但与传统nlp\",{\"2\":{\"1787\":1}}],[\"但与初代\",{\"2\":{\"926\":1}}],[\"但整体自主性较低\",{\"2\":{\"1728\":1}}],[\"但不要过于啰嗦\",{\"2\":{\"2690\":1}}],[\"但不可估算值如临时变量和未知数据也占据了显存的一部分\",{\"2\":{\"2021\":1}}],[\"但不同之处在于它允许代码生成与推理多步交叉\",{\"2\":{\"1788\":1}}],[\"但不同之处在于t5会掩码连续的三个词\",{\"2\":{\"1062\":1}}],[\"但不一定能提供示范\",{\"2\":{\"1687\":1}}],[\"但为了保证正常运行\",{\"2\":{\"1545\":1}}],[\"但为梯度提供了稳定路径\",{\"2\":{\"183\":1}}],[\"但实际上在人工评估时效果却下降\",{\"2\":{\"1505\":1}}],[\"但实际数据中的文本片段长度各不相同\",{\"2\":{\"782\":1}}],[\"但这会导致高方差\",{\"2\":{\"2415\":1,\"2441\":1}}],[\"但这需要满足一个前提条件\",{\"2\":{\"1465\":1}}],[\"但这也可能导致对特定需求进行定制化修改时遇到较高的门槛\",{\"2\":{\"1392\":1}}],[\"但仍然存在一些不可忽视的挑战\",{\"2\":{\"1459\":1}}],[\"但速度较慢\",{\"2\":{\"1418\":1}}],[\"但只能处理固定长度的句子\",{\"2\":{\"1418\":1}}],[\"但由于闭源限制\",{\"2\":{\"1347\":1}}],[\"但由于硬件缓存大小有限\",{\"2\":{\"429\":1}}],[\"但显著提升了性能\",{\"2\":{\"1155\":1}}],[\"但牺牲了并行计算能力\",{\"2\":{\"1131\":1}}],[\"但缺乏长度外推性\",{\"2\":{\"1131\":1}}],[\"但每个token只需使用12\",{\"2\":{\"1121\":1}}],[\"但推理时仅使用其中两个\",{\"2\":{\"1121\":1}}],[\"但指出其采用了\",{\"2\":{\"1102\":1}}],[\"但模型的推理能力得到了提升\",{\"2\":{\"1069\":1}}],[\"但未达到openai\",{\"2\":{\"1013\":1}}],[\"但无法直接获得\",{\"2\":{\"995\":1}}],[\"但其计算成本高昂\",{\"2\":{\"2637\":1}}],[\"但其兼容性和易用性使得它成为许多开发者的首选\",{\"2\":{\"2381\":1}}],[\"但其中的内容却不是我们最终想要的\",{\"2\":{\"2379\":1}}],[\"但其缺点是速度较慢\",{\"2\":{\"2235\":1}}],[\"但其实际应用范围可能受到一定限制\",{\"2\":{\"2094\":1}}],[\"但其实现和优化也存在一定难度\",{\"2\":{\"880\":1}}],[\"但其在以下方面存在不足\",{\"2\":{\"1343\":1}}],[\"但其效果通常不如\",{\"2\":{\"1260\":1}}],[\"但其创新之处在于使用了更大的数据集和模型参数\",{\"2\":{\"901\":1}}],[\"但占用内存较少\",{\"2\":{\"768\":1}}],[\"但对于word\",{\"2\":{\"2651\":1}}],[\"但对任务处理没有任何帮助\",{\"2\":{\"1594\":1}}],[\"但对应的最优价值函数只有一个\",{\"2\":{\"767\":1}}],[\"但对复杂生成任务效果欠佳\",{\"2\":{\"301\":1}}],[\"但同时也带来了巨大的计算和存储挑战\",{\"2\":{\"728\":1}}],[\"但成本控制仍是关键挑战\",{\"2\":{\"701\":1}}],[\"但成本可能较高\",{\"2\":{\"465\":1}}],[\"但它具有更强的扩展性\",{\"2\":{\"1849\":1}}],[\"但它蕴含着\",{\"2\":{\"1717\":1}}],[\"但它提供了一种灵活的模型调整方式\",{\"2\":{\"1668\":1}}],[\"但它提供了更直接\",{\"2\":{\"608\":1}}],[\"但它可能会导致生成的块\",{\"2\":{\"1513\":1}}],[\"但它们也存在一些不可忽视的局限性\",{\"2\":{\"1378\":1}}],[\"但它们的计算和存储成本也显著增加\",{\"2\":{\"692\":1}}],[\"但它的能力和适用范围也因此受到限制\",{\"2\":{\"1241\":1}}],[\"但它也带来了新的挑战\",{\"2\":{\"845\":1}}],[\"但它通过简单的线性偏置实现了更高效的相对位置编码\",{\"2\":{\"293\":1}}],[\"但避免其发生始终是更优的选择\",{\"2\":{\"525\":1}}],[\"但传统python库解析效果有限\",{\"2\":{\"465\":1}}],[\"但也有诸多缺点\",{\"2\":{\"2118\":1}}],[\"但也存在一些不足\",{\"2\":{\"341\":1}}],[\"但也可能在以下两种情况下出现问题\",{\"2\":{\"295\":1}}],[\"但训练效率低\",{\"2\":{\"339\":1}}],[\"但代价是计算复杂度更高\",{\"2\":{\"324\":1}}],[\"但生成能力较弱\",{\"2\":{\"316\":1}}],[\"但在多跳问题\",{\"2\":{\"2546\":1}}],[\"但在知识密集型任务中\",{\"2\":{\"2514\":1}}],[\"但在复杂任务中表现不稳定\",{\"2\":{\"2054\":1}}],[\"但在较小模型\",{\"2\":{\"1736\":1}}],[\"但在测试集上的效果却下降的现象\",{\"2\":{\"1460\":1}}],[\"但在前向传播时会模拟低精度运算\",{\"2\":{\"1160\":1}}],[\"但在注意力的qkv层保留\",{\"2\":{\"1155\":1}}],[\"但在数据处理和训练目的上存在显著差异\",{\"2\":{\"1150\":1}}],[\"但在结构上做了一些改动\",{\"2\":{\"1059\":1}}],[\"但在处理大规模数据时需要结合降维技术\",{\"2\":{\"1025\":1}}],[\"但在实际使用中也存在一些潜在的问题需要注意\",{\"2\":{\"1392\":1}}],[\"但在实际使用中也存在一些局限性\",{\"2\":{\"1147\":1}}],[\"但在实际应用中需要注意以下几个方面的问题和挑战\",{\"2\":{\"1366\":1}}],[\"但在实际推理中非线性量化的计算复杂度较高\",{\"2\":{\"868\":1}}],[\"但在实验中发现通常需要结合策略损失和预训练损失的大小综合设定\",{\"2\":{\"1076\":1}}],[\"但在实现路径\",{\"2\":{\"587\":1}}],[\"但在具体实现上有所创新\",{\"2\":{\"867\":1}}],[\"但在合并子词时采用了基于互信息\",{\"2\":{\"308\":1}}],[\"但在很多实际问题中都非常有效\",{\"2\":{\"185\":1}}],[\"但效果强\",{\"2\":{\"305\":1}}],[\"但会增加输入维度\",{\"2\":{\"223\":1}}],[\"但直接外推会导致注意力分数\",{\"2\":{\"222\":1}}],[\"但transformer需要额外机制来提供这种信息\",{\"2\":{\"216\":1}}],[\"但保留样本内特征之间的相对关系\",{\"2\":{\"190\":1}}],[\"但需要注意最终存储时仍需转为fp32\",{\"2\":{\"2330\":1}}],[\"但需要调整超参数\",{\"2\":{\"315\":1}}],[\"但需优化\",{\"2\":{\"1259\":1}}],[\"但需能有效区分主要类别\",{\"2\":{\"566\":1}}],[\"但需进一步研究如何动态选择注意力区域\",{\"2\":{\"168\":1}}],[\"但需设计适配器结构\",{\"2\":{\"40\":1}}],[\"但\",{\"2\":{\"162\":1}}],[\"但我们想要的是一个概率值\",{\"2\":{\"90\":1}}],[\"但是现在\",{\"2\":{\"2145\":1}}],[\"但是\",{\"2\":{\"2118\":1,\"2602\":1}}],[\"但是softmax由于分母需要完整输入数据\",{\"2\":{\"1872\":1}}],[\"但是对于激活值\",{\"2\":{\"1813\":1}}],[\"但是占比不能过高\",{\"2\":{\"847\":1}}],[\"但是这个作为基础一定是要好好学习的\",{\"2\":{\"56\":1}}],[\"但是时间所剩无几了\",{\"2\":{\"56\":1}}],[\"但计算成本高\",{\"2\":{\"40\":1}}],[\"但性能有限\",{\"2\":{\"40\":1}}],[\"但并没有绝对的限制\",{\"2\":{\"11\":1}}],[\"快捷键\",{\"2\":{\"2234\":1}}],[\"快\",{\"2\":{\"2118\":1}}],[\"快手\",{\"2\":{\"411\":1,\"559\":1}}],[\"快速轻量\",{\"2\":{\"373\":1}}],[\"快速收敛阶段\",{\"2\":{\"1344\":1}}],[\"快速收敛\",{\"2\":{\"330\":1}}],[\"快速实现\",{\"2\":{\"40\":1}}],[\"快慢指针\",{\"2\":{\"35\":1}}],[\"条作为负例集\",{\"2\":{\"1075\":1}}],[\"条作为正例集\",{\"2\":{\"1075\":1}}],[\"条件计算\",{\"2\":{\"988\":1}}],[\"条件可以是达到预设的词表大小或概率增量低于某一阈值\",{\"2\":{\"381\":1}}],[\"条标注数据微调\",{\"2\":{\"49\":1}}],[\"条\",{\"2\":{\"40\":2}}],[\"方式\",{\"2\":{\"2033\":1}}],[\"方面\",{\"2\":{\"1259\":1}}],[\"方差小但有偏\",{\"2\":{\"672\":1}}],[\"方差较大\",{\"2\":{\"654\":1}}],[\"方差更低的估计方法\",{\"2\":{\"608\":1}}],[\"方法采用以下策略\",{\"2\":{\"2546\":1}}],[\"方法提出了以下改进\",{\"2\":{\"2514\":1}}],[\"方法以提高模型性能\",{\"2\":{\"2219\":1}}],[\"方法以适应多模态数据\",{\"2\":{\"1176\":1}}],[\"方法进一步改进了\",{\"2\":{\"2144\":1}}],[\"方法进一步挖掘深度神经网络中不同层级的特征信息\",{\"2\":{\"845\":1}}],[\"方法也存在明显的局限性\",{\"2\":{\"2094\":1}}],[\"方法通过树\",{\"2\":{\"2094\":1}}],[\"方法通过仅微调少量或额外的模型参数\",{\"2\":{\"1875\":1}}],[\"方法存在幻觉和错误传播问题\",{\"2\":{\"2011\":1}}],[\"方法是一种有效提升大语言模型\",{\"2\":{\"1990\":1}}],[\"方法是一种用于估计策略价值函数的无模型\",{\"2\":{\"574\":1}}],[\"方法训练模型\",{\"2\":{\"1976\":1}}],[\"方法简介\",{\"0\":{\"1716\":1,\"1948\":1,\"2514\":1,\"2546\":1,\"2570\":1,\"2601\":1}}],[\"方法基于论文\",{\"2\":{\"1665\":1}}],[\"方法可以自动将文本切分为句子\",{\"2\":{\"1612\":1}}],[\"方法与剪枝相结合\",{\"2\":{\"1050\":1}}],[\"方法不仅关注教师模型中特定网络层的特征输出\",{\"2\":{\"880\":1}}],[\"方法直接学习教师模型的输出结果\",{\"2\":{\"845\":1}}],[\"方法于复杂推理任务\",{\"2\":{\"739\":1}}],[\"方法来估计动作价值函数\",{\"2\":{\"577\":1}}],[\"方法3\",{\"0\":{\"473\":1}}],[\"方法2\",{\"0\":{\"446\":1}}],[\"方法1\",{\"0\":{\"421\":1}}],[\"方法\",{\"0\":{\"1930\":1},\"2\":{\"40\":1,\"259\":1,\"292\":1,\"420\":1,\"433\":1,\"445\":1,\"534\":1,\"574\":1,\"621\":1,\"622\":1,\"1281\":1,\"1328\":1,\"1373\":1,\"1493\":1,\"1753\":1,\"2168\":1,\"2280\":1,\"2554\":1}}],[\"方案设计\",{\"2\":{\"4\":1}}],[\"以virtual\",{\"2\":{\"2697\":1}}],[\"以此类推\",{\"2\":{\"2697\":1}}],[\"以此来综合多种方法解决问题\",{\"2\":{\"2335\":1}}],[\"以此来提升模型的性能\",{\"2\":{\"1626\":1}}],[\"以此来减小模型的大小和计算复杂度\",{\"2\":{\"729\":1}}],[\"以指导\",{\"2\":{\"2693\":1}}],[\"以缩短每个步骤的执行时间\",{\"2\":{\"2688\":1}}],[\"以承载更多的通信量\",{\"2\":{\"2688\":1}}],[\"以捕捉细节\",{\"2\":{\"2613\":1}}],[\"以捕获更丰富的位置信息\",{\"2\":{\"1606\":1}}],[\"以识别其中的不准确之处\",{\"2\":{\"2436\":1}}],[\"以检索到的上下文为条件\",{\"2\":{\"2420\":1}}],[\"以平衡显存占用和训练速度\",{\"2\":{\"2252\":1}}],[\"以加速模型的训练和推理过程\",{\"2\":{\"2563\":1}}],[\"以加速搜索过程\",{\"2\":{\"2234\":1}}],[\"以加速推理\",{\"2\":{\"40\":1}}],[\"以弥补量化造成的精度损失\",{\"2\":{\"2085\":1}}],[\"以进一步优化推理能力\",{\"2\":{\"1917\":1}}],[\"以进一步提高预训练数据质量\",{\"2\":{\"1327\":1}}],[\"以进一步提高效率和准确性\",{\"2\":{\"598\":1}}],[\"以降低计算资源的需求\",{\"2\":{\"1899\":1}}],[\"以编码prompt\",{\"2\":{\"1796\":1}}],[\"以增加返回结果的数量\",{\"2\":{\"1774\":1}}],[\"以增强模型的指令遵循能力\",{\"2\":{\"1631\":1}}],[\"以期找到更优的解决方案\",{\"2\":{\"1765\":1}}],[\"以缓解优化困难\",{\"2\":{\"1736\":1}}],[\"以最大化训练效率\",{\"2\":{\"1667\":1}}],[\"以最大化长期累积奖励\",{\"2\":{\"572\":1}}],[\"以支持这种推理与行动结合的方法\",{\"2\":{\"1608\":1}}],[\"以支持更复杂的任务类型\",{\"2\":{\"2473\":1}}],[\"以支持更灵活的序列建模\",{\"2\":{\"1359\":1}}],[\"以支持更广泛的数据训练\",{\"2\":{\"1257\":1}}],[\"以更多的通信量换取空泡比率降低\",{\"2\":{\"2697\":1}}],[\"以更精确地估计每个动作对未来收益的影响\",{\"2\":{\"1955\":1}}],[\"以更贴近实际应用场景\",{\"2\":{\"1453\":1}}],[\"以更有效地处理权重衰减\",{\"2\":{\"1162\":1}}],[\"以帮助读者更好地理解和应用这些技术\",{\"2\":{\"1365\":1}}],[\"以实现更高的累计奖励\",{\"2\":{\"2171\":1}}],[\"以实现更有效的管理和检索\",{\"2\":{\"1285\":1}}],[\"以实现高效预训练\",{\"2\":{\"1265\":1}}],[\"以达到最佳性能\",{\"2\":{\"1262\":1}}],[\"以优化训练效率和效果\",{\"2\":{\"2488\":1}}],[\"以优化模型性能\",{\"2\":{\"1531\":1}}],[\"以优化当前预测的奖励函数\",{\"2\":{\"1491\":1}}],[\"以优化示例顺序对模型推断结果的影响\",{\"2\":{\"1413\":1}}],[\"以优化在这些领域的性能\",{\"2\":{\"1252\":1}}],[\"以优化生成更长文本与空白填充目标\",{\"2\":{\"1089\":1}}],[\"以决定需要使用哪种外部系统\",{\"2\":{\"1233\":1}}],[\"以维持模型通用能力\",{\"2\":{\"1199\":1}}],[\"以组为单位\",{\"2\":{\"1022\":1}}],[\"以融合双向语义信息\",{\"2\":{\"997\":1}}],[\"以确保生成的偏好对能够有效提升模型性能\",{\"2\":{\"2127\":1}}],[\"以确保准确性\",{\"2\":{\"2103\":1}}],[\"以确保结构化输出\",{\"2\":{\"1797\":1}}],[\"以确保模板在语义上与句子保持一致\",{\"2\":{\"1796\":1}}],[\"以确保模型的高效性和准确性\",{\"2\":{\"1084\":1}}],[\"以确保训练过程顺利进行\",{\"2\":{\"1740\":1}}],[\"以确保整个过程按计划执行\",{\"2\":{\"1702\":1}}],[\"以确保策略更新的准确性\",{\"2\":{\"1622\":1}}],[\"以确保知识库始终保持最新状态\",{\"2\":{\"1558\":1}}],[\"以确保高质量信息的代表性\",{\"2\":{\"1205\":1}}],[\"以确保每个设备大约接收到相同数量的隐藏状态\",{\"2\":{\"1030\":1}}],[\"以确保最终选择的示例具有更高的多样性\",{\"2\":{\"949\":1}}],[\"以确保数据集中语言一致性\",{\"2\":{\"515\":1}}],[\"以一层网络的每个量化通道为单位\",{\"2\":{\"981\":1}}],[\"以一层网络为单位一组量化参数\",{\"2\":{\"939\":1}}],[\"以一致性最多的答案作为最终结果\",{\"2\":{\"561\":1}}],[\"以减少不必要的计算量\",{\"2\":{\"2613\":1}}],[\"以减少偏差\",{\"2\":{\"2220\":1}}],[\"以减少中间步骤和内存使用\",{\"2\":{\"2110\":1}}],[\"以减少模型复杂性\",{\"2\":{\"1866\":1}}],[\"以减少attention的计算和内存要求\",{\"2\":{\"1807\":1}}],[\"以减少参数数量和计算量\",{\"2\":{\"763\":1}}],[\"以减轻对齐税的影响\",{\"2\":{\"911\":1}}],[\"以应对多变环境\",{\"2\":{\"892\":1}}],[\"以恢复部分因剪枝造成的性能损失\",{\"2\":{\"795\":1}}],[\"以在有限资源下实现最佳性能\",{\"2\":{\"763\":1}}],[\"以在未来获得更高的累积奖励\",{\"2\":{\"639\":1}}],[\"以适配具体的业务场景\",{\"2\":{\"1450\":1}}],[\"以适配多语言\",{\"2\":{\"736\":1}}],[\"以适应新任务需求\",{\"2\":{\"1983\":1}}],[\"以适应新的数据或任务\",{\"2\":{\"1866\":1}}],[\"以适应超长序列任务\",{\"2\":{\"1543\":1}}],[\"以适应更复杂的决策环境\",{\"2\":{\"852\":1}}],[\"以适应更多低资源场景\",{\"2\":{\"413\":1}}],[\"以适应稳定的梯度波动\",{\"2\":{\"589\":1}}],[\"以适应不同任务需求\",{\"2\":{\"314\":1}}],[\"以自然语言处理领域为例\",{\"2\":{\"728\":1}}],[\"以如何学习策略划分\",{\"0\":{\"724\":1}}],[\"以防止偏离预期行为\",{\"2\":{\"721\":1}}],[\"以防泄露\",{\"2\":{\"198\":1}}],[\"以需不需要环境动态划分\",{\"0\":{\"688\":1}}],[\"以采样策略和更新策略划分\",{\"0\":{\"653\":1}}],[\"以免影响训练效率\",{\"2\":{\"2252\":1}}],[\"以免影响模型表现\",{\"2\":{\"1280\":1}}],[\"以免影响模型的通用能力\",{\"2\":{\"422\":1}}],[\"以免基准污染\",{\"2\":{\"1190\":1}}],[\"以免导致收敛不正确\",{\"2\":{\"647\":1}}],[\"以结合深度学习技术优化bpe的子词选择过程\",{\"2\":{\"631\":1}}],[\"以限制梯度范围\",{\"2\":{\"622\":1}}],[\"以数据来源划分\",{\"0\":{\"618\":1}}],[\"以解决需要序贯决策的问题\",{\"2\":{\"572\":1}}],[\"以满足特定任务需求\",{\"2\":{\"542\":1}}],[\"以上是关于显存优化与推理阶段显存分析的博客笔记\",{\"2\":{\"2214\":1}}],[\"以上内容为基于原文的博客笔记总结\",{\"2\":{\"1953\":1}}],[\"以上内容基于最新研究和技术发展总结而来\",{\"2\":{\"1386\":1}}],[\"以上内容将\",{\"2\":{\"65\":1}}],[\"以上\",{\"2\":{\"502\":1,\"2580\":1}}],[\"以下为使用\",{\"2\":{\"1646\":1}}],[\"以下\",{\"2\":{\"501\":1}}],[\"以下是grpo在\",{\"2\":{\"2500\":1}}],[\"以下是glm1模型的一些关键改动\",{\"2\":{\"961\":1}}],[\"以下是优化模型性能的关键步骤\",{\"2\":{\"2346\":1}}],[\"以下是部分数据集的格式与内容的简要概述\",{\"2\":{\"2223\":1}}],[\"以下是dora优化技术的核心代码实现\",{\"2\":{\"1831\":1}}],[\"以下是\",{\"2\":{\"1816\":1}}],[\"以下是cot\",{\"2\":{\"1788\":1}}],[\"以下是奖励模型训练的关键步骤\",{\"2\":{\"1582\":1}}],[\"以下是具体建议\",{\"2\":{\"1763\":1}}],[\"以下是具体步骤\",{\"2\":{\"1465\":1}}],[\"以下是具体原理\",{\"2\":{\"125\":1}}],[\"以下是实现任务分解的几种方式\",{\"2\":{\"1420\":1}}],[\"以下是自主智能体的关键特征\",{\"2\":{\"1408\":1}}],[\"以下是几个需要考虑的重要因素\",{\"2\":{\"2655\":1}}],[\"以下是几个典型的低代码平台\",{\"2\":{\"1347\":1}}],[\"以下是几种常见的高级策略\",{\"2\":{\"2104\":1}}],[\"以下是几种常见的\",{\"2\":{\"2102\":1}}],[\"以下是几种常见的工作流类型及其特点\",{\"2\":{\"1595\":1}}],[\"以下是几种常见的多智能体协作框架\",{\"2\":{\"1300\":1}}],[\"以下是几种常见的智能体框架分类及其特点\",{\"2\":{\"1200\":1}}],[\"以下是几种主流采样技术的核心概念及应用场景\",{\"2\":{\"249\":1}}],[\"以下是两个重要的工具及其核心功能\",{\"2\":{\"2550\":1}}],[\"以下是两种常用的全代码框架\",{\"2\":{\"1250\":1}}],[\"以下是两者的核心特点和功能总结\",{\"2\":{\"373\":1}}],[\"以下是使用fasttext进行文本分类的基本代码框架\",{\"2\":{\"1208\":1}}],[\"以下是使用word2vec的python代码示例\",{\"2\":{\"1111\":1}}],[\"以下是使用python实现独热编码的代码示例\",{\"2\":{\"1025\":1}}],[\"以下是使用python实现scaled\",{\"2\":{\"213\":1}}],[\"以下是针对多个平台的数据爬虫id列表配置\",{\"2\":{\"559\":1}}],[\"以下是爬虫配置的关键参数\",{\"2\":{\"526\":1}}],[\"以下是从通用数据中筛选垂域相关内容的具体步骤\",{\"2\":{\"500\":1}}],[\"以下是ulm优化过程中需要关注的数据点\",{\"2\":{\"471\":1}}],[\"以下是混合精度训练的主要步骤\",{\"2\":{\"435\":1}}],[\"以下是核心观点\",{\"2\":{\"422\":1}}],[\"以下是核心内容\",{\"2\":{\"159\":1}}],[\"以下是wordpiece中计算互信息得分的核心代码\",{\"2\":{\"407\":1}}],[\"以下是wordpiece分词的主要步骤\",{\"2\":{\"381\":1}}],[\"以下是一些重点数据集的介绍\",{\"2\":{\"2138\":1}}],[\"以下是一些与mrkl系统相关的技术工作\",{\"2\":{\"1569\":1}}],[\"以下是一些常用且好用的pdf文件解析工具\",{\"2\":{\"2270\":1}}],[\"以下是一些常用的开源数据集及其获取地址\",{\"2\":{\"741\":1}}],[\"以下是一些常用的benchmark\",{\"2\":{\"549\":1}}],[\"以下是一些常见的可设定参数\",{\"2\":{\"1894\":1}}],[\"以下是一些常见的向量搜索算法\",{\"2\":{\"1422\":1}}],[\"以下是一些值得思考的问题\",{\"2\":{\"406\":1}}],[\"以下是一个典型的agent交互流程\",{\"2\":{\"2363\":1}}],[\"以下是一个效果较好的prompt示例\",{\"2\":{\"2050\":1}}],[\"以下是一个使用\",{\"2\":{\"1823\":1}}],[\"以下是一个示例代码\",{\"2\":{\"1776\":1}}],[\"以下是一个生成正弦位置编码的python代码示例\",{\"2\":{\"1435\":1}}],[\"以下是一个具体的代码示例\",{\"2\":{\"1458\":1}}],[\"以下是一个具体示例\",{\"2\":{\"1322\":1}}],[\"以下是一个具体分配案例\",{\"2\":{\"772\":1}}],[\"以下是一个基于\",{\"2\":{\"444\":1}}],[\"以下是一个简单的\",{\"2\":{\"2433\":1}}],[\"以下是一个简单的bpe操作示例\",{\"2\":{\"418\":1}}],[\"以下是一个简单的代码示例\",{\"2\":{\"135\":1}}],[\"以下是一个实现swiglu的简单代码片段\",{\"2\":{\"266\":1}}],[\"以下是bbpe分词的核心代码实现示例\",{\"2\":{\"391\":1}}],[\"以下是bbpe与传统bpe在分词结果上的对比\",{\"2\":{\"365\":1}}],[\"以下是利用正弦函数生成位置编码的python实现\",{\"2\":{\"332\":1}}],[\"以下是attention机制的简化公式\",{\"2\":{\"208\":1}}],[\"以下是完善后的公式格式\",{\"2\":{\"173\":1}}],[\"以下是对比两种生成流程的示例\",{\"2\":{\"145\":1}}],[\"以保证模型对中文任务的适配性\",{\"2\":{\"474\":1}}],[\"以内容计划的风格重新表述这些事实\",{\"2\":{\"2601\":1}}],[\"以内\",{\"2\":{\"473\":1}}],[\"以pdf格式存储\",{\"2\":{\"465\":1}}],[\"以\",{\"2\":{\"435\":1,\"553\":1}}],[\"以便支持递归搜索\",{\"2\":{\"2625\":1}}],[\"以便后续的操作\",{\"2\":{\"2549\":1}}],[\"以便技能召回\",{\"2\":{\"2277\":1}}],[\"以便进行对比或投票\",{\"2\":{\"2037\":1}}],[\"以便得出更优的检索结果\",{\"2\":{\"1949\":1}}],[\"以便未来使用\",{\"2\":{\"1904\":1}}],[\"以便在obsidian中识别为块级公式\",{\"2\":{\"2215\":1}}],[\"以便在推理阶段更好地适应量化后的模型\",{\"2\":{\"1813\":1}}],[\"以便在保持模型性能的同时减少模型的参数量和计算复杂度\",{\"2\":{\"749\":1}}],[\"以便系统能够更灵活地理解用户查询\",{\"2\":{\"1466\":1}}],[\"以便于模型理解\",{\"2\":{\"929\":1}}],[\"以便发现异常\",{\"2\":{\"525\":1}}],[\"以便更高效地进行处理和分析\",{\"2\":{\"2552\":1}}],[\"以便更高效地获取目标数据\",{\"2\":{\"411\":1}}],[\"以便更好地适配不同任务类型\",{\"2\":{\"422\":1}}],[\"以便有效地处理api集成的复杂性\",{\"2\":{\"265\":1}}],[\"以同时提升模型效率和性能\",{\"2\":{\"362\":1}}],[\"以语言表征为目标\",{\"2\":{\"316\":1}}],[\"以避免对模型性能产生负面影响\",{\"2\":{\"2698\":1}}],[\"以避免不必要的训练不稳定性\",{\"2\":{\"2450\":1}}],[\"以避免不同位置出现重叠编码\",{\"2\":{\"287\":1}}],[\"以避免因带宽通信成本导致的训练速度减慢\",{\"2\":{\"2287\":1}}],[\"以避免层间不匹配\",{\"2\":{\"1923\":1}}],[\"以避免误差\",{\"2\":{\"1845\":1}}],[\"以避免奖励计算错误\",{\"2\":{\"1741\":1}}],[\"以避免偏差\",{\"2\":{\"1639\":1,\"1859\":1}}],[\"以避免模型误判\",{\"2\":{\"2355\":1}}],[\"以避免模型输出的多样性不足\",{\"2\":{\"1821\":1}}],[\"以避免模型初期不稳定\",{\"2\":{\"1405\":1}}],[\"以避免模型偏差\",{\"2\":{\"1236\":1}}],[\"以避免计算复杂度增加\",{\"2\":{\"1405\":1}}],[\"以避免过拟合或训练效率低下的问题\",{\"2\":{\"2250\":1}}],[\"以避免过拟合和奖励黑客问题\",{\"2\":{\"1656\":1}}],[\"以避免过度更新\",{\"2\":{\"1681\":1}}],[\"以避免过度或不足更新\",{\"2\":{\"678\":1}}],[\"以避免过多token溢出导致模型性能下降\",{\"2\":{\"1270\":1}}],[\"以避免策略遗忘预训练阶段的知识\",{\"2\":{\"992\":1}}],[\"以避免策略更新不准确\",{\"2\":{\"856\":1}}],[\"以避免影响评估结果\",{\"2\":{\"575\":1}}],[\"以避免通用能力显著下降\",{\"2\":{\"501\":1}}],[\"以避免名称冲突\",{\"2\":{\"10\":1}}],[\"以提取高质量的反事实数据\",{\"2\":{\"1224\":1}}],[\"以提升模型的推理效率\",{\"2\":{\"2263\":1}}],[\"以提升模型性能\",{\"2\":{\"1659\":1}}],[\"以提升召回效果\",{\"2\":{\"1610\":1}}],[\"以提升其对人类喜好的量化判断能力\",{\"2\":{\"1541\":1}}],[\"以提升奖励模型的效果\",{\"2\":{\"1213\":1}}],[\"以提升外推能力\",{\"2\":{\"1155\":1}}],[\"以提升训练速度和性能\",{\"2\":{\"894\":1}}],[\"以提升训练稳定性\",{\"2\":{\"275\":1}}],[\"以提高计算效率和训练速度\",{\"2\":{\"2526\":1}}],[\"以提高排序质量\",{\"2\":{\"2394\":1}}],[\"以提高效率和准确性\",{\"2\":{\"2362\":1}}],[\"以提高效率\",{\"2\":{\"2110\":1}}],[\"以提高整体计算效率\",{\"2\":{\"2609\":1}}],[\"以提高整体模型质量\",{\"2\":{\"1913\":1}}],[\"以提高整体效率\",{\"2\":{\"1843\":1}}],[\"以提高模型学习难度\",{\"2\":{\"2256\":1}}],[\"以提高模型的灵活性和适应性\",{\"2\":{\"1796\":1}}],[\"以提高模型的效率和性能\",{\"2\":{\"1692\":1}}],[\"以提高模型在各个任务上的表现\",{\"2\":{\"1794\":1}}],[\"以提高训练稳定性\",{\"2\":{\"1740\":1}}],[\"以提高解决方案质量\",{\"2\":{\"1181\":1}}],[\"以提高测试样本的准确率\",{\"2\":{\"1173\":1}}],[\"以提高下游任务的性能\",{\"2\":{\"1050\":1}}],[\"以提高语言理解能力\",{\"2\":{\"1041\":1}}],[\"以提高适应性\",{\"2\":{\"892\":1}}],[\"以提高处理复杂任务的能力\",{\"2\":{\"791\":1}}],[\"以提高最终效果\",{\"2\":{\"258\":1}}],[\"以非负激活函数替代softmax\",{\"2\":{\"189\":1}}],[\"以其高效的参数使用和出色的性能而闻名\",{\"2\":{\"115\":1}}],[\"以生成式任务为主\",{\"2\":{\"115\":1}}],[\"以及相应的\",{\"2\":{\"2573\":1}}],[\"以及在分布式计算中常用的\",{\"2\":{\"2344\":1}}],[\"以及在预训练阶段进行数据去重的具体方法和注意事项\",{\"2\":{\"425\":1}}],[\"以及基于llm的ai\",{\"2\":{\"2166\":1}}],[\"以及无法使用的显存碎片\",{\"2\":{\"2161\":1}}],[\"以及\",{\"2\":{\"2081\":1}}],[\"以及reduction操作如softmax\",{\"2\":{\"2027\":1}}],[\"以及执行复杂认知任务\",{\"2\":{\"1998\":1}}],[\"以及研究不同偏好标签对学习效果的影响\",{\"2\":{\"1811\":1}}],[\"以及与问题相关的任何外部知识\",{\"2\":{\"1766\":1}}],[\"以及它们的优缺点和适用场景\",{\"2\":{\"1609\":1}}],[\"以及如何训练出具备通用能力且能产生清晰连贯推理过程的模型\",{\"2\":{\"2429\":1}}],[\"以及如何调整损失函数以避免训练不充分的问题\",{\"2\":{\"2267\":1}}],[\"以及如何评估抽取结果的准确性\",{\"2\":{\"1948\":1}}],[\"以及如何组织这些信息\",{\"2\":{\"1550\":1}}],[\"以及如何通过合成和飞轮机制来增强数据集\",{\"2\":{\"2181\":1}}],[\"以及如何通过\",{\"2\":{\"248\":1}}],[\"以及其改进方法实际上就是在进行任务分解\",{\"2\":{\"1375\":1}}],[\"以及其相关技能\",{\"2\":{\"1368\":1}}],[\"以及智能体之间的交流\",{\"2\":{\"1291\":1}}],[\"以及moe模型如qwen2\",{\"2\":{\"1156\":1}}],[\"以及指令微调和强化学习过程\",{\"2\":{\"1046\":1}}],[\"以及学生模型中的哪一层\",{\"2\":{\"845\":1}}],[\"以及预训练中学到的知识\",{\"2\":{\"742\":1}}],[\"以及kl散度\",{\"2\":{\"603\":1}}],[\"以及加入sft损失等\",{\"2\":{\"505\":1}}],[\"以及梯度处理中的\",{\"2\":{\"433\":1}}],[\"以及字符级\",{\"2\":{\"426\":1}}],[\"以及不同频率组合避免位置冲突\",{\"2\":{\"263\":1}}],[\"以及进制转换\",{\"2\":{\"202\":1}}],[\"以及deepseekv2提出的mla\",{\"2\":{\"111\":1}}],[\"以及是否患病的标签\",{\"2\":{\"66\":1}}],[\"蒸馏策略在资源有限的情况下提供了一种可行的高效解决方案\",{\"2\":{\"2661\":1}}],[\"蒸馏策略优势\",{\"2\":{\"2642\":1}}],[\"蒸馏策略能够有效地将更强大的模型转化为更小的模型\",{\"2\":{\"2637\":1}}],[\"蒸馏与强化学习对比\",{\"2\":{\"2642\":1}}],[\"蒸馏和强化学习是两种主要策略\",{\"2\":{\"2637\":1}}],[\"蒸馏模型的性能提升\",{\"0\":{\"2617\":1}}],[\"蒸馏实验结果\",{\"0\":{\"2596\":1}}],[\"蒸馏技术的应用\",{\"0\":{\"1195\":1}}],[\"蒸馏的核心目标是将\",{\"2\":{\"1175\":1}}],[\"蒸馏的方法\",{\"0\":{\"916\":1},\"1\":{\"954\":1,\"995\":1,\"1035\":1}}],[\"蒸馏学习可以用于压缩模型\",{\"2\":{\"715\":1}}],[\"蒸馏算法迁移知识\",{\"2\":{\"954\":1}}],[\"蒸馏算法\",{\"2\":{\"715\":1}}],[\"蒸馏\",{\"2\":{\"40\":1,\"1175\":1,\"2647\":1}}],[\"早停策略防止过拟合\",{\"2\":{\"40\":1}}],[\"小节标题或关键词\",{\"2\":{\"2675\":1}}],[\"小的分块和大的分块各有优势\",{\"2\":{\"2625\":1}}],[\"小心选择数据源\",{\"2\":{\"1311\":1}}],[\"小模型+大数据\",{\"2\":{\"1282\":1}}],[\"小模型\",{\"2\":{\"990\":1,\"1419\":1}}],[\"小\",{\"2\":{\"768\":1}}],[\"小红书\",{\"2\":{\"559\":1}}],[\"小语种根据需求选择性收集\",{\"2\":{\"535\":1}}],[\"小说生成等\",{\"2\":{\"264\":1}}],[\"小数据集使用数据增强提升泛化性\",{\"2\":{\"40\":1}}],[\"小型程序和学习阶段\",{\"2\":{\"27\":1}}],[\"层在\",{\"2\":{\"2253\":2,\"2641\":1}}],[\"层的\",{\"2\":{\"1451\":1,\"1592\":1}}],[\"层的实现差异\",{\"2\":{\"1225\":1}}],[\"层可能无法生成有效表示\",{\"2\":{\"1079\":1}}],[\"层嵌入\",{\"2\":{\"560\":1}}],[\"层占据了总参数量的\",{\"2\":{\"495\":1}}],[\"层通常放置在\",{\"2\":{\"467\":1}}],[\"层数配置\",{\"2\":{\"932\":1}}],[\"层数\",{\"2\":{\"259\":1}}],[\"层归一化\",{\"0\":{\"205\":1},\"2\":{\"104\":1,\"121\":2}}],[\"层参数\",{\"2\":{\"49\":1}}],[\"层\",{\"2\":{\"40\":1,\"560\":1}}],[\"层次聚类\",{\"2\":{\"39\":1}}],[\"前述gpipe和pipedream是分成4个阶段\",{\"2\":{\"2697\":1}}],[\"前面不是说\",{\"2\":{\"2349\":1}}],[\"前向\",{\"2\":{\"2688\":2}}],[\"前向传递和后向传递\",{\"2\":{\"2468\":1}}],[\"前向传播过程如下\",{\"2\":{\"1871\":1}}],[\"前向传播\",{\"2\":{\"435\":1}}],[\"前向kl\",{\"2\":{\"1546\":1}}],[\"前提条件\",{\"0\":{\"1469\":1}}],[\"前提是有足够高质量的pdf\",{\"2\":{\"568\":1}}],[\"前提是有足够高质量的pdf与文本对齐数据\",{\"2\":{\"465\":1}}],[\"前11层网络仅使用相对位置编码\",{\"2\":{\"1237\":1}}],[\"前11层为encoder\",{\"2\":{\"1088\":1}}],[\"前馈块从8组不同参数集中选择两个\",{\"2\":{\"1704\":1}}],[\"前馈神经网络\",{\"2\":{\"144\":1}}],[\"前馈网络激活函数更改\",{\"0\":{\"1092\":1}}],[\"前馈网络\",{\"0\":{\"162\":1},\"2\":{\"104\":1,\"121\":2}}],[\"前沿解决方案\",{\"2\":{\"57\":1}}],[\"前\",{\"2\":{\"40\":1,\"1933\":1,\"2379\":1}}],[\"前缀语言模型\",{\"0\":{\"363\":1}}],[\"前缀\",{\"2\":{\"17\":1,\"27\":1}}],[\"冻结主参数\",{\"2\":{\"2115\":1}}],[\"冻结sft模型参数\",{\"2\":{\"1790\":1}}],[\"冻结sft模型的参数\",{\"2\":{\"1621\":1}}],[\"冻结前\",{\"2\":{\"49\":1}}],[\"冻结\",{\"2\":{\"40\":1}}],[\"调查现有rlhf技术的应用领域\",{\"2\":{\"1863\":1}}],[\"调度器与余弦退火算法在大规模任务中的性能差异\",{\"2\":{\"1629\":1}}],[\"调度器\",{\"2\":{\"1577\":1}}],[\"调度器的三阶段学习率策略\",{\"0\":{\"1344\":1}}],[\"调试效率高\",{\"2\":{\"1451\":1}}],[\"调研最新的数据合成技术\",{\"2\":{\"2409\":1}}],[\"调研最新的多模态嵌入技术及其应用场景\",{\"2\":{\"1225\":1}}],[\"调研针对小语种任务的词表扩充策略\",{\"2\":{\"1800\":1}}],[\"调研现有闭源模型\",{\"2\":{\"851\":1}}],[\"调研现有的开源数据集\",{\"2\":{\"669\":1}}],[\"调研市面上最优的pdf解析服务\",{\"2\":{\"663\":1}}],[\"调研其他开源框架的性能表现并进行对比分析\",{\"2\":{\"1818\":1}}],[\"调研其他增强长文本处理能力的方法\",{\"2\":{\"740\":1}}],[\"调研其他基于rope优化的方法并进行对比实验\",{\"2\":{\"372\":1}}],[\"调研其他激活函数\",{\"2\":{\"311\":1}}],[\"调整后值\",{\"2\":{\"2479\":1}}],[\"调整损失函数可以显著提高模型在多轮对话上的表现\",{\"2\":{\"2442\":1}}],[\"调整损失函数以避免训练不充分\",{\"2\":{\"2361\":1}}],[\"调整裁剪阈值以促进低概率token的探索\",{\"2\":{\"2387\":1}}],[\"调整裁剪阈值为\",{\"2\":{\"2327\":1}}],[\"调整学习率以适应不同数据集\",{\"2\":{\"2233\":1}}],[\"调整策略学习\",{\"2\":{\"2612\":1,\"2665\":1}}],[\"调整策略\",{\"2\":{\"2200\":1}}],[\"调整策略以优化整条轨迹的奖励\",{\"2\":{\"2171\":1}}],[\"调整策略以最大化期望回报\",{\"2\":{\"844\":1}}],[\"调整因子\",{\"2\":{\"2092\":1}}],[\"调整正则化系数\",{\"2\":{\"1966\":1}}],[\"调整trainer类方法\",{\"0\":{\"1832\":1}}],[\"调整奖励公式以反映新的策略有效性\",{\"2\":{\"1790\":1}}],[\"调整权重或通过残差连接发送至下一层\",{\"2\":{\"1219\":1}}],[\"调整ptx\",{\"2\":{\"1123\":1}}],[\"调整模型大小\",{\"2\":{\"1329\":1}}],[\"调整模型参数以最小化损失\",{\"2\":{\"858\":1}}],[\"调整模型结构\",{\"2\":{\"40\":1}}],[\"调整rope参数对远程注意力的影响为模型优化提供了新思路\",{\"2\":{\"634\":1}}],[\"调整rope参数以减少远距离token衰减\",{\"2\":{\"567\":1}}],[\"调整数据比例\",{\"2\":{\"475\":1}}],[\"调整query和key的比例\",{\"2\":{\"346\":1}}],[\"调整参数\",{\"2\":{\"185\":1,\"912\":1}}],[\"调用处理时\",{\"2\":{\"2037\":1}}],[\"调用为一个更容易处理的小任务\",{\"2\":{\"1760\":1}}],[\"调用来处理上一步骤的输出\",{\"2\":{\"1702\":1}}],[\"调用经典planner\",{\"2\":{\"1465\":1}}],[\"调用链构建等\",{\"2\":{\"1392\":1}}],[\"调用相比\",{\"2\":{\"1118\":1}}],[\"调用函数\",{\"2\":{\"11\":1}}],[\"调用\",{\"2\":{\"10\":1,\"1392\":1,\"2374\":1}}],[\"选用何种向量化工具来构建向量库\",{\"2\":{\"1450\":1}}],[\"选自提供文本内容\",{\"2\":{\"1276\":1}}],[\"选自深度学习技术文档\",{\"2\":{\"362\":1}}],[\"选出得分最高的答案\",{\"2\":{\"1164\":1}}],[\"选取内容\",{\"2\":{\"2003\":1,\"2360\":1}}],[\"选取内容来源\",{\"2\":{\"818\":1}}],[\"选取最高分的\",{\"2\":{\"1075\":1}}],[\"选取与当前测试句子\",{\"2\":{\"910\":1}}],[\"选择开源模型\",{\"2\":{\"2699\":1}}],[\"选择一些推理链进行编辑\",{\"2\":{\"2514\":1}}],[\"选择一个锚样本\",{\"2\":{\"1784\":1}}],[\"选择何种初始化策略需权衡特征学习效率与训练稳定性\",{\"2\":{\"2372\":1}}],[\"选择精度相同但显存消耗更低的算子\",{\"2\":{\"2073\":1,\"2125\":1}}],[\"选择具有代表性语义的词进行初始化\",{\"2\":{\"2069\":1}}],[\"选择具有代表性语义的词作为伪标记的初始化\",{\"2\":{\"1796\":1}}],[\"选择贡献最大的top\",{\"2\":{\"1809\":1}}],[\"选择top\",{\"2\":{\"1809\":1}}],[\"选择稳定\",{\"2\":{\"1740\":1}}],[\"选择合适的分块大小需要综合考虑嵌入模型\",{\"2\":{\"2655\":1}}],[\"选择合适的分块大小是影响文本处理效果的重要因素\",{\"2\":{\"2655\":1}}],[\"选择合适的蒸馏策略\",{\"2\":{\"2652\":1}}],[\"选择合适的数据类型\",{\"2\":{\"2266\":1}}],[\"选择合适的基线以降低方差\",{\"2\":{\"2096\":1,\"2147\":1}}],[\"选择合适的路径或模块来处理任务\",{\"2\":{\"1728\":1}}],[\"选择合适激活函数\",{\"2\":{\"380\":1}}],[\"选择适当的上下文\",{\"0\":{\"1550\":1}}],[\"选择适合的kv压缩方式\",{\"2\":{\"353\":1}}],[\"选择适合的语言模型\",{\"2\":{\"133\":1}}],[\"选择训练框架\",{\"2\":{\"1542\":1}}],[\"选择megatron\",{\"0\":{\"1451\":1}}],[\"选择未绑定嵌入以提升性能\",{\"2\":{\"1304\":1}}],[\"选择算法\",{\"2\":{\"1302\":1}}],[\"选择最合适的索引进行数据检索\",{\"2\":{\"1285\":1}}],[\"选择最佳参数数量和训练令牌数量对结果影响显著\",{\"2\":{\"1201\":1}}],[\"选择最优分词\",{\"2\":{\"444\":1}}],[\"选择使用自有标注数据以确保高质量训练\",{\"2\":{\"1114\":1}}],[\"选择高质量的数据源\",{\"2\":{\"929\":1}}],[\"选择策略\",{\"2\":{\"844\":1}}],[\"选择性激活\",{\"2\":{\"664\":1}}],[\"选择模型架构\",{\"2\":{\"560\":1}}],[\"选择垂域相关内容作为扩充数据\",{\"2\":{\"532\":1}}],[\"选择得分最高的答案作为最终结果\",{\"2\":{\"528\":1}}],[\"选择pre\",{\"2\":{\"1203\":1}}],[\"选择p\",{\"2\":{\"444\":1}}],[\"选择互信息最大的子词对合并\",{\"2\":{\"381\":1}}],[\"选择插值方法\",{\"2\":{\"359\":1}}],[\"选择不合适的\",{\"2\":{\"338\":1}}],[\"选择预训练模型\",{\"2\":{\"40\":1}}],[\"选题与开题\",{\"2\":{\"4\":1}}],[\"步骤流程\",{\"0\":{\"2413\":1}}],[\"步骤三\",{\"2\":{\"1353\":1}}],[\"步骤二\",{\"2\":{\"1353\":1}}],[\"步骤一\",{\"2\":{\"1353\":1}}],[\"步骤可预定义的场景\",{\"2\":{\"1269\":1}}],[\"步骤5\",{\"2\":{\"359\":1,\"381\":1}}],[\"步骤4\",{\"2\":{\"359\":1,\"381\":1}}],[\"步骤3\",{\"2\":{\"287\":1,\"359\":1,\"381\":1,\"1374\":1,\"1890\":1}}],[\"步骤2\",{\"0\":{\"1712\":1},\"2\":{\"287\":1,\"359\":1,\"381\":1,\"1374\":1,\"1890\":1}}],[\"步骤1\",{\"0\":{\"1657\":1},\"2\":{\"287\":1,\"359\":1,\"381\":1,\"1374\":1,\"1890\":1}}],[\"步骤0\",{\"2\":{\"245\":1}}],[\"步骤解析\",{\"2\":{\"125\":1}}],[\"步骤\",{\"2\":{\"40\":1,\"49\":2,\"166\":1,\"187\":1,\"421\":1,\"446\":1,\"473\":1}}],[\"降序排序后的最好状态的\",{\"2\":{\"2183\":1}}],[\"降采样矩阵\",{\"2\":{\"283\":1}}],[\"降至\",{\"2\":{\"189\":1}}],[\"降低系统性能和回答质量\",{\"2\":{\"2533\":1}}],[\"降低召回精度\",{\"0\":{\"2465\":1}}],[\"降低\",{\"2\":{\"2402\":1}}],[\"降低计算资源消耗\",{\"2\":{\"2166\":1}}],[\"降低计算复杂度\",{\"2\":{\"1653\":1}}],[\"降低方差\",{\"2\":{\"1992\":1,\"2045\":1}}],[\"降低了计算成本\",{\"2\":{\"1121\":1}}],[\"降低到了\",{\"2\":{\"2008\":1}}],[\"降低到\",{\"2\":{\"941\":1}}],[\"降低推理时的计算复杂度\",{\"2\":{\"868\":1}}],[\"降低模型部署的成本\",{\"0\":{\"794\":1}}],[\"降低梯度更新幅度\",{\"2\":{\"593\":1}}],[\"降低配比数据\",{\"2\":{\"558\":1}}],[\"降低部分区域计算\",{\"2\":{\"305\":1}}],[\"降低碳排放\",{\"2\":{\"57\":1}}],[\"降低数据需求\",{\"2\":{\"40\":1}}],[\"降维\",{\"2\":{\"39\":1}}],[\"降维算法\",{\"2\":{\"39\":1}}],[\"优选框架\",{\"2\":{\"1404\":1}}],[\"优先考虑使用gqa或mla\",{\"2\":{\"353\":1}}],[\"优先选择\",{\"2\":{\"275\":1,\"1542\":1}}],[\"优缺点分析\",{\"0\":{\"434\":1,\"529\":1,\"907\":1},\"1\":{\"943\":1,\"985\":1}}],[\"优缺点\",{\"2\":{\"305\":1}}],[\"优点是适配性强\",{\"2\":{\"1722\":1}}],[\"优点\",{\"0\":{\"943\":1,\"969\":1,\"1424\":1,\"1773\":1,\"2445\":1,\"2499\":1,\"2534\":1,\"2568\":1,\"2592\":1,\"2613\":1,\"2630\":1,\"2645\":1},\"2\":{\"168\":1,\"169\":3,\"194\":1,\"215\":1,\"238\":1,\"246\":2,\"261\":1,\"285\":1,\"292\":1,\"307\":1,\"330\":1,\"434\":1,\"529\":1,\"941\":1,\"983\":1,\"1023\":1,\"1281\":1,\"1328\":1,\"1373\":1}}],[\"优势值\",{\"2\":{\"2357\":1}}],[\"优势与挑战\",{\"0\":{\"2103\":1}}],[\"优势与局限\",{\"2\":{\"40\":1}}],[\"优势分析\",{\"2\":{\"1932\":1}}],[\"优势函数应用\",{\"2\":{\"2306\":1}}],[\"优势函数估计\",{\"2\":{\"2306\":1}}],[\"优势函数\",{\"2\":{\"2004\":1,\"2238\":1}}],[\"优势函数通过下式计算\",{\"2\":{\"1683\":1}}],[\"优势函数计算\",{\"0\":{\"1683\":1}}],[\"优势函数在每个输出token处都进行计算\",{\"2\":{\"1622\":1}}],[\"优势函数的计算\",{\"2\":{\"1622\":1}}],[\"优势\",{\"0\":{\"1514\":1},\"2\":{\"40\":1,\"212\":1,\"400\":1,\"419\":1,\"595\":1,\"2103\":1}}],[\"优化过长回答的奖励机制\",{\"0\":{\"2677\":1},\"1\":{\"2680\":1,\"2683\":1,\"2686\":1,\"2689\":1,\"2692\":1,\"2695\":1,\"2698\":1,\"2701\":1}}],[\"优化过程是寻找代价函数的最小值\",{\"2\":{\"32\":1}}],[\"优化数据索引\",{\"2\":{\"2499\":1}}],[\"优化多轮对话的处理效率将成为研究热点之一\",{\"2\":{\"2497\":1}}],[\"优化代码实现\",{\"2\":{\"2471\":1}}],[\"优化代码以提高计算效率\",{\"2\":{\"1852\":1}}],[\"优化loss计算方法以提高训练效率\",{\"2\":{\"2410\":1}}],[\"优化训练脚本参数以提高效率\",{\"2\":{\"2332\":1}}],[\"优化存储与检索效率\",{\"0\":{\"2237\":1}}],[\"优化ppo方向的算法\",{\"2\":{\"2202\":1}}],[\"优化循环\",{\"0\":{\"2224\":1},\"2\":{\"2089\":1}}],[\"优化动态缩放头的训练策略以提高模型效率\",{\"2\":{\"2078\":1}}],[\"优化ai框架的显存管理\",{\"2\":{\"2214\":1}}],[\"优化ai框架中产生的中间副本\",{\"2\":{\"2073\":1}}],[\"优化attention计算复杂度的技术探讨\",{\"0\":{\"81\":1},\"1\":{\"94\":1,\"109\":1,\"127\":1,\"147\":1,\"168\":1,\"189\":1,\"210\":1,\"233\":1,\"257\":1,\"281\":1,\"305\":1,\"327\":1},\"2\":{\"63\":1}}],[\"优化attention计算复杂度的技术探讨|优化attention计算复杂度的技术探讨\",{\"2\":{\"5\":1}}],[\"优化后内存需求\",{\"2\":{\"2065\":1}}],[\"优化system\",{\"0\":{\"2064\":1},\"1\":{\"2117\":1,\"2166\":1}}],[\"优化奖励设计\",{\"2\":{\"1989\":1}}],[\"优化其策略梯度\",{\"2\":{\"1901\":1}}],[\"优化细节\",{\"0\":{\"1762\":1}}],[\"优化公式如下\",{\"2\":{\"1628\":1}}],[\"优化公式\",{\"0\":{\"1628\":1}}],[\"优化参数配置\",{\"2\":{\"1542\":1}}],[\"优化目标\",{\"2\":{\"1471\":1}}],[\"优化目标的核心区别\",{\"0\":{\"655\":1}}],[\"优化冷启动数据策略以提高模型性能\",{\"2\":{\"1387\":1}}],[\"优化模型参数\",{\"2\":{\"2377\":1}}],[\"优化模型在选择与拒绝回答的概率差异\",{\"2\":{\"1620\":1}}],[\"优化模型在长距离依赖上的表现\",{\"2\":{\"475\":1}}],[\"优化模型训练效率\",{\"2\":{\"1348\":1}}],[\"优化n\",{\"2\":{\"1307\":1}}],[\"优化和增强\",{\"2\":{\"1185\":1}}],[\"优化资源分配\",{\"2\":{\"1162\":1}}],[\"优化器更新模型参数\",{\"2\":{\"2468\":1}}],[\"优化器通过显存的精细管理来提高模型训练的效率\",{\"2\":{\"2161\":1}}],[\"优化器状态分区\",{\"0\":{\"2308\":1}}],[\"优化器状态占据了显存的\",{\"2\":{\"2161\":1}}],[\"优化器状态值\",{\"2\":{\"2123\":1}}],[\"优化器状态\",{\"2\":{\"2021\":1,\"2047\":1,\"2099\":1,\"2192\":1,\"2447\":1}}],[\"优化器与学习率\",{\"2\":{\"1204\":1}}],[\"优化器\",{\"2\":{\"1162\":1,\"1248\":1,\"1605\":1}}],[\"优化长序列数据建模\",{\"2\":{\"1112\":1}}],[\"优化高维数据处理将成为重点\",{\"2\":{\"985\":1}}],[\"优化为多查询注意力\",{\"2\":{\"889\":1}}],[\"优化策略至关重要\",{\"2\":{\"1197\":1}}],[\"优化策略\",{\"0\":{\"2559\":1,\"2634\":1,\"2664\":1},\"1\":{\"2567\":1,\"2575\":1,\"2583\":1,\"2591\":1,\"2598\":1,\"2605\":1,\"2612\":1,\"2619\":1,\"2624\":1,\"2629\":1,\"2639\":1,\"2644\":1,\"2649\":1,\"2654\":1,\"2658\":1,\"2662\":1,\"2665\":1,\"2667\":1,\"2668\":1,\"2670\":1,\"2671\":1,\"2673\":1,\"2674\":1,\"2676\":1},\"2\":{\"844\":1,\"1969\":1,\"2054\":1}}],[\"优化并发数量设置\",{\"2\":{\"663\":1}}],[\"优化kv\",{\"2\":{\"613\":1}}],[\"优化领域数据比例\",{\"2\":{\"599\":1}}],[\"优化这些步骤可以显著提升模型性能\",{\"2\":{\"580\":1}}],[\"优化放置位置\",{\"2\":{\"560\":1}}],[\"优化注意力机制\",{\"2\":{\"502\":1}}],[\"优化\",{\"2\":{\"297\":1,\"1441\":1,\"1578\":1}}],[\"优化初始化策略以提升post\",{\"2\":{\"234\":1}}],[\"优化初始训练阶段的梯度问题\",{\"2\":{\"150\":1}}],[\"优化嵌入调整\",{\"2\":{\"221\":1}}],[\"优化跨块注意力的计算效率\",{\"2\":{\"196\":1}}],[\"优化深层网络的梯度回传\",{\"0\":{\"183\":1}}],[\"优化点\",{\"2\":{\"170\":1,\"191\":1,\"1021\":1}}],[\"优化了固定大小文本切块方法的缺陷\",{\"2\":{\"1763\":1}}],[\"优化了注意力权重的计算\",{\"2\":{\"163\":1}}],[\"优化了资源使用\",{\"2\":{\"155\":1}}],[\"优化了计算效率和模型性能\",{\"2\":{\"138\":1}}],[\"优化算法\",{\"2\":{\"87\":1,\"1521\":1}}],[\"优化任务目标\",{\"2\":{\"40\":1}}],[\"优化商品推荐\",{\"2\":{\"39\":1}}],[\"优化分词算法\",{\"0\":{\"298\":1},\"1\":{\"320\":1,\"343\":1,\"367\":1,\"393\":1,\"419\":1,\"444\":1,\"471\":1,\"498\":1,\"530\":1,\"563\":1},\"2\":{\"5\":2}}],[\"优化子词分词的技巧与实践\",{\"0\":{\"274\":1},\"1\":{\"297\":1,\"319\":1,\"342\":1,\"366\":1,\"392\":1,\"418\":1,\"443\":1,\"470\":1,\"497\":1,\"529\":1,\"562\":1,\"597\":1,\"631\":1},\"2\":{\"5\":1}}],[\"优化子词分词的技巧与实践|使用byte\",{\"2\":{\"5\":1}}],[\"优化transformer自回归生成效率\",{\"0\":{\"68\":1,\"78\":1},\"1\":{\"78\":1,\"92\":1,\"107\":1,\"125\":1,\"145\":1,\"166\":1,\"187\":1,\"208\":1,\"231\":1,\"255\":1,\"279\":1,\"303\":1},\"2\":{\"5\":1,\"63\":1}}],[\"优化transformer自回归生成效率|kv\",{\"2\":{\"5\":1}}],[\"迁移学习原理与实践整合为统一框架\",{\"2\":{\"65\":1}}],[\"迁移学习方法对比\",{\"2\":{\"40\":1}}],[\"迁移学习步骤\",{\"2\":{\"40\":1}}],[\"迁移学习核心思想\",{\"2\":{\"40\":1}}],[\"迁移学习的定义与实施流程\",{\"0\":{\"40\":1}}],[\"二级标题或三级标题\",{\"2\":{\"2235\":1}}],[\"二者皆为token序列\",{\"2\":{\"1673\":1}}],[\"二者的优化目标虽然都涉及数据分布下期望值的优化\",{\"2\":{\"587\":1}}],[\"二维位置编码技术\",{\"0\":{\"1045\":1}}],[\"二维张量掩码会变成四维张量\",{\"2\":{\"917\":1}}],[\"二维情况下的公式\",{\"2\":{\"247\":1}}],[\"二值网络\",{\"2\":{\"768\":1}}],[\"二是内存占用是动态的\",{\"2\":{\"750\":1}}],[\"二叉搜索树\",{\"2\":{\"41\":1}}],[\"二叉树\",{\"2\":{\"41\":1}}],[\"二\",{\"0\":{\"40\":1,\"1893\":1},\"1\":{\"1948\":1,\"1999\":1,\"2050\":1,\"2103\":1}}],[\"正如\",{\"2\":{\"2408\":1}}],[\"正则化系数的应用\",{\"0\":{\"1857\":1}}],[\"正则化\",{\"2\":{\"1575\":1}}],[\"正确性\",{\"2\":{\"2257\":1}}],[\"正确率奖励\",{\"2\":{\"1797\":1}}],[\"正确答案获得\",{\"2\":{\"1740\":1}}],[\"正确行动数\",{\"2\":{\"1594\":1}}],[\"正确设置\",{\"2\":{\"1399\":1}}],[\"正确的选择做得多了才能更快的向正确的结果收敛\",{\"2\":{\"39\":1}}],[\"正弦位置编码的相对位置表达能力可能被投影矩阵破坏\",{\"2\":{\"1343\":1}}],[\"正弦和余弦函数具有周期性和规律性\",{\"2\":{\"1246\":1}}],[\"正弦函数是否是唯一选择\",{\"2\":{\"356\":1}}],[\"正弦函数具有周期性和无穷可扩展性\",{\"2\":{\"263\":1}}],[\"正弦函数的应用\",{\"0\":{\"263\":1}}],[\"正样本\",{\"2\":{\"983\":1}}],[\"正类走右子树\",{\"2\":{\"980\":1}}],[\"正常情况下损失会逐渐下降并趋于稳定\",{\"2\":{\"516\":1}}],[\"正面或负面情绪\",{\"2\":{\"39\":1}}],[\"等非推理模型\",{\"2\":{\"2603\":1}}],[\"等分\",{\"2\":{\"2218\":2}}],[\"等待所有进程达到一定程度后再执行指令\",{\"2\":{\"2201\":1}}],[\"等待人类反馈\",{\"2\":{\"1501\":1}}],[\"等算法的实现\",{\"2\":{\"2081\":1}}],[\"等同于保存了过去经历的记忆\",{\"2\":{\"2011\":1}}],[\"等于\",{\"2\":{\"1868\":3,\"2431\":1}}],[\"等任务\",{\"2\":{\"1701\":1}}],[\"等人提出了一个非常值得深思的观点\",{\"2\":{\"1617\":1}}],[\"等组件\",{\"2\":{\"1542\":1}}],[\"等架构\",{\"2\":{\"560\":1}}],[\"等方法构建\",{\"2\":{\"393\":1}}],[\"等方法完成的\",{\"2\":{\"32\":1}}],[\"等\",{\"0\":{\"1467\":1},\"2\":{\"39\":1,\"381\":1,\"909\":1,\"1439\":1,\"1708\":1,\"2215\":1,\"2640\":1}}],[\"疾病类型等\",{\"2\":{\"39\":1}}],[\"垃圾邮件\",{\"2\":{\"39\":1}}],[\"垃圾邮件检测\",{\"2\":{\"39\":1}}],[\"问题解决与策略调整\",{\"0\":{\"2605\":1,\"2662\":1}}],[\"问题被拆解为子问题\",{\"2\":{\"2554\":1}}],[\"问题pddl\",{\"2\":{\"1465\":1}}],[\"问题翻译\",{\"2\":{\"1465\":1}}],[\"问题与挑战\",{\"0\":{\"1411\":1},\"1\":{\"1457\":1,\"1503\":1}}],[\"问题分解器和子问题解决器\",{\"2\":{\"1224\":1}}],[\"问题陈述或请求模型执行的操作\",{\"2\":{\"670\":1}}],[\"问题类型\",{\"2\":{\"591\":1}}],[\"问题\",{\"2\":{\"238\":1,\"261\":1,\"290\":1,\"308\":1,\"465\":1,\"498\":1,\"523\":1,\"529\":1,\"533\":1,\"556\":1,\"568\":1,\"1125\":1,\"1394\":1,\"1766\":1,\"1774\":1}}],[\"问题背景\",{\"0\":{\"42\":1}}],[\"问题目标明确\",{\"2\":{\"39\":1}}],[\"问答系统的基本架\",{\"2\":{\"207\":1}}],[\"问答系统\",{\"2\":{\"38\":1,\"240\":1,\"901\":1,\"1019\":1}}],[\"普通客户等\",{\"2\":{\"39\":1}}],[\"每层有两个神经元\",{\"2\":{\"2526\":1}}],[\"每张卡再独立进行参数更新\",{\"2\":{\"2374\":1}}],[\"每张卡根据拿到的\",{\"2\":{\"2374\":1}}],[\"每张卡都保存一个完整模型的副本\",{\"2\":{\"2374\":1}}],[\"每张卡只存储\",{\"2\":{\"2308\":1}}],[\"每张卡的通信数据量\",{\"2\":{\"2276\":1}}],[\"每秒生成的\",{\"2\":{\"2228\":1}}],[\"每种类型都有其独特的实现方式和应用场景\",{\"2\":{\"1752\":1}}],[\"每种方法各有优缺点\",{\"2\":{\"896\":1}}],[\"每日工作时间\",{\"2\":{\"1374\":1}}],[\"每日观察测试集合上的loss表现\",{\"2\":{\"651\":1}}],[\"每日观察模型在这些集合上的损失\",{\"2\":{\"516\":1}}],[\"每块gpu上\",{\"2\":{\"2667\":1}}],[\"每块gpu就可以继续独立计算\",{\"2\":{\"2616\":1}}],[\"每块长度为\",{\"2\":{\"2286\":1}}],[\"每块的长度为\",{\"2\":{\"2286\":2}}],[\"每块a800的吞吐量为210\",{\"2\":{\"1232\":1}}],[\"每块500词\",{\"2\":{\"116\":1}}],[\"每列对应一个量化系数\",{\"2\":{\"981\":1}}],[\"每行对应一个量化系数\",{\"2\":{\"981\":1}}],[\"每一个变量都会触发一次\",{\"2\":{\"2079\":1}}],[\"每一个示例都包含\",{\"2\":{\"1766\":1}}],[\"每一个状态的价值被估计为回报的平均值\",{\"2\":{\"778\":1}}],[\"每一步\",{\"2\":{\"2276\":1}}],[\"每一步都由一个\",{\"2\":{\"1702\":1}}],[\"每一步的损失函数\",{\"2\":{\"820\":1}}],[\"每一步从每个候选序列的概率分布中选择概率最高的\",{\"2\":{\"324\":1}}],[\"每条序列形如\",{\"2\":{\"778\":1}}],[\"每生成一个token需要加载的数据总量为14\",{\"2\":{\"429\":1}}],[\"每次训练前进行采样\",{\"2\":{\"2519\":1}}],[\"每次训练前采样200个样本\",{\"2\":{\"662\":1}}],[\"每次喂给模型一个chunk并更新kv缓存\",{\"2\":{\"2386\":1}}],[\"每次需要修改的文件数量以及每个文件的修改方式可能因具体任务而异\",{\"2\":{\"2139\":1}}],[\"每次调用一个\",{\"2\":{\"2037\":1}}],[\"每次迭代都旨在改进前一次的结果\",{\"2\":{\"2026\":1}}],[\"每次只更新部分权重\",{\"2\":{\"983\":1}}],[\"每次交互后\",{\"2\":{\"690\":1}}],[\"每次选择概率最高的词\",{\"2\":{\"301\":1}}],[\"每次选择概率最大的词\",{\"2\":{\"253\":1}}],[\"每次生成新的token时都需要计算之前所有token的attention值\",{\"2\":{\"107\":1}}],[\"每句话独立归一化\",{\"2\":{\"227\":1}}],[\"每组单独处理\",{\"2\":{\"197\":1}}],[\"每组单独计算注意力\",{\"2\":{\"136\":1}}],[\"每组大小\",{\"2\":{\"197\":1}}],[\"每组共享一组kv\",{\"2\":{\"191\":1}}],[\"每组数据具有相似的特性\",{\"2\":{\"39\":1}}],[\"每个计算节点都保存完整的模型\",{\"2\":{\"2704\":1}}],[\"每个设备上最少只需要保存一份micro\",{\"2\":{\"2694\":1}}],[\"每个mini\",{\"2\":{\"2691\":1}}],[\"每个词出现的概率\",{\"2\":{\"2660\":1}}],[\"每个阶段的通信量都相等\",{\"2\":{\"2621\":1}}],[\"每个蓝色块表示一个被复制\",{\"2\":{\"2579\":1}}],[\"每个全连接层都涉及矩阵乘法\",{\"2\":{\"2579\":1}}],[\"每个全连接层的参数矩阵被量化为低比特整数矩阵和标量向量\",{\"2\":{\"1588\":1}}],[\"每个节点在完成了自己的计算后会生成一组梯度\",{\"2\":{\"2452\":1}}],[\"每个节点只需通过很少的步数即可连接到其他任何节点\",{\"2\":{\"2234\":1}}],[\"每个向量可能代表了文档的不同方面\",{\"2\":{\"2304\":1}}],[\"每个叶子节点存储一个数据点\",{\"2\":{\"2195\":1}}],[\"每个非叶子节点表示将输入空间划分为两半的一个超平面\",{\"2\":{\"2195\":1}}],[\"每个kernel将输入数据从低速的hbm中加载到高速的sram中\",{\"2\":{\"2128\":1}}],[\"每个参数量化后\",{\"2\":{\"2085\":1}}],[\"每个文本块最多包含\",{\"2\":{\"1937\":1}}],[\"每个文本块与前一个块有\",{\"2\":{\"1598\":1}}],[\"每个响应的基线值被设置为其奖励减去其他响应奖励的均值\",{\"2\":{\"1901\":1}}],[\"每个分块的语义完整性更高\",{\"2\":{\"1514\":1}}],[\"每个分块对应一个完整的逻辑单元\",{\"2\":{\"1424\":1}}],[\"每个gpu上的数据维度是\",{\"2\":{\"1456\":1}}],[\"每个智能体都具有独特的策略和行为\",{\"2\":{\"1338\":1}}],[\"每个位置编码值在\",{\"2\":{\"1296\":1}}],[\"每个token被视为一个动作\",{\"2\":{\"1673\":1}}],[\"每个token分配给第\",{\"2\":{\"1326\":1}}],[\"每个token只与其他token的一个子集计算attention\",{\"2\":{\"1179\":1}}],[\"每个token之间两两计算attention\",{\"2\":{\"1179\":1}}],[\"每个token对应的kv\",{\"2\":{\"455\":1}}],[\"每个expert接收的token上限为\",{\"2\":{\"1119\":1}}],[\"每个类别在向量空间中保持等距\",{\"2\":{\"1068\":1}}],[\"每个组比如\",{\"2\":{\"1022\":1}}],[\"每个通道单独用一组量化参数\",{\"2\":{\"981\":1}}],[\"每个固定长度的块可以看成虚拟内存中的页\",{\"2\":{\"750\":1}}],[\"每个样本可以被使用多次\",{\"2\":{\"712\":1}}],[\"每个样本都带有明确标签\",{\"2\":{\"690\":1}}],[\"每个状态的期望回报\",{\"2\":{\"647\":1}}],[\"每个单词被拆分为基础字母或符号\",{\"2\":{\"381\":1}}],[\"每个矩阵元素执行一次乘加运算\",{\"2\":{\"376\":1}}],[\"每个attention\",{\"2\":{\"293\":1}}],[\"每个头的维度为\",{\"2\":{\"1782\":1}}],[\"每个头的维度\",{\"2\":{\"259\":1}}],[\"每个\",{\"2\":{\"162\":1,\"1409\":1,\"2145\":1,\"2402\":1,\"2636\":1}}],[\"每个子空间通过不同的注意力头关注不同的信息\",{\"2\":{\"149\":1}}],[\"每个服务都有独特的认证机制\",{\"2\":{\"137\":1}}],[\"每个新token的生成都会依赖于之前所有token的key和value向量\",{\"2\":{\"125\":1}}],[\"每个块包含固定长度的token\",{\"2\":{\"750\":1}}],[\"每个块包含一部分文本\",{\"2\":{\"116\":1}}],[\"每个块内的单词仅与同块内其他单词交互\",{\"2\":{\"116\":1}}],[\"每个库中都有一个叫做\",{\"2\":{\"10\":1}}],[\"单卡的计算量保持恒定\",{\"2\":{\"2704\":1}}],[\"单并发\",{\"2\":{\"1843\":2}}],[\"单步mdp模型\",{\"0\":{\"1787\":1}}],[\"单步mdp视角\",{\"2\":{\"1673\":1}}],[\"单智能体在任务规划\",{\"2\":{\"1439\":1}}],[\"单智能体应用\",{\"0\":{\"1439\":1}}],[\"单独训练大小向量mmm以优化模型性能\",{\"2\":{\"1890\":1}}],[\"单独的文本命令\",{\"2\":{\"1368\":1}}],[\"单独对每个块应用注意力机制\",{\"2\":{\"116\":1}}],[\"单纯依靠指标或使用\",{\"2\":{\"1309\":1}}],[\"单纯的文本转换可能会导致表格原有结构的丢失\",{\"2\":{\"1284\":1}}],[\"单射性和同构性\",{\"2\":{\"918\":1}}],[\"单位是bytes\",{\"2\":{\"1977\":1}}],[\"单位是flops\",{\"2\":{\"1977\":1}}],[\"单位通常是ops\",{\"2\":{\"1977\":1}}],[\"单位\",{\"2\":{\"837\":1,\"873\":1,\"909\":1,\"2192\":1}}],[\"单个智能体的特点包括\",{\"2\":{\"1241\":1}}],[\"单个智能体进行任务规划与行动\",{\"0\":{\"1241\":1}}],[\"单个智能体\",{\"2\":{\"1139\":1,\"1241\":1}}],[\"单个请求\",{\"2\":{\"750\":1}}],[\"单个序列输入进来需要占用1\",{\"2\":{\"750\":1}}],[\"单个文档内部的重复\",{\"2\":{\"575\":1}}],[\"单向注意力\",{\"2\":{\"595\":1}}],[\"单视频\",{\"2\":{\"526\":1}}],[\"单一方法可能难以应对复杂场景\",{\"2\":{\"630\":1}}],[\"单一信息检索任务\",{\"2\":{\"524\":1}}],[\"单一分词方案\",{\"2\":{\"445\":1}}],[\"单词的具体操作示例\",{\"2\":{\"444\":1}}],[\"单词\",{\"2\":{\"443\":1}}],[\"单调\",{\"2\":{\"400\":1}}],[\"单组内上下文长度\",{\"2\":{\"197\":1}}],[\"单类支持向量机\",{\"2\":{\"39\":1}}],[\"单变量线性回归\",{\"0\":{\"32\":1}}],[\"孤立森林\",{\"2\":{\"39\":1}}],[\"异常数据或数据关系\",{\"2\":{\"39\":1}}],[\"异常检测\",{\"2\":{\"39\":2}}],[\"异常处理\",{\"2\":{\"24\":2}}],[\"标记文本所属章节或小节\",{\"2\":{\"2675\":1}}],[\"标记真实性\",{\"2\":{\"1510\":1}}],[\"标点处或通过模型预测段落边界进行分块\",{\"2\":{\"1470\":1}}],[\"标点符号比例等标准筛选不正规文章\",{\"2\":{\"548\":1}}],[\"标识符来表示分隔\",{\"2\":{\"1193\":1}}],[\"标识\",{\"2\":{\"917\":1}}],[\"标题是快速生成摘要的核心文本\",{\"2\":{\"2196\":1}}],[\"标题\",{\"2\":{\"485\":1}}],[\"标准safe\",{\"0\":{\"1925\":1}}],[\"标准attention\",{\"0\":{\"1868\":1}}],[\"标准attention与safe\",{\"0\":{\"1806\":1},\"1\":{\"1868\":1,\"1925\":1},\"2\":{\"193\":1}}],[\"标准优化目标\",{\"2\":{\"614\":1}}],[\"标准化\",{\"0\":{\"480\":1}}],[\"标注数据场景\",{\"2\":{\"39\":1}}],[\"标签平滑\",{\"2\":{\"1960\":1}}],[\"标签\",{\"0\":{\"571\":1,\"805\":1,\"962\":1,\"999\":1,\"1024\":1,\"1055\":1,\"1214\":1,\"1272\":1,\"1521\":1,\"1532\":1,\"1637\":1,\"1678\":1,\"1755\":1,\"1767\":1,\"1780\":1,\"1829\":1,\"1842\":1,\"2193\":1,\"2683\":1},\"2\":{\"39\":1,\"71\":1,\"74\":1,\"80\":1,\"85\":1,\"87\":1,\"88\":1,\"92\":1,\"94\":1,\"96\":1,\"104\":1,\"110\":1,\"119\":1,\"132\":1,\"139\":1,\"142\":1,\"154\":1,\"160\":1,\"181\":1,\"182\":1,\"225\":1,\"226\":1,\"229\":1,\"273\":1,\"286\":1,\"297\":1,\"320\":1,\"328\":1,\"344\":1,\"345\":1,\"347\":1,\"377\":1,\"382\":1,\"384\":1,\"396\":1,\"397\":1,\"398\":1,\"405\":1,\"424\":1,\"431\":1,\"436\":1,\"437\":1,\"478\":1,\"484\":1,\"487\":1,\"489\":1,\"539\":1,\"540\":1,\"543\":1,\"545\":1,\"550\":1,\"552\":1,\"573\":1,\"588\":1,\"617\":1,\"641\":1,\"642\":1,\"655\":6,\"659\":1,\"832\":1,\"835\":1,\"836\":1,\"848\":1,\"854\":1,\"859\":1,\"861\":1,\"862\":1,\"865\":1,\"883\":1,\"887\":1,\"890\":1,\"899\":1,\"908\":1,\"920\":1,\"922\":1,\"930\":1,\"935\":1,\"986\":1,\"987\":1,\"988\":1,\"990\":1,\"1000\":1,\"1001\":1,\"1015\":1,\"1017\":1,\"1018\":1,\"1044\":1,\"1063\":1,\"1070\":1,\"1085\":1,\"1086\":1,\"1098\":1,\"1101\":1,\"1103\":1,\"1148\":1,\"1414\":1,\"1445\":1,\"1449\":1,\"1461\":1,\"1471\":1,\"1473\":1,\"1478\":1,\"1479\":1,\"1486\":1,\"1489\":1,\"1497\":1,\"1516\":1,\"1546\":1,\"1568\":1,\"1575\":1,\"1583\":1,\"1599\":1,\"1604\":1,\"1605\":1,\"1615\":1,\"1624\":1,\"1625\":1,\"1638\":1,\"1682\":1,\"1689\":1,\"1694\":1,\"1707\":1,\"1726\":1,\"1785\":1,\"1919\":1,\"1969\":1,\"2047\":1,\"2067\":1,\"2088\":1,\"2101\":1,\"2114\":1,\"2116\":1,\"2131\":1,\"2134\":1,\"2135\":1,\"2225\":1,\"2238\":1,\"2261\":1,\"2279\":1,\"2297\":1,\"2329\":1,\"2404\":1,\"2467\":1,\"2494\":1,\"2535\":1,\"2567\":1,\"2639\":1}}],[\"预计未来sft训练将更加高效\",{\"2\":{\"2407\":1}}],[\"预填充阶段\",{\"2\":{\"1870\":1}}],[\"预印本\",{\"2\":{\"1658\":1}}],[\"预算\",{\"2\":{\"1329\":1}}],[\"预分词\",{\"0\":{\"508\":1},\"2\":{\"373\":1}}],[\"预测下一个\",{\"2\":{\"1225\":1}}],[\"预测跨度\",{\"2\":{\"1127\":1}}],[\"预测第二个句子是否是原始文档中的后续句子\",{\"2\":{\"1037\":1}}],[\"预测\",{\"2\":{\"656\":1}}],[\"预测句子中某个词出现的概率模型\",{\"2\":{\"499\":1}}],[\"预测新数据\",{\"0\":{\"143\":1}}],[\"预测为负类\",{\"2\":{\"105\":1}}],[\"预测为正类\",{\"2\":{\"105\":1}}],[\"预测未来的销售量\",{\"2\":{\"39\":1}}],[\"预训练与微调结合\",{\"2\":{\"1243\":1}}],[\"预训练旨在知识学习\",{\"2\":{\"1199\":1}}],[\"预训练trick\",{\"2\":{\"1197\":1}}],[\"预训练流程是关键步骤之一\",{\"2\":{\"1153\":1}}],[\"预训练主要是知识的学习\",{\"2\":{\"1150\":1}}],[\"预训练损失ptx\",{\"0\":{\"1076\":1}}],[\"预训练后期通过多阶段长文本训练达到了128k\",{\"2\":{\"1071\":1}}],[\"预训练阶段\",{\"0\":{\"847\":1,\"1130\":1}}],[\"预训练数据与方法\",{\"0\":{\"1205\":1}}],[\"预训练数据与目标领域差异大时\",{\"2\":{\"57\":1}}],[\"预训练数据达到模型输入长度上限\",{\"2\":{\"1199\":1}}],[\"预训练数据\",{\"2\":{\"1018\":1}}],[\"预训练数据处理\",{\"0\":{\"929\":1}}],[\"预训练数据的来源与规模\",{\"0\":{\"535\":1}}],[\"预训练的定义与目标\",{\"0\":{\"503\":1}}],[\"预训练的scaling\",{\"0\":{\"1086\":1},\"1\":{\"1132\":1,\"1183\":1,\"1232\":1,\"1282\":1,\"1329\":1,\"1374\":1,\"1419\":1,\"1464\":1,\"1508\":1,\"1556\":1,\"1607\":1},\"2\":{\"5\":1,\"113\":1}}],[\"预训练依赖于高质量\",{\"2\":{\"449\":1}}],[\"预训练策略\",{\"0\":{\"1099\":1},\"1\":{\"1148\":1,\"1197\":1,\"1247\":1,\"1297\":1,\"1344\":1,\"1389\":1,\"1436\":1,\"1482\":1,\"1526\":1,\"1577\":1,\"1629\":1},\"2\":{\"113\":1,\"1148\":1}}],[\"预训练策略|预训练策略\",{\"2\":{\"5\":1}}],[\"预训练定义以及数据来源\",{\"0\":{\"424\":1},\"1\":{\"449\":1,\"476\":1,\"503\":1,\"535\":1,\"568\":1,\"601\":1,\"635\":1,\"669\":1,\"707\":1,\"741\":1,\"772\":1,\"803\":1,\"837\":1,\"873\":1,\"909\":1},\"2\":{\"113\":1}}],[\"预训练定义以及数据来源|预训练定义以及数据来源\",{\"2\":{\"5\":1}}],[\"预训练模型缺失\",{\"2\":{\"1719\":1}}],[\"预训练模型llama\",{\"2\":{\"1216\":1}}],[\"预训练模型的参数设置\",{\"2\":{\"1046\":1}}],[\"预训练模型的加载与微调\",{\"2\":{\"65\":1}}],[\"预训练模型\",{\"2\":{\"398\":1,\"883\":1,\"1086\":1,\"1638\":1,\"2194\":1}}],[\"预训练模型微调电子病历实体识别任务\",{\"2\":{\"49\":1}}],[\"预训练过程\",{\"2\":{\"5\":4}}],[\"预训练过程|预训练过程\",{\"2\":{\"5\":1}}],[\"预训练评估文档\",{\"2\":{\"616\":1}}],[\"预训练评估是大语言模型\",{\"2\":{\"457\":1}}],[\"预训练评估的核心观点\",{\"0\":{\"457\":1}}],[\"预训练评估2\",{\"0\":{\"436\":1},\"1\":{\"463\":1,\"492\":1,\"524\":1,\"557\":1,\"592\":1,\"626\":1,\"661\":1,\"699\":1,\"735\":1,\"770\":1,\"800\":1,\"834\":1,\"869\":1,\"905\":1,\"940\":1,\"982\":1},\"2\":{\"113\":1}}],[\"预训练评估2|预训练评估2\",{\"2\":{\"5\":1,\"819\":1}}],[\"预训练评估\",{\"0\":{\"431\":1},\"1\":{\"457\":1,\"486\":1,\"516\":1,\"549\":1,\"583\":1,\"616\":1,\"651\":1,\"686\":1,\"722\":1,\"756\":1,\"788\":1,\"819\":1},\"2\":{\"113\":1,\"431\":1}}],[\"预训练评估|预训练评估\",{\"2\":{\"5\":1}}],[\"预训练\",{\"0\":{\"113\":1,\"1093\":1,\"1214\":1},\"2\":{\"5\":19,\"377\":1,\"424\":1,\"660\":1,\"685\":1,\"819\":1,\"859\":1,\"862\":1,\"865\":1,\"887\":1,\"1001\":1,\"1015\":1,\"1101\":1}}],[\"预训练|pre\",{\"2\":{\"5\":1}}],[\"销售预测\",{\"2\":{\"39\":1}}],[\"时效性\",{\"0\":{\"2529\":1}}],[\"时既可以按照\",{\"2\":{\"813\":1}}],[\"时的期望回报\",{\"2\":{\"779\":1}}],[\"时间敏感数据处理\",{\"0\":{\"1558\":1}}],[\"时间\",{\"2\":{\"1421\":1}}],[\"时间因素相关索引\",{\"2\":{\"1285\":1}}],[\"时间步\",{\"2\":{\"775\":1}}],[\"时间序列预测\",{\"2\":{\"39\":1}}],[\"时表现如何\",{\"2\":{\"719\":1}}],[\"时序差分误差\",{\"2\":{\"619\":1,\"643\":1}}],[\"时序差分目标\",{\"2\":{\"619\":1}}],[\"时序差分方法可以从样本数据中学习\",{\"2\":{\"608\":1}}],[\"时序差分\",{\"2\":{\"540\":1,\"574\":1}}],[\"时序差分算法\",{\"0\":{\"540\":1},\"1\":{\"574\":1,\"608\":1,\"643\":1,\"678\":1,\"717\":1,\"752\":1,\"784\":1,\"815\":1,\"850\":1},\"2\":{\"151\":1}}],[\"时序差分算法|时序差分算法\",{\"2\":{\"5\":1}}],[\"时\",{\"0\":{\"2456\":1,\"2475\":1},\"2\":{\"488\":1,\"501\":1,\"656\":1,\"881\":2,\"1022\":1,\"1201\":1,\"1399\":1,\"1405\":1,\"1813\":1,\"1841\":1,\"1925\":1,\"1932\":1,\"1937\":1,\"1949\":1,\"1987\":1,\"2002\":1,\"2059\":1,\"2133\":1,\"2228\":1,\"2616\":1,\"2699\":1}}],[\"时延计算\",{\"0\":{\"402\":1,\"2095\":1},\"1\":{\"429\":1,\"455\":1,\"483\":1,\"2145\":1}}],[\"时延优化\",{\"2\":{\"328\":1}}],[\"根据预算和数据隐私需求\",{\"2\":{\"2699\":1}}],[\"根据前置知识\",{\"2\":{\"2643\":1}}],[\"根据段落换行符\",{\"2\":{\"2606\":1}}],[\"根据内容计划在语料库中检索相关事实\",{\"2\":{\"2601\":1}}],[\"根据具体场景需求\",{\"2\":{\"2693\":1}}],[\"根据具体任务需求设置文本块长度范围\",{\"2\":{\"2543\":1}}],[\"根据具体需求选择合适的方案\",{\"2\":{\"2129\":1}}],[\"根据用户问题与文本块之间的相似度\",{\"2\":{\"2420\":1}}],[\"根据用户的购买行为\",{\"2\":{\"39\":1}}],[\"根据选择的优化器\",{\"2\":{\"2266\":1}}],[\"根据megtron论文提供的公式\",{\"2\":{\"2231\":1}}],[\"根据不同数据类型\",{\"2\":{\"2192\":1}}],[\"根据上下文对单个文档内容进行压缩\",{\"2\":{\"2154\":1}}],[\"根据上下文信息灵活选择下一步操作\",{\"2\":{\"1786\":1}}],[\"根据调整后的基线值\",{\"2\":{\"2007\":1}}],[\"根据实时反馈调整采样策略\",{\"2\":{\"1989\":1}}],[\"根据采样概率差异\",{\"2\":{\"1966\":1}}],[\"根据需求选择合适的\",{\"0\":{\"2699\":1}}],[\"根据需求选择合适的工具\",{\"2\":{\"465\":1}}],[\"根据需要应用缩放调整\",{\"2\":{\"1871\":1}}],[\"根据是否包含示例\",{\"2\":{\"1826\":1}}],[\"根据配置\",{\"2\":{\"1809\":1}}],[\"根据输入动态决定\",{\"2\":{\"2139\":1}}],[\"根据输入动态调整参数\",{\"2\":{\"406\":1}}],[\"根据输出进行评分\",{\"2\":{\"1721\":1}}],[\"根据下游任务需求进行优化\",{\"2\":{\"1653\":1}}],[\"根据给定的提示\",{\"2\":{\"1619\":1}}],[\"根据人类反馈的偏好标签构建奖励函数\",{\"2\":{\"1586\":1}}],[\"根据语义或句子边界对文本进行切分的技术\",{\"2\":{\"1425\":1}}],[\"根据示例与当前输入之间的距离远近进行排序\",{\"2\":{\"1413\":1}}],[\"根据相对位置\",{\"2\":{\"1353\":1}}],[\"根据熵不变性对注意力值进行缩放\",{\"2\":{\"1255\":1}}],[\"根据智能体的数量和交互方式\",{\"2\":{\"1139\":1}}],[\"根据量化压缩模型的阶段\",{\"2\":{\"1110\":1}}],[\"根据量化数据表示的原始数据范围是否均匀\",{\"0\":{\"868\":1}}],[\"根据隐藏层的向量进行分类\",{\"2\":{\"980\":1}}],[\"根据\",{\"0\":{\"904\":1},\"1\":{\"939\":1,\"981\":1,\"1022\":1},\"2\":{\"2141\":1}}],[\"根据问题选择合适的策略\",{\"2\":{\"844\":1}}],[\"根据动作概率分布随机采样\",{\"2\":{\"820\":1}}],[\"根据其中的文字内容\",{\"2\":{\"812\":1}}],[\"根据某种策略对模型进行剪枝\",{\"2\":{\"795\":1}}],[\"根据ppo\",{\"2\":{\"695\":1}}],[\"根据教师模型的开放性程度\",{\"2\":{\"677\":1}}],[\"根据价值函数导出一个贪婪策略\",{\"2\":{\"647\":1}}],[\"根据$$\",{\"2\":{\"646\":1,\"681\":1}}],[\"根据数据来源和特征选择基本处理单元\",{\"2\":{\"644\":1}}],[\"根据全量梯度向量的\",{\"2\":{\"622\":1}}],[\"根据本指南设计并优化自己的数据清洗pipeline\",{\"2\":{\"615\":1}}],[\"根据当前状态生成动作的概率\",{\"2\":{\"581\":1}}],[\"根据任务的子目标数量将其分为简单和困难两个级别\",{\"2\":{\"1648\":1}}],[\"根据任务需求动态调整适配器权重\",{\"2\":{\"1938\":1}}],[\"根据任务需求调整n\",{\"2\":{\"1159\":1}}],[\"根据任务需求自动调整领域数据比例\",{\"2\":{\"705\":1}}],[\"根据任务需求实时调整\",{\"2\":{\"665\":1}}],[\"根据任务需求选择\",{\"2\":{\"560\":1}}],[\"根据任务类型选择模型\",{\"2\":{\"40\":1}}],[\"根据文章长度\",{\"2\":{\"548\":1}}],[\"根据权重进行加权采样\",{\"2\":{\"446\":1}}],[\"根据最大似然原则\",{\"2\":{\"444\":1}}],[\"根据公式计算每个token对应的正弦值作为其位置编码\",{\"2\":{\"287\":1}}],[\"根据公式计算缩放因子\",{\"2\":{\"276\":1}}],[\"根据概率值和阈值进行分类\",{\"2\":{\"185\":1}}],[\"根据天气和用电需求预测未来的能耗\",{\"2\":{\"39\":1}}],[\"根据房屋面积\",{\"2\":{\"39\":1}}],[\"股票价格预测\",{\"2\":{\"39\":1}}],[\"房价预测\",{\"2\":{\"39\":1}}],[\"将0\",{\"2\":{\"2697\":1}}],[\"将惩罚值与准确率奖励结合\",{\"2\":{\"2695\":1}}],[\"将希望生成的问答示例加入提示词中\",{\"2\":{\"2693\":1}}],[\"将gpu上的\",{\"2\":{\"2676\":1}}],[\"将glu中的sigmoid替换为更复杂的激活函数\",{\"2\":{\"199\":1}}],[\"将其与真值做cross\",{\"2\":{\"2673\":1}}],[\"将其ref\",{\"2\":{\"846\":2}}],[\"将每块gpu上的结果做allreduce操作\",{\"2\":{\"2670\":1}}],[\"将每个数据源视为不同任务进行多任务学习\",{\"2\":{\"2371\":1}}],[\"将每个token视为动作\",{\"2\":{\"1958\":1}}],[\"将每个原理与答案联系起来\",{\"2\":{\"1224\":1}}],[\"将所有块拼接回完整的张量\",{\"2\":{\"2628\":1}}],[\"将所有可微调参数集中到attention的某一个参数矩阵可能导致效果不佳\",{\"2\":{\"2164\":1}}],[\"将更新后的\",{\"2\":{\"2623\":1}}],[\"将最新的文档放置在注意力最强的位置\",{\"2\":{\"2529\":1}}],[\"将最大化问题转换为最小化\",{\"2\":{\"1712\":1}}],[\"将检索与微调\",{\"2\":{\"2523\":1}}],[\"将检测出的所有标题存储为一个列表\",{\"2\":{\"2235\":1}}],[\"将tensor分割成多块\",{\"2\":{\"2515\":1}}],[\"将token重新分组\",{\"2\":{\"156\":1}}],[\"将token按组大小的一半进行移位\",{\"2\":{\"136\":1}}],[\"将整个输出的优势值应用于每个token上\",{\"2\":{\"2396\":1}}],[\"将新技能加入技能库\",{\"2\":{\"2277\":1}}],[\"将匹配到子文档所属的主文档与用户提问一并传递给\",{\"2\":{\"2236\":1}}],[\"将分析结果应用于实际业务场景\",{\"2\":{\"2220\":1}}],[\"将该分块周围的一些块作为上下文一并传递给\",{\"2\":{\"2197\":1}}],[\"将技能库划分为不同的任务类型\",{\"2\":{\"2168\":1}}],[\"将依赖奖励函数的问题转化为直接优化策略比对问题\",{\"2\":{\"2148\":1}}],[\"将计算结果从sram中写入到hbm中\",{\"2\":{\"2128\":1}}],[\"将计算复杂度从\",{\"2\":{\"189\":1}}],[\"将多个计算步骤合并为一个\",{\"2\":{\"2110\":1}}],[\"将多个操作融合为一个操作\",{\"2\":{\"1810\":1}}],[\"将大任务分成小块来处理\",{\"2\":{\"2110\":1}}],[\"将大模型变成小模型\",{\"2\":{\"715\":1}}],[\"将长文档拆分为适合检索的\",{\"2\":{\"2393\":1}}],[\"将长文本分割成若干较小的\",{\"2\":{\"116\":1}}],[\"将长篇文档分割成多个文本块\",{\"2\":{\"2105\":1}}],[\"将mask和dropout加上的forward过程整合为一个操作\",{\"2\":{\"2080\":1}}],[\"将m个数分成n组的问题\",{\"2\":{\"47\":1}}],[\"将任务划分为可以并行运行的独立子任务\",{\"2\":{\"2037\":1}}],[\"将生成的工具存储为记忆\",{\"2\":{\"1904\":1}}],[\"将生成的推理过程\",{\"2\":{\"1885\":1}}],[\"将目标表达式重写为\",{\"2\":{\"1830\":1}}],[\"将目标位置\",{\"2\":{\"291\":1}}],[\"将推理分为prefill和decode两个流程\",{\"2\":{\"1782\":1}}],[\"将上一次推理的输出\",{\"2\":{\"1782\":1}}],[\"将上下文长度划分为多个组\",{\"2\":{\"136\":1}}],[\"将模型学习建模为状态和动作序列\",{\"2\":{\"2124\":1}}],[\"将模型参数分为不同组\",{\"2\":{\"1771\":1}}],[\"将模型中的浮点数参数转换为低精度整数\",{\"2\":{\"763\":1}}],[\"将预训练的权重矩阵拆分为大小向量mmm和方向矩阵vvv\",{\"2\":{\"1890\":1}}],[\"将预训练的权重矩阵分解为两个部分\",{\"2\":{\"1770\":1}}],[\"将预训练模型\",{\"2\":{\"40\":1}}],[\"将输入token通过attention层及残差连接传入模型\",{\"2\":{\"1822\":1}}],[\"将输入路由到特定的下游工作流时\",{\"2\":{\"1728\":1}}],[\"将输入信息直接传递到后续层\",{\"2\":{\"183\":1}}],[\"将这些问题作为\",{\"2\":{\"2578\":1}}],[\"将这些大模型部署到生产环境中同样面临巨大的挑战\",{\"2\":{\"728\":1}}],[\"将这个假设性回复和原始查询一起用于向量检索\",{\"2\":{\"1717\":1}}],[\"将prompt视为初始状态\",{\"2\":{\"1958\":1}}],[\"将prompt到response视为单步mdp\",{\"2\":{\"1864\":1}}],[\"将prompt转换为可学习的embedding层\",{\"2\":{\"1858\":1}}],[\"将prompt与response结合计算损失\",{\"2\":{\"1677\":1}}],[\"将pddl计划翻译回自然语言\",{\"2\":{\"1465\":1}}],[\"将自身的私域数据上传至第三方平台进行训练\",{\"2\":{\"1512\":1}}],[\"将自然语言问题转化为带有任务前缀的文本序列\",{\"2\":{\"1107\":1}}],[\"将内容翻译为其他语言\",{\"2\":{\"1466\":1}}],[\"将降低flops成本\",{\"2\":{\"1464\":1}}],[\"将绝对位置和相对位置混用\",{\"2\":{\"1452\":1}}],[\"将demonstrations加入到task\",{\"2\":{\"1368\":1}}],[\"将不同大小的分块全部存储到向量数据库中\",{\"2\":{\"2625\":1}}],[\"将不同预训练目标混合以增强多语言能力\",{\"2\":{\"1348\":1}}],[\"将不同的相对距离映射到离散的桶中\",{\"2\":{\"1258\":1}}],[\"将attention改为了sparse\",{\"2\":{\"1278\":1}}],[\"将位置编码设置为可训练\",{\"2\":{\"1243\":1}}],[\"将位置编码与输入嵌入向量相加\",{\"2\":{\"287\":1}}],[\"将专家模块分割成细粒度单元以提高专业化\",{\"2\":{\"1120\":1}}],[\"将效果较好的moe模型蒸馏到dense模型\",{\"2\":{\"1083\":1}}],[\"将训练集中的每一个样本都当作示例\",{\"2\":{\"1075\":1}}],[\"将训练语料中的单词拆解为单个字符\",{\"2\":{\"392\":1}}],[\"将复杂模型精简化\",{\"2\":{\"2652\":1}}],[\"将复杂的语言表达映射到高维向量空间\",{\"2\":{\"2155\":1}}],[\"将复杂的输出映射为单一数值\",{\"2\":{\"1645\":1}}],[\"将复杂的专家系统拆分成更小的部分\",{\"2\":{\"1073\":1}}],[\"将复杂度从n降低到logn\",{\"2\":{\"980\":1}}],[\"将参数高效微调\",{\"2\":{\"1050\":1}}],[\"将文档库分割成较短的文本块\",{\"2\":{\"2420\":1}}],[\"将文档分段为有意义的单元\",{\"2\":{\"1425\":1}}],[\"将文字\",{\"2\":{\"1036\":1}}],[\"将文本分割为句子\",{\"2\":{\"2584\":1}}],[\"将文本划分为若干块\",{\"2\":{\"1366\":1}}],[\"将文本内容按字节顺序进行滑动窗口操作\",{\"2\":{\"1021\":1}}],[\"将文本拆分为更小的单位\",{\"2\":{\"508\":1}}],[\"将对应索引的位置置为1\",{\"2\":{\"1025\":1}}],[\"将relu激活函数替换为gelu\",{\"2\":{\"1011\":1}}],[\"将词表大小从\",{\"2\":{\"1007\":1}}],[\"将softmax替换为sigmoid\",{\"2\":{\"998\":1}}],[\"将单词拆分为小单位\",{\"2\":{\"1226\":1}}],[\"将单词分解为更小的token\",{\"2\":{\"956\":1}}],[\"将单词的位置信息编码为特征向量\",{\"2\":{\"956\":1}}],[\"将教师模型中的知识迁移到学生模型中\",{\"2\":{\"954\":1}}],[\"将实际问题抽象为mdp\",{\"2\":{\"844\":1}}],[\"将在更多复杂任务中得到应用\",{\"2\":{\"829\":1}}],[\"将有监督学习的数据分布假设直接套用到强化学习中\",{\"2\":{\"792\":1}}],[\"将权重矩阵分解为多个低秩矩阵\",{\"2\":{\"763\":1}}],[\"将权重从\",{\"2\":{\"729\":1}}],[\"将可能在强化学习中发挥更大的作用\",{\"2\":{\"745\":1}}],[\"将连续取值如\",{\"2\":{\"733\":1}}],[\"将成为提升计算效率的核心技术之一\",{\"2\":{\"629\":1}}],[\"将成为预训练的重要方向\",{\"2\":{\"535\":1}}],[\"将小梯度放大到可表示范围\",{\"2\":{\"556\":1}}],[\"将梯度恢复为\",{\"2\":{\"589\":1}}],[\"将梯度从\",{\"2\":{\"523\":1}}],[\"将梯度转为\",{\"2\":{\"435\":1}}],[\"将公式中的参数\",{\"2\":{\"502\":1}}],[\"将bpe误认为是基于互信息的方法\",{\"2\":{\"472\":1}}],[\"将语言阈值分数低于0\",{\"2\":{\"515\":1}}],[\"将语料拆分为最小单元\",{\"2\":{\"381\":1}}],[\"将语音转化为文本\",{\"2\":{\"39\":1}}],[\"将原始attention计算\",{\"2\":{\"293\":1}}],[\"将缩放因子应用于rope嵌入\",{\"2\":{\"276\":1}}],[\"将扩展范围压缩到原范围\",{\"2\":{\"246\":1}}],[\"将扩展的上下文长度映射到模型训练时支持的范围\",{\"2\":{\"222\":1}}],[\"将一个复杂的模型转化为一个较小且高效的版本\",{\"2\":{\"2647\":1}}],[\"将一个复杂的问题分解为多个子问题\",{\"2\":{\"2546\":1}}],[\"将一个整数拆分为多维向量\",{\"2\":{\"223\":1}}],[\"将一种语言翻译成另一种语言\",{\"2\":{\"39\":1}}],[\"将query分组\",{\"2\":{\"191\":1}}],[\"将query和key向量以\",{\"2\":{\"184\":1}}],[\"将源语言与目标语言对齐\",{\"2\":{\"188\":1}}],[\"将\",{\"2\":{\"90\":1,\"251\":1,\"527\":1,\"553\":1,\"560\":1,\"1353\":1,\"1376\":1,\"1594\":1,\"2144\":1,\"2286\":3,\"2589\":1,\"2653\":1}}],[\"将直线输出的值转换成概率\",{\"2\":{\"51\":1}}],[\"将高维数据降维后以\",{\"2\":{\"39\":1}}],[\"将高维数据映射到低维空间\",{\"2\":{\"39\":1}}],[\"将图片中的像素划分为不同区域\",{\"2\":{\"39\":1}}],[\"将客户划分为不同的群体\",{\"2\":{\"39\":1}}],[\"将数据划分为若干组\",{\"2\":{\"39\":1}}],[\"将数据和操作数据的代码封装在对象内部\",{\"2\":{\"12\":1}}],[\"情感分析等\",{\"2\":{\"59\":1}}],[\"情感分析\",{\"2\":{\"39\":1}}],[\"人评则通过人工直接判断模型输出的质量\",{\"2\":{\"2194\":1}}],[\"人类通过比较智能体行为轨迹片段来提供偏好标签\",{\"2\":{\"1491\":1}}],[\"人类反馈标签\",{\"2\":{\"1631\":1}}],[\"人类反馈的强化学习\",{\"2\":{\"1530\":1}}],[\"人类反馈\",{\"2\":{\"1473\":1,\"1532\":1,\"1726\":1}}],[\"人类偏好\",{\"2\":{\"1445\":1,\"1521\":1}}],[\"人类可通过绝对位置\",{\"2\":{\"216\":1}}],[\"人类建模偏好角度理解dpo\",{\"0\":{\"1426\":1},\"2\":{\"151\":1}}],[\"人工给数据打偏好标签\",{\"2\":{\"1631\":1}}],[\"人工筛选\",{\"2\":{\"532\":1}}],[\"人工智能研究\",{\"2\":{\"1018\":1}}],[\"人工智能模型训练\",{\"2\":{\"2404\":1}}],[\"人工智能模型\",{\"2\":{\"987\":1}}],[\"人工智能模型架构\",{\"2\":{\"920\":1}}],[\"人工智能与机器学习\",{\"2\":{\"552\":1}}],[\"人工智能技术\",{\"2\":{\"436\":1,\"859\":1,\"899\":1,\"1689\":1,\"1785\":1}}],[\"人工智能\",{\"2\":{\"85\":1,\"87\":1,\"139\":1,\"225\":1,\"328\":1,\"424\":1,\"431\":1,\"550\":1,\"854\":2,\"890\":2,\"899\":1,\"922\":1,\"986\":1,\"1000\":1,\"1001\":1,\"1445\":1,\"1478\":1,\"1486\":1,\"1624\":1,\"2114\":1}}],[\"人工神经网络\",{\"2\":{\"39\":1}}],[\"人脸识别\",{\"2\":{\"39\":1}}],[\"典型应用\",{\"2\":{\"39\":8}}],[\"典型模型\",{\"2\":{\"34\":1,\"294\":1,\"316\":1,\"339\":1,\"363\":1,\"595\":1}}],[\"输入受限\",{\"0\":{\"2483\":1}}],[\"输入到llm的prompt会携带多轮对话历史\",{\"2\":{\"2166\":1}}],[\"输入ffn的hidden维度为\",{\"2\":{\"1782\":1}}],[\"输入ffn的hidden\",{\"2\":{\"1782\":1}}],[\"输入attention的q维度为\",{\"2\":{\"1782\":1}}],[\"输入attention的q\",{\"2\":{\"1782\":1}}],[\"输入一条prompt并获取对应的response\",{\"2\":{\"1677\":1}}],[\"输入一条prompt\",{\"2\":{\"1572\":1}}],[\"输入和输出不共享权重\",{\"2\":{\"1490\":1}}],[\"输入和输出嵌入不共享权重\",{\"2\":{\"1155\":1}}],[\"输入embedding初始化\",{\"2\":{\"1437\":1}}],[\"输入文本\",{\"2\":{\"1225\":1}}],[\"输入形式的改变\",{\"0\":{\"1193\":1}}],[\"输入激活范数\",{\"2\":{\"1050\":1}}],[\"输入是带有任务前缀声明的文本序列\",{\"2\":{\"978\":1}}],[\"输入层embedding包括word\",{\"2\":{\"2651\":1}}],[\"输入层embedding\",{\"0\":{\"2651\":1}}],[\"输入层\",{\"2\":{\"938\":1}}],[\"输入状态输出动作的概率分布\",{\"2\":{\"652\":1}}],[\"输入\",{\"2\":{\"595\":1,\"938\":1,\"1207\":2,\"1353\":2,\"2418\":1,\"2443\":1}}],[\"输入采用双向注意力\",{\"2\":{\"339\":1}}],[\"输入为\",{\"2\":{\"246\":1}}],[\"输入为正时不会饱和\",{\"2\":{\"238\":1}}],[\"输入维度\",{\"2\":{\"190\":1}}],[\"输入序列长度为1024\",{\"2\":{\"1203\":1}}],[\"输入序列长度从512增加到1024\",{\"2\":{\"1059\":1}}],[\"输入序列\",{\"2\":{\"166\":1,\"187\":1}}],[\"输入特征数据\",{\"2\":{\"185\":1}}],[\"输入特征\",{\"2\":{\"164\":1}}],[\"输入数据集\",{\"2\":{\"2374\":1}}],[\"输入数据的质量\",{\"2\":{\"1775\":1,\"1895\":1}}],[\"输入数据\",{\"0\":{\"66\":1},\"2\":{\"1119\":1}}],[\"输入数据被划分为多个类别\",{\"2\":{\"39\":1}}],[\"输入历史对话上下文\",{\"2\":{\"49\":1}}],[\"输出序号\",{\"2\":{\"2446\":1}}],[\"输出形式为文本\",{\"2\":{\"2443\":1}}],[\"输出动作多为底层控制\",{\"2\":{\"2418\":1}}],[\"输出中可能出现多语言混杂的情况\",{\"2\":{\"2315\":1}}],[\"输出数据\",{\"2\":{\"2123\":1}}],[\"输出一致性\",{\"0\":{\"1600\":1}}],[\"输出其对应的response\",{\"2\":{\"1572\":1}}],[\"输出的负例\",{\"2\":{\"1368\":1}}],[\"输出例子\",{\"2\":{\"1368\":1}}],[\"输出计算\",{\"2\":{\"1266\":1}}],[\"输出对\",{\"2\":{\"1224\":1}}],[\"输出层只有一个word\",{\"2\":{\"2656\":1}}],[\"输出层embedding\",{\"0\":{\"2656\":1}}],[\"输出层\",{\"2\":{\"938\":1}}],[\"输出结果\",{\"2\":{\"445\":1,\"1025\":1}}],[\"输出为单向注意力\",{\"2\":{\"339\":1}}],[\"输出均值接近零\",{\"2\":{\"285\":1,\"330\":1}}],[\"输出张量形状\",{\"2\":{\"266\":1}}],[\"输出值在\",{\"2\":{\"215\":1}}],[\"输出非零中心\",{\"2\":{\"194\":1,\"330\":2}}],[\"输出\",{\"2\":{\"10\":3,\"595\":1,\"938\":1,\"996\":1,\"1225\":1,\"2228\":3,\"2418\":1,\"2443\":1}}],[\"分出更多的pipeline阶段\",{\"2\":{\"2697\":1}}],[\"分割精度受限于工具库的能力\",{\"2\":{\"2599\":1}}],[\"分专项能力评估\",{\"0\":{\"2477\":1},\"1\":{\"2493\":1,\"2506\":1,\"2518\":1,\"2529\":1,\"2540\":1}}],[\"分解为子目标\",{\"2\":{\"2370\":1}}],[\"分解器将原始问题分解为一系列子问题\",{\"2\":{\"1224\":1}}],[\"分治思想\",{\"2\":{\"2188\":1}}],[\"分成两块\",{\"2\":{\"2130\":1}}],[\"分段\",{\"2\":{\"2037\":1}}],[\"分段自然梯度核\",{\"2\":{\"184\":1}}],[\"分为\",{\"2\":{\"1826\":1,\"2276\":1}}],[\"分为确定性策略和随机性策略\",{\"2\":{\"676\":1}}],[\"分开实现有利于针对性的优化\",{\"2\":{\"1782\":1}}],[\"分开监控\",{\"2\":{\"525\":1}}],[\"分阶段特点\",{\"2\":{\"1344\":1}}],[\"分配到第\",{\"2\":{\"1326\":1}}],[\"分配资源更公平\",{\"2\":{\"631\":1}}],[\"分享关于\",{\"2\":{\"1309\":1}}],[\"分别设计为prefill和decode两个过程\",{\"2\":{\"1782\":1}}],[\"分别设置学习率和权重衰减\",{\"2\":{\"1771\":1}}],[\"分别进行训练和处理\",{\"2\":{\"1659\":1}}],[\"分别对应\",{\"2\":{\"1536\":1}}],[\"分别作用于key和value的计算\",{\"2\":{\"1266\":1}}],[\"分别是query和key向量\",{\"2\":{\"228\":1}}],[\"分别是ntk\",{\"2\":{\"159\":1}}],[\"分层窗口self\",{\"2\":{\"1255\":1}}],[\"分层softmax是否可以进一步优化以支持动态类别扩展\",{\"2\":{\"1354\":1}}],[\"分层softmax适合大类别数场景\",{\"2\":{\"1259\":1}}],[\"分层softmax在处理大类别数问题时效率显著提升\",{\"2\":{\"980\":1}}],[\"分层softmax\",{\"2\":{\"980\":1}}],[\"分桶\",{\"0\":{\"1258\":1},\"2\":{\"1108\":1,\"1258\":1,\"1306\":1,\"1353\":1,\"1399\":1,\"1447\":2,\"1493\":1}}],[\"分析显存节省对大型模型训练的影响\",{\"2\":{\"2275\":1}}],[\"分析估算值与实际值的差异原因\",{\"2\":{\"2212\":1}}],[\"分析rlhf技术在其他ai模型中的应用效果\",{\"2\":{\"1918\":1}}],[\"分析模型在不同数据集上的泛化能力\",{\"2\":{\"1310\":1}}],[\"分析模型的优缺点及适用场景\",{\"2\":{\"133\":1}}],[\"分析多查询注意力\",{\"2\":{\"1140\":1}}],[\"分析不同长度和划分方式对检索和生成效果的影响\",{\"2\":{\"2543\":1}}],[\"分析不同数据来源对模型性能的影响\",{\"2\":{\"1475\":1}}],[\"分析不同策略对蒙特卡洛方法效率的影响\",{\"2\":{\"914\":1}}],[\"分析不同任务场景下\",{\"2\":{\"409\":1}}],[\"分析单元内部是否存在大量重复内容\",{\"2\":{\"644\":1}}],[\"分析\",{\"0\":{\"558\":1}}],[\"分析等方面\",{\"2\":{\"464\":1}}],[\"分析上下文扩展需求\",{\"2\":{\"359\":1}}],[\"分布要多样化\",{\"2\":{\"2312\":1}}],[\"分布式引用计数和分布式调度\",{\"2\":{\"2408\":1}}],[\"分布式计算框架成为了不可或缺的工具\",{\"2\":{\"2320\":1}}],[\"分布式计算的利器\",{\"0\":{\"2320\":1},\"1\":{\"2351\":1,\"2381\":1,\"2408\":1,\"2433\":1}}],[\"分布式训练\",{\"0\":{\"2158\":1},\"1\":{\"2201\":1}}],[\"分布式推理\",{\"0\":{\"2108\":1}}],[\"分布式初始化是将专家分布排列到多个gpu上的过程\",{\"2\":{\"1410\":1}}],[\"分布式初始化\",{\"0\":{\"1410\":1}}],[\"分布式系统\",{\"2\":{\"1272\":1}}],[\"分布改进\",{\"2\":{\"1130\":1}}],[\"分布平坦时\",{\"2\":{\"295\":1}}],[\"分布尖锐时\",{\"2\":{\"295\":1}}],[\"分块大小的选择\",{\"0\":{\"2655\":1}}],[\"分块的目标是将大段的文本划分为更小的块\",{\"2\":{\"2552\":1}}],[\"分块\",{\"2\":{\"2552\":1}}],[\"分块技术\",{\"2\":{\"2110\":1}}],[\"分块计算的难点\",{\"0\":{\"1872\":1}}],[\"分块计算\",{\"0\":{\"1810\":1}}],[\"分块策略不合理\",{\"2\":{\"175\":1}}],[\"分块处理降低了显存需求\",{\"2\":{\"155\":1}}],[\"分块处理\",{\"2\":{\"116\":1}}],[\"分散插值压力\",{\"2\":{\"159\":1}}],[\"分组\",{\"2\":{\"218\":1}}],[\"分组与移位示例\",{\"2\":{\"218\":1}}],[\"分组与移位处理\",{\"0\":{\"218\":1}}],[\"分组计算\",{\"2\":{\"156\":1}}],[\"分组处理\",{\"2\":{\"136\":1}}],[\"分类结果决定向下传递路径\",{\"2\":{\"980\":1}}],[\"分类器推荐采用\",{\"2\":{\"474\":1}}],[\"分类\",{\"0\":{\"538\":1,\"774\":1,\"924\":1,\"958\":1,\"984\":1,\"1014\":1,\"1214\":1,\"1221\":1,\"1477\":1,\"1488\":1,\"1584\":1,\"1623\":1,\"1697\":1,\"1723\":1,\"1768\":1,\"1781\":1,\"2150\":1,\"2680\":1},\"1\":{\"1755\":1,\"1815\":1,\"2683\":1,\"2686\":1},\"2\":{\"71\":1,\"74\":1,\"80\":1,\"85\":1,\"87\":1,\"88\":1,\"92\":1,\"94\":1,\"96\":1,\"104\":1,\"110\":1,\"119\":1,\"132\":1,\"139\":1,\"142\":1,\"154\":1,\"160\":1,\"181\":1,\"182\":1,\"225\":1,\"226\":1,\"229\":1,\"273\":1,\"286\":1,\"297\":1,\"320\":1,\"328\":1,\"344\":1,\"345\":1,\"347\":1,\"377\":1,\"380\":1,\"382\":1,\"384\":1,\"396\":1,\"397\":1,\"398\":1,\"405\":1,\"424\":1,\"431\":1,\"436\":1,\"437\":1,\"478\":1,\"484\":1,\"487\":1,\"489\":1,\"539\":1,\"540\":1,\"543\":1,\"545\":1,\"550\":1,\"552\":1,\"573\":1,\"588\":1,\"617\":1,\"641\":1,\"642\":1,\"659\":1,\"832\":1,\"835\":1,\"836\":1,\"848\":1,\"854\":1,\"859\":1,\"861\":1,\"862\":1,\"865\":1,\"883\":1,\"887\":1,\"890\":1,\"899\":1,\"908\":1,\"920\":1,\"922\":1,\"930\":1,\"935\":1,\"986\":1,\"987\":1,\"988\":1,\"990\":1,\"1000\":1,\"1001\":1,\"1015\":1,\"1017\":1,\"1018\":1,\"1044\":1,\"1063\":1,\"1070\":1,\"1085\":1,\"1086\":1,\"1098\":1,\"1101\":1,\"1103\":1,\"1148\":1,\"1414\":1,\"1445\":1,\"1449\":1,\"1461\":1,\"1471\":1,\"1473\":1,\"1478\":1,\"1479\":1,\"1486\":1,\"1489\":1,\"1497\":1,\"1516\":1,\"1546\":1,\"1568\":1,\"1575\":1,\"1583\":1,\"1599\":1,\"1604\":1,\"1605\":1,\"1615\":1,\"1624\":1,\"1625\":1,\"1638\":1,\"1682\":1,\"1689\":1,\"1694\":1,\"1707\":1,\"1726\":1,\"1785\":1,\"1919\":1,\"1969\":1,\"2047\":1,\"2067\":1,\"2088\":1,\"2101\":1,\"2114\":1,\"2116\":1,\"2131\":1,\"2134\":1,\"2135\":1,\"2225\":1,\"2238\":1,\"2261\":1,\"2279\":1,\"2297\":1,\"2329\":1,\"2404\":1,\"2467\":1,\"2494\":1,\"2535\":1,\"2567\":1,\"2639\":1}}],[\"分类任务评估\",{\"0\":{\"2354\":1}}],[\"分类任务\",{\"2\":{\"39\":1}}],[\"分隔链表\",{\"0\":{\"47\":1}}],[\"分词器\",{\"2\":{\"1225\":1,\"1253\":1}}],[\"分词歧义问题\",{\"2\":{\"562\":1}}],[\"分词模型和后处理\",{\"2\":{\"373\":1}}],[\"分词是自然语言处理中的基础步骤\",{\"2\":{\"368\":1}}],[\"分词单位\",{\"2\":{\"365\":1}}],[\"分词方法\",{\"2\":{\"344\":1}}],[\"分词算法的比较\",{\"0\":{\"321\":1},\"1\":{\"344\":1,\"368\":1,\"394\":1,\"420\":1,\"445\":1,\"472\":1,\"499\":1,\"531\":1,\"564\":1}}],[\"分词算法的比较|分词算法的比较\",{\"2\":{\"5\":1}}],[\"分词算法\",{\"2\":{\"286\":1,\"297\":1,\"320\":1,\"347\":1}}],[\"分词工具的选择应根据具体任务需求和数据规模调整\",{\"2\":{\"610\":1}}],[\"分词工具\",{\"2\":{\"278\":1}}],[\"分词技术\",{\"2\":{\"273\":1,\"1112\":1}}],[\"分词\",{\"2\":{\"5\":6,\"59\":1,\"426\":1,\"929\":1}}],[\"分词|分词\",{\"2\":{\"5\":1}}],[\"xa2​\",{\"2\":{\"2609\":1}}],[\"xa2\",{\"2\":{\"2609\":1}}],[\"xa1​\",{\"2\":{\"2609\":1}}],[\"xa1\",{\"2\":{\"2609\":1}}],[\"xa\",{\"2\":{\"2587\":2}}],[\"xa=\",{\"2\":{\"2537\":2}}],[\"xd​\",{\"2\":{\"2492\":1}}],[\"xd\",{\"2\":{\"2492\":1}}],[\"x=\",{\"2\":{\"2492\":4}}],[\"xbx\",{\"2\":{\"2263\":1}}],[\"x⋅wg​\",{\"2\":{\"2140\":1}}],[\"x⋅wg\",{\"2\":{\"2140\":1}}],[\"x⋅diag\",{\"2\":{\"2033\":2}}],[\"x^\",{\"2\":{\"2030\":14,\"2492\":2}}],[\"x^+\",{\"2\":{\"1671\":4}}],[\"x≥89x\",{\"2\":{\"1925\":1}}],[\"x+\",{\"2\":{\"1671\":8}}],[\"x+x^+x+\",{\"2\":{\"1566\":1,\"1784\":1}}],[\"xlx\",{\"2\":{\"2579\":1}}],[\"xlora\",{\"2\":{\"1928\":10}}],[\"xloralinearlayer的前向传播\",{\"0\":{\"1871\":1}}],[\"xl论文\",{\"2\":{\"1647\":1}}],[\"xlnet中的可训练向量\",{\"2\":{\"1593\":1}}],[\"xlnet中的位置编码\",{\"0\":{\"1313\":1},\"1\":{\"1359\":1}}],[\"xlnet直接使用正弦波形式生成相对位置向量\",{\"2\":{\"1359\":1}}],[\"xlnet的attention公式如下\",{\"2\":{\"1359\":1}}],[\"xlnet进一步优化了相对位置编码\",{\"2\":{\"1313\":1}}],[\"xlnet\",{\"2\":{\"1070\":1}}],[\"xyz\",{\"2\":{\"1420\":2}}],[\"xj​wv​+ri\",{\"2\":{\"1266\":1}}],[\"xj​wk​+ri\",{\"2\":{\"1266\":1}}],[\"xjwv+ri\",{\"2\":{\"1266\":1}}],[\"xjwk+ri\",{\"2\":{\"1266\":1}}],[\"xm​\",{\"2\":{\"1142\":1}}],[\"xm\",{\"2\":{\"1142\":1}}],[\"xxx\",{\"2\":{\"981\":1,\"1566\":1,\"1582\":1,\"1784\":1,\"1982\":1,\"2050\":1,\"2140\":1,\"2145\":1,\"2233\":1}}],[\"xix\",{\"2\":{\"1901\":1,\"2007\":1}}],[\"xi−​\",{\"2\":{\"1566\":1,\"1671\":2,\"1784\":1}}],[\"xi−\",{\"2\":{\"1566\":1,\"1671\":2,\"1784\":1}}],[\"xiwq\",{\"2\":{\"1266\":1}}],[\"xiwqwk⊤xj⊤+βi\",{\"2\":{\"1207\":1}}],[\"xi​wq​\",{\"2\":{\"1266\":1}}],[\"xi​wq​wk⊤​xj⊤​+βi\",{\"2\":{\"1207\":1}}],[\"xi​\",{\"2\":{\"773\":1,\"1222\":1,\"1901\":4,\"1925\":2,\"2531\":3,\"2542\":3}}],[\"xi\",{\"2\":{\"773\":1,\"1222\":1,\"1901\":4,\"1925\":2,\"2531\":3,\"2542\":3}}],[\"xiaohongshu\",{\"2\":{\"559\":1}}],[\"xk​\",{\"2\":{\"773\":1}}],[\"xk+1x\",{\"2\":{\"773\":1}}],[\"xk+1​\",{\"2\":{\"773\":2}}],[\"xk+1\",{\"2\":{\"773\":1}}],[\"xk\",{\"2\":{\"773\":1,\"1870\":2,\"2618\":1}}],[\"x1a1\",{\"2\":{\"2602\":1}}],[\"x1a1+x2a2\",{\"2\":{\"2602\":2}}],[\"x1x2\",{\"2\":{\"2537\":1}}],[\"x1​a1​\",{\"2\":{\"2602\":1}}],[\"x1​a1​+x2​a2​\",{\"2\":{\"2602\":2}}],[\"x1​x2​​\",{\"2\":{\"2537\":1}}],[\"x1​\",{\"2\":{\"773\":1,\"2492\":1}}],[\"x1\",{\"2\":{\"773\":1,\"2492\":1}}],[\"x∈rmax​\",{\"2\":{\"704\":1}}],[\"xnor\",{\"2\":{\"768\":3}}],[\"xn​∣x1​\",{\"2\":{\"503\":1}}],[\"xn−1​\",{\"2\":{\"503\":1}}],[\"xn−1\",{\"2\":{\"503\":1}}],[\"xn∣x1\",{\"2\":{\"503\":1}}],[\"x≤0x\",{\"2\":{\"285\":1}}],[\"x2a2\",{\"2\":{\"2602\":1}}],[\"x2x\",{\"2\":{\"2537\":1}}],[\"x2​a2​\",{\"2\":{\"2602\":1}}],[\"x2​\",{\"2\":{\"503\":1,\"2492\":1}}],[\"x2\",{\"2\":{\"503\":1,\"2492\":1}}],[\"x27\",{\"2\":{\"222\":2,\"640\":3,\"647\":3,\"653\":4,\"656\":3,\"732\":10,\"757\":3,\"767\":11,\"775\":1,\"810\":3,\"1127\":1,\"1364\":1,\"2430\":3,\"2581\":2,\"2597\":2}}],[\"x26\",{\"2\":{\"47\":2,\"762\":1,\"769\":1}}],[\"xw\",{\"2\":{\"199\":1}}],[\"xw₁\",{\"2\":{\"178\":1}}],[\"xv​\",{\"2\":{\"1870\":2}}],[\"xvx\",{\"2\":{\"1870\":2}}],[\"xv\",{\"2\":{\"199\":1}}],[\"x\",{\"0\":{\"1367\":1,\"1585\":1,\"1769\":3,\"2031\":1},\"1\":{\"1412\":1,\"1638\":1,\"1692\":1,\"1749\":1,\"1809\":1,\"1830\":3,\"1871\":1,\"1928\":1,\"1979\":1,\"2028\":1,\"2078\":1,\"2081\":1,\"2132\":1,\"2178\":1,\"2218\":1,\"2253\":1,\"2288\":1},\"2\":{\"76\":6,\"151\":1,\"178\":1,\"190\":5,\"193\":1,\"194\":4,\"199\":6,\"215\":7,\"238\":6,\"261\":7,\"266\":5,\"285\":8,\"307\":10,\"355\":4,\"503\":4,\"537\":3,\"614\":11,\"623\":21,\"704\":4,\"766\":8,\"773\":4,\"820\":4,\"998\":4,\"1142\":2,\"1187\":5,\"1207\":1,\"1222\":1,\"1266\":3,\"1359\":4,\"1367\":1,\"1393\":1,\"1552\":7,\"1566\":1,\"1582\":12,\"1638\":1,\"1657\":4,\"1658\":1,\"1666\":7,\"1671\":17,\"1676\":3,\"1685\":12,\"1692\":1,\"1712\":4,\"1720\":6,\"1727\":3,\"1732\":3,\"1784\":1,\"1787\":3,\"1795\":3,\"1809\":1,\"1830\":16,\"1831\":2,\"1870\":2,\"1889\":12,\"1901\":5,\"1922\":2,\"1925\":7,\"1944\":4,\"1980\":6,\"1994\":9,\"2030\":58,\"2033\":2,\"2046\":7,\"2140\":4,\"2145\":1,\"2148\":3,\"2289\":3,\"2492\":9,\"2500\":2,\"2520\":6,\"2526\":1,\"2531\":3,\"2532\":6,\"2537\":4,\"2542\":3,\"2587\":1,\"2602\":6,\"2609\":2}}],[\"xgboost\",{\"2\":{\"39\":1}}],[\"x3c\",{\"2\":{\"10\":18,\"11\":17,\"12\":12,\"15\":9,\"22\":5,\"27\":5,\"47\":5,\"391\":1,\"640\":1,\"646\":1,\"656\":1,\"762\":5,\"769\":3,\"783\":2,\"840\":1,\"2406\":4}}],[\"线性层输出\",{\"2\":{\"961\":1}}],[\"线性内插与进制转换的优化策略\",{\"0\":{\"246\":1}}],[\"线性内插\",{\"2\":{\"202\":1,\"246\":1,\"292\":1}}],[\"线性门控单元\",{\"2\":{\"199\":1}}],[\"线性回归的输出\",{\"2\":{\"90\":1}}],[\"线性回归部分\",{\"0\":{\"76\":1}}],[\"线性回归\",{\"2\":{\"39\":1}}],[\"线性的问题\",{\"2\":{\"20\":1}}],[\"线性的任务\",{\"2\":{\"12\":1}}],[\"常采用近似最近邻\",{\"2\":{\"2102\":1}}],[\"常规kv\",{\"0\":{\"1978\":1}}],[\"常识和推理能力\",{\"2\":{\"1708\":1}}],[\"常识推理\",{\"2\":{\"1708\":1}}],[\"常考\",{\"2\":{\"682\":1}}],[\"常量损失放大\",{\"0\":{\"553\":1}}],[\"常见文本分块策略\",{\"0\":{\"2552\":1}}],[\"常见问题\",{\"0\":{\"1394\":1}}],[\"常见问题与解决方法\",{\"0\":{\"491\":1},\"1\":{\"523\":1,\"556\":1}}],[\"常见误区\",{\"2\":{\"1324\":1}}],[\"常见比例\",{\"2\":{\"474\":1}}],[\"常见索引优化算法实现\",{\"0\":{\"1396\":1},\"2\":{\"237\":1}}],[\"常见激活函数解析\",{\"0\":{\"173\":1},\"1\":{\"194\":1,\"215\":1,\"238\":1,\"261\":1,\"285\":1,\"307\":1}}],[\"常见错误包括路径配置错误\",{\"2\":{\"2268\":1}}],[\"常见错误警示\",{\"0\":{\"2098\":1}}],[\"常见错误警告区块\",{\"0\":{\"251\":1,\"1113\":1,\"1632\":1}}],[\"常见错误警告\",{\"0\":{\"241\":1,\"348\":1,\"582\":1,\"594\":1,\"627\":1,\"678\":1,\"1066\":1,\"1280\":1,\"2343\":1}}],[\"常见错误⚠️\",{\"0\":{\"498\":1}}],[\"常见错误提示\",{\"0\":{\"417\":1,\"1463\":1}}],[\"常见错误提醒\",{\"0\":{\"269\":1},\"2\":{\"1329\":1}}],[\"常见错误3\",{\"2\":{\"309\":1,\"461\":1}}],[\"常见错误2\",{\"2\":{\"309\":1,\"461\":1}}],[\"常见错误1\",{\"2\":{\"309\":1,\"461\":1}}],[\"常见错误与解决方法\",{\"0\":{\"1064\":1},\"1\":{\"1109\":1,\"1159\":1}}],[\"常见错误与警示区块\",{\"0\":{\"354\":1}}],[\"常见错误与警告\",{\"0\":{\"309\":1,\"313\":1}}],[\"常见错误与注意事项\",{\"0\":{\"171\":1,\"243\":1,\"335\":1,\"461\":1,\"562\":1,\"565\":1,\"576\":1,\"601\":1,\"657\":1,\"679\":1,\"1079\":1,\"1482\":1},\"1\":{\"192\":1,\"718\":1}}],[\"常见错误及警告\",{\"0\":{\"231\":1}}],[\"常见错误\",{\"0\":{\"175\":1,\"192\":1,\"209\":1,\"210\":1,\"338\":1,\"378\":1,\"472\":1,\"527\":1,\"546\":1,\"600\":1,\"630\":1,\"671\":1,\"673\":1,\"684\":1,\"686\":1,\"689\":1,\"691\":1,\"720\":1,\"731\":1,\"758\":1,\"777\":1,\"792\":1,\"806\":1,\"809\":1,\"834\":1,\"856\":1,\"866\":1,\"879\":1,\"1051\":1,\"1080\":1,\"1091\":1,\"1109\":1,\"1157\":1,\"1171\":1,\"1174\":1,\"1189\":1,\"1192\":1,\"1194\":1,\"1254\":1,\"1262\":1,\"1270\":1,\"1293\":1,\"1295\":1,\"1301\":1,\"1311\":1,\"1314\":1,\"1325\":1,\"1335\":1,\"1345\":1,\"1346\":1,\"1351\":1,\"1352\":1,\"1371\":1,\"1383\":1,\"1399\":1,\"1452\":1,\"1547\":1,\"1592\":1,\"1601\":1,\"1639\":1,\"1696\":1,\"1733\":1,\"1743\":1,\"1757\":1,\"1777\":1,\"1778\":1,\"1802\":1,\"1821\":1,\"1840\":1,\"1845\":1,\"1850\":1,\"1851\":1,\"1881\":1,\"1911\":1,\"1914\":1,\"1945\":1,\"1946\":1,\"1965\":1,\"1975\":1,\"1988\":1,\"2009\":1,\"2018\":1,\"2041\":1,\"2056\":1,\"2086\":1,\"2106\":1,\"2126\":1,\"2127\":1,\"2133\":1,\"2146\":1,\"2164\":1,\"2172\":1,\"2191\":1,\"2203\":1,\"2239\":1,\"2243\":1,\"2249\":1,\"2268\":1,\"2287\":1,\"2290\":1,\"2299\":1,\"2353\":1,\"2355\":1,\"2367\":1,\"2390\":1,\"2403\":1,\"2414\":1,\"2438\":1,\"2450\":1,\"2480\":1,\"2496\":1,\"2513\":1,\"2530\":1,\"2538\":1,\"2593\":1,\"2619\":1,\"2657\":1,\"2668\":1,\"2698\":1},\"2\":{\"118\":1,\"211\":1,\"243\":1,\"251\":1,\"276\":1,\"354\":1,\"494\":1,\"576\":1,\"647\":1,\"657\":1,\"967\":1,\"1079\":1,\"1113\":1,\"1343\":1,\"1741\":1,\"2028\":1}}],[\"常见的数据类型有fp32\",{\"2\":{\"2192\":1}}],[\"常见的感知方式包括\",{\"2\":{\"1518\":1}}],[\"常见的多智能体协作工具包括\",{\"2\":{\"1485\":1}}],[\"常见的向量搜索算法\",{\"0\":{\"1422\":1},\"1\":{\"1467\":1,\"1511\":1,\"1559\":1,\"1610\":1,\"1663\":1,\"1717\":1,\"1774\":1,\"1835\":1,\"1894\":1,\"1949\":1,\"2000\":1,\"2051\":1,\"2104\":1,\"2154\":1,\"2197\":1,\"2236\":1,\"2271\":1,\"2304\":1,\"2335\":1,\"2365\":1,\"2394\":1}}],[\"常见的蒸馏方法可以分为三类\",{\"2\":{\"916\":1}}],[\"常见的方法包括\",{\"2\":{\"763\":1,\"2051\":1}}],[\"常见的无监督学习算法\",{\"2\":{\"39\":1}}],[\"常见的监督学习算法\",{\"2\":{\"39\":1}}],[\"常用基线是价值函数\",{\"2\":{\"1992\":1,\"2045\":1}}],[\"常用\",{\"2\":{\"996\":1}}],[\"常用于机器翻译任务\",{\"2\":{\"2292\":1}}],[\"常用于优化策略以对齐人类偏好\",{\"2\":{\"875\":1}}],[\"常用于深度学习\",{\"2\":{\"768\":1}}],[\"常用的方法是\",{\"2\":{\"2276\":1}}],[\"常用的学习率调度器类型有\",{\"2\":{\"2217\":1}}],[\"常用的一种评估指标是\",{\"2\":{\"1590\":1}}],[\"常用的数据类型\",{\"0\":{\"768\":1}}],[\"常用的机器阅读理解数据集\",{\"2\":{\"349\":1}}],[\"常用的机器学习算法\",{\"2\":{\"91\":1}}],[\"常用分词库\",{\"0\":{\"323\":1},\"1\":{\"347\":1,\"373\":1,\"399\":1,\"426\":1,\"452\":1,\"480\":1,\"508\":1,\"542\":1,\"576\":1,\"610\":1,\"645\":1,\"680\":1,\"719\":1}}],[\"常用分词库|常用分词库\",{\"2\":{\"5\":1}}],[\"即第几个句子\",{\"2\":{\"2608\":1}}],[\"即重要信息被忽略\",{\"2\":{\"2484\":1}}],[\"即模型未能找到相关答案\",{\"2\":{\"2466\":1}}],[\"即模型扮演自己的奖励模型角色\",{\"2\":{\"1924\":1}}],[\"即一张卡上会发生一次完整的前向和反向\",{\"2\":{\"2288\":1}}],[\"即便是目前最大的\",{\"2\":{\"2281\":1}}],[\"即便面对糟糕的用户提问\",{\"2\":{\"1496\":1}}],[\"即prompt\",{\"2\":{\"2166\":1}}],[\"即我们常说的显存\",{\"2\":{\"2077\":1}}],[\"即通过统计多个推理路径中最常见的答案来决定最终结果\",{\"2\":{\"2042\":1}}],[\"即通过rl训练展现出强大的推理行为\",{\"2\":{\"934\":1}}],[\"即采用混合精度分解的量化方法\",{\"2\":{\"1982\":1}}],[\"即operations\",{\"2\":{\"1977\":1}}],[\"即各层的输入\",{\"2\":{\"1813\":1}}],[\"即为\",{\"2\":{\"1787\":1}}],[\"即kv\",{\"2\":{\"1782\":1}}],[\"即k=1\",{\"2\":{\"1129\":1}}],[\"即句子末尾的token\",{\"2\":{\"1732\":1}}],[\"即实际学到的行为与人类期望不符合\",{\"2\":{\"1633\":1}}],[\"即在缺乏某一领域知识或不擅长的场景下\",{\"2\":{\"1468\":1}}],[\"即在物理内存上新开辟一块空间\",{\"2\":{\"846\":1}}],[\"即使我们没有每块的\",{\"2\":{\"2517\":1}}],[\"即使我们设法将模型适应单个\",{\"2\":{\"2313\":1}}],[\"即使用原始字符串进行关键字匹配\",{\"2\":{\"1949\":1}}],[\"即使在复杂任务中\",{\"2\":{\"1801\":1}}],[\"即使某些智能体出现故障\",{\"2\":{\"1384\":1}}],[\"即使字符集不重叠\",{\"2\":{\"318\":1}}],[\"即不能进一步分解的单个语义元素\",{\"2\":{\"1367\":1}}],[\"即对权重和激活进行量化和反量化操作\",{\"2\":{\"1355\":1}}],[\"即波长变长\",{\"2\":{\"1296\":1}}],[\"即\",{\"2\":{\"1222\":1,\"1343\":1,\"1708\":1,\"2000\":1,\"2518\":1}}],[\"即虽然rlhf有助于对齐人类偏好\",{\"2\":{\"992\":1}}],[\"即移除个别参数\",{\"2\":{\"931\":1}}],[\"即尽管对齐人类偏好\",{\"2\":{\"875\":1}}],[\"即学生模型\",{\"2\":{\"677\":1}}],[\"即教师模型\",{\"2\":{\"677\":1}}],[\"即时奖励函数和折扣因子\",{\"2\":{\"676\":1}}],[\"即可计算各自维护部分的\",{\"2\":{\"2673\":1}}],[\"即可能出现的词汇总数\",{\"2\":{\"996\":1}}],[\"即可\",{\"2\":{\"507\":1,\"1885\":1,\"1951\":1}}],[\"即长度外推问题\",{\"2\":{\"239\":1}}],[\"即16384\",{\"2\":{\"220\":1}}],[\"即因果注意力机制\",{\"2\":{\"125\":1}}],[\"即没有明确的目标输出\",{\"2\":{\"39\":1}}],[\"即每个输入数据都有明确的目标\",{\"2\":{\"39\":1}}],[\"即代价函数的值\",{\"2\":{\"32\":1}}],[\"翻译等\",{\"2\":{\"2223\":1}}],[\"翻译\",{\"2\":{\"34\":1,\"631\":1,\"882\":1}}],[\"联合编码\",{\"2\":{\"34\":1}}],[\"仅更新一次\",{\"2\":{\"2577\":1}}],[\"仅更新这些prefix的参数\",{\"2\":{\"1865\":1}}],[\"仅对问题的部分内容作出回答\",{\"2\":{\"2540\":1}}],[\"仅对最后一个logit进行解码得到第1个生成的token\",{\"2\":{\"1782\":1}}],[\"仅返回相关信息\",{\"2\":{\"2154\":1}}],[\"仅需偏好数据即可训练\",{\"2\":{\"2148\":1}}],[\"仅需少量标注数据\",{\"2\":{\"40\":1}}],[\"仅反映方向上的相似性\",{\"2\":{\"2051\":1}}],[\"仅调整embedding层表现力不够\",{\"2\":{\"1974\":1,\"2173\":1}}],[\"仅调整输入提示词的嵌入表示\",{\"2\":{\"57\":1}}],[\"仅训练\",{\"2\":{\"2115\":1}}],[\"仅训练向量d和b\",{\"2\":{\"1923\":1}}],[\"仅训练顶层和分类头\",{\"2\":{\"49\":1}}],[\"仅训练顶层\",{\"2\":{\"40\":1}}],[\"仅在指令中添加一行经典的提示语\",{\"2\":{\"1885\":1}}],[\"仅在组内计算注意力\",{\"2\":{\"156\":1}}],[\"仅起到简单的分发作用\",{\"2\":{\"1728\":1}}],[\"仅修改深层的l个transformer层\",{\"2\":{\"1722\":1,\"1779\":1}}],[\"仅用50\",{\"2\":{\"2692\":1}}],[\"仅用于提供奖励值\",{\"2\":{\"1533\":1}}],[\"仅用相对位置编码\",{\"2\":{\"1088\":1}}],[\"仅依赖自身算法和模型即可完成任务\",{\"2\":{\"1289\":1}}],[\"仅通过相对位置编码完成主要特征提取\",{\"2\":{\"1288\":1}}],[\"仅有一个智能体负责感知环境\",{\"2\":{\"1241\":1}}],[\"仅使用答案正确性的奖励函数\",{\"2\":{\"1740\":1}}],[\"仅使用独热编码可能导致模型无法捕捉词语之间的关联性\",{\"2\":{\"1113\":1}}],[\"仅使用相对位置编码处理大部分任务\",{\"2\":{\"1088\":1}}],[\"仅靠语言模型的学习便可以完成其他有监督学习的任务\",{\"2\":{\"975\":1}}],[\"仅保留prefix的参数\",{\"2\":{\"1974\":1}}],[\"仅保留核心的输入与位置信息\",{\"2\":{\"1353\":1}}],[\"仅保留\",{\"2\":{\"881\":1}}],[\"仅能关注自身及之前的\",{\"2\":{\"881\":1}}],[\"仅关注奖励函数本身\",{\"2\":{\"792\":1}}],[\"仅激活部分专家\",{\"2\":{\"440\":1}}],[\"仅计算当前token的q向量与缓存的k\",{\"2\":{\"187\":1}}],[\"仅解码器\",{\"2\":{\"34\":1}}],[\"仅编码器\",{\"2\":{\"34\":1}}],[\"文件分块器\",{\"2\":{\"2640\":2}}],[\"文件\",{\"2\":{\"2640\":2}}],[\"文学作品的翻译往往需要对语言细节进行反复推敲\",{\"2\":{\"2294\":1}}],[\"文学翻译润色\",{\"2\":{\"2294\":1}}],[\"文档类型以及用户查询特点等多方面因素\",{\"2\":{\"2655\":1}}],[\"文档类型决定了上下文保留的重要性\",{\"2\":{\"2655\":1}}],[\"文档类型\",{\"2\":{\"2655\":1}}],[\"文档代理递归检索在深入研究特定文档和检索详细答案方面表现出色\",{\"2\":{\"2335\":1}}],[\"文档需要被分割成多个文本块后再进行向量嵌入\",{\"2\":{\"2303\":1}}],[\"文档切片\",{\"0\":{\"2105\":1}}],[\"文档撰写\",{\"2\":{\"1820\":1}}],[\"文档本身需要具有清晰的结构\",{\"2\":{\"1469\":1}}],[\"文档划分\",{\"0\":{\"1421\":1}}],[\"文档知识准备是至关重要的一步\",{\"2\":{\"1185\":1}}],[\"文档对应的类别标签\",{\"2\":{\"938\":1}}],[\"文档\",{\"2\":{\"660\":1}}],[\"文章概述\",{\"0\":{\"1792\":1}}],[\"文章内容\",{\"0\":{\"1523\":1},\"1\":{\"1572\":1,\"1622\":1,\"1677\":1,\"1733\":1,\"1791\":1,\"1852\":1}}],[\"文章未注明具体来源\",{\"2\":{\"300\":1}}],[\"文章还探讨了不同模型结构在理解和生成任务中的应用场景\",{\"2\":{\"248\":1}}],[\"文本关键信息\",{\"2\":{\"2675\":1}}],[\"文本的语义信息得以以数值化的形式表示\",{\"2\":{\"2659\":1}}],[\"文本结构复杂且信息密度变化较大的场景\",{\"2\":{\"2620\":1}}],[\"文本来源未提供\",{\"2\":{\"1961\":1}}],[\"文本编码与词汇表\",{\"0\":{\"1096\":1}}],[\"文本到文本\",{\"2\":{\"978\":1}}],[\"文本转换\",{\"2\":{\"865\":1}}],[\"文本理解\",{\"2\":{\"861\":1}}],[\"文本处理\",{\"2\":{\"836\":1}}],[\"文本\",{\"2\":{\"669\":1}}],[\"文本对齐数据\",{\"2\":{\"568\":1}}],[\"文本分块过短的影响\",{\"0\":{\"2498\":1},\"1\":{\"2511\":1,\"2522\":1,\"2533\":1}}],[\"文本分块过长的影响\",{\"0\":{\"2419\":1},\"1\":{\"2444\":1,\"2465\":1,\"2483\":1}}],[\"文本分块的策略直接影响检索和生成的效果\",{\"2\":{\"2334\":1}}],[\"文本分块策略对大模型输出的影响\",{\"0\":{\"2393\":1},\"1\":{\"2419\":1,\"2444\":1,\"2465\":1,\"2483\":1,\"2498\":1,\"2511\":1,\"2522\":1,\"2533\":1}}],[\"文本分块策略的意义\",{\"0\":{\"2334\":1},\"1\":{\"2364\":1}}],[\"文本分块策略\",{\"0\":{\"2303\":1}}],[\"文本分词是自然语言处理\",{\"2\":{\"373\":1}}],[\"文本分类选\",{\"2\":{\"40\":1}}],[\"文本分类\",{\"2\":{\"34\":1,\"38\":1,\"39\":1,\"832\":1,\"1019\":1}}],[\"文本压缩\",{\"2\":{\"273\":1}}],[\"文本表示\",{\"2\":{\"59\":1}}],[\"文本预处理\",{\"2\":{\"59\":1}}],[\"文本主题分析\",{\"2\":{\"39\":1}}],[\"文本生成强\",{\"2\":{\"595\":1}}],[\"文本生成效果一般\",{\"2\":{\"339\":1}}],[\"文本生成\",{\"2\":{\"34\":1,\"861\":1}}],[\"文献综述的撰写\",{\"2\":{\"428\":1}}],[\"文献综述\",{\"2\":{\"4\":1}}],[\"纯\",{\"2\":{\"34\":2}}],[\"q的分块数量\",{\"2\":{\"2406\":1}}],[\"qaf方法\",{\"0\":{\"1538\":1},\"1\":{\"1588\":1,\"1641\":1}}],[\"qaf\",{\"0\":{\"1209\":1,\"1494\":1},\"1\":{\"1538\":1,\"1588\":1,\"1641\":1,\"1695\":1},\"2\":{\"1209\":3,\"1260\":1}}],[\"qat能够将带有权重和kv缓存量化的llama模型蒸馏为仅有4比特的模型\",{\"2\":{\"1448\":1}}],[\"qat是一种利用预训练模型生成结果来实现无数据蒸馏的方法\",{\"2\":{\"1448\":1}}],[\"qat方法\",{\"0\":{\"1400\":1},\"1\":{\"1448\":1}}],[\"qat\",{\"0\":{\"1160\":1,\"1308\":1,\"1448\":1,\"1813\":1},\"1\":{\"1355\":1,\"1400\":1,\"1448\":1},\"2\":{\"1160\":3,\"1209\":2,\"1260\":1,\"1308\":1,\"1813\":1}}],[\"qi∈rbr×d\",{\"2\":{\"2643\":1}}],[\"qiq\",{\"2\":{\"2573\":1}}],[\"qikj⊤=xiwqwk⊤xj⊤+xiwqwk⊤ri−j⊤+uwqwk⊤xj⊤+vwqwk⊤ri−j⊤q\",{\"2\":{\"1359\":1}}],[\"qikan\",{\"2\":{\"837\":1}}],[\"qi​∈rbr​×d\",{\"2\":{\"2643\":1}}],[\"qi​kj⊤​=xi​wq​wk⊤​xj⊤​+xi​wq​wk⊤​ri−j⊤​+uwq​wk⊤​xj⊤​+vwq​wk⊤​ri−j⊤​\",{\"2\":{\"1359\":1}}],[\"qi​\",{\"2\":{\"1187\":1}}],[\"qi\",{\"2\":{\"1187\":1,\"2286\":3,\"2539\":2,\"2573\":1,\"2581\":3}}],[\"qk^\",{\"2\":{\"1535\":1}}],[\"qk^t\",{\"2\":{\"34\":1,\"2080\":1}}],[\"qkv\",{\"2\":{\"1156\":1}}],[\"q3\",{\"2\":{\"1047\":1}}],[\"q3a3\",{\"2\":{\"1047\":1}}],[\"q2\",{\"2\":{\"1047\":1}}],[\"q2a2\",{\"2\":{\"1047\":1}}],[\"q1\",{\"2\":{\"1047\":2}}],[\"q1a1q2a2q3\",{\"2\":{\"1047\":1}}],[\"q1a1q2\",{\"2\":{\"1047\":1}}],[\"q1a1\",{\"2\":{\"1047\":1}}],[\"qqq\",{\"2\":{\"868\":1,\"2306\":1}}],[\"q=clip\",{\"2\":{\"868\":2}}],[\"qlearning\",{\"2\":{\"840\":1}}],[\"qlora的创新在于其能够在不牺牲性能的情况下显著降低内存需求\",{\"2\":{\"1964\":1}}],[\"qlora通过在每个网络层添加适配器\",{\"2\":{\"1735\":1}}],[\"qlora作为qaf方法的一种实现\",{\"2\":{\"1695\":1}}],[\"qlora是一种基于lora的微调方法\",{\"2\":{\"1679\":1}}],[\"qlora也是一种qaf方法\",{\"2\":{\"1641\":1}}],[\"qlora\",{\"0\":{\"1574\":1,\"1641\":1},\"1\":{\"1624\":1,\"1679\":1,\"1735\":1,\"1793\":1,\"1855\":1,\"1911\":1,\"1964\":1,\"2015\":1,\"2065\":1},\"2\":{\"151\":1,\"1624\":1}}],[\"q^\",{\"2\":{\"767\":3}}],[\"q∗\",{\"2\":{\"767\":4}}],[\"qπ​\",{\"2\":{\"732\":2,\"779\":1,\"810\":2}}],[\"qπ\",{\"2\":{\"732\":2,\"779\":1,\"810\":2}}],[\"qπθ​​\",{\"2\":{\"586\":1}}],[\"qπθ\",{\"2\":{\"586\":1}}],[\"qsa\",{\"2\":{\"647\":14,\"656\":9}}],[\"q值\",{\"2\":{\"640\":1}}],[\"qwq​\",{\"2\":{\"2164\":1,\"2636\":1}}],[\"qwq\",{\"2\":{\"1917\":1,\"2603\":1,\"2622\":1}}],[\"qw​\",{\"2\":{\"640\":1}}],[\"qw\",{\"2\":{\"640\":2}}],[\"qwen\",{\"2\":{\"1404\":1,\"1535\":1,\"1542\":1,\"1878\":1,\"1955\":1,\"2210\":1,\"2338\":1,\"2603\":1,\"2642\":2}}],[\"qwen在模型性能和外推能力上取得了显著提升\",{\"2\":{\"1060\":1}}],[\"qwen模型通过未绑定嵌入和多种注意力机制的创新组合\",{\"2\":{\"1397\":1}}],[\"qwen模型在结构上进行了多项改进\",{\"2\":{\"1155\":1}}],[\"qwen模型是一种基于transformer改进的语言模型\",{\"2\":{\"1060\":1}}],[\"qwen模型\",{\"2\":{\"1017\":1}}],[\"qwen2通过多种技术手段提升模型对长文本和多语言的处理能力\",{\"2\":{\"1372\":1}}],[\"qwen2的训练过程分为两个阶段\",{\"2\":{\"1230\":1}}],[\"qwen2的训练过程涉及多个关键步骤\",{\"2\":{\"1084\":1}}],[\"qwen2模型在其架构上进行了多项优化\",{\"2\":{\"1041\":1}}],[\"qwen2\",{\"0\":{\"977\":1,\"1001\":1},\"1\":{\"1018\":1,\"1041\":1,\"1061\":1,\"1084\":1,\"1106\":1,\"1130\":1,\"1156\":1,\"1181\":1,\"1205\":1,\"1230\":1,\"1256\":1,\"1280\":1,\"1305\":1,\"1327\":1,\"1352\":1,\"1372\":1,\"1398\":1,\"1446\":1,\"1492\":1},\"2\":{\"172\":2,\"1001\":1,\"1018\":1,\"1061\":1,\"1156\":1,\"1256\":1,\"1305\":1,\"1372\":1,\"1398\":1,\"1446\":1,\"1492\":1}}],[\"qwen1\",{\"0\":{\"976\":1},\"1\":{\"1017\":1,\"1060\":1,\"1105\":1,\"1155\":1,\"1204\":1,\"1255\":1,\"1304\":1,\"1351\":1,\"1397\":1,\"1444\":1,\"1490\":1,\"1535\":1},\"2\":{\"172\":1}}],[\"q0​q1​​\",{\"2\":{\"247\":1}}],[\"q0q1\",{\"2\":{\"247\":1}}],[\"qmax​\",{\"2\":{\"868\":1}}],[\"qmax⁡\",{\"2\":{\"868\":1}}],[\"qmin​\",{\"2\":{\"868\":1}}],[\"qmin⁡\",{\"2\":{\"868\":1}}],[\"qmtkn−λ∣m−n∣q\",{\"2\":{\"293\":1}}],[\"qmtknq\",{\"2\":{\"293\":1}}],[\"qmt​kn​−λ∣m−n∣\",{\"2\":{\"293\":1}}],[\"qmt​kn​\",{\"2\":{\"293\":1}}],[\"qm​\",{\"2\":{\"247\":1}}],[\"qm\",{\"2\":{\"247\":1}}],[\"q代表query向量\",{\"2\":{\"130\":1}}],[\"quantization\",{\"0\":{\"1160\":1,\"1209\":1,\"1260\":1,\"1588\":1},\"2\":{\"763\":1,\"1308\":1}}],[\"quad\",{\"2\":{\"261\":1,\"283\":1,\"307\":1,\"622\":1,\"1891\":1,\"1901\":1,\"2692\":1}}],[\"question\",{\"2\":{\"544\":1,\"1885\":1,\"2233\":1,\"2546\":1}}],[\"query\",{\"0\":{\"170\":1,\"191\":1,\"1835\":1,\"2578\":1},\"2\":{\"111\":2,\"112\":1,\"1069\":1,\"1358\":1,\"1701\":1,\"1912\":2,\"2286\":1,\"2312\":1,\"2484\":1,\"2570\":1,\"2578\":4}}],[\"quot\",{\"2\":{\"444\":4,\"507\":2,\"562\":6,\"647\":8,\"882\":2,\"1406\":2,\"1843\":2,\"2091\":6,\"2141\":4}}],[\"quotient\",{\"2\":{\"47\":3}}],[\"quote\",{\"2\":{\"18\":2}}],[\"q\",{\"0\":{\"640\":1,\"710\":1,\"775\":1,\"2085\":1},\"2\":{\"34\":1,\"130\":2,\"135\":3,\"188\":1,\"189\":7,\"208\":4,\"213\":5,\"228\":1,\"247\":4,\"571\":1,\"573\":1,\"586\":1,\"611\":6,\"623\":7,\"640\":19,\"646\":5,\"647\":2,\"653\":4,\"656\":8,\"672\":6,\"710\":8,\"723\":1,\"732\":2,\"775\":6,\"779\":2,\"810\":2,\"840\":8,\"868\":3,\"928\":1,\"1187\":3,\"1207\":1,\"1266\":1,\"1359\":4,\"1535\":3,\"1813\":1,\"1868\":1,\"2085\":1,\"2286\":6,\"2317\":1,\"2357\":1,\"2430\":10,\"2455\":1,\"2485\":4,\"2539\":16,\"2549\":4,\"2573\":2,\"2618\":1,\"2643\":1,\"2653\":4}}],[\"结果广播\",{\"2\":{\"2452\":1}}],[\"结果是生成的向量难以代表文本的重要内容\",{\"2\":{\"2444\":1}}],[\"结果显示其性能大幅领先\",{\"2\":{\"2277\":1}}],[\"结果\",{\"2\":{\"2076\":1}}],[\"结果数量\",{\"0\":{\"2000\":1}}],[\"结果表明\",{\"2\":{\"1701\":1}}],[\"结束循环\",{\"2\":{\"789\":1}}],[\"结尾\",{\"2\":{\"548\":1}}],[\"结合相关文档与问题形成新的提示\",{\"2\":{\"2445\":1}}],[\"结合业务需求\",{\"2\":{\"2245\":1}}],[\"结合其他优化技术\",{\"2\":{\"2048\":1}}],[\"结合传统方法\",{\"2\":{\"1989\":1}}],[\"结合gae和value能够有效提高critic模型的稳定性和准确性\",{\"2\":{\"1877\":1}}],[\"结合连续提示与离散token\",{\"2\":{\"1796\":1}}],[\"结合历史对话的重新表述\",{\"0\":{\"1663\":1}}],[\"结合推理与行动\",{\"0\":{\"1608\":1}}],[\"结合递归式分块\",{\"0\":{\"1561\":1}}],[\"结合小模型预热和大模型微调\",{\"2\":{\"1464\":1}}],[\"结合\",{\"0\":{\"1578\":1},\"2\":{\"1439\":1,\"1507\":1}}],[\"结合绝对位置编码\",{\"2\":{\"1288\":1}}],[\"结合绝对位置信息\",{\"2\":{\"1088\":1}}],[\"结合pca或其他降维算法\",{\"2\":{\"1263\":1}}],[\"结合pytorch和hugging\",{\"2\":{\"240\":1}}],[\"结合预训练和few\",{\"2\":{\"1228\":1}}],[\"结合faiss相似度计算框架\",{\"2\":{\"1075\":1}}],[\"结合使用也叫\",{\"2\":{\"981\":1}}],[\"结合使用以进一步优化性能\",{\"2\":{\"360\":1}}],[\"结合自监督预训练和有监督微调\",{\"2\":{\"968\":1}}],[\"结合自动化工具和人工筛选\",{\"2\":{\"532\":1}}],[\"结合了双向和自回归的特性\",{\"2\":{\"897\":1}}],[\"结合了以下技术特性\",{\"2\":{\"889\":1}}],[\"结合权重的量化可以充分利用整数计算获得性能提升\",{\"2\":{\"799\":1}}],[\"结合多答案选择策略\",{\"2\":{\"665\":1}}],[\"结合质量权重\",{\"2\":{\"473\":1}}],[\"结合sparse和linear\",{\"2\":{\"327\":1}}],[\"结合空洞attention和局部attention\",{\"2\":{\"168\":1}}],[\"结合外推和内插方法\",{\"2\":{\"159\":1}}],[\"结合规则引擎过滤敏感信息\",{\"2\":{\"49\":1}}],[\"结合掩码自注意力和编码器\",{\"2\":{\"34\":1}}],[\"结构上按照\",{\"2\":{\"2218\":1}}],[\"结构创新\",{\"2\":{\"1277\":1}}],[\"结构化剪枝方法\",{\"0\":{\"1143\":1}}],[\"结构化剪枝是指根据预定义规则移除连接或分层结构\",{\"2\":{\"1094\":1}}],[\"结构化剪枝\",{\"0\":{\"1094\":1},\"1\":{\"1143\":1}}],[\"结构正逐渐被更高效的变种所取代\",{\"2\":{\"138\":1}}],[\"结构\",{\"2\":{\"65\":1}}],[\"结构特点\",{\"2\":{\"34\":1}}],[\"结构和解码策略\",{\"0\":{\"98\":1},\"2\":{\"5\":4}}],[\"结构和解码策略|structure\",{\"2\":{\"5\":1}}],[\"架构以适应更多任务场景\",{\"2\":{\"1758\":1}}],[\"架构时\",{\"2\":{\"1091\":1}}],[\"架构展现了强大的自回归生成能力\",{\"2\":{\"1006\":1}}],[\"架构通过使用\",{\"2\":{\"1006\":1}}],[\"架构通过\",{\"2\":{\"664\":1}}],[\"架构的设计理念和技术细节\",{\"2\":{\"248\":1}}],[\"架构\",{\"0\":{\"389\":1,\"1006\":1},\"1\":{\"415\":1,\"440\":1,\"467\":1,\"495\":1},\"2\":{\"34\":1,\"664\":1,\"889\":1,\"1542\":1,\"1860\":1,\"2288\":1}}],[\"一卡工作\",{\"2\":{\"2688\":1}}],[\"一旦确认好\",{\"2\":{\"2616\":1}}],[\"一旦任务明确\",{\"2\":{\"1408\":1}}],[\"一次性生成文本在长文本生成任务中容易产生幻觉\",{\"2\":{\"2570\":1}}],[\"一张卡存一块\",{\"2\":{\"2515\":1}}],[\"一张卡放不下\",{\"2\":{\"2515\":1}}],[\"一律用块级公式包裹\",{\"2\":{\"2215\":1}}],[\"一致\",{\"2\":{\"2129\":1}}],[\"一句话总结\",{\"0\":{\"2022\":1,\"2317\":1}}],[\"一开始就失败和处理到\",{\"2\":{\"1544\":1}}],[\"一些任务可能需要处理长文本上下文\",{\"2\":{\"2699\":1}}],[\"一些细微的语言差异可能在初稿中未被充分体现\",{\"2\":{\"2294\":1}}],[\"一些典型的单智能体应用包括\",{\"2\":{\"1439\":1}}],[\"一些后续模型\",{\"2\":{\"1388\":1}}],[\"一些基于\",{\"2\":{\"1224\":1}}],[\"一般ddd的取值在64～128\",{\"2\":{\"2653\":1}}],[\"一般设置为\",{\"2\":{\"2252\":1}}],[\"一般来说\",{\"2\":{\"2087\":1,\"2364\":1}}],[\"一般出现在输入示例之前\",{\"2\":{\"1368\":1}}],[\"一般的师生架构如下图所示\",{\"2\":{\"715\":1}}],[\"一起被投影到注意力机制中时\",{\"2\":{\"1343\":1}}],[\"一种机器学习方法\",{\"2\":{\"2647\":1}}],[\"一种机制\",{\"2\":{\"970\":1,\"1073\":1}}],[\"一种选择正确响应的方法\",{\"2\":{\"2516\":1}}],[\"一种解决方案是窗口搜索\",{\"2\":{\"2197\":1}}],[\"一种实验方法\",{\"2\":{\"2024\":1}}],[\"一种优化技术\",{\"2\":{\"1983\":1}}],[\"一种常见的稀疏搜索算法是最佳匹配25\",{\"2\":{\"1949\":1}}],[\"一种基于深度强化学习的算法\",{\"2\":{\"1939\":1}}],[\"一种需要长时间推理计算的模型类型\",{\"2\":{\"1939\":1}}],[\"一种衡量两个概率分布差异的指标\",{\"2\":{\"1939\":1}}],[\"一种用随机数填充的矩阵\",{\"2\":{\"1866\":1}}],[\"一种用于记录和分析模型推理过程的数据结构\",{\"2\":{\"2516\":1}}],[\"一种用于减少模型参数的技术\",{\"2\":{\"1793\":1}}],[\"一种用于处理序列数据的神经网络架构\",{\"2\":{\"1722\":1}}],[\"一种用于处理输入数据并生成输出数据的结构\",{\"2\":{\"970\":1}}],[\"一种用于更新价值函数的方法\",{\"2\":{\"1645\":1}}],[\"一种用于优化神经网络训练的正则化方法\",{\"2\":{\"1002\":1}}],[\"一种用于确定最优策略的方程\",{\"2\":{\"647\":1}}],[\"一种通过在输入中插入特殊提示来引导模型学习的技术\",{\"2\":{\"1794\":1}}],[\"一种技术\",{\"2\":{\"1793\":1}}],[\"一种数据表示方式\",{\"2\":{\"1793\":1}}],[\"一种数学函数\",{\"2\":{\"970\":1}}],[\"一种将文本切分为小单位\",{\"2\":{\"1531\":1}}],[\"一种更为高级的规划方法是利用llm进行长序列的整体规划\",{\"2\":{\"1465\":1}}],[\"一种自然且有效的分块方式是利用文档内部已经存在的内在结构\",{\"2\":{\"1379\":1}}],[\"一条序列的数据用来训练轮数\",{\"2\":{\"766\":1}}],[\"一是自回归过程中缓存的k和v张量非常大\",{\"2\":{\"750\":1}}],[\"一边更新其策略\",{\"2\":{\"618\":1}}],[\"一个灵活且功能强大的框架\",{\"2\":{\"2702\":1}}],[\"一个transformerblock需要在前向和后向总共需要4个all\",{\"2\":{\"2679\":1}}],[\"一个token一个token地生成response\",{\"2\":{\"1927\":1}}],[\"一个模型的内存和计算被分布在多个计算节点上\",{\"2\":{\"2503\":1}}],[\"一个模型实例负责处理用户查询\",{\"2\":{\"2037\":1}}],[\"一个优秀的模型需要能够从这些噪声中提取有用的信息\",{\"2\":{\"2458\":1}}],[\"一个良好的分块策略能够让每个文本片段既包含足够的信息来回答某类问题\",{\"2\":{\"2393\":1}}],[\"一个理想的文本块应该满足以下条件\",{\"2\":{\"2364\":1}}],[\"一个功能更新可能涉及多处代码修改\",{\"2\":{\"2185\":1}}],[\"一个常见问题是显存估算值与实际测量值之间的差异\",{\"2\":{\"2170\":1}}],[\"一个\",{\"2\":{\"2144\":1,\"2224\":1,\"2281\":1}}],[\"一个分块计算softmax的例子\",{\"0\":{\"2130\":1},\"1\":{\"2176\":1,\"2216\":1}}],[\"一个状态机型系统可能会反复检查任务进展\",{\"2\":{\"1847\":1}}],[\"一个状态的价值可以通过从该状态出发的回报期望来估计\",{\"2\":{\"747\":1}}],[\"一个自然的想法是将多个请求合并成1个batch进行推理\",{\"2\":{\"1843\":1}}],[\"一个完整的包含\",{\"2\":{\"1766\":1}}],[\"一个系统的\",{\"2\":{\"1672\":1}}],[\"一个系统可以是渐进的\",{\"2\":{\"1617\":1}}],[\"一个简单的线性层\",{\"2\":{\"1645\":1}}],[\"一个大型语言模型\",{\"2\":{\"1569\":1}}],[\"一个大矩阵\",{\"2\":{\"351\":1,\"1991\":1}}],[\"一个很好的思路是\",{\"2\":{\"847\":1}}],[\"一个序列从后往前计算\",{\"2\":{\"843\":1}}],[\"一个prompt需要生成多个输出序列\",{\"2\":{\"750\":1}}],[\"一个2000词的文本可以分成4个\",{\"2\":{\"116\":1}}],[\"一\",{\"0\":{\"34\":1,\"1662\":1},\"1\":{\"1716\":1,\"1773\":1,\"1834\":1}}],[\"直到完成生成\",{\"2\":{\"2570\":1}}],[\"直到完成任务或满足某个条件\",{\"2\":{\"1847\":1}}],[\"直到遍历完最后一块\",{\"2\":{\"2517\":1}}],[\"直到最终得到满意的结果\",{\"2\":{\"2363\":1}}],[\"直到所有文本块都满足\",{\"2\":{\"2141\":1}}],[\"直到目标达成\",{\"2\":{\"1847\":1}}],[\"直到问题得到解决\",{\"2\":{\"1788\":1}}],[\"直到每个chunk都在模型允许的上下文长度范围内\",{\"2\":{\"1561\":1}}],[\"直到要超过\",{\"2\":{\"917\":1}}],[\"直到相邻两次迭代的变化小于给定阈值\",{\"2\":{\"647\":1}}],[\"直到达到最大限制\",{\"2\":{\"1306\":1}}],[\"直到达到终止条件\",{\"2\":{\"646\":1}}],[\"直到达到预设的子词表大小或频率阈值\",{\"2\":{\"392\":1}}],[\"直到收敛到一个最优值\",{\"2\":{\"612\":1}}],[\"直到词表缩减到目标大小\",{\"2\":{\"393\":1}}],[\"直到满足块大小的要求\",{\"2\":{\"2606\":1}}],[\"直到满足所需的词汇量\",{\"2\":{\"391\":1}}],[\"直到满足条件\",{\"2\":{\"381\":1}}],[\"直到找到最低点\",{\"2\":{\"32\":1}}],[\"直接翻了virtual\",{\"2\":{\"2697\":1}}],[\"直接基于用户输入进行查询\",{\"2\":{\"2445\":1}}],[\"直接混合不同的sft数据源并应用sft\",{\"2\":{\"2371\":1}}],[\"直接生成的速度会十分缓慢\",{\"2\":{\"2129\":1}}],[\"直接更新prefix参数可能导致训练不稳定和性能下降\",{\"2\":{\"2126\":1}}],[\"直接给予奖励\",{\"2\":{\"1958\":1}}],[\"直接影响了该系统在智能体属性上的表现\",{\"2\":{\"1672\":1}}],[\"直接影响梯度计算的稳定性\",{\"2\":{\"625\":1}}],[\"直接使用蒙特卡洛估计可能导致方差过大\",{\"2\":{\"2480\":1,\"2496\":1}}],[\"直接使用人类反馈作为奖励函数成本过高\",{\"2\":{\"1633\":1}}],[\"直接使用低质量数据\",{\"2\":{\"718\":1}}],[\"直接偏好优化可能减少信息损失和资源需求\",{\"2\":{\"1754\":1}}],[\"直接偏好优化\",{\"2\":{\"1495\":1}}],[\"直接提示\",{\"2\":{\"1420\":1}}],[\"直接加入到attention矩阵中\",{\"2\":{\"1353\":1}}],[\"直接加绝对位置编码\",{\"2\":{\"1187\":1}}],[\"直接假设正弦位置编码能完全表达相对位置信息\",{\"2\":{\"1343\":1}}],[\"直接移植v2的softmax路由机制\",{\"2\":{\"1324\":1}}],[\"直接将绝对位置向量替换为相对位置向量\",{\"2\":{\"1313\":1}}],[\"直接将结论告诉学生模型\",{\"2\":{\"811\":1}}],[\"直接用llm生成demonstration\",{\"0\":{\"1032\":1}}],[\"直接用大模型\",{\"2\":{\"568\":1}}],[\"直接显式地学习一个目标策略\",{\"2\":{\"724\":1}}],[\"直接通过更新状态价值函数来求解最优策略\",{\"2\":{\"656\":1}}],[\"直接对策略更新进行clip操作\",{\"2\":{\"590\":1}}],[\"直接从原始数据中进行训练\",{\"2\":{\"426\":1}}],[\"直接替换嵌入向量\",{\"2\":{\"309\":1}}],[\"直接外推问题\",{\"2\":{\"313\":1}}],[\"直接外推的风险\",{\"2\":{\"269\":1}}],[\"直接外推可能导致模型性能下降\",{\"2\":{\"223\":1}}],[\"直接外推\",{\"2\":{\"202\":1,\"223\":1,\"292\":1}}],[\"直接复用前序token的k\",{\"2\":{\"187\":1}}],[\"直接调用\",{\"2\":{\"10\":1}}],[\"下的表现\",{\"2\":{\"2401\":1}}],[\"下的动作\",{\"2\":{\"775\":1}}],[\"下采样矩阵\",{\"2\":{\"2062\":1}}],[\"下面给出具体的图例加深理解\",{\"2\":{\"2431\":1}}],[\"下面是官方的例子\",{\"2\":{\"2158\":1}}],[\"下面是标准的attention计算流程\",{\"2\":{\"1868\":1}}],[\"下面是dpo损失函数的代码示例\",{\"2\":{\"1731\":1}}],[\"下面分别介绍它们的适用场景\",{\"2\":{\"17\":1}}],[\"下一步就是将这些demonstrations整合成一个自然语言prompt\",{\"2\":{\"1322\":1}}],[\"下游任务微调方式\",{\"0\":{\"1288\":1}}],[\"下游任务不需要用标签数据进行微调\",{\"2\":{\"1154\":1}}],[\"下游任务性能一致\",{\"2\":{\"1008\":1}}],[\"下执行动作\",{\"2\":{\"779\":1}}],[\"下\",{\"2\":{\"748\":1}}],[\"下个状态的最大q值\",{\"2\":{\"640\":1}}],[\"下坡\",{\"2\":{\"32\":1}}],[\"换句话说\",{\"2\":{\"32\":1,\"1540\":1,\"1672\":1,\"2566\":1}}],[\"只考虑\",{\"2\":{\"2653\":1}}],[\"只能应用于特定类型的文档\",{\"2\":{\"2650\":1}}],[\"只用大体知道\",{\"2\":{\"2349\":1}}],[\"只用配置文件即可对\",{\"2\":{\"2055\":1}}],[\"只计算bot\",{\"2\":{\"2322\":1}}],[\"只在主进程中保存模型\",{\"2\":{\"2201\":1}}],[\"只在最后一个token处计算奖励值\",{\"2\":{\"1582\":1}}],[\"只适合\",{\"2\":{\"2118\":1}}],[\"只负责其中一部分训练\",{\"2\":{\"2108\":1}}],[\"只有最后一个动作处有奖励\",{\"2\":{\"2415\":1,\"2441\":1}}],[\"只有最后一个块可能会浪费内存\",{\"2\":{\"750\":1}}],[\"只有1\",{\"2\":{\"2077\":1}}],[\"只对剩余特征做量化\",{\"2\":{\"1982\":1}}],[\"只要找到一种合理的匹配即可\",{\"2\":{\"1377\":1}}],[\"只保留有限长度的范围\",{\"2\":{\"1266\":1}}],[\"只需将\",{\"2\":{\"1951\":1}}],[\"只需要将输入数据传递给这些函数\",{\"2\":{\"2526\":1}}],[\"只需要利用unstructured获取标题高度值即可完成层级判断\",{\"2\":{\"2235\":1}}],[\"只需要更新几行代码即可开启分布式训练之旅啦\",{\"2\":{\"2158\":1}}],[\"只需要少量校准数据\",{\"2\":{\"1874\":1}}],[\"只需要朝梯度的反方向移动\",{\"2\":{\"32\":1}}],[\"只需获取目标向量的哈希值\",{\"2\":{\"1559\":1}}],[\"只需选择一种rl算法即可完成任务\",{\"2\":{\"1222\":1}}],[\"只需计算\",{\"2\":{\"1047\":1}}],[\"只是根据提供的上下文信息调整其生成或分类行为\",{\"2\":{\"569\":1}}],[\"只是知道书本上的知识\",{\"2\":{\"56\":1}}],[\"只引入\",{\"2\":{\"22\":1}}],[\"只引入一个或几个特定的标准库成员\",{\"2\":{\"22\":1}}],[\"表达方式对模型性能的影响\",{\"2\":{\"2451\":1}}],[\"表达方式和难度升级\",{\"2\":{\"2373\":1}}],[\"表达方式要多样化\",{\"2\":{\"2280\":1}}],[\"表达式\",{\"2\":{\"16\":2}}],[\"表明其已被充分拟合\",{\"2\":{\"1681\":1}}],[\"表格等文件时\",{\"2\":{\"1284\":1}}],[\"表格\",{\"2\":{\"646\":1}}],[\"表格数据整理\",{\"0\":{\"292\":1}}],[\"表征提取优\",{\"2\":{\"595\":1}}],[\"表现优于init\",{\"2\":{\"2372\":1}}],[\"表现效果因多方面因素而异\",{\"0\":{\"1775\":1,\"1895\":1}}],[\"表现\",{\"2\":{\"516\":1}}],[\"表示前\",{\"2\":{\"2318\":1}}],[\"表示切完后的某块矩阵\",{\"2\":{\"2286\":2}}],[\"表示句子分隔\",{\"2\":{\"2141\":1}}],[\"表示段落分隔\",{\"2\":{\"2141\":1}}],[\"表示优先按段落分隔符\",{\"2\":{\"2091\":1}}],[\"表示浮点数运算次数\",{\"2\":{\"1926\":1}}],[\"表示输出结束的特殊token\",{\"2\":{\"1782\":1}}],[\"表示输入词向量\",{\"2\":{\"1187\":1}}],[\"表示每秒钟执行的浮点数操作次数\",{\"2\":{\"1926\":1}}],[\"表示每次响应生成允许的最大工具调用次数\",{\"2\":{\"1740\":1}}],[\"表示每个token去向每个expert的概率\",{\"2\":{\"1119\":1}}],[\"表示每个特征的重要性\",{\"2\":{\"76\":1}}],[\"表示系统对用户查询的响应越好\",{\"2\":{\"1698\":1}}],[\"表示拒绝的响应\",{\"2\":{\"1582\":1}}],[\"表示选择的响应\",{\"2\":{\"1582\":1}}],[\"表示提示\",{\"2\":{\"1582\":1}}],[\"表示锚样本与正\",{\"2\":{\"1566\":1}}],[\"表示整个batch每个token分配给第\",{\"2\":{\"1279\":1}}],[\"表示被分配到第\",{\"2\":{\"1279\":1}}],[\"表示文本结束的符号\",{\"2\":{\"1249\":1}}],[\"表示模型的维度\",{\"2\":{\"1246\":1}}],[\"表示模型需要寻找的信息\",{\"2\":{\"112\":1}}],[\"表示序列中的具体位置\",{\"2\":{\"1246\":1}}],[\"表示序列中包含的信息\",{\"2\":{\"112\":1}}],[\"表示相对位置编码矩阵\",{\"2\":{\"1187\":1}}],[\"表示取整\",{\"2\":{\"868\":1}}],[\"表示示例\",{\"2\":{\"773\":1}}],[\"表示在状态\",{\"2\":{\"748\":1,\"779\":1}}],[\"表示在给定策略下\",{\"2\":{\"647\":1}}],[\"表示从教师模型中提取的内容\",{\"2\":{\"715\":1}}],[\"表示单词结尾\",{\"2\":{\"392\":1}}],[\"表示子词\",{\"2\":{\"355\":1}}],[\"表示token在序列中的绝对位置\",{\"2\":{\"263\":1}}],[\"表示\",{\"2\":{\"223\":1,\"435\":1,\"938\":1,\"1949\":1}}],[\"表示函数在某一点处的变化率或斜率\",{\"2\":{\"32\":1}}],[\"梯度和优化器状态\",{\"2\":{\"2704\":1}}],[\"梯度通过优势函数和kl项提供信号\",{\"2\":{\"2577\":1}}],[\"梯度通常是浮点数\",{\"2\":{\"799\":1}}],[\"梯度分区\",{\"0\":{\"2308\":1}}],[\"梯度检查点\",{\"2\":{\"2252\":1}}],[\"梯度会在多少个小批次上累积\",{\"2\":{\"2217\":1}}],[\"梯度累积与批量大小\",{\"2\":{\"2217\":1}}],[\"梯度累积采用分阶段更新策略\",{\"2\":{\"1227\":1}}],[\"梯度值\",{\"2\":{\"2123\":1}}],[\"梯度值和激活值对显存的影响\",{\"2\":{\"2099\":1}}],[\"梯度值小于\",{\"2\":{\"591\":1}}],[\"梯度值过大或过小导致训练失败\",{\"2\":{\"211\":1}}],[\"梯度\",{\"2\":{\"488\":1,\"657\":1,\"799\":1,\"2288\":1}}],[\"梯度去缩放与裁剪\",{\"2\":{\"435\":1}}],[\"梯度裁剪是否会对稀疏参数优化产生负面影响\",{\"2\":{\"694\":1}}],[\"梯度裁剪阈值设置不当\",{\"2\":{\"657\":1}}],[\"梯度裁剪可以有效防止梯度爆炸问题\",{\"2\":{\"622\":1}}],[\"梯度裁剪\",{\"0\":{\"622\":1},\"2\":{\"433\":1}}],[\"梯度处理\",{\"2\":{\"405\":1}}],[\"梯度下溢\",{\"0\":{\"556\":1},\"2\":{\"382\":1,\"591\":1}}],[\"梯度下降法\",{\"2\":{\"123\":1}}],[\"梯度下降法是一种从高处\",{\"2\":{\"32\":1}}],[\"梯度下降\",{\"2\":{\"32\":1,\"820\":1}}],[\"梯度饱和问题\",{\"2\":{\"330\":1}}],[\"梯度饱和问题仍然存在\",{\"2\":{\"215\":1}}],[\"梯度为\",{\"2\":{\"238\":1}}],[\"梯度爆炸与消失\",{\"2\":{\"211\":1}}],[\"梯度接近于\",{\"2\":{\"194\":1}}],[\"梯度过小问题\",{\"2\":{\"192\":1}}],[\"梯度依然能顺畅地回传\",{\"2\":{\"183\":1}}],[\"梯度范数在各层间保持近似相等\",{\"2\":{\"169\":1}}],[\"梯度稳定性\",{\"2\":{\"150\":1}}],[\"梯度消失问题\",{\"2\":{\"194\":1}}],[\"梯度消失\",{\"2\":{\"132\":1,\"330\":1,\"2494\":1}}],[\"梯度提升树\",{\"2\":{\"39\":1}}],[\"梯度指出了代价函数增大的方向\",{\"2\":{\"32\":1}}],[\"梯度指引方向\",{\"2\":{\"32\":1}}],[\"梯度是一个向量\",{\"2\":{\"32\":1}}],[\"梯度是指函数的偏导数\",{\"2\":{\"32\":1}}],[\"代表此蓝色复制\",{\"2\":{\"2579\":1}}],[\"代表的是一个\",{\"2\":{\"2408\":1}}],[\"代表的含义即可\",{\"2\":{\"2349\":1}}],[\"代表了生成每个\",{\"2\":{\"2145\":1}}],[\"代入bradley\",{\"2\":{\"2046\":1}}],[\"代替矩阵乘积\",{\"2\":{\"996\":1}}],[\"代理无需与环境交互采样\",{\"2\":{\"688\":1}}],[\"代理使用预先收集好的轨迹样本进行学习\",{\"2\":{\"618\":1}}],[\"代理一边收集数据\",{\"2\":{\"618\":1}}],[\"代理\",{\"2\":{\"618\":1}}],[\"代价函数优化的核心\",{\"2\":{\"32\":1}}],[\"代码库和学术论文等\",{\"2\":{\"2650\":1}}],[\"代码库与框架\",{\"2\":{\"65\":1}}],[\"代码中重要性采样处理的不足之处\",{\"2\":{\"2545\":1}}],[\"代码优化\",{\"2\":{\"2535\":1}}],[\"代码分析\",{\"2\":{\"2279\":1}}],[\"代码执行能力\",{\"2\":{\"2269\":1}}],[\"代码块\",{\"0\":{\"2201\":1,\"2526\":1,\"2688\":1},\"1\":{\"2691\":1,\"2694\":1,\"2697\":1},\"2\":{\"2406\":1}}],[\"代码效率高\",{\"2\":{\"2055\":1}}],[\"代码编写和执行能力是agent的一项重要能力\",{\"2\":{\"1674\":1}}],[\"代码解释器等\",{\"2\":{\"1619\":1}}],[\"代码数据扩充了4倍\",{\"2\":{\"1117\":1}}],[\"代码及研究论文\",{\"2\":{\"929\":1}}],[\"代码生成\",{\"2\":{\"706\":1}}],[\"代码相关数据\",{\"2\":{\"535\":1}}],[\"代码片段\",{\"0\":{\"526\":1}}],[\"代码等数据集\",{\"2\":{\"516\":1}}],[\"代码和逻辑数据\",{\"2\":{\"474\":1}}],[\"代码和逻辑数据需适量增加\",{\"2\":{\"422\":1}}],[\"代码=4\",{\"2\":{\"474\":2}}],[\"代码\",{\"2\":{\"474\":2,\"525\":1,\"803\":1}}],[\"代码实现中的关键步骤\",{\"2\":{\"1591\":1}}],[\"代码实现\",{\"0\":{\"364\":1,\"1912\":1,\"2500\":1},\"2\":{\"324\":1,\"1622\":1,\"2174\":1,\"2467\":1}}],[\"代码也更简洁易懂\",{\"2\":{\"27\":1}}],[\"代码简单直接\",{\"2\":{\"20\":1}}],[\"代码主要由函数组成\",{\"2\":{\"12\":1}}],[\"代码示例与计算步骤\",{\"0\":{\"1703\":1},\"1\":{\"1761\":1}}],[\"代码示例\",{\"0\":{\"213\":1,\"266\":1,\"820\":1,\"840\":1,\"843\":1,\"1817\":1,\"1831\":1,\"1928\":1,\"1936\":1,\"1984\":1,\"2284\":1,\"2417\":1,\"2433\":1},\"2\":{\"11\":1,\"480\":1,\"647\":1,\"1984\":1}}],[\"使系统更加灵活和可扩展\",{\"2\":{\"2523\":1}}],[\"使系统能够正确地理解用户查询\",{\"2\":{\"1376\":1}}],[\"使之与\",{\"2\":{\"2129\":1}}],[\"使排在前面的\",{\"2\":{\"2087\":1}}],[\"使\",{\"2\":{\"1684\":1}}],[\"使快速的微调和高效的任务切换成为可能\",{\"2\":{\"1588\":1}}],[\"使评估更具现实意义\",{\"2\":{\"1453\":1}}],[\"使每个部分能够专注于特定的任务\",{\"2\":{\"1073\":1}}],[\"使模型逐渐适应不同的语言表征\",{\"2\":{\"933\":1}}],[\"使模型更易于理解其关注模式\",{\"2\":{\"1543\":1}}],[\"使模型更关注长程依赖\",{\"2\":{\"502\":1}}],[\"使模型更好地处理超长上下文场景\",{\"2\":{\"159\":1}}],[\"使模型更容易找到合适的参数空间\",{\"2\":{\"150\":1}}],[\"使语义相近的词在向量空间中也相邻\",{\"2\":{\"870\":1}}],[\"使样本满足独立假设\",{\"2\":{\"712\":1}}],[\"使yarn在不同任务中更具适应性\",{\"2\":{\"372\":1}}],[\"使负输入也能产生非零梯度\",{\"2\":{\"261\":1}}],[\"使sparse\",{\"2\":{\"233\":1}}],[\"使其具备更高程度的\",{\"2\":{\"1847\":1}}],[\"使其具备较高的精度和性能\",{\"2\":{\"954\":1}}],[\"使其支持更长句子的外推能力\",{\"2\":{\"1555\":1}}],[\"使其支持概率分词\",{\"2\":{\"631\":1}}],[\"使其既能保留绝对位置信息\",{\"2\":{\"1481\":1}}],[\"使其更适合应用需求\",{\"2\":{\"1578\":1}}],[\"使其更加贴合用户需求\",{\"2\":{\"1510\":1}}],[\"使其更加有序和易于检索\",{\"2\":{\"1421\":1}}],[\"使其更高效且不损失性能\",{\"2\":{\"702\":1}}],[\"使其能够更高效地完成复杂任务\",{\"2\":{\"1569\":1}}],[\"使其能够更灵活地处理超长上下文场景\",{\"2\":{\"412\":1}}],[\"使其能够与用户进行对话\",{\"2\":{\"1184\":1}}],[\"使其达到较高的性能\",{\"2\":{\"795\":1}}],[\"使其在特定任务中表现更好\",{\"2\":{\"2647\":1}}],[\"使其在多个方面全面优于\",{\"2\":{\"2603\":1}}],[\"使其在固定数据分布下最小化损失函数的期望\",{\"2\":{\"655\":1}}],[\"使其在保证信息完整性的同时降低计算成本\",{\"2\":{\"217\":1}}],[\"使其适应更复杂的上下文场景\",{\"2\":{\"1447\":1}}],[\"使其适应不同场景\",{\"2\":{\"771\":1}}],[\"使其适应不同上下文长度\",{\"2\":{\"466\":1}}],[\"使其适配更加复杂的上下文场景\",{\"2\":{\"300\":1}}],[\"使其对未训练范围的数据具有更强的泛化能力\",{\"2\":{\"337\":1}}],[\"使其与内插一致\",{\"2\":{\"221\":1}}],[\"使预测更准确\",{\"2\":{\"185\":1}}],[\"使得训练过程更加稳定\",{\"2\":{\"2575\":1,\"2644\":1}}],[\"使得权重和关联的优化器状态不需要同时存储在一个gpu上\",{\"2\":{\"2503\":1}}],[\"使得开发者能够轻松地构建分布式应用程序\",{\"2\":{\"2433\":1}}],[\"使得策略更新时保持一致性\",{\"2\":{\"2396\":1}}],[\"使得生成的数据更具多样性和精准性\",{\"2\":{\"2321\":1}}],[\"使得生成结果更加实时和可靠\",{\"2\":{\"1664\":1}}],[\"使得当前策略更新每个token的条件输出概率时\",{\"2\":{\"2306\":1}}],[\"使得系统能够更全面地考虑文档内容\",{\"2\":{\"2304\":1}}],[\"使得智能体能够更好地应对复杂的任务\",{\"2\":{\"2269\":1}}],[\"使得大型模型的微调在单gpu上成为可能\",{\"2\":{\"1964\":1}}],[\"使得大语言模型\",{\"2\":{\"1355\":1}}],[\"使得llm用自然语言生成整体推理过程\",{\"2\":{\"1608\":1}}],[\"使得llm能够与环境交互\",{\"2\":{\"1608\":1}}],[\"使得每一步都可以由\",{\"2\":{\"1595\":1}}],[\"使得每个节点都持有相同的汇总数据\",{\"2\":{\"2452\":1}}],[\"使得每个簇内的数据点具有较高的相似性\",{\"2\":{\"1467\":1}}],[\"使得每个\",{\"2\":{\"813\":1}}],[\"使得相似的样本彼此接近\",{\"2\":{\"1566\":1}}],[\"使得新的token\",{\"2\":{\"1522\":1}}],[\"使得簇内点到中心的距离总和最小化\",{\"2\":{\"1467\":1}}],[\"使得在面对海量知识向量时\",{\"2\":{\"2237\":1}}],[\"使得在资源受限的环境中部署大规模语言模型成为可能\",{\"2\":{\"1448\":1}}],[\"使得在复杂环境中更容易找到最优策略\",{\"2\":{\"891\":1}}],[\"使得分块计算需要的内存不超过sram的大小\",{\"2\":{\"1810\":1}}],[\"使得分块后的内容更加贴近原文的逻辑\",{\"2\":{\"1379\":1}}],[\"使得分类器可以处理非数值型数据\",{\"2\":{\"943\":1}}],[\"使得众包人员更好地理解任务\",{\"2\":{\"1368\":1}}],[\"使得距离计算更加合理\",{\"2\":{\"1068\":1}}],[\"使得可以从\",{\"2\":{\"1050\":1}}],[\"使得量化导致的损失更低\",{\"2\":{\"868\":1}}],[\"使得采样分布更接近正态分布\",{\"2\":{\"473\":1}}],[\"使得更大规模的模型可以在有限硬件上运行\",{\"2\":{\"462\":1}}],[\"使得合并后能最大程度提高语料的概率\",{\"2\":{\"381\":1}}],[\"使得模型能够在复杂任务中保持稳定的学习过程\",{\"2\":{\"2213\":1}}],[\"使得模型能够更好地理解复杂问题的解决路径\",{\"2\":{\"1940\":1}}],[\"使得模型能够更加高效地捕捉相对位置关系\",{\"2\":{\"1108\":1}}],[\"使得模型在训练过程中能够\",{\"2\":{\"1355\":1}}],[\"使得模型既能高效编码\",{\"2\":{\"366\":1}}],[\"使得模型可以根据输入范围自动调整编码方式\",{\"2\":{\"337\":1}}],[\"使得模型的预测误差最小\",{\"2\":{\"123\":1}}],[\"使得模型的预测结果尽可能接近真实标签\",{\"2\":{\"123\":1}}],[\"使得嵌入更具鲁棒性\",{\"2\":{\"184\":1}}],[\"使得后续生成过程可以直接复用之前的计算结果\",{\"2\":{\"107\":1}}],[\"使得预测值与真实值之间的差距\",{\"2\":{\"32\":1}}],[\"使用开发框架搭建\",{\"0\":{\"2702\":1}}],[\"使用一种软惩罚机制对过长回答进行处理\",{\"2\":{\"2692\":1}}],[\"使用一块\",{\"2\":{\"2313\":1}}],[\"使用大规模数据集进行基础模型训练\",{\"2\":{\"2652\":1}}],[\"使用大量数据和参数进行预训练\",{\"2\":{\"1203\":1}}],[\"使用训练集中说明性文本的专家内容计划\",{\"2\":{\"2608\":1}}],[\"使用概括性的主题作为查询\",{\"2\":{\"2570\":1}}],[\"使用语言一致性奖励提升多语言环境下的推理能力\",{\"2\":{\"2527\":1}}],[\"使用问题重写\",{\"2\":{\"2484\":1}}],[\"使用贪心解码产生的响应奖励值作为基线值来降低方差\",{\"2\":{\"2462\":1,\"2481\":1}}],[\"使用causal\",{\"2\":{\"2442\":1}}],[\"使用create\",{\"2\":{\"1832\":1}}],[\"使用update\",{\"2\":{\"2425\":1}}],[\"使用unicode编码字符\",{\"2\":{\"426\":1}}],[\"使用unigram语言模型训练子词概率\",{\"2\":{\"381\":1}}],[\"使用unigram语言模型\",{\"0\":{\"298\":1},\"1\":{\"320\":1,\"343\":1,\"367\":1,\"393\":1,\"419\":1,\"444\":1,\"471\":1,\"498\":1,\"530\":1,\"563\":1},\"2\":{\"5\":1,\"393\":1}}],[\"使用强大模型生成答案并进行模型训练\",{\"2\":{\"2375\":1}}],[\"使用强化学习\",{\"2\":{\"1222\":1}}],[\"使用启发式规则收集和改写数据\",{\"2\":{\"2375\":1}}],[\"使用奖励模型对采样输出进行奖励值评估\",{\"2\":{\"2306\":1,\"2337\":1}}],[\"使用价值模型进行细粒度策略优化是提升复杂任务表现的关键\",{\"2\":{\"2274\":1}}],[\"使用价值模型初始化\",{\"2\":{\"2200\":1}}],[\"使用参考公式评估激活值对显存的影响\",{\"2\":{\"2266\":1}}],[\"使用参数量\",{\"2\":{\"2090\":1}}],[\"使用适当的技术存储和清洗数据\",{\"2\":{\"2255\":1}}],[\"使用以下命令启动sft训练\",{\"2\":{\"2233\":1}}],[\"使用nvidia\",{\"2\":{\"2212\":1,\"2284\":1}}],[\"使用next\",{\"2\":{\"449\":1}}],[\"使用效果好的模型如\",{\"2\":{\"2210\":1}}],[\"使用分块技术进行计算任务分割\",{\"2\":{\"2160\":1}}],[\"使用分类器对文档进行类别判断\",{\"2\":{\"474\":1}}],[\"使用第一个分割符\",{\"2\":{\"2141\":1}}],[\"使用多卡并行设计新的参数\",{\"2\":{\"2125\":1}}],[\"使用多种benchmark可以全面评估模型的各方面能力\",{\"2\":{\"722\":1}}],[\"使用轨迹的总回报进行初步估计\",{\"2\":{\"2096\":1,\"2147\":1}}],[\"使用频率最高的方法\",{\"2\":{\"2073\":1}}],[\"使用户能够更轻松地利用大规模计算资源并加速模型训练过程\",{\"2\":{\"2055\":1}}],[\"使用直接偏好优化\",{\"2\":{\"1976\":1}}],[\"使用方法\",{\"0\":{\"1951\":1}}],[\"使用少量提示\",{\"2\":{\"1924\":1}}],[\"使用双重量化技术以进一步降低内存需求\",{\"2\":{\"1855\":1}}],[\"使用示例\",{\"0\":{\"1823\":1,\"1837\":1}}],[\"使用人类反馈作为奖励函数是一种创新\",{\"2\":{\"1801\":1}}],[\"使用较多\",{\"2\":{\"2217\":1}}],[\"使用较少的比特来存储浮点数\",{\"2\":{\"1793\":1}}],[\"使用较大的学习率\",{\"2\":{\"1436\":1}}],[\"使用门控机制进一步稳定微调过程\",{\"2\":{\"1779\":1}}],[\"使用加权平均算法计算了每项子能力的得分\",{\"2\":{\"1759\":1}}],[\"使用最后一个token的值作为整个响应的奖励\",{\"2\":{\"1744\":1}}],[\"使用裁剪操作来稳定values的计算\",{\"2\":{\"1699\":1}}],[\"使用无监督算法为缩写词\",{\"2\":{\"1665\":1}}],[\"使用偏好数据训练奖励函数\",{\"2\":{\"1642\":1}}],[\"使用与生成回答相同的llm对回答中的潜在错误进行评估和批判\",{\"2\":{\"1619\":1}}],[\"使用交叉熵损失函数进行优化\",{\"2\":{\"1586\":1}}],[\"使用情况等\",{\"2\":{\"1451\":1}}],[\"使用高质量数据\",{\"2\":{\"1436\":1}}],[\"使用高质量公共领域文学作品开发指令\",{\"2\":{\"1181\":1}}],[\"使用自然语言完整地呈现一个独立的概念或事实\",{\"2\":{\"1412\":1}}],[\"使用自我评价而非外部模型或手动注释来选择数据\",{\"2\":{\"1008\":1}}],[\"使用可训练向量\",{\"2\":{\"1405\":1}}],[\"使用这些框架时的注意事项\",{\"0\":{\"1392\":1}}],[\"使用不合适的提示长度可能导致性能下降\",{\"2\":{\"1965\":1}}],[\"使用不当的权重初始化方法可能导致模型收敛缓慢或不稳定\",{\"2\":{\"1345\":1}}],[\"使用不同的预训练目标的混合方法\",{\"2\":{\"1102\":1}}],[\"使用不同任务场景验证模型性能\",{\"2\":{\"560\":1}}],[\"使用幂律公式拟合最优点\",{\"2\":{\"1329\":1}}],[\"使用flashattention2生成首token的时间与输入prompt的长度近似成线性关系\",{\"2\":{\"1910\":1}}],[\"使用flash\",{\"2\":{\"1304\":1}}],[\"使用fasttext分类器提取\",{\"2\":{\"1138\":1}}],[\"使用fasttext或langid工具进行语言检测\",{\"2\":{\"515\":1}}],[\"使用前11层encoder处理输入数据\",{\"2\":{\"1288\":1}}],[\"使用成功率作为主要评估指标\",{\"2\":{\"1268\":1}}],[\"使用预训练模型时\",{\"2\":{\"1262\":1}}],[\"使用预先收集的偏好数据集进行dpo训练\",{\"2\":{\"1230\":1}}],[\"使用adafactor优化器\",{\"2\":{\"1298\":1}}],[\"使用adafactor优化器进行训练\",{\"2\":{\"1248\":1}}],[\"使用adamw优化器\",{\"2\":{\"1162\":1,\"1204\":1}}],[\"使用adam优化器\",{\"2\":{\"820\":1}}],[\"使用冷启动数据解决语言混合问题\",{\"2\":{\"1245\":1}}],[\"使用随机高斯初始化\",{\"2\":{\"2062\":1}}],[\"使用随机路由策略选择第二个专家\",{\"2\":{\"1219\":1}}],[\"使用随机替换和保持不变的方法提高了模型的泛化能力\",{\"2\":{\"1126\":1}}],[\"使用grpo进行强化学习\",{\"2\":{\"1240\":1}}],[\"使用gate确定每个token的去向\",{\"2\":{\"1219\":1}}],[\"使用gelu激活函数\",{\"2\":{\"199\":1}}],[\"使用100台a800显卡训练一个月\",{\"2\":{\"1232\":1}}],[\"使用1024块v100\",{\"2\":{\"1012\":1,\"1145\":1}}],[\"使用18t\",{\"2\":{\"1205\":1}}],[\"使用特殊标记符可以有效提升模型理解复杂语境的能力\",{\"2\":{\"1391\":1}}],[\"使用特殊标记符分割角色和语义\",{\"2\":{\"1299\":1}}],[\"使用特殊标记符来构造语义\",{\"2\":{\"1199\":1}}],[\"使用特殊标记符构造知识\",{\"2\":{\"1150\":1}}],[\"使用并行化结构以提升计算效率\",{\"2\":{\"1198\":1}}],[\"使用并行语料库\",{\"2\":{\"39\":1}}],[\"使用动态掩码策略以适应不同语言表征\",{\"2\":{\"1145\":1}}],[\"使用ppo算法更新actor模型\",{\"2\":{\"1677\":1}}],[\"使用ppo优化策略\",{\"2\":{\"1642\":1}}],[\"使用prefix\",{\"2\":{\"1137\":1}}],[\"使用pytorch进行nlp深度学习\",{\"2\":{\"544\":1}}],[\"使用python进行自然语言处理\",{\"2\":{\"67\":1}}],[\"使用deepseek\",{\"2\":{\"1134\":1}}],[\"使用qwen模型过滤低质量数据\",{\"2\":{\"1130\":1}}],[\"使用线形层gate判断token应该送去哪个expert\",{\"2\":{\"1119\":1}}],[\"使用统一的t5模型进行文本到文本转换\",{\"2\":{\"1107\":1}}],[\"使用统一比例\",{\"2\":{\"312\":1}}],[\"使用对比学习的方法\",{\"2\":{\"1075\":1}}],[\"使用纯粹rl增强大模型推理能力\",{\"2\":{\"1053\":1}}],[\"使用哈希存储减少内存占用\",{\"2\":{\"1021\":1}}],[\"使用单层线性层进行token预测\",{\"2\":{\"961\":1}}],[\"使用单向注意力机制\",{\"2\":{\"294\":1}}],[\"使用更节省显存的api替换默认操作\",{\"2\":{\"2073\":1}}],[\"使用更大且无预处理的bpe词汇表\",{\"2\":{\"1145\":1}}],[\"使用更大的byte\",{\"2\":{\"933\":1}}],[\"使用更高的进制以保持输入维度不变\",{\"2\":{\"246\":1}}],[\"使用了分块技术\",{\"2\":{\"1957\":1}}],[\"使用了1\",{\"2\":{\"1211\":1}}],[\"使用了160gb的纯文本数据集\",{\"2\":{\"933\":1}}],[\"使用了\",{\"2\":{\"925\":1}}],[\"使用了rmsnorm\",{\"2\":{\"894\":1}}],[\"使用教师模型中两层\",{\"2\":{\"880\":1}}],[\"使用状态或动作价值函数评估策略\",{\"2\":{\"844\":1}}],[\"使用贝尔曼方程迭代更新价值函数\",{\"2\":{\"831\":1}}],[\"使用rnn编码伪标记\",{\"2\":{\"2069\":1}}],[\"使用replay\",{\"2\":{\"808\":1}}],[\"使用rope\",{\"2\":{\"502\":1}}],[\"使用策略\",{\"2\":{\"778\":1}}],[\"使用mdp模型分析nlp任务中的prompt\",{\"2\":{\"2058\":1}}],[\"使用mlp+lstm对prompt\",{\"2\":{\"1858\":1}}],[\"使用mc方法时\",{\"2\":{\"689\":1}}],[\"使用minicpm提出的wsd\",{\"2\":{\"593\":1}}],[\"使用蒙特卡洛估计后续回报\",{\"2\":{\"2462\":1,\"2481\":1}}],[\"使用蒙特卡洛估计\",{\"2\":{\"654\":1}}],[\"使用整个轨迹的总回报来指导策略更新\",{\"2\":{\"654\":1}}],[\"使用ocr工具提取标题区块文字\",{\"2\":{\"2235\":1}}],[\"使用openrlhf进行sft训练的启动脚本示例展示了如何设置训练参数\",{\"2\":{\"2194\":1}}],[\"使用opencompass进行benchmark评估\",{\"2\":{\"651\":1}}],[\"使用oauth2等标准化认证流程\",{\"2\":{\"198\":1}}],[\"使用token\",{\"2\":{\"1791\":1}}],[\"使用tokenizers库对多语言文本进行标准化和预分词\",{\"2\":{\"645\":1}}],[\"使用td\",{\"2\":{\"1699\":1}}],[\"使用trafilatura抓取网页内容\",{\"2\":{\"485\":1}}],[\"使用专业pdf解析服务\",{\"2\":{\"568\":1}}],[\"使用专业的pdf解析服务\",{\"2\":{\"465\":1}}],[\"使用损失缩放技术\",{\"2\":{\"556\":1}}],[\"使用具体分词算法\",{\"2\":{\"542\":1}}],[\"使用kl散度作为惩罚项可以有效控制模型偏离预训练策略的程度\",{\"2\":{\"537\":1}}],[\"使用kv\",{\"0\":{\"187\":1},\"2\":{\"208\":1}}],[\"使用jieba分词工具对种子文本进行关键词挖掘\",{\"2\":{\"532\":1}}],[\"使用bpe\",{\"2\":{\"1302\":1}}],[\"使用bpe算法进行分词\",{\"2\":{\"1112\":1}}],[\"使用bpe或字符级初始化构建大规模初始词表\",{\"2\":{\"530\":1}}],[\"使用base模型进行文本续写并计算相似度\",{\"2\":{\"800\":1}}],[\"使用base模型续写文本\",{\"2\":{\"699\":1}}],[\"使用byte\",{\"0\":{\"274\":1},\"1\":{\"297\":1,\"319\":1,\"342\":1,\"366\":1,\"392\":1,\"418\":1,\"443\":1,\"470\":1,\"497\":1,\"529\":1,\"562\":1,\"597\":1,\"631\":1},\"2\":{\"5\":1}}],[\"使用百科\",{\"2\":{\"516\":1}}],[\"使用8bit权重则需7\",{\"2\":{\"483\":1}}],[\"使用缩放后的损失计算梯度\",{\"2\":{\"435\":1}}],[\"使用svd进行奇异值裁剪\",{\"2\":{\"1938\":1}}],[\"使用softmax函数对非零缩放值进行归一化处理\",{\"2\":{\"1809\":1}}],[\"使用swiglu激活函数和并行层设计显著提高了模型的训练效率和稳定性\",{\"2\":{\"1198\":1}}],[\"使用swish激活函数\",{\"2\":{\"199\":1}}],[\"使用sparse\",{\"2\":{\"1179\":1}}],[\"使用skip\",{\"2\":{\"1111\":1}}],[\"使用sigmoid函数简化计算\",{\"2\":{\"983\":1}}],[\"使用simbert对数据进行向量化处理\",{\"2\":{\"421\":1}}],[\"使用位置内插法可以有效扩展语言模型的上下文窗口\",{\"2\":{\"336\":1}}],[\"使用未见过的位置索引会导致注意力分数异常高\",{\"2\":{\"313\":1}}],[\"使用公式表示奇异值与秩关系\",{\"2\":{\"2142\":1}}],[\"使用公式估算flops预算\",{\"2\":{\"1374\":1}}],[\"使用公式\",{\"2\":{\"291\":1,\"2263\":1}}],[\"使用低精度数据替换高精度数据\",{\"2\":{\"2073\":1,\"2125\":1}}],[\"使用低秩kv压缩\",{\"2\":{\"212\":1}}],[\"使用低学习率\",{\"2\":{\"40\":1}}],[\"使用模型进行自动标注可能无法得到满意的结果\",{\"2\":{\"2642\":1}}],[\"使用模型蒸馏技术\",{\"2\":{\"57\":1}}],[\"使用模板\",{\"2\":{\"15\":1}}],[\"使用场景对比总结\",{\"2\":{\"39\":1}}],[\"使用历史数据预测未来的趋势或值\",{\"2\":{\"39\":1}}],[\"使用\",{\"0\":{\"2124\":1},\"2\":{\"10\":1,\"27\":3,\"49\":3,\"435\":1,\"503\":1,\"591\":1,\"634\":1,\"889\":1,\"1006\":1,\"1092\":1,\"1112\":1,\"1268\":1,\"1348\":1,\"2002\":1,\"2252\":1,\"2319\":1,\"2606\":1,\"2608\":1,\"2641\":1}}],[\"使用命名空间可以将这些函数放在不同的命名空间下\",{\"2\":{\"10\":1}}],[\"滑动窗口注意力机制不仅优化了缓存\",{\"2\":{\"2460\":1}}],[\"滑动窗口注意力机制旨在减少kv缓存的存储压力\",{\"2\":{\"2326\":1}}],[\"滑动窗口注意力机制\",{\"0\":{\"2326\":1}}],[\"滑动窗口注意力机制通过限制每个token只与其前面固定数量的token进行注意力计算\",{\"2\":{\"2260\":1}}],[\"滑动窗口\",{\"2\":{\"30\":1,\"2225\":1}}],[\"并尽可能帮助提问者解决问题\",{\"2\":{\"2690\":1}}],[\"并保存每个分块之间的上下级关系\",{\"2\":{\"2625\":1}}],[\"并保持无损压缩\",{\"2\":{\"318\":1}}],[\"并保持命名空间清晰\",{\"2\":{\"27\":1}}],[\"并打印调试信息\",{\"2\":{\"2618\":1}}],[\"并允许更大规模的模型在有限硬件资源下进行训练\",{\"2\":{\"2537\":1}}],[\"并选择更为可信的信息\",{\"2\":{\"2506\":1}}],[\"并选择合适的数据集\",{\"2\":{\"2200\":1}}],[\"并选择合适的模型和数据规模平衡策略\",{\"2\":{\"1374\":1}}],[\"并配置放缩因子\",{\"2\":{\"2425\":1}}],[\"并使我们能够比以往更快地进行大规模迭代\",{\"2\":{\"2408\":1}}],[\"并使用奖励模型对这些回答给予奖励值\",{\"2\":{\"2273\":1}}],[\"并使用强化学习\",{\"2\":{\"1491\":1}}],[\"并使用近似稀疏回归求解器来解决\",{\"2\":{\"1050\":1}}],[\"并使用二维位置编码技术来增强模型的性能\",{\"2\":{\"923\":1}}],[\"并增加通信成本\",{\"2\":{\"2402\":1}}],[\"并增加线性层以输出标量奖励值\",{\"2\":{\"1631\":1}}],[\"并思考哪些部分需要修改\",{\"2\":{\"2363\":1}}],[\"并决定块之间是否需要重叠内容\",{\"2\":{\"2560\":1}}],[\"并决定是否需要进一步搜索\",{\"2\":{\"2294\":1}}],[\"并决定如何推进推理\",{\"2\":{\"2227\":1}}],[\"并应用于每个token\",{\"2\":{\"2273\":1,\"2337\":1}}],[\"并应用yarn和dca技术以扩展处理能力\",{\"2\":{\"1256\":1}}],[\"并针对性地进行优化\",{\"2\":{\"2263\":1}}],[\"并针对不同类型的输入构建更为专门化的提示\",{\"2\":{\"1935\":1}}],[\"并评估其潜在奖励\",{\"2\":{\"2171\":1}}],[\"并进行适当改写\",{\"2\":{\"2168\":1}}],[\"并进行了以下改动\",{\"2\":{\"1198\":1}}],[\"并进行了多项改进以提升模型性能和训练稳定性\",{\"2\":{\"1149\":1}}],[\"并进行了若干调整\",{\"2\":{\"932\":1}}],[\"并进行了人类偏好对齐训练\",{\"2\":{\"925\":1}}],[\"并详细阐述了sft评估的原则和方法\",{\"2\":{\"2151\":1}}],[\"并详细说明了google提出的改进以及xlnet中的位置编码策略\",{\"2\":{\"1166\":1}}],[\"并对其中的基线计算进行了修改\",{\"2\":{\"2388\":1,\"2416\":1}}],[\"并对\",{\"2\":{\"2129\":1}}],[\"并对合成数据进行了严格过滤和奖励机制评估\",{\"2\":{\"1205\":1}}],[\"并自发探索解决问题的替代方法\",{\"2\":{\"2122\":1}}],[\"并返回近似的前\",{\"2\":{\"2102\":1}}],[\"并缓存其对应的key和value值\",{\"2\":{\"2064\":1}}],[\"并非所有嵌入模型都支持所有度量方法\",{\"2\":{\"2051\":1}}],[\"并非所有任务都适合稀疏或线性attention\",{\"2\":{\"210\":1}}],[\"并能够持续\",{\"2\":{\"1998\":1}}],[\"并能更直接影响模型预测\",{\"2\":{\"1680\":1}}],[\"并解耦拼接向量的softmax计算\",{\"2\":{\"1980\":1}}],[\"并共享预训练语言模型的核心参数\",{\"2\":{\"1930\":1}}],[\"并介绍了如何通过优势函数指导策略更新\",{\"2\":{\"1887\":1,\"1943\":1}}],[\"并从每个思维链中提取答案\",{\"2\":{\"2042\":1}}],[\"并从思维链中提取最终答案\",{\"2\":{\"1885\":1}}],[\"并从中检索出相关的文本向量\",{\"2\":{\"1377\":1}}],[\"并固定大部分预训练参数\",{\"2\":{\"1875\":1}}],[\"并动态调整策略\",{\"2\":{\"1847\":1}}],[\"并生成第1个token的过程\",{\"2\":{\"1782\":1}}],[\"并减少性能损失\",{\"2\":{\"1668\":1}}],[\"并仅在微调时训练两个向量d和b\",{\"2\":{\"1636\":1}}],[\"并仅预测被掩码的部分词\",{\"2\":{\"1062\":1}}],[\"并根据生成结果的优劣进行评分\",{\"2\":{\"1614\":1}}],[\"并努力减少输出值的重复\",{\"2\":{\"1559\":1}}],[\"并指出了现有方法中存在的挑战\",{\"2\":{\"1495\":1}}],[\"并重点突出核心内容\",{\"2\":{\"2582\":1}}],[\"并重新生成句子\",{\"2\":{\"2570\":1}}],[\"并重新微调\",{\"2\":{\"1281\":1}}],[\"并重复上述步骤\",{\"2\":{\"1470\":1}}],[\"并设置合适的\",{\"2\":{\"1450\":1}}],[\"并与\",{\"2\":{\"1412\":1}}],[\"并与其他扩展方法\",{\"2\":{\"360\":1}}],[\"并撰写总结报告\",{\"2\":{\"1381\":1}}],[\"并提高模型的推理效率\",{\"2\":{\"2356\":1}}],[\"并提高了模型的适应能力\",{\"2\":{\"1824\":1}}],[\"并提供一个较好的初始策略\",{\"2\":{\"2474\":1}}],[\"并提供改进建议\",{\"2\":{\"2294\":1}}],[\"并提供相关代码示例\",{\"2\":{\"1620\":1}}],[\"并提供关键流程的编号列表\",{\"2\":{\"1365\":1}}],[\"并提前规划\",{\"2\":{\"1375\":1}}],[\"并提升模型的推理性能\",{\"2\":{\"692\":1}}],[\"并不能全面地评估生成内容的质量\",{\"2\":{\"1309\":1}}],[\"并优先选择megatron\",{\"2\":{\"1265\":1}}],[\"并将一个batch切分成多个mini\",{\"2\":{\"2691\":1}}],[\"并将每组放置在不同的设备上进行计算的方法\",{\"2\":{\"2685\":1}}],[\"并将检索到的文档加入\",{\"2\":{\"2578\":1}}],[\"并将结果返回给用户\",{\"2\":{\"2272\":1}}],[\"并将最终分析结果整合成一份完整报告\",{\"2\":{\"2185\":1}}],[\"并将这些回答组合为最终答案\",{\"2\":{\"2546\":1}}],[\"并将这些子任务分配给多个\",{\"2\":{\"2089\":1}}],[\"并将这些切分结果转化为模型可理解的token\",{\"2\":{\"1253\":1}}],[\"并将它们的输出加权结合\",{\"2\":{\"1704\":1}}],[\"并将其叠加到准确率奖励上\",{\"2\":{\"2689\":1}}],[\"并将其加入输出\",{\"2\":{\"2601\":1}}],[\"并将其输入到大语言模型中\",{\"2\":{\"2305\":1}}],[\"并将其分配到专门的后续任务中\",{\"2\":{\"1935\":1}}],[\"并将其与原始问题一起用于检索\",{\"2\":{\"1774\":1}}],[\"并将其与原始llama词表合并\",{\"2\":{\"1442\":1}}],[\"并将其合并为新的子词\",{\"2\":{\"392\":1}}],[\"并额外添加辅助损失以提高softmax标准化的稳定性\",{\"2\":{\"1248\":1}}],[\"并基于马尔可夫决策过程\",{\"2\":{\"1222\":1}}],[\"并采用余弦学习率计划\",{\"2\":{\"1204\":1}}],[\"并采用top2expert策略来确保计算效率\",{\"2\":{\"1072\":1}}],[\"并去掉了dense层和layer\",{\"2\":{\"1198\":1}}],[\"并行策略挑战\",{\"0\":{\"2344\":1}}],[\"并行策略等相关\",{\"2\":{\"2231\":1}}],[\"并行\",{\"2\":{\"2167\":1}}],[\"并行方式进行的训练\",{\"2\":{\"2129\":1}}],[\"并行推理\",{\"2\":{\"2115\":1}}],[\"并行加速方案\",{\"2\":{\"2081\":1}}],[\"并行算法\",{\"2\":{\"2081\":2}}],[\"并行技术\",{\"2\":{\"2081\":1}}],[\"并行化非常有效\",{\"2\":{\"2037\":1}}],[\"并行化有两个主要变体\",{\"2\":{\"2037\":1}}],[\"并行化工作流允许\",{\"2\":{\"2037\":1}}],[\"并行化\",{\"0\":{\"1985\":1},\"1\":{\"2037\":1},\"2\":{\"2139\":1}}],[\"并行处理高效\",{\"2\":{\"1373\":1}}],[\"并行训练主要涉及以下几个技术\",{\"2\":{\"2132\":1}}],[\"并行训练\",{\"2\":{\"1272\":1}}],[\"并行训练机制\",{\"2\":{\"502\":1}}],[\"并行层设计\",{\"2\":{\"1198\":1}}],[\"并展现出一定程度的自主性\",{\"2\":{\"1184\":1}}],[\"并关注距离较近的上下文\",{\"2\":{\"1179\":1}}],[\"并为模型进一步训练提供了优质样本\",{\"2\":{\"1164\":1}}],[\"并探讨其核心代码实现\",{\"2\":{\"2311\":1}}],[\"并探讨它们各自的特点和优势\",{\"2\":{\"2320\":1}}],[\"并探讨它们的适用场景与示例\",{\"2\":{\"2089\":1}}],[\"并探讨它们在transformer的编码器\",{\"2\":{\"93\":1}}],[\"并探讨中文预训练的独特挑战与解决方案\",{\"2\":{\"1153\":1}}],[\"并简化gating为只选择一个expert\",{\"2\":{\"1129\":1}}],[\"并由sentencepiece实现\",{\"2\":{\"1112\":1}}],[\"并引入了一些全新的功能\",{\"2\":{\"2094\":1}}],[\"并引入\",{\"2\":{\"1108\":1}}],[\"并拥有更大的数据量和模型参数\",{\"2\":{\"1082\":1}}],[\"并用通俗语言解释技术术语\",{\"2\":{\"1067\":1}}],[\"并适用于不同的场景\",{\"2\":{\"896\":1}}],[\"并在qwen2\",{\"2\":{\"2686\":1}}],[\"并在回答复杂或多方面的查询时提供更精确的结果\",{\"2\":{\"2304\":1}}],[\"并在实践中应用这些知识\",{\"2\":{\"2175\":1}}],[\"并在环境中接收观察结果\",{\"2\":{\"2113\":1}}],[\"并在此基础上进一步探索了新的算法结构\",{\"2\":{\"1860\":1}}],[\"并在训练过程中仅微调一部分参数\",{\"2\":{\"1853\":1}}],[\"并在训练中不断更新\",{\"2\":{\"1281\":1}}],[\"并在推理阶段不再使用\",{\"2\":{\"1796\":1}}],[\"并在每层都加上prompt的参数以提高性能\",{\"2\":{\"1745\":1}}],[\"并在每个输出token处计算损失\",{\"2\":{\"1572\":1}}],[\"并在该桶内进行搜索即可\",{\"2\":{\"1559\":1}}],[\"并在后续步骤中不断完善\",{\"2\":{\"1557\":1}}],[\"并在不同层级中组织\",{\"2\":{\"1285\":1}}],[\"并在序列之间添加\",{\"2\":{\"1193\":1}}],[\"并在少样本学习范式下进行\",{\"2\":{\"1175\":1}}],[\"并在对话阶段采用\",{\"2\":{\"889\":1}}],[\"并在特定任务中进行微调\",{\"2\":{\"115\":1}}],[\"并逐步移除冗余权重\",{\"2\":{\"826\":1}}],[\"并成为强化学习领域的重要工具\",{\"2\":{\"784\":1}}],[\"并给出三种不同的回答\",{\"2\":{\"781\":1}}],[\"并给出参数名称\",{\"2\":{\"11\":1}}],[\"并实现了copy\",{\"2\":{\"750\":1}}],[\"并测试在文本分类任务中的效果\",{\"2\":{\"1647\":1}}],[\"并测试其在不同数据集上的性能表现\",{\"2\":{\"1493\":1}}],[\"并测试其在文本生成中的效果\",{\"2\":{\"739\":1}}],[\"并测试不同语料下的效果\",{\"2\":{\"522\":1}}],[\"并且会有更多自动化工具来简化参数调整过程\",{\"2\":{\"2407\":1}}],[\"并且无需更新模型\",{\"2\":{\"2188\":1}}],[\"并且这些离群值分布在少量的几个特征中\",{\"2\":{\"1982\":1}}],[\"并且可以更好地控制熵值\",{\"2\":{\"2598\":1,\"2658\":1}}],[\"并且可以通过prompt灵活调整解析需求\",{\"2\":{\"2103\":1}}],[\"并且可以通过多数投票进一步增强性能\",{\"2\":{\"1915\":1}}],[\"并且可能会与其他优化算法结合使用以提高效率\",{\"2\":{\"647\":1}}],[\"并且大部分都包含了微调过程\",{\"2\":{\"1569\":1}}],[\"并且不会增加训练时间\",{\"2\":{\"1260\":1}}],[\"并且强调指令遵循能力\",{\"2\":{\"1150\":1}}],[\"并且结合无监督目标函数\",{\"2\":{\"1142\":1}}],[\"并且包含48层\",{\"2\":{\"1059\":1}}],[\"并且在一些低精度运算较快的处理器上可以增加推理速度\",{\"2\":{\"733\":1}}],[\"并记录其对训练稳定性的影响\",{\"2\":{\"730\":1}}],[\"并记录性能变化\",{\"2\":{\"439\":1}}],[\"并尝试删除或修剪这些冗余和非关键的权重\",{\"2\":{\"729\":1}}],[\"并尝试整合到自己的项目中\",{\"2\":{\"669\":1}}],[\"并利用mlp和lstm对其进行处理\",{\"2\":{\"1738\":1}}],[\"并利用其产生per\",{\"2\":{\"1621\":1}}],[\"并利用奖励模型对这些答案进行评分\",{\"2\":{\"1164\":1}}],[\"并利用梯度上升方法最大化目标函数\",{\"2\":{\"723\":1}}],[\"并利用相似度指标评估续写质量\",{\"2\":{\"699\":1}}],[\"并发数设置过高\",{\"2\":{\"594\":1}}],[\"并发爬虫数量控制\",{\"2\":{\"526\":1}}],[\"并跳过更新\",{\"2\":{\"589\":1}}],[\"并更新权重\",{\"2\":{\"589\":1}}],[\"并计算惩罚值\",{\"2\":{\"2695\":1}}],[\"并计算一个奖励分数以反映其性能\",{\"2\":{\"2113\":1}}],[\"并计算梯度\",{\"2\":{\"589\":1}}],[\"并计算相关参数\",{\"2\":{\"359\":1}}],[\"并转为\",{\"2\":{\"553\":1}}],[\"并人工整理关键词表\",{\"2\":{\"532\":1}}],[\"并可通过行为约束优化目标来调整策略更新\",{\"2\":{\"514\":1}}],[\"并执行梯度裁剪操作\",{\"2\":{\"435\":1}}],[\"并调整波长相关参数\",{\"2\":{\"359\":1}}],[\"并结合这些信息生成最终回复\",{\"2\":{\"1569\":1}}],[\"并结合递归式分块策略\",{\"2\":{\"1334\":1}}],[\"并结合原始提问\",{\"2\":{\"1333\":1}}],[\"并结合$$\",{\"2\":{\"577\":1}}],[\"并结合实验验证其在特征提取中的作用\",{\"2\":{\"275\":1}}],[\"并结合ntk\",{\"2\":{\"184\":1}}],[\"并通过编码器构建向量索引\",{\"2\":{\"2420\":1}}],[\"并通过不断训练进行优化\",{\"2\":{\"2418\":1}}],[\"并通过不同阶段的训练提升其在中英文指令数据上的表现\",{\"2\":{\"960\":1}}],[\"并通过修改loss\",{\"2\":{\"2300\":1}}],[\"并通过残差连接获取最终输出\",{\"2\":{\"1822\":1}}],[\"并通过kernel融合优化了计算效率\",{\"2\":{\"1750\":1}}],[\"并通过多任务学习进行预训练\",{\"2\":{\"1736\":1}}],[\"并通过一个可训练的缩放头来动态调整每个lora模型的贡献\",{\"2\":{\"1692\":1}}],[\"并通过一个统一模型来解决\",{\"2\":{\"901\":1}}],[\"并通过行为约束来防止策略偏离\",{\"2\":{\"1515\":1}}],[\"并通过损失函数\",{\"2\":{\"1152\":1}}],[\"并通过辅助损失函数来保证负载均衡\",{\"2\":{\"1119\":1}}],[\"并通过渐进式训练适应不同长度的上下文\",{\"2\":{\"1061\":1}}],[\"并通过上下文预测这些被掩盖的单词\",{\"2\":{\"997\":1}}],[\"并通过对数似然损失优化\",{\"2\":{\"503\":1}}],[\"并通过在推理阶段提供相关的上下文信息来生成或调整模型输出\",{\"2\":{\"477\":1}}],[\"并通过维特比算法寻找最优分词结果\",{\"2\":{\"393\":1}}],[\"并通过代码示例展示了beam\",{\"2\":{\"253\":1}}],[\"并通过调整中间层维度来保持参数量的平衡\",{\"2\":{\"138\":1}}],[\"并完成attention\",{\"2\":{\"166\":1}}],[\"并分析其不同层级的实现方式\",{\"2\":{\"1617\":1}}],[\"并分析最优策略的定义及其应用\",{\"2\":{\"696\":1}}],[\"并分析了奖励机制的设计\",{\"2\":{\"1618\":1}}],[\"并分析了它们在词表生成策略和合并规则上的差异\",{\"2\":{\"368\":1}}],[\"并分析了它们的优缺点\",{\"2\":{\"202\":1}}],[\"并分析了其计算公式与特性\",{\"2\":{\"128\":1}}],[\"并分享了相关技术实现与注意事项\",{\"2\":{\"403\":1}}],[\"并分别在块内和块间应用注意力机制\",{\"2\":{\"86\":1}}],[\"可针对特定问题上下文替换或重组模块\",{\"2\":{\"2534\":1}}],[\"可针对性深入探讨\",{\"2\":{\"65\":1}}],[\"可用于训练的\",{\"2\":{\"2402\":1}}],[\"可是这里\",{\"2\":{\"2379\":1}}],[\"可读性低\",{\"2\":{\"2315\":1}}],[\"可调模板\",{\"2\":{\"2254\":1}}],[\"可调节的模板参数\",{\"2\":{\"2032\":1}}],[\"可估算值\",{\"2\":{\"2123\":1}}],[\"可选择在本地部署模型如\",{\"2\":{\"2210\":1}}],[\"可选择字粒度或词粒度的n\",{\"2\":{\"1021\":1}}],[\"可选的基座模型\",{\"0\":{\"1999\":1}}],[\"可否结合动态调整策略\",{\"2\":{\"1447\":1}}],[\"可否结合动态学习机制\",{\"2\":{\"356\":1}}],[\"可节省时间\",{\"2\":{\"1389\":1}}],[\"可训练向量维度\",{\"2\":{\"1499\":1}}],[\"可训练向量\",{\"2\":{\"1359\":1}}],[\"可视化低代码平台是一个非常友好的选择\",{\"2\":{\"1347\":1}}],[\"可视化低代码平台\",{\"0\":{\"1347\":1}}],[\"可扩展至其他任务\",{\"2\":{\"1259\":1}}],[\"可扩展到图像处理领域\",{\"2\":{\"326\":1}}],[\"可通过训练优化\",{\"2\":{\"918\":1}}],[\"可学习参数矩阵\",{\"2\":{\"918\":1}}],[\"可学习的位置编码是否会引入额外的过拟合风险\",{\"2\":{\"1481\":1}}],[\"可学习的偏移参数\",{\"2\":{\"190\":1}}],[\"可学习的缩放参数\",{\"2\":{\"190\":1}}],[\"可达到减少模型大小内存和占用空间\",{\"2\":{\"799\":1}}],[\"可有效缓解模型\",{\"2\":{\"533\":1}}],[\"可微分的融合方法\",{\"2\":{\"440\":1}}],[\"可进一步优化算法以减少计算复杂度\",{\"2\":{\"326\":1}}],[\"可能包含大量不相关的信息\",{\"2\":{\"2334\":1}}],[\"可能包含过多不相关的信息\",{\"2\":{\"2154\":1}}],[\"可能需要多轮搜索和分析\",{\"2\":{\"2294\":1}}],[\"可能需要对多个文件进行复杂且不同的改动\",{\"2\":{\"2185\":1}}],[\"可能需调整模型参数\",{\"2\":{\"292\":1}}],[\"可能原因是未知数据的比例过大\",{\"2\":{\"2170\":1}}],[\"可能在某些情况下提供更好的模型性能\",{\"2\":{\"1932\":1}}],[\"可能更容易找到答案\",{\"2\":{\"1774\":1}}],[\"可能是因为奖励模型被\",{\"2\":{\"1505\":1}}],[\"可能是负数或很大的数\",{\"2\":{\"90\":1}}],[\"可能引发调试困难和性能下降\",{\"2\":{\"1482\":1}}],[\"可能引发法律风险\",{\"2\":{\"582\":1}}],[\"可能成为性能瓶颈\",{\"2\":{\"1463\":1}}],[\"可能不利于深度定制\",{\"2\":{\"1347\":1}}],[\"可能不会导致命名冲突\",{\"2\":{\"27\":1}}],[\"可能存在以下几种索引\",{\"2\":{\"1285\":1}}],[\"可能出现基于深度学习的自动化质量评估工具\",{\"2\":{\"753\":1}}],[\"可能逐步成为主流工具\",{\"2\":{\"701\":1}}],[\"可能影响最终价值估计\",{\"2\":{\"689\":1}}],[\"可能影响模型收敛速度\",{\"2\":{\"657\":1}}],[\"可能会丢失部分上下文信息\",{\"2\":{\"2576\":1}}],[\"可能会影响训练收敛性或推理性能\",{\"2\":{\"2172\":1}}],[\"可能会导致更高的调用成本以及更差的响应效果\",{\"2\":{\"2154\":1}}],[\"可能会导致模型在处理时性能下降\",{\"2\":{\"1504\":1}}],[\"可能会忽视某些模型对策略稳定性的贡献\",{\"2\":{\"2106\":1}}],[\"可能会忽略特定任务对参数的特殊需求\",{\"2\":{\"1988\":1}}],[\"可能会忽略损失函数与参数规模之间的等比关系\",{\"2\":{\"1301\":1}}],[\"可能会忽略某些状态的转移路径\",{\"2\":{\"866\":1}}],[\"可能会打断句子或段落\",{\"2\":{\"1457\":1}}],[\"可能会遗漏重要的数据片段\",{\"2\":{\"1383\":1}}],[\"可能会出现生成质量不佳的候选响应\",{\"2\":{\"2127\":1}}],[\"可能会出现误差\",{\"2\":{\"1733\":1}}],[\"可能会出现训练集上的奖励\",{\"2\":{\"1460\":1}}],[\"可能会出现设备过载或通信阻塞的问题\",{\"2\":{\"1171\":1}}],[\"可能会出现更高效的多模态嵌入技术\",{\"2\":{\"1036\":1}}],[\"可能会结合更多先进技术如分布式训练和自适应采样策略\",{\"2\":{\"877\":1}}],[\"可能会与深度学习技术更紧密结合\",{\"2\":{\"791\":1}}],[\"可能会过于依赖即时奖励而忽略长期策略优化\",{\"2\":{\"673\":1}}],[\"可能会有上升趋势\",{\"2\":{\"558\":1}}],[\"可能错过全局最优解\",{\"2\":{\"562\":1}}],[\"可能有以下分词方式\",{\"2\":{\"444\":1}}],[\"可能产生不合理的子词切分\",{\"2\":{\"434\":1}}],[\"可能仅占总数据的0\",{\"2\":{\"369\":1}}],[\"可能丢失原始语义信息\",{\"2\":{\"309\":1}}],[\"可能无法充分利用长上下文特性\",{\"2\":{\"241\":1}}],[\"可能导致\",{\"2\":{\"2466\":1}}],[\"可能导致短对话数据训练不充分\",{\"2\":{\"2390\":1}}],[\"可能导致较大的误差\",{\"2\":{\"2249\":1}}],[\"可能导致估算值与实际测量值之间存在较大差距\",{\"2\":{\"2021\":1}}],[\"可能导致后续策略优化失败\",{\"2\":{\"1696\":1}}],[\"可能导致资源浪费或性能不足\",{\"2\":{\"1482\":1}}],[\"可能导致资源浪费\",{\"2\":{\"1329\":1}}],[\"可能导致过拟合\",{\"2\":{\"1079\":1}}],[\"可能导致语义信息丢失\",{\"2\":{\"1079\":1}}],[\"可能导致训练效果不佳\",{\"2\":{\"1778\":1}}],[\"可能导致训练速度慢\",{\"2\":{\"1592\":1}}],[\"可能导致训练收敛困难\",{\"2\":{\"1452\":1}}],[\"可能导致训练中断\",{\"2\":{\"657\":1}}],[\"可能导致训练时间过长或出现低质量子词\",{\"2\":{\"461\":1}}],[\"可能导致对状态空间的探索不足\",{\"2\":{\"646\":1}}],[\"可能导致字符编码问题\",{\"2\":{\"576\":1}}],[\"可能导致生成内容不连贯或胡言乱语\",{\"2\":{\"295\":1}}],[\"可能导致性能严重下降\",{\"2\":{\"269\":1}}],[\"可能导致模型性能不佳\",{\"2\":{\"2086\":1}}],[\"可能导致模型性能下降\",{\"2\":{\"1066\":1,\"1975\":1}}],[\"可能导致模型拟合不足或过拟合\",{\"2\":{\"2018\":1}}],[\"可能导致模型对不同语言表征适应不良\",{\"2\":{\"1194\":1}}],[\"可能导致模型输出不准确\",{\"2\":{\"1157\":1}}],[\"可能导致模型表现偏向某些语言\",{\"2\":{\"582\":1}}],[\"可能导致模型训练效率低下\",{\"2\":{\"209\":1}}],[\"可能导致模型学习效率下降\",{\"2\":{\"170\":1}}],[\"可能导致梯度过小\",{\"2\":{\"192\":1}}],[\"可以借助一些\",{\"2\":{\"2702\":1}}],[\"可以让\",{\"2\":{\"2687\":1}}],[\"可以快速定位与用户查询高度相关的小节内容\",{\"2\":{\"2675\":1}}],[\"可以采取以下优化策略\",{\"2\":{\"2664\":1}}],[\"可以采用一些内存管理技术\",{\"2\":{\"2489\":1}}],[\"可以采用一些常见的分类指标进行评估\",{\"2\":{\"2354\":1}}],[\"可以采用以下改进方法\",{\"2\":{\"1548\":1}}],[\"可以采用以下数据增强方法\",{\"2\":{\"1466\":1}}],[\"可以采用更小的基数\",{\"2\":{\"223\":1}}],[\"可以确保正确地保留和理解这些文档的结构\",{\"2\":{\"2640\":1}}],[\"可以支持多层次搜索\",{\"2\":{\"2630\":1}}],[\"可以支持session\",{\"2\":{\"2166\":1}}],[\"可以按照以下步骤进行递归分块\",{\"2\":{\"2606\":1}}],[\"可以被视为一种特殊的\",{\"2\":{\"2469\":1}}],[\"可以结合使用场景进行探索\",{\"2\":{\"2335\":1}}],[\"可以构建三个样本\",{\"2\":{\"2322\":1}}],[\"可以实现近乎完美的线性扩展\",{\"2\":{\"2704\":1}}],[\"可以实现更合理的损失计算\",{\"2\":{\"2300\":1}}],[\"可以实现对nlp任务的优化\",{\"2\":{\"1515\":1}}],[\"可以实现对困惑度的统一调节\",{\"2\":{\"184\":1}}],[\"可以判断当前结果是否足够全面\",{\"2\":{\"2294\":1}}],[\"可以指出这些不足\",{\"2\":{\"2294\":1}}],[\"可以降低内存使用量\",{\"2\":{\"2252\":1}}],[\"可以估算激活值占用的显存大小\",{\"2\":{\"2231\":1}}],[\"可以提升语言模型的泛化能力和性能表现\",{\"2\":{\"2165\":1}}],[\"可以提升模型的泛化能力\",{\"2\":{\"456\":1}}],[\"可以看看李沐的视频\",{\"2\":{\"2209\":1}}],[\"可以看到\",{\"2\":{\"2161\":1}}],[\"可以看作是从复杂的现实世界到计算机可操作世界的一种\",{\"2\":{\"882\":1}}],[\"可以看作\",{\"2\":{\"363\":1}}],[\"可以设置如下提示词\",{\"2\":{\"2690\":1}}],[\"可以设置为\",{\"2\":{\"2091\":1}}],[\"可以设为3个epoch以避免过拟合\",{\"2\":{\"2217\":1}}],[\"可以设定每块大约包含\",{\"2\":{\"1763\":1}}],[\"可以参考以下原则来制定文本分块策略\",{\"2\":{\"2543\":1}}],[\"可以参考模型的注意力机制\",{\"2\":{\"2529\":1}}],[\"可以参考\",{\"2\":{\"2059\":1,\"2218\":1,\"2253\":1,\"2384\":1}}],[\"可以利用causal\",{\"2\":{\"2300\":1}}],[\"可以利用单轮对话合成多轮对话数据\",{\"2\":{\"2291\":1}}],[\"可以利用pdf提取器抽取文本内容\",{\"2\":{\"2052\":1}}],[\"可以利用bm25或sbert对训练集进行预筛选\",{\"2\":{\"1075\":1}}],[\"可以利用bpe\",{\"2\":{\"393\":1}}],[\"可以查看各个进程的显存使用情况\",{\"2\":{\"2021\":1}}],[\"可以下载\",{\"2\":{\"2002\":1}}],[\"可以求得safe\",{\"2\":{\"1980\":1}}],[\"可以帮助开发者定义回调函数\",{\"2\":{\"2702\":1}}],[\"可以帮助我们节省推理时间\",{\"2\":{\"1870\":1}}],[\"可以帮助模型理解特定任务的模式或要求\",{\"2\":{\"708\":1}}],[\"可以这样\",{\"2\":{\"1843\":1}}],[\"可以使用模板或gpt进行合成\",{\"2\":{\"2291\":1}}],[\"可以使用\",{\"2\":{\"1835\":1}}],[\"可以使用分号或其他符号来区分数据\",{\"2\":{\"1284\":1}}],[\"可以深入了解不同模型在部分可观测环境中的表现\",{\"2\":{\"1819\":1}}],[\"可以包含问题的解决方案\",{\"2\":{\"1766\":1}}],[\"可以添加程序检查\",{\"2\":{\"1702\":1}}],[\"可以选择生成一个抽象层次更高的\",{\"2\":{\"1774\":1}}],[\"可以选择与actor共享参数或从reward\",{\"2\":{\"1699\":1}}],[\"可以选择全代码框架\",{\"2\":{\"1392\":1}}],[\"可以具备不同程度的智能体属性\",{\"2\":{\"1617\":1}}],[\"可以尝试以下几种方法对问题进行重写\",{\"2\":{\"1610\":1}}],[\"可以尝试逐步增大\",{\"2\":{\"589\":1}}],[\"可以促进模型压缩并加速推理\",{\"2\":{\"1588\":1}}],[\"可以凭借其强大的表示与推理能力预处理信息\",{\"2\":{\"1578\":1}}],[\"可以引入递归式分块策略\",{\"2\":{\"1561\":1}}],[\"可以得出人类偏好片段\",{\"2\":{\"1536\":1}}],[\"可以表示为\",{\"2\":{\"1536\":1,\"2014\":1,\"2228\":1}}],[\"可以在保持准确率的同时\",{\"2\":{\"2692\":1}}],[\"可以在保证模型训练精度的同时\",{\"2\":{\"433\":1}}],[\"可以在不同设备上并行执行不同的模型阶段\",{\"2\":{\"2685\":1}}],[\"可以在不显著增加计算复杂度的情况下提升模型性能\",{\"2\":{\"1996\":1}}],[\"可以在gpu上迅速执行\",{\"2\":{\"2579\":1}}],[\"可以在其上构建各种分布式计算系统\",{\"2\":{\"2408\":1}}],[\"可以在模型的较小片段上使用数据并行\",{\"2\":{\"2374\":1}}],[\"可以在模型压缩和保持性能之间取得平衡\",{\"2\":{\"1494\":1}}],[\"可以在有限资源下最大化训练效率\",{\"2\":{\"2319\":1}}],[\"可以在一次显存访问中完成多个计算任务\",{\"2\":{\"2175\":1}}],[\"可以在推理前事先计算好量化系数\",{\"2\":{\"1813\":1}}],[\"可以发现相比于标准attention\",{\"2\":{\"2648\":1}}],[\"可以发现\",{\"2\":{\"1442\":1}}],[\"可以协调复杂流程\",{\"2\":{\"1429\":1}}],[\"可以很好地保留原始文档的逻辑顺序\",{\"2\":{\"1424\":1}}],[\"可以根据以下几个关键因素进行决策\",{\"2\":{\"2699\":1}}],[\"可以根据文本内容动态调整分块规则\",{\"2\":{\"2613\":1}}],[\"可以根据标点符号\",{\"2\":{\"2584\":1}}],[\"可以根据具体需求选择合适的工具\",{\"2\":{\"2270\":1}}],[\"可以根据具体使用场景进行取舍\",{\"2\":{\"1422\":1}}],[\"可以根据向量数据库的特定设置来优化一些检索参数\",{\"2\":{\"1894\":1}}],[\"可以根据主题\",{\"2\":{\"1421\":1}}],[\"可以先给出\",{\"2\":{\"1420\":1}}],[\"可以动态应对复杂环境中的变化\",{\"2\":{\"1384\":1}}],[\"可以代表用户执行任务\",{\"2\":{\"1336\":1}}],[\"可以处理超过训练时设定长度的序列\",{\"2\":{\"1328\":1}}],[\"可以直接以列并行的方法切分qkv相关的gemms\",{\"2\":{\"2631\":1}}],[\"可以直接与第一个mlp得到的\",{\"2\":{\"2609\":1}}],[\"可以直接把两个gelu的输出拼接起来\",{\"2\":{\"2609\":1}}],[\"可以直接利用已经缓存的system\",{\"2\":{\"2064\":1}}],[\"可以直接利用\",{\"2\":{\"1321\":1}}],[\"可以直接处理整个多轮对话数据\",{\"2\":{\"1006\":1}}],[\"可以观察到以下现象\",{\"2\":{\"1296\":1}}],[\"可以考虑进一步尝试多重索引技术\",{\"2\":{\"1285\":1}}],[\"可以计算准确率并作为奖励信号\",{\"2\":{\"1222\":1}}],[\"可以分为两大类系统\",{\"0\":{\"1218\":1},\"1\":{\"1269\":1,\"1316\":1,\"1362\":1}}],[\"可以通过四路张量并行\",{\"2\":{\"2710\":1}}],[\"可以通过调用外部api获取额外的信息\",{\"2\":{\"2269\":1}}],[\"可以通过一个平滑系数\",{\"2\":{\"2033\":1}}],[\"可以通过嵌入技术\",{\"2\":{\"1163\":1}}],[\"可以通过改进前缀和复合词处理\",{\"2\":{\"434\":1}}],[\"可以优化计算资源的使用\",{\"2\":{\"1132\":1}}],[\"可以减少显存访问次数\",{\"2\":{\"2175\":1}}],[\"可以减少读写hbm的次数\",{\"2\":{\"1810\":1}}],[\"可以减少对外部样本库的依赖\",{\"2\":{\"1032\":1}}],[\"可以减少代码的复杂性\",{\"2\":{\"27\":1}}],[\"可以从非量化和量化两个维度进行分析\",{\"2\":{\"2222\":1}}],[\"可以从多样性的角度出发进行选择\",{\"2\":{\"949\":1}}],[\"可以从文本中提取主题\",{\"2\":{\"39\":1}}],[\"可以更好地优化模型训练过程\",{\"2\":{\"2316\":1}}],[\"可以更好地满足不同场景下的性能要求\",{\"2\":{\"2129\":1}}],[\"可以更全面地评估模型在不同维度上的表现\",{\"2\":{\"2151\":1}}],[\"可以更加全面地衡量自然语言生成系统的性能\",{\"2\":{\"2292\":1}}],[\"可以更加灵活地优化模型性能\",{\"2\":{\"2068\":1}}],[\"可以更加充分的利用量化数据信息\",{\"2\":{\"868\":1}}],[\"可以更高效地完成复杂任务\",{\"2\":{\"1485\":1}}],[\"可以更灵活地适配不同上下文长度下的注意力分布\",{\"2\":{\"228\":1}}],[\"可以显著提高对生成内容事实性的评估效率\",{\"2\":{\"2436\":1}}],[\"可以显著提高模型训练速度和效率\",{\"2\":{\"1597\":1}}],[\"可以显著提升蒸馏模型的性能\",{\"2\":{\"2627\":1}}],[\"可以显著提升大模型的性能\",{\"2\":{\"1708\":1}}],[\"可以显著提升数据质量\",{\"2\":{\"548\":1}}],[\"可以显著降低模型在生产环境中的部署成本\",{\"2\":{\"794\":1}}],[\"可以灵活地选择适合具体问题的强化学习算法\",{\"2\":{\"790\":1}}],[\"可以将其看作是将输入矩阵分块进行计算\",{\"2\":{\"2526\":1}}],[\"可以将生成的答案与已验证事实的数据库进行比较\",{\"2\":{\"2436\":1}}],[\"可以将缓存容量维持在w\",{\"2\":{\"2326\":1}}],[\"可以将任意思维聚合起来\",{\"2\":{\"2188\":1}}],[\"可以将\",{\"2\":{\"1826\":1}}],[\"可以将传统强化学习中的奖励加和替换为聚合操作\",{\"2\":{\"1688\":1}}],[\"可以将示例选择看作是一个序列决策问题\",{\"2\":{\"1222\":1}}],[\"可以将量化方法分为线性量化和非线性量化\",{\"0\":{\"868\":1}}],[\"可以将模型压缩为1\",{\"2\":{\"768\":1}}],[\"可以将关于目标分布p\",{\"2\":{\"623\":1}}],[\"可以有多个\",{\"2\":{\"767\":1}}],[\"可以有效地影响模型对不同类型问题的接受程度和回答方式\",{\"2\":{\"2687\":1}}],[\"可以有效地将大型模型的计算任务分配到多个gpu上\",{\"2\":{\"2537\":1}}],[\"可以有效地控制策略的偏移\",{\"2\":{\"1908\":1}}],[\"可以有效解决这一问题\",{\"2\":{\"2267\":1}}],[\"可以有效减轻灾难性遗忘现象\",{\"2\":{\"2180\":1}}],[\"可以有效减少模型的存储需求和计算复杂度\",{\"2\":{\"693\":1}}],[\"可以有效提升\",{\"2\":{\"2603\":1}}],[\"可以有效提升语言模型的灵活性和适应性\",{\"2\":{\"2373\":1}}],[\"可以有效提升模型运行效率\",{\"2\":{\"2175\":1}}],[\"可以有效提升训练数据的质量\",{\"2\":{\"425\":1}}],[\"可以有效提高llm推理的效率\",{\"2\":{\"2166\":1}}],[\"可以有效避免语义割裂\",{\"2\":{\"2141\":1}}],[\"可以有效避免数值不稳定的问题\",{\"2\":{\"1925\":1}}],[\"可以有效裁剪不重要的奇异值\",{\"2\":{\"1653\":1}}],[\"可以有效降低模型训练难度\",{\"2\":{\"1487\":1}}],[\"可以有效追踪困惑度的变化\",{\"2\":{\"558\":1}}],[\"可以获取教师模型的参数或输出分布\",{\"2\":{\"677\":1}}],[\"可以停止策略评估\",{\"2\":{\"656\":1}}],[\"可以精准定位目标内容\",{\"2\":{\"559\":1}}],[\"可以避免策略走得过远\",{\"2\":{\"1033\":1}}],[\"可以避免被目标网站封禁\",{\"2\":{\"526\":1}}],[\"可以避免全局引入命名空间\",{\"2\":{\"22\":1}}],[\"可以用于对训练数据进行打分\",{\"2\":{\"479\":1}}],[\"可以增加维度\",{\"2\":{\"223\":1}}],[\"可以规避移位可能引入的信息泄漏问题\",{\"2\":{\"136\":1}}],[\"可以理解为给每个单词分配一个\",{\"2\":{\"1418\":1}}],[\"可以理解为\",{\"2\":{\"90\":1}}],[\"可以理解为一个调整值\",{\"2\":{\"76\":1}}],[\"可以自行补充\",{\"2\":{\"48\":1}}],[\"可以与面向对象编程结合使用\",{\"2\":{\"20\":1}}],[\"或专有模型\",{\"2\":{\"2699\":1}}],[\"或设定不同的投票阈值以平衡误报与漏报\",{\"2\":{\"2037\":1}}],[\"或工作记忆\",{\"0\":{\"1998\":1}}],[\"或上下文阶段\",{\"2\":{\"1910\":1}}],[\"或其他工具依次完成\",{\"2\":{\"1595\":1}}],[\"或者利用更高级的自然语言处理工具库\",{\"2\":{\"2584\":1}}],[\"或者存在两篇描述同一事件但一篇内容正确\",{\"2\":{\"2506\":1}}],[\"或者其他需要汇总的数据\",{\"2\":{\"2452\":1}}],[\"或者从数据库中提取信息\",{\"2\":{\"2443\":1}}],[\"或者是图像等结构化数据\",{\"2\":{\"2418\":1}}],[\"或者对返回结果进行一定程度的过滤\",{\"2\":{\"2154\":1}}],[\"或者当需要通过多角度\",{\"2\":{\"2037\":1}}],[\"或者通过模型预测段落边界\",{\"2\":{\"1425\":1}}],[\"或者\",{\"2\":{\"1420\":1,\"2118\":1}}],[\"或者预测一个人是否患有某种疾病\",{\"2\":{\"42\":1}}],[\"或wordpiece算法\",{\"2\":{\"1302\":1}}],[\"或类似架构可能在多模态任务中获得更广泛应用\",{\"2\":{\"629\":1}}],[\"或相对位置\",{\"2\":{\"216\":1}}],[\"或称casual\",{\"2\":{\"167\":1}}],[\"或\",{\"2\":{\"123\":1,\"528\":1,\"560\":1,\"562\":1,\"631\":1,\"1377\":1,\"1536\":1,\"1542\":1,\"2427\":1,\"2584\":1,\"2655\":1}}],[\"或超平面\",{\"2\":{\"51\":1}}],[\"或冻结部分参数\",{\"2\":{\"40\":1}}],[\"或期望的输出\",{\"2\":{\"39\":1}}],[\"或编写简单的代码时\",{\"2\":{\"27\":1}}],[\"或算法\",{\"2\":{\"12\":1}}],[\"你应保持友善\",{\"2\":{\"2690\":1}}],[\"你的目标是提供准确的信息\",{\"2\":{\"2690\":1}}],[\"你是一名智能客服\",{\"2\":{\"2690\":1}}],[\"你提出一个问题或任务\",{\"2\":{\"2363\":1}}],[\"你可能会有疑惑\",{\"2\":{\"2349\":1}}],[\"你可以根据需要选择函数定义的位置\",{\"2\":{\"11\":1}}],[\"你只需要输入一个提示\",{\"2\":{\"2333\":1}}],[\"你需要掌握以下知识领域\",{\"2\":{\"578\":1}}],[\"你不需要在每次使用标准库的成员时加上\",{\"2\":{\"27\":1}}],[\"高度的模型并行会产生很多的小矩阵乘法\",{\"2\":{\"2526\":1}}],[\"高达11b参数\",{\"2\":{\"1062\":1}}],[\"高质量数据\",{\"2\":{\"568\":1}}],[\"高质量多模态数据\",{\"2\":{\"535\":1}}],[\"高质量pdf数据解析方法\",{\"0\":{\"465\":1}}],[\"高loss可能由乱码数据引起\",{\"2\":{\"525\":1}}],[\"高维稀疏问题需要额外处理\",{\"2\":{\"1163\":1}}],[\"高维稀疏问题\",{\"2\":{\"985\":1}}],[\"高维到低维\",{\"2\":{\"918\":1}}],[\"高维向量嵌入\",{\"2\":{\"315\":1}}],[\"高维扩展\",{\"2\":{\"247\":1}}],[\"高成本\",{\"2\":{\"305\":1}}],[\"高性能\",{\"2\":{\"259\":1}}],[\"高频词靠近树根\",{\"2\":{\"941\":1}}],[\"高频区域\",{\"2\":{\"221\":1}}],[\"高频外推与低频内插\",{\"0\":{\"200\":1},\"1\":{\"221\":1,\"244\":1}}],[\"高速通道\",{\"2\":{\"183\":1}}],[\"高效微调原理\",{\"2\":{\"1853\":1}}],[\"高效微调技术\",{\"2\":{\"57\":1}}],[\"高效处理高频词\",{\"2\":{\"1023\":1}}],[\"高效利用内存的好处很明显\",{\"2\":{\"750\":1}}],[\"高效平衡了词汇表大小和编码步数\",{\"2\":{\"529\":1}}],[\"高效的平台支持\",{\"2\":{\"1347\":1}}],[\"高效的数据处理工具是预训练成功的关键\",{\"2\":{\"568\":1}}],[\"高效的压缩能力\",{\"2\":{\"318\":1}}],[\"高效的训练流程\",{\"2\":{\"294\":1}}],[\"高效但需人工选择保留区域\",{\"2\":{\"305\":1}}],[\"高效实现是技术推广的关键\",{\"2\":{\"257\":1}}],[\"高效深度学习模型训练框架选择与优化指南\",{\"0\":{\"1115\":1},\"1\":{\"1165\":1,\"1214\":1,\"1265\":1,\"1312\":1,\"1358\":1,\"1404\":1,\"1451\":1,\"1498\":1,\"1542\":1,\"1592\":1,\"1646\":1,\"1700\":1,\"1758\":1,\"1818\":1,\"1878\":1},\"2\":{\"113\":1}}],[\"高效深度学习模型训练框架选择与优化指南|高效深度学习模型训练框架选择与优化指南\",{\"2\":{\"5\":1}}],[\"高价值客户\",{\"2\":{\"39\":1}}],[\"高级优化增加了系统复杂性\",{\"2\":{\"2512\":1}}],[\"高级检索策略能够进一步提升系统性能\",{\"2\":{\"2104\":1}}],[\"高级检索策略\",{\"0\":{\"2104\":1},\"1\":{\"2154\":1,\"2197\":1,\"2236\":1,\"2271\":1,\"2304\":1,\"2335\":1,\"2365\":1,\"2394\":1}}],[\"高级\",{\"2\":{\"24\":3}}],[\"高级特性\",{\"0\":{\"24\":1}}],[\"如摘要或主要观点\",{\"2\":{\"2675\":1}}],[\"如技术文档\",{\"2\":{\"2650\":1}}],[\"如句号\",{\"2\":{\"2584\":1}}],[\"如句子\",{\"2\":{\"1425\":1}}],[\"如本地知识库\",{\"2\":{\"2469\":1}}],[\"如冗余和风格一致性问题\",{\"2\":{\"2466\":1}}],[\"如编码\",{\"2\":{\"2399\":1}}],[\"如查询意图\",{\"2\":{\"2394\":1}}],[\"如fp32\",{\"2\":{\"2266\":1}}],[\"如fineweb\",{\"2\":{\"669\":1}}],[\"如mc等任务环境\",{\"2\":{\"2242\":1}}],[\"如mish\",{\"2\":{\"311\":1}}],[\"如1万条以内\",{\"2\":{\"2217\":1}}],[\"如16384\",{\"2\":{\"567\":1}}],[\"如指令遵循\",{\"2\":{\"2194\":1}}],[\"如段落\",{\"2\":{\"2141\":1}}],[\"如剪枝或量化\",{\"2\":{\"2048\":1}}],[\"如激活函数\",{\"2\":{\"2027\":1}}],[\"如学习和推理\",{\"2\":{\"1998\":1}}],[\"如视觉\",{\"2\":{\"1947\":1}}],[\"如搜索引擎查询\",{\"2\":{\"1876\":1}}],[\"如加和\",{\"2\":{\"1688\":1}}],[\"如联网搜索\",{\"2\":{\"1619\":1}}],[\"如部分固定\",{\"2\":{\"1606\":1}}],[\"如章节\",{\"2\":{\"1561\":1}}],[\"如词或字\",{\"2\":{\"1531\":1}}],[\"如词汇表大小\",{\"2\":{\"597\":1}}],[\"如多栏排版\",{\"2\":{\"1834\":1}}],[\"如多任务联合训练\",{\"2\":{\"1526\":1}}],[\"如多余的标点符号\",{\"2\":{\"1331\":1}}],[\"如医学\",{\"2\":{\"1508\":1}}],[\"如医学文本或法律文档\",{\"2\":{\"1261\":1}}],[\"如医疗和法律文本分析\",{\"2\":{\"1484\":1}}],[\"如h100\",{\"2\":{\"1464\":1}}],[\"如一段话或一个小节\",{\"2\":{\"1424\":1}}],[\"如复杂性\",{\"2\":{\"1332\":1}}],[\"如蜜蜂群\",{\"2\":{\"1300\":1}}],[\"如grpo\",{\"2\":{\"2054\":1}}],[\"如glove和fasttext\",{\"2\":{\"1261\":1}}],[\"如gpt系列\",{\"2\":{\"701\":1,\"851\":1}}],[\"如gpt\",{\"2\":{\"479\":1,\"568\":1}}],[\"如情感分析\",{\"2\":{\"1259\":1}}],[\"如条件生成任务\",{\"2\":{\"1239\":1}}],[\"如计算器\",{\"2\":{\"1233\":1}}],[\"如word\",{\"2\":{\"1263\":1}}],[\"如word2vec\",{\"2\":{\"1163\":1,\"1212\":1}}],[\"如wordpiece\",{\"2\":{\"597\":1}}],[\"如vector\",{\"2\":{\"1161\":1}}],[\"如格式不当\",{\"2\":{\"1157\":1}}],[\"如将post\",{\"2\":{\"1059\":1}}],[\"如将原三维向量扩展为四维\",{\"2\":{\"223\":1}}],[\"如pca\",{\"2\":{\"1025\":1,\"1212\":1}}],[\"如pdf文件和网页数据\",{\"2\":{\"411\":1}}],[\"如游戏ai和自动驾驶\",{\"2\":{\"928\":1}}],[\"如文字\",{\"2\":{\"882\":1}}],[\"如文本+图像\",{\"2\":{\"1176\":1}}],[\"如文本或图像\",{\"2\":{\"882\":1}}],[\"如文本\",{\"2\":{\"318\":1}}],[\"如文本分类或摘要生成\",{\"2\":{\"279\":1}}],[\"如文本分类\",{\"2\":{\"59\":1}}],[\"如question\",{\"2\":{\"1368\":1}}],[\"如q\",{\"2\":{\"754\":1,\"928\":1}}],[\"如混合注意力机制\",{\"2\":{\"740\":1}}],[\"如混合位置编码\",{\"2\":{\"360\":1}}],[\"如动态代理池或模拟用户行为\",{\"2\":{\"737\":1}}],[\"如动态位置编码\",{\"2\":{\"413\":1}}],[\"如中英混合\",{\"2\":{\"719\":1}}],[\"如中文知识\",{\"2\":{\"525\":1}}],[\"如中文\",{\"2\":{\"474\":1}}],[\"如中文和日语\",{\"2\":{\"296\":1}}],[\"如deepseek\",{\"2\":{\"685\":1,\"1955\":1}}],[\"如价值函数\",{\"2\":{\"654\":1}}],[\"如结合深度学习的内容分类器\",{\"2\":{\"650\":1}}],[\"如xsec\",{\"2\":{\"594\":1}}],[\"如减半\",{\"2\":{\"589\":1}}],[\"如重复行或段落\",{\"2\":{\"644\":1}}],[\"如重复行\",{\"2\":{\"575\":1}}],[\"如论文\",{\"2\":{\"568\":1}}],[\"如论文或书籍\",{\"2\":{\"465\":1}}],[\"如以\",{\"2\":{\"548\":1}}],[\"如抓取超时\",{\"2\":{\"548\":1}}],[\"如从4096扩展至16384\",{\"2\":{\"475\":1}}],[\"如从1000扩展到2000\",{\"2\":{\"223\":1}}],[\"如7\",{\"2\":{\"475\":1,\"567\":1}}],[\"如代码生成\",{\"2\":{\"707\":1}}],[\"如代码\",{\"2\":{\"475\":1,\"2424\":1,\"2640\":1}}],[\"如数学\",{\"2\":{\"474\":1,\"1441\":1}}],[\"如成人网站\",{\"2\":{\"456\":1}}],[\"如显存容量增加\",{\"2\":{\"432\":1}}],[\"如英文与中文\",{\"2\":{\"426\":1}}],[\"如英文中的26个字母和符号\",{\"2\":{\"420\":1}}],[\"如cohere模型\",{\"2\":{\"2394\":1}}],[\"如clip\",{\"2\":{\"414\":1}}],[\"如cnn\",{\"2\":{\"207\":1}}],[\"如小红书\",{\"2\":{\"411\":1}}],[\"如基于神经网络生成的位置表示\",{\"2\":{\"409\":1}}],[\"如em算法\",{\"2\":{\"393\":1}}],[\"如elu\",{\"2\":{\"354\":1}}],[\"如rnn\",{\"2\":{\"388\":1}}],[\"如绝对位置编码\",{\"2\":{\"387\":1}}],[\"如adam\",{\"2\":{\"2266\":1}}],[\"如adapter\",{\"2\":{\"2244\":1}}],[\"如a\",{\"2\":{\"381\":1}}],[\"如alibi\",{\"2\":{\"322\":1}}],[\"如哈希编码\",{\"2\":{\"361\":1}}],[\"如分段映射\",{\"2\":{\"337\":1}}],[\"如分类标签或目标值\",{\"2\":{\"39\":1}}],[\"如图像生成或语音识别\",{\"2\":{\"1593\":1}}],[\"如图像和文本\",{\"2\":{\"1543\":1}}],[\"如图像与文本\",{\"2\":{\"635\":1}}],[\"如图像或连续变量\",{\"2\":{\"606\":1}}],[\"如图像\",{\"2\":{\"442\":1,\"535\":1}}],[\"如图像+文本\",{\"2\":{\"333\":1,\"469\":1}}],[\"如图像分割\",{\"2\":{\"327\":1}}],[\"如语音处理\",{\"2\":{\"281\":1}}],[\"如实时对话生成或代码补全\",{\"2\":{\"255\":1}}],[\"如机器翻译\",{\"2\":{\"240\":1,\"901\":1}}],[\"如bpe\",{\"2\":{\"373\":1,\"542\":1,\"645\":1}}],[\"如batch\",{\"2\":{\"234\":1}}],[\"如bert模型\",{\"2\":{\"308\":1}}],[\"如bert\",{\"2\":{\"133\":1,\"1261\":1,\"1307\":1,\"1381\":1,\"1388\":1}}],[\"如80\",{\"2\":{\"473\":1}}],[\"如8192x8192\",{\"2\":{\"351\":1}}],[\"如875\",{\"2\":{\"246\":1}}],[\"如8进制或2进制\",{\"2\":{\"223\":1}}],[\"如8行4列\",{\"2\":{\"156\":1}}],[\"如4096\",{\"2\":{\"222\":1}}],[\"如2048\",{\"2\":{\"222\":1}}],[\"如tensorflow或pytorch\",{\"2\":{\"719\":1}}],[\"如tpus\",{\"2\":{\"334\":1}}],[\"如transformer\",{\"2\":{\"217\":1,\"260\":1,\"469\":1,\"1354\":1}}],[\"如tf\",{\"2\":{\"207\":1}}],[\"如何提高效率一直是研究的重点之一\",{\"2\":{\"2685\":1}}],[\"如何通过合理的切分策略来减少gpu之间的通信量\",{\"2\":{\"2609\":1}}],[\"如何通过优化少量参数达到理想性能的创新思路\",{\"2\":{\"2136\":1}}],[\"如何高效地利用gpu资源成为了一个重要的研究课题\",{\"2\":{\"2609\":1}}],[\"如何高效地利用计算资源是一个非常重要的问题\",{\"2\":{\"751\":1}}],[\"如何制定合适的文本分块策略\",{\"0\":{\"2543\":1}}],[\"如何使用\",{\"2\":{\"2433\":1}}],[\"如何自动化评估指令执行难度\",{\"2\":{\"2345\":1}}],[\"如何更好地利用大模型进行机评以减少偏差\",{\"2\":{\"2301\":1}}],[\"如何更有效地平衡探索与利用\",{\"2\":{\"776\":1}}],[\"如何利用检索到的信息\",{\"2\":{\"2693\":1}}],[\"如何利用这些数据集提高模型的准确性和鲁棒性\",{\"2\":{\"2258\":1}}],[\"如何利用位置内插法提升多模态任务中的上下文处理能力\",{\"2\":{\"413\":1}}],[\"如何计算\",{\"0\":{\"2228\":1}}],[\"如何保证智能体的训练质量\",{\"2\":{\"1973\":1}}],[\"如何确保用户反馈的准确性和一致性\",{\"2\":{\"1973\":1}}],[\"如何确保跨语言的一致性\",{\"2\":{\"1971\":1}}],[\"如何确保生成结果的一致性和准确性\",{\"2\":{\"1600\":1}}],[\"如何判断一个nlp任务是否需要引入绝对位置信息\",{\"2\":{\"1472\":1}}],[\"如何切分不同类型的文件\",{\"2\":{\"1450\":1}}],[\"如何建立知识向量库\",{\"0\":{\"1450\":1}}],[\"如何降低推理成本将成为一个需要关注的问题\",{\"2\":{\"1314\":1}}],[\"如何调整mdp建模以获得最佳结果\",{\"2\":{\"1897\":1}}],[\"如何调整word2vec以处理语言间语义差异\",{\"2\":{\"1210\":1}}],[\"如何调整模型初始参数以减少对缩放因子的依赖\",{\"2\":{\"260\":1}}],[\"如何实现独热编码\",{\"0\":{\"1025\":1}}],[\"如何实时调整策略以适应变化\",{\"2\":{\"994\":1}}],[\"如何有效地处理过长回答的问题是一个关键挑战\",{\"2\":{\"2686\":1}}],[\"如何有效地评估人类偏好标签的质量\",{\"2\":{\"1971\":1}}],[\"如何有效地分块是一个重要的问题\",{\"2\":{\"1334\":1}}],[\"如何有效地结合策略梯度和基于值的方法以提高算法性能\",{\"2\":{\"965\":1}}],[\"如何有效地选择合适的折扣因子\",{\"2\":{\"876\":1}}],[\"如何有效地监控和调试api调用\",{\"2\":{\"219\":1}}],[\"如何正确匹配教师与学生的特征表示也是一个尚未完全解决的难题\",{\"2\":{\"845\":1}}],[\"如何评估行为约束对模型性能的影响\",{\"2\":{\"1897\":1}}],[\"如何评估生成内容的创造力与准确性之间的平衡\",{\"2\":{\"771\":1}}],[\"如何评估其实际收益\",{\"2\":{\"289\":1}}],[\"如何衡量llm的续写能力对用户体验的影响\",{\"2\":{\"770\":1}}],[\"如何动态调整$$\",{\"2\":{\"754\":1}}],[\"如何动态调整norm位置以适应不同任务需求\",{\"2\":{\"258\":1}}],[\"如何进一步提高伪多轮数据的质量\",{\"2\":{\"2476\":1}}],[\"如何进一步提高llm在长文本中的信息提取精度\",{\"2\":{\"770\":1}}],[\"如何进一步细化loss和困惑度的监控策略\",{\"2\":{\"736\":1}}],[\"如何进一步优化合成数据生成过程以减少偏差\",{\"2\":{\"2382\":1}}],[\"如何进一步优化tokenizer以支持多语种任务\",{\"2\":{\"1580\":1}}],[\"如何进一步优化\",{\"2\":{\"1447\":1,\"1758\":1}}],[\"如何进一步优化dqn以适应更复杂的状态空间\",{\"2\":{\"913\":1}}],[\"如何进一步优化聚类算法以减少噪声影响\",{\"2\":{\"632\":1}}],[\"如何进一步优化ntk\",{\"2\":{\"466\":1}}],[\"如何进一步优化kv压缩方法以适应更长序列长度\",{\"2\":{\"404\":1}}],[\"如何进一步优化跨组信息流动而不增加计算复杂度\",{\"2\":{\"333\":1}}],[\"如何进一步优化yarn方法\",{\"2\":{\"300\":1}}],[\"如何进一步优化块间注意力\",{\"2\":{\"217\":1}}],[\"如何选择与配置训练框架\",{\"0\":{\"1542\":1}}],[\"如何选择教师模型中的哪一层特征激活\",{\"2\":{\"845\":1}}],[\"如何选择策略迭代与价值迭代\",{\"2\":{\"727\":1}}],[\"如何选择合适的参考策略以避免策略偏离\",{\"2\":{\"1838\":1}}],[\"如何选择合适的折扣因子\",{\"2\":{\"965\":1}}],[\"如何选择合适的步长参数$$\",{\"2\":{\"850\":1}}],[\"如何选择合适的收敛阈值以平衡计算效率与结果精度\",{\"2\":{\"647\":1}}],[\"如何选择合适的api网关以满足特定需求\",{\"2\":{\"219\":1}}],[\"如何改进现有的稀疏门控机制\",{\"2\":{\"702\":1}}],[\"如何改进bpe算法\",{\"2\":{\"631\":1}}],[\"如何处理状态空间过大的问题\",{\"2\":{\"647\":1}}],[\"如何处理不同语言间的差异\",{\"2\":{\"563\":1}}],[\"如何优化packing策略以提升泛化能力\",{\"2\":{\"2449\":1}}],[\"如何优化deepseek\",{\"0\":{\"2346\":1}}],[\"如何优化独热编码在大规模文本数据中的性能\",{\"2\":{\"1263\":1}}],[\"如何优化多模态数据\",{\"2\":{\"635\":1}}],[\"如何优化self\",{\"2\":{\"304\":1}}],[\"如何解决语义偏差问题\",{\"2\":{\"632\":1}}],[\"如何权衡不同语种的数据比例以提升性能\",{\"2\":{\"635\":1}}],[\"如何权衡\",{\"2\":{\"564\":1,\"1606\":1}}],[\"如何平衡合成数据与真实用户数据在训练中的比例\",{\"2\":{\"2382\":1}}],[\"如何平衡不同维度的权重\",{\"2\":{\"2301\":1}}],[\"如何平衡通用性与领域专用性\",{\"2\":{\"1580\":1}}],[\"如何平衡灵活性与泛化能力\",{\"2\":{\"1481\":1}}],[\"如何平衡\",{\"2\":{\"1176\":1}}],[\"如何平衡数据清洗效率与模型性能提升之间的资源投入\",{\"2\":{\"785\":1}}],[\"如何平衡长文本处理能力与计算资源消耗\",{\"2\":{\"740\":1}}],[\"如何平衡初始大词表的覆盖范围和计算复杂度\",{\"2\":{\"563\":1}}],[\"如何平衡绝对位置信息与相对位置信息的重要性\",{\"2\":{\"466\":1}}],[\"如何撰写学术论文\",{\"2\":{\"454\":1}}],[\"如何结合fasttext与深度学习模型\",{\"2\":{\"1354\":1}}],[\"如何结合td与深度学习技术以增强其在复杂任务中的表现\",{\"2\":{\"850\":1}}],[\"如何结合两种解码策略\",{\"2\":{\"453\":1}}],[\"如何结合激活函数与优化算法进一步提升模型收敛速度\",{\"2\":{\"406\":1}}],[\"如何在训练过程中实时监控和调整损失函数\",{\"2\":{\"2449\":1}}],[\"如何在更大规模的数据集上优化sft训练效率\",{\"2\":{\"2350\":1}}],[\"如何在数据合成过程中更高效地提高\",{\"2\":{\"2345\":1}}],[\"如何在不同硬件条件下灵活调整\",{\"2\":{\"1577\":1}}],[\"如何在不同的领域中优化llm的知识掌握\",{\"2\":{\"616\":1}}],[\"如何在有限预算下进一步提升预训练效率\",{\"2\":{\"1508\":1}}],[\"如何在生成好的词向量中进一步加入语法信息\",{\"2\":{\"1210\":1}}],[\"如何在多智能体环境中应用mdp\",{\"2\":{\"994\":1}}],[\"如何在复杂环境中有效计算状态和动作价值\",{\"2\":{\"915\":1}}],[\"如何在复杂环境中有效地扩展sarsa算法\",{\"2\":{\"754\":1}}],[\"如何在保证成本可控的前提下\",{\"2\":{\"628\":1}}],[\"如何在实际应用中有效地选择最优策略\",{\"2\":{\"797\":1}}],[\"如何在实际应用中提升强化学习算法的效率\",{\"2\":{\"776\":1}}],[\"如何在实际应用中选择适合的分词方法\",{\"2\":{\"564\":1}}],[\"如何在实际工程中选择合适的注意力机制优化方法\",{\"2\":{\"432\":1}}],[\"如何在wordpiece中更好地处理拼写错误或前缀问题\",{\"2\":{\"490\":1}}],[\"如何在深度模型中平衡宽度与深度\",{\"2\":{\"258\":1}}],[\"如何应用ntk\",{\"0\":{\"359\":1}}],[\"如何应对这些挑战\",{\"0\":{\"177\":1},\"1\":{\"198\":1}}],[\"如何设计更高效的\",{\"2\":{\"1176\":1}}],[\"如何设计一种新的位置编码方式\",{\"2\":{\"1481\":1}}],[\"如何设计一种动态进制转换机制\",{\"2\":{\"337\":1}}],[\"如何设计一个高效的奖励函数以加速策略优化\",{\"2\":{\"966\":1}}],[\"如何设计动态调整\",{\"2\":{\"771\":1}}],[\"如何设计动态清理策略以应对超长序列缓存问题\",{\"2\":{\"279\":1}}],[\"如何设计动态选择注意力区域的机制\",{\"2\":{\"233\":1}}],[\"如何设计数字输入的表示方式对模型性能和扩展能力至关重要\",{\"2\":{\"202\":1}}],[\"如法律分析\",{\"2\":{\"706\":1}}],[\"如法律文档分析\",{\"2\":{\"264\":1}}],[\"如法律文本\",{\"2\":{\"155\":1}}],[\"如法律\",{\"2\":{\"196\":1}}],[\"如llama\",{\"2\":{\"1867\":1}}],[\"如llama模型的增强\",{\"2\":{\"163\":1}}],[\"如llama2\",{\"2\":{\"138\":1}}],[\"如sarsa和q\",{\"2\":{\"815\":1}}],[\"如squad\",{\"2\":{\"349\":1}}],[\"如sparse\",{\"2\":{\"279\":1}}],[\"如swish和gelu\",{\"2\":{\"138\":1}}],[\"如slack\",{\"2\":{\"118\":1}}],[\"如决策树\",{\"2\":{\"91\":1}}],[\"如需进一步扩展某部分细节\",{\"2\":{\"65\":1}}],[\"如回译\",{\"2\":{\"40\":1}}],[\"如添加分类头\",{\"2\":{\"40\":1}}],[\"如购物篮分析\",{\"2\":{\"39\":1}}],[\"如癌症检测\",{\"2\":{\"39\":1}}],[\"如猫狗分类\",{\"2\":{\"39\":1}}],[\"如卷积神经网络\",{\"2\":{\"39\":1}}],[\"如\",{\"2\":{\"39\":2,\"40\":2,\"49\":1,\"57\":1,\"359\":1,\"392\":1,\"408\":1,\"416\":2,\"439\":1,\"528\":1,\"542\":1,\"548\":1,\"562\":1,\"589\":1,\"698\":1,\"734\":1,\"917\":1,\"954\":1,\"1110\":1,\"1207\":1,\"1264\":1,\"1306\":2,\"1389\":1,\"1392\":1,\"1394\":1,\"1399\":1,\"1436\":1,\"1451\":1,\"1463\":1,\"1671\":1,\"1700\":1,\"1702\":1,\"2113\":1,\"2141\":2,\"2215\":1,\"2374\":1,\"2584\":1,\"2640\":1,\"2699\":2}}],[\"如另一个库中也有\",{\"2\":{\"22\":1}}],[\"如果对\",{\"2\":{\"2616\":1}}],[\"如果仍然超过阈值\",{\"2\":{\"2606\":1}}],[\"如果某个块的大小超过预设阈值\",{\"2\":{\"2606\":1}}],[\"如果存在低可信度\",{\"2\":{\"2570\":1}}],[\"如果模型生成的文本与答案完全匹配\",{\"2\":{\"2458\":1}}],[\"如果优势值为正\",{\"2\":{\"2387\":1}}],[\"如果将多个样本合并为一个样本进行计算\",{\"2\":{\"2353\":1}}],[\"如果将这样的整个文档传递给大语言模型\",{\"2\":{\"2154\":1}}],[\"如果分块过大\",{\"2\":{\"2334\":1}}],[\"如果分块方式导致语义断裂\",{\"2\":{\"175\":1}}],[\"如果任务能够通过明确标准进行迭代优化\",{\"2\":{\"2325\":1}}],[\"如果任务具有较高的不确定性和动态性\",{\"2\":{\"2325\":1}}],[\"如果查询与文档的某个具体部分或摘要更相关\",{\"2\":{\"2304\":1}}],[\"如果现有数据量不足\",{\"2\":{\"2291\":1}}],[\"如果发现损失持续升高\",{\"2\":{\"2243\":1}}],[\"如果数据量较小\",{\"2\":{\"2217\":1}}],[\"如果损失持续升高\",{\"2\":{\"2206\":1}}],[\"如果文档文块太小\",{\"2\":{\"2197\":1}}],[\"如果文档结构混乱或者没有明确的章节划分\",{\"2\":{\"1469\":1}}],[\"如果得到的文本块长度超过了\",{\"2\":{\"2141\":1}}],[\"如果直接进行生成\",{\"2\":{\"2079\":1}}],[\"如果直接将短文本用\",{\"2\":{\"782\":1}}],[\"如果用户查询较为复杂\",{\"2\":{\"2655\":1}}],[\"如果用户查询通常简短且具体\",{\"2\":{\"2655\":1}}],[\"如果用户的问题模糊且指向不明\",{\"2\":{\"1496\":1}}],[\"如果用浮点数进行计算\",{\"2\":{\"1977\":1}}],[\"如果用基于规则的奖励替换reward\",{\"2\":{\"1954\":1}}],[\"如果去掉reference\",{\"2\":{\"1954\":1}}],[\"如果没有就使用保存下来的前一个节点的梯度重新计算当前节点的梯度再使用\",{\"2\":{\"2503\":1}}],[\"如果没有路由机制\",{\"2\":{\"1935\":1}}],[\"如果没有匹配结果\",{\"2\":{\"1644\":1}}],[\"如果采用kv\",{\"2\":{\"1870\":1}}],[\"如果启用\",{\"2\":{\"1809\":1}}],[\"如果一个系统使用多个\",{\"2\":{\"1786\":1}}],[\"如果原始查询太复杂或返回的信息过于广泛\",{\"2\":{\"1774\":1}}],[\"如果第一个相关结果排名靠后\",{\"2\":{\"1698\":1}}],[\"如果第一个相关结果排名靠前\",{\"2\":{\"1698\":1}}],[\"如果偏好数据不准确或不全面\",{\"2\":{\"1696\":1}}],[\"如果单独使用\",{\"2\":{\"1611\":1}}],[\"如果单个expert溢出\",{\"2\":{\"1119\":1}}],[\"如果搜索结果不理想\",{\"2\":{\"1610\":1}}],[\"如果答案跨越块边界\",{\"2\":{\"1598\":1}}],[\"如果奖励函数模型与人类偏好对齐不佳\",{\"2\":{\"1539\":1}}],[\"如果测试集上的效果下降\",{\"2\":{\"1505\":1}}],[\"如果训练集上的人工评估结果也在上涨\",{\"2\":{\"1505\":1}}],[\"如果上下文过长\",{\"2\":{\"1504\":1}}],[\"如果两个分段的余弦相似度较高\",{\"2\":{\"1470\":1}}],[\"如果两个demonstration高度语义相似\",{\"2\":{\"949\":1}}],[\"如果输入长度超过模型支持的最大长度\",{\"2\":{\"1463\":1}}],[\"如果人类都无法轻松判断需要查阅哪个文档来回答常见问题\",{\"2\":{\"1421\":1}}],[\"如果使用\",{\"2\":{\"1404\":1,\"2145\":1}}],[\"如果更关注开发效率和易用性\",{\"2\":{\"1392\":1}}],[\"如果需要检索\",{\"2\":{\"2365\":1}}],[\"如果需要高自由度和深度定制\",{\"2\":{\"1392\":1}}],[\"如果需要调用\",{\"2\":{\"10\":1}}],[\"如果预训练时最大序列长度为\",{\"2\":{\"1281\":1}}],[\"如果选择错误\",{\"2\":{\"1066\":1}}],[\"如果遇到超长文本则会面临阶段的问题\",{\"2\":{\"847\":1}}],[\"如果重复比例过高\",{\"2\":{\"644\":1}}],[\"如果是低资源语言建模\",{\"2\":{\"631\":1}}],[\"如果溢出\",{\"2\":{\"553\":1}}],[\"如果初始词表不能覆盖语料中的所有单词\",{\"2\":{\"498\":1}}],[\"如果不考虑ooo的话\",{\"2\":{\"2648\":1}}],[\"如果不调整损失函数\",{\"2\":{\"2390\":1}}],[\"如果不调整\",{\"2\":{\"2331\":1}}],[\"如果不一致\",{\"2\":{\"1975\":1}}],[\"如果不使用目标网络\",{\"2\":{\"777\":1}}],[\"如果不使用命名空间\",{\"2\":{\"10\":1}}],[\"如果不删除\",{\"2\":{\"488\":1}}],[\"如果合并阈值过低\",{\"2\":{\"461\":1}}],[\"如果未对权重进行缩放\",{\"2\":{\"192\":1}}],[\"如果概率\",{\"2\":{\"105\":2}}],[\"如果我们希望减小代价函数值\",{\"2\":{\"32\":1}}],[\"如果你的程序很小\",{\"2\":{\"27\":1}}],[\"如果你的代码中可能有其他库使用相同名字的标识符\",{\"2\":{\"22\":1}}],[\"避免策略过于随机或探索不足\",{\"2\":{\"2612\":1,\"2665\":1}}],[\"避免策略过于随机或探索不足的问题\",{\"2\":{\"2598\":1,\"2658\":1}}],[\"避免策略更新偏离上一个迭代回合的策略\",{\"2\":{\"658\":1}}],[\"避免通信开销成为性能瓶颈\",{\"2\":{\"2422\":1}}],[\"避免\",{\"2\":{\"2422\":1,\"2484\":1}}],[\"避免训练数据过于集中在某些特定模式\",{\"2\":{\"2343\":1}}],[\"避免训练过程中出现过拟合\",{\"2\":{\"1771\":1}}],[\"避免训练过程中的潜在问题\",{\"2\":{\"464\":1}}],[\"避免注意力退化\",{\"2\":{\"2280\":1}}],[\"避免实例化完整的注意力矩阵\",{\"2\":{\"2160\":1}}],[\"避免实例化注意力矩阵\",{\"2\":{\"2008\":1}}],[\"避免对整个模型造成不必要的变化\",{\"2\":{\"1779\":1}}],[\"避免传统模型中固定奖励机制的局限性\",{\"2\":{\"1747\":1}}],[\"避免传统方法的高计算成本\",{\"2\":{\"264\":1}}],[\"避免rl策略过度优化\",{\"2\":{\"1685\":1}}],[\"避免影响模型回答准确性\",{\"2\":{\"1632\":1}}],[\"避免用户查询到不再适用的信息\",{\"2\":{\"1558\":1}}],[\"避免在sft阶段进行大量知识注入\",{\"2\":{\"1299\":1}}],[\"避免在输入中加入特殊字符\",{\"2\":{\"1254\":1}}],[\"避免冗余\",{\"2\":{\"1190\":1}}],[\"避免不同专家模块之间的信息重复\",{\"2\":{\"1073\":1}}],[\"避免因设置错误导致模型不收敛\",{\"2\":{\"1946\":1}}],[\"避免因重复内容而导致检索效率下降\",{\"2\":{\"1331\":1}}],[\"避免因选择策略不当导致价值估计偏差\",{\"2\":{\"806\":1}}],[\"避免因低精度导致的舍入误差和梯度下溢\",{\"2\":{\"462\":1}}],[\"避免目标不断变化导致训练不稳定\",{\"2\":{\"746\":1}}],[\"避免依赖低效的python库\",{\"2\":{\"568\":1}}],[\"避免oov\",{\"2\":{\"529\":1}}],[\"避免过于单一\",{\"2\":{\"2312\":1}}],[\"避免过拟合\",{\"2\":{\"2280\":1}}],[\"避免过度更新对好答案的不利影响\",{\"2\":{\"2068\":1}}],[\"避免过度更新\",{\"2\":{\"1857\":1}}],[\"避免过度解读指标的绝对值\",{\"2\":{\"834\":1}}],[\"避免过度优化导致效率低下\",{\"2\":{\"507\":1}}],[\"避免过大的更新\",{\"2\":{\"622\":1}}],[\"避免过大的值影响计算稳定性\",{\"2\":{\"239\":1}}],[\"避免侵犯版权\",{\"2\":{\"485\":1}}],[\"避免模型对单一来源的过度依赖\",{\"2\":{\"456\":1}}],[\"避免超出模型适配范围\",{\"2\":{\"269\":1}}],[\"避免新增维度\",{\"2\":{\"246\":1,\"292\":1}}],[\"避免了反复地从hbm中读写数据\",{\"2\":{\"2080\":1}}],[\"避免了传统模型中奖励模型固定不变的瓶颈\",{\"2\":{\"2026\":1}}],[\"避免了以前微调方法中几乎所有的准确性折衷\",{\"2\":{\"1735\":1}}],[\"避免了多语言编码差异问题\",{\"2\":{\"426\":1}}],[\"避免了灾难性性能下降\",{\"2\":{\"222\":1}}],[\"避免了直接外推导致的性能下降\",{\"2\":{\"180\":1}}],[\"避免解码过程中信息泄漏\",{\"2\":{\"167\":1}}],[\"避免梯度消失\",{\"2\":{\"2519\":1}}],[\"避免梯度过小导致模型训练困难\",{\"2\":{\"130\":1}}],[\"避免梯度爆炸或消失问题\",{\"2\":{\"435\":1}}],[\"避免梯度爆炸\",{\"2\":{\"121\":1,\"593\":1}}],[\"避免使用不完整上下文\",{\"2\":{\"2239\":1}}],[\"避免使用\",{\"2\":{\"27\":1,\"1542\":1}}],[\"避免全局使用\",{\"2\":{\"27\":1}}],[\"避免命名冲突\",{\"2\":{\"22\":1}}],[\"避免污染命名空间\",{\"2\":{\"22\":1}}],[\"提前在\",{\"2\":{\"2245\":1}}],[\"提醒\",{\"0\":{\"2209\":1}}],[\"提示链是一种有效的工作流方式\",{\"2\":{\"1760\":1}}],[\"提示链\",{\"0\":{\"1649\":1},\"1\":{\"1702\":1,\"1760\":1,\"1820\":1}}],[\"提示优化\",{\"2\":{\"1625\":1,\"1794\":1}}],[\"提示\",{\"0\":{\"2002\":1},\"2\":{\"1154\":1,\"1333\":3,\"2042\":1,\"2119\":1}}],[\"提示层\",{\"2\":{\"845\":1}}],[\"提示词应明确指出回答仅基于检索到的信息\",{\"2\":{\"2690\":1}}],[\"提示词\",{\"2\":{\"2687\":1}}],[\"提示词对模型行为的影响\",{\"0\":{\"2687\":1}}],[\"提示词设计的关键要点\",{\"0\":{\"2684\":1},\"1\":{\"2687\":1,\"2690\":1,\"2693\":1}}],[\"提示词可能包括一些示例输入和输出\",{\"2\":{\"670\":1}}],[\"提示词通常包括任务描述\",{\"2\":{\"670\":1}}],[\"提示词和示例\",{\"0\":{\"670\":1}}],[\"提示技术\",{\"0\":{\"450\":1},\"1\":{\"477\":1,\"504\":1,\"536\":1,\"569\":1,\"602\":1,\"636\":1,\"670\":1,\"708\":1,\"742\":1,\"773\":1,\"804\":1,\"838\":1,\"874\":1,\"910\":1,\"949\":1,\"991\":1,\"1032\":1,\"1075\":1,\"1122\":1,\"1173\":1,\"1222\":1,\"1273\":1,\"1322\":1,\"1368\":1,\"1413\":1,\"1459\":1,\"1504\":1,\"1550\":1,\"1600\":1},\"2\":{\"237\":1}}],[\"提到gpt使用的few\",{\"2\":{\"477\":1}}],[\"提高生成效率\",{\"2\":{\"2484\":1}}],[\"提高代码可读性和维护性\",{\"2\":{\"2471\":1}}],[\"提高代码复用性和灵活性\",{\"2\":{\"15\":1}}],[\"提高标注准确性\",{\"2\":{\"2409\":1}}],[\"提高种子数据的多样性\",{\"2\":{\"2409\":1}}],[\"提高模型性能\",{\"2\":{\"2692\":1}}],[\"提高模型推理性能与用户友好性方法探讨\",{\"0\":{\"2376\":1}}],[\"提高模型对长文本的处理能力\",{\"2\":{\"1307\":1}}],[\"提高用户可读性\",{\"2\":{\"2346\":1}}],[\"提高对话响应速度和用户体验\",{\"2\":{\"2166\":1}}],[\"提高强化学习的上限\",{\"2\":{\"2157\":1}}],[\"提高策略灵活性\",{\"2\":{\"2143\":1}}],[\"提高信息检索的准确性\",{\"2\":{\"2105\":1}}],[\"提高计算的精度和稳定性\",{\"2\":{\"1925\":1}}],[\"提高计算效率\",{\"2\":{\"1490\":1,\"2175\":1}}],[\"提高计算效率和准确性\",{\"2\":{\"747\":1}}],[\"提高检索准确性\",{\"2\":{\"1514\":1}}],[\"提高效率的预训练技巧\",{\"0\":{\"1389\":1}}],[\"提高训练的稳定性\",{\"2\":{\"1162\":1}}],[\"提高推理效率\",{\"2\":{\"889\":1,\"2115\":1}}],[\"提高了复杂场景下的表现能力\",{\"2\":{\"2499\":1}}],[\"提高了检索和生成的质量\",{\"2\":{\"2499\":1}}],[\"提高了索引内容质量\",{\"2\":{\"2499\":1}}],[\"提高了重要性权重的上裁剪阈值\",{\"2\":{\"2327\":1}}],[\"提高了训练效率\",{\"2\":{\"1967\":1}}],[\"提高了算法的实用性\",{\"2\":{\"766\":1}}],[\"提高了计算效率和性能\",{\"2\":{\"220\":1}}],[\"提高样本效率\",{\"2\":{\"712\":1}}],[\"提高垂域数据的精准度\",{\"2\":{\"532\":1}}],[\"提高算法效率\",{\"2\":{\"518\":1}}],[\"提高语言模型表现\",{\"2\":{\"434\":1}}],[\"提高灵活性\",{\"2\":{\"419\":1}}],[\"提高分词质量\",{\"2\":{\"419\":1}}],[\"提出的\",{\"2\":{\"1493\":1}}],[\"提出了迭代的检索生成方法\",{\"2\":{\"2570\":1}}],[\"提出了一个五级分类体系\",{\"2\":{\"1188\":1}}],[\"提出了一种结合llm推理和生成动作能力的方法\",{\"2\":{\"2011\":1}}],[\"提出了一种新的剪枝度量\",{\"2\":{\"1050\":1}}],[\"提出了一种名为\",{\"2\":{\"101\":1}}],[\"提出了针对高频和低频区域的差异化处理方法\",{\"2\":{\"386\":1}}],[\"提出机构\",{\"2\":{\"212\":1}}],[\"提升长样本在策略学习中的影响力\",{\"2\":{\"2612\":1,\"2665\":1}}],[\"提升长文本处理能力\",{\"2\":{\"534\":1}}],[\"提升深度学习模型的训练效果\",{\"0\":{\"2559\":1,\"2634\":1},\"1\":{\"2567\":1,\"2575\":1,\"2583\":1,\"2591\":1,\"2598\":1,\"2605\":1,\"2612\":1,\"2619\":1,\"2624\":1,\"2629\":1,\"2639\":1,\"2644\":1,\"2649\":1,\"2654\":1,\"2658\":1,\"2662\":1,\"2665\":1,\"2668\":1,\"2671\":1,\"2674\":1}}],[\"提升文本的一致性\",{\"2\":{\"2484\":1}}],[\"提升生成数据的质量\",{\"2\":{\"2409\":1}}],[\"提升可读性\",{\"2\":{\"2346\":1}}],[\"提升低概率token探索能力\",{\"0\":{\"2226\":1},\"1\":{\"2261\":1,\"2296\":1,\"2327\":1,\"2357\":1,\"2387\":1,\"2414\":1,\"2439\":1,\"2461\":1,\"2479\":1}}],[\"提升任务相关性\",{\"2\":{\"1989\":1}}],[\"提升回答质量与交互表现\",{\"2\":{\"1578\":1}}],[\"提升高质量数据使用比例\",{\"2\":{\"1526\":1}}],[\"提升其适用于中文任务的能力\",{\"2\":{\"1487\":1}}],[\"提升幅度\",{\"2\":{\"1178\":1}}],[\"提升策略优化效率\",{\"2\":{\"790\":1,\"2143\":1}}],[\"提升gpu的利用率\",{\"2\":{\"750\":1}}],[\"提升复杂任务的推理准确性\",{\"2\":{\"665\":1}}],[\"提升pdf解析的准确性\",{\"2\":{\"628\":1}}],[\"提升训练效率\",{\"2\":{\"567\":1,\"634\":1,\"983\":1,\"1023\":1}}],[\"提升了自然语言处理能力\",{\"2\":{\"898\":1}}],[\"提升了大模型的效率\",{\"2\":{\"664\":1}}],[\"提升了算法的稳定性和效率\",{\"2\":{\"521\":1}}],[\"提升了语言模型的表现力\",{\"2\":{\"308\":1}}],[\"提升解析准确性\",{\"2\":{\"465\":1}}],[\"提升模型对长序列的理解能力\",{\"2\":{\"1166\":1}}],[\"提升模型对不同波长嵌入的适配能力\",{\"2\":{\"412\":1}}],[\"提升模型性能\",{\"0\":{\"2677\":1},\"1\":{\"2680\":1,\"2683\":1,\"2686\":1,\"2689\":1,\"2692\":1,\"2695\":1,\"2698\":1,\"2701\":1},\"2\":{\"1112\":1,\"1966\":1}}],[\"提升模型性能与计算效率\",{\"2\":{\"248\":1}}],[\"提升模型的综合分析能力\",{\"2\":{\"869\":1}}],[\"提升模型的推理性能\",{\"0\":{\"825\":1}}],[\"提升模型的适配能力\",{\"2\":{\"184\":1}}],[\"提升模型处理长序列文本的表现\",{\"2\":{\"423\":1}}],[\"提升模型学习能力\",{\"2\":{\"169\":1}}],[\"提升模型推理效率\",{\"2\":{\"107\":1}}],[\"提升效率\",{\"2\":{\"168\":1}}],[\"提升用户体验\",{\"2\":{\"49\":1}}],[\"提升泛化能力\",{\"2\":{\"40\":1}}],[\"提取并存储文本中的核心信息\",{\"2\":{\"2675\":1}}],[\"提取关键错误信息\",{\"2\":{\"1740\":1}}],[\"提取重点段落\",{\"2\":{\"1067\":1}}],[\"提取其cls\",{\"2\":{\"910\":1}}],[\"提取最优策略\",{\"2\":{\"647\":2}}],[\"提取\",{\"2\":{\"39\":1}}],[\"提供经济高效的解决方案\",{\"2\":{\"2637\":1}}],[\"提供多样性和灵活性\",{\"2\":{\"2534\":1}}],[\"提供多智能体协作框架\",{\"2\":{\"1485\":1}}],[\"提供更专业和针对性的训练素材\",{\"2\":{\"2437\":1}}],[\"提供更高的抽象层次\",{\"2\":{\"20\":1}}],[\"提供稳定的训练过程\",{\"2\":{\"2372\":1}}],[\"提供的句子分割功能\",{\"2\":{\"2584\":1}}],[\"提供的文本内容\",{\"2\":{\"2120\":1}}],[\"提供的灵活配置选项\",{\"2\":{\"1542\":1}}],[\"提供奖励信号以指导策略优化\",{\"2\":{\"2004\":1}}],[\"提供动作后的回报\",{\"2\":{\"1992\":1,\"2045\":1}}],[\"提供保留和召回长期信息的能力\",{\"2\":{\"1833\":1}}],[\"提供训练信号并决定优化方向\",{\"2\":{\"1797\":1}}],[\"提供智能体行为轨迹的片段给人类进行比较\",{\"2\":{\"1586\":1}}],[\"提供对多种工具的访问\",{\"2\":{\"1569\":1}}],[\"提供一个类似系统期望的输入\",{\"2\":{\"1368\":2}}],[\"提供了以下特殊分块器\",{\"2\":{\"2640\":1}}],[\"提供了以下经典的规划算法\",{\"2\":{\"2378\":1}}],[\"提供了简单但通用的分布式编程抽象\",{\"2\":{\"2408\":1}}],[\"提供了一系列稳健规划方法\",{\"2\":{\"2405\":1}}],[\"提供了一种轻量级的模型微调方法\",{\"2\":{\"2179\":1}}],[\"提供了一种新的思维建模方式\",{\"2\":{\"2094\":1}}],[\"提供了一种新的优化思路\",{\"2\":{\"1996\":1}}],[\"提供了一种有效扩展巨型模型的方法\",{\"2\":{\"1317\":1}}],[\"提供了禁用dp和梯度累加平均的选项\",{\"2\":{\"2300\":1}}],[\"提供了训练接口\",{\"2\":{\"1719\":1}}],[\"提供了灵活的优化方式\",{\"2\":{\"1675\":1}}],[\"提供了灵活的多智能体协作方案\",{\"2\":{\"1300\":1}}],[\"提供了丰富的工具集\",{\"2\":{\"2702\":1}}],[\"提供了丰富的工具和模块\",{\"2\":{\"1347\":1}}],[\"提供了丰富的文本处理功能\",{\"2\":{\"1612\":1}}],[\"提供了上百个参数选项\",{\"2\":{\"1451\":1}}],[\"提供了强大的功能和灵活性\",{\"2\":{\"1347\":1}}],[\"提供了多智能体之间的高效协作机制\",{\"2\":{\"1300\":1}}],[\"提供了更多可学习的参数\",{\"2\":{\"1680\":1}}],[\"提供了更多的灵活性\",{\"2\":{\"20\":1}}],[\"提供了更全面的评估视角\",{\"2\":{\"1453\":1}}],[\"提供了更好的性能表现\",{\"2\":{\"1092\":1}}],[\"提供了\",{\"2\":{\"1065\":1,\"1763\":1}}],[\"提供几个示例输入和输出对\",{\"2\":{\"708\":1}}],[\"提供高质量知识内容\",{\"2\":{\"535\":1}}],[\"提供完整的编码流程\",{\"2\":{\"373\":1}}],[\"提供分布式训练接口\",{\"2\":{\"65\":1}}],[\"而标准attention需要存储\",{\"2\":{\"2648\":1}}],[\"而手动标注则不利于规模化\",{\"2\":{\"2642\":1}}],[\"而gelu是非线性的\",{\"2\":{\"2616\":1}}],[\"而gpt\",{\"2\":{\"1228\":1,\"1278\":1}}],[\"而gpt1仅使用了mask\",{\"2\":{\"1009\":1}}],[\"而当前实现的trl\",{\"2\":{\"2545\":1}}],[\"而当前主流的大模型训练集基本基于网络公开的数据\",{\"2\":{\"1423\":1}}],[\"而上下文对于理解语言意义至关重要\",{\"2\":{\"2511\":1}}],[\"而上采样矩阵\",{\"2\":{\"2062\":1}}],[\"而模型本身可能被\",{\"2\":{\"2433\":1}}],[\"而分块过小则可能丢失必要的上下文信息\",{\"2\":{\"2334\":1}}],[\"而评估者\",{\"2\":{\"2294\":1}}],[\"而优化器状态还需额外的\",{\"2\":{\"2281\":1}}],[\"而pandoc则适用于文档格式转换\",{\"2\":{\"2270\":1}}],[\"而pal方法则仅支持单个代码生成步骤\",{\"2\":{\"1788\":1}}],[\"而主题变化的伪多轮数据则选择性加入\",{\"2\":{\"2256\":1}}],[\"而另一个\",{\"2\":{\"2224\":1}}],[\"而另一些章节则较短\",{\"2\":{\"1513\":1}}],[\"而每处修改都需要根据上下文动态决定\",{\"2\":{\"2185\":1}}],[\"而每个\",{\"2\":{\"2108\":1}}],[\"而实际使用达到75gb\",{\"2\":{\"2170\":1}}],[\"而实际上它是基于共现频率\",{\"2\":{\"472\":1}}],[\"而更新参数时还需加上\",{\"2\":{\"2161\":1}}],[\"而价值模型可以生成低方差的估计\",{\"2\":{\"2157\":1}}],[\"而价值迭代则直接更新状态价值函数\",{\"2\":{\"621\":1}}],[\"而向量表示更加密集\",{\"2\":{\"2155\":1}}],[\"而顶点之间的依赖关系则被建模为边\",{\"2\":{\"2144\":1}}],[\"而在alpacaeval\",{\"2\":{\"2588\":1}}],[\"而在检索时只拿叶子节点和问题进行匹配\",{\"2\":{\"2271\":1}}],[\"而在参数更新阶段则转换为\",{\"2\":{\"2059\":1}}],[\"而在计算attention时可以高效地找到并获取那些块\",{\"2\":{\"750\":1}}],[\"而仅基于act\",{\"2\":{\"2011\":1}}],[\"而显存优化则需要从多方面着手\",{\"2\":{\"1972\":1}}],[\"而将稀有的词视为关键词\",{\"2\":{\"1949\":1}}],[\"而预训练模型参数保持固定\",{\"2\":{\"1873\":1}}],[\"而reward是环境自带的规则设计\",{\"2\":{\"1954\":1}}],[\"而reinforce++则提供了一种简单高效的方法来对齐大型语言模型\",{\"2\":{\"1783\":1}}],[\"而rnn位置编码虽然灵活且具有外推性\",{\"2\":{\"1131\":1}}],[\"而利用则强调使用现有的较优策略来获得稳定的收益\",{\"2\":{\"1765\":1}}],[\"而保持llm其他部分参数不变\",{\"2\":{\"1745\":1}}],[\"而大模型奖励模型仅针对整个响应提供一个奖励值\",{\"2\":{\"1634\":1}}],[\"而现有方法如逆强化学习和模仿学习在处理复杂行为时存在局限性\",{\"2\":{\"1633\":1}}],[\"而现实世界中的智能体应用通常涉及多轮交互\",{\"2\":{\"1453\":1}}],[\"而关于\",{\"2\":{\"1617\":1}}],[\"而一个完美的知识库是实现检索精准的关键\",{\"2\":{\"1609\":1}}],[\"而自我反思在其中发挥着至关重要的作用\",{\"2\":{\"1557\":1}}],[\"而以下几个因素都会对下游链路的结果产生重要影响\",{\"2\":{\"1450\":1}}],[\"而忽略了io读写的内存访问开销\",{\"2\":{\"1869\":1}}],[\"而忽略其方向性不足的问题\",{\"2\":{\"1343\":1}}],[\"而忽略掉\",{\"2\":{\"881\":1}}],[\"而压缩率过高会影响模型知识表达能力\",{\"2\":{\"1302\":1}}],[\"而低频部分主要用于捕捉全局信息\",{\"2\":{\"1296\":1}}],[\"而是模拟一种助手的行为\",{\"2\":{\"2363\":1}}],[\"而是检查训练代码是否有问题\",{\"2\":{\"2243\":1}}],[\"而是自由参数\",{\"2\":{\"1865\":1}}],[\"而是根据任务需求动态调整各层和参数类型的秩\",{\"2\":{\"1764\":1}}],[\"而是通过调整一些关键参数来优化训练效果\",{\"2\":{\"2177\":1}}],[\"而是通过在输入文本中添加特殊的\",{\"2\":{\"1752\":1}}],[\"而是通过智能体与环境交互生成数据\",{\"2\":{\"690\":1}}],[\"而是直接根据当前状态和动作给予奖励\",{\"2\":{\"1673\":1}}],[\"而是利用预先收集的离线数据集进行模拟学习\",{\"2\":{\"1667\":1}}],[\"而是用共享的随机权值初始化这些矩阵\",{\"2\":{\"1636\":1}}],[\"而是要找到\",{\"2\":{\"1377\":1}}],[\"而是更关心推荐内容是否总体上符合他们的兴趣\",{\"2\":{\"1377\":1}}],[\"而是建立了多个针对不同数据类型和查询需求的索引\",{\"2\":{\"1285\":1}}],[\"而新方法将其移除\",{\"2\":{\"1266\":1}}],[\"而输入embedding则使用标准正态分布初始化\",{\"2\":{\"1248\":1}}],[\"而输出则是相应任务的结果\",{\"2\":{\"978\":1}}],[\"而多级索引和多级路由机制的引入为这一过程提供了更强大的支持\",{\"2\":{\"1235\":1}}],[\"而子问题解决器则负责解决这些子问题\",{\"2\":{\"1224\":1}}],[\"而示例选择的问题与其类似\",{\"2\":{\"1173\":1}}],[\"而sft则是应用这些知识\",{\"2\":{\"1150\":1}}],[\"而sentencepiece和tokenizers库提供了高效\",{\"2\":{\"373\":1}}],[\"而黑盒知识蒸馏则有所不同\",{\"2\":{\"1124\":1}}],[\"而软件开发相关的agent甚至能够与计算机接口进行交互\",{\"2\":{\"1118\":1}}],[\"而独热编码通过将离散特征映射到欧式空间\",{\"2\":{\"1068\":1}}],[\"而最初的bert仅使用16gb的数据集\",{\"2\":{\"1052\":1}}],[\"而真实地形可能是多维的\",{\"2\":{\"1036\":1}}],[\"而言\",{\"2\":{\"981\":2}}],[\"而deepseek\",{\"2\":{\"934\":1,\"2642\":1}}],[\"而backward\",{\"2\":{\"1596\":1}}],[\"而bart没有\",{\"2\":{\"932\":1}}],[\"而bert使用的是16gb的数据集\",{\"2\":{\"933\":1}}],[\"而large模型则扩展到12层\",{\"2\":{\"932\":1}}],[\"而剪枝技术作为其中的一种方法\",{\"2\":{\"860\":1}}],[\"而且短文本的\",{\"2\":{\"847\":1}}],[\"而物理块可以根据新生成的token按需分配\",{\"2\":{\"750\":1}}],[\"而时序差分算法关注单步状态转移\",{\"2\":{\"672\":1}}],[\"而直接使用更高效的低精度训练\",{\"2\":{\"660\":1}}],[\"而a\",{\"2\":{\"653\":1}}],[\"而有监督学习则专注于静态数据集上模型的损失最小化\",{\"2\":{\"587\":1}}],[\"而无需编写冗长的样板代码\",{\"2\":{\"2055\":1}}],[\"而无需改变模型本身的参数\",{\"2\":{\"2032\":1}}],[\"而无需对llm架构进行修改或进行重新训练\",{\"2\":{\"1874\":1}}],[\"而无需真正更新模型参数\",{\"2\":{\"477\":1}}],[\"而无需重新训练整个模型\",{\"2\":{\"336\":1}}],[\"而非线性层涉及特定的函数计算\",{\"2\":{\"2526\":1}}],[\"而非外部的干预\",{\"2\":{\"2070\":1}}],[\"而非知识注入\",{\"2\":{\"1150\":1}}],[\"而非基于输入特征的动态路由\",{\"2\":{\"527\":1}}],[\"而非指令跟随能力或安全性等\",{\"2\":{\"457\":1}}],[\"而非所有网络\",{\"2\":{\"415\":1}}],[\"而非叠加位置编码\",{\"2\":{\"309\":1}}],[\"而非\",{\"2\":{\"275\":1}}],[\"而\",{\"2\":{\"221\":1,\"1006\":1,\"2129\":1,\"2145\":1,\"2603\":1}}],[\"而残差连接为梯度提供了一条\",{\"2\":{\"183\":1}}],[\"而梯度在这个过程中起到了关键作用\",{\"2\":{\"32\":1}}],[\"而具体的优化过程通常是通过\",{\"2\":{\"32\":1}}],[\"而不应包含任何其他主观推测\",{\"2\":{\"2690\":1}}],[\"而不存各块\",{\"2\":{\"2505\":1}}],[\"而不依赖外部调整\",{\"2\":{\"2169\":1}}],[\"而不依赖于少量示例\",{\"2\":{\"1275\":1}}],[\"而不偏好回答的概率会减少\",{\"2\":{\"1675\":1}}],[\"而不相似的样本彼此远离\",{\"2\":{\"1566\":1}}],[\"而不包含方向信息\",{\"2\":{\"1343\":1}}],[\"而不仅仅是输入层\",{\"2\":{\"1680\":1}}],[\"而不仅仅是成功与否\",{\"2\":{\"1544\":1}}],[\"而不仅仅是简单的输入\",{\"2\":{\"1224\":1}}],[\"而不仅仅是预测任务\",{\"2\":{\"760\":1}}],[\"而不考虑整体网络结构\",{\"2\":{\"931\":1}}],[\"而不需要额外的通信\",{\"2\":{\"2609\":1}}],[\"而不需要额外的训练\",{\"2\":{\"1104\":1}}],[\"而不需要重新训练整个模型\",{\"2\":{\"1983\":1}}],[\"而不需要sft过程\",{\"2\":{\"1146\":1}}],[\"而不需要学习状态转移模型\",{\"2\":{\"688\":1}}],[\"而不需要写\",{\"2\":{\"22\":1}}],[\"而不是偏离主题或提供无关信息\",{\"2\":{\"2574\":1}}],[\"而不是将其视为同一个概念进行总结\",{\"2\":{\"2493\":1}}],[\"而不是简单地减少计算量\",{\"2\":{\"2240\":1}}],[\"而不是预先编程设定的\",{\"2\":{\"2122\":1}}],[\"而不是预训练模型中的主要特征\",{\"2\":{\"1962\":1}}],[\"而不是近似计算\",{\"2\":{\"2057\":1}}],[\"而不是一次将数据复制四份存入内存\",{\"2\":{\"2055\":1}}],[\"而不是减少计算量\",{\"2\":{\"1957\":1}}],[\"而不是严格按照字符数进行切分\",{\"2\":{\"1652\":1}}],[\"而不是绝对数值分数\",{\"2\":{\"1491\":1}}],[\"而不是像简单启发式方法那样仅仅基于规则进行分割\",{\"2\":{\"1321\":1}}],[\"而不是改变参数的精度\",{\"2\":{\"729\":1}}],[\"而不是行为策略采样得到的\",{\"2\":{\"653\":1}}],[\"而不是依赖于显式的训练过程\",{\"2\":{\"536\":1}}],[\"而不是引入整个\",{\"2\":{\"27\":1}}],[\"而不必每次都写出完整的命名空间路径\",{\"2\":{\"10\":1}}],[\"而面向对象编程侧重数据和功能的封装\",{\"2\":{\"20\":1}}],[\"↩︎\",{\"2\":{\"18\":4}}],[\"v∈rn×d\",{\"2\":{\"2653\":1}}],[\"v∈rn×dk\",{\"2\":{\"2653\":1}}],[\"vndee\",{\"2\":{\"2345\":1}}],[\"vj​∈rbc​×d\",{\"2\":{\"2643\":1}}],[\"vj∈rbc×dp\",{\"2\":{\"2643\":1}}],[\"vj=torch\",{\"2\":{\"2597\":2}}],[\"vjv\",{\"2\":{\"2565\":1}}],[\"vj+1​\",{\"2\":{\"2528\":4}}],[\"vj+1\",{\"2\":{\"2528\":4}}],[\"vj\",{\"2\":{\"2286\":3,\"2539\":1,\"2565\":1,\"2597\":4,\"2611\":2}}],[\"vwv​\",{\"2\":{\"2164\":1,\"2636\":1}}],[\"vwk​\",{\"2\":{\"1870\":1}}],[\"vlm\",{\"2\":{\"1948\":1}}],[\"vllm是一个开源的大模型推理加速框架\",{\"2\":{\"1808\":1}}],[\"vllm拿到sample\",{\"2\":{\"812\":1}}],[\"vllm\",{\"0\":{\"1748\":1,\"1808\":1},\"1\":{\"1808\":1,\"1870\":2,\"1927\":2,\"1978\":2},\"2\":{\"193\":1,\"2081\":2,\"2129\":6}}],[\"v中\",{\"2\":{\"1870\":1}}],[\"vxk​\",{\"2\":{\"1870\":2}}],[\"v追加到kv\",{\"2\":{\"1782\":1}}],[\"v维度则为\",{\"2\":{\"1782\":1}}],[\"v维度均为\",{\"2\":{\"1782\":1}}],[\"v导致算力浪费\",{\"2\":{\"1782\":1}}],[\"v将被保留在显存中\",{\"2\":{\"1782\":1}}],[\"vvv\",{\"2\":{\"1770\":1}}],[\"vtv\",{\"2\":{\"1541\":1}}],[\"v$$\",{\"2\":{\"1405\":1,\"1452\":1,\"1593\":1}}],[\"v∗\",{\"2\":{\"767\":8}}],[\"v^\",{\"2\":{\"656\":2,\"767\":4}}],[\"vπ​\",{\"2\":{\"732\":2,\"748\":1,\"810\":2}}],[\"vπ\",{\"2\":{\"656\":4,\"732\":2,\"748\":1,\"810\":2}}],[\"vk​\",{\"2\":{\"647\":1}}],[\"vk\",{\"2\":{\"647\":1,\"2653\":2}}],[\"vk+1​\",{\"2\":{\"647\":1}}],[\"vk+1\",{\"2\":{\"647\":1}}],[\"vision\",{\"2\":{\"1948\":1}}],[\"virtual\",{\"0\":{\"2697\":1},\"2\":{\"1912\":2,\"2697\":1}}],[\"via\",{\"0\":{\"1368\":1,\"1588\":1},\"2\":{\"632\":1,\"1902\":1}}],[\"view\",{\"2\":{\"324\":3,\"619\":3,\"640\":4,\"766\":3,\"820\":1,\"1912\":1,\"2417\":3}}],[\"voyager对比了react\",{\"2\":{\"2277\":1}}],[\"voyager主要包含以下三个部分\",{\"2\":{\"2277\":1}}],[\"voyager\",{\"0\":{\"2277\":1}}],[\"voting\",{\"2\":{\"2037\":1}}],[\"vote\",{\"0\":{\"561\":1},\"2\":{\"2042\":1}}],[\"von\",{\"2\":{\"1458\":3}}],[\"vowel\",{\"2\":{\"783\":5}}],[\"vocab\",{\"2\":{\"391\":4,\"996\":3,\"1025\":6,\"1703\":9}}],[\"vocabulary\",{\"2\":{\"308\":1,\"498\":1,\"529\":1}}],[\"void\",{\"2\":{\"10\":4,\"11\":3,\"12\":1}}],[\"v交互\",{\"2\":{\"187\":1}}],[\"v缓存\",{\"2\":{\"187\":1}}],[\"v3\",{\"0\":{\"884\":1},\"1\":{\"920\":1,\"957\":1,\"998\":1,\"1038\":1,\"1081\":1,\"1127\":1,\"1178\":1,\"1227\":1,\"1277\":1,\"1324\":1},\"2\":{\"172\":1,\"837\":1,\"920\":1,\"1146\":1,\"1178\":1,\"1324\":1,\"2504\":1,\"2580\":1}}],[\"v100\",{\"2\":{\"2313\":1}}],[\"v1在性能和推理成本上取得了显著平衡\",{\"2\":{\"1287\":1}}],[\"v1基于llama架构\",{\"2\":{\"1002\":1}}],[\"v1是基于llama架构的开源语言模型\",{\"2\":{\"960\":1}}],[\"v1\",{\"0\":{\"885\":1},\"1\":{\"922\":1,\"960\":1,\"1002\":1,\"1043\":1,\"1087\":1,\"1134\":1,\"1186\":1,\"1236\":1,\"1287\":1},\"2\":{\"172\":1}}],[\"v向量并缓存\",{\"2\":{\"187\":1}}],[\"v向量并完成attention\",{\"2\":{\"166\":1}}],[\"v向量\",{\"2\":{\"166\":1}}],[\"verify\",{\"0\":{\"2501\":1},\"1\":{\"2514\":1,\"2525\":1},\"2\":{\"2514\":1,\"2554\":1}}],[\"verification\",{\"2\":{\"1146\":1,\"2277\":1}}],[\"verifier\",{\"2\":{\"528\":1}}],[\"very\",{\"2\":{\"1458\":1}}],[\"vera通过共享权值和简化微调过程\",{\"2\":{\"2025\":1}}],[\"vera通过将所有层中的矩阵a和b初始化为相同的随机权值\",{\"2\":{\"1746\":1}}],[\"vera只需训练两个新的向量d和b\",{\"2\":{\"1804\":1}}],[\"vera的创新机制\",{\"0\":{\"1746\":1}}],[\"vera不直接训练矩阵a和b\",{\"2\":{\"1636\":1}}],[\"vera\",{\"0\":{\"1583\":1},\"1\":{\"1636\":1,\"1690\":1,\"1746\":1,\"1804\":1,\"1866\":1,\"1923\":1,\"1975\":1,\"2025\":1,\"2075\":1},\"2\":{\"151\":1,\"1583\":1,\"1636\":1}}],[\"vectors\",{\"2\":{\"996\":1,\"1883\":1}}],[\"vector\",{\"2\":{\"47\":3,\"762\":3,\"769\":1,\"981\":1,\"1022\":1,\"1111\":4,\"1261\":1,\"1636\":1,\"1982\":1,\"2666\":1}}],[\"v2引入了通信平衡损失\",{\"2\":{\"1030\":1}}],[\"v2是一种新的语言模型架构\",{\"2\":{\"989\":1}}],[\"v2\",{\"0\":{\"872\":1,\"1625\":1},\"1\":{\"908\":1,\"947\":1,\"989\":1,\"1030\":1,\"1073\":1,\"1120\":1,\"1171\":1,\"1220\":1,\"1271\":1,\"1318\":1,\"1364\":1,\"1680\":1,\"1736\":1,\"1794\":1,\"1856\":1,\"1912\":1,\"1965\":1,\"2017\":1},\"2\":{\"151\":1,\"172\":1,\"873\":1,\"908\":1,\"1178\":1,\"1364\":1,\"1625\":1,\"1680\":2,\"1912\":1,\"2017\":2}}],[\"vanderplas\",{\"2\":{\"302\":1}}],[\"variance\",{\"2\":{\"1248\":1,\"1298\":1,\"2161\":1}}],[\"var\",{\"2\":{\"190\":1}}],[\"vapo通过准确训练的价值模型可以实现更高的性能上限\",{\"2\":{\"2054\":1}}],[\"vapo在aime\",{\"2\":{\"1955\":1}}],[\"vapo算法\",{\"0\":{\"1842\":1}}],[\"vapo\",{\"0\":{\"1724\":1},\"1\":{\"1781\":1,\"1842\":1,\"1900\":1,\"1955\":1,\"2005\":1,\"2054\":1,\"2107\":1,\"2157\":1,\"2200\":1,\"2239\":1,\"2274\":1,\"2307\":1,\"2338\":1,\"2368\":1},\"2\":{\"151\":1,\"1955\":1,\"2338\":1,\"2368\":1}}],[\"value=0\",{\"2\":{\"2539\":1,\"2589\":1}}],[\"valueloss\",{\"2\":{\"1817\":1}}],[\"valueloss类用于计算损失\",{\"2\":{\"1591\":1}}],[\"valueerror\",{\"2\":{\"917\":1}}],[\"valueiteration\",{\"2\":{\"647\":1}}],[\"valuenet\",{\"2\":{\"619\":1,\"766\":3}}],[\"values维度\",{\"2\":{\"1912\":1}}],[\"values\",{\"2\":{\"391\":1,\"640\":4,\"656\":4,\"1771\":4,\"1817\":9,\"1883\":1,\"1912\":5}}],[\"value\",{\"0\":{\"2054\":2,\"2107\":1},\"2\":{\"18\":1,\"112\":1,\"189\":3,\"724\":1,\"1582\":1,\"1645\":1,\"1902\":1,\"1955\":2,\"2043\":1,\"2286\":1,\"2378\":1,\"2405\":1,\"2433\":4}}],[\"v代表value向量\",{\"2\":{\"130\":1}}],[\"v\",{\"0\":{\"2054\":1},\"2\":{\"34\":2,\"107\":1,\"130\":2,\"135\":1,\"188\":1,\"189\":3,\"208\":4,\"213\":4,\"283\":1,\"608\":6,\"647\":12,\"654\":3,\"656\":10,\"732\":2,\"748\":2,\"767\":1,\"778\":3,\"810\":2,\"843\":4,\"941\":2,\"1266\":1,\"1359\":1,\"1535\":6,\"1591\":2,\"1992\":3,\"2045\":3,\"2080\":1,\"2286\":6,\"2306\":3,\"2528\":21,\"2539\":4,\"2565\":1,\"2611\":1,\"2618\":1,\"2643\":2,\"2653\":2,\"2660\":1,\"2676\":1}}],[\"vs\",{\"0\":{\"145\":1,\"227\":1,\"236\":1,\"257\":1,\"326\":1,\"610\":1,\"1163\":1,\"1259\":1},\"1\":{\"166\":1,\"187\":1},\"2\":{\"20\":3,\"1843\":1}}],[\"vscode\",{\"2\":{\"18\":1}}],[\"ωyω​\",{\"2\":{\"18\":2}}],[\"∂wi\",{\"2\":{\"622\":1}}],[\"∂ωr∂r​\",{\"2\":{\"18\":1}}],[\"∂r∂ωr\",{\"2\":{\"18\":1}}],[\"^i\",{\"2\":{\"2531\":2,\"2542\":2}}],[\"^tkt\",{\"2\":{\"2286\":1}}],[\"^m\",{\"2\":{\"1566\":1,\"1671\":2}}],[\"^v\",{\"2\":{\"1266\":1}}],[\"^k$$\",{\"2\":{\"1187\":1}}],[\"^k\",{\"2\":{\"1187\":2,\"1266\":1}}],[\"^2\",{\"2\":{\"640\":1,\"1591\":1,\"2012\":1}}],[\"^n\",{\"2\":{\"268\":1,\"503\":1,\"558\":1}}],[\"^first\",{\"2\":{\"18\":1}}],[\"^\",{\"2\":{\"18\":2,\"640\":1,\"757\":2,\"1127\":3,\"1227\":1,\"1266\":1,\"1279\":1,\"1359\":2,\"1364\":2,\"1455\":1,\"1628\":1,\"1644\":1,\"1671\":4,\"1685\":3,\"1901\":2,\"1925\":1,\"1942\":3,\"1993\":3,\"2013\":3,\"2033\":3,\"2080\":5,\"2085\":1,\"2124\":1,\"2137\":1,\"2140\":1,\"2485\":2,\"2528\":6,\"2531\":2,\"2542\":2,\"2577\":2,\"2643\":4,\"2653\":2}}],[\"^r\",{\"2\":{\"18\":2}}],[\"y∣\",{\"2\":{\"2289\":2}}],[\"y∣x1​\",{\"2\":{\"1142\":1}}],[\"y∣x1\",{\"2\":{\"1142\":1}}],[\"y∣x\",{\"2\":{\"614\":6,\"1552\":4,\"1566\":2,\"1657\":12,\"1685\":4,\"1712\":6,\"1720\":4,\"1830\":8,\"1889\":8,\"1944\":8,\"1994\":4}}],[\"y2y\",{\"2\":{\"2609\":1}}],[\"y2​\",{\"2\":{\"2609\":1}}],[\"y2​∣x\",{\"2\":{\"2046\":2}}],[\"y2\",{\"2\":{\"2609\":1}}],[\"y2∣x\",{\"2\":{\"2046\":2}}],[\"y=gelu\",{\"2\":{\"2587\":2,\"2602\":2}}],[\"y=xay\",{\"2\":{\"2526\":1}}],[\"y=k⋅x+b\",{\"2\":{\"2145\":1}}],[\"y=k⋅x+by\",{\"2\":{\"2145\":1}}],[\"y=kx+b\",{\"2\":{\"513\":1}}],[\"y=kx+by\",{\"2\":{\"513\":1}}],[\"y=i=0∑n−1​softmax\",{\"2\":{\"2140\":1}}],[\"y=∑i=0n−1softmax\",{\"2\":{\"2140\":1}}],[\"y=\",{\"2\":{\"2033\":2}}],[\"yji∣xi\",{\"2\":{\"1901\":1}}],[\"yji​∣xi​\",{\"2\":{\"1901\":1}}],[\"yji​\",{\"2\":{\"1901\":2}}],[\"yji\",{\"2\":{\"1901\":2}}],[\"y∑​π∗\",{\"2\":{\"1889\":1}}],[\"y−\",{\"2\":{\"1727\":2}}],[\"y+≻y−\",{\"2\":{\"1727\":2}}],[\"y+\",{\"2\":{\"1727\":2}}],[\"y分别表示prompt和response\",{\"2\":{\"1666\":1}}],[\"yx\",{\"2\":{\"1666\":2}}],[\"yang\",{\"2\":{\"1658\":1}}],[\"yarn是否也能有效提升性能\",{\"2\":{\"300\":1}}],[\"yarn提供了一个经验公式来选择温度参数\",{\"2\":{\"276\":1}}],[\"yarn\",{\"2\":{\"142\":1,\"163\":1,\"740\":1,\"1156\":1}}],[\"yarn方法解析\",{\"0\":{\"122\":1},\"1\":{\"142\":1,\"163\":1,\"184\":1,\"206\":1,\"228\":1,\"252\":1,\"276\":1,\"300\":1,\"322\":1,\"346\":1,\"372\":1},\"2\":{\"5\":1,\"84\":1}}],[\"yl∣x\",{\"2\":{\"1795\":2}}],[\"yly\",{\"2\":{\"1582\":1}}],[\"yl​∣x\",{\"2\":{\"1795\":2}}],[\"yl​\",{\"2\":{\"1582\":2,\"1795\":1}}],[\"yl\",{\"2\":{\"1582\":2,\"1795\":1}}],[\"yw∣x\",{\"2\":{\"1795\":4}}],[\"ywy\",{\"2\":{\"1582\":1}}],[\"yw​∣x\",{\"2\":{\"1795\":4}}],[\"yw​\",{\"2\":{\"1582\":3,\"1795\":1}}],[\"yw\",{\"2\":{\"1582\":3,\"1795\":1}}],[\"y|x\",{\"2\":{\"1552\":2,\"1566\":1,\"1657\":6,\"1712\":3,\"1830\":4,\"1889\":4,\"1944\":4,\"1994\":2}}],[\"yyy\",{\"2\":{\"1536\":1,\"2140\":1,\"2289\":1}}],[\"yifan\",{\"2\":{\"1658\":1}}],[\"yi​\",{\"2\":{\"773\":1,\"1222\":1}}],[\"yi\",{\"2\":{\"773\":1,\"1222\":1}}],[\"yki​\",{\"2\":{\"1901\":2}}],[\"yki\",{\"2\":{\"1901\":2}}],[\"yk​\",{\"2\":{\"773\":1}}],[\"yk\",{\"2\":{\"773\":1}}],[\"y1y\",{\"2\":{\"2609\":1}}],[\"y1∣x\",{\"2\":{\"2046\":4}}],[\"y1≻y2∣x\",{\"2\":{\"2046\":1}}],[\"y1​∣x\",{\"2\":{\"2046\":4}}],[\"y1​≻y2​∣x\",{\"2\":{\"2046\":1}}],[\"y1​\",{\"2\":{\"773\":1,\"2609\":1}}],[\"y1\",{\"2\":{\"773\":1,\"2609\":1}}],[\"yeah\",{\"0\":{\"2195\":1}}],[\"yes\",{\"2\":{\"1360\":2}}],[\"yeungnlp\",{\"2\":{\"741\":1}}],[\"yet\",{\"2\":{\"163\":1}}],[\"y∼π​\",{\"2\":{\"614\":1,\"1552\":1,\"1666\":1,\"1720\":1}}],[\"y∼π\",{\"2\":{\"614\":1,\"1552\":1,\"1666\":1,\"1720\":1}}],[\"yoshua\",{\"2\":{\"165\":1}}],[\"your\",{\"2\":{\"1814\":1,\"1902\":1,\"2434\":1}}],[\"you\",{\"2\":{\"18\":1,\"230\":1,\"508\":2}}],[\"y\",{\"2\":{\"18\":2,\"190\":1,\"355\":2,\"537\":3,\"614\":11,\"773\":5,\"1142\":1,\"1222\":1,\"1393\":1,\"1536\":7,\"1552\":7,\"1582\":5,\"1634\":3,\"1657\":5,\"1666\":7,\"1676\":3,\"1685\":8,\"1712\":4,\"1720\":6,\"1732\":3,\"1787\":3,\"1795\":8,\"1830\":8,\"1889\":8,\"1901\":5,\"1922\":2,\"1994\":6,\"2046\":8,\"2140\":1,\"2289\":1,\"2520\":3,\"2532\":3,\"2537\":3,\"2587\":1,\"2602\":1,\"2609\":2}}],[\"y^+\",{\"2\":{\"1727\":2}}],[\"y^​k+1​\",{\"2\":{\"773\":1}}],[\"y^k+1\",{\"2\":{\"773\":1}}],[\"y^\",{\"2\":{\"18\":2,\"1727\":2}}],[\"yωω\",{\"2\":{\"18\":2}}],[\"~\",{\"2\":{\"18\":1}}],[\"−bθ​\",{\"2\":{\"2531\":1,\"2542\":1}}],[\"−bθ\",{\"2\":{\"2531\":1,\"2542\":1}}],[\"−m\",{\"2\":{\"2030\":8,\"2528\":7}}],[\"−m−11​k=j∑​r\",{\"2\":{\"1901\":1}}],[\"−logz\",{\"2\":{\"1944\":1}}],[\"−log⁡z\",{\"2\":{\"1830\":1,\"1944\":1}}],[\"−λmax\",{\"2\":{\"1795\":1}}],[\"−λmax⁡\",{\"2\":{\"1795\":1}}],[\"−0\",{\"2\":{\"1740\":1}}],[\"−trt\",{\"2\":{\"757\":2}}],[\"−β⋅\",{\"2\":{\"1732\":2}}],[\"−β⋅kl\",{\"2\":{\"1676\":2}}],[\"−βdkl​\",{\"2\":{\"1552\":1,\"1628\":1,\"1720\":1,\"2485\":1}}],[\"−βdkl\",{\"2\":{\"1552\":1,\"1628\":1,\"1720\":1,\"2485\":1}}],[\"−βlog\",{\"2\":{\"1685\":1}}],[\"−βlog⁡\",{\"2\":{\"1685\":1}}],[\"−βlog⁡πθ\",{\"2\":{\"1795\":1}}],[\"−βlog⁡π\",{\"2\":{\"1657\":1}}],[\"−βlog⁡πref\",{\"2\":{\"614\":1,\"2046\":1}}],[\"−βlogπref​\",{\"2\":{\"1657\":1}}],[\"−βlogπ\",{\"2\":{\"614\":1}}],[\"−βkl\",{\"2\":{\"537\":2}}],[\"−q\",{\"2\":{\"611\":2,\"640\":2,\"672\":2,\"710\":2}}],[\"−v\",{\"2\":{\"608\":2}}],[\"−n1​i=1∑n​logp\",{\"2\":{\"268\":1,\"558\":1}}],[\"−1exp\",{\"2\":{\"2528\":1}}],[\"−1exp⁡\",{\"2\":{\"2528\":1}}],[\"−1m−1∑k≠jr\",{\"2\":{\"1901\":1}}],[\"−1βr\",{\"2\":{\"1712\":1}}],[\"−1n∑i=1nlog⁡p\",{\"2\":{\"268\":1,\"558\":1}}],[\"−1\",{\"2\":{\"18\":2,\"215\":2,\"1246\":2,\"1296\":2,\"1712\":1,\"1740\":1,\"2033\":2,\"2528\":10}}],[\"−\",{\"2\":{\"18\":2,\"640\":2}}],[\"e​\",{\"2\":{\"2673\":1}}],[\"e∑\",{\"2\":{\"2673\":1}}],[\"e−m\",{\"2\":{\"2528\":2}}],[\"e−1+e0\",{\"2\":{\"2176\":2}}],[\"e−1\",{\"2\":{\"2176\":4}}],[\"e0\",{\"2\":{\"2176\":4}}],[\"e2−2\",{\"2\":{\"2176\":2}}],[\"e1−2\",{\"2\":{\"2176\":2}}],[\"equations\",{\"2\":{\"2050\":1}}],[\"eft\",{\"2\":{\"1867\":1}}],[\"efficiency\",{\"2\":{\"2449\":1}}],[\"efficient\",{\"0\":{\"1588\":1,\"2008\":1},\"2\":{\"101\":1,\"740\":1,\"1261\":1,\"1310\":1,\"1354\":1,\"1364\":1,\"1658\":2,\"2202\":1,\"2229\":1,\"2253\":1,\"2265\":1,\"2275\":1,\"2368\":1}}],[\"effective\",{\"2\":{\"740\":1,\"2229\":1,\"2265\":1}}],[\"et\",{\"2\":{\"1658\":5}}],[\"eta$$\",{\"2\":{\"1344\":1}}],[\"eta\",{\"2\":{\"1344\":3,\"1891\":2}}],[\"ey∼π\",{\"2\":{\"1657\":2,\"1712\":2,\"1830\":1}}],[\"europe\",{\"2\":{\"1458\":1}}],[\"european\",{\"2\":{\"1458\":1}}],[\"eggs\",{\"2\":{\"1458\":2}}],[\"each\",{\"2\":{\"2433\":1}}],[\"earliest\",{\"2\":{\"1458\":2}}],[\"easter\",{\"2\":{\"1458\":8}}],[\"e×s×k×capacity\",{\"2\":{\"1455\":2}}],[\"e∼n\",{\"2\":{\"1437\":2}}],[\"economical\",{\"2\":{\"1364\":1}}],[\"e4\",{\"2\":{\"1329\":2}}],[\"e9\",{\"2\":{\"1329\":2}}],[\"emoji\",{\"2\":{\"2245\":1}}],[\"em\",{\"2\":{\"2030\":4,\"2528\":4}}],[\"emphasis\",{\"2\":{\"1368\":1}}],[\"emd\",{\"2\":{\"1237\":1}}],[\"emb\",{\"2\":{\"1127\":3,\"1868\":1}}],[\"embedding权重时\",{\"2\":{\"2656\":1}}],[\"embedding计算一次梯度\",{\"2\":{\"2656\":1}}],[\"embedding拆分到各个gpu上\",{\"2\":{\"2651\":1}}],[\"embedding两部分\",{\"2\":{\"2651\":1}}],[\"embedding和positional\",{\"2\":{\"2651\":1}}],[\"embedding切分策略\",{\"0\":{\"2646\":1},\"1\":{\"2651\":1,\"2656\":1}}],[\"embedding模型阶段\",{\"0\":{\"2659\":1},\"1\":{\"2663\":1}}],[\"embedding模型的核心任务是将文本转换为向量形式\",{\"2\":{\"2155\":1}}],[\"embedding模型\",{\"0\":{\"2155\":1},\"2\":{\"1950\":1}}],[\"embedding进行处理\",{\"2\":{\"1858\":1}}],[\"embedding序列\",{\"2\":{\"1796\":1}}],[\"embedding的输出向量\",{\"2\":{\"910\":1}}],[\"embedding\",{\"0\":{\"882\":1,\"955\":1,\"956\":1,\"1036\":1},\"1\":{\"918\":1,\"996\":1,\"1036\":1},\"2\":{\"247\":1,\"848\":1,\"882\":2,\"918\":2,\"938\":1,\"996\":4,\"1036\":3,\"1079\":1,\"1125\":1,\"1176\":3,\"1225\":2,\"1263\":1,\"1343\":1,\"1450\":2,\"1470\":3,\"1682\":1,\"1771\":2,\"1832\":3,\"1912\":6,\"2651\":2,\"2655\":1,\"2656\":2,\"2659\":1}}],[\"embed\",{\"2\":{\"135\":1,\"996\":3}}],[\"emergent\",{\"2\":{\"1008\":1,\"1124\":2}}],[\"eee\",{\"2\":{\"789\":1}}],[\"ee=1→e\",{\"2\":{\"775\":1}}],[\"e=1\",{\"2\":{\"1455\":1}}],[\"e=1e\",{\"2\":{\"789\":1}}],[\"e=1→ee\",{\"2\":{\"775\":1}}],[\"everyone\",{\"2\":{\"2201\":1}}],[\"everybody\",{\"2\":{\"302\":1}}],[\"eval\",{\"2\":{\"2233\":1,\"2384\":1}}],[\"evaluator和self\",{\"2\":{\"2113\":1}}],[\"evaluator\",{\"0\":{\"2224\":1},\"2\":{\"2089\":1,\"2113\":1,\"2224\":1,\"2259\":1,\"2325\":2}}],[\"evaluation\",{\"2\":{\"656\":2,\"1867\":1}}],[\"evals\",{\"2\":{\"2037\":1}}],[\"evolution\",{\"0\":{\"1968\":1}}],[\"evolved\",{\"2\":{\"1458\":1}}],[\"evidence\",{\"2\":{\"1458\":3}}],[\"epoch设置\",{\"2\":{\"2217\":1}}],[\"epoch\",{\"2\":{\"2201\":1,\"2319\":1}}],[\"epoch=25\",{\"2\":{\"1208\":1}}],[\"epochs\",{\"2\":{\"575\":1,\"766\":3,\"1186\":2,\"2233\":1}}],[\"episode\",{\"2\":{\"843\":3}}],[\"episodes\",{\"2\":{\"843\":2}}],[\"eps\",{\"2\":{\"766\":3,\"1622\":5,\"1817\":6}}],[\"epsilon=1e^\",{\"2\":{\"1204\":1}}],[\"epsilonϵ值对模型性能的影响\",{\"2\":{\"1852\":1}}],[\"epsilonϵ取0到1之间的值\",{\"2\":{\"1622\":1}}],[\"epsilonϵ\",{\"2\":{\"775\":1,\"2479\":1}}],[\"epsilon\",{\"2\":{\"590\":2,\"640\":2,\"646\":5,\"840\":4,\"1622\":2,\"1628\":2,\"2044\":2,\"2097\":2,\"2327\":3,\"2485\":2,\"2524\":1,\"2539\":1,\"2597\":1}}],[\"epsilon$$以适应不同的环境\",{\"2\":{\"754\":1}}],[\"epsilon$$的调整\",{\"2\":{\"720\":1}}],[\"epsilon$$来控制两者的比例\",{\"2\":{\"646\":1}}],[\"epsilon$$\",{\"2\":{\"577\":1,\"593\":1,\"646\":2,\"656\":1,\"681\":1}}],[\"ep​\",{\"2\":{\"623\":1}}],[\"ep\",{\"2\":{\"623\":1,\"1410\":1,\"1502\":1}}],[\"error中学习仍然是一个很大的挑战\",{\"2\":{\"2113\":1}}],[\"errors\",{\"2\":{\"1594\":2}}],[\"error更新critic模型\",{\"2\":{\"1699\":1}}],[\"error更新\",{\"2\":{\"1591\":1}}],[\"error进行更新\",{\"2\":{\"1541\":1}}],[\"error\",{\"2\":{\"572\":1,\"646\":2,\"1645\":1}}],[\"eric\",{\"2\":{\"302\":1}}],[\"estimation\",{\"0\":{\"570\":1},\"2\":{\"1261\":1}}],[\"essentials\",{\"2\":{\"302\":1}}],[\"eos标记符\",{\"2\":{\"1249\":1}}],[\"eos\",{\"2\":{\"537\":3,\"1249\":1,\"1782\":1,\"2500\":3}}],[\"ell\",{\"2\":{\"1671\":1}}],[\"eleutherai\",{\"2\":{\"741\":1}}],[\"elu\",{\"0\":{\"285\":1},\"2\":{\"311\":1,\"330\":1}}],[\"else\",{\"2\":{\"48\":1,\"640\":1,\"646\":1,\"647\":1,\"656\":1,\"840\":1,\"1582\":1,\"1731\":1,\"1817\":1,\"1832\":1,\"1883\":1,\"1912\":2,\"1984\":2}}],[\"e\",{\"2\":{\"190\":1,\"381\":1,\"470\":1,\"497\":1,\"586\":1,\"590\":1,\"614\":3,\"623\":1,\"655\":2,\"748\":2,\"757\":1,\"779\":2,\"783\":1,\"1119\":6,\"1225\":2,\"1437\":1,\"1455\":4,\"1456\":1,\"1458\":1,\"1536\":1,\"1552\":1,\"1582\":1,\"1628\":1,\"1634\":1,\"1657\":3,\"1666\":1,\"1685\":2,\"1712\":2,\"1720\":1,\"1727\":1,\"1795\":1,\"1830\":2,\"1883\":1,\"1942\":1,\"1944\":1,\"1993\":1,\"2044\":1,\"2097\":1,\"2306\":1,\"2485\":1,\"2577\":1,\"2667\":3,\"2670\":3,\"2673\":4}}],[\"einsum\",{\"2\":{\"189\":2,\"2539\":1,\"2581\":3,\"2597\":3}}],[\"executed\",{\"2\":{\"2433\":1}}],[\"exemplars\",{\"2\":{\"1766\":1}}],[\"exact\",{\"0\":{\"2057\":1},\"2\":{\"2275\":1}}],[\"examples即可泛化到新任务实例\",{\"2\":{\"2011\":1}}],[\"examples\",{\"2\":{\"1368\":2}}],[\"example\",{\"2\":{\"485\":1,\"917\":1,\"2500\":2}}],[\"exclude\",{\"2\":{\"2050\":1}}],[\"excel表格\",{\"2\":{\"2001\":1}}],[\"extract\",{\"2\":{\"485\":1,\"1193\":1,\"2050\":1}}],[\"extension\",{\"2\":{\"163\":1,\"740\":1}}],[\"ex−1\",{\"2\":{\"285\":2}}],[\"exponential\",{\"2\":{\"2217\":1}}],[\"exported\",{\"2\":{\"1458\":1}}],[\"exp⁡\",{\"2\":{\"1582\":2,\"1634\":2,\"1671\":1,\"1830\":2,\"1889\":2,\"1925\":1,\"2046\":1,\"2528\":5}}],[\"exp⁡∑r^\",{\"2\":{\"1536\":1}}],[\"exp∑r^\",{\"2\":{\"1536\":1}}],[\"explanation\",{\"2\":{\"1458\":2}}],[\"explore\",{\"2\":{\"559\":1}}],[\"expert\",{\"2\":{\"1170\":1,\"1229\":3,\"1409\":2,\"1936\":2,\"2050\":1,\"2608\":1}}],[\"expert与溢出处理\",{\"2\":{\"1119\":1}}],[\"experts​\",{\"2\":{\"1229\":1}}],[\"expertstokens\",{\"2\":{\"1229\":1}}],[\"experts模型通过将大型模型分解为多个\",{\"2\":{\"1031\":1}}],[\"expertscore\",{\"2\":{\"998\":1}}],[\"experts\",{\"2\":{\"415\":1,\"1040\":1,\"1229\":1,\"1364\":1,\"1365\":1,\"1658\":1,\"1936\":5,\"2140\":1}}],[\"exp\",{\"2\":{\"213\":2,\"268\":1,\"332\":1,\"558\":1,\"1435\":1,\"1536\":3,\"1582\":5,\"1622\":1,\"1634\":5,\"1671\":4,\"1830\":4,\"1889\":4,\"1925\":2,\"2046\":4,\"2528\":12,\"2539\":1,\"2561\":3,\"2597\":3,\"2604\":6,\"2618\":6}}],[\"expressions\",{\"2\":{\"1367\":1}}],[\"expression\",{\"2\":{\"18\":1}}],[\"exists\",{\"2\":{\"189\":1}}],[\"e^0l1​=∑f1​=e−1+e0\",{\"2\":{\"2176\":1}}],[\"e^0\",{\"2\":{\"2176\":3}}],[\"e^x\",{\"2\":{\"285\":1}}],[\"e^\",{\"2\":{\"90\":1,\"164\":1,\"194\":1,\"215\":4,\"1925\":2,\"2030\":4,\"2176\":6,\"2528\":6}}],[\"edit\",{\"0\":{\"2501\":1},\"1\":{\"2514\":1,\"2525\":1},\"2\":{\"2514\":1,\"2554\":1}}],[\"edx\",{\"2\":{\"67\":1,\"106\":1,\"302\":1}}],[\"edward\",{\"2\":{\"67\":1,\"1658\":1}}],[\"ewan\",{\"2\":{\"67\":1}}],[\"enhancing\",{\"2\":{\"2449\":1}}],[\"enhanced\",{\"2\":{\"1088\":1,\"1237\":1}}],[\"entropy即可\",{\"2\":{\"2660\":1}}],[\"entropy切分的基本流程\",{\"0\":{\"2660\":1}}],[\"entropy\",{\"0\":{\"2673\":1},\"2\":{\"2201\":1,\"2378\":1,\"2598\":1,\"2658\":1,\"2673\":1}}],[\"entities\",{\"2\":{\"1458\":1}}],[\"entity\",{\"2\":{\"1458\":1}}],[\"entire\",{\"2\":{\"1458\":1}}],[\"ensembling\",{\"0\":{\"1930\":1},\"2\":{\"1930\":1,\"2219\":1}}],[\"ensuring\",{\"2\":{\"1458\":1}}],[\"en\",{\"2\":{\"873\":1}}],[\"envs\",{\"2\":{\"2347\":3}}],[\"env\",{\"2\":{\"647\":6,\"656\":15}}],[\"enabled\",{\"2\":{\"1832\":2}}],[\"enable\",{\"2\":{\"526\":3,\"1928\":1}}],[\"enc\",{\"2\":{\"332\":6}}],[\"encode\",{\"2\":{\"391\":1,\"426\":1,\"1912\":2}}],[\"encoder在不同任务中的应用\",{\"2\":{\"2019\":1}}],[\"encoder端增加前缀是为了引导输入部分的编码\",{\"2\":{\"1922\":1}}],[\"encoder和decoder都增加了前缀\",{\"2\":{\"1922\":1}}],[\"encoder和针对示例编码的prompt\",{\"2\":{\"1075\":1}}],[\"encoder进行编码以加速收敛\",{\"2\":{\"1914\":1}}],[\"encoder类的定义\",{\"2\":{\"1912\":1}}],[\"encoder来表征伪标记\",{\"2\":{\"1796\":1}}],[\"encoder的引入\",{\"2\":{\"1796\":1}}],[\"encoder部分\",{\"2\":{\"1237\":1}}],[\"encoder与decoder的分工\",{\"0\":{\"1237\":1}}],[\"encoder中的self\",{\"0\":{\"146\":1}}],[\"encoder\",{\"0\":{\"316\":1,\"339\":1},\"2\":{\"34\":4,\"40\":2,\"93\":1,\"115\":1,\"363\":1,\"391\":2,\"560\":2,\"595\":3,\"919\":1,\"970\":1,\"1075\":1,\"1796\":1,\"2069\":1}}],[\"encoding\",{\"0\":{\"84\":1,\"274\":1,\"871\":1},\"1\":{\"297\":1,\"319\":1,\"342\":1,\"366\":1,\"392\":1,\"418\":1,\"443\":1,\"470\":1,\"497\":1,\"529\":1,\"562\":1,\"597\":1,\"631\":1},\"2\":{\"5\":2,\"174\":1,\"308\":1,\"319\":1,\"332\":2,\"368\":1,\"383\":1,\"393\":1,\"426\":1,\"933\":1,\"1025\":5,\"1096\":1,\"1302\":2,\"1435\":8}}],[\"encoding位置编码\",{\"2\":{\"5\":11}}],[\"encoding位置编码|positional\",{\"2\":{\"5\":1}}],[\"enumerate\",{\"2\":{\"324\":1,\"656\":1,\"1025\":1,\"1816\":1}}],[\"end\",{\"2\":{\"247\":2,\"285\":1,\"775\":2,\"1344\":1,\"1364\":1,\"1782\":1,\"1795\":1,\"2537\":2}}],[\"endl\",{\"2\":{\"10\":4,\"11\":3,\"12\":3,\"15\":2,\"22\":1,\"27\":3}}],[\"engineering\",{\"2\":{\"49\":1}}],[\"hnsw\",{\"0\":{\"2234\":1},\"2\":{\"2234\":3}}],[\"h0​\",{\"2\":{\"2121\":1}}],[\"h0\",{\"2\":{\"2121\":1}}],[\"hbm访问\",{\"2\":{\"2110\":1}}],[\"hbm带宽​\",{\"2\":{\"2014\":1}}],[\"hbm带宽\",{\"2\":{\"2014\":1}}],[\"hbm带宽模型参数量\",{\"2\":{\"2014\":1}}],[\"hf\",{\"2\":{\"2108\":1}}],[\"h系列gpu而言是吃不满算力的\",{\"2\":{\"1843\":1}}],[\"h∗hs\",{\"2\":{\"1782\":4}}],[\"hs\",{\"2\":{\"1782\":11}}],[\"hshshs\",{\"2\":{\"1782\":1}}],[\"hhh\",{\"2\":{\"1782\":1,\"2579\":2}}],[\"hyde\",{\"0\":{\"1717\":1},\"2\":{\"1717\":1}}],[\"hypothesis\",{\"2\":{\"1458\":1}}],[\"ht\",{\"2\":{\"1364\":2}}],[\"https\",{\"2\":{\"469\":1,\"485\":1,\"559\":1,\"631\":1,\"1492\":1,\"1647\":1,\"1878\":1,\"1920\":1,\"2275\":3,\"2345\":2}}],[\"hop\",{\"2\":{\"2546\":1}}],[\"honesty\",{\"2\":{\"2194\":1}}],[\"horrison\",{\"2\":{\"1617\":1}}],[\"hot\",{\"2\":{\"1025\":2}}],[\"hot编码的缺陷\",{\"2\":{\"870\":1}}],[\"how\",{\"2\":{\"480\":1,\"508\":2}}],[\"home\",{\"2\":{\"18\":1}}],[\"hôw\",{\"2\":{\"480\":1}}],[\"héllò\",{\"2\":{\"480\":1}}],[\"human\",{\"2\":{\"1564\":1,\"1633\":1,\"1634\":1,\"1902\":2,\"1920\":1,\"1971\":1,\"2202\":1}}],[\"hu\",{\"2\":{\"444\":2,\"1658\":1}}],[\"hug\",{\"2\":{\"444\":3}}],[\"hugginggpt\",{\"2\":{\"1439\":1}}],[\"huggingface\",{\"0\":{\"1725\":1},\"1\":{\"1782\":1,\"1843\":1},\"2\":{\"193\":1,\"1439\":1}}],[\"hugging\",{\"2\":{\"65\":1,\"230\":1,\"375\":1,\"1569\":1,\"2351\":1,\"2381\":1,\"2663\":1}}],[\"highly\",{\"2\":{\"2434\":1}}],[\"highlight\",{\"2\":{\"18\":1}}],[\"high\",{\"2\":{\"2327\":1}}],[\"higher的描述\",{\"2\":{\"2479\":1}}],[\"higher的作用\",{\"2\":{\"2327\":1}}],[\"higher在不同应用场景中的效果\",{\"2\":{\"2461\":1}}],[\"higher不仅提高了token生成的灵活性\",{\"2\":{\"2439\":1}}],[\"higher促进学习长推理过程和新的推理范式\",{\"2\":{\"2296\":1}}],[\"higher是一个技术改进方法\",{\"2\":{\"2296\":1}}],[\"higher\",{\"2\":{\"2261\":1}}],[\"higher技术改进\",{\"0\":{\"2226\":1},\"1\":{\"2261\":1,\"2296\":1,\"2327\":1,\"2357\":1,\"2387\":1,\"2414\":1,\"2439\":1,\"2461\":1,\"2479\":1}}],[\"hi​\",{\"2\":{\"2121\":3}}],[\"hi​=mlp\",{\"2\":{\"2121\":1}}],[\"hi=mlp\",{\"2\":{\"2121\":1}}],[\"hits\",{\"0\":{\"1933\":1}}],[\"hik−1​\",{\"2\":{\"1127\":1}}],[\"hik−1\",{\"2\":{\"1127\":1}}],[\"hi\",{\"2\":{\"1127\":2,\"2121\":3}}],[\"hierarchical\",{\"0\":{\"941\":1,\"2234\":1},\"2\":{\"980\":1,\"1023\":1}}],[\"hidden\",{\"2\":{\"266\":5,\"619\":4,\"766\":9,\"820\":5,\"1458\":1,\"1912\":3}}],[\"hallucination\",{\"2\":{\"2466\":1,\"2690\":1}}],[\"half\",{\"2\":{\"218\":3}}],[\"happen\",{\"2\":{\"2433\":1}}],[\"hard\",{\"0\":{\"1981\":1},\"2\":{\"1752\":1,\"1981\":1,\"2032\":1,\"2133\":1,\"2254\":1}}],[\"hare\",{\"2\":{\"1458\":5}}],[\"hares\",{\"2\":{\"1458\":4}}],[\"hashing\",{\"2\":{\"1559\":1}}],[\"hacking现象\",{\"2\":{\"2657\":1}}],[\"hacking问题\",{\"2\":{\"1633\":1}}],[\"hacking\",{\"2\":{\"1460\":1}}],[\"have\",{\"2\":{\"1458\":1}}],[\"hat\",{\"2\":{\"773\":2,\"1536\":7,\"2033\":2,\"2306\":1,\"2446\":4,\"2485\":2,\"2577\":1}}],[\"hands\",{\"2\":{\"106\":1}}],[\"h\",{\"2\":{\"67\":1,\"190\":2,\"259\":5,\"283\":2,\"444\":5,\"623\":4,\"1127\":2,\"1225\":2,\"1364\":1,\"1782\":11,\"2121\":5,\"2621\":1,\"2641\":1}}],[\"h2o\",{\"2\":{\"18\":1}}],[\"herd\",{\"2\":{\"1406\":1,\"2434\":1}}],[\"hessian\",{\"2\":{\"1143\":1}}],[\"he\",{\"2\":{\"562\":1,\"1458\":1}}],[\"hell\",{\"2\":{\"562\":1}}],[\"hello\",{\"2\":{\"11\":2,\"22\":1,\"27\":1,\"480\":1,\"508\":2,\"562\":1}}],[\"headers\",{\"2\":{\"2050\":1}}],[\"head层\",{\"2\":{\"1645\":1}}],[\"heads份\",{\"2\":{\"917\":1}}],[\"heads\",{\"0\":{\"2636\":1},\"2\":{\"917\":6,\"1912\":2,\"2218\":1}}],[\"head可以使用不同的\",{\"2\":{\"293\":1}}],[\"head\",{\"0\":{\"149\":1,\"212\":1,\"2571\":1},\"2\":{\"47\":3,\"48\":4,\"111\":2,\"1009\":2,\"1582\":1,\"1744\":1,\"1782\":2,\"2571\":1,\"2579\":1,\"2636\":2}}],[\"heading\",{\"0\":{\"3\":1,\"6\":1,\"9\":1,\"13\":1,\"18\":1},\"1\":{\"6\":1,\"9\":2,\"13\":3,\"18\":4}}],[\"6φ6\",{\"2\":{\"2369\":1}}],[\"663932651\",{\"2\":{\"2275\":1}}],[\"669926191\",{\"2\":{\"2275\":1}}],[\"6章节\",{\"2\":{\"1641\":1}}],[\"6万亿参数和2048个专家\",{\"2\":{\"1040\":1}}],[\"65b\",{\"2\":{\"2065\":1}}],[\"65\",{\"2\":{\"1007\":1,\"1141\":1,\"1292\":2}}],[\"65的文章剔除\",{\"2\":{\"515\":1}}],[\"6b\",{\"2\":{\"889\":1,\"925\":1}}],[\"67321\",{\"2\":{\"2347\":2}}],[\"676655352\",{\"2\":{\"2275\":1}}],[\"67b\",{\"2\":{\"1186\":1}}],[\"67b参数模型进行2个epochs\",{\"2\":{\"1087\":1}}],[\"6792\",{\"2\":{\"873\":1}}],[\"675\",{\"2\":{\"873\":1}}],[\"67\",{\"2\":{\"591\":1}}],[\"600k\",{\"2\":{\"2564\":1}}],[\"600b\",{\"2\":{\"1211\":1}}],[\"60\",{\"2\":{\"40\":1,\"1949\":5,\"2338\":1}}],[\"6\",{\"0\":{\"18\":1,\"325\":1,\"1176\":1,\"1819\":1,\"1994\":1,\"2565\":1},\"1\":{\"349\":1,\"375\":1},\"2\":{\"40\":1,\"49\":1,\"443\":1,\"508\":1,\"1087\":1,\"1134\":1,\"1186\":1,\"1232\":1,\"1297\":1,\"1949\":1,\"2233\":1,\"2539\":3,\"2697\":1}}],[\"不太对劲\",{\"2\":{\"2379\":1}}],[\"不难理解\",{\"2\":{\"2286\":1}}],[\"不连续为0\",{\"2\":{\"2256\":1}}],[\"不参与参数调整\",{\"2\":{\"2254\":1}}],[\"不参与训练过程中的参数调整\",{\"2\":{\"1981\":1}}],[\"不要怀疑数据的难度\",{\"2\":{\"2243\":1}}],[\"不要混淆\",{\"2\":{\"1237\":1}}],[\"不建议使用packing策略\",{\"2\":{\"2278\":1}}],[\"不建议使用\",{\"2\":{\"2235\":1}}],[\"不局限于共享前缀\",{\"2\":{\"2166\":1}}],[\"不熟悉的可以自行搜索\",{\"2\":{\"2145\":1}}],[\"不用自己设计把模型的layer分配到哪个gpu\",{\"2\":{\"2108\":1}}],[\"不论是\",{\"2\":{\"1982\":1}}],[\"不进行状态转移\",{\"2\":{\"1958\":1}}],[\"不进行拼接\",{\"2\":{\"1299\":1}}],[\"不添加示例\",{\"2\":{\"1885\":1}}],[\"不准确地\",{\"2\":{\"1843\":1}}],[\"不够通用\",{\"2\":{\"1834\":1}}],[\"不可能一次性计算完整的注意力\",{\"2\":{\"1810\":1}}],[\"不会造成性能瓶颈\",{\"2\":{\"1843\":1}}],[\"不会将敏感信息暴露给大模型的训练过程\",{\"2\":{\"1718\":1}}],[\"不会过大\",{\"2\":{\"1405\":1}}],[\"不正确的\",{\"2\":{\"1633\":1}}],[\"不如承认这个世界并非非黑即白\",{\"2\":{\"1617\":1}}],[\"不如讨论\",{\"0\":{\"1617\":1},\"1\":{\"1672\":1,\"1728\":1,\"1786\":1,\"1847\":1,\"1904\":1}}],[\"不断调整规则\",{\"2\":{\"2606\":1}}],[\"不断优化数据收集和标注方法\",{\"2\":{\"2220\":1}}],[\"不断增长\",{\"2\":{\"1460\":1}}],[\"不断合并频率最高的字符对\",{\"2\":{\"366\":1}}],[\"不推荐框架\",{\"2\":{\"1404\":1}}],[\"不开启\",{\"2\":{\"1389\":1}}],[\"不再进行截断\",{\"2\":{\"1359\":1}}],[\"不依赖于传统的微调步骤\",{\"2\":{\"1342\":1}}],[\"不仅要关注训练集的表现\",{\"2\":{\"1656\":1}}],[\"不仅能提升模型的输出表现\",{\"2\":{\"1718\":1}}],[\"不仅能够满足用户需求\",{\"2\":{\"1377\":1}}],[\"不仅能感知环境\",{\"2\":{\"760\":1}}],[\"不仅提高了模型在各种任务上的表现\",{\"2\":{\"1340\":1}}],[\"不涉及与其他智能体的交互\",{\"2\":{\"1241\":1}}],[\"不涉及其他\",{\"2\":{\"162\":1}}],[\"不需生成新数据\",{\"2\":{\"1721\":1}}],[\"不需生成数据\",{\"2\":{\"1667\":1}}],[\"不需拼接\",{\"2\":{\"1199\":1}}],[\"不需要额外通信操作\",{\"2\":{\"2609\":1}}],[\"不需要额外的信息来解释\",{\"2\":{\"1412\":1}}],[\"不需要消耗大量的计算资源\",{\"2\":{\"2568\":1}}],[\"不需要在训练过程中考虑量化问题\",{\"2\":{\"1260\":1}}],[\"不需要预标注的数据集\",{\"2\":{\"690\":1}}],[\"不需要事先知道环境\",{\"2\":{\"608\":1}}],[\"不需要对原始文本进行预处理\",{\"2\":{\"426\":1}}],[\"不需要指数运算\",{\"2\":{\"238\":1}}],[\"不需要声明\",{\"2\":{\"11\":1}}],[\"不考虑目标kl的变化可能导致策略过拟合\",{\"2\":{\"1174\":1}}],[\"不做\",{\"2\":{\"881\":1}}],[\"不为0的时候为不对称量化\",{\"2\":{\"868\":1}}],[\"不必追求打分器100\",{\"2\":{\"507\":1}}],[\"不合理设置阈值\",{\"2\":{\"461\":1}}],[\"不在初始词表中\",{\"2\":{\"444\":1}}],[\"不自然\",{\"2\":{\"400\":1}}],[\"不改变向量模长\",{\"0\":{\"270\":1},\"1\":{\"293\":1,\"315\":1},\"2\":{\"315\":1}}],[\"不缩放或轻微缩放\",{\"2\":{\"221\":1}}],[\"不同嵌入模型的效果差异\",{\"0\":{\"2663\":1}}],[\"不同嵌入模型有其最佳输入大小\",{\"2\":{\"2655\":1}}],[\"不同位置的贡献不同\",{\"2\":{\"2087\":1}}],[\"不同时机的量化有不同版本\",{\"2\":{\"2033\":1}}],[\"不同任务需要不同的损失函数\",{\"2\":{\"2206\":1}}],[\"不同任务可以共享大部分权重参数\",{\"2\":{\"1932\":1}}],[\"不同任务场景对模型架构提出了差异化需求\",{\"2\":{\"664\":1}}],[\"不同级别的自主性一样\",{\"2\":{\"1617\":1}}],[\"不同于稀疏注意力\",{\"2\":{\"2057\":1}}],[\"不同于ppo使用的backward\",{\"2\":{\"1596\":1}}],[\"不同于bpe按频率选择合并对\",{\"2\":{\"355\":1}}],[\"不同长度的问题\",{\"0\":{\"1513\":1},\"1\":{\"1561\":1}}],[\"不同类型的数据文件需要有针对性的处理方式\",{\"2\":{\"1450\":1}}],[\"不同主题的文档是集中存放还是分散存放\",{\"2\":{\"1421\":1}}],[\"不同术语可能会指代相同的实体或概念\",{\"2\":{\"1376\":1}}],[\"不同数据源可能导致微调结果不一致\",{\"2\":{\"1311\":1}}],[\"不同数据集采样时设定的重复轮次\",{\"2\":{\"575\":1}}],[\"不同的嵌入模型在效果上可能存在显著差异\",{\"2\":{\"2663\":1}}],[\"不同的并行策略对应不同的通信模式和通信量\",{\"2\":{\"2344\":1}}],[\"不同的是\",{\"2\":{\"2304\":1}}],[\"不同的任务类型\",{\"2\":{\"2163\":1}}],[\"不同的解题思路\",{\"2\":{\"2033\":1}}],[\"不同的\",{\"2\":{\"1775\":1}}],[\"不同的实际环境会根据场景使用不同的评分标准\",{\"2\":{\"1268\":1}}],[\"不同的数据源和标注供应商显著影响下游微调结果\",{\"2\":{\"1114\":1}}],[\"不同的大语言模型路径\",{\"2\":{\"1102\":1}}],[\"不同的分词方法会显著影响模型性能\",{\"2\":{\"368\":1}}],[\"不同模型在推理阶段所需的计算资源和时间可能差别较大\",{\"2\":{\"2699\":1}}],[\"不同模型尺寸和训练token数的llm在预训练损失相同的情况下\",{\"2\":{\"1008\":1}}],[\"不同模型之间直接比较困惑度可能导致误解\",{\"2\":{\"686\":1}}],[\"不同文档使用不同的标识符\",{\"2\":{\"917\":1}}],[\"不同来源的文本使用特殊字符隔开\",{\"2\":{\"847\":1}}],[\"不同解码策略下的用法\",{\"0\":{\"781\":1},\"1\":{\"812\":1,\"846\":1}}],[\"不同预训练模型对领域数据的阈值要求有所不同\",{\"2\":{\"501\":1}}],[\"不同维度分布不均\",{\"2\":{\"292\":1}}],[\"不同维度的分布不均衡\",{\"2\":{\"246\":1}}],[\"不同序列长度下\",{\"2\":{\"239\":1}}],[\"不同\",{\"2\":{\"205\":1,\"995\":1,\"1275\":1}}],[\"不同api有各自的认证流程和使用限制\",{\"2\":{\"157\":1}}],[\"不易推广\",{\"2\":{\"168\":1}}],[\"不足\",{\"2\":{\"168\":1}}],[\"不使用sft微调\",{\"2\":{\"1053\":1}}],[\"不使用kv\",{\"0\":{\"166\":1},\"2\":{\"208\":1}}],[\"不使用缓存\",{\"0\":{\"145\":1},\"1\":{\"166\":1,\"187\":1}}],[\"不过后续在megatron3中用序列并行技术对这两部分进行了并行\",{\"2\":{\"2682\":1}}],[\"不过省略一些常数项不会影响我们最终的分析\",{\"2\":{\"2653\":1}}],[\"不过在原论文的分析中并没有考虑写回的复杂度\",{\"2\":{\"2653\":1}}],[\"不过\",{\"2\":{\"17\":1,\"2704\":1}}],[\"字节\",{\"2\":{\"2161\":1}}],[\"字节数\",{\"2\":{\"2014\":3}}],[\"字节级别\",{\"2\":{\"365\":1}}],[\"字节级别解码可能存在歧义\",{\"2\":{\"341\":1}}],[\"字节级别子词可以实现更高效的共享\",{\"2\":{\"318\":1}}],[\"字节级别的bpe\",{\"2\":{\"296\":1}}],[\"字节级别的bpe分词技术\",{\"0\":{\"296\":1},\"1\":{\"318\":1,\"341\":1,\"365\":1,\"391\":1,\"417\":1,\"442\":1}}],[\"字节级别的bpe分词技术解析与应用\",{\"0\":{\"250\":1},\"1\":{\"273\":1,\"296\":1,\"318\":1,\"341\":1,\"365\":1,\"391\":1,\"417\":1,\"442\":1,\"469\":1},\"2\":{\"5\":1}}],[\"字节级别的bpe分词技术解析与应用|bbpe\",{\"2\":{\"5\":1}}],[\"字粒度和词粒度均可用\",{\"2\":{\"1259\":1}}],[\"字符\",{\"2\":{\"470\":1,\"497\":1}}],[\"字符级别\",{\"2\":{\"365\":1}}],[\"字符串\",{\"2\":{\"16\":2}}],[\"基线值\",{\"2\":{\"2520\":1,\"2532\":1}}],[\"基线值是通过每个输出token处使用贪心解码产生的响应的奖励值计算得出的\",{\"2\":{\"2440\":1,\"2463\":1}}],[\"基线计算的创新\",{\"0\":{\"2440\":1,\"2463\":1}}],[\"基线改进版本\",{\"2\":{\"1992\":1,\"2045\":1}}],[\"基准测试结果\",{\"2\":{\"1324\":1}}],[\"基本数据清理\",{\"0\":{\"1331\":1}}],[\"基本配置建议\",{\"0\":{\"526\":1}}],[\"基本的nlp任务\",{\"2\":{\"59\":1}}],[\"基因组数据分析\",{\"2\":{\"39\":1}}],[\"基于上下文生成的正确答案数\",{\"2\":{\"2566\":1}}],[\"基于上下文预测当前词\",{\"2\":{\"870\":1}}],[\"基于大语言模型\",{\"2\":{\"2443\":1}}],[\"基于大模型的智能体接受的是文字输入\",{\"2\":{\"2443\":1}}],[\"基于大模型的智能体\",{\"0\":{\"2443\":1},\"2\":{\"1233\":1}}],[\"基于大模型的智能体原理\",{\"0\":{\"1133\":1},\"1\":{\"1184\":1,\"1233\":1,\"1283\":1,\"1330\":1,\"1375\":1,\"1420\":1,\"1465\":1,\"1509\":1,\"1557\":1,\"1608\":1},\"2\":{\"237\":1}}],[\"基于大模型的分块\",{\"0\":{\"1321\":1},\"1\":{\"1367\":1,\"1412\":1,\"1458\":1},\"2\":{\"237\":1}}],[\"基于值的算法\",{\"0\":{\"2430\":1}}],[\"基于区间的稳健规划\",{\"2\":{\"2405\":1}}],[\"基于ray和deepspeed\",{\"2\":{\"2177\":1}}],[\"基于结果的推理\",{\"2\":{\"1917\":1}}],[\"基于多条样本的公式为\",{\"2\":{\"1942\":1,\"1993\":1}}],[\"基于多模态大模型的解析技术\",{\"0\":{\"1893\":1},\"1\":{\"1948\":1,\"1999\":1,\"2050\":1,\"2103\":1}}],[\"基于多样性\",{\"0\":{\"949\":1}}],[\"基于多样性的方法\",{\"2\":{\"804\":1}}],[\"基于成功率\",{\"2\":{\"1759\":1}}],[\"基于规则的解析算法\",{\"0\":{\"1662\":1},\"1\":{\"1716\":1,\"1773\":1,\"1834\":1}}],[\"基于gpt\",{\"2\":{\"1631\":1}}],[\"基于用户反馈对现有内容进行增补或修正\",{\"2\":{\"1510\":1}}],[\"基于任务规划\",{\"2\":{\"1439\":1}}],[\"基于标题和章节的分块方式\",{\"2\":{\"1424\":1}}],[\"基于熵指标重排\",{\"2\":{\"1413\":1}}],[\"基于距离排序\",{\"2\":{\"1413\":1}}],[\"基于有修改的\",{\"2\":{\"1347\":1}}],[\"基于指令跟随的蒸馏\",{\"0\":{\"1275\":1}}],[\"基于自生成的\",{\"0\":{\"1273\":1},\"1\":{\"1322\":1,\"1368\":1,\"1413\":1}}],[\"基于prompt召回\",{\"0\":{\"1075\":1}}],[\"基于策略的方法可能会在解决高维度问题上表现出更强的能力\",{\"2\":{\"927\":1}}],[\"基于语义单元划分\",{\"2\":{\"2543\":1}}],[\"基于语义相似度\",{\"0\":{\"910\":1}}],[\"基于语义分块|基于语义分块\",{\"2\":{\"2599\":1}}],[\"基于语义分块是一种利用自然语言处理方法\",{\"2\":{\"1425\":1}}],[\"基于语义分块\",{\"0\":{\"1380\":1},\"1\":{\"1425\":1,\"1470\":1,\"1514\":1,\"1562\":1,\"1612\":1,\"1665\":1,\"1719\":1,\"1776\":1,\"1837\":1,\"1896\":1,\"1951\":1,\"2002\":1},\"2\":{\"237\":1}}],[\"基于这一机制\",{\"2\":{\"881\":1}}],[\"基于当前词预测上下文\",{\"2\":{\"870\":1}}],[\"基于原始文本内容整理而成\",{\"2\":{\"822\":1}}],[\"基于主动学习\",{\"0\":{\"1122\":1},\"1\":{\"1173\":1,\"1222\":1},\"2\":{\"804\":1}}],[\"基于llm的方法\",{\"2\":{\"804\":1}}],[\"基于动态环境\",{\"2\":{\"726\":1}}],[\"基于静态数据集进行一次性训练\",{\"2\":{\"726\":1}}],[\"基于状态价值函数改进策略\",{\"2\":{\"656\":1}}],[\"基于所感知的状态\",{\"2\":{\"639\":1}}],[\"基于bert的问答系统\",{\"2\":{\"544\":1}}],[\"基于前512\",{\"2\":{\"532\":1}}],[\"基于贪婪算法\",{\"2\":{\"529\":1}}],[\"基于fasttext的语言识别\",{\"2\":{\"515\":1}}],[\"基于搜索引擎爬取\",{\"2\":{\"494\":1}}],[\"基于关键词爬取指定网站\",{\"2\":{\"494\":1}}],[\"基于聚类簇的多样性权重和质量权重\",{\"0\":{\"446\":1}}],[\"基于概率评估分词效果\",{\"2\":{\"445\":1}}],[\"基于knn聚类的权重采样\",{\"0\":{\"473\":1}}],[\"基于k\",{\"0\":{\"421\":1}}],[\"基于互信息的wordpiece可能更受欢迎\",{\"2\":{\"420\":1}}],[\"基于词的共现频率\",{\"2\":{\"420\":1}}],[\"基于词与词之间的互信息\",{\"2\":{\"420\":1}}],[\"基于拆分后的数据\",{\"2\":{\"381\":1}}],[\"基于文档结构分块虽然自然\",{\"2\":{\"1513\":1}}],[\"基于文档结构分块\",{\"0\":{\"1334\":1},\"1\":{\"1379\":1,\"1424\":1,\"1469\":1,\"1513\":1,\"1561\":1},\"2\":{\"237\":1}}],[\"基于\",{\"0\":{\"1896\":1},\"1\":{\"1951\":1,\"2002\":1},\"2\":{\"49\":3,\"889\":1,\"1347\":1,\"1536\":1,\"2081\":1}}],[\"基于历史天气数据预测未来的气温和降雨量\",{\"2\":{\"39\":1}}],[\"基于历史数据预测未来的股票价格\",{\"2\":{\"39\":1}}],[\"基于shifted\",{\"0\":{\"75\":1},\"1\":{\"87\":1,\"101\":1,\"117\":1,\"136\":1,\"156\":1,\"176\":1,\"197\":1,\"218\":1,\"241\":1,\"264\":1,\"288\":1,\"310\":1,\"333\":1,\"358\":1,\"385\":1},\"2\":{\"5\":2,\"63\":1}}],[\"基础构建模块\",{\"0\":{\"1362\":1}}],[\"基础字符频次统计\",{\"0\":{\"470\":1}}],[\"基础词表过小会导致过多无意义的子词生成\",{\"2\":{\"461\":1}}],[\"基础dp\",{\"2\":{\"50\":1}}],[\"基础\",{\"0\":{\"52\":1},\"1\":{\"59\":1,\"67\":1},\"2\":{\"16\":4}}],[\"支持跨模块训练\",{\"2\":{\"2534\":1}}],[\"支持串行或端到端训练方法\",{\"2\":{\"2523\":1}}],[\"支持查询搜索引擎\",{\"2\":{\"2523\":1}}],[\"支持复杂场景下的应用\",{\"2\":{\"2366\":1}}],[\"支持复杂任务分解与执行\",{\"2\":{\"1485\":1}}],[\"支持的模型类型较少\",{\"2\":{\"2351\":1}}],[\"支持数据并行\",{\"2\":{\"2167\":1}}],[\"支持两种后端组合\",{\"2\":{\"2081\":1}}],[\"支持同时使用\",{\"2\":{\"2059\":1}}],[\"支持无论是单机单卡还是多机多卡适配同一套代码\",{\"2\":{\"2055\":1}}],[\"支持人工检查点干预\",{\"0\":{\"1501\":1}}],[\"支持高效的\",{\"2\":{\"1451\":1}}],[\"支持高效的语言模型训练\",{\"2\":{\"434\":1}}],[\"支持长度外推\",{\"2\":{\"1328\":1,\"1373\":1}}],[\"支持不同类型智能体之间的无缝交互\",{\"2\":{\"1300\":1}}],[\"支持约30种语言\",{\"2\":{\"1130\":1}}],[\"支持其大规模数据训练\",{\"2\":{\"1019\":1}}],[\"支持bpe\",{\"2\":{\"426\":1}}],[\"支持生成带概率的分词结果\",{\"2\":{\"419\":1}}],[\"支持灵活定制\",{\"2\":{\"373\":1}}],[\"支持多语种任务的统一预训练框架\",{\"2\":{\"1742\":1}}],[\"支持多种数据索引和检索方式\",{\"2\":{\"2702\":1}}],[\"支持多种数据类型\",{\"2\":{\"318\":1}}],[\"支持多种分词算法\",{\"2\":{\"373\":1}}],[\"支持多\",{\"2\":{\"65\":1}}],[\"支持\",{\"2\":{\"65\":1,\"917\":1,\"2055\":2}}],[\"支持向量机等\",{\"2\":{\"91\":1}}],[\"支持向量机\",{\"2\":{\"39\":1}}],[\"支持自回归生成\",{\"2\":{\"34\":1}}],[\"支持类型参数化\",{\"2\":{\"15\":1}}],[\"支持代码复用\",{\"2\":{\"15\":1}}],[\"模式\",{\"2\":{\"2139\":1}}],[\"模式切换的方式\",{\"2\":{\"2079\":1}}],[\"模式或分布\",{\"2\":{\"39\":2}}],[\"模仿群体智能\",{\"2\":{\"1300\":1}}],[\"模块结构\",{\"2\":{\"1127\":1}}],[\"模块的矩阵维度扩展\",{\"2\":{\"1069\":1}}],[\"模块中的自注意力\",{\"2\":{\"467\":1}}],[\"模块汇聚了不同\",{\"2\":{\"162\":1}}],[\"模拟\",{\"2\":{\"162\":1}}],[\"模型选择与开发框架\",{\"0\":{\"2696\":1},\"1\":{\"2699\":1,\"2702\":1}}],[\"模型选择以及\",{\"2\":{\"2681\":1}}],[\"模型输出张量\",{\"2\":{\"2482\":1}}],[\"模型输出一个具体的数值\",{\"2\":{\"39\":1}}],[\"模型并行\",{\"0\":{\"2472\":1},\"2\":{\"2709\":2}}],[\"模型并行处理的特性\",{\"2\":{\"1328\":1}}],[\"模型可理解性\",{\"2\":{\"2364\":1}}],[\"模型可以在没有额外训练的情况下处理多种任务\",{\"2\":{\"1303\":1}}],[\"模型可以训练约10t\",{\"2\":{\"1282\":1}}],[\"模型可以访问损坏文本和之前预测的spans\",{\"2\":{\"1004\":1}}],[\"模型可以更有效地提取与输出相关的信息\",{\"2\":{\"97\":1}}],[\"模型所需的大量计算操作也会导致训练时间大幅延长\",{\"2\":{\"2313\":1}}],[\"模型应具备切换话题能力\",{\"2\":{\"2312\":1}}],[\"模型深度\",{\"2\":{\"2225\":1}}],[\"模型显存\",{\"2\":{\"2192\":1}}],[\"模型显存总体分析\",{\"0\":{\"1916\":1},\"1\":{\"1969\":1,\"2021\":1,\"2071\":1,\"2123\":1,\"2170\":1,\"2212\":1,\"2249\":1,\"2284\":1,\"2316\":1,\"2347\":1,\"2377\":1},\"2\":{\"193\":1}}],[\"模型梯度\",{\"2\":{\"2161\":1}}],[\"模型状态\",{\"2\":{\"2161\":1}}],[\"模型简化\",{\"2\":{\"2148\":1}}],[\"模型会根据生成阶段的反馈\",{\"2\":{\"2171\":1}}],[\"模型会重新审视和评估其先前步骤\",{\"2\":{\"2122\":1}}],[\"模型会输出一个概率值\",{\"2\":{\"143\":1}}],[\"模型开始表现出复杂行为\",{\"2\":{\"2122\":1}}],[\"模型内\",{\"2\":{\"2081\":1}}],[\"模型间\",{\"2\":{\"2081\":1}}],[\"模型通过内在的指令辨别能力评估数据集质量\",{\"2\":{\"2282\":1}}],[\"模型通过llm\",{\"2\":{\"1924\":1}}],[\"模型通常能更专注地解决每个问题\",{\"2\":{\"2037\":1}}],[\"模型使用自己的输出来细化和提高其指令遵循和奖励评估能力\",{\"2\":{\"2026\":1}}],[\"模型浮点计算量\",{\"2\":{\"1963\":1}}],[\"模型为给定的新指令生成多个候选响应\",{\"2\":{\"1924\":1}}],[\"模型上的运行效果\",{\"2\":{\"1878\":1}}],[\"模型能够在短时间内获取\",{\"2\":{\"1772\":1}}],[\"模型生成固定格式的答案以便验证\",{\"2\":{\"1797\":1}}],[\"模型生成的内容可能会有所不同\",{\"2\":{\"1600\":1}}],[\"模型生成财报摘要\",{\"2\":{\"49\":1}}],[\"模型中\",{\"2\":{\"2323\":1}}],[\"模型中的通用性\",{\"2\":{\"1493\":1}}],[\"模型中会插入\",{\"2\":{\"1355\":1}}],[\"模型名\",{\"2\":{\"1487\":1}}],[\"模型进行微调\",{\"2\":{\"1450\":1}}],[\"模型微调\",{\"2\":{\"1450\":1,\"1694\":1}}],[\"模型方法对\",{\"2\":{\"1441\":1}}],[\"模型或\",{\"2\":{\"1439\":1}}],[\"模型无法获取\",{\"2\":{\"1423\":1}}],[\"模型大小\",{\"2\":{\"1419\":1}}],[\"模型版本\",{\"2\":{\"1292\":1,\"1395\":1}}],[\"模型只能训练约1t\",{\"2\":{\"1282\":1}}],[\"模型只会接收到该\",{\"2\":{\"881\":1}}],[\"模型效率\",{\"2\":{\"1259\":1}}],[\"模型更轻量化\",{\"2\":{\"1237\":1}}],[\"模型尺寸\",{\"2\":{\"1232\":1}}],[\"模型预测文本中句子的索引位置\",{\"2\":{\"2608\":1}}],[\"模型预测\",{\"2\":{\"1208\":1}}],[\"模型参数的存储和计算效率一直是研究的重点\",{\"2\":{\"2339\":1}}],[\"模型参数的数量呈指数级增长\",{\"2\":{\"2066\":1}}],[\"模型参数的选择需根据训练资源进行灵活调整\",{\"2\":{\"1358\":1}}],[\"模型参数量\",{\"2\":{\"2014\":1,\"2263\":2}}],[\"模型参数\",{\"2\":{\"1186\":1,\"1278\":1,\"2047\":1,\"2123\":1,\"2288\":1}}],[\"模型对同一提示生成多个响应\",{\"2\":{\"1164\":1}}],[\"模型对比\",{\"2\":{\"516\":1}}],[\"模型系列\",{\"2\":{\"1398\":1}}],[\"模型系列与结构\",{\"0\":{\"1156\":1}}],[\"模型系列包括多个参数规模的版本\",{\"2\":{\"1061\":1}}],[\"模型特点\",{\"0\":{\"1040\":1}}],[\"模型采用了多种先进技术以优化性能和推理成本\",{\"2\":{\"960\":1}}],[\"模型规模与算力\",{\"0\":{\"1012\":1}}],[\"模型规模\",{\"2\":{\"933\":1}}],[\"模型规模不断扩大\",{\"2\":{\"698\":1}}],[\"模型架构\",{\"2\":{\"932\":1}}],[\"模型蒸馏\",{\"2\":{\"899\":1}}],[\"模型结构选择\",{\"2\":{\"1243\":1}}],[\"模型结构设计\",{\"0\":{\"1129\":1}}],[\"模型结构分为两部分\",{\"2\":{\"1088\":1}}],[\"模型结构分类\",{\"0\":{\"271\":1},\"1\":{\"294\":1,\"316\":1,\"339\":1,\"363\":1}}],[\"模型结构改进\",{\"0\":{\"1069\":1,\"1112\":1}}],[\"模型结构与参数选择\",{\"0\":{\"1358\":1}}],[\"模型结构与技术创新\",{\"0\":{\"1128\":1},\"1\":{\"1179\":1,\"1228\":1,\"1278\":1}}],[\"模型结构与工作原理\",{\"0\":{\"1121\":1}}],[\"模型结构与预训练\",{\"0\":{\"1102\":1}}],[\"模型结构与训练范式\",{\"0\":{\"1059\":1}}],[\"模型结构与创新之处\",{\"0\":{\"1155\":1}}],[\"模型结构与创新\",{\"0\":{\"1041\":1}}],[\"模型结构与创新点\",{\"0\":{\"961\":1}}],[\"模型结构与输入输出\",{\"0\":{\"938\":1}}],[\"模型结构\",{\"0\":{\"894\":1,\"1002\":1,\"1009\":1,\"1071\":1,\"1198\":1,\"1237\":1},\"2\":{\"1278\":1}}],[\"模型结构概述\",{\"0\":{\"889\":1}}],[\"模型类似\",{\"2\":{\"867\":1}}],[\"模型类型\",{\"2\":{\"595\":1}}],[\"模型类型与适用场景\",{\"2\":{\"34\":1}}],[\"模型来模仿一个较大的\",{\"2\":{\"763\":1}}],[\"模型变得越来越大\",{\"0\":{\"728\":1}}],[\"模型变体\",{\"0\":{\"31\":1}}],[\"模型不与环境直接交互\",{\"2\":{\"726\":1}}],[\"模型分词与后处理\",{\"0\":{\"542\":1}}],[\"模型根据提供的上下文进行推理\",{\"2\":{\"742\":1}}],[\"模型根据输入的上下文信息\",{\"2\":{\"536\":1}}],[\"模型根据上下文预测下一个最可能的单词\",{\"2\":{\"503\":1}}],[\"模型需要具备择优能力\",{\"2\":{\"2506\":1}}],[\"模型需要约\",{\"2\":{\"2281\":1}}],[\"模型需要逐个生成token\",{\"2\":{\"107\":1}}],[\"模型需更低比例\",{\"2\":{\"501\":1}}],[\"模型打分器的选择\",{\"0\":{\"479\":1}}],[\"模型打分与数据去重在预训练中的应用\",{\"2\":{\"851\":1}}],[\"模型打分与数据去重\",{\"0\":{\"371\":1},\"1\":{\"398\":1,\"425\":1,\"451\":1,\"479\":1,\"507\":1,\"541\":1,\"575\":1,\"609\":1,\"644\":1,\"679\":1,\"718\":1,\"753\":1,\"785\":1,\"816\":1,\"851\":1},\"2\":{\"113\":1}}],[\"模型打分与数据去重|模型打分与数据去重\",{\"2\":{\"5\":1,\"685\":1}}],[\"模型稳定性\",{\"2\":{\"315\":1}}],[\"模型性能可以显著提升\",{\"2\":{\"1242\":1}}],[\"模型性能急剧下降\",{\"2\":{\"313\":1}}],[\"模型性能下降风险高\",{\"2\":{\"292\":1}}],[\"模型时\",{\"2\":{\"275\":1}}],[\"模型未训练过新增维度的数据\",{\"2\":{\"269\":1}}],[\"模型超过了原始2048上下文窗口大小的性能\",{\"2\":{\"245\":1}}],[\"模型在\",{\"2\":{\"2655\":1}}],[\"模型在归纳时需要优先利用最新的资料进行回答\",{\"2\":{\"2529\":1}}],[\"模型在归纳总结时需要能够区分这些实体\",{\"2\":{\"2493\":1}}],[\"模型在解决问题时\",{\"2\":{\"2169\":1}}],[\"模型在指令遵循能力和奖励模型能力上都得到了提升\",{\"2\":{\"2076\":1}}],[\"模型在llm对齐过程中不断更新\",{\"2\":{\"2026\":1}}],[\"模型在经过上述instruction数据集微调后\",{\"2\":{\"1368\":1}}],[\"模型在权衡计算效率与精确性之间找到了平衡\",{\"2\":{\"1306\":1}}],[\"模型在推理时会动态地适应给定的上下文\",{\"2\":{\"602\":1}}],[\"模型在扩展到8192上下文窗口时\",{\"2\":{\"245\":1}}],[\"模型在反向传播时\",{\"2\":{\"211\":1}}],[\"模型初始参数选择仍需进一步优化\",{\"2\":{\"236\":1}}],[\"模型难以理解标记间的顺序变化\",{\"2\":{\"312\":1}}],[\"模型难以适应\",{\"2\":{\"223\":1}}],[\"模型难以有效训练\",{\"2\":{\"192\":1}}],[\"模型剪枝的流程可以分为以下三种主要方式\",{\"2\":{\"764\":1}}],[\"模型剪枝则不同\",{\"2\":{\"729\":1}}],[\"模型剪枝\",{\"0\":{\"693\":1},\"1\":{\"729\":1,\"764\":1,\"795\":1,\"826\":1,\"860\":1,\"896\":1,\"931\":1,\"969\":1,\"1010\":1,\"1050\":1,\"1094\":1,\"1143\":1},\"2\":{\"214\":1}}],[\"模型量化可以减少模型尺寸\",{\"2\":{\"733\":1}}],[\"模型量化是指在保持推理精度损失较低的情况下\",{\"2\":{\"733\":1}}],[\"模型量化是通过减少权重表示或激活所需的比特数来压缩模型\",{\"2\":{\"729\":1}}],[\"模型量化与剪枝的区别\",{\"0\":{\"729\":1}}],[\"模型量化\",{\"0\":{\"697\":1,\"733\":1},\"1\":{\"733\":1,\"768\":1,\"799\":1},\"2\":{\"214\":1}}],[\"模型压缩比高\",{\"2\":{\"969\":1}}],[\"模型压缩是一个重要的研究方向\",{\"2\":{\"860\":1}}],[\"模型压缩是一个非常重要的研究方向\",{\"2\":{\"693\":1}}],[\"模型压缩技术还可以提升推理性能\",{\"2\":{\"825\":1}}],[\"模型压缩\",{\"0\":{\"214\":1}}],[\"模型外推\",{\"2\":{\"181\":1}}],[\"模型计算\",{\"2\":{\"164\":1}}],[\"模型计算其对应的key和value向量并存储\",{\"2\":{\"125\":1}}],[\"模型直接复用前面已缓存的key和value\",{\"2\":{\"125\":1}}],[\"模型训练方法\",{\"0\":{\"1204\":1}}],[\"模型训练方式\",{\"0\":{\"1062\":1}}],[\"模型训练与数据处理\",{\"0\":{\"1084\":1},\"1\":{\"1130\":1,\"1181\":1}}],[\"模型训练与验证\",{\"2\":{\"349\":1}}],[\"模型训练的过程中剪枝\",{\"0\":{\"826\":1}}],[\"模型训练的最大上下文长度\",{\"2\":{\"197\":1}}],[\"模型训练和下游应用一致\",{\"2\":{\"294\":1}}],[\"模型训练\",{\"0\":{\"1214\":1,\"2683\":1},\"2\":{\"110\":1,\"382\":1,\"396\":1,\"854\":1,\"986\":1,\"1055\":1,\"2067\":1}}],[\"模型优化\",{\"0\":{\"1214\":1},\"2\":{\"110\":1,\"345\":1,\"397\":1,\"437\":1,\"862\":1,\"890\":1,\"987\":1,\"1001\":1,\"1015\":1,\"1101\":1,\"1148\":1,\"2135\":1}}],[\"模型评估与数据平衡\",{\"0\":{\"2250\":1}}],[\"模型评估\",{\"2\":{\"91\":1,\"2101\":1}}],[\"模型评估有清晰的指标\",{\"2\":{\"39\":1}}],[\"模型的规模和复杂度不断增加\",{\"2\":{\"2609\":1}}],[\"模型的规模也在不断扩大\",{\"2\":{\"692\":1}}],[\"模型的成本较高\",{\"2\":{\"2351\":1}}],[\"模型的能力在很多情况下可能受到权重丢失信息的限制\",{\"2\":{\"2269\":1}}],[\"模型的显存消耗与参数量和数据类型有关\",{\"2\":{\"2192\":1}}],[\"模型的生成速度和生成\",{\"2\":{\"2145\":1}}],[\"模型的预测时间可以近似理解为\",{\"2\":{\"2145\":1}}],[\"模型的预测时间可以近似为\",{\"2\":{\"513\":1}}],[\"模型的回答长度和思考时间几乎线性增长\",{\"2\":{\"2070\":1}}],[\"模型的存储和计算成本一直是一个重要的挑战\",{\"2\":{\"1753\":1}}],[\"模型的基础上\",{\"2\":{\"1582\":1}}],[\"模型的广泛应用\",{\"2\":{\"1537\":1}}],[\"模型的底层原理都是基于数学概率\",{\"2\":{\"1468\":1}}],[\"模型的精度和计算效率往往是两个重要的考量因素\",{\"2\":{\"1308\":1}}],[\"模型的大小和推理速度是两个非常重要的因素\",{\"2\":{\"1110\":1}}],[\"模型的知识掌握能力将进一步提升\",{\"2\":{\"788\":1}}],[\"模型的标配\",{\"2\":{\"205\":1}}],[\"模型的目标是探索数据的结构\",{\"2\":{\"39\":1}}],[\"模型的目标是学习输入与输出之间的映射关系\",{\"2\":{\"39\":1}}],[\"模型的核心结构与工作原理\",{\"0\":{\"34\":1}}],[\"模型\",{\"0\":{\"294\":1,\"316\":1,\"339\":1},\"2\":{\"34\":3,\"49\":2,\"251\":1,\"299\":1,\"655\":4,\"738\":1,\"763\":1,\"1404\":1,\"1416\":1,\"1536\":1,\"1542\":1,\"2313\":1,\"2433\":1,\"2622\":1}}],[\"模型与迁移学习整合解析\",{\"0\":{\"29\":1},\"1\":{\"34\":1,\"40\":1,\"49\":1,\"57\":1,\"65\":1}}],[\"模板设计\",{\"2\":{\"2219\":1}}],[\"模板要求模型首先生成推理过程\",{\"2\":{\"1859\":1}}],[\"模板来实现模型微调的方法\",{\"2\":{\"1752\":1}}],[\"模板\",{\"2\":{\"15\":1,\"21\":2,\"2082\":1}}],[\"实体解析\",{\"0\":{\"1376\":1}}],[\"实体识别\",{\"2\":{\"34\":1}}],[\"实际代码中使用gae+value=returns\",{\"2\":{\"1591\":1}}],[\"实际上\",{\"2\":{\"813\":1,\"1885\":1,\"2469\":1}}],[\"实际中激活值往往是占内存使用的大头\",{\"2\":{\"799\":1}}],[\"实际中浪费的内存低于4\",{\"2\":{\"750\":1}}],[\"实施soft\",{\"2\":{\"2695\":1}}],[\"实施动态采样策略\",{\"2\":{\"2551\":1}}],[\"实施动态采样策略优化\",{\"2\":{\"2093\":1}}],[\"实施预检索和后检索方法\",{\"2\":{\"2499\":1}}],[\"实施数据合成策略以扩大训练集\",{\"2\":{\"2410\":1}}],[\"实施\",{\"2\":{\"2401\":1}}],[\"实施适当的文档分块策略的目标是在信息完整性和相关性之间找到平衡\",{\"2\":{\"2334\":1}}],[\"实施ppo剪辑机制以稳定训练\",{\"2\":{\"2096\":1,\"2147\":1}}],[\"实施dora技术于现有模型以观察性能提升\",{\"2\":{\"2048\":1}}],[\"实施更严格的测试集监控机制\",{\"2\":{\"1709\":1}}],[\"实施更多实际场景下的信息检索任务\",{\"2\":{\"905\":1}}],[\"实施步骤\",{\"0\":{\"1856\":1},\"2\":{\"1324\":1}}],[\"实施拒绝采样以优化生成质量\",{\"2\":{\"1264\":1}}],[\"实施bert微调以提高特定任务的性能\",{\"2\":{\"1177\":1}}],[\"实施0\",{\"2\":{\"1162\":1}}],[\"实施代码示例以加深对算法过程的理解\",{\"2\":{\"761\":1}}],[\"实施行为约束策略并测试其有效性\",{\"2\":{\"755\":1}}],[\"实施td算法并观察其在不同参数设置下的表现\",{\"2\":{\"752\":1}}],[\"实施课程学习策略\",{\"2\":{\"599\":1}}],[\"实时计算激活的量化系数\",{\"2\":{\"1022\":1}}],[\"实时捕捉loss\",{\"2\":{\"662\":1}}],[\"实时收集轨迹样本并进行策略学习\",{\"2\":{\"618\":1}}],[\"实验性\",{\"2\":{\"2408\":1}}],[\"实验表明\",{\"2\":{\"2250\":1}}],[\"实验结果\",{\"0\":{\"2340\":1,\"2572\":1},\"1\":{\"2580\":1,\"2588\":1,\"2596\":1,\"2603\":1,\"2610\":1,\"2617\":1,\"2622\":1,\"2627\":1},\"2\":{\"2692\":1}}],[\"实验结果显示\",{\"2\":{\"2076\":1}}],[\"实验结果与分析\",{\"0\":{\"2076\":1}}],[\"实验结果表明\",{\"2\":{\"1648\":1,\"1747\":1,\"2689\":1}}],[\"实验qlora与其他微调方法的性能比较\",{\"2\":{\"2015\":1}}],[\"实验了多种展开策略\",{\"2\":{\"1917\":1}}],[\"实验如何处理\",{\"2\":{\"1125\":1}}],[\"实验不同学习率调度器对训练效果的影响\",{\"2\":{\"2380\":1}}],[\"实验不同剪辑参数对ppo算法性能的影响\",{\"2\":{\"2229\":1,\"2265\":1}}],[\"实验不同模型组合对ppo性能的影响\",{\"2\":{\"2199\":1}}],[\"实验不同参数设置对模型性能的影响\",{\"2\":{\"2040\":1}}],[\"实验不同β\",{\"2\":{\"1961\":1}}],[\"实验不同行为约束策略对模型效果的影响\",{\"2\":{\"1952\":1}}],[\"实验不同\",{\"2\":{\"1629\":1}}],[\"实验不同上下文长度对模型性能的影响\",{\"2\":{\"1444\":1}}],[\"实验不同容量系数设置对overflow情况的影响\",{\"2\":{\"1417\":1}}],[\"实验不同网络架构对dqn性能的影响\",{\"2\":{\"842\":1}}],[\"实验不同的packing策略对小数据集的影响\",{\"2\":{\"2470\":1}}],[\"实验不同的策略更新方法对优势函数应用的影响\",{\"2\":{\"2421\":1}}],[\"实验不同的矩阵初始化策略对微调效果的影响\",{\"2\":{\"2244\":1}}],[\"实验不同的上下文词选择策略对模型性能的影响\",{\"2\":{\"2019\":1}}],[\"实验不同的辅助损失函数对负载均衡的影响\",{\"2\":{\"1363\":1}}],[\"实验不同的数据集组合以优化模型性能\",{\"2\":{\"2412\":1}}],[\"实验不同的数据集以评估dpo性能\",{\"2\":{\"1902\":1}}],[\"实验不同的数据集对gpt\",{\"2\":{\"1350\":1}}],[\"实验不同的数据配比方案\",{\"2\":{\"599\":1}}],[\"实验不同的model\",{\"2\":{\"821\":1}}],[\"实验不同gae参数对模型性能的影响\",{\"2\":{\"709\":1}}],[\"实验不同rope参数值对长文本处理效果的影响\",{\"2\":{\"668\":1}}],[\"实验流程\",{\"2\":{\"533\":1}}],[\"实验设计\",{\"2\":{\"349\":1}}],[\"实验验证不同窗口大小对推理效率和准确性的影响\",{\"2\":{\"2478\":1}}],[\"实验验证不同放缩因子对训练效果的影响\",{\"2\":{\"2471\":1}}],[\"实验验证不同进制转换方式对模型训练时间及预测准确率的影响\",{\"2\":{\"361\":1}}],[\"实验验证\",{\"2\":{\"334\":1}}],[\"实验\",{\"2\":{\"256\":1,\"2219\":1}}],[\"实验目标\",{\"2\":{\"240\":1}}],[\"实验分析\",{\"2\":{\"72\":1}}],[\"实验与结果\",{\"2\":{\"4\":1}}],[\"实践中pp也会把batch数据分割成\",{\"2\":{\"2688\":1}}],[\"实践编写简单的mdp模型以加深理解\",{\"2\":{\"1034\":1}}],[\"实践与项目\",{\"0\":{\"482\":1},\"1\":{\"511\":1,\"544\":1},\"2\":{\"578\":1}}],[\"实践平台\",{\"2\":{\"65\":1,\"544\":1}}],[\"实践项目\",{\"0\":{\"53\":1}}],[\"实现难度大\",{\"0\":{\"2706\":1}}],[\"实现难度较高\",{\"2\":{\"2650\":1}}],[\"实现简单\",{\"0\":{\"2704\":1}}],[\"实现简单的强化学习算法来验证理论\",{\"2\":{\"902\":1}}],[\"实现remax算法并与其他强化学习算法进行对比实验\",{\"2\":{\"2508\":1,\"2521\":1}}],[\"实现为一个\",{\"2\":{\"2408\":1}}],[\"实现中使用了\",{\"2\":{\"2308\":1}}],[\"实现高效的异步通信\",{\"2\":{\"2081\":1}}],[\"实现并测试lora+优化器在不同模型中的效果\",{\"2\":{\"1997\":1}}],[\"实现并测试policyloss类中的forward方法\",{\"2\":{\"1852\":1}}],[\"实现步骤\",{\"2\":{\"1832\":1}}],[\"实现方法\",{\"0\":{\"1805\":1},\"1\":{\"1867\":1,\"1924\":1,\"1976\":1,\"2026\":1}}],[\"实现方式\",{\"2\":{\"189\":1,\"315\":1}}],[\"实现基于规则的奖励函数\",{\"2\":{\"1740\":1}}],[\"实现基于unigram模型的em算法\",{\"2\":{\"530\":1}}],[\"实现google提出的相对位置编码方案\",{\"2\":{\"1647\":1}}],[\"实现greedy\",{\"2\":{\"481\":1}}],[\"实现多智能体之间的无缝对话与协作\",{\"2\":{\"1485\":1}}],[\"实现规范\",{\"0\":{\"1227\":1}}],[\"实现更高效的分类\",{\"2\":{\"1354\":1}}],[\"实现更高效的长文本预训练\",{\"2\":{\"423\":1}}],[\"实现更高程度的专业化和更准确的知识获取\",{\"2\":{\"1030\":1}}],[\"实现sarsa算法在不同环境中的应用\",{\"2\":{\"817\":1}}],[\"实现ppo算法并进行实验验证\",{\"2\":{\"796\":1}}],[\"实现不同采样方法的代码\",{\"2\":{\"739\":1}}],[\"实现\",{\"0\":{\"996\":1},\"2\":{\"730\":1,\"771\":1,\"1353\":1,\"1493\":1,\"1816\":1}}],[\"实现动态优化\",{\"2\":{\"705\":1}}],[\"实现context\",{\"2\":{\"567\":1}}],[\"实现wordpiece分词算法\",{\"2\":{\"522\":1}}],[\"实现知识注入\",{\"2\":{\"475\":1}}],[\"实现参考\",{\"2\":{\"432\":1}}],[\"实现了张量并行和\",{\"2\":{\"2129\":1}}],[\"实现了与全量微调相当的性能\",{\"2\":{\"1875\":1}}],[\"实现了比huggingface\",{\"2\":{\"1808\":1}}],[\"实现了在减少资源消耗的情况下对大模型的有效微调\",{\"2\":{\"1792\":1}}],[\"实现了在外推能力上的突破性进展\",{\"2\":{\"1397\":1}}],[\"实现了对未知环境的有效探索和利用\",{\"2\":{\"786\":1}}],[\"实现了简单且可逆的编解码流程\",{\"2\":{\"426\":1}}],[\"实现了长上下文训练的高效性\",{\"2\":{\"101\":1}}],[\"实现代码及其与ppo\",{\"2\":{\"2467\":1}}],[\"实现代码片段\",{\"0\":{\"407\":1}}],[\"实现代码效率低下\",{\"2\":{\"210\":1}}],[\"实现一个简单的蒙特卡洛模拟器用于教学演示\",{\"2\":{\"914\":1}}],[\"实现一个简单的价值迭代算法\",{\"2\":{\"647\":1}}],[\"实现一个简单的bpe算法\",{\"2\":{\"531\":1,\"597\":1}}],[\"实现一个简单的rope和alibi代码示例\",{\"2\":{\"388\":1}}],[\"实现一个简单的kv\",{\"2\":{\"303\":1}}],[\"实现mha优化时\",{\"2\":{\"353\":1}}],[\"实现需优化矩阵运算以提升效率\",{\"2\":{\"257\":1}}],[\"实现需要特定优化设计\",{\"2\":{\"168\":1}}],[\"实现信息整合\",{\"2\":{\"116\":1}}],[\"实现过程相对复杂\",{\"2\":{\"2620\":1}}],[\"实现过程较为复杂\",{\"2\":{\"1562\":1}}],[\"实现过程\",{\"0\":{\"62\":1}}],[\"实现类型无关的代码\",{\"2\":{\"15\":1}}],[\"|o\",{\"2\":{\"2485\":1,\"2577\":1}}],[\"|=======================================================================================|\",{\"2\":{\"2347\":1}}],[\"|w\",{\"2\":{\"2033\":1}}],[\"|x\",{\"2\":{\"1795\":6,\"2033\":1}}],[\"|q|\",{\"2\":{\"1644\":2}}],[\"||\",{\"2\":{\"783\":4,\"1628\":1,\"2485\":1}}],[\"||g||\",{\"2\":{\"622\":2}}],[\"|s\",{\"2\":{\"656\":1}}],[\"|m\",{\"2\":{\"293\":1}}],[\"|\",{\"2\":{\"14\":3,\"503\":1,\"537\":2,\"558\":1,\"590\":1,\"647\":1,\"909\":15,\"1324\":26,\"1901\":1,\"1942\":2,\"1993\":2,\"2044\":5,\"2046\":1,\"2085\":1,\"2097\":5,\"2306\":1,\"2347\":12,\"2485\":4,\"2526\":12,\"2577\":1,\"2688\":10}}],[\"|dca\",{\"2\":{\"5\":1}}],[\"5的元素置为0\",{\"2\":{\"2589\":1}}],[\"5tb\",{\"2\":{\"2077\":1}}],[\"51\",{\"2\":{\"2369\":2}}],[\"51​\",{\"2\":{\"1756\":1}}],[\"512\",{\"2\":{\"1281\":3,\"1435\":1,\"1463\":1,\"2655\":1}}],[\"512×768\",{\"2\":{\"1281\":1}}],[\"5−0\",{\"2\":{\"1740\":1}}],[\"5在不同领域的应用效果\",{\"2\":{\"1492\":1}}],[\"5实现了对长文本的高效处理能力\",{\"2\":{\"1446\":1}}],[\"570g\",{\"2\":{\"1416\":1}}],[\"5b\",{\"2\":{\"1398\":1}}],[\"5b到72b不等\",{\"2\":{\"1061\":1}}],[\"5g\",{\"2\":{\"1395\":1}}],[\"537$$\",{\"2\":{\"1329\":1}}],[\"5天\",{\"2\":{\"1324\":1}}],[\"5个汉字以平衡解码效率与模型知识能力\",{\"2\":{\"1302\":1}}],[\"5e\",{\"2\":{\"1186\":1,\"2233\":1}}],[\"5包含多个参数规模的模型\",{\"2\":{\"1156\":1}}],[\"567\",{\"2\":{\"1756\":2}}],[\"567mrr\",{\"2\":{\"1756\":1}}],[\"56\",{\"2\":{\"1138\":1,\"1290\":1}}],[\"5和5e\",{\"2\":{\"1087\":1}}],[\"5百万条中英文指令数据\",{\"2\":{\"1087\":1}}],[\"5是一系列专注于长文本处理的高性能模型\",{\"2\":{\"1061\":1}}],[\"5章节中详细描述了yarn技术的应用\",{\"2\":{\"1041\":1}}],[\"50k子词单元\",{\"2\":{\"1341\":1}}],[\"50257\",{\"2\":{\"1225\":1}}],[\"50\",{\"2\":{\"1037\":1,\"1178\":1,\"1598\":1,\"1644\":2,\"1763\":1,\"1823\":1,\"1987\":2}}],[\"500000\",{\"2\":{\"2233\":1}}],[\"50000\",{\"2\":{\"1487\":1}}],[\"500b\",{\"2\":{\"1211\":1}}],[\"500\",{\"2\":{\"49\":1,\"917\":4,\"1763\":1}}],[\"5模型\",{\"2\":{\"1018\":1}}],[\"528\",{\"2\":{\"1007\":1,\"1292\":1}}],[\"5400\",{\"2\":{\"495\":1}}],[\"5x\",{\"2\":{\"199\":1}}],[\"5⋅收入+0\",{\"2\":{\"164\":2}}],[\"5800\",{\"2\":{\"1324\":1}}],[\"58\",{\"2\":{\"56\":1}}],[\"5\",{\"0\":{\"13\":1,\"185\":1,\"254\":1,\"498\":1,\"847\":1,\"881\":1,\"977\":1,\"1125\":1,\"1429\":1,\"1759\":1,\"1944\":1,\"2104\":1,\"2224\":1,\"2540\":1},\"1\":{\"18\":1,\"278\":1,\"302\":1,\"1018\":1,\"1061\":1,\"1106\":1,\"1156\":1,\"1205\":1,\"1256\":1,\"1305\":1,\"1352\":1,\"1398\":1,\"1446\":1,\"1492\":1,\"2154\":1,\"2197\":1,\"2236\":1,\"2271\":1,\"2304\":1,\"2335\":1,\"2365\":1,\"2394\":1},\"2\":{\"12\":2,\"15\":3,\"40\":1,\"49\":2,\"105\":3,\"135\":1,\"164\":3,\"172\":1,\"213\":2,\"246\":2,\"369\":1,\"443\":1,\"508\":2,\"925\":1,\"996\":1,\"1156\":2,\"1178\":1,\"1186\":1,\"1225\":1,\"1232\":1,\"1256\":1,\"1305\":1,\"1324\":1,\"1398\":1,\"1492\":1,\"1536\":1,\"1641\":1,\"1644\":1,\"1740\":2,\"1756\":3,\"1817\":1,\"2369\":1,\"2433\":1,\"2539\":2,\"2589\":1,\"2686\":1,\"2692\":1}}],[\"允许跨多个模块进行定制\",{\"2\":{\"2523\":1}}],[\"允许在单个实例上训练更大的数据集\",{\"2\":{\"2055\":1}}],[\"允许在训练过程中进行优化\",{\"2\":{\"2032\":1}}],[\"允许在编译时选择类型\",{\"2\":{\"15\":1}}],[\"允许策略更自由地演变\",{\"2\":{\"1989\":1}}],[\"允许策略有更大的灵活性\",{\"2\":{\"1884\":1}}],[\"允许模板参数在训练过程中根据上下文语义和任务目标进行连续调整\",{\"2\":{\"1981\":1}}],[\"允许模型在给定的上下文中进行学习和推理\",{\"2\":{\"477\":1}}],[\"允许循环运行\",{\"0\":{\"1847\":1},\"2\":{\"1847\":1}}],[\"允许非专家用户对智能体进行教导\",{\"2\":{\"1687\":1}}],[\"允许解码器更好地理解编码器生成的信息\",{\"2\":{\"970\":1}}],[\"允许通过基类指针或引用调用派生类的方法\",{\"2\":{\"12\":1}}],[\"允许你将变量\",{\"2\":{\"10\":1}}],[\"多代理检索\",{\"0\":{\"2335\":1},\"2\":{\"2335\":1}}],[\"多向量检索同样会给一个知识文档转化成多个向量存入数据库\",{\"2\":{\"2304\":1}}],[\"多向量检索\",{\"0\":{\"2304\":1}}],[\"多轮合并加速\",{\"2\":{\"2331\":1}}],[\"多轮合并加速计算\",{\"2\":{\"2300\":1}}],[\"多轮计算loss\",{\"0\":{\"2322\":1}}],[\"多轮聊天与答复分布\",{\"0\":{\"2312\":1}}],[\"多轮对话模型需要做哪些调整\",{\"2\":{\"2476\":1}}],[\"多轮对话数据合成\",{\"0\":{\"2291\":1}}],[\"多轮对话数据判断\",{\"0\":{\"2256\":1}}],[\"多轮对话\",{\"0\":{\"2193\":1},\"2\":{\"1324\":1,\"2088\":1,\"2135\":1,\"2184\":1}}],[\"多轮对话中\",{\"2\":{\"1006\":1}}],[\"多轮对话专项提升2\",{\"0\":{\"2100\":1},\"1\":{\"2150\":1,\"2193\":1,\"2232\":1,\"2267\":1,\"2300\":1,\"2331\":1,\"2361\":1,\"2390\":1,\"2417\":1,\"2442\":1,\"2464\":1,\"2482\":1,\"2497\":1,\"2510\":1},\"2\":{\"131\":1}}],[\"多轮对话专项提升2|多轮对话专项提升2\",{\"2\":{\"5\":1,\"2476\":1}}],[\"多轮对话专项提升\",{\"0\":{\"2084\":1},\"1\":{\"2135\":1,\"2181\":1,\"2221\":1,\"2256\":1,\"2291\":1,\"2322\":1,\"2353\":1,\"2383\":1,\"2410\":1,\"2435\":1,\"2457\":1,\"2476\":1},\"2\":{\"131\":1}}],[\"多轮对话专项提升|多轮对话专项提升\",{\"2\":{\"5\":1}}],[\"多源信息搜索分析\",{\"2\":{\"2185\":1}}],[\"多文件代码修改\",{\"2\":{\"2185\":1}}],[\"多卡并行\",{\"2\":{\"2073\":1}}],[\"多次尝试来提高结果置信度时\",{\"2\":{\"2037\":1}}],[\"多层感知器结构\",{\"2\":{\"2024\":1}}],[\"多步mdp将\",{\"2\":{\"1848\":1}}],[\"多步mdp模型\",{\"0\":{\"1848\":1}}],[\"多步mdp视角\",{\"2\":{\"1673\":1}}],[\"多路召回\",{\"0\":{\"1835\":1}}],[\"多查询检索\",{\"0\":{\"1835\":1}}],[\"多回合交互\",{\"0\":{\"1701\":1}}],[\"多模型协同训练策略\",{\"2\":{\"1526\":1}}],[\"多智能体应用侧重于协作与交流\",{\"2\":{\"1485\":1}}],[\"多智能体应用\",{\"0\":{\"1485\":1}}],[\"多智能体协作框架显得尤为重要\",{\"2\":{\"1300\":1}}],[\"多智能体协作框架\",{\"0\":{\"1300\":1}}],[\"多人在线游戏中的虚拟玩家或对手\",{\"2\":{\"1431\":1}}],[\"多级标题如何处理\",{\"0\":{\"2153\":1},\"1\":{\"2196\":1,\"2235\":1}}],[\"多级路由决策增加了以下能力\",{\"2\":{\"1786\":1}}],[\"多级路由决策\",{\"0\":{\"1786\":1}}],[\"多级路由机制和多重索引技术相辅相成\",{\"2\":{\"1332\":1}}],[\"多级路由机制的作用在于确保每个查询被高效地引导至最合适的索引\",{\"2\":{\"1332\":1}}],[\"多级路由机制\",{\"0\":{\"1332\":1}}],[\"多级索引和多向量查询结合\",{\"2\":{\"2335\":1}}],[\"多级索引\",{\"0\":{\"1285\":1}}],[\"多gpu通信优化\",{\"2\":{\"1324\":1}}],[\"多样性确保\",{\"2\":{\"2314\":1}}],[\"多样性数据的需求将持续增长\",{\"2\":{\"598\":1}}],[\"多样化的推理格式\",{\"2\":{\"1917\":1}}],[\"多样化的推理范式\",{\"2\":{\"1860\":1}}],[\"多样化的智能体特性\",{\"2\":{\"1338\":1}}],[\"多样化的智能体协作与集体决策\",{\"0\":{\"1291\":1},\"1\":{\"1338\":1,\"1384\":1,\"1431\":1}}],[\"多重索引技术的核心思想是将庞大的数据和信息需求按类别划分\",{\"2\":{\"1285\":1}}],[\"多目标训练体系\",{\"0\":{\"1081\":1},\"1\":{\"1127\":1}}],[\"多任务处理能力\",{\"2\":{\"1336\":1}}],[\"多任务预训练策略\",{\"0\":{\"1089\":1}}],[\"多任务学习是否适用于所有类型的数据集\",{\"2\":{\"2449\":1}}],[\"多任务学习和提示长度优化\",{\"2\":{\"1736\":1}}],[\"多任务学习\",{\"0\":{\"2371\":1},\"2\":{\"935\":1,\"1794\":1,\"2114\":1}}],[\"多任务场景\",{\"2\":{\"40\":1}}],[\"多token预测\",{\"0\":{\"1127\":1},\"2\":{\"920\":1}}],[\"多领域的语料\",{\"2\":{\"741\":1}}],[\"多领域的数据\",{\"2\":{\"449\":1}}],[\"多领域数据\",{\"2\":{\"736\":1}}],[\"多语种混合以及多轮连贯性等问题\",{\"2\":{\"967\":1}}],[\"多语种处理需确保语料分布均衡\",{\"2\":{\"601\":1}}],[\"多语种支持\",{\"2\":{\"535\":1}}],[\"多语言翻译\",{\"2\":{\"1466\":1}}],[\"多语言训练\",{\"2\":{\"1083\":1}}],[\"多语言能力\",{\"2\":{\"1015\":1}}],[\"多语言和低资源语言的支持将成为分词工具的重要发展方向\",{\"2\":{\"680\":1}}],[\"多语言兼容性\",{\"2\":{\"426\":1}}],[\"多语言共享能力\",{\"2\":{\"365\":1}}],[\"多语言支持让工具更通用\",{\"2\":{\"610\":1}}],[\"多语言支持\",{\"2\":{\"347\":1,\"1138\":1}}],[\"多语言处理\",{\"2\":{\"273\":1,\"987\":1}}],[\"多信息检索任务\",{\"2\":{\"524\":1}}],[\"多信息检索和多信息推理任务\",{\"2\":{\"492\":1}}],[\"多答案选择策略\",{\"0\":{\"496\":1},\"1\":{\"528\":1,\"561\":1,\"596\":1}}],[\"多个micro\",{\"2\":{\"2688\":1}}],[\"多个提示从不同角度评估\",{\"2\":{\"2037\":1}}],[\"多个不同提示审查代码\",{\"2\":{\"2037\":1}}],[\"多个block的softmax\",{\"2\":{\"2030\":1}}],[\"多个机器人可以分工合作\",{\"2\":{\"1338\":1}}],[\"多个智能体通过协作\",{\"2\":{\"1338\":1}}],[\"多个智能体系统广泛应用于以下领域\",{\"2\":{\"1431\":1}}],[\"多个智能体系统的优势\",{\"0\":{\"1384\":1}}],[\"多个智能体系统的核心特征\",{\"0\":{\"1338\":1}}],[\"多个智能体系统更适合解决动态\",{\"2\":{\"1291\":1}}],[\"多个智能体\",{\"2\":{\"1291\":1}}],[\"多个单词及其n\",{\"2\":{\"938\":1}}],[\"多个请求\",{\"2\":{\"750\":1}}],[\"多个文档之间的完全匹配或模糊匹配\",{\"2\":{\"575\":1}}],[\"多个带概率的分词结果\",{\"2\":{\"445\":1}}],[\"多个独立的子网络\",{\"2\":{\"440\":1}}],[\"多分词粒度支持\",{\"2\":{\"426\":1}}],[\"多头注意力并行切分\",{\"0\":{\"2631\":1}}],[\"多头注意力机制\",{\"2\":{\"889\":1}}],[\"多头注意力\",{\"2\":{\"162\":1}}],[\"多线程\",{\"2\":{\"24\":2}}],[\"多态\",{\"2\":{\"12\":1}}],[\"派生类可以继承父类的属性和方法\",{\"2\":{\"12\":1}}],[\"封装\",{\"2\":{\"12\":1}}],[\"继续关注新兴开源项目的发布动态\",{\"2\":{\"2459\":1}}],[\"继续切分\",{\"2\":{\"2141\":1}}],[\"继续优化数据过滤算法\",{\"2\":{\"1327\":1}}],[\"继续优化模型以降低困惑度\",{\"2\":{\"756\":1}}],[\"继续预训练\",{\"0\":{\"397\":1},\"1\":{\"423\":1,\"448\":1,\"475\":1,\"502\":1,\"534\":1,\"567\":1,\"600\":1,\"634\":1,\"668\":1,\"706\":1,\"740\":1},\"2\":{\"113\":1,\"397\":1,\"475\":1}}],[\"继续预训练|继续预训练\",{\"2\":{\"5\":1}}],[\"继承\",{\"2\":{\"12\":1}}],[\"继承和多态\",{\"2\":{\"12\":1}}],[\"o∈rn×d\",{\"2\":{\"2653\":1}}],[\"o∈rn×dq\",{\"2\":{\"2653\":1}}],[\"oq\",{\"2\":{\"2653\":2}}],[\"os\",{\"2\":{\"2284\":2}}],[\"osterhase\",{\"2\":{\"1458\":1}}],[\"olmocr\",{\"2\":{\"2270\":1}}],[\"old​\",{\"2\":{\"2485\":2}}],[\"old\",{\"2\":{\"656\":2,\"1622\":4,\"1628\":2,\"1817\":3,\"2485\":4}}],[\"oh\",{\"0\":{\"2195\":1}}],[\"o=pdropped​v∈rn×d\",{\"2\":{\"2080\":1}}],[\"o=pdroppedv∈rn×do\",{\"2\":{\"2080\":1}}],[\"ocr\",{\"2\":{\"2050\":1,\"2052\":1}}],[\"occur\",{\"2\":{\"1458\":1}}],[\"o1​=l1​f1​=\",{\"2\":{\"2176\":1}}],[\"o1=l1f1=\",{\"2\":{\"2176\":1}}],[\"o1\",{\"2\":{\"1917\":1,\"2145\":1,\"2603\":1,\"2622\":2}}],[\"o1的水平\",{\"2\":{\"1013\":1}}],[\"observation\",{\"0\":{\"1906\":1}}],[\"obj\",{\"2\":{\"18\":1}}],[\"objective\",{\"2\":{\"1685\":3}}],[\"object\",{\"2\":{\"12\":1,\"2408\":1}}],[\"other\",{\"2\":{\"1458\":2}}],[\"otherwise​\",{\"2\":{\"1364\":1}}],[\"otherwise\",{\"2\":{\"1364\":1}}],[\"otherwiseg\",{\"2\":{\"1364\":1}}],[\"own\",{\"2\":{\"1458\":1}}],[\"owl\",{\"2\":{\"454\":1}}],[\"overlap\",{\"0\":{\"1987\":1},\"2\":{\"1450\":1,\"1823\":1,\"1987\":1}}],[\"oi=oi+当前最新结果o\",{\"2\":{\"2517\":1}}],[\"oi=∑jai\",{\"2\":{\"1266\":1}}],[\"oio\",{\"2\":{\"2505\":1,\"2517\":2,\"2573\":1,\"2618\":1}}],[\"oi\",{\"2\":{\"2485\":16,\"2528\":2,\"2539\":1,\"2573\":1}}],[\"oij​\",{\"2\":{\"2379\":3}}],[\"oijo\",{\"2\":{\"2379\":3}}],[\"oi​=oi​+当前最新结果\",{\"2\":{\"2517\":1}}],[\"oi​=j∑​ai\",{\"2\":{\"1266\":1}}],[\"oi​∣q\",{\"2\":{\"1628\":4,\"2357\":1}}],[\"oi∣q\",{\"2\":{\"1628\":4,\"2357\":1}}],[\"ooo\",{\"2\":{\"2306\":1,\"2379\":1,\"2505\":2,\"2549\":1}}],[\"oom\",{\"2\":{\"2118\":1}}],[\"ood\",{\"2\":{\"1902\":1}}],[\"oov\",{\"2\":{\"1125\":1}}],[\"oop\",{\"2\":{\"12\":1}}],[\"openmanus\",{\"0\":{\"1798\":2},\"1\":{\"1860\":2,\"1917\":2,\"1970\":2,\"2022\":2,\"2072\":2,\"2124\":2,\"2171\":2,\"2213\":2,\"2250\":2,\"2285\":2,\"2317\":2,\"2348\":2,\"2378\":2,\"2405\":2,\"2430\":2,\"2455\":2},\"2\":{\"1860\":1}}],[\"openrlhf\",{\"2\":{\"1404\":1,\"2131\":1,\"2233\":1}}],[\"open\",{\"2\":{\"1287\":1,\"1310\":1,\"1403\":1,\"2187\":1,\"2199\":1}}],[\"openai\",{\"0\":{\"1188\":1},\"1\":{\"1238\":1,\"1289\":1,\"1336\":1,\"1382\":1,\"1429\":1},\"2\":{\"1136\":1,\"1188\":1,\"1439\":1,\"1971\":1,\"2245\":1,\"2408\":2,\"2655\":1,\"2699\":1}}],[\"openai通过增加思想链cot推理过程的长度引入inference\",{\"2\":{\"1013\":1}}],[\"oplus\",{\"2\":{\"1127\":1}}],[\"optmem\",{\"2\":{\"2192\":1}}],[\"optmem=1024×1024×1024\",{\"2\":{\"2192\":1}}],[\"optmem=\",{\"2\":{\"2192\":1}}],[\"optional\",{\"2\":{\"1622\":1,\"1817\":1}}],[\"optimistic\",{\"2\":{\"2378\":1,\"2405\":1}}],[\"optimizer方法创建优化器\",{\"2\":{\"1832\":1}}],[\"optimizer方法以支持lora+优化器\",{\"2\":{\"1832\":1}}],[\"optimizers等技术\",{\"2\":{\"1679\":1}}],[\"optimizer\",{\"0\":{\"2224\":1,\"2288\":1},\"2\":{\"619\":6,\"640\":2,\"766\":4,\"820\":3,\"1771\":5,\"1832\":12,\"2089\":1,\"2201\":5,\"2224\":1,\"2259\":1,\"2325\":2}}],[\"optimization\",{\"2\":{\"521\":1,\"875\":1,\"1495\":1,\"1517\":1,\"1523\":1,\"1533\":1,\"1596\":2,\"1814\":1,\"1841\":1,\"1902\":2,\"1917\":3,\"1954\":1,\"1976\":1,\"2202\":1,\"2213\":3,\"2273\":1,\"2467\":2,\"2545\":2,\"2605\":1,\"2662\":1}}],[\"optimal\",{\"2\":{\"656\":3}}],[\"optim\",{\"2\":{\"619\":2,\"766\":2,\"820\":1,\"2201\":1}}],[\"opt\",{\"2\":{\"294\":1,\"1832\":2}}],[\"outcome\",{\"2\":{\"1917\":1,\"2273\":1}}],[\"outline\",{\"2\":{\"1420\":1}}],[\"outputs=false\",{\"2\":{\"2600\":1}}],[\"output\",{\"2\":{\"213\":2,\"266\":2,\"480\":3,\"508\":3,\"996\":1,\"1458\":1,\"1708\":2,\"1912\":1,\"2201\":2,\"2228\":1,\"2233\":1,\"2417\":2,\"2482\":1}}],[\"out\",{\"2\":{\"135\":4,\"308\":1,\"498\":1,\"529\":1,\"1458\":1,\"1783\":1,\"1831\":1,\"1883\":1,\"2118\":1,\"2400\":4,\"2425\":1}}],[\"outside\",{\"2\":{\"18\":1}}],[\"once\",{\"2\":{\"2433\":1}}],[\"online\",{\"0\":{\"995\":1,\"1614\":1},\"2\":{\"618\":1,\"916\":1,\"995\":1,\"1035\":1,\"1564\":1}}],[\"only方法的对比\",{\"0\":{\"2060\":1}}],[\"only的方法又不能充分利用llm\",{\"2\":{\"2011\":1}}],[\"only结构\",{\"2\":{\"1009\":1,\"1243\":1}}],[\"only\",{\"0\":{\"294\":1,\"316\":1,\"1006\":1},\"2\":{\"560\":2,\"595\":2,\"889\":1,\"1006\":2,\"1047\":1}}],[\"on\",{\"2\":{\"106\":1,\"653\":1,\"750\":1,\"846\":1,\"1458\":1,\"2434\":1,\"2471\":1}}],[\"ones\",{\"2\":{\"2539\":1}}],[\"onehot编码优缺点及代码示例\",{\"2\":{\"1263\":1}}],[\"onehot编码\",{\"2\":{\"1025\":1}}],[\"onehot\",{\"0\":{\"802\":1,\"871\":1},\"1\":{\"836\":1,\"871\":1,\"907\":1,\"943\":1,\"985\":1,\"1025\":1,\"1068\":1,\"1113\":1,\"1163\":1,\"1212\":1,\"1263\":1},\"2\":{\"46\":1,\"55\":1}}],[\"onehot|onehot\",{\"2\":{\"5\":1}}],[\"one\",{\"2\":{\"39\":1,\"1025\":2,\"1783\":1}}],[\"offload\",{\"2\":{\"1389\":1,\"2252\":1}}],[\"offline\",{\"0\":{\"954\":1,\"1667\":1},\"2\":{\"618\":1,\"916\":1,\"954\":1,\"995\":1,\"1564\":1,\"1902\":1}}],[\"off\",{\"2\":{\"653\":1}}],[\"of\",{\"0\":{\"528\":1,\"1588\":1,\"1655\":1,\"2094\":1,\"2144\":1},\"1\":{\"1708\":1,\"1766\":1,\"1826\":1,\"1885\":1,\"1940\":1,\"1990\":1,\"2042\":1,\"2094\":1,\"2144\":1,\"2188\":2,\"2227\":2,\"2262\":2},\"2\":{\"101\":1,\"106\":1,\"153\":1,\"230\":1,\"240\":1,\"308\":1,\"498\":1,\"529\":1,\"631\":1,\"683\":1,\"740\":2,\"867\":1,\"870\":1,\"917\":1,\"1008\":2,\"1031\":1,\"1224\":1,\"1229\":3,\"1261\":1,\"1354\":1,\"1364\":1,\"1365\":1,\"1375\":1,\"1406\":1,\"1420\":1,\"1458\":9,\"1658\":2,\"1708\":1,\"1782\":1,\"1788\":1,\"1902\":1,\"1917\":2,\"1990\":3,\"2011\":1,\"2078\":1,\"2118\":1,\"2140\":1,\"2145\":1,\"2199\":1,\"2253\":1,\"2434\":1,\"2471\":1}}],[\"o\",{\"2\":{\"57\":1,\"147\":1,\"189\":2,\"305\":2,\"381\":1,\"470\":1,\"497\":1,\"562\":1,\"783\":1,\"1179\":4,\"1266\":1,\"1628\":4,\"2008\":6,\"2176\":1,\"2357\":1,\"2485\":8,\"2517\":1,\"2539\":4,\"2549\":2,\"2573\":1,\"2618\":6,\"2628\":2,\"2643\":13,\"2648\":6,\"2653\":24}}],[\"orm\",{\"2\":{\"2238\":1}}],[\"orchestrator\",{\"0\":{\"2089\":1},\"2\":{\"2089\":3,\"2139\":2,\"2185\":2,\"2224\":1,\"2325\":2}}],[\"or\",{\"2\":{\"1458\":2}}],[\"origin\",{\"2\":{\"1458\":1}}],[\"original\",{\"2\":{\"1458\":1,\"2050\":2}}],[\"oriented\",{\"2\":{\"12\":1}}],[\"organizers\",{\"0\":{\"1429\":1},\"2\":{\"1429\":1}}],[\"org\",{\"2\":{\"153\":1,\"469\":1,\"631\":1,\"1492\":1,\"1647\":1,\"1920\":1,\"2345\":1,\"2368\":1}}],[\"ordered\",{\"2\":{\"18\":3}}],[\"omega^i\",{\"2\":{\"18\":1}}],[\"omega^r\",{\"2\":{\"18\":1}}],[\"omega\",{\"2\":{\"18\":4}}],[\"适当的输出处理可以带来显著的性能提升\",{\"2\":{\"2617\":1}}],[\"适当控制知识注入比例可保持模型的多样性和灵活性\",{\"2\":{\"1391\":1}}],[\"适量伪多轮数据能够有效提升模型的学习能力\",{\"2\":{\"2383\":1}}],[\"适应性强\",{\"2\":{\"2534\":1}}],[\"适应新框架和工具\",{\"2\":{\"2377\":1}}],[\"适应多种任务\",{\"2\":{\"1328\":1}}],[\"适应用户偏好\",{\"2\":{\"1013\":1}}],[\"适配\",{\"2\":{\"2351\":1}}],[\"适配不同任务\",{\"2\":{\"1281\":1}}],[\"适配算法需求\",{\"2\":{\"1068\":1}}],[\"适配器\",{\"2\":{\"40\":1,\"1605\":1}}],[\"适用场景以及优缺点\",{\"2\":{\"2552\":1}}],[\"适用场景\",{\"0\":{\"1760\":1,\"2139\":1,\"2259\":1},\"2\":{\"22\":1,\"27\":1,\"40\":1,\"191\":1,\"2037\":1}}],[\"适用于教育领域的ai模型训练\",{\"2\":{\"2184\":1}}],[\"适用于多任务推理场景\",{\"2\":{\"2179\":1}}],[\"适用于多种下游任务\",{\"2\":{\"1932\":1}}],[\"适用于多结果排序任务\",{\"2\":{\"1876\":1}}],[\"适用于追求高易用性和缺乏训练资源的场景\",{\"2\":{\"1874\":1}}],[\"适用于不同语言和文本类型\",{\"2\":{\"1514\":1}}],[\"适用于不同的场景和需求\",{\"2\":{\"780\":1}}],[\"适用于任务步骤难以预知\",{\"2\":{\"1316\":1}}],[\"适用于任务明确\",{\"2\":{\"1269\":1}}],[\"适用于分布式任务处理\",{\"2\":{\"1300\":1}}],[\"适用于更复杂的场景\",{\"2\":{\"1289\":1}}],[\"适用于简单的自动化任务\",{\"2\":{\"1241\":1}}],[\"适用于大多数nlp任务\",{\"2\":{\"1237\":1}}],[\"适用于大规模数据集\",{\"2\":{\"983\":1}}],[\"适用于处理大规模数据集或复杂任务\",{\"2\":{\"1031\":1}}],[\"适用于处理多种类型的数据\",{\"2\":{\"15\":1}}],[\"适用于极端资源受限的场景\",{\"2\":{\"768\":1}}],[\"适用于模型参数的数据范围映射\",{\"2\":{\"768\":1}}],[\"适用于已知环境动态的\",{\"2\":{\"621\":1}}],[\"适用于无法得知环境动力学的情况\",{\"2\":{\"574\":1}}],[\"适用于需要处理超长文本的任务\",{\"2\":{\"264\":1}}],[\"适用于复杂系统的建模和开发\",{\"2\":{\"12\":1}}],[\"适用于解决简单\",{\"2\":{\"12\":1}}],[\"适合采用\",{\"2\":{\"2325\":1}}],[\"适合构建复杂对话系统\",{\"2\":{\"2184\":1}}],[\"适合构建复杂的系统\",{\"2\":{\"20\":1}}],[\"适合更长的句子\",{\"2\":{\"1418\":1}}],[\"适合企业需求\",{\"2\":{\"1347\":1}}],[\"适合快速构建和测试原型\",{\"2\":{\"1347\":1}}],[\"适合快速原型验证\",{\"2\":{\"65\":1}}],[\"适合大规模文本数据的处理\",{\"2\":{\"867\":1}}],[\"适合大多数只需局部紧密相关性的任务\",{\"2\":{\"168\":1}}],[\"适合用于构建通用型预训练模型\",{\"2\":{\"741\":1}}],[\"适合深度神经网络的梯度学习\",{\"2\":{\"712\":1}}],[\"适合多任务应用\",{\"2\":{\"610\":1}}],[\"适合从零开始训练\",{\"2\":{\"610\":1}}],[\"适合问答任务\",{\"2\":{\"595\":1}}],[\"适合理解任务\",{\"2\":{\"316\":1}}],[\"适合长序列任务\",{\"2\":{\"305\":1}}],[\"适合简单任务\",{\"2\":{\"301\":1}}],[\"适合文本生成任务\",{\"2\":{\"294\":1}}],[\"适合小范围数字\",{\"2\":{\"292\":1}}],[\"适合计算机视觉任务\",{\"2\":{\"205\":1}}],[\"适合二分类问题\",{\"2\":{\"194\":1,\"330\":1}}],[\"适合复杂任务分解与协作场景\",{\"2\":{\"1300\":1}}],[\"适合复杂任务\",{\"2\":{\"169\":1,\"330\":1}}],[\"适合处理大量重复内容的数据\",{\"2\":{\"318\":1}}],[\"适合处理超长文本\",{\"2\":{\"155\":1}}],[\"适合处理简单的\",{\"2\":{\"20\":1}}],[\"适合无监督学习的场景\",{\"2\":{\"39\":1}}],[\"适合监督学习的场景\",{\"2\":{\"39\":1}}],[\"适合语义理解\",{\"2\":{\"34\":1}}],[\"适合在小范围的代码中使用\",{\"2\":{\"22\":1}}],[\"适合将\",{\"2\":{\"11\":1}}],[\"特殊结构分块\",{\"0\":{\"2640\":1},\"1\":{\"2645\":1,\"2650\":1}}],[\"特殊标记\",{\"2\":{\"2163\":1}}],[\"特殊标记符\",{\"2\":{\"1249\":1}}],[\"特殊的\",{\"2\":{\"595\":1}}],[\"特性\",{\"2\":{\"155\":1,\"169\":2,\"227\":1,\"315\":1,\"365\":1}}],[\"特征学习\",{\"2\":{\"2279\":1}}],[\"特征类型\",{\"2\":{\"1226\":1}}],[\"特征\",{\"2\":{\"655\":6}}],[\"特征分块\",{\"2\":{\"156\":1}}],[\"特征工程\",{\"2\":{\"91\":1,\"836\":1}}],[\"特征提取\",{\"2\":{\"40\":1}}],[\"特征选择\",{\"2\":{\"39\":1}}],[\"特别关注多轮交互能力的评估\",{\"2\":{\"1453\":1}}],[\"特别地\",{\"2\":{\"1124\":1,\"2166\":1}}],[\"特别适用于大模型强化学习场景\",{\"2\":{\"2328\":1,\"2359\":1}}],[\"特别适用于复杂决策问题\",{\"2\":{\"823\":1}}],[\"特别适用于多种不确定性条件下的模拟\",{\"2\":{\"713\":1}}],[\"特别适用于处理通用算法和数据结构\",{\"2\":{\"20\":1}}],[\"特别适合资源受限的环境\",{\"2\":{\"2025\":1}}],[\"特别适合需要处理大规模数据的场景\",{\"2\":{\"1250\":1}}],[\"特别适合\",{\"2\":{\"121\":1}}],[\"特别是\",{\"2\":{\"2118\":1,\"2524\":1}}],[\"特别是基于人类反馈的强化学习\",{\"2\":{\"2081\":1}}],[\"特别是对于\",{\"2\":{\"1925\":1}}],[\"特别是大规模语言模型\",{\"2\":{\"1753\":1}}],[\"特别是介绍了deepseek\",{\"2\":{\"934\":1}}],[\"特别是低资源语言的数据增强\",{\"2\":{\"650\":1}}],[\"特别是围绕\",{\"2\":{\"433\":1}}],[\"特别是在涉及大量文本处理和生成任务的场景中\",{\"2\":{\"2166\":1}}],[\"特别是在kl约束的应用上\",{\"2\":{\"1880\":1}}],[\"特别是在数据合成和执行反馈方面的创新\",{\"2\":{\"1372\":1}}],[\"特别是在需要将文档输入大语言模型的场景下\",{\"2\":{\"1334\":1}}],[\"特别是在处理如\",{\"2\":{\"1284\":1}}],[\"特别是在多语言能力方面表现突出\",{\"2\":{\"1057\":1}}],[\"特别是在生成式任务中\",{\"2\":{\"787\":1}}],[\"特别是在nlp领域\",{\"2\":{\"128\":1}}],[\"特别是在函数较多时\",{\"2\":{\"11\":1}}],[\"特别是当你只需要少数几个标准库元素时\",{\"2\":{\"22\":1}}],[\"特点\",{\"2\":{\"12\":2,\"15\":1,\"146\":1,\"149\":1,\"162\":1,\"167\":1,\"199\":1,\"294\":1,\"301\":1,\"316\":1,\"339\":1,\"363\":1,\"535\":1}}],[\"强迫模型首先熟悉目标数据集的一个子集\",{\"2\":{\"2314\":1}}],[\"强制模型将思维过程生成在指定的标签内\",{\"2\":{\"1797\":1}}],[\"强化模型能力\",{\"2\":{\"1436\":1}}],[\"强化学习过程中可能出现reward\",{\"2\":{\"2657\":1}}],[\"强化学习等技术相结合\",{\"2\":{\"2523\":1}}],[\"强化学习智能体接收的是预设好的向量化环境状态\",{\"2\":{\"2418\":1}}],[\"强化学习智能体\",{\"0\":{\"2418\":1}}],[\"强化学习策略可能会因不当行为约束设置而偏离预期路径\",{\"2\":{\"1777\":1}}],[\"强化学习策略需要在一个合理范围内更新\",{\"2\":{\"721\":1}}],[\"强化学习目标修改\",{\"0\":{\"1685\":1}}],[\"强化学习旨在最大化累积奖励的期望值\",{\"2\":{\"1666\":1}}],[\"强化学习应用于nlp任务时\",{\"2\":{\"1613\":1}}],[\"强化学习算法的优化\",{\"0\":{\"1576\":1}}],[\"强化学习算法\",{\"0\":{\"1480\":1}}],[\"强化学习算法将越来越多地应用于自动驾驶\",{\"2\":{\"912\":1}}],[\"强化学习理论推导\",{\"2\":{\"1461\":1}}],[\"强化学习方法\",{\"0\":{\"1222\":1}}],[\"强化学习在复杂任务中的潜力值得进一步探索\",{\"2\":{\"2661\":1}}],[\"强化学习在许多任务中面临目标复杂\",{\"2\":{\"1633\":1}}],[\"强化学习在大模型上的应用\",{\"0\":{\"1146\":1}}],[\"强化学习在自动驾驶\",{\"2\":{\"953\":1}}],[\"强化学习是否仍具有优势\",{\"2\":{\"966\":1}}],[\"强化学习是一种机器学习方法\",{\"2\":{\"572\":1}}],[\"强化学习能否完全替代有监督学习在某些任务中的作用\",{\"2\":{\"966\":1}}],[\"强化学习将在动态环境决策中发挥更重要的作用\",{\"2\":{\"893\":1}}],[\"强化学习将在nlp中扮演越来越重要的角色\",{\"2\":{\"787\":1}}],[\"强化学习通过实时交互生成数据\",{\"2\":{\"858\":1}}],[\"强化学习通过以下步骤实现目标\",{\"2\":{\"639\":1}}],[\"强化学习中model\",{\"2\":{\"857\":1}}],[\"强化学习中的奖励利用与泛化问题\",{\"0\":{\"1414\":1},\"1\":{\"1460\":1,\"1505\":1,\"1551\":1,\"1601\":1,\"1656\":1,\"1709\":1}}],[\"强化学习中的动态数据分布调整机制是其核心竞争力\",{\"2\":{\"823\":1}}],[\"强化学习中的\",{\"2\":{\"760\":1}}],[\"强化学习强调智能体不仅能感知环境\",{\"2\":{\"711\":1}}],[\"强化学习结合采样策略\",{\"2\":{\"703\":1}}],[\"强化学习优化目标\",{\"0\":{\"614\":1,\"1666\":1}}],[\"强化学习更关注动态交互环境中的策略优化\",{\"2\":{\"587\":1}}],[\"强化学习和有监督学习是机器学习的两大重要领域\",{\"2\":{\"587\":1}}],[\"强化学习的核心价值\",{\"0\":{\"2283\":1}}],[\"强化学习的主要目标是最大化累积奖励的期望值\",{\"2\":{\"1515\":1}}],[\"强化学习的方法以及基于自生成的方法\",{\"2\":{\"804\":1}}],[\"强化学习的流程\",{\"0\":{\"639\":1}}],[\"强化学习的目标是最大化累积奖励的期望值\",{\"2\":{\"514\":1}}],[\"强化学习的独特性\",{\"0\":{\"519\":1},\"1\":{\"552\":1,\"587\":1,\"620\":1,\"655\":1,\"690\":1,\"726\":1,\"760\":1,\"792\":1,\"823\":1,\"858\":1,\"893\":1,\"928\":1,\"966\":1},\"2\":{\"151\":1}}],[\"强化学习的独特性|强化学习的独特性\",{\"2\":{\"5\":1}}],[\"强化学习分类\",{\"0\":{\"517\":1},\"1\":{\"550\":1,\"585\":1,\"618\":1,\"653\":1,\"688\":1,\"724\":1,\"758\":1,\"790\":1,\"821\":1,\"857\":1,\"892\":1},\"2\":{\"151\":1}}],[\"强化学习分类|强化学习分类\",{\"2\":{\"5\":1}}],[\"强化学习基础\",{\"0\":{\"151\":1}}],[\"强化学习\",{\"0\":{\"962\":1,\"1122\":1,\"1780\":1,\"1842\":1},\"1\":{\"1173\":1,\"1222\":1},\"2\":{\"37\":1,\"478\":1,\"484\":1,\"487\":1,\"489\":2,\"539\":1,\"540\":1,\"543\":1,\"550\":1,\"552\":1,\"571\":1,\"573\":2,\"588\":1,\"617\":1,\"642\":1,\"655\":1,\"659\":1,\"690\":1,\"726\":1,\"805\":1,\"858\":1,\"899\":1,\"1414\":1,\"1449\":1,\"1471\":1,\"1478\":1,\"1479\":1,\"1489\":1,\"1532\":1,\"1546\":1,\"1567\":1,\"1578\":1,\"1707\":2,\"1726\":1,\"1767\":1,\"1829\":1,\"2238\":2,\"2297\":1,\"2329\":1,\"2404\":1,\"2418\":1,\"2467\":1,\"2535\":1,\"2647\":1}}],[\"强化学习问题与流程\",{\"0\":{\"572\":1},\"1\":{\"605\":1}}],[\"强化学习问题\",{\"0\":{\"539\":1},\"1\":{\"572\":1,\"605\":1,\"639\":1,\"673\":1,\"711\":1,\"745\":1,\"776\":1,\"807\":1,\"841\":1},\"2\":{\"5\":1,\"151\":1}}],[\"强闭源模型\",{\"2\":{\"479\":1}}],[\"强正则化能力\",{\"2\":{\"330\":1}}],[\"强调了数据检查的重要性\",{\"2\":{\"1114\":1}}],[\"强调数据质量的重要性\",{\"2\":{\"1114\":1}}],[\"强调数据和操作数据的函数绑定在一起\",{\"2\":{\"12\":1}}],[\"强调封装\",{\"2\":{\"12\":1}}],[\"强调步骤和数据处理的顺序\",{\"2\":{\"12\":1}}],[\"强调过程\",{\"2\":{\"12\":1}}],[\"+gelu\",{\"2\":{\"2602\":2}}],[\"+ϵ\",{\"2\":{\"2597\":1}}],[\"+ϵl\",{\"2\":{\"2597\":1}}],[\"+em\",{\"2\":{\"2030\":2}}],[\"+exp\",{\"2\":{\"1582\":1,\"1634\":1,\"2046\":1}}],[\"+exp⁡\",{\"2\":{\"1582\":1,\"1634\":1,\"2046\":1}}],[\"+exp⁡∑r^\",{\"2\":{\"1536\":1}}],[\"+exp∑r^\",{\"2\":{\"1536\":1}}],[\"+βlog⁡z\",{\"2\":{\"1994\":1,\"2046\":1}}],[\"+∑i=1m​exp\",{\"2\":{\"1671\":1}}],[\"+∑i=1mexp⁡\",{\"2\":{\"1671\":1}}],[\"+∑i=1nrgi\",{\"2\":{\"1364\":1}}],[\"+y\",{\"2\":{\"1536\":2}}],[\"+i=1∑nr​​gi\",{\"2\":{\"1364\":1}}],[\"+λ⋅l1​\",{\"2\":{\"1142\":1}}],[\"+λ⋅l1\",{\"2\":{\"1142\":1}}],[\"++i\",{\"2\":{\"762\":1,\"783\":2}}],[\"+γex∼dpretrain​​\",{\"2\":{\"1685\":1}}],[\"+γex∼dpretrain\",{\"2\":{\"1685\":1}}],[\"+γs\",{\"2\":{\"647\":1,\"656\":1,\"732\":2,\"767\":3,\"810\":1}}],[\"+γ∑s\",{\"2\":{\"647\":1,\"656\":1,\"732\":2,\"767\":3,\"810\":1}}],[\"+α\",{\"2\":{\"608\":2,\"611\":2,\"640\":2,\"672\":2,\"710\":2}}],[\"+单向\",{\"2\":{\"595\":1}}],[\"+1+1+1\",{\"2\":{\"1740\":1}}],[\"+1\",{\"2\":{\"184\":2,\"276\":2}}],[\"+=\",{\"2\":{\"48\":1,\"324\":1,\"640\":1,\"646\":1,\"647\":3,\"656\":3,\"762\":1,\"769\":2,\"783\":2,\"1816\":1,\"2433\":1}}],[\"+\",{\"0\":{\"2349\":2},\"2\":{\"11\":1,\"12\":2,\"15\":1,\"18\":2,\"47\":2,\"76\":4,\"90\":1,\"164\":3,\"178\":2,\"184\":1,\"190\":2,\"194\":1,\"199\":3,\"215\":1,\"218\":1,\"276\":1,\"324\":1,\"346\":1,\"364\":1,\"513\":1,\"590\":1,\"608\":2,\"611\":2,\"619\":1,\"631\":1,\"640\":4,\"646\":1,\"647\":3,\"656\":3,\"672\":4,\"710\":2,\"732\":2,\"748\":1,\"762\":8,\"766\":1,\"767\":3,\"769\":1,\"778\":2,\"779\":1,\"810\":1,\"820\":1,\"843\":3,\"868\":1,\"998\":2,\"1127\":1,\"1142\":1,\"1156\":2,\"1187\":2,\"1207\":1,\"1233\":3,\"1265\":3,\"1266\":2,\"1333\":1,\"1344\":1,\"1359\":3,\"1364\":2,\"1536\":2,\"1582\":1,\"1591\":1,\"1622\":2,\"1634\":1,\"1671\":1,\"1685\":1,\"1756\":2,\"1763\":1,\"1817\":1,\"1831\":1,\"1994\":1,\"2013\":2,\"2030\":1,\"2044\":1,\"2046\":2,\"2081\":2,\"2097\":1,\"2117\":1,\"2145\":1,\"2161\":5,\"2176\":2,\"2192\":2,\"2228\":2,\"2322\":2,\"2347\":4,\"2363\":1,\"2430\":1,\"2517\":1,\"2528\":4,\"2537\":2,\"2597\":1,\"2602\":3,\"2604\":1,\"2618\":1,\"2676\":1}}],[\"=o\",{\"2\":{\"2643\":2,\"2653\":6}}],[\"=diag\",{\"2\":{\"2528\":10}}],[\"=pi\",{\"2\":{\"2528\":1}}],[\"=2\",{\"2\":{\"2176\":1}}],[\"=2m\",{\"2\":{\"2176\":1}}],[\"=4φ+12φ=16φ\",{\"2\":{\"2161\":1}}],[\"=4φ+12φ=16φ2\",{\"2\":{\"2161\":1}}],[\"=x1​a1​+x2​a2​=y1​+y2​=y\",{\"2\":{\"2537\":1}}],[\"=x1a1+x2a2=y1+y2=yx\",{\"2\":{\"2537\":1}}],[\"=x^⋅w^\",{\"2\":{\"2033\":1}}],[\"=x^⋅w^y\",{\"2\":{\"2033\":1}}],[\"=x⋅σ\",{\"2\":{\"307\":2}}],[\"=f\",{\"2\":{\"2030\":1}}],[\"=βlogπref​\",{\"2\":{\"1994\":1}}],[\"=βlog⁡π∗\",{\"2\":{\"1994\":1}}],[\"=π∗\",{\"2\":{\"1944\":2}}],[\"=πmax​vπ​\",{\"2\":{\"767\":1}}],[\"=z\",{\"2\":{\"1889\":2}}],[\"=y∑​πref​\",{\"2\":{\"1830\":1}}],[\"=31​×1\",{\"2\":{\"1756\":1}}],[\"=−logexp\",{\"2\":{\"1671\":1}}],[\"=−log⁡exp⁡\",{\"2\":{\"1671\":1}}],[\"=−e\",{\"2\":{\"1536\":2,\"1795\":1}}],[\"=softmax\",{\"2\":{\"1535\":2}}],[\"=s⋅m\",{\"2\":{\"222\":1}}],[\"=s⋅mg\",{\"2\":{\"222\":1}}],[\"=ut+∑i=1nsffni\",{\"2\":{\"1364\":1}}],[\"=⎩⎨⎧​ws​⋅η\",{\"2\":{\"1344\":1}}],[\"=检索技术+llm\",{\"2\":{\"1333\":2}}],[\"=6×数据\",{\"2\":{\"1232\":2}}],[\"=li​\",{\"2\":{\"2618\":1}}],[\"=lili\",{\"2\":{\"2618\":1}}],[\"=l\",{\"2\":{\"2030\":3}}],[\"=l2​\",{\"2\":{\"1142\":1}}],[\"=l2\",{\"2\":{\"1142\":1}}],[\"=log\",{\"2\":{\"537\":1}}],[\"=log⁡\",{\"2\":{\"537\":1}}],[\"=∑j=1d​exj​−mexi​−m​\",{\"2\":{\"1925\":1}}],[\"=∑yπref\",{\"2\":{\"1830\":1}}],[\"=∑logp\",{\"2\":{\"1093\":1,\"1142\":1}}],[\"=∑log⁡p\",{\"2\":{\"1093\":1,\"1142\":1}}],[\"=∑a∈aπ\",{\"2\":{\"656\":1,\"732\":1,\"810\":1}}],[\"=σ\",{\"2\":{\"998\":2}}],[\"=n\",{\"2\":{\"778\":1}}],[\"=mlp\",{\"2\":{\"2121\":2}}],[\"=m−11​k=j∑​r\",{\"2\":{\"1901\":1}}],[\"=m\",{\"2\":{\"778\":1,\"2030\":2}}],[\"=max\",{\"2\":{\"238\":1,\"261\":1,\"2030\":1}}],[\"=max⁡πvπ\",{\"2\":{\"767\":1}}],[\"=max⁡a∈a\",{\"2\":{\"647\":1,\"767\":1}}],[\"=max⁡\",{\"2\":{\"238\":1,\"261\":1,\"2030\":1}}],[\"=true\",{\"2\":{\"2597\":2}}],[\"=torch\",{\"2\":{\"2597\":2}}],[\"=t∑t​γt\",{\"2\":{\"757\":1}}],[\"=t\",{\"2\":{\"757\":1}}],[\"=ttγt\",{\"2\":{\"757\":1}}],[\"=r+γa\",{\"2\":{\"2430\":1}}],[\"=r+γmax⁡a\",{\"2\":{\"2430\":1}}],[\"=r\",{\"2\":{\"732\":2,\"767\":4,\"810\":2}}],[\"=rm​q=\",{\"2\":{\"247\":1}}],[\"=rmq=\",{\"2\":{\"247\":1}}],[\"=a∈a∑​π\",{\"2\":{\"656\":1,\"732\":1,\"810\":1}}],[\"=a∈amax​\",{\"2\":{\"647\":1,\"767\":1}}],[\"=∫h\",{\"2\":{\"623\":2}}],[\"=e​i=1∑g​t=1∑∣oi​∣​\",{\"2\":{\"2485\":1,\"2577\":1}}],[\"=em\",{\"2\":{\"2030\":2}}],[\"=e\",{\"2\":{\"1628\":2,\"1685\":2,\"2485\":1,\"2577\":1}}],[\"=eπ​\",{\"2\":{\"748\":2,\"779\":2,\"2306\":1}}],[\"=eπ\",{\"2\":{\"748\":2,\"779\":2,\"2306\":1}}],[\"=eπθ​​\",{\"2\":{\"586\":1,\"757\":1}}],[\"=eπθ\",{\"2\":{\"586\":1,\"757\":1}}],[\"=exi−m∑j=1dexj−msoftmax\",{\"2\":{\"1925\":1}}],[\"=exp∑r^\",{\"2\":{\"1536\":1}}],[\"=exp⁡∑r^\",{\"2\":{\"1536\":1}}],[\"=exp⁡\",{\"2\":{\"558\":1,\"2046\":1}}],[\"=exp\",{\"2\":{\"268\":2,\"558\":1,\"2046\":1}}],[\"=ex+e−xex−e−x​\",{\"2\":{\"215\":1}}],[\"=ex−e−xex+e−xf\",{\"2\":{\"215\":1}}],[\"=i\",{\"2\":{\"537\":2}}],[\"=====================\",{\"2\":{\"2688\":2}}],[\"======================\",{\"2\":{\"2688\":2}}],[\"==\",{\"2\":{\"189\":1,\"640\":1,\"647\":1,\"656\":2,\"783\":5,\"840\":1,\"1816\":1,\"2500\":1}}],[\"=1m−1∑k≠jr\",{\"2\":{\"1901\":1}}],[\"=1\",{\"2\":{\"1889\":2}}],[\"=1z\",{\"2\":{\"1889\":2}}],[\"=13×1\",{\"2\":{\"1756\":1}}],[\"=1+e−x1​\",{\"2\":{\"194\":1}}],[\"=1+e−z1​=0\",{\"2\":{\"164\":1}}],[\"=1+e−z1​\",{\"2\":{\"90\":1}}],[\"=11+e−xf\",{\"2\":{\"194\":1}}],[\"=11+e−z=0\",{\"2\":{\"164\":1}}],[\"=11+e−z\",{\"2\":{\"90\":1}}],[\"=\",{\"0\":{\"2636\":1},\"2\":{\"11\":1,\"14\":1,\"18\":7,\"34\":1,\"47\":17,\"48\":6,\"76\":1,\"90\":1,\"130\":1,\"135\":4,\"164\":3,\"178\":1,\"184\":1,\"189\":6,\"190\":5,\"194\":1,\"199\":2,\"208\":2,\"213\":9,\"215\":1,\"218\":6,\"221\":2,\"222\":2,\"238\":1,\"247\":2,\"252\":1,\"261\":1,\"263\":2,\"266\":7,\"268\":1,\"276\":1,\"283\":3,\"285\":3,\"290\":2,\"291\":2,\"307\":1,\"324\":12,\"332\":8,\"346\":1,\"355\":1,\"364\":3,\"391\":5,\"407\":1,\"426\":1,\"427\":1,\"444\":4,\"474\":1,\"480\":2,\"485\":3,\"503\":1,\"508\":2,\"513\":1,\"515\":7,\"526\":6,\"537\":3,\"558\":1,\"586\":1,\"619\":20,\"622\":2,\"623\":1,\"640\":16,\"646\":8,\"647\":13,\"655\":2,\"656\":21,\"732\":2,\"748\":4,\"757\":1,\"762\":7,\"766\":25,\"767\":4,\"769\":4,\"775\":2,\"778\":1,\"779\":6,\"783\":6,\"789\":1,\"803\":1,\"810\":2,\"820\":21,\"840\":10,\"843\":5,\"868\":1,\"917\":4,\"996\":3,\"998\":2,\"1025\":6,\"1050\":1,\"1093\":1,\"1111\":4,\"1119\":1,\"1127\":2,\"1142\":2,\"1187\":1,\"1208\":2,\"1229\":1,\"1232\":3,\"1233\":1,\"1246\":1,\"1266\":2,\"1279\":1,\"1297\":1,\"1329\":1,\"1333\":1,\"1343\":1,\"1344\":2,\"1359\":1,\"1364\":2,\"1435\":6,\"1455\":2,\"1458\":1,\"1535\":1,\"1536\":2,\"1582\":3,\"1591\":1,\"1594\":1,\"1622\":9,\"1628\":1,\"1634\":1,\"1644\":1,\"1657\":1,\"1671\":1,\"1683\":1,\"1685\":1,\"1703\":6,\"1727\":1,\"1731\":13,\"1732\":3,\"1756\":6,\"1771\":2,\"1795\":1,\"1816\":3,\"1817\":9,\"1823\":6,\"1830\":1,\"1831\":8,\"1832\":6,\"1837\":3,\"1868\":2,\"1883\":6,\"1889\":3,\"1901\":2,\"1912\":10,\"1922\":2,\"1925\":2,\"1928\":8,\"1936\":2,\"1942\":2,\"1944\":1,\"1951\":3,\"1984\":4,\"1993\":2,\"1994\":1,\"2012\":1,\"2013\":1,\"2030\":8,\"2033\":3,\"2046\":2,\"2080\":5,\"2085\":1,\"2108\":1,\"2117\":1,\"2121\":2,\"2124\":1,\"2137\":1,\"2140\":1,\"2142\":1,\"2145\":1,\"2161\":2,\"2176\":10,\"2183\":1,\"2192\":5,\"2201\":13,\"2217\":1,\"2228\":3,\"2263\":2,\"2306\":3,\"2308\":2,\"2322\":1,\"2327\":3,\"2400\":7,\"2406\":4,\"2417\":3,\"2425\":2,\"2430\":1,\"2433\":4,\"2485\":1,\"2492\":2,\"2500\":15,\"2517\":1,\"2526\":1,\"2528\":7,\"2531\":1,\"2537\":4,\"2539\":34,\"2542\":1,\"2549\":3,\"2565\":2,\"2566\":1,\"2573\":4,\"2577\":1,\"2581\":1,\"2587\":1,\"2589\":2,\"2597\":6,\"2600\":2,\"2602\":1,\"2604\":2,\"2609\":3,\"2611\":2,\"2618\":1,\"2621\":1,\"2623\":2,\"2628\":3,\"2641\":1,\"2643\":2,\"2653\":3,\"2692\":2}}],[\"类别频率未正确考虑会导致分层softmax性能下降\",{\"2\":{\"1109\":1}}],[\"类间高相似度可能导致采样结果偏差\",{\"2\":{\"565\":1}}],[\"类似的方法可以用于计算第二个block\",{\"2\":{\"2216\":1}}],[\"类似的方法\",{\"2\":{\"1788\":1}}],[\"类似的相对位置编码是否同样适用\",{\"2\":{\"1447\":1}}],[\"类似进程间共享物理页\",{\"2\":{\"750\":1}}],[\"类似context\",{\"2\":{\"706\":1}}],[\"类似于grpo\",{\"2\":{\"2388\":1,\"2416\":1}}],[\"类似于用递归方式一步步计算每个单词的位置信息\",{\"2\":{\"1418\":1}}],[\"类似于路由器\",{\"2\":{\"1170\":1}}],[\"类似于翻译系统\",{\"2\":{\"970\":1}}],[\"类似于\",{\"2\":{\"499\":1,\"502\":1,\"1537\":1,\"2554\":1}}],[\"类似\",{\"2\":{\"308\":1,\"1209\":1}}],[\"类似mla的显存优化技术将成为大模型部署的关键方向\",{\"2\":{\"306\":1}}],[\"类\",{\"2\":{\"21\":2}}],[\"类型的数据\",{\"2\":{\"1925\":1}}],[\"类型的参数\",{\"2\":{\"11\":2}}],[\"类型\",{\"2\":{\"34\":1,\"2223\":1,\"2254\":1}}],[\"类型推导\",{\"2\":{\"15\":1}}],[\"类模板\",{\"2\":{\"15\":1}}],[\"类等放入不同的命名空间中\",{\"2\":{\"10\":1}}],[\"返回类型为\",{\"2\":{\"11\":2}}],[\"返回首页\",{\"2\":{\"4\":1}}],[\"声明\",{\"2\":{\"11\":1}}],[\"之间汇总数据\",{\"2\":{\"2427\":1}}],[\"之间取得平衡\",{\"2\":{\"1763\":1}}],[\"之间的数据传输需求\",{\"2\":{\"2486\":1}}],[\"之间的通信量\",{\"2\":{\"2397\":1}}],[\"之间的语义关系\",{\"2\":{\"985\":1}}],[\"之间的\",{\"2\":{\"880\":1}}],[\"之间的矛盾\",{\"2\":{\"685\":1}}],[\"之间的信息\",{\"2\":{\"162\":1}}],[\"之间\",{\"2\":{\"194\":1,\"215\":1,\"1786\":1,\"2235\":1}}],[\"之前的提示优化方法在大规模模型中表现良好\",{\"2\":{\"1736\":1}}],[\"之前的信息\",{\"2\":{\"881\":1}}],[\"之前突然想到人的一生无时无刻不在做着选择\",{\"2\":{\"39\":1}}],[\"之前声明函数\",{\"2\":{\"11\":1}}],[\"之前定义\",{\"2\":{\"11\":2}}],[\"之后定义\",{\"2\":{\"11\":2}}],[\"这篇文章介绍了一种称为\",{\"2\":{\"2689\":1}}],[\"这篇论文提出了一个新的跨任务instruction数据集\",{\"2\":{\"1368\":1}}],[\"这给我们带来了一些启示\",{\"2\":{\"2687\":1}}],[\"这表明在模型蒸馏过程中\",{\"2\":{\"2617\":1}}],[\"这表明deepseek\",{\"2\":{\"2588\":1}}],[\"这表明模型可能过拟合了训练集\",{\"2\":{\"1505\":1}}],[\"这时的\",{\"2\":{\"2517\":1}}],[\"这时可以尝试结合稀疏搜索\",{\"2\":{\"1949\":1}}],[\"这部分就不过多展开了\",{\"2\":{\"2682\":1}}],[\"这部分计算任务被卸载到\",{\"2\":{\"2468\":1}}],[\"这部分影响可以忽略不计\",{\"2\":{\"455\":1}}],[\"这限制了可以使用的最大设备数\",{\"2\":{\"2402\":1}}],[\"这两种工作流不仅为人工智能任务提供了高效解决方案\",{\"2\":{\"2325\":1}}],[\"这两种方法在性能上的差异如何\",{\"2\":{\"362\":1}}],[\"这增强了模型对短查询的拟合能力\",{\"2\":{\"2310\":1}}],[\"这需要大约\",{\"2\":{\"2145\":1}}],[\"这通常通过以下几种方法实现\",{\"2\":{\"2119\":1}}],[\"这项关键步骤有助于\",{\"2\":{\"2105\":1}}],[\"这在处理重要特征时起着关键作用\",{\"2\":{\"2085\":1}}],[\"这也可以被理解为将大矩阵运算拆分成多个小矩阵运算\",{\"2\":{\"2515\":1}}],[\"这也是一个需要考虑的挑战\",{\"2\":{\"2344\":1}}],[\"这也就是为什么众人都知\",{\"2\":{\"2145\":1}}],[\"这也提升了计算效率\",{\"2\":{\"2030\":1}}],[\"这也符合基本常识\",{\"2\":{\"1648\":1}}],[\"这简化了模型的复杂性\",{\"2\":{\"1864\":1}}],[\"这对于长序列任务尤为重要\",{\"2\":{\"2274\":1}}],[\"这对于llm来说尤其昂贵\",{\"2\":{\"931\":1}}],[\"这对计算资源提出了巨大的要求\",{\"2\":{\"1807\":1}}],[\"这可以被理解为策略与正\",{\"2\":{\"1727\":1}}],[\"这可能是未来研究的一个重要方向\",{\"2\":{\"1507\":1}}],[\"这可能导致偏差\",{\"2\":{\"2239\":1}}],[\"这可能导致计算效率未能达到预期\",{\"2\":{\"2203\":1}}],[\"这可能导致用户无法直接接触到底层提示\",{\"2\":{\"1392\":1}}],[\"这可能导致在性能上无法与同规模的密集型模型相比\",{\"2\":{\"1314\":1}}],[\"这会产生额外的通信量\",{\"2\":{\"2616\":1}}],[\"这会直接导致召回结果的相关性下降\",{\"2\":{\"2465\":1}}],[\"这会降低\",{\"2\":{\"2402\":1}}],[\"这会影响模型的训练效果\",{\"2\":{\"2331\":1}}],[\"这会影响检索阶段的匹配精度\",{\"2\":{\"1503\":1}}],[\"这会导致模型性能下降\",{\"2\":{\"1051\":1}}],[\"这会导致结果不准确\",{\"2\":{\"866\":1}}],[\"这主要是由于奖励黑客\",{\"2\":{\"1460\":1}}],[\"这与实际应用中智能体需要主动探索环境的情况不符\",{\"2\":{\"1453\":1}}],[\"这与传统有监督学习中的模型有本质区别\",{\"2\":{\"711\":1}}],[\"这意味着提示词的设计会直接影响模型的输出质量和行为表现\",{\"2\":{\"2681\":1}}],[\"这意味着最终每个节点都会得到相同的结果\",{\"2\":{\"2452\":1}}],[\"这意味着不同的rag系统之间可能存在较大的效果差异\",{\"2\":{\"1895\":1}}],[\"这意味着虽然表面上看训练集的表现提高了\",{\"2\":{\"1505\":1}}],[\"这意味着\",{\"2\":{\"1448\":1,\"2262\":1,\"2616\":1}}],[\"这意味着系统不仅依赖于单一索引\",{\"2\":{\"1285\":1}}],[\"这类似于cnn中的感受野概念\",{\"2\":{\"2260\":1}}],[\"这类记忆通常只能持续几秒钟\",{\"2\":{\"1947\":1}}],[\"这类平台通常提供图形化界面\",{\"2\":{\"1347\":1}}],[\"这类系统的主要特点是\",{\"2\":{\"1238\":1}}],[\"这为未来的模型优化提供了重要的启发\",{\"2\":{\"2627\":1}}],[\"这为未来开源语言模型的发展提供了新思路\",{\"2\":{\"1287\":1}}],[\"这为大型模型的推理提供了一种高效解决方案\",{\"2\":{\"2460\":1}}],[\"这为其他模型优化提供了启示\",{\"2\":{\"1244\":1}}],[\"这为模型的炼丹炉和炼丹材料的最适大小提供了指导\",{\"2\":{\"1201\":1}}],[\"这实际上是transformer的decoder部分\",{\"2\":{\"961\":1}}],[\"这不仅包括调用外部工具的准确性\",{\"2\":{\"2518\":1}}],[\"这不仅包括硬件资源的节省\",{\"2\":{\"794\":1}}],[\"这不仅会降低回答的准确性\",{\"2\":{\"2000\":1}}],[\"这不仅提升了训练速度\",{\"2\":{\"894\":1}}],[\"这反映了网络层输出之间的关系\",{\"2\":{\"880\":1}}],[\"这使得\",{\"2\":{\"2188\":1}}],[\"这使得模型能够忽略文本长度差异\",{\"2\":{\"2051\":1}}],[\"这使得基于相似度的方法难以挑选出合适的demonstration\",{\"2\":{\"949\":1}}],[\"这使得它在某些应用场景中的灵活性受到限制\",{\"2\":{\"2351\":1}}],[\"这使得它能更好地捕捉局部上下文信息\",{\"2\":{\"938\":1}}],[\"这使得它们成为实际应用中的理想选择\",{\"2\":{\"825\":1}}],[\"这使得代码更加简洁\",{\"2\":{\"10\":1}}],[\"这三种类型各有特点\",{\"2\":{\"780\":1}}],[\"这一提示明确了模型的角色\",{\"2\":{\"2690\":1}}],[\"这一指标确保了答案来源的可靠性\",{\"2\":{\"2566\":1}}],[\"这一步确保了所有节点在下一步的计算中都能使用一致的数据\",{\"2\":{\"2452\":1}}],[\"这一步由llm完成\",{\"2\":{\"1465\":1}}],[\"这一环节的效果对下游链路的准确性有着深远影响\",{\"2\":{\"2323\":1}}],[\"这一阶段是rag系统的核心目标所在\",{\"2\":{\"2305\":1}}],[\"这一阶段通过模型的推理能力\",{\"2\":{\"2171\":1}}],[\"这一阶段的\",{\"2\":{\"1382\":1}}],[\"这一层级可以被视为介于\",{\"2\":{\"1786\":1}}],[\"这一层级的特点是\",{\"2\":{\"1728\":1}}],[\"这一层级的\",{\"2\":{\"1238\":1}}],[\"这一特性弥补了通用大模型在某些垂直领域或专业领域中的知识不足问题\",{\"2\":{\"1664\":1}}],[\"这一特性使得强化学习适用于动态决策场景\",{\"2\":{\"760\":1}}],[\"这一模块能够为开发者提供明确的安全性评估指标\",{\"2\":{\"1407\":1}}],[\"这一分类系统为我们理解智能体的能力演进提供了清晰的框架\",{\"2\":{\"1188\":1}}],[\"这一过程通常由深度学习模型实现\",{\"2\":{\"2394\":1}}],[\"这一过程的核心目标是在保持语义连贯性的同时\",{\"2\":{\"2303\":1}}],[\"这一过程确保了用户能够快速获取与问题相关的信息\",{\"2\":{\"2272\":1}}],[\"这一过程提升了生成质量\",{\"2\":{\"1164\":1}}],[\"这一过程展示了蒙特卡洛方法如何通过简单的随机抽样解决几何问题\",{\"2\":{\"747\":1}}],[\"这一改变使得模型加载速度显著提升\",{\"2\":{\"1007\":1}}],[\"这一方法在统计学和计算机科学中具有重要地位\",{\"2\":{\"713\":1}}],[\"这一行和下一行代码是价值迭代和策略迭代的主要区别\",{\"2\":{\"647\":1}}],[\"这就是softmax中的分母\",{\"2\":{\"2670\":1}}],[\"这就是decode的过程\",{\"2\":{\"1782\":1}}],[\"这就像自动驾驶汽车有\",{\"2\":{\"1617\":1}}],[\"这就需要一些有效的模型压缩技术来降低模型部署的成本\",{\"2\":{\"692\":1}}],[\"这就属于icl的一个部分\",{\"2\":{\"477\":1}}],[\"这是减少单层神经网络中间激活的唯一方法\",{\"2\":{\"2706\":1}}],[\"这是为了扩展效率考虑\",{\"2\":{\"2697\":1}}],[\"这是grpo的一大创新\",{\"2\":{\"2396\":1}}],[\"这是一种二叉树集合\",{\"2\":{\"2195\":1}}],[\"这是一个测试文本\",{\"2\":{\"1208\":1}}],[\"这是通过自定义采样器实现的\",{\"2\":{\"2055\":1}}],[\"这是目前最为高级的\",{\"2\":{\"1429\":1}}],[\"这是\",{\"2\":{\"1336\":1}}],[\"这是因为向量化模型需要将大量词汇信息压缩成固定长度的向量表示\",{\"2\":{\"2444\":1}}],[\"这是因为\",{\"2\":{\"1321\":1}}],[\"这是预训练模型的第一步\",{\"2\":{\"1253\":1}}],[\"这是最为经典的一种剪枝流程\",{\"2\":{\"795\":1}}],[\"这是其在强化学习中广泛应用的基础\",{\"2\":{\"786\":1}}],[\"这是初始化长度为n的哈希表全部为\",{\"2\":{\"762\":1}}],[\"这是解决超大规模计算瓶颈的关键思路\",{\"2\":{\"664\":1}}],[\"这是在更新价值函数时用于调整估计值的关键部分\",{\"2\":{\"643\":1}}],[\"这是生成每个token的理论最小时间\",{\"2\":{\"483\":1}}],[\"这个通讯开销也不容忽视\",{\"2\":{\"2660\":1}}],[\"这个同步点让不同gpu之间交换信息\",{\"2\":{\"2602\":1}}],[\"这个\",{\"2\":{\"2379\":1}}],[\"这个等式不太对劲\",{\"2\":{\"2379\":1}}],[\"这个流程可以总结为一个\",{\"2\":{\"2363\":1}}],[\"这个耗时的近似估算和\",{\"2\":{\"2145\":1}}],[\"这个过程涉及矩阵乘法和加法操作\",{\"2\":{\"2526\":1}}],[\"这个过程会不断进行思考和迭代\",{\"2\":{\"2363\":1}}],[\"这个过程是迭代的\",{\"2\":{\"2026\":1}}],[\"这个过程称为safe\",{\"2\":{\"1925\":1}}],[\"这个过程包括\",{\"2\":{\"1809\":1}}],[\"这个值越高\",{\"2\":{\"1594\":1}}],[\"这个定义包含了智能体实现其功能所需的四大关键能力\",{\"2\":{\"1474\":1}}],[\"这个乘积是通过使用一个小型校准数据集来近似计算的\",{\"2\":{\"1050\":1}}],[\"这个数据集可以是用于教师模型预训练的数据集\",{\"2\":{\"715\":1}}],[\"这个散度在训练过程中作为奖励函数中的惩罚项被纳入\",{\"2\":{\"537\":1}}],[\"这个公式可以帮助模型在不同上下文长度下保持较好的性能\",{\"2\":{\"276\":1}}],[\"这个函数的输出值在0到1之间\",{\"2\":{\"90\":1}}],[\"这种实现没有进行clip操作\",{\"2\":{\"2561\":1}}],[\"这种技术在处理大型深度学习模型时尤为重要\",{\"2\":{\"2537\":1}}],[\"这种策略对于需要保留语义连贯性的文档处理任务非常有用\",{\"2\":{\"2599\":1}}],[\"这种策略有效地减少了\",{\"2\":{\"2486\":1}}],[\"这种策略大大压缩了模型的大小\",{\"2\":{\"1588\":1}}],[\"这种限制可能导致遗漏重要上下文或相关信息\",{\"2\":{\"2483\":1}}],[\"这种限制显得不再必要\",{\"2\":{\"1884\":1}}],[\"这种智能体不仅能处理复杂的文字任务\",{\"2\":{\"2443\":1}}],[\"这种智能体主要应用于特定的任务场景\",{\"2\":{\"2418\":1}}],[\"这种提升主要得益于参数的分片存储和有效的通信策略\",{\"2\":{\"2369\":1}}],[\"这种提升源于模型内部的自我调整\",{\"2\":{\"2070\":1}}],[\"这种交互模式简单直观\",{\"2\":{\"2333\":1}}],[\"这种交互是迭代进行的\",{\"2\":{\"639\":1}}],[\"这种工具的使用\",{\"2\":{\"2269\":1}}],[\"这种工作流类似于一个人在编写文档时反复修改\",{\"2\":{\"2259\":1}}],[\"这种工作流非常适合处理子任务不可预知的复杂任务\",{\"2\":{\"2139\":1}}],[\"这种自我改进的能力展示了强化学习的强大与优雅\",{\"2\":{\"2248\":1}}],[\"这种场景非常适合采用\",{\"2\":{\"2185\":1}}],[\"这种约束会极大限制\",{\"2\":{\"2094\":1}}],[\"这种通信具有数据量较小\",{\"2\":{\"2081\":1}}],[\"这种初始化确保了训练开始时旁路矩阵依然是0矩阵\",{\"2\":{\"2062\":1}}],[\"这种做法表现更优\",{\"2\":{\"2037\":1}}],[\"这种系统不仅能够完成复杂任务\",{\"2\":{\"1904\":1}}],[\"这种能力要求模型能够对比文档内容\",{\"2\":{\"2506\":1}}],[\"这种能力显著增强了系统的自主性\",{\"2\":{\"1847\":1}}],[\"这种能力通过外部向量存储和检索来实现\",{\"2\":{\"1833\":1}}],[\"这种简化的训练过程使得模型在保持性能的同时\",{\"2\":{\"1804\":1}}],[\"这种灵活性使得模型能够更加高效地处理不同的任务\",{\"2\":{\"1764\":1}}],[\"这种长度通常足够包含一个完整的细节或论点\",{\"2\":{\"1763\":1}}],[\"这种长度的不一致可能带来以下问题\",{\"2\":{\"1513\":1}}],[\"这种共享权值的方法不仅降低了计算复杂度\",{\"2\":{\"1746\":1}}],[\"这种差异反映了不同任务类型对智能体多回合交互能力的不同要求\",{\"2\":{\"1701\":1}}],[\"这种创新方法使得在单gpu上微调最大的公开可用模型成为可能\",{\"2\":{\"1679\":1}}],[\"这种创新性的内存管理方式为大规模模型推理提供了新的解决方案\",{\"2\":{\"846\":1}}],[\"这种视角采用了agg聚合操作中的\",{\"2\":{\"1673\":1}}],[\"这种改进使得微调过程更加稳定\",{\"2\":{\"1668\":1}}],[\"这种改进提高了模型的效率和一致性\",{\"2\":{\"1048\":1}}],[\"这种奖励函数的设计需要大量专业人士的精力\",{\"2\":{\"1633\":1}}],[\"这种选择的原因在于kl距离的非对称性\",{\"2\":{\"1596\":1}}],[\"这种哈希函数还需满足另一个条件\",{\"2\":{\"1559\":1}}],[\"这种碰撞正是分组的关键\",{\"2\":{\"1559\":1}}],[\"这种顾虑导致完全依赖通用大模型能力的应用方案在数据安全性和效果之间不得不做出取舍\",{\"2\":{\"1512\":1}}],[\"这种循环机制能够帮助我们不断改进知识库\",{\"2\":{\"1510\":1}}],[\"这种幻觉问题难以区分\",{\"2\":{\"1468\":1}}],[\"这种集体决策方式可以有效解决单个智能体难以应对的问题\",{\"2\":{\"1338\":1}}],[\"这种多样性使得系统能够应对不同场景和问题\",{\"2\":{\"1338\":1}}],[\"这种多重索引策略使得\",{\"2\":{\"1285\":1}}],[\"这种机制能够实现任务分工\",{\"2\":{\"1935\":1}}],[\"这种机制旨在防止策略过度偏离sft模型\",{\"2\":{\"1621\":1}}],[\"这种机制不仅提升了处理效率\",{\"2\":{\"1332\":1}}],[\"这种机制解决了传统循环神经网络\",{\"2\":{\"97\":1}}],[\"这种训练数据的增加有助于学生模型的学习过程\",{\"2\":{\"1224\":1}}],[\"这种编码方式确保每个位置的编码值都位于\",{\"2\":{\"1246\":1}}],[\"这种编码方式具有生成规律性和一定的外推能力\",{\"2\":{\"1147\":1}}],[\"这种编码方式虽然简单\",{\"2\":{\"1025\":1}}],[\"这种设计方式不仅有助于提高检索的精确度\",{\"2\":{\"2364\":1}}],[\"这种设计为未来agent技术的发展提供了重要启示\",{\"2\":{\"1986\":1}}],[\"这种设计为自然语言处理\",{\"2\":{\"1088\":1}}],[\"这种设计允许系统在不同阶段调用不同的模型或模块\",{\"2\":{\"1786\":1}}],[\"这种设计背后的逻辑是\",{\"2\":{\"1306\":1}}],[\"这种设计使得总参数量为46\",{\"2\":{\"1121\":1}}],[\"这种设计的核心思想是利用正弦函数的周期性和连续性\",{\"2\":{\"263\":1}}],[\"这种统一的处理方式使得模型在应对不同任务时无需进行结构上的调整\",{\"2\":{\"978\":1}}],[\"这种格式允许更细致的注意力策略\",{\"2\":{\"917\":1}}],[\"这种基于关系的方法能够更全面地传递教师模型中蕴含的信息\",{\"2\":{\"880\":1}}],[\"这种情况下会直接影响后续的文本向量化效果和语义理解\",{\"2\":{\"1457\":1}}],[\"这种情况下\",{\"2\":{\"750\":1,\"1728\":1}}],[\"这种适应能力来源于模型在预训练阶段学到的通用知识\",{\"2\":{\"602\":1}}],[\"这种方法结合了语义匹配和时间排序\",{\"2\":{\"2672\":1}}],[\"这种方法结合了大范围上下文和精准匹配子文档的优点\",{\"2\":{\"2236\":1}}],[\"这种方法适合处理具有明确结构化特征的文本\",{\"2\":{\"2650\":1}}],[\"这种方法适用于需要多粒度语义查询的场景\",{\"2\":{\"2635\":1}}],[\"这种方法适用于需要控制生成文本风格和随机程度的场景\",{\"2\":{\"416\":1}}],[\"这种方法适用于对性能要求较高的场景\",{\"2\":{\"795\":1}}],[\"这种方法不需要同步点\",{\"2\":{\"2609\":1}}],[\"这种方法不仅能使模型的回答更加精准\",{\"2\":{\"2693\":1}}],[\"这种方法不仅减少了人为干预\",{\"2\":{\"2283\":1}}],[\"这种方法不仅减少了对外部样本库的依赖\",{\"2\":{\"1273\":1}}],[\"这种方法不仅节省计算资源\",{\"2\":{\"1695\":1}}],[\"这种方法不仅提升了模型的适应性\",{\"2\":{\"1660\":1}}],[\"这种方法不仅提高了模型在特定任务上的适应能力\",{\"2\":{\"1979\":1}}],[\"这种方法不仅提高了模型的适应性\",{\"2\":{\"1206\":1}}],[\"这种方法不仅提高了计算效率\",{\"2\":{\"1448\":1}}],[\"这种方法解决了传统sample\",{\"2\":{\"2591\":1,\"2654\":1}}],[\"这种方法避免了新旧策略一致的情况\",{\"2\":{\"2569\":1}}],[\"这种方法有效减少了方差\",{\"2\":{\"2440\":1,\"2463\":1}}],[\"这种方法有助于优化资源使用并提高计算效率\",{\"2\":{\"1410\":1}}],[\"这种方法提供了一种无需人工干预即可检查信息有效性的自动化方式\",{\"2\":{\"2436\":1}}],[\"这种方法帮助缓解缓存压力\",{\"2\":{\"2356\":1}}],[\"这种方法为其他领域的优化提供了新的思路\",{\"2\":{\"2240\":1}}],[\"这种方法为不同agent在多场景下的性能对比提供了统一的参考\",{\"2\":{\"1268\":1}}],[\"这种方法允许模型使用不同的思维路径\",{\"2\":{\"2094\":1}}],[\"这种方法允许在不同任务中灵活应用多个低秩适应技术\",{\"2\":{\"1692\":1}}],[\"这种方法显著提高了思维链方法的性能\",{\"2\":{\"2042\":1}}],[\"这种方法交替生成推理轨迹和特定任务的动作\",{\"2\":{\"2011\":1}}],[\"这种方法大大降低了计算量\",{\"2\":{\"1824\":1}}],[\"这种方法大大增加了计算成本\",{\"2\":{\"1813\":1}}],[\"这种方法简单但有效\",{\"2\":{\"1708\":1}}],[\"这种方法采用基于svd\",{\"2\":{\"1653\":1}}],[\"这种方法可以有效地将计算任务分配到多个gpu上\",{\"2\":{\"2555\":1}}],[\"这种方法可以有效提高训练效率\",{\"2\":{\"2059\":1}}],[\"这种方法可以节省一定的时间和计算资源\",{\"2\":{\"826\":1}}],[\"这种方法可能会失效\",{\"2\":{\"1469\":1}}],[\"这种方法使用规划域定义语言\",{\"2\":{\"1465\":1}}],[\"这种方法使得模型在训练过程中就能够适应量化带来的噪声\",{\"2\":{\"1160\":1}}],[\"这种方法被称为最近邻搜索\",{\"2\":{\"1377\":1}}],[\"这种方法是完全合理的\",{\"2\":{\"1377\":1}}],[\"这种方法实现起来非常容易\",{\"2\":{\"1366\":1}}],[\"这种方法特别适用于复杂问题\",{\"2\":{\"1835\":1}}],[\"这种方法特别适用于对模型精度要求较高的场景\",{\"2\":{\"1355\":1}}],[\"这种方法特别适用于多种任务\",{\"2\":{\"901\":1}}],[\"这种方法也存在一定的挑战\",{\"2\":{\"1321\":1}}],[\"这种方法能够有效稳定训练过程\",{\"2\":{\"2692\":1}}],[\"这种方法能够有效减少传递给\",{\"2\":{\"2154\":1}}],[\"这种方法能够提供多样化的种子数据\",{\"2\":{\"2220\":1}}],[\"这种方法能够生成语义孤立且有意义的分块\",{\"2\":{\"1321\":1}}],[\"这种方法能够训练模型理解语言的不同方面\",{\"2\":{\"1102\":1}}],[\"这种方法充分利用了\",{\"2\":{\"1275\":1}}],[\"这种方法充分利用了模型的预训练知识\",{\"2\":{\"477\":1}}],[\"这种方法无法捕捉序列中元素之间的相对位置信息\",{\"2\":{\"1215\":1}}],[\"这种方法将拥有65b参数的模型内存需求从\",{\"2\":{\"1735\":1}}],[\"这种方法将上下文学习目标与传统的语言建模目标相结合\",{\"2\":{\"1175\":1}}],[\"这种方法将剪枝过程融入到模型训练中\",{\"2\":{\"826\":1}}],[\"这种方法主要包括以下三种蒸馏方式\",{\"2\":{\"1124\":1}}],[\"这种方法主要适用于以下场景\",{\"2\":{\"995\":1}}],[\"这种方法一次性地针对整组权重\",{\"2\":{\"1094\":1}}],[\"这种方法强调使用大量数据和更大的模型参数\",{\"2\":{\"1062\":1}}],[\"这种方法依赖于llms强大的语言理解和生成能力\",{\"2\":{\"1032\":1}}],[\"这种方法旨在减轻对齐税\",{\"2\":{\"992\":1}}],[\"这种方法通过提供样本问题\",{\"2\":{\"1940\":1}}],[\"这种方法通过对每个prompt\",{\"2\":{\"1901\":1}}],[\"这种方法通过调整学习率提高了训练效率\",{\"2\":{\"1832\":1}}],[\"这种方法通过引入用户定义的插件\",{\"2\":{\"1849\":1}}],[\"这种方法通过引入\",{\"2\":{\"1619\":1}}],[\"这种方法通过在句子结尾或标点处分块\",{\"2\":{\"1425\":1}}],[\"这种方法通过结合检索和模型评估\",{\"2\":{\"1075\":1}}],[\"这种方法通过将低于阈值的参数置零的方式对个别权重或神经元进行处理\",{\"2\":{\"931\":1}}],[\"这种方法通常侧重于知识迁移部分\",{\"2\":{\"954\":1}}],[\"这种方法的劣势之一是空泡率\",{\"2\":{\"2691\":1}}],[\"这种方法的优势在于\",{\"2\":{\"2042\":1}}],[\"这种方法的目的在于引入量化误差\",{\"2\":{\"1355\":1}}],[\"这种方法的核心在于通过语义相似性度量\",{\"2\":{\"910\":1}}],[\"这种方法的核心思想是通过试错\",{\"2\":{\"572\":1}}],[\"这种方法的特点是学习目标非常明确\",{\"2\":{\"811\":1}}],[\"这种方法在扩展性上通常表现出色\",{\"2\":{\"2374\":1}}],[\"这种方法在扩展上下文窗口时表现出较好的困惑度\",{\"2\":{\"180\":1}}],[\"这种方法在降低计算和存储成本的同时\",{\"2\":{\"1875\":1}}],[\"这种方法在多种语言\",{\"2\":{\"1665\":1}}],[\"这种方法在attention矩阵上增加了一个可训练偏置项\",{\"2\":{\"1108\":1}}],[\"这种方法在实际应用中面临一定限制\",{\"2\":{\"995\":1}}],[\"这种方法在机器学习和数据预处理中广泛使用\",{\"2\":{\"871\":1}}],[\"这种方法在复杂推理任务中表现尤为突出\",{\"2\":{\"596\":1}}],[\"这种方法在处理长序列时会导致计算成本过高\",{\"2\":{\"147\":1}}],[\"这种方式不仅能够帮助模型更准确地理解用户意图\",{\"2\":{\"2687\":1}}],[\"这种方式降低了模型对事实实体\",{\"2\":{\"2608\":1}}],[\"这种方式能够有效验证系统在复杂场景下的鲁棒性和功能调用能力\",{\"2\":{\"2384\":1}}],[\"这种方式能够增加\",{\"2\":{\"2197\":1}}],[\"这种方式通过程序化的方式解决问题\",{\"2\":{\"1730\":1}}],[\"这种方式可以帮助保留句子的完整性和段落的连贯性\",{\"2\":{\"1598\":1}}],[\"这种方式可以有效地识别真实世界中潜在的严重故障\",{\"2\":{\"1407\":1}}],[\"这种方式可以提升生成质量\",{\"2\":{\"295\":1}}],[\"这种方式的优点在于能够保持文档的自然结构\",{\"2\":{\"1379\":1}}],[\"这种方式极大地减少了计算复杂度\",{\"2\":{\"1207\":1}}],[\"这种方式动态调整候选词集合大小\",{\"2\":{\"340\":1}}],[\"这种方式使得query和key能够更好地适配扩展上下文窗口中的远距离依赖\",{\"2\":{\"252\":1}}],[\"这种调整在保持模型参数量基本不变的同时\",{\"2\":{\"220\":1}}],[\"这种归一化方式能够消除样本间的大小关系\",{\"2\":{\"190\":1}}],[\"这种分块与跨块结合的方法为长文本处理开辟了新方向\",{\"2\":{\"155\":1}}],[\"这些框架通常配备了调试工具\",{\"2\":{\"2702\":1}}],[\"这些框架提供了便捷的工具\",{\"2\":{\"1250\":1}}],[\"这些元数据不仅能够提升知识检索的准确性\",{\"2\":{\"2675\":1}}],[\"这些元素可以用于构成更大的语义单位\",{\"2\":{\"1367\":1}}],[\"这些问题以临时句子中概率低于阈值的\",{\"2\":{\"2578\":1}}],[\"这些操作也是高度并行化的\",{\"2\":{\"2579\":1}}],[\"这些操作可以被高效地并行执行\",{\"2\":{\"2571\":1}}],[\"这些操作涉及大量的矩阵计算\",{\"2\":{\"2563\":1}}],[\"这些操作在深度学习框架中会被高度优化\",{\"2\":{\"2526\":1}}],[\"这些函数在数学上是已知的\",{\"2\":{\"2526\":1}}],[\"这些层的计算过程是基于输入数据应用某种非线性函数\",{\"2\":{\"2526\":1}}],[\"这些计算任务依然在\",{\"2\":{\"2468\":1}}],[\"这些则保留在\",{\"2\":{\"2447\":1}}],[\"这些被卸载到\",{\"2\":{\"2447\":1}}],[\"这些算法通过估计每个状态\",{\"2\":{\"2430\":1}}],[\"这些算法通过模拟环境中的可能路径\",{\"2\":{\"2378\":1}}],[\"这些算法通过牺牲少量精度来显著提升速度\",{\"2\":{\"2102\":1}}],[\"这些指标能够有效衡量模型在意图分流任务中的表现\",{\"2\":{\"2354\":1}}],[\"这些指标包括但不限于\",{\"2\":{\"2292\":1}}],[\"这些向量不仅包括文档在不同大小下的分块\",{\"2\":{\"2304\":1}}],[\"这些信息包括但不限于\",{\"2\":{\"2269\":1}}],[\"这些错误可能导致训练失败或结果不理想\",{\"2\":{\"2268\":1}}],[\"这些策略通过动态调整奖励分布\",{\"2\":{\"2213\":1}}],[\"这些树是独立随机构建的\",{\"2\":{\"2195\":1}}],[\"这些参数包括\",{\"2\":{\"2177\":1}}],[\"这些都是理论下限\",{\"2\":{\"2145\":1}}],[\"这些行为是模型与强化学习环境互动的结果\",{\"2\":{\"2122\":1}}],[\"这些卡既用作训练也用作生成\",{\"2\":{\"2079\":1}}],[\"这些是由模型生成的最高分和最低分响应构成的\",{\"2\":{\"1976\":1}}],[\"这些矩阵仅放大了对下游任务有用的特征\",{\"2\":{\"1962\":1}}],[\"这些矩阵仅放大对下游任务有用的特征\",{\"2\":{\"1853\":1}}],[\"这些\",{\"2\":{\"1873\":1}}],[\"这些virtual\",{\"2\":{\"1865\":1}}],[\"这些工具各有特点\",{\"2\":{\"2270\":1}}],[\"这些工具不仅扩展了单一智能体的能力\",{\"2\":{\"1485\":1}}],[\"这些工具为用户提供了强大的自动化能力\",{\"2\":{\"1439\":1}}],[\"这些工具确保了高质量数据的选择\",{\"2\":{\"1167\":1}}],[\"这些标签是可以通过学习调整的\",{\"2\":{\"1418\":1}}],[\"这些局限性包括以下几个方面\",{\"2\":{\"1378\":1}}],[\"这些系统在学术和专业领域中表现出色\",{\"2\":{\"1289\":1}}],[\"这些字符在预训练时未见过\",{\"2\":{\"1254\":1}}],[\"这些步骤不仅能够影响最终的输出\",{\"2\":{\"1224\":1}}],[\"这些数据需要在所有节点之间进行汇总\",{\"2\":{\"2452\":1}}],[\"这些数据集涵盖了对话翻译\",{\"2\":{\"2138\":1}}],[\"这些数据集涵盖了多语言\",{\"2\":{\"741\":1}}],[\"这些数据来源多样且公开\",{\"2\":{\"1211\":1}}],[\"这些改进旨在更高效地捕捉序列中元素的相对位置信息\",{\"2\":{\"1166\":1}}],[\"这些任务往往没有唯一的正确答案\",{\"2\":{\"1118\":1}}],[\"这些措施不仅提高了英语内容处理效率\",{\"2\":{\"1117\":1}}],[\"这些示意图展示了不同粒度下的浮点数到整数的转换过程\",{\"2\":{\"1065\":1}}],[\"这些技术在实际应用中具有重要价值\",{\"2\":{\"2166\":1}}],[\"这些技术框架的共同点在于通过集成外部工具的能力来增强模型的功能\",{\"2\":{\"1569\":1}}],[\"这些技术用于提高模型对长文本的处理能力\",{\"2\":{\"1041\":1}}],[\"这些技术的目标是减少模型的参数数量和计算量\",{\"2\":{\"763\":1}}],[\"这些技术包括token级别的kl惩罚\",{\"2\":{\"505\":1}}],[\"这些大模型在许多任务中取得了突破性的进展\",{\"2\":{\"728\":1}}],[\"这些教师模型一般来自闭源的大语言模型\",{\"2\":{\"677\":1}}],[\"这些样本作为一个离线数据集提供给代理\",{\"2\":{\"618\":1}}],[\"这些方法通过引入稳健性约束\",{\"2\":{\"2405\":1}}],[\"这些方法通过调整模型选择词语的概率分布\",{\"2\":{\"249\":1}}],[\"这些方法不仅能降低显存消耗\",{\"2\":{\"2073\":1}}],[\"这些方法不仅能够改善模型的训练效果\",{\"2\":{\"505\":1}}],[\"这些方法并没有得到广泛应用\",{\"2\":{\"1869\":1}}],[\"这些方法与mrkl系统类似\",{\"2\":{\"1569\":1}}],[\"这些优化是否会变得不再必要\",{\"2\":{\"432\":1}}],[\"这些变种通过引入更复杂的激活函数\",{\"2\":{\"138\":1}}],[\"这些模型具备丰富的世界知识\",{\"2\":{\"2443\":1}}],[\"这些模型会考虑更多的特征\",{\"2\":{\"2394\":1}}],[\"这些模型通过先进的算法\",{\"2\":{\"2155\":1}}],[\"这些模型都基于llm初始化或改进\",{\"2\":{\"1954\":1}}],[\"这些模型都基于大型语言模型\",{\"2\":{\"1539\":1}}],[\"这些模型在搜索时追求的是语义上的相似性\",{\"2\":{\"1377\":1}}],[\"这些模型不仅推动了自然语言处理技术的进步\",{\"2\":{\"99\":1}}],[\"这些模块分别承担了以下功能\",{\"2\":{\"121\":1}}],[\"这些权重用于聚合序列中相关性更高的信息\",{\"2\":{\"112\":1}}],[\"这么一想就感觉自己基础还是很薄弱的\",{\"2\":{\"56\":1}}],[\"这里近似后io复杂度为\",{\"2\":{\"2653\":1}}],[\"这里确实只用到算到\",{\"2\":{\"2349\":1}}],[\"这里就需要将大模型中的不同\",{\"2\":{\"2108\":1}}],[\"这里需要根据具体需求选择适合的模型\",{\"2\":{\"1999\":1}}],[\"这里需要显式将梯度置为0\",{\"2\":{\"640\":1}}],[\"这里的\",{\"2\":{\"2124\":1}}],[\"这里的动作是一个完整的token序列\",{\"2\":{\"1787\":1}}],[\"这里的encoder和decoder命名与传统意义上的transformer结构不同\",{\"2\":{\"1237\":1}}],[\"这里的高效主要还是体现在多轮对话场景下\",{\"2\":{\"881\":1}}],[\"这里将长度排序\",{\"2\":{\"917\":1}}],[\"这里\",{\"2\":{\"228\":1,\"2306\":1}}],[\"这里没有\",{\"2\":{\"48\":1}}],[\"这里可以直接用\",{\"2\":{\"27\":1}}],[\"这里不用写\",{\"2\":{\"22\":1}}],[\"这里汇总了毕业设计相关资料与进展\",{\"2\":{\"4\":1}}],[\"这样x1x\",{\"2\":{\"2537\":1}}],[\"这样修正后的形式可以更好地适应大模型场景\",{\"2\":{\"2415\":1,\"2441\":1}}],[\"这样做的好处是可以取长补短\",{\"2\":{\"2335\":1}}],[\"这样\",{\"2\":{\"2129\":1}}],[\"这样就避免了对于system\",{\"2\":{\"2064\":1}}],[\"这样在对后面的token计算attention时\",{\"2\":{\"1870\":1}}],[\"这样在进行搜索时\",{\"2\":{\"1559\":1}}],[\"这样一进一出抵消掉了\",{\"2\":{\"783\":1}}],[\"这样的场景\",{\"2\":{\"2117\":1}}],[\"这样的分配方法很容易引起\",{\"2\":{\"1978\":1}}],[\"这样的固定尺寸\",{\"2\":{\"1978\":1}}],[\"这样的策略旨在增强吞吐量并支持更长的序列\",{\"2\":{\"1448\":1}}],[\"这样的指令\",{\"2\":{\"1420\":1}}],[\"这样的模型拥有数以百亿计的参数\",{\"2\":{\"728\":1}}],[\"这样的过程可以用以下形式表示\",{\"2\":{\"618\":1}}],[\"这样可以节省时间\",{\"2\":{\"2331\":1}}],[\"这样可以避免打断句子\",{\"2\":{\"1652\":1}}],[\"这样可以利用之前迭代的策略产生的数据\",{\"2\":{\"623\":1}}],[\"这样可以保留sft模型的既有能力\",{\"2\":{\"603\":1}}],[\"这样gae方法就转变为蒙特卡洛估计方法\",{\"2\":{\"570\":1}}],[\"这样能防止命名冲突\",{\"2\":{\"27\":1}}],[\"这样你在代码中就可以直接使用\",{\"2\":{\"22\":1}}],[\"这样更直接\",{\"2\":{\"11\":1}}],[\"`long\",{\"2\":{\"762\":1}}],[\"``\",{\"2\":{\"47\":1}}],[\"```python\",{\"2\":{\"1984\":1}}],[\"```cpp\",{\"2\":{\"10\":1,\"12\":1}}],[\"```\",{\"2\":{\"10\":1}}],[\"`\",{\"2\":{\"14\":1}}],[\"`using`\",{\"2\":{\"10\":1}}],[\"0513\",{\"2\":{\"2603\":1,\"2617\":1}}],[\"05118\",{\"2\":{\"2368\":1}}],[\"0上的平均长度为2218个token\",{\"2\":{\"2588\":1}}],[\"0xw0​x\",{\"2\":{\"2115\":1}}],[\"0w0​\",{\"2\":{\"2115\":1}}],[\"0排行榜上\",{\"2\":{\"2076\":1}}],[\"0a0​\",{\"2\":{\"1787\":1}}],[\"0s0​\",{\"2\":{\"1787\":1}}],[\"0~7\",{\"2\":{\"1258\":1,\"1306\":1}}],[\"0的梯度裁剪\",{\"2\":{\"1162\":1}}],[\"02860\",{\"2\":{\"1647\":1}}],[\"02\",{\"2\":{\"932\":3,\"1011\":3}}],[\"024\",{\"2\":{\"837\":1,\"1007\":1,\"1141\":1,\"1292\":2}}],[\"0^\",{\"2\":{\"778\":3}}],[\"0ll\",{\"2\":{\"762\":2}}],[\"07909\",{\"2\":{\"631\":1}}],[\"0ms\",{\"2\":{\"483\":1,\"2145\":1}}],[\"03741\",{\"2\":{\"1920\":1}}],[\"03341\",{\"2\":{\"469\":1}}],[\"03220\",{\"2\":{\"153\":1}}],[\"0$$\",{\"2\":{\"293\":1}}],[\"0​\",{\"2\":{\"285\":1}}],[\"0f\",{\"2\":{\"285\":1}}],[\"0182\",{\"2\":{\"837\":1}}],[\"011作为最优分词结果\",{\"2\":{\"444\":1}}],[\"011\",{\"2\":{\"444\":1}}],[\"01\",{\"2\":{\"261\":3}}],[\"044715x³\",{\"2\":{\"199\":1}}],[\"0或1\",{\"2\":{\"66\":1}}],[\"002\",{\"2\":{\"2655\":1}}],[\"003\",{\"2\":{\"2223\":1}}],[\"0010\",{\"2\":{\"2235\":2}}],[\"001\",{\"2\":{\"1323\":1,\"2235\":1}}],[\"006\",{\"2\":{\"444\":1}}],[\"005\",{\"2\":{\"444\":1}}],[\"000\",{\"2\":{\"194\":1,\"238\":1,\"1644\":1}}],[\"000z\",{\"0\":{\"56\":1}}],[\"00\",{\"0\":{\"56\":2}}],[\"0到1之间\",{\"2\":{\"42\":1,\"90\":1}}],[\"0\",{\"2\":{\"10\":2,\"11\":3,\"12\":1,\"15\":1,\"22\":1,\"27\":1,\"47\":4,\"48\":1,\"105\":2,\"135\":1,\"164\":5,\"184\":1,\"189\":1,\"194\":3,\"199\":2,\"213\":8,\"218\":1,\"238\":3,\"247\":1,\"261\":3,\"263\":1,\"276\":1,\"285\":2,\"324\":2,\"332\":3,\"346\":1,\"391\":2,\"407\":1,\"444\":4,\"471\":1,\"497\":1,\"508\":1,\"515\":3,\"640\":3,\"647\":3,\"656\":10,\"769\":3,\"783\":2,\"820\":1,\"837\":4,\"840\":1,\"843\":1,\"917\":1,\"932\":6,\"1011\":6,\"1025\":7,\"1208\":1,\"1246\":2,\"1323\":1,\"1347\":2,\"1364\":3,\"1398\":1,\"1435\":3,\"1437\":6,\"1536\":2,\"1622\":1,\"1644\":1,\"1731\":2,\"1740\":1,\"1756\":1,\"1771\":2,\"1787\":2,\"1795\":3,\"1816\":3,\"1817\":1,\"1883\":1,\"1928\":1,\"1949\":1,\"1984\":2,\"2013\":3,\"2121\":1,\"2235\":1,\"2253\":2,\"2308\":2,\"2327\":3,\"2400\":3,\"2433\":2,\"2479\":2,\"2539\":2,\"2589\":1,\"2618\":1}}],[\"rm\",{\"2\":{\"2546\":1}}],[\"rms\",{\"2\":{\"1265\":1,\"1358\":1}}],[\"rmsnorm\",{\"2\":{\"889\":1,\"1002\":1,\"1112\":1,\"1127\":4,\"1155\":1,\"1156\":1,\"1287\":1}}],[\"running\",{\"2\":{\"2408\":1}}],[\"rbr​\",{\"2\":{\"2286\":2,\"2318\":1,\"2379\":2}}],[\"r=t=0∑t​γtrt​\",{\"2\":{\"2124\":1}}],[\"r=∑t=0tγtrtr\",{\"2\":{\"2124\":1}}],[\"r≪min\",{\"2\":{\"2013\":1}}],[\"r≪min⁡\",{\"2\":{\"2013\":1}}],[\"r∗\",{\"2\":{\"1994\":2}}],[\"rϕ​\",{\"2\":{\"1685\":1}}],[\"rϕ\",{\"2\":{\"1685\":1}}],[\"rgr\",{\"2\":{\"2446\":1}}],[\"rg​\",{\"2\":{\"1683\":2}}],[\"rg\",{\"2\":{\"1683\":2}}],[\"rgb\",{\"2\":{\"227\":1}}],[\"r2r\",{\"2\":{\"2446\":1}}],[\"r2​\",{\"2\":{\"1683\":2}}],[\"r2\",{\"2\":{\"1683\":2}}],[\"r^\",{\"2\":{\"1536\":2,\"1994\":1}}],[\"rkr​\",{\"2\":{\"1318\":1}}],[\"rnr​\",{\"2\":{\"1318\":1}}],[\"rnn的位置编码\",{\"2\":{\"1418\":1}}],[\"rnn位置编码的效率问题\",{\"2\":{\"1463\":1}}],[\"rnn位置编码\",{\"0\":{\"1328\":1},\"2\":{\"1373\":1}}],[\"rnn\",{\"2\":{\"39\":1,\"97\":1,\"144\":1,\"1085\":1,\"1328\":1,\"1463\":1,\"1507\":1,\"1555\":1,\"1606\":1}}],[\"rd×d维度一致性\",{\"2\":{\"1227\":1}}],[\"rs\",{\"2\":{\"1164\":1}}],[\"rrr\",{\"2\":{\"868\":1}}],[\"rt∣st=s\",{\"2\":{\"2306\":1}}],[\"rtr​\",{\"2\":{\"2286\":1,\"2431\":1}}],[\"rtr\",{\"2\":{\"2124\":1}}],[\"rtn\",{\"2\":{\"2085\":1}}],[\"rt=r\",{\"2\":{\"1732\":1}}],[\"rt=−β⋅\",{\"2\":{\"1732\":1}}],[\"rt​∣st​=s\",{\"2\":{\"2306\":1}}],[\"rt​=r\",{\"2\":{\"1732\":1}}],[\"rt​=−β⋅\",{\"2\":{\"1732\":1}}],[\"rt​\",{\"2\":{\"618\":1}}],[\"rt​+γ⋅vt+1​−vt​\",{\"2\":{\"1591\":1}}],[\"rt​+γrt+1​+⋯+γnq\",{\"2\":{\"672\":1}}],[\"rt​+γamax​q\",{\"2\":{\"640\":1,\"710\":1}}],[\"rt​+γqπ​\",{\"2\":{\"779\":1}}],[\"rt​+γq\",{\"2\":{\"611\":1}}],[\"rt​+γvπ​\",{\"2\":{\"748\":1}}],[\"rt​+γv\",{\"2\":{\"608\":1}}],[\"rt\",{\"2\":{\"618\":1}}],[\"rt+γ⋅vt+1−vt\",{\"2\":{\"1591\":1}}],[\"rt+γrt+1+⋯+γnq\",{\"2\":{\"672\":1}}],[\"rt+γmax⁡aq\",{\"2\":{\"640\":1,\"710\":1}}],[\"rt+γqπ\",{\"2\":{\"779\":1}}],[\"rt+γq\",{\"2\":{\"611\":1}}],[\"rt+γvπ\",{\"2\":{\"748\":1}}],[\"rt+γv\",{\"2\":{\"608\":1}}],[\"rtx\",{\"2\":{\"483\":1,\"2145\":1}}],[\"rationale\",{\"2\":{\"1766\":1,\"1885\":1}}],[\"ratio\",{\"2\":{\"1622\":3,\"1771\":3,\"1832\":3}}],[\"rate\",{\"0\":{\"1544\":1,\"1933\":1},\"2\":{\"820\":2,\"2233\":1}}],[\"rabbit\",{\"2\":{\"1458\":1}}],[\"raise\",{\"2\":{\"917\":1}}],[\"rare\",{\"2\":{\"631\":1}}],[\"rag检索增强生成\",{\"0\":{\"2678\":1},\"1\":{\"2681\":1,\"2684\":1,\"2687\":1,\"2690\":1,\"2693\":1,\"2696\":1,\"2699\":1,\"2702\":1},\"2\":{\"2576\":1,\"2599\":1}}],[\"ragas\",{\"0\":{\"2558\":1},\"1\":{\"2566\":1,\"2574\":1,\"2582\":1},\"2\":{\"2558\":1}}],[\"rag是rag发展的高级阶段\",{\"2\":{\"2523\":1}}],[\"rag是最基础的rag实现\",{\"2\":{\"2420\":1}}],[\"rag在naive\",{\"2\":{\"2484\":1}}],[\"rag技术的发展可以划分为以下三个阶段\",{\"2\":{\"2366\":1}}],[\"rag首先用检索评分来评估用户提问是否需要检索\",{\"2\":{\"2365\":1}}],[\"rag分类\",{\"0\":{\"2336\":1},\"1\":{\"2366\":1,\"2395\":1}}],[\"rag系统的工作流程可以分为以下五个基本步骤\",{\"2\":{\"1950\":1}}],[\"rag整体思路\",{\"0\":{\"1950\":1}}],[\"ragen\",{\"0\":{\"1970\":1},\"1\":{\"2022\":1,\"2072\":1,\"2124\":1,\"2171\":1,\"2213\":1,\"2250\":1},\"2\":{\"1860\":1,\"2022\":1,\"2124\":1,\"2171\":1,\"2213\":1}}],[\"rag流程与分类\",{\"0\":{\"1836\":1},\"1\":{\"1895\":1,\"1950\":1,\"2001\":1,\"2052\":1,\"2105\":1,\"2155\":1,\"2198\":1,\"2237\":1,\"2272\":1,\"2305\":1,\"2336\":1,\"2366\":1,\"2395\":1,\"2420\":1,\"2445\":1,\"2466\":1,\"2484\":1,\"2499\":1,\"2512\":1,\"2523\":1,\"2534\":1,\"2544\":1}}],[\"rag流程和分类\",{\"0\":{\"1286\":1},\"1\":{\"1333\":1,\"1378\":1,\"1423\":1,\"1468\":1,\"1512\":1,\"1560\":1,\"1611\":1,\"1664\":1,\"1718\":1,\"1775\":1},\"2\":{\"237\":1}}],[\"rag的基础上进行了改进\",{\"2\":{\"2484\":1}}],[\"rag的基础上\",{\"2\":{\"2366\":1}}],[\"rag的效果受到多个因素的影响\",{\"2\":{\"1895\":1}}],[\"rag的特点\",{\"0\":{\"1560\":1},\"1\":{\"1611\":1,\"1664\":1,\"1718\":1,\"1775\":1}}],[\"rag的难点\",{\"0\":{\"1402\":1},\"1\":{\"1450\":1,\"1496\":1,\"1540\":1}}],[\"rag应用了\",{\"2\":{\"1333\":1}}],[\"rag\",{\"0\":{\"2365\":1,\"2366\":3,\"2420\":1,\"2448\":1,\"2484\":1,\"2523\":1,\"2702\":1},\"1\":{\"2445\":1,\"2466\":1,\"2499\":1,\"2512\":1,\"2534\":1,\"2544\":1},\"2\":{\"1185\":1,\"1234\":1,\"1285\":1,\"1309\":2,\"1332\":1,\"1333\":5,\"1356\":1,\"1450\":1,\"1496\":2,\"1560\":1,\"1610\":1,\"1611\":3,\"1664\":2,\"1718\":2,\"1775\":2,\"2000\":1,\"2303\":1,\"2323\":2,\"2334\":1,\"2366\":3,\"2393\":1,\"2419\":1,\"2469\":2,\"2550\":1,\"2681\":1,\"2690\":1,\"2702\":1}}],[\"rag方向\",{\"0\":{\"1251\":1},\"2\":{\"237\":1}}],[\"rag优化中查询索引阶段|rag优化中查询索引阶段\",{\"0\":{\"2678\":1},\"1\":{\"2681\":1,\"2684\":1,\"2687\":1,\"2690\":1,\"2693\":1,\"2696\":1,\"2699\":1,\"2702\":1}}],[\"rag优化中查询索引阶段\",{\"0\":{\"1235\":1},\"1\":{\"1285\":1,\"1332\":1,\"1377\":1,\"1422\":1,\"1467\":1,\"1511\":1,\"1559\":1,\"1610\":1,\"1663\":1,\"1717\":1,\"1774\":1,\"1835\":1,\"1894\":1,\"1949\":1,\"2000\":1,\"2051\":1,\"2104\":1,\"2154\":1,\"2197\":1,\"2236\":1,\"2271\":1,\"2304\":1,\"2335\":1,\"2365\":1,\"2394\":1},\"2\":{\"237\":1}}],[\"rag优化\",{\"0\":{\"1185\":1},\"1\":{\"1234\":1,\"1284\":1,\"1331\":1,\"1376\":1,\"1421\":1,\"1466\":1,\"1510\":1,\"1558\":1,\"1609\":1,\"1662\":1,\"1716\":1,\"1773\":1,\"1834\":1,\"1893\":1,\"1948\":1,\"1999\":1,\"2050\":1,\"2103\":1,\"2153\":1,\"2196\":1,\"2235\":1,\"2270\":1,\"2303\":1,\"2334\":1,\"2364\":1,\"2393\":1,\"2419\":1,\"2444\":1,\"2465\":1,\"2483\":1,\"2498\":1,\"2511\":1,\"2522\":1,\"2533\":1,\"2543\":1,\"2552\":1,\"2560\":1,\"2568\":1,\"2576\":1,\"2584\":1,\"2592\":1,\"2599\":1,\"2606\":1,\"2613\":1,\"2620\":1,\"2625\":1,\"2630\":1,\"2635\":1,\"2640\":1,\"2645\":1,\"2650\":1,\"2655\":1,\"2659\":1,\"2663\":1,\"2666\":1,\"2669\":1,\"2672\":1,\"2675\":1},\"2\":{\"237\":1}}],[\"rag评估的核心维度\",{\"0\":{\"1356\":1}}],[\"rag评估\",{\"0\":{\"1309\":1},\"1\":{\"1356\":1,\"1402\":1,\"1450\":1,\"1496\":1,\"1540\":1,\"1590\":1,\"1644\":1,\"1698\":1,\"1756\":1,\"1816\":1,\"1876\":1,\"1933\":1,\"1984\":1,\"2035\":1,\"2087\":1,\"2137\":1,\"2183\":1,\"2222\":1,\"2257\":1,\"2292\":1,\"2323\":1,\"2354\":1,\"2384\":1,\"2411\":1,\"2436\":1,\"2458\":1,\"2477\":1,\"2493\":1,\"2506\":1,\"2518\":1,\"2529\":1,\"2540\":1,\"2550\":1,\"2558\":1,\"2566\":1,\"2574\":1,\"2582\":1,\"2590\":1},\"2\":{\"237\":1}}],[\"rangle\",{\"2\":{\"1708\":2}}],[\"range\",{\"2\":{\"218\":1,\"324\":1,\"647\":4,\"656\":6,\"820\":1,\"840\":2,\"843\":1,\"1936\":1,\"2201\":1,\"2433\":2,\"2539\":2,\"2565\":1,\"2573\":1}}],[\"random\",{\"2\":{\"640\":3,\"646\":3,\"840\":3,\"1170\":1,\"1636\":1}}],[\"randint\",{\"2\":{\"324\":1,\"640\":1,\"646\":1,\"840\":1}}],[\"randn\",{\"2\":{\"266\":1,\"1883\":4,\"2539\":3}}],[\"ranknum=α⋅scaling\",{\"2\":{\"2142\":2}}],[\"ranknum\",{\"2\":{\"1883\":3,\"2142\":1}}],[\"ranked\",{\"2\":{\"1816\":5}}],[\"rankirank\",{\"2\":{\"1644\":1}}],[\"rank\",{\"0\":{\"682\":1},\"2\":{\"57\":1,\"214\":1,\"324\":1,\"763\":1,\"1590\":1,\"1636\":1,\"1644\":1,\"1658\":2,\"1792\":1,\"1816\":6,\"1831\":2,\"1883\":1,\"2078\":1}}],[\"ray\",{\"0\":{\"2031\":1,\"2320\":1,\"2408\":1},\"1\":{\"2081\":1,\"2132\":1,\"2178\":1,\"2218\":1,\"2253\":1,\"2288\":1,\"2351\":1,\"2381\":1,\"2408\":1,\"2433\":2},\"2\":{\"193\":1,\"2081\":2,\"2320\":1,\"2408\":6,\"2433\":8}}],[\"r1避免了在评估过程中引入长度偏差\",{\"2\":{\"2588\":1}}],[\"r1生成的总结长度较为简洁\",{\"2\":{\"2588\":1}}],[\"r1的准确率可以达到70\",{\"2\":{\"2580\":1}}],[\"r1在chinese\",{\"0\":{\"2580\":1},\"2\":{\"2580\":1}}],[\"r1r\",{\"2\":{\"2446\":1}}],[\"r1论文链接\",{\"2\":{\"1387\":1}}],[\"r1蒸馏至小模型\",{\"2\":{\"1245\":1}}],[\"r1蒸馏到小模型\",{\"2\":{\"1053\":1}}],[\"r1蒸馏到小模型的效果\",{\"2\":{\"934\":1}}],[\"r1通过多阶段训练和冷启动数据解决了zero模型的可读性差等问题\",{\"2\":{\"934\":1}}],[\"r1和deepseek\",{\"2\":{\"934\":1}}],[\"r1​\",{\"2\":{\"618\":1,\"1683\":2}}],[\"r1\",{\"0\":{\"863\":1,\"2248\":1,\"2315\":1,\"2346\":1},\"1\":{\"899\":1,\"934\":1,\"972\":1,\"1013\":1,\"1053\":1,\"1097\":1,\"1146\":1,\"1195\":1,\"1245\":1,\"1295\":1,\"1342\":1,\"1387\":1,\"2283\":1,\"2315\":1,\"2346\":1},\"2\":{\"172\":1,\"618\":1,\"934\":2,\"1053\":1,\"1683\":2,\"1915\":1,\"1917\":1,\"1955\":1,\"2070\":1,\"2145\":1,\"2211\":1,\"2248\":1,\"2283\":1,\"2315\":1,\"2338\":1,\"2603\":6,\"2617\":1,\"2622\":3,\"2642\":2}}],[\"rloo能够更准确地反映每个response的相对价值\",{\"2\":{\"2109\":1}}],[\"rloo的分析\",{\"0\":{\"1901\":1}}],[\"rloo通过调整基线值来优化策略梯度\",{\"2\":{\"1783\":1}}],[\"rloo\",{\"2\":{\"1726\":1,\"1783\":1}}],[\"rloo与reinforce++\",{\"0\":{\"1670\":1},\"1\":{\"1726\":1,\"1783\":1,\"1844\":1,\"1901\":1,\"1956\":1,\"2007\":1,\"2056\":1,\"2109\":1,\"2159\":1,\"2202\":1},\"2\":{\"151\":1}}],[\"rl算法\",{\"2\":{\"1445\":1}}],[\"rl​​\",{\"2\":{\"537\":1}}],[\"rlπsft\",{\"2\":{\"537\":1}}],[\"rl\",{\"0\":{\"1578\":1,\"1798\":1,\"2285\":1},\"1\":{\"1860\":1,\"1917\":1,\"1970\":1,\"2022\":1,\"2072\":1,\"2124\":1,\"2171\":1,\"2213\":1,\"2250\":1,\"2285\":1,\"2317\":2,\"2348\":2,\"2378\":2,\"2405\":2,\"2430\":2,\"2455\":2},\"2\":{\"514\":1,\"537\":1,\"1222\":1,\"1460\":1,\"1491\":1,\"1515\":1,\"1578\":5,\"1684\":1,\"1685\":3,\"1787\":1,\"1797\":1,\"1902\":2,\"2317\":1,\"2378\":1,\"2405\":1,\"2418\":1,\"2430\":1,\"2455\":1,\"2580\":1,\"2647\":1}}],[\"rlhf能否应用于其他机器学习领域\",{\"2\":{\"1973\":1}}],[\"rlhf能否应用于其他类型的机器学习任务\",{\"2\":{\"1971\":1}}],[\"rlhf过程分为两个阶段\",{\"2\":{\"1539\":1}}],[\"rlhf和直接微调等步骤\",{\"2\":{\"1267\":1}}],[\"rlhf\",{\"0\":{\"1614\":1,\"1667\":1},\"2\":{\"967\":1,\"1449\":1,\"1486\":1,\"1497\":1,\"1516\":1,\"1539\":1,\"1564\":1,\"1589\":1,\"1633\":1,\"2081\":1,\"2118\":1}}],[\"rlhf研究方法及研究总结\",{\"0\":{\"1445\":1},\"1\":{\"1491\":1,\"1536\":1,\"1586\":1,\"1639\":1,\"1693\":1,\"1751\":1,\"1811\":1},\"2\":{\"151\":1}}],[\"rlhf流程\",{\"0\":{\"1443\":1},\"1\":{\"1488\":1,\"1532\":1,\"1581\":1,\"1633\":1,\"1687\":1,\"1743\":1,\"1801\":1,\"1863\":1,\"1920\":1,\"1973\":1},\"2\":{\"151\":1}}],[\"rl在nlp场景下的拓展\",{\"0\":{\"484\":1,\"1471\":1},\"1\":{\"514\":1,\"547\":1,\"581\":1,\"614\":1,\"649\":1,\"684\":1,\"721\":1,\"755\":1,\"787\":1,\"818\":1,\"1515\":1,\"1563\":1,\"1613\":1,\"1666\":1,\"1720\":1,\"1777\":1,\"1838\":1,\"1897\":1,\"1952\":1,\"2003\":1},\"2\":{\"151\":2}}],[\"rl强化学习基础\",{\"2\":{\"5\":12,\"682\":1,\"2202\":1}}],[\"rl强化学习基础|rl强化学习基础\",{\"2\":{\"5\":1}}],[\"robust\",{\"2\":{\"2405\":3}}],[\"roberta的动态掩码策略使其能够更好地学习不同语言表征\",{\"2\":{\"1244\":1}}],[\"roberta能够更好地适应不同的语言表征\",{\"2\":{\"1052\":1}}],[\"roberta使用更大的byte\",{\"2\":{\"1096\":1}}],[\"roberta使用了160gb的纯文本数据集\",{\"2\":{\"1052\":1}}],[\"roberta使用1024块v100\",{\"2\":{\"933\":1}}],[\"roberta采用了更大的模型参数量\",{\"2\":{\"1012\":1}}],[\"roberta在以下几个方面对bert进行了优化\",{\"2\":{\"933\":1}}],[\"roberta是对bert预训练的优化版本\",{\"2\":{\"898\":1}}],[\"roberta\",{\"0\":{\"828\":1},\"1\":{\"862\":1,\"898\":1,\"933\":1,\"971\":1,\"1012\":1,\"1052\":1,\"1096\":1,\"1145\":1,\"1194\":1,\"1244\":1,\"1294\":1,\"1341\":1,\"1386\":1},\"2\":{\"34\":1,\"172\":1,\"862\":1,\"1341\":1}}],[\"rolling\",{\"0\":{\"2356\":1}}],[\"router\",{\"0\":{\"1728\":1},\"2\":{\"1569\":1}}],[\"routing\",{\"0\":{\"1879\":1},\"1\":{\"1935\":1},\"2\":{\"1170\":1,\"1935\":1}}],[\"round\",{\"2\":{\"868\":6,\"2085\":1}}],[\"rouge\",{\"2\":{\"735\":1,\"2292\":1}}],[\"rowsum\",{\"2\":{\"2505\":1,\"2517\":1}}],[\"rowmax\",{\"2\":{\"2505\":1,\"2517\":1}}],[\"row\",{\"0\":{\"1065\":1},\"2\":{\"656\":2,\"1065\":1}}],[\"rotary\",{\"2\":{\"247\":1}}],[\"rope位置编码\",{\"2\":{\"1490\":1}}],[\"rope位置编码和pre\",{\"2\":{\"1155\":1}}],[\"rope位置编码和flash\",{\"2\":{\"1060\":1}}],[\"rope等经典技术组合\",{\"2\":{\"894\":1}}],[\"rope和alibi可能会进一步优化以适配超长序列任务\",{\"2\":{\"414\":1}}],[\"rope和alibi是否可以结合使用\",{\"2\":{\"362\":1}}],[\"rope缩放因子\",{\"2\":{\"346\":1}}],[\"rope与alibi的对比\",{\"0\":{\"315\":1}}],[\"rope可以通过二维拼接扩展到高维空间\",{\"2\":{\"247\":1}}],[\"rope的核心公式为\",{\"2\":{\"247\":1}}],[\"rope的问题与位置内插法的解决方案\",{\"0\":{\"222\":1}}],[\"rope将位置信息注入到attention机制中的查询向量\",{\"2\":{\"247\":1}}],[\"rope\",{\"2\":{\"160\":1,\"163\":1,\"182\":1,\"203\":1,\"222\":1,\"247\":1,\"252\":1,\"315\":1,\"397\":1,\"889\":1,\"1112\":1,\"1140\":1,\"1156\":1,\"1198\":1,\"1265\":1,\"1358\":1,\"1436\":1,\"1451\":2,\"1542\":1,\"1592\":1}}],[\"rope嵌入的比例缩放\",{\"0\":{\"252\":1}}],[\"rope嵌入提前生成且可重复使用\",{\"2\":{\"184\":1}}],[\"rope嵌入\",{\"2\":{\"139\":1,\"142\":1}}],[\"r\",{\"2\":{\"18\":1,\"247\":1,\"470\":1,\"497\":4,\"537\":6,\"608\":1,\"611\":1,\"614\":6,\"618\":2,\"640\":2,\"646\":2,\"647\":7,\"653\":6,\"656\":7,\"672\":2,\"676\":1,\"704\":1,\"710\":1,\"732\":4,\"748\":1,\"757\":1,\"767\":5,\"778\":2,\"779\":1,\"810\":1,\"843\":2,\"868\":1,\"1187\":3,\"1227\":1,\"1266\":2,\"1359\":2,\"1364\":6,\"1536\":4,\"1552\":6,\"1582\":9,\"1591\":1,\"1634\":3,\"1657\":3,\"1666\":6,\"1676\":2,\"1683\":7,\"1685\":1,\"1712\":1,\"1720\":3,\"1732\":3,\"1787\":6,\"1830\":2,\"1883\":6,\"1889\":2,\"1901\":4,\"1994\":2,\"2013\":6,\"2080\":5,\"2092\":1,\"2124\":1,\"2286\":1,\"2306\":8,\"2357\":1,\"2400\":2,\"2425\":2,\"2430\":1,\"2520\":3,\"2531\":3,\"2532\":3,\"2542\":3,\"2643\":10,\"2653\":2}}],[\"rir\",{\"2\":{\"2306\":1,\"2446\":1}}],[\"rico\",{\"0\":{\"2171\":1},\"2\":{\"1860\":1,\"2171\":1}}],[\"richard\",{\"2\":{\"1458\":3}}],[\"ri+γmax⁡a\",{\"2\":{\"640\":1}}],[\"ringallreduce\",{\"2\":{\"2118\":1}}],[\"ring\",{\"2\":{\"502\":1,\"2276\":1}}],[\"ri​−mean\",{\"2\":{\"1683\":1,\"2306\":1}}],[\"ri​+γa\",{\"2\":{\"640\":1}}],[\"ri​\",{\"2\":{\"18\":1}}],[\"ri\",{\"2\":{\"18\":1,\"2357\":2}}],[\"rightarrow→\",{\"2\":{\"1872\":5}}],[\"rightarrow\",{\"2\":{\"773\":1,\"775\":2,\"778\":4,\"1708\":3}}],[\"right\",{\"2\":{\"18\":5,\"34\":1,\"228\":1,\"268\":1,\"537\":1,\"558\":1,\"590\":3,\"647\":1,\"656\":1,\"732\":1,\"757\":2,\"767\":1,\"1127\":1,\"1229\":1,\"1535\":1,\"1552\":2,\"1582\":2,\"1622\":2,\"1628\":4,\"1634\":2,\"1657\":3,\"1685\":1,\"1712\":2,\"1727\":1,\"1732\":2,\"1756\":1,\"1795\":1,\"1830\":4,\"1889\":2,\"1901\":2,\"1942\":1,\"1944\":2,\"1993\":1,\"2044\":3,\"2046\":2,\"2097\":3,\"2322\":1,\"2485\":4,\"2531\":1,\"2542\":1,\"2577\":2}}],[\"riωi\",{\"2\":{\"18\":1}}],[\"r−i+1\",{\"2\":{\"18\":2}}],[\"r+∑i=1r​ωi\",{\"2\":{\"18\":1}}],[\"r+∑i=1r\",{\"2\":{\"18\":1}}],[\"rewriting\",{\"2\":{\"2484\":1}}],[\"rewarding\",{\"2\":{\"1747\":1}}],[\"reward根据时间状态进行区分\",{\"2\":{\"1676\":1}}],[\"rewardr\",{\"2\":{\"1676\":1}}],[\"reward能够更准确地反映策略的有效性\",{\"2\":{\"1522\":1}}],[\"reward系数时\",{\"2\":{\"1174\":1}}],[\"reward系数\",{\"2\":{\"1123\":1}}],[\"reward系数设置\",{\"0\":{\"1033\":1}}],[\"reward中的系数\",{\"2\":{\"1033\":1}}],[\"reward的系数\",{\"2\":{\"911\":1}}],[\"rewards\",{\"2\":{\"619\":3,\"640\":3,\"766\":3,\"820\":1,\"1731\":4}}],[\"reward\",{\"0\":{\"1489\":1,\"1534\":1},\"1\":{\"1533\":1,\"1582\":1,\"1584\":1,\"1634\":1,\"1637\":1,\"1688\":1,\"1691\":1,\"1744\":1,\"1747\":1,\"1802\":1,\"1805\":1,\"1864\":1,\"1867\":1,\"1921\":1,\"1924\":1,\"1976\":1,\"2026\":1,\"2076\":1,\"2127\":1,\"2174\":1},\"2\":{\"151\":2,\"820\":5,\"1222\":1,\"1460\":2,\"1530\":1,\"1533\":1,\"1539\":1,\"1582\":10,\"1631\":1,\"1634\":3,\"1676\":2,\"1740\":1,\"1814\":1,\"1902\":3,\"2004\":1,\"2148\":1,\"2213\":3,\"2273\":2}}],[\"remote\",{\"2\":{\"2433\":4}}],[\"remained\",{\"2\":{\"1458\":2}}],[\"remainder\",{\"2\":{\"47\":3}}],[\"remax通过减去基线值来降低方差\",{\"2\":{\"2440\":1,\"2463\":1}}],[\"remax完全回到了策略梯度算法\",{\"2\":{\"2388\":1,\"2416\":1}}],[\"remax算法通过创新的基线计算方法\",{\"2\":{\"2495\":1,\"2509\":1}}],[\"remax算法的出发点是去掉critic\",{\"2\":{\"2388\":1,\"2416\":1}}],[\"remax算法是基于策略梯度方法的强化学习算法\",{\"2\":{\"2328\":1,\"2359\":1}}],[\"remax的基本概念\",{\"0\":{\"2388\":1,\"2416\":1}}],[\"remax具体算法\",{\"0\":{\"2264\":1,\"2298\":1},\"1\":{\"2297\":1,\"2328\":1,\"2329\":1,\"2358\":1,\"2359\":1,\"2388\":1,\"2389\":1,\"2415\":1,\"2416\":1,\"2440\":1,\"2441\":1,\"2462\":1,\"2463\":1,\"2480\":1,\"2481\":1,\"2495\":1,\"2496\":1,\"2508\":1,\"2509\":1,\"2520\":1,\"2521\":1,\"2531\":1,\"2532\":1,\"2542\":1}}],[\"remax|remax\",{\"2\":{\"2202\":1}}],[\"remax是一种简单\",{\"2\":{\"1887\":1,\"1943\":1}}],[\"remax\",{\"0\":{\"1710\":1,\"1711\":1},\"1\":{\"1767\":1,\"1768\":1,\"1828\":1,\"1829\":1,\"1887\":1,\"1888\":1,\"1942\":1,\"1943\":1,\"1992\":1,\"1993\":1,\"2044\":1,\"2045\":1,\"2096\":1,\"2097\":1,\"2146\":1,\"2147\":1,\"2190\":1,\"2191\":1,\"2229\":1,\"2230\":1,\"2265\":1},\"2\":{\"151\":2,\"2229\":1,\"2265\":1,\"2297\":1,\"2329\":1}}],[\"reranking\",{\"2\":{\"2394\":1}}],[\"reduce通信操作\",{\"2\":{\"2609\":1,\"2679\":1}}],[\"reduce了\",{\"2\":{\"2609\":1}}],[\"reduce\",{\"0\":{\"2427\":1},\"1\":{\"2452\":1},\"2\":{\"2308\":2,\"2344\":1,\"2374\":1,\"2427\":1,\"2452\":1,\"2621\":1}}],[\"reducescatter\",{\"2\":{\"2276\":1}}],[\"redundancy\",{\"0\":{\"2288\":1}}],[\"redpajama\",{\"2\":{\"669\":1,\"741\":1}}],[\"revisiting\",{\"2\":{\"2202\":1}}],[\"reversed\",{\"2\":{\"820\":1}}],[\"regularization\",{\"2\":{\"1902\":1}}],[\"regions\",{\"2\":{\"2050\":1}}],[\"region\",{\"2\":{\"1596\":1}}],[\"requires\",{\"2\":{\"1883\":2,\"2400\":1,\"2539\":4}}],[\"requests\",{\"2\":{\"1843\":1}}],[\"requests的处理\",{\"2\":{\"1843\":1}}],[\"really\",{\"2\":{\"2449\":1}}],[\"rearrange\",{\"2\":{\"2129\":1}}],[\"react方法仅需学习1到6个context\",{\"2\":{\"2011\":1}}],[\"react提示词模板包含特定设计\",{\"2\":{\"1608\":1}}],[\"react是一种被分类在5\",{\"2\":{\"1608\":1}}],[\"react\",{\"0\":{\"1608\":1},\"2\":{\"1917\":1}}],[\"reason\",{\"2\":{\"1368\":1}}],[\"reasoners\",{\"0\":{\"1289\":1},\"2\":{\"1289\":1}}],[\"reasoning\",{\"0\":{\"1252\":1,\"1569\":1,\"1788\":1,\"2011\":1},\"2\":{\"1569\":1,\"1608\":1,\"1708\":4,\"1788\":2,\"1917\":1,\"2199\":1,\"2368\":1}}],[\"recv\",{\"2\":{\"2129\":1}}],[\"recursivecharactertextsplitter\",{\"0\":{\"1763\":1},\"2\":{\"1763\":1,\"1823\":1,\"2141\":1}}],[\"reciprocal\",{\"2\":{\"1590\":1,\"1816\":4}}],[\"recipe\",{\"2\":{\"837\":1}}],[\"recorded\",{\"2\":{\"1458\":2}}],[\"recall\",{\"2\":{\"1208\":1,\"1984\":4,\"2354\":1}}],[\"retain\",{\"2\":{\"2050\":1}}],[\"retriever\",{\"2\":{\"2601\":1,\"2608\":2}}],[\"retrieved\",{\"2\":{\"1984\":10}}],[\"retrieval\",{\"0\":{\"1367\":1,\"1835\":1,\"2562\":1},\"1\":{\"1412\":1,\"2570\":1,\"2578\":1,\"2586\":1},\"2\":{\"1185\":1,\"1285\":1,\"1309\":1,\"1333\":1,\"1367\":2,\"1609\":1,\"1610\":1,\"2000\":1,\"2303\":1,\"2323\":1,\"2395\":1,\"2469\":1,\"2550\":1,\"2570\":1,\"2601\":1,\"2690\":1}}],[\"returns\",{\"2\":{\"1817\":4}}],[\"return\",{\"2\":{\"10\":2,\"11\":4,\"12\":3,\"15\":2,\"22\":1,\"27\":1,\"47\":1,\"48\":1,\"135\":1,\"189\":1,\"213\":1,\"266\":1,\"324\":1,\"332\":1,\"364\":1,\"407\":1,\"515\":1,\"619\":1,\"640\":1,\"646\":1,\"656\":3,\"762\":1,\"766\":3,\"769\":1,\"783\":2,\"820\":2,\"840\":2,\"1025\":1,\"1435\":1,\"1582\":1,\"1622\":3,\"1731\":1,\"1816\":1,\"1817\":1,\"1831\":1,\"1832\":1,\"1912\":1,\"1928\":1,\"1936\":1,\"1984\":2,\"2433\":2,\"2500\":1,\"2600\":1}}],[\"rejected\",{\"2\":{\"1582\":1,\"1731\":8}}],[\"reject\",{\"2\":{\"1164\":1,\"1582\":3}}],[\"reset\",{\"2\":{\"2400\":1}}],[\"research\",{\"2\":{\"1658\":1}}],[\"researcher\",{\"2\":{\"1485\":1}}],[\"residual\",{\"2\":{\"2161\":1}}],[\"response部分\",{\"2\":{\"2322\":1}}],[\"response过程\",{\"2\":{\"2058\":1}}],[\"response视为动作\",{\"2\":{\"1958\":1}}],[\"response\",{\"0\":{\"811\":1},\"2\":{\"780\":1,\"811\":1,\"845\":2,\"881\":2,\"1392\":1,\"1582\":2,\"1848\":1,\"2233\":1}}],[\"res\",{\"2\":{\"647\":4,\"1928\":2}}],[\"results\",{\"2\":{\"1458\":1,\"2433\":5}}],[\"result\",{\"2\":{\"11\":2,\"213\":2,\"1208\":3}}],[\"reinforce方法的修正\",{\"0\":{\"2415\":1,\"2441\":1}}],[\"reinforce++\",{\"2\":{\"2202\":1}}],[\"reinforce++是一种简单且高效的方法\",{\"2\":{\"1956\":1}}],[\"reinforce++概述\",{\"0\":{\"1956\":1}}],[\"reinforcement\",{\"2\":{\"934\":1,\"1564\":1,\"1633\":1,\"1634\":1,\"1920\":1,\"2187\":1,\"2229\":1,\"2265\":1,\"2368\":1,\"2418\":1,\"2467\":1,\"2545\":2,\"2647\":1}}],[\"reinforce是一种策略梯度算法\",{\"2\":{\"652\":1}}],[\"reinforce\",{\"2\":{\"617\":1,\"820\":1,\"1726\":1,\"1783\":1,\"2202\":1}}],[\"reinforce算法在处理连续动作空间时有哪些挑战\",{\"2\":{\"965\":1}}],[\"reinforce算法采用蒙特卡洛方法来估计q值\",{\"2\":{\"757\":1}}],[\"reinforce算法\",{\"0\":{\"757\":1}}],[\"reinforce算法使用蒙特卡洛方法\",{\"2\":{\"586\":1}}],[\"reinforce算法改进\",{\"0\":{\"1670\":1},\"1\":{\"1726\":1,\"1783\":1,\"1844\":1,\"1901\":1,\"1956\":1,\"2007\":1,\"2056\":1,\"2109\":1,\"2159\":1,\"2202\":1},\"2\":{\"151\":1}}],[\"refgpt\",{\"2\":{\"2184\":2}}],[\"reflexion和autogpt\",{\"2\":{\"2277\":1}}],[\"reflexion\",{\"0\":{\"2113\":1},\"1\":{\"2162\":1,\"2205\":1}}],[\"reflection\",{\"2\":{\"1557\":1,\"2113\":2}}],[\"reflection和生成长cot功能\",{\"2\":{\"1146\":1}}],[\"refer\",{\"2\":{\"1458\":1}}],[\"reference和reward\",{\"2\":{\"1899\":1}}],[\"reference\",{\"0\":{\"1478\":1},\"1\":{\"1522\":1,\"1571\":1,\"1621\":1,\"1676\":1,\"1732\":1,\"1790\":1,\"1851\":1,\"1908\":1,\"1961\":1},\"2\":{\"151\":1,\"1539\":1,\"1703\":8,\"1731\":6,\"1954\":1,\"2004\":1}}],[\"ref\",{\"2\":{\"614\":1,\"1552\":2,\"1628\":1,\"1657\":2,\"1712\":1,\"1720\":1,\"1731\":2,\"1732\":2,\"1795\":4,\"1830\":2,\"1889\":2,\"1994\":1,\"2046\":3,\"2485\":1,\"2577\":1}}],[\"re\",{\"2\":{\"391\":1}}],[\"reliable\",{\"2\":{\"2368\":1}}],[\"rel\",{\"2\":{\"2137\":5,\"2183\":3}}],[\"relevant\",{\"2\":{\"1984\":10}}],[\"relation\",{\"0\":{\"880\":1},\"2\":{\"780\":1,\"880\":1}}],[\"relative\",{\"2\":{\"383\":1,\"1954\":1}}],[\"relu问题导致部分神经元无效\",{\"2\":{\"354\":1}}],[\"relu问题\",{\"2\":{\"330\":2}}],[\"relu激活函数\",{\"2\":{\"178\":1}}],[\"relu\",{\"0\":{\"238\":1,\"261\":1},\"2\":{\"132\":1,\"178\":1,\"238\":1,\"261\":2,\"307\":1,\"330\":2,\"766\":2,\"820\":1}}],[\"repeat\",{\"2\":{\"2500\":1}}],[\"repeated\",{\"2\":{\"18\":1}}],[\"replicate\",{\"2\":{\"2433\":1}}],[\"replacing\",{\"2\":{\"1458\":1}}],[\"replace\",{\"2\":{\"515\":2}}],[\"replaybuffer\",{\"2\":{\"640\":1}}],[\"report\",{\"2\":{\"1324\":1,\"1372\":1,\"1492\":1,\"1535\":1,\"2434\":1}}],[\"representation\",{\"2\":{\"919\":1}}],[\"representations\",{\"2\":{\"115\":1,\"1261\":1}}],[\"repaly\",{\"0\":{\"712\":1}}],[\"和流水线并行\",{\"2\":{\"2710\":1}}],[\"和标准attention相比\",{\"2\":{\"2648\":1}}],[\"和标签平滑参数可能影响优化结果\",{\"2\":{\"1789\":1}}],[\"和可能的dropout层\",{\"2\":{\"2579\":1}}],[\"和相关代码分析\",{\"2\":{\"2471\":1}}],[\"和转换不相关性问题\",{\"2\":{\"2466\":1}}],[\"和升维矩阵\",{\"2\":{\"2425\":1}}],[\"和联合创始人\",{\"2\":{\"2408\":1}}],[\"和执行结构化文本\",{\"2\":{\"2370\":1}}],[\"和harmlessness\",{\"2\":{\"2194\":1}}],[\"和评价函数\",{\"2\":{\"2148\":1}}],[\"和评价指令跟随数据\",{\"2\":{\"1867\":1}}],[\"和反向传播\",{\"2\":{\"2059\":1}}],[\"和算子融合来实现这一目标\",{\"2\":{\"1957\":1}}],[\"和问题\",{\"2\":{\"1885\":1}}],[\"和一小部分人类标注的种子数据\",{\"2\":{\"1867\":1}}],[\"和一组负样本\",{\"2\":{\"1566\":1}}],[\"和负样本集合\",{\"2\":{\"1784\":1}}],[\"和reinforce++\",{\"2\":{\"1783\":1}}],[\"和余下的推理\",{\"2\":{\"1782\":1}}],[\"和方向矩阵\",{\"2\":{\"1770\":1}}],[\"和普通提示的区别\",{\"0\":{\"1766\":1}}],[\"和检索精准\",{\"2\":{\"1763\":1}}],[\"和行动\",{\"2\":{\"1608\":1}}],[\"和学习率\",{\"2\":{\"1577\":1}}],[\"和离线\",{\"2\":{\"1564\":1}}],[\"和直接偏好优化\",{\"2\":{\"1517\":1}}],[\"和泛化问题\",{\"2\":{\"1460\":1}}],[\"和工作流\",{\"2\":{\"1439\":1}}],[\"和工具的系统\",{\"2\":{\"1269\":1}}],[\"和多个智能体\",{\"2\":{\"1139\":1}}],[\"和之前直接使用贪心搜索算法不同\",{\"2\":{\"917\":1}}],[\"和动作价值函数\",{\"2\":{\"732\":1}}],[\"和温度值\",{\"2\":{\"665\":1}}],[\"和奖励机制指导智能体\",{\"2\":{\"572\":1}}],[\"和计算url分数来筛选内容\",{\"2\":{\"456\":1}}],[\"和单词级\",{\"2\":{\"426\":1}}],[\"和门控网络\",{\"2\":{\"415\":1}}],[\"和ulm\",{\"2\":{\"368\":1}}],[\"和键向量\",{\"2\":{\"247\":1}}],[\"和alibi\",{\"2\":{\"203\":1}}],[\"和值\",{\"2\":{\"188\":1}}],[\"和偏置\",{\"2\":{\"123\":1}}],[\"和gqa\",{\"2\":{\"111\":1}}],[\"和value\",{\"2\":{\"107\":1}}],[\"和卷积神经网络\",{\"2\":{\"97\":1}}],[\"和解码器\",{\"2\":{\"93\":1}}],[\"和前馈神经网络\",{\"2\":{\"34\":1}}],[\"和\",{\"0\":{\"525\":1,\"904\":1,\"1065\":1,\"2183\":1},\"1\":{\"939\":1,\"981\":1,\"1022\":1},\"2\":{\"10\":2,\"27\":2,\"121\":1,\"123\":1,\"199\":1,\"216\":1,\"228\":1,\"247\":1,\"299\":1,\"355\":1,\"359\":1,\"408\":1,\"433\":2,\"439\":1,\"468\":1,\"497\":1,\"502\":1,\"575\":1,\"685\":1,\"730\":1,\"738\":1,\"765\":1,\"768\":1,\"771\":1,\"780\":1,\"916\":1,\"919\":1,\"926\":1,\"956\":1,\"985\":1,\"1007\":1,\"1022\":2,\"1047\":1,\"1065\":1,\"1092\":1,\"1124\":1,\"1162\":1,\"1187\":1,\"1193\":1,\"1197\":1,\"1204\":1,\"1260\":1,\"1313\":1,\"1353\":1,\"1356\":1,\"1359\":1,\"1376\":1,\"1389\":1,\"1404\":1,\"1412\":1,\"1439\":1,\"1450\":1,\"1451\":1,\"1507\":1,\"1536\":1,\"1587\":1,\"1592\":2,\"1617\":1,\"1619\":1,\"1701\":1,\"1752\":1,\"1786\":1,\"1813\":1,\"1826\":1,\"1925\":1,\"1980\":1,\"1990\":1,\"2059\":1,\"2079\":1,\"2081\":2,\"2085\":1,\"2089\":1,\"2115\":3,\"2129\":1,\"2130\":1,\"2145\":1,\"2161\":2,\"2164\":1,\"2177\":1,\"2188\":1,\"2202\":1,\"2252\":1,\"2276\":1,\"2280\":1,\"2308\":2,\"2319\":1,\"2320\":1,\"2325\":1,\"2327\":1,\"2343\":1,\"2408\":1,\"2433\":1,\"2486\":1,\"2505\":1,\"2517\":1,\"2524\":1,\"2549\":1,\"2565\":1,\"2603\":1,\"2604\":1,\"2623\":1,\"2641\":1,\"2643\":1}}],[\"ili​\",{\"2\":{\"2573\":1,\"2604\":1,\"2623\":1}}],[\"ijl\",{\"2\":{\"2604\":1}}],[\"ij−mi​\",{\"2\":{\"2604\":1,\"2618\":1}}],[\"ij−mi\",{\"2\":{\"2604\":1,\"2618\":1}}],[\"ij=torch\",{\"2\":{\"2597\":2}}],[\"ij\",{\"2\":{\"2318\":1,\"2349\":6,\"2379\":3,\"2539\":9,\"2581\":4,\"2589\":4,\"2597\":18,\"2604\":6,\"2611\":3,\"2618\":2,\"2643\":4}}],[\"iqi​\",{\"2\":{\"2286\":3,\"2573\":1}}],[\"i​⋅swiglui​\",{\"2\":{\"2140\":1}}],[\"i=0\",{\"2\":{\"2140\":1}}],[\"i=1∑g​\",{\"2\":{\"1628\":1}}],[\"i=1m​\",{\"2\":{\"1566\":1,\"1671\":1}}],[\"i=1m\",{\"2\":{\"1566\":1,\"1671\":1}}],[\"i=1\",{\"2\":{\"18\":1,\"268\":1,\"558\":1,\"640\":1,\"1279\":1,\"1364\":2,\"1566\":1,\"1628\":1,\"1644\":1,\"1671\":2,\"1901\":1,\"1942\":1,\"1993\":1,\"2085\":1,\"2137\":1,\"2485\":1,\"2531\":1,\"2542\":1,\"2577\":1}}],[\"i⋅swiglui\",{\"2\":{\"2140\":1}}],[\"i|\",{\"2\":{\"2085\":1,\"2485\":1,\"2577\":1}}],[\"i|q\",{\"2\":{\"1628\":4}}],[\"ixi​\",{\"2\":{\"2007\":1}}],[\"ixi​采样mmm条response\",{\"2\":{\"1901\":1}}],[\"io复杂度是\",{\"2\":{\"2653\":1}}],[\"io复杂度\",{\"0\":{\"2653\":1}}],[\"ioi​\",{\"2\":{\"2505\":1,\"2517\":2,\"2573\":1,\"2618\":1}}],[\"io\",{\"2\":{\"2275\":1}}],[\"io感知\",{\"2\":{\"1785\":1,\"2110\":1}}],[\"iostream>\",{\"2\":{\"10\":2,\"11\":3,\"22\":1,\"27\":1}}],[\"ipo\",{\"2\":{\"1731\":4}}],[\"ipi​\",{\"2\":{\"1279\":1,\"1326\":1}}],[\"i$$表示第$$i$$个样本输出的token数量\",{\"2\":{\"2322\":1}}],[\"i$$表示第$$i$$个样本的loss\",{\"2\":{\"2322\":1}}],[\"i$$\",{\"2\":{\"1187\":1}}],[\"ik​wq​wkt​xkj​\",{\"2\":{\"1187\":1}}],[\"ikwqwktxkjq\",{\"2\":{\"1187\":1}}],[\"i^\",{\"2\":{\"1127\":1,\"1364\":2,\"1566\":1,\"1671\":2,\"1784\":1,\"2528\":5}}],[\"iii\",{\"2\":{\"773\":1,\"1279\":2,\"1326\":2,\"1644\":1,\"2137\":1,\"2306\":1}}],[\"imitator\",{\"2\":{\"2601\":1,\"2608\":2}}],[\"imi​\",{\"2\":{\"2573\":1,\"2604\":1,\"2623\":1}}],[\"immigrants\",{\"2\":{\"1458\":1}}],[\"img\",{\"2\":{\"1329\":2}}],[\"image\",{\"2\":{\"1329\":2}}],[\"images\",{\"2\":{\"526\":1,\"2050\":1}}],[\"impact\",{\"2\":{\"2471\":1}}],[\"implicit\",{\"2\":{\"1902\":1}}],[\"improve\",{\"2\":{\"949\":1}}],[\"improvement\",{\"0\":{\"1710\":1},\"1\":{\"1767\":1,\"1828\":1,\"1887\":1,\"1942\":1,\"1992\":1,\"2044\":1,\"2096\":1,\"2146\":1,\"2190\":1,\"2229\":1},\"2\":{\"151\":1,\"656\":2}}],[\"improving\",{\"2\":{\"632\":1,\"1385\":1}}],[\"import\",{\"2\":{\"213\":1,\"266\":2,\"332\":1,\"480\":2,\"485\":1,\"508\":1,\"996\":1,\"1111\":1,\"1208\":1,\"1435\":1,\"1646\":1,\"1837\":1,\"1951\":1,\"2108\":1,\"2201\":4,\"2284\":1,\"2433\":1,\"2539\":1}}],[\"icml\",{\"2\":{\"1658\":1}}],[\"iclr\",{\"2\":{\"1493\":1}}],[\"icl\",{\"0\":{\"1175\":1,\"1459\":1},\"1\":{\"1504\":1,\"1550\":1,\"1600\":1},\"2\":{\"1124\":1,\"1175\":3,\"1224\":1,\"1275\":1}}],[\"icl示例设计\",{\"0\":{\"804\":1},\"1\":{\"838\":1,\"874\":1,\"910\":1,\"949\":1,\"991\":1,\"1032\":1,\"1075\":1,\"1122\":1,\"1173\":1,\"1222\":1,\"1273\":1,\"1322\":1,\"1368\":1,\"1413\":1,\"1459\":1,\"1504\":1,\"1550\":1,\"1600\":1}}],[\"icl可以形式化地定义为\",{\"2\":{\"773\":1}}],[\"icl形式化定义\",{\"0\":{\"773\":1}}],[\"icl常通过提示词来引导模型的生成过程\",{\"2\":{\"670\":1}}],[\"icl不涉及对模型实际参数的修改\",{\"2\":{\"569\":1}}],[\"icl的核心在于利用模型的上下文理解能力来完成任务\",{\"2\":{\"536\":1}}],[\"icl概念原理\",{\"0\":{\"477\":1}}],[\"icons\",{\"2\":{\"18\":1}}],[\"it\",{\"2\":{\"1458\":3}}],[\"its\",{\"2\":{\"1458\":1}}],[\"iterative\",{\"0\":{\"2562\":1},\"1\":{\"2570\":1,\"2578\":1,\"2586\":1},\"2\":{\"2601\":1}}],[\"iteration\",{\"2\":{\"656\":1,\"2276\":1,\"2374\":1,\"2378\":1,\"2405\":1}}],[\"item\",{\"2\":{\"619\":1,\"640\":1,\"766\":1,\"820\":1,\"1816\":2,\"2087\":6,\"2137\":1}}],[\"items\",{\"2\":{\"407\":1,\"2600\":1}}],[\"italic\",{\"2\":{\"18\":2,\"2050\":1}}],[\"idcg\",{\"0\":{\"2183\":1},\"2\":{\"2183\":2}}],[\"identical\",{\"2\":{\"917\":1}}],[\"id类型\",{\"2\":{\"559\":1}}],[\"id\",{\"2\":{\"515\":2,\"1324\":1,\"2347\":2,\"2500\":1,\"2581\":2,\"2597\":2}}],[\"idx\",{\"2\":{\"324\":15,\"364\":3,\"1025\":5,\"2500\":1}}],[\"ids和labels的设置\",{\"2\":{\"2353\":1}}],[\"ids\",{\"2\":{\"324\":5,\"917\":8,\"1225\":1,\"2500\":12,\"2600\":4}}],[\"idf\",{\"2\":{\"59\":1,\"207\":1}}],[\"ian\",{\"2\":{\"165\":1}}],[\"ifd\",{\"0\":{\"2282\":1}}],[\"ift\",{\"2\":{\"1436\":1,\"1867\":1}}],[\"ifi​\",{\"2\":{\"1279\":1,\"1326\":1}}],[\"if\",{\"0\":{\"1275\":1},\"2\":{\"48\":1,\"189\":1,\"640\":2,\"646\":1,\"647\":2,\"656\":4,\"762\":2,\"769\":1,\"840\":2,\"917\":1,\"1025\":1,\"1275\":1,\"1364\":2,\"1582\":1,\"1622\":1,\"1731\":1,\"1816\":1,\"1817\":1,\"1832\":3,\"1883\":1,\"1912\":2,\"1928\":2,\"1984\":4,\"2201\":1,\"2500\":1}}],[\"i+k\",{\"2\":{\"1127\":1}}],[\"i+group\",{\"2\":{\"218\":1}}],[\"i++\",{\"2\":{\"47\":1,\"769\":1}}],[\"i+1\",{\"2\":{\"18\":1,\"2137\":3}}],[\"i\",{\"2\":{\"47\":5,\"135\":2,\"190\":2,\"218\":2,\"263\":3,\"268\":1,\"470\":1,\"497\":1,\"508\":1,\"537\":1,\"558\":2,\"622\":2,\"640\":4,\"656\":2,\"762\":6,\"769\":5,\"773\":5,\"778\":21,\"783\":8,\"820\":4,\"840\":3,\"843\":2,\"998\":3,\"1093\":3,\"1127\":1,\"1187\":6,\"1207\":3,\"1222\":2,\"1225\":2,\"1258\":1,\"1266\":7,\"1279\":2,\"1353\":1,\"1359\":5,\"1364\":4,\"1405\":1,\"1628\":2,\"1644\":1,\"1683\":2,\"1901\":5,\"1925\":3,\"1936\":2,\"2085\":1,\"2121\":7,\"2137\":6,\"2140\":2,\"2183\":3,\"2306\":2,\"2356\":1,\"2357\":3,\"2406\":1,\"2446\":1,\"2485\":10,\"2500\":1,\"2517\":2,\"2528\":7,\"2531\":3,\"2539\":7,\"2542\":3,\"2573\":5,\"2577\":1,\"2581\":2,\"2597\":2,\"2604\":7,\"2618\":12,\"2623\":2,\"2643\":2}}],[\"irp\",{\"0\":{\"2594\":1},\"1\":{\"2601\":1,\"2608\":1,\"2615\":1},\"2\":{\"2601\":2}}],[\"iri​\",{\"2\":{\"2306\":1,\"2446\":1}}],[\"iranki​\",{\"2\":{\"1644\":1}}],[\"ir\",{\"2\":{\"18\":1}}],[\"ir⋯\",{\"2\":{\"18\":2}}],[\"increment\",{\"2\":{\"2433\":5}}],[\"including\",{\"2\":{\"2050\":1}}],[\"include\",{\"2\":{\"10\":2,\"11\":3,\"22\":1,\"27\":1}}],[\"inner\",{\"0\":{\"2102\":1},\"1\":{\"2152\":1,\"2195\":1,\"2234\":1}}],[\"innovators\",{\"0\":{\"1382\":1},\"2\":{\"1382\":1}}],[\"instances中即可\",{\"2\":{\"1368\":1}}],[\"instruct模型过滤以确保质量\",{\"2\":{\"1205\":1}}],[\"instructions\",{\"0\":{\"1368\":1},\"2\":{\"1971\":1}}],[\"instruction\",{\"2\":{\"1124\":1,\"1275\":1,\"1766\":1,\"1867\":1}}],[\"instructgpt研究论文\",{\"2\":{\"1971\":1}}],[\"instructgpt在实现ppo时修改了传统的强化学习目标\",{\"2\":{\"1685\":1}}],[\"instructgpt的训练流程\",{\"0\":{\"1631\":1}}],[\"instructgpt使得模型能够更好地与人类意图对齐\",{\"2\":{\"1530\":1}}],[\"instructgpt是openai在语言模型后训练中应用rlhf\",{\"2\":{\"1530\":1}}],[\"instructgpt\",{\"2\":{\"1486\":1}}],[\"instructgpt中将\",{\"2\":{\"1076\":1}}],[\"instructgpt提出了ppo\",{\"2\":{\"875\":1}}],[\"instruct\",{\"0\":{\"1440\":1},\"1\":{\"1486\":1,\"1530\":1,\"1579\":1,\"1631\":1,\"1685\":1,\"1741\":1,\"1799\":1,\"1861\":1,\"1918\":1,\"1971\":1},\"2\":{\"151\":1,\"1216\":1,\"2168\":1}}],[\"ing\",{\"2\":{\"956\":1}}],[\"infermemory≈1\",{\"2\":{\"2023\":2}}],[\"inference\",{\"2\":{\"683\":1,\"2079\":1,\"2081\":2,\"2145\":1}}],[\"infinity\",{\"2\":{\"2539\":1}}],[\"infinf\",{\"2\":{\"1925\":1}}],[\"infilling\",{\"2\":{\"1239\":1}}],[\"inf⁡\",{\"2\":{\"1925\":1}}],[\"influence\",{\"2\":{\"1458\":1}}],[\"inf\",{\"2\":{\"553\":1,\"2539\":2}}],[\"information\",{\"2\":{\"308\":1,\"499\":1,\"1458\":2}}],[\"index=labels\",{\"2\":{\"1703\":2}}],[\"index=sorted\",{\"2\":{\"364\":1}}],[\"index\",{\"2\":{\"324\":2,\"1025\":4}}],[\"indices\",{\"2\":{\"324\":6,\"364\":2,\"996\":2,\"1928\":2}}],[\"input→reasoning\",{\"2\":{\"1708\":2}}],[\"input→output\",{\"2\":{\"1708\":2}}],[\"input=\",{\"2\":{\"1208\":1}}],[\"inputs\",{\"2\":{\"917\":4,\"2500\":10,\"2600\":5}}],[\"input\",{\"2\":{\"266\":5,\"324\":5,\"917\":8,\"996\":2,\"1343\":1,\"1458\":2,\"1708\":2,\"1912\":1,\"2233\":1,\"2500\":1}}],[\"initialization\",{\"2\":{\"2471\":1}}],[\"initialize\",{\"2\":{\"1646\":2}}],[\"init\",{\"2\":{\"266\":2,\"619\":2,\"646\":1,\"656\":1,\"766\":5,\"820\":3,\"840\":1,\"1622\":2,\"1731\":2,\"1817\":2,\"1831\":2,\"1883\":1,\"1912\":2,\"2372\":2,\"2400\":6,\"2433\":1}}],[\"in\",{\"0\":{\"2370\":1},\"1\":{\"2398\":1},\"2\":{\"218\":2,\"324\":2,\"391\":3,\"407\":1,\"477\":1,\"647\":8,\"656\":13,\"704\":1,\"723\":2,\"732\":4,\"767\":5,\"810\":2,\"820\":1,\"840\":2,\"843\":2,\"917\":1,\"949\":1,\"1025\":2,\"1175\":1,\"1228\":1,\"1248\":1,\"1261\":1,\"1298\":1,\"1333\":1,\"1364\":1,\"1437\":1,\"1458\":11,\"1536\":1,\"1550\":1,\"1634\":1,\"1727\":1,\"1816\":2,\"1823\":1,\"1831\":1,\"1837\":1,\"1883\":1,\"1901\":1,\"1902\":1,\"1936\":2,\"1951\":1,\"1984\":4,\"2013\":3,\"2079\":1,\"2080\":5,\"2129\":1,\"2199\":1,\"2201\":2,\"2202\":1,\"2400\":4,\"2425\":1,\"2433\":4,\"2449\":1,\"2484\":1,\"2500\":2,\"2539\":2,\"2565\":1,\"2573\":1,\"2600\":1,\"2643\":4,\"2653\":2}}],[\"inline\",{\"2\":{\"18\":1}}],[\"intra\",{\"0\":{\"2515\":1},\"1\":{\"2526\":1,\"2537\":1},\"2\":{\"2081\":1,\"2218\":1}}],[\"integrated\",{\"0\":{\"1788\":1},\"2\":{\"1788\":2}}],[\"integer\",{\"0\":{\"1588\":1}}],[\"interleave\",{\"2\":{\"2500\":1}}],[\"interval\",{\"2\":{\"2405\":1}}],[\"inter\",{\"0\":{\"2685\":1},\"1\":{\"2688\":1,\"2691\":1,\"2694\":1,\"2697\":1,\"2700\":1,\"2703\":1,\"2704\":1,\"2705\":1,\"2706\":1,\"2707\":1,\"2708\":1,\"2709\":1,\"2710\":1,\"2711\":1},\"2\":{\"2081\":1,\"2253\":1}}],[\"interactive\",{\"0\":{\"1619\":1}}],[\"interpretations\",{\"2\":{\"1458\":1}}],[\"interpretable\",{\"2\":{\"1458\":1}}],[\"interpolation\",{\"2\":{\"180\":1}}],[\"into\",{\"2\":{\"1458\":4}}],[\"int>\",{\"2\":{\"762\":3,\"769\":1}}],[\"int4\",{\"2\":{\"733\":3,\"768\":1}}],[\"int8=1024×1024×10241×params​\",{\"2\":{\"2192\":1}}],[\"int8=1×params1024×1024×1024\",{\"2\":{\"2192\":1}}],[\"int8\",{\"0\":{\"1982\":1},\"2\":{\"733\":3,\"768\":1,\"1813\":1,\"1982\":1,\"2033\":1,\"2085\":1,\"2192\":1}}],[\"int\",{\"2\":{\"10\":2,\"11\":14,\"12\":9,\"15\":1,\"22\":1,\"27\":1,\"47\":7,\"623\":1,\"762\":3,\"769\":6,\"783\":7,\"2400\":4}}],[\"issue\",{\"2\":{\"1460\":1}}],[\"isvowel\",{\"2\":{\"783\":4}}],[\"is\",{\"2\":{\"10\":7,\"11\":1,\"18\":6,\"230\":1,\"632\":1,\"1458\":2,\"1582\":1,\"1622\":1,\"1814\":1,\"1817\":1,\"1832\":3,\"1885\":1,\"1902\":1,\"1928\":1,\"2201\":1,\"2400\":1,\"2434\":1,\"2500\":2}}],[\"示例检索\",{\"0\":{\"2578\":1}}],[\"示例流程\",{\"0\":{\"2554\":1}}],[\"示例计算\",{\"0\":{\"1756\":1}}],[\"示例顺序可以随机排列或按照固定规则排列\",{\"2\":{\"1413\":1}}],[\"示例顺序\",{\"0\":{\"1413\":1}}],[\"示例格式\",{\"0\":{\"1322\":1}}],[\"示例语料库\",{\"2\":{\"1111\":1}}],[\"示例选择的目标是从样本库中挑选适合的示例提供给prompt\",{\"2\":{\"1173\":1}}],[\"示例选择\",{\"0\":{\"838\":1},\"1\":{\"874\":1,\"910\":1,\"949\":1,\"991\":1,\"1032\":1,\"1075\":1,\"1122\":1,\"1173\":1,\"1222\":1,\"1273\":1,\"1322\":1,\"1368\":1,\"1413\":1},\"2\":{\"804\":1}}],[\"示例id\",{\"2\":{\"559\":1}}],[\"示例值\",{\"2\":{\"471\":1,\"1499\":1}}],[\"示例公式\",{\"2\":{\"426\":1}}],[\"示例调用\",{\"2\":{\"324\":1}}],[\"示例代码展示如何使用门控机制选择专家\",{\"2\":{\"1936\":1}}],[\"示例代码\",{\"0\":{\"218\":1,\"332\":1,\"1025\":1,\"1111\":1,\"1208\":1,\"1435\":1,\"1646\":1,\"2600\":1},\"2\":{\"485\":1,\"2284\":1,\"2433\":1}}],[\"示例输入\",{\"2\":{\"213\":1,\"996\":1}}],[\"示例\",{\"0\":{\"418\":1,\"1820\":1,\"2185\":1,\"2294\":1,\"2423\":1,\"2672\":1},\"1\":{\"443\":1,\"470\":1,\"497\":1},\"2\":{\"10\":1,\"12\":2,\"15\":1,\"246\":1,\"266\":1,\"332\":1,\"508\":1,\"575\":1,\"644\":1,\"1232\":1,\"1435\":1,\"1766\":1}}],[\"的生成回答阶段\",{\"2\":{\"2681\":1}}],[\"的生成能力\",{\"2\":{\"1032\":1}}],[\"的解码器部分通常基于给定输入来预测下一个词\",{\"2\":{\"2681\":1}}],[\"的系统时\",{\"2\":{\"2681\":1}}],[\"的嵌入模型排行榜\",{\"2\":{\"2663\":1}}],[\"的block\",{\"2\":{\"2653\":1}}],[\"的专用分块器\",{\"2\":{\"2640\":1}}],[\"的专门分块器\",{\"2\":{\"2640\":1}}],[\"的专有参数\",{\"2\":{\"1873\":1,\"2082\":1}}],[\"的归因分数\",{\"2\":{\"2608\":1}}],[\"的值\",{\"2\":{\"2524\":1}}],[\"的值和梯度\",{\"2\":{\"1050\":1}}],[\"的样本准确率介于0到1之间\",{\"2\":{\"2519\":1}}],[\"的智能体具有更广泛的适用场景和更高层次的处理能力\",{\"2\":{\"2443\":1}}],[\"的编程抽象中\",{\"2\":{\"2408\":1}}],[\"的编程前端包括\",{\"2\":{\"2408\":1}}],[\"的利用率\",{\"2\":{\"2402\":1}}],[\"的批量大小变得太小\",{\"2\":{\"2402\":1}}],[\"的shape对了\",{\"2\":{\"2379\":1}}],[\"的通信量为\",{\"2\":{\"2369\":1}}],[\"的通用语言知识迁移到新任务中\",{\"2\":{\"40\":1}}],[\"的多样性\",{\"2\":{\"2345\":1}}],[\"的多种\",{\"2\":{\"2055\":1}}],[\"的单一化\",{\"2\":{\"2343\":1}}],[\"的单词会被替换为\",{\"2\":{\"997\":1}}],[\"的维度都变成\",{\"2\":{\"2636\":1}}],[\"的维度为\",{\"2\":{\"2286\":3}}],[\"的维度和模型性能\",{\"2\":{\"1176\":1}}],[\"的维度和表现能力将进一步提升\",{\"2\":{\"1036\":1}}],[\"的长度均衡\",{\"2\":{\"2280\":1}}],[\"的长度几乎呈正相关\",{\"2\":{\"2145\":1}}],[\"的两个重要组件\",{\"0\":{\"2262\":1}}],[\"的两种策略\",{\"0\":{\"520\":1},\"1\":{\"553\":1,\"589\":1}}],[\"的组合使用效果\",{\"2\":{\"2244\":1}}],[\"的设计方式会显著影响模型预测下一个词的概率\",{\"2\":{\"2687\":1}}],[\"的设计思想来源于小世界网络\",{\"2\":{\"2234\":1}}],[\"的设置至关重要\",{\"2\":{\"911\":1}}],[\"的延迟时间\",{\"2\":{\"2228\":1}}],[\"的消息\",{\"2\":{\"2227\":1}}],[\"的教程\",{\"2\":{\"2178\":1}}],[\"的损失一开始可能会较高\",{\"2\":{\"2163\":1}}],[\"的梯度和模型参数\",{\"2\":{\"2486\":1}}],[\"的梯度每张卡只发送一次\",{\"2\":{\"2308\":1}}],[\"的梯度均值\",{\"2\":{\"2308\":1}}],[\"的梯度\",{\"2\":{\"2161\":1}}],[\"的模式\",{\"2\":{\"2694\":1}}],[\"的模型参数\",{\"2\":{\"2308\":1}}],[\"的模型参数备份\",{\"2\":{\"2161\":1}}],[\"的模块组成\",{\"0\":{\"2227\":1},\"1\":{\"2262\":1}}],[\"的模板允许编写与数据类型无关的代码\",{\"2\":{\"15\":1}}],[\"的无关内容\",{\"2\":{\"2154\":1}}],[\"的帮助\",{\"2\":{\"2154\":1}}],[\"的十几倍或更多\",{\"2\":{\"2145\":1}}],[\"的总数量\",{\"2\":{\"2145\":1}}],[\"的总回报\",{\"2\":{\"778\":1}}],[\"的耗时\",{\"2\":{\"2145\":2}}],[\"的最小可能时间\",{\"2\":{\"2145\":1}}],[\"的概念及其计算方法\",{\"2\":{\"2492\":1}}],[\"的概念\",{\"2\":{\"2144\":1}}],[\"的概率\",{\"2\":{\"1536\":1,\"2289\":1,\"2690\":1}}],[\"的局限性\",{\"2\":{\"2144\":1}}],[\"的局限性提供了一种有效方法\",{\"2\":{\"1560\":1}}],[\"的限制\",{\"2\":{\"2141\":1}}],[\"的工作原理如下\",{\"2\":{\"2141\":1}}],[\"的相关文献和研究资料\",{\"2\":{\"2289\":1}}],[\"的相关性得分\",{\"2\":{\"2137\":1}}],[\"的相关度矩阵\",{\"2\":{\"147\":1}}],[\"的即时奖励\",{\"2\":{\"2124\":1}}],[\"的推理能力\",{\"2\":{\"2094\":1}}],[\"的推理过程\",{\"2\":{\"2094\":1}}],[\"的顺序很重要\",{\"2\":{\"2087\":1}}],[\"的高效解决方案\",{\"2\":{\"2081\":1}}],[\"的高效做法\",{\"2\":{\"881\":1}}],[\"的集合通信\",{\"2\":{\"2081\":1}}],[\"的数据并行度\",{\"2\":{\"2079\":1}}],[\"的数值范围下界为\",{\"2\":{\"556\":1}}],[\"的大量模型\",{\"2\":{\"2381\":1}}],[\"的大模型\",{\"2\":{\"2374\":1}}],[\"的大模型推理增强还是需要很多\",{\"2\":{\"2145\":1}}],[\"的大型语言模型\",{\"2\":{\"2066\":1}}],[\"的大小\",{\"2\":{\"593\":1}}],[\"的分布式训练框架\",{\"2\":{\"2066\":1}}],[\"的分词结果可能出现多种形式\",{\"2\":{\"562\":1}}],[\"的全称是\",{\"2\":{\"2035\":1}}],[\"的中文语言模型\",{\"2\":{\"2002\":1}}],[\"的中间推理过程\",{\"2\":{\"1766\":1}}],[\"的思维被建模为一个顶点\",{\"2\":{\"2144\":1}}],[\"的思维建模为图结构\",{\"2\":{\"2144\":1}}],[\"的思路是\",{\"2\":{\"1982\":1}}],[\"的思想\",{\"0\":{\"2087\":1},\"2\":{\"420\":1,\"1057\":1,\"1102\":1}}],[\"的区别\",{\"0\":{\"1981\":1},\"2\":{\"2467\":1}}],[\"的问题\",{\"2\":{\"1978\":1,\"2505\":1}}],[\"的问题解决能力\",{\"2\":{\"1441\":1}}],[\"的得分来自稀疏搜索\",{\"2\":{\"1949\":1}}],[\"的保留能力\",{\"2\":{\"1947\":1}}],[\"的出现标志着系统从被动执行者转变为主动决策者\",{\"2\":{\"1904\":1}}],[\"的出现为解决\",{\"2\":{\"1560\":1}}],[\"的顶层\",{\"2\":{\"1904\":1}}],[\"的输出能显著改进\",{\"2\":{\"2259\":1}}],[\"的输出\",{\"2\":{\"1885\":1,\"2140\":1,\"2603\":1}}],[\"的减少\",{\"2\":{\"1869\":1}}],[\"的减函数\",{\"2\":{\"1344\":1}}],[\"的范畴\",{\"2\":{\"1847\":1}}],[\"的二次增长所带来的资源和效率问题\",{\"2\":{\"1846\":1}}],[\"的代码示例\",{\"2\":{\"1816\":1,\"1823\":1}}],[\"的量化研究主要集中在训练后量化\",{\"2\":{\"1813\":1}}],[\"的量化效果\",{\"2\":{\"1209\":1}}],[\"的效果受多种因素影响\",{\"2\":{\"1775\":1}}],[\"的奖励减少\",{\"2\":{\"1740\":1}}],[\"的支持\",{\"2\":{\"1700\":1}}],[\"的支持情况\",{\"2\":{\"698\":1}}],[\"的任务\",{\"2\":{\"1687\":1}}],[\"的不同实现方式\",{\"2\":{\"1672\":1}}],[\"的研究成果\",{\"2\":{\"1665\":1}}],[\"的步骤\",{\"2\":{\"1619\":1}}],[\"的运作需要结合强大的\",{\"2\":{\"1611\":1}}],[\"的灵活性和并行计算效率\",{\"2\":{\"1606\":1}}],[\"的错误分为两类\",{\"2\":{\"1594\":1}}],[\"的位置编码机制迁移到视觉\",{\"2\":{\"1587\":1}}],[\"的位置编码效果\",{\"2\":{\"1587\":1}}],[\"的位置编码为\",{\"2\":{\"1555\":1}}],[\"的学习过程\",{\"2\":{\"1578\":1}}],[\"的双向优势\",{\"0\":{\"1578\":1}}],[\"的风险\",{\"2\":{\"1551\":1}}],[\"的关键组成部分\",{\"2\":{\"1797\":1}}],[\"的关键挑战之一\",{\"2\":{\"1550\":1}}],[\"的关系\",{\"2\":{\"732\":1,\"2312\":1}}],[\"的新指标\",{\"2\":{\"1544\":1}}],[\"的统一位置表示\",{\"2\":{\"1543\":1}}],[\"的进一步发展\",{\"2\":{\"1526\":1}}],[\"的定制模型\",{\"2\":{\"1508\":1}}],[\"的定义\",{\"0\":{\"1188\":1},\"1\":{\"1238\":1,\"1289\":1,\"1336\":1,\"1382\":1,\"1429\":1},\"2\":{\"1617\":1}}],[\"的定义和调用\",{\"2\":{\"12\":1}}],[\"的评估框架\",{\"2\":{\"2550\":1}}],[\"的评估\",{\"0\":{\"2384\":1},\"2\":{\"2384\":1}}],[\"的评估方法与指标\",{\"0\":{\"1500\":1},\"1\":{\"1544\":1,\"1594\":1,\"1648\":1,\"1701\":1,\"1759\":1,\"1819\":1}}],[\"的评估需要从\",{\"2\":{\"1356\":1}}],[\"的异同点\",{\"2\":{\"1493\":1}}],[\"的简化相对位置编码将成为主流趋势之一\",{\"2\":{\"1537\":1}}],[\"的简化相对位置编码\",{\"2\":{\"1493\":1}}],[\"的训练步数就超过了grpo\",{\"2\":{\"2692\":1}}],[\"的训练步数就超过了传统的grpo方法\",{\"2\":{\"2689\":1}}],[\"的训练过程中\",{\"2\":{\"1460\":1}}],[\"的训练时间可能会有所增加\",{\"2\":{\"1160\":1}}],[\"的挑战\",{\"0\":{\"1459\":1,\"2107\":1},\"1\":{\"1504\":1,\"1550\":1,\"1600\":1}}],[\"的知识完全来源于其训练数据\",{\"2\":{\"1423\":1}}],[\"的部分\",{\"2\":{\"1420\":1}}],[\"的获取方式是通过构建提示词\",{\"2\":{\"1412\":1}}],[\"的项\",{\"2\":{\"1377\":1}}],[\"的取值范围\",{\"2\":{\"1353\":1}}],[\"的基本原理\",{\"0\":{\"1873\":1}}],[\"的基本组成\",{\"2\":{\"1333\":1}}],[\"的基本概念\",{\"2\":{\"207\":1}}],[\"的能力来创建分块\",{\"2\":{\"1321\":1}}],[\"的行为模式\",{\"2\":{\"1300\":1}}],[\"的规律公式\",{\"2\":{\"1297\":1}}],[\"的选择\",{\"0\":{\"1297\":1}}],[\"的选择影响训练过程的收敛行为\",{\"2\":{\"1162\":1}}],[\"的矩阵\",{\"2\":{\"1281\":1}}],[\"的指令\",{\"2\":{\"1275\":1}}],[\"的主要作用是将输入的句子切分为词或字\",{\"2\":{\"1253\":1}}],[\"的主要优势在于其能够在保持模型准确率的同时实现显著的压缩效果\",{\"2\":{\"1160\":1}}],[\"的调用\",{\"2\":{\"1250\":1}}],[\"的性能将进一步提升\",{\"2\":{\"1700\":1}}],[\"的性能表现\",{\"2\":{\"1381\":1}}],[\"的性能\",{\"2\":{\"1307\":1,\"2037\":1,\"2603\":1}}],[\"的性能高度依赖于知识数据的准确性和清洁程度\",{\"2\":{\"1234\":1}}],[\"的性能差异\",{\"2\":{\"322\":1}}],[\"的动态词嵌入方法\",{\"2\":{\"1225\":1}}],[\"的动态规划方法\",{\"2\":{\"612\":1}}],[\"的完全自动反事实知识蒸馏方法\",{\"2\":{\"1224\":1}}],[\"的蒸馏工作包括\",{\"2\":{\"1224\":1}}],[\"的核心数据结构是随机投影树\",{\"2\":{\"2195\":1}}],[\"的核心算法\",{\"2\":{\"2171\":1}}],[\"的核心作用是动态拆解任务\",{\"2\":{\"2089\":1}}],[\"的核心改进在于引入了多数投票\",{\"2\":{\"2042\":1}}],[\"的核心思想是接收用户提问后\",{\"2\":{\"1717\":1}}],[\"的核心思想是将llm作为agent进行评估\",{\"2\":{\"1217\":1}}],[\"的核心定义是一个能够感知环境\",{\"2\":{\"1474\":1}}],[\"的核心目标是解决当前\",{\"2\":{\"1453\":1}}],[\"的核心目标\",{\"0\":{\"1453\":1}}],[\"的核心组成可以表示为\",{\"2\":{\"1233\":1}}],[\"的核心特点\",{\"0\":{\"426\":1,\"2188\":1}}],[\"的优缺点\",{\"0\":{\"2118\":1}}],[\"的优点\",{\"2\":{\"1507\":1}}],[\"的优化器状态和梯度\",{\"2\":{\"2308\":1}}],[\"的优化方案\",{\"0\":{\"1705\":1},\"1\":{\"1763\":1}}],[\"的优化上不如\",{\"2\":{\"1592\":1}}],[\"的优化是提升性能的关键\",{\"2\":{\"1451\":1}}],[\"的优化和变化\",{\"2\":{\"926\":1}}],[\"的优劣势\",{\"2\":{\"1261\":1}}],[\"的优劣\",{\"2\":{\"1212\":1}}],[\"的优势在于其能够在较短的时间内获得接近\",{\"2\":{\"1209\":1}}],[\"的可学习位置编码\",{\"2\":{\"1555\":1}}],[\"的可训练偏置项\",{\"2\":{\"1207\":1}}],[\"的可能性\",{\"2\":{\"388\":1}}],[\"的泛化能力\",{\"2\":{\"1176\":1}}],[\"的上下文窗口通常是有限的\",{\"2\":{\"1321\":1}}],[\"的上下文少样本学习能力和语言建模能力转移到学生模型中\",{\"2\":{\"1175\":1}}],[\"的上下文长度从\",{\"2\":{\"889\":1}}],[\"的方式\",{\"2\":{\"2693\":1}}],[\"的方式不同\",{\"2\":{\"1708\":1}}],[\"的方式实现zero\",{\"2\":{\"1154\":1}}],[\"的方法向\",{\"2\":{\"2408\":1}}],[\"的方法中\",{\"2\":{\"2323\":1}}],[\"的方法进行优化\",{\"2\":{\"1222\":1}}],[\"的方法\",{\"0\":{\"593\":1},\"2\":{\"32\":1,\"101\":1,\"1531\":1,\"1930\":1,\"2384\":1,\"2601\":1,\"2689\":1}}],[\"的具体实现细节\",{\"2\":{\"1140\":1}}],[\"的更多用法\",{\"2\":{\"1125\":1}}],[\"的非英语token\",{\"2\":{\"1117\":1}}],[\"的结合来提升推理效率\",{\"2\":{\"2129\":1}}],[\"的结合方式\",{\"2\":{\"387\":1}}],[\"的结构来建模\",{\"2\":{\"2094\":1}}],[\"的结构\",{\"2\":{\"1149\":1}}],[\"的结构完整\",{\"2\":{\"1094\":1}}],[\"的一个实例\",{\"2\":{\"1618\":1}}],[\"的一些关键技术点和优化策略\",{\"2\":{\"1057\":1}}],[\"的一种特例\",{\"2\":{\"1035\":1}}],[\"的物理意义\",{\"0\":{\"1036\":1}}],[\"的语料库\",{\"2\":{\"1019\":1}}],[\"的tokens保持不变以提供模型偏向\",{\"2\":{\"997\":1}}],[\"的tokens替换为随机单词以增强纠错能力\",{\"2\":{\"997\":1}}],[\"的tokens替换为\",{\"2\":{\"997\":1}}],[\"的形式\",{\"2\":{\"978\":1}}],[\"的形式展示\",{\"2\":{\"39\":1}}],[\"的混合目标函数\",{\"2\":{\"925\":1}}],[\"的共享范围即量化粒度\",{\"0\":{\"904\":1},\"1\":{\"939\":1,\"981\":1,\"1022\":1}}],[\"的本质是一种映射关系\",{\"2\":{\"882\":1}}],[\"的计数器\",{\"2\":{\"778\":1}}],[\"的计算量为\",{\"2\":{\"2643\":1}}],[\"的计算代码\",{\"2\":{\"2539\":1}}],[\"的计算\",{\"2\":{\"2379\":1}}],[\"的计算为\",{\"2\":{\"2033\":1}}],[\"的计算过程如下\",{\"2\":{\"1756\":1}}],[\"的计算效率\",{\"2\":{\"467\":1}}],[\"的计算公式\",{\"2\":{\"439\":1}}],[\"的计算公式为\",{\"2\":{\"221\":1,\"537\":1,\"1644\":1}}],[\"的状态\",{\"2\":{\"778\":1}}],[\"的算法\",{\"2\":{\"771\":1}}],[\"的1\",{\"2\":{\"768\":1}}],[\"的内存布局进行调整\",{\"2\":{\"2129\":1}}],[\"的内存\",{\"2\":{\"750\":1}}],[\"的期望\",{\"2\":{\"2306\":1}}],[\"的期望收益\",{\"2\":{\"748\":1}}],[\"的期望重写为\",{\"2\":{\"623\":1}}],[\"的架构设计\",{\"2\":{\"738\":1}}],[\"的发展及其对混合精度训练的影响\",{\"2\":{\"734\":1}}],[\"的发展迅速\",{\"2\":{\"99\":1}}],[\"的过程\",{\"2\":{\"733\":1,\"2129\":1,\"2363\":1}}],[\"的浮点型权重近似为有限多个离散值权重如\",{\"2\":{\"733\":1}}],[\"的技术文档与相关论文内容整理而成\",{\"2\":{\"1587\":1}}],[\"的技术文档整理与总结\",{\"2\":{\"563\":1}}],[\"的技术报告中并未详细说明模型结构\",{\"2\":{\"1102\":1}}],[\"的技术\",{\"2\":{\"677\":1}}],[\"的联合预训练方法\",{\"2\":{\"635\":1}}],[\"的实施非常简单\",{\"2\":{\"1260\":1}}],[\"的实现由一组交互式模块构成\",{\"2\":{\"2227\":1}}],[\"的实现思路是基于论文中提供的提示词\",{\"2\":{\"1458\":1}}],[\"的实现\",{\"2\":{\"1451\":1}}],[\"的实现与工作机制\",{\"0\":{\"955\":1},\"1\":{\"996\":1,\"1036\":1}}],[\"的实现细节\",{\"2\":{\"734\":1}}],[\"的实现方案\",{\"0\":{\"1458\":1},\"2\":{\"702\":1}}],[\"的实现及优劣\",{\"2\":{\"383\":1}}],[\"的实际效果\",{\"2\":{\"597\":1}}],[\"的自注意力子层之后\",{\"2\":{\"560\":1}}],[\"的句子对是前后关系\",{\"2\":{\"1037\":1}}],[\"的句子\",{\"2\":{\"548\":2,\"1281\":1}}],[\"的文本切分方法\",{\"2\":{\"1896\":1}}],[\"的文本切分功能\",{\"0\":{\"1612\":1},\"1\":{\"1665\":1,\"1719\":1},\"2\":{\"1776\":1}}],[\"的文本切块\",{\"0\":{\"1896\":1},\"1\":{\"1951\":1,\"2002\":1}}],[\"的文本分类\",{\"2\":{\"49\":1}}],[\"的文章\",{\"2\":{\"548\":1}}],[\"的稀疏激活机制误解为随机选择专家\",{\"2\":{\"527\":1}}],[\"的建模\",{\"2\":{\"514\":1}}],[\"的准确率\",{\"2\":{\"507\":1}}],[\"的原理\",{\"2\":{\"502\":1,\"1333\":1}}],[\"的综合方法\",{\"2\":{\"468\":1}}],[\"的硬件上\",{\"2\":{\"462\":1}}],[\"的激活值\",{\"2\":{\"435\":1}}],[\"的权重进行前向计算\",{\"2\":{\"435\":1}}],[\"的参数空间\",{\"2\":{\"2281\":1}}],[\"的参数重分片同步到\",{\"2\":{\"2129\":1}}],[\"的参数分片模式\",{\"2\":{\"2079\":1}}],[\"的参数化形式\",{\"2\":{\"1653\":1}}],[\"的参数\",{\"2\":{\"435\":1,\"1083\":1,\"2308\":1}}],[\"的显存使用\",{\"2\":{\"433\":1}}],[\"的温度系数来影响输出词的概率分布\",{\"2\":{\"416\":1}}],[\"的爬虫id列表配置\",{\"2\":{\"411\":1}}],[\"的影响\",{\"2\":{\"393\":1,\"1441\":1}}],[\"的特点\",{\"0\":{\"1412\":1,\"2167\":1}}],[\"的特殊\",{\"2\":{\"847\":1}}],[\"的特例\",{\"2\":{\"363\":1}}],[\"的特性\",{\"2\":{\"217\":1}}],[\"的表现\",{\"2\":{\"327\":1}}],[\"的候选序列集合\",{\"2\":{\"324\":1}}],[\"的策略\",{\"2\":{\"308\":1,\"2374\":1}}],[\"的应用中\",{\"2\":{\"1753\":1}}],[\"的应用案例\",{\"2\":{\"1441\":1}}],[\"的应用潜力\",{\"2\":{\"442\":1}}],[\"的应用\",{\"2\":{\"281\":1}}],[\"的变化\",{\"2\":{\"276\":1}}],[\"的独立性\",{\"2\":{\"251\":1,\"275\":1}}],[\"的四种主要结构及其特点\",{\"2\":{\"248\":1}}],[\"的适应性来提升学生模型的性能\",{\"2\":{\"1275\":1}}],[\"的适配性\",{\"2\":{\"240\":1}}],[\"的适用场景\",{\"2\":{\"234\":1}}],[\"的词序不同\",{\"2\":{\"216\":1}}],[\"的创新\",{\"2\":{\"199\":1}}],[\"的改进方法\",{\"2\":{\"1990\":1}}],[\"的改进\",{\"0\":{\"199\":1}}],[\"的比例缩放\",{\"2\":{\"184\":1}}],[\"的交互则更加复杂和动态\",{\"2\":{\"2363\":1}}],[\"的交互非常直接\",{\"2\":{\"2333\":1}}],[\"的交互项\",{\"2\":{\"1353\":1}}],[\"的交互\",{\"2\":{\"162\":1}}],[\"的处理是独立的\",{\"2\":{\"162\":1}}],[\"的作用类似于一个\",{\"2\":{\"1728\":1}}],[\"的作用是调整点积结果的幅度\",{\"2\":{\"228\":1}}],[\"的作用是控制数值范围\",{\"2\":{\"130\":1}}],[\"的作用与应用|transformer核心模块解析\",{\"2\":{\"5\":1}}],[\"的作用与应用|ffn\",{\"2\":{\"5\":1}}],[\"的作用与应用\",{\"0\":{\"89\":1},\"1\":{\"104\":1,\"121\":1,\"141\":1,\"162\":1,\"183\":1,\"205\":1,\"227\":1,\"251\":1,\"275\":1,\"299\":1},\"2\":{\"5\":6,\"73\":1}}],[\"的信息\",{\"2\":{\"121\":1}}],[\"的对话生成\",{\"2\":{\"49\":1}}],[\"的\",{\"2\":{\"10\":1,\"57\":1,\"162\":1,\"261\":1,\"495\":1,\"575\":1,\"813\":1,\"881\":1,\"1065\":1,\"1069\":1,\"1436\":1,\"1500\":1,\"1617\":1,\"1766\":1,\"1860\":1,\"2081\":6,\"2161\":2,\"2252\":1,\"2286\":3,\"2408\":1,\"2518\":1,\"2546\":1,\"2578\":1,\"2655\":1,\"2699\":1}}],[\"的命名空间\",{\"2\":{\"10\":2}}],[\"的函数\",{\"2\":{\"10\":1}}],[\"函数f\",{\"2\":{\"307\":1}}],[\"函数模板\",{\"2\":{\"15\":1}}],[\"函数之后定义\",{\"2\":{\"11\":1}}],[\"函数之前定义\",{\"2\":{\"11\":1}}],[\"函数定义\",{\"2\":{\"11\":1}}],[\"函数定义立即可用\",{\"2\":{\"11\":1}}],[\"函数定义的位置对代码的清晰度和组织有影响\",{\"2\":{\"11\":1}}],[\"函数声明\",{\"0\":{\"11\":1},\"2\":{\"11\":2}}],[\"函数\",{\"2\":{\"10\":2,\"11\":1,\"21\":2,\"307\":2}}],[\"是针对说明性文本生成任务提出的一种方法\",{\"2\":{\"2601\":1}}],[\"是模型的一个分片\",{\"2\":{\"2433\":1}}],[\"是模型生成的预测输出\",{\"2\":{\"773\":1}}],[\"是归一化后的结果吗\",{\"2\":{\"2349\":1}}],[\"是归一化前的结果\",{\"2\":{\"2349\":1}}],[\"是根据\",{\"2\":{\"2183\":1}}],[\"是生成\",{\"2\":{\"2145\":1}}],[\"是后续每个\",{\"2\":{\"2145\":1}}],[\"是首个\",{\"2\":{\"2145\":1}}],[\"是在时间步\",{\"2\":{\"2124\":1}}],[\"是在模型训练过程中引入量化的意识\",{\"2\":{\"1160\":1}}],[\"是折扣因子\",{\"2\":{\"2124\":1}}],[\"是预训练必用框架\",{\"2\":{\"2118\":1}}],[\"是另一个广泛使用的深度学习框架\",{\"2\":{\"2381\":1}}],[\"是另一个关键因素\",{\"2\":{\"2000\":1}}],[\"是另一款强大的自然语言处理库\",{\"2\":{\"1896\":1}}],[\"是对整个输入prompt对应的key和value值进行caching操作\",{\"2\":{\"2166\":1}}],[\"是对输入进行分类\",{\"2\":{\"1935\":1}}],[\"是对传统q\",{\"2\":{\"606\":1}}],[\"是经过验证有效的提示语\",{\"2\":{\"1885\":1}}],[\"是考虑到生成第1个token和其余token时计算模式的差异较大\",{\"2\":{\"1782\":1}}],[\"是将任务分解为顺序执行的子步骤\",{\"2\":{\"1702\":1}}],[\"是将整个\",{\"2\":{\"27\":1}}],[\"是第\",{\"2\":{\"1644\":1,\"2137\":1,\"2306\":1}}],[\"是查询总数\",{\"2\":{\"1644\":1}}],[\"是需要特别关注的问题\",{\"2\":{\"1600\":1}}],[\"是目前基座训练和应用最重要的两个方向之一\",{\"2\":{\"1578\":1}}],[\"是目前计算成本最高的分块技术之一\",{\"2\":{\"1321\":1}}],[\"是icl\",{\"2\":{\"1550\":1}}],[\"是两种不同的模型训练方法\",{\"2\":{\"1564\":1}}],[\"是两种重要的技术\",{\"2\":{\"1517\":1}}],[\"是两个非常重要的概念\",{\"2\":{\"7\":1}}],[\"是递归计算\",{\"2\":{\"1463\":1}}],[\"是可训练的\",{\"2\":{\"1359\":1}}],[\"是频率参数\",{\"2\":{\"1246\":1}}],[\"是指在模型训练完成后\",{\"2\":{\"1260\":1}}],[\"是指在特定任务中\",{\"2\":{\"1241\":1}}],[\"是指将多个短的序列拼接成一个长序列\",{\"2\":{\"813\":1}}],[\"是衡量推理性能的重要指标\",{\"2\":{\"2228\":1}}],[\"是衡量模型或算法复杂度的指标\",{\"2\":{\"1926\":1}}],[\"是衡量硬件性能的指标\",{\"2\":{\"1926\":1}}],[\"是衡量计算量的标准\",{\"2\":{\"1232\":1}}],[\"是衡量语言模型性能的重要指标\",{\"2\":{\"268\":1}}],[\"是common\",{\"2\":{\"1138\":1}}],[\"是github代码\",{\"2\":{\"1138\":1}}],[\"是google在2018年提出的预训练语言模型\",{\"2\":{\"115\":1}}],[\"是谷歌尝试的一种与\",{\"2\":{\"1102\":1}}],[\"是谷歌推出的一种新型大语言模型\",{\"2\":{\"1057\":1}}],[\"是随机组合\",{\"2\":{\"1037\":1}}],[\"是大多数知识蒸馏算法采用的方法\",{\"2\":{\"954\":1}}],[\"是单射的映射\",{\"2\":{\"918\":1}}],[\"是如何优化的\",{\"0\":{\"917\":1}}],[\"是提升模型性能的重要环节之一\",{\"2\":{\"804\":1}}],[\"是要预测的答案\",{\"2\":{\"773\":1}}],[\"是输入\",{\"2\":{\"773\":1}}],[\"是输入特征\",{\"2\":{\"76\":1}}],[\"是任务定义\",{\"2\":{\"773\":1}}],[\"是最常用的高精度表示方式\",{\"2\":{\"768\":1}}],[\"是智能体在不同状态下采取动作的概率分布\",{\"2\":{\"676\":1}}],[\"是强化学习中用于抽象实际问题的基础结构\",{\"2\":{\"676\":1}}],[\"是通过max⁡\",{\"2\":{\"653\":1}}],[\"是未来大模型训练的重要方向\",{\"2\":{\"625\":1}}],[\"是设定的裁剪阈值\",{\"2\":{\"622\":1}}],[\"是基于现有基础模型\",{\"2\":{\"475\":1}}],[\"是超参数\",{\"2\":{\"293\":1}}],[\"是上下文窗口的扩展比例\",{\"2\":{\"276\":1}}],[\"是正交矩阵\",{\"0\":{\"270\":1},\"1\":{\"293\":1,\"315\":1}}],[\"是旋转角度\",{\"2\":{\"247\":1}}],[\"是位置信息\",{\"2\":{\"247\":1}}],[\"是向量的维度\",{\"2\":{\"228\":1}}],[\"是个位数\",{\"2\":{\"223\":1}}],[\"是十位数\",{\"2\":{\"223\":1}}],[\"是百位数\",{\"2\":{\"223\":1}}],[\"是否能够合理地拒绝回答也是评估的重要内容之一\",{\"2\":{\"2540\":1}}],[\"是否能够紧密衔接用户输入内容\",{\"2\":{\"2257\":1}}],[\"是否符合数据库中的事实\",{\"2\":{\"2436\":1}}],[\"是否提供了有用的信息\",{\"2\":{\"2257\":1}}],[\"是否覆盖了用户需求的所有信息点\",{\"2\":{\"2257\":1}}],[\"是否引入衰减需视实验而定\",{\"2\":{\"1436\":1}}],[\"是否需要不同的优化策略\",{\"2\":{\"1758\":1}}],[\"是否需要不同于主流语言的数据清洗策略\",{\"2\":{\"685\":1}}],[\"是否需要对\",{\"2\":{\"1450\":1}}],[\"是否需要针对不同语言定制化的去重策略\",{\"2\":{\"785\":1}}],[\"是否需要额外优化\",{\"2\":{\"719\":1}}],[\"是否需要重新设计预训练目标\",{\"2\":{\"635\":1}}],[\"是否需要根据任务动态调整\",{\"2\":{\"564\":1}}],[\"是否开启爬二级评论模式\",{\"2\":{\"526\":1}}],[\"是否开启爬评论模式\",{\"2\":{\"526\":1}}],[\"是否开启爬图片模式\",{\"2\":{\"526\":1}}],[\"是否有通用的参数优化策略\",{\"2\":{\"2350\":1}}],[\"是否有其他更有效的方法来优化小模型的训练过程\",{\"2\":{\"2345\":1}}],[\"是否有可能通过自动化工具进一步简化参数调整过程\",{\"2\":{\"2350\":1}}],[\"是否有可能通过混合式方法\",{\"2\":{\"1606\":1}}],[\"是否有可能开发出通用的策略优化算法\",{\"2\":{\"994\":1}}],[\"是否有可能结合其他算法进一步提高学习效率\",{\"2\":{\"876\":1}}],[\"是否有可能完全摆脱\",{\"2\":{\"660\":1}}],[\"是否有更适合的小型分词模型\",{\"2\":{\"719\":1}}],[\"是否有更智能化的解决方案\",{\"2\":{\"628\":1}}],[\"是否有更先进的解码策略能解决beam\",{\"2\":{\"453\":1}}],[\"是否有新的技术趋势可以进一步简化api集成\",{\"2\":{\"219\":1}}],[\"是否会有更多复杂激活函数被引入\",{\"2\":{\"289\":1}}],[\"是否可以进一步扩展为多维矩阵以增强表达能力\",{\"2\":{\"1593\":1}}],[\"是否可以进一步优化以提升训练效率\",{\"2\":{\"702\":1}}],[\"是否可以进一步优化或自动化\",{\"2\":{\"660\":1}}],[\"是否可以开发一种通用算法\",{\"2\":{\"705\":1}}],[\"是否可以通过图神经网络\",{\"2\":{\"1606\":1}}],[\"是否可以通过迁移学习减少对大规模数据的依赖\",{\"2\":{\"1508\":1}}],[\"是否可以通过预训练技术进一步提升\",{\"2\":{\"1176\":1}}],[\"是否可以通过生成式ai辅助更高效地完成数据质量评估\",{\"2\":{\"785\":1}}],[\"是否可以通过生成式ai辅助生成高质量数据以弥补清洗后的数据缺失\",{\"2\":{\"685\":1}}],[\"是否可以通过自动化手段更高效地定位并修复loss\",{\"2\":{\"736\":1}}],[\"是否可以通过其他方式优化\",{\"2\":{\"289\":1}}],[\"是否可以引入主动学习机制来动态调整采样权重\",{\"2\":{\"632\":1}}],[\"是否可以动态调整beam大小以适配不同任务\",{\"2\":{\"453\":1}}],[\"是否可以扩展到图像处理任务\",{\"2\":{\"432\":1}}],[\"是否可以设计一种动态调整压缩率的方法以适应不同任务场景\",{\"2\":{\"1580\":1}}],[\"是否可以设计一种既支持并行计算又具有长度外推能力的位置编码方法\",{\"2\":{\"1507\":1}}],[\"是否可以设计一个自适应激活函数\",{\"2\":{\"406\":1}}],[\"是否可以设计动态调整波长的方法\",{\"2\":{\"466\":1}}],[\"是否可以设计更语义化的位置编码方法\",{\"2\":{\"356\":1}}],[\"是否可以将不同领域的数据集结合起来\",{\"2\":{\"2258\":1}}],[\"是否可以将s2\",{\"2\":{\"333\":1}}],[\"是否可以将类似温度参数的思想应用于其他类型的位置编码方法\",{\"2\":{\"300\":1}}],[\"是否可以结合transformer模型优化word2vec的性能\",{\"2\":{\"1210\":1}}],[\"是否可以结合语义理解优化采样过程\",{\"2\":{\"771\":1}}],[\"是否可以结合混合精度训练和其他显存优化技术进一步提升效率\",{\"2\":{\"694\":1}}],[\"是否可以结合wordpiece和ulm的方法\",{\"2\":{\"564\":1}}],[\"是否可以结合bpe和wordpiece的优点创建新的分词算法\",{\"2\":{\"490\":1}}],[\"是否可以结合神经网络\",{\"2\":{\"469\":1}}],[\"是否可以结合动态分组策略进一步提升性能\",{\"2\":{\"404\":1}}],[\"是否可以结合分块处理\",{\"2\":{\"337\":1}}],[\"是否可以结合其他编码方式\",{\"2\":{\"413\":1}}],[\"是否可以结合其他优化技术\",{\"2\":{\"279\":1}}],[\"是否可以结合其他模型\",{\"2\":{\"217\":1}}],[\"是否可以结合pre\",{\"2\":{\"258\":1}}],[\"是否存在事实性错误\",{\"2\":{\"2257\":1}}],[\"是否存在更高效的调度器替代\",{\"2\":{\"1577\":1}}],[\"是否存在更高效的算法来解决贝尔曼方程中的计算复杂性\",{\"2\":{\"797\":1}}],[\"是否存在轻量化\",{\"2\":{\"702\":1}}],[\"是否存在替代函数满足同样需求\",{\"2\":{\"356\":1}}],[\"是否存在其他潜在替代品\",{\"2\":{\"289\":1}}],[\"是否存在性能瓶颈\",{\"2\":{\"233\":1}}],[\"是否保留上下文信息\",{\"2\":{\"227\":1}}],[\"是更优选择\",{\"2\":{\"205\":1}}],[\"是机器学习的经典算法之一\",{\"2\":{\"185\":1}}],[\"是transformer模型中一种用于弥补序列时序信息缺失的机制\",{\"2\":{\"174\":1}}],[\"是\",{\"2\":{\"162\":2,\"205\":1,\"227\":1,\"926\":1,\"1035\":1,\"2393\":1}}],[\"是构建其强大性能的关键模块\",{\"2\":{\"121\":1}}],[\"是一项非常重要的技术\",{\"2\":{\"2552\":1}}],[\"是一个允许调试\",{\"2\":{\"2590\":1}}],[\"是一个主要用于评估忠实性\",{\"2\":{\"2558\":1}}],[\"是一个代理\",{\"2\":{\"2433\":1}}],[\"是一个高性能分布式执行框架\",{\"2\":{\"2408\":1}}],[\"是一个性能极高的深度学习模型训练框架\",{\"2\":{\"2351\":1}}],[\"是一个动态结构\",{\"2\":{\"2262\":1}}],[\"是一个静态结构\",{\"2\":{\"2262\":1}}],[\"是一个基于\",{\"2\":{\"2066\":1}}],[\"是一个为\",{\"2\":{\"2055\":1}}],[\"是一个用于计算文本长度的函数\",{\"2\":{\"2039\":1}}],[\"是一个\",{\"2\":{\"1885\":1,\"2433\":2}}],[\"是一个广泛使用的\",{\"2\":{\"1612\":1}}],[\"是一个非常重要的环节\",{\"2\":{\"1557\":1}}],[\"是一个非常重要的概念\",{\"2\":{\"1136\":1,\"1139\":1}}],[\"是一个专注于数据索引和查询的框架\",{\"2\":{\"1250\":1}}],[\"是一个仅依赖于位置\",{\"2\":{\"1207\":1}}],[\"是一个全连接层\",{\"2\":{\"918\":1}}],[\"是一个需要深入研究的问题\",{\"2\":{\"845\":1}}],[\"是一个任意实数\",{\"2\":{\"90\":1}}],[\"是一种能够将文本转换为高维向量表示的工具\",{\"2\":{\"2659\":1}}],[\"是一种逐句生成\",{\"2\":{\"2601\":1}}],[\"是一种在并行计算和分布式计算中常用的通信操作\",{\"2\":{\"2427\":1}}],[\"是一种在已有的预训练模型基础上进行微调的量化方法\",{\"2\":{\"1209\":1}}],[\"是一种将模型训练任务分散到多个计算单元\",{\"2\":{\"2374\":1}}],[\"是一种将高维数据\",{\"2\":{\"882\":1}}],[\"是一种兼顾效率与效果的检索策略\",{\"2\":{\"2236\":1}}],[\"是一种兼顾效率与性能的方法\",{\"2\":{\"1209\":1}}],[\"是一种经典的强化学习框架\",{\"2\":{\"2124\":1}}],[\"是一种经典的聚类算法\",{\"2\":{\"1467\":1}}],[\"是一种有效的方法\",{\"2\":{\"2102\":1}}],[\"是一种有效的探索和利用平衡方法\",{\"2\":{\"840\":1}}],[\"是一种去掉critic\",{\"2\":{\"1954\":1}}],[\"是一种集成多种\",{\"2\":{\"1930\":1}}],[\"是一种高效的微调大模型方法\",{\"2\":{\"1792\":1}}],[\"是一种常用且有效的策略\",{\"2\":{\"1763\":1}}],[\"是一种常见的子词分词算法\",{\"2\":{\"319\":1}}],[\"是一种推荐用于通用文本处理的工具\",{\"2\":{\"1763\":1}}],[\"是一种改进的\",{\"2\":{\"1708\":1}}],[\"是一种改进的提示优化技术\",{\"2\":{\"1680\":1}}],[\"是一种改进的分词技术\",{\"2\":{\"296\":1}}],[\"是一种创新方法\",{\"2\":{\"1636\":1}}],[\"是一种旨在使模型输出与人类偏好对齐的技术\",{\"2\":{\"1620\":1}}],[\"是一种旨在将知识从大型复杂模型\",{\"2\":{\"677\":1}}],[\"是一种强化学习算法\",{\"2\":{\"1589\":1}}],[\"是一种利用人类偏好数据训练机器学习模型的方法\",{\"2\":{\"1589\":1}}],[\"是一种模块化推理\",{\"2\":{\"1569\":1}}],[\"是一种新提出的算法\",{\"2\":{\"1955\":1}}],[\"是一种新的方法\",{\"2\":{\"1495\":1}}],[\"是一种新型的开放基础和微调聊天模型\",{\"2\":{\"1026\":1}}],[\"是一种从目标概率分布中获取样本的蒙特卡洛方法\",{\"2\":{\"1164\":1}}],[\"是一种从排名靠前的\",{\"2\":{\"295\":1}}],[\"是一种基于编码器\",{\"2\":{\"901\":1}}],[\"是一种基于概率统计的数值计算方法\",{\"2\":{\"675\":1}}],[\"是一种基于概率的分词算法\",{\"2\":{\"343\":1}}],[\"是一种平衡数值稳定性和精度的有效方法\",{\"2\":{\"589\":1}}],[\"是一种用于强化学习的策略更新方法\",{\"2\":{\"2467\":1}}],[\"是一种用于强化学习的策略优化算法\",{\"2\":{\"521\":1}}],[\"是一种用于衡量信息检索系统表现的指标\",{\"2\":{\"1590\":1}}],[\"是一种用于自然语言处理的预训练模型\",{\"2\":{\"919\":1}}],[\"是一种用于优化transformer结构中自回归生成过程的技术\",{\"2\":{\"107\":1}}],[\"是一种结合\",{\"2\":{\"468\":1}}],[\"是一种通过从外部来源\",{\"2\":{\"2469\":1}}],[\"是一种通过调整提示\",{\"2\":{\"1752\":1}}],[\"是一种通过自我训练过程提升语言模型指令遵循能力和奖励评估能力的方法\",{\"2\":{\"1747\":1}}],[\"是一种通过引入多个专家网络\",{\"2\":{\"415\":1}}],[\"是一种通过对query和key向量进行旋转变换来引入位置信息的方法\",{\"2\":{\"252\":1}}],[\"是一种更简单的改进方法\",{\"2\":{\"293\":1}}],[\"是一种扩展语言模型上下文窗口长度的技术\",{\"2\":{\"180\":1}}],[\"是一种针对rope\",{\"2\":{\"163\":1}}],[\"是一种针对长文本处理的创新技术\",{\"2\":{\"86\":1}}],[\"是一种组织代码的方式\",{\"2\":{\"10\":1}}],[\"是线性回归的输出\",{\"2\":{\"76\":1}}],[\"是偏置项\",{\"2\":{\"76\":1}}],[\"是权重\",{\"2\":{\"76\":1}}],[\"1层放device1\",{\"2\":{\"2697\":1}}],[\"1f1b\",{\"2\":{\"2694\":1}}],[\"1f1​\",{\"2\":{\"1268\":1}}],[\"1y1​和y2y\",{\"2\":{\"2660\":1}}],[\"1y1​\",{\"2\":{\"2609\":1}}],[\"1a1​可以在第一个gpu上计算\",{\"2\":{\"2537\":1}}],[\"1x1​\",{\"2\":{\"2537\":1}}],[\"1r1​\",{\"2\":{\"2446\":1}}],[\"1d\",{\"2\":{\"2400\":1}}],[\"1m\",{\"2\":{\"2223\":1}}],[\"1ms\",{\"2\":{\"483\":2,\"2145\":2}}],[\"1gb\",{\"2\":{\"2145\":1}}],[\"14b\",{\"2\":{\"2603\":1,\"2622\":1}}],[\"1400gb\",{\"2\":{\"2281\":1}}],[\"140万+\",{\"2\":{\"2223\":1}}],[\"14\",{\"0\":{\"2611\":1},\"2\":{\"2145\":3,\"2697\":1}}],[\"1|x\",{\"2\":{\"2046\":4}}],[\"1​y∑​πref​\",{\"2\":{\"1889\":1}}],[\"1​πref​\",{\"2\":{\"1830\":1,\"1889\":1}}],[\"1s\",{\"2\":{\"1843\":1}}],[\"1βr\",{\"2\":{\"1830\":2,\"1889\":2}}],[\"1β1​\",{\"2\":{\"1162\":1}}],[\"1z\",{\"2\":{\"1830\":1}}],[\"1−n1​\",{\"2\":{\"2308\":1}}],[\"1−αmax\",{\"2\":{\"2033\":1}}],[\"1−αs\",{\"2\":{\"2033\":1}}],[\"1−1n\",{\"2\":{\"2308\":1}}],[\"1−1\",{\"2\":{\"1712\":1,\"1740\":1}}],[\"1−ϵ\",{\"2\":{\"590\":2,\"1622\":2,\"1628\":2,\"2044\":2,\"2097\":2,\"2485\":2}}],[\"1操作\",{\"2\":{\"1673\":1}}],[\"1n⋅φ\",{\"2\":{\"2308\":1}}],[\"1n\",{\"2\":{\"1644\":1,\"2308\":3}}],[\"1nin\",{\"2\":{\"1437\":1}}],[\"1+\",{\"2\":{\"1628\":1,\"2485\":1}}],[\"1+ϵ\",{\"2\":{\"590\":2,\"1622\":2,\"1628\":2,\"2044\":2,\"2097\":2,\"2485\":2}}],[\"1σ1​\",{\"2\":{\"1536\":3}}],[\"1亿\",{\"2\":{\"1395\":1}}],[\"1t−k≥1约束条件\",{\"2\":{\"1227\":1}}],[\"1t=0\",{\"2\":{\"184\":1,\"276\":1}}],[\"1=0\",{\"2\":{\"1204\":1}}],[\"1e10\",{\"2\":{\"2539\":1}}],[\"1e\",{\"2\":{\"1186\":1,\"2539\":1}}],[\"1e=1\",{\"2\":{\"789\":1}}],[\"1的权重衰减和1\",{\"2\":{\"1162\":1}}],[\"1的通用语料\",{\"2\":{\"475\":1}}],[\"1γ\",{\"2\":{\"1076\":1}}],[\"1基本一致\",{\"2\":{\"1059\":1}}],[\"1^\",{\"2\":{\"778\":3}}],[\"1比特是模型压缩的极限\",{\"2\":{\"768\":1}}],[\"1位二值网络\",{\"2\":{\"768\":1}}],[\"18th\",{\"2\":{\"1458\":2}}],[\"18\",{\"2\":{\"470\":1,\"1324\":1,\"1329\":1,\"1419\":1}}],[\"1750\",{\"2\":{\"2281\":1,\"2313\":1}}],[\"1750亿\",{\"2\":{\"1416\":1}}],[\"17953\",{\"2\":{\"1487\":1}}],[\"1706\",{\"2\":{\"1920\":1}}],[\"170\",{\"2\":{\"471\":1}}],[\"17\",{\"2\":{\"396\":1}}],[\"1749变为874\",{\"2\":{\"246\":1}}],[\"1$$\",{\"2\":{\"346\":1,\"416\":2,\"778\":1}}],[\"1678\",{\"2\":{\"1458\":2}}],[\"16b\",{\"2\":{\"1419\":1}}],[\"16gb\",{\"2\":{\"1341\":1}}],[\"16~23\",{\"2\":{\"1258\":1}}],[\"160gb\",{\"2\":{\"1341\":1}}],[\"160专家\",{\"2\":{\"1178\":1}}],[\"1602\",{\"2\":{\"837\":2}}],[\"16位截断的\",{\"2\":{\"768\":1}}],[\"16位浮点数\",{\"2\":{\"488\":1,\"768\":1}}],[\"16\",{\"0\":{\"2623\":1},\"2\":{\"332\":1,\"2161\":1}}],[\"16进制编码可以用三维向量表示0~4095的范围\",{\"2\":{\"246\":1}}],[\"1ln\",{\"2\":{\"184\":1,\"276\":1}}],[\"1ln⁡\",{\"2\":{\"184\":1,\"276\":1}}],[\"1⋅年龄+0\",{\"2\":{\"164\":2}}],[\"1️⃣\",{\"0\":{\"116\":1,\"368\":1}}],[\"10$$\",{\"2\":{\"1419\":1}}],[\"10^9\",{\"2\":{\"1297\":1}}],[\"10^\",{\"2\":{\"1232\":2}}],[\"1023\",{\"2\":{\"917\":1}}],[\"1024块v100\",{\"2\":{\"1341\":1}}],[\"1024\",{\"2\":{\"917\":1,\"2192\":12}}],[\"10t\",{\"2\":{\"535\":1}}],[\"10\",{\"0\":{\"2581\":1},\"2\":{\"56\":2,\"332\":1,\"345\":1,\"384\":1,\"396\":1,\"398\":1,\"405\":1,\"424\":2,\"501\":1,\"508\":1,\"526\":1,\"803\":1,\"997\":2,\"1103\":1,\"1138\":1,\"1258\":1,\"1290\":2,\"1329\":1,\"1499\":2,\"2201\":1,\"2433\":1,\"2539\":2,\"2697\":1}}],[\"100万+\",{\"2\":{\"2223\":1}}],[\"1008\",{\"2\":{\"2145\":1}}],[\"100m到1b参数\",{\"2\":{\"1736\":1}}],[\"100$$\",{\"2\":{\"1419\":1}}],[\"100b\",{\"2\":{\"535\":1,\"803\":1}}],[\"100+\",{\"2\":{\"65\":1}}],[\"1000$$\",{\"2\":{\"1419\":1}}],[\"10000\",{\"2\":{\"332\":1,\"1435\":1}}],[\"10000^\",{\"2\":{\"263\":1}}],[\"1000以内的整数可以用三维向量\",{\"2\":{\"223\":1}}],[\"1000\",{\"2\":{\"40\":1,\"245\":1,\"917\":2}}],[\"100\",{\"2\":{\"40\":1,\"324\":1,\"1089\":1,\"1232\":1,\"1435\":1,\"1763\":1,\"2050\":1,\"2417\":7}}],[\"13层模型用于预训练\",{\"2\":{\"1288\":1}}],[\"130b\",{\"2\":{\"1008\":1}}],[\"13b中\",{\"2\":{\"750\":1}}],[\"13\",{\"0\":{\"2604\":1},\"2\":{\"56\":1,\"345\":1,\"1225\":1}}],[\"1901\",{\"2\":{\"1647\":1}}],[\"1909\",{\"2\":{\"469\":1}}],[\"19\",{\"2\":{\"56\":1,\"470\":1,\"497\":1}}],[\"19th\",{\"2\":{\"18\":1}}],[\"11层放在device2\",{\"2\":{\"2697\":1}}],[\"115万\",{\"2\":{\"2223\":1}}],[\"11​\",{\"2\":{\"1756\":1}}],[\"111\",{\"2\":{\"1698\":1}}],[\"1123\",{\"2\":{\"1225\":1}}],[\"11008\",{\"2\":{\"266\":1}}],[\"11\",{\"0\":{\"2589\":1},\"2\":{\"56\":3,\"384\":1,\"1258\":1,\"1394\":1,\"1756\":1,\"2539\":1}}],[\"15层放在device4\",{\"2\":{\"2697\":1}}],[\"15115\",{\"2\":{\"1492\":1}}],[\"15亿\",{\"2\":{\"1395\":1,\"1416\":1}}],[\"15t+\",{\"2\":{\"1360\":1}}],[\"150k\",{\"2\":{\"1178\":1}}],[\"150\",{\"2\":{\"1007\":1,\"1292\":1}}],[\"150b\",{\"2\":{\"741\":1,\"909\":1}}],[\"1508\",{\"2\":{\"631\":1}}],[\"15\",{\"0\":{\"2618\":1},\"2\":{\"49\":1,\"501\":2,\"1756\":1,\"2697\":1}}],[\"12+15+11\",{\"2\":{\"1756\":1}}],[\"120万行文本\",{\"2\":{\"1487\":1}}],[\"120b数学标记来自common\",{\"2\":{\"1138\":1}}],[\"12139\",{\"2\":{\"1225\":1}}],[\"128k\",{\"2\":{\"847\":1}}],[\"128k长度训练的吞吐量\",{\"2\":{\"502\":1}}],[\"12\",{\"0\":{\"56\":1,\"2597\":1},\"2\":{\"56\":3,\"1103\":1,\"1178\":1,\"1232\":1,\"1756\":1,\"2090\":1,\"2161\":1,\"2539\":1}}],[\"12345\",{\"2\":{\"49\":1}}],[\"12n−1−1\",{\"2\":{\"18\":1}}],[\"1\",{\"0\":{\"10\":1,\"12\":1,\"22\":1,\"42\":1,\"52\":1,\"178\":1,\"216\":1,\"228\":1,\"247\":1,\"393\":1,\"426\":1,\"475\":1,\"503\":1,\"553\":1,\"655\":1,\"795\":1,\"811\":1,\"847\":1,\"882\":1,\"895\":1,\"954\":1,\"996\":1,\"1232\":1,\"1238\":1,\"1246\":1,\"1284\":1,\"1423\":1,\"1450\":1,\"1454\":1,\"1467\":1,\"1504\":1,\"1544\":1,\"1552\":1,\"1598\":1,\"1611\":1,\"1649\":1,\"1728\":1,\"1746\":1,\"1937\":1,\"1962\":1,\"2124\":1,\"2378\":1,\"2444\":1,\"2493\":1,\"2511\":1,\"2558\":1,\"2566\":1,\"2617\":1},\"1\":{\"59\":1,\"67\":1,\"918\":1,\"930\":1,\"968\":1,\"1009\":1,\"1049\":1,\"1093\":1,\"1142\":1,\"1193\":1,\"1243\":1,\"1293\":1,\"1340\":1,\"1385\":1,\"1702\":1,\"1760\":1,\"1820\":1,\"2566\":1,\"2574\":1,\"2582\":1},\"2\":{\"18\":10,\"20\":1,\"39\":1,\"47\":3,\"49\":1,\"57\":1,\"76\":4,\"90\":2,\"135\":1,\"164\":3,\"172\":2,\"184\":3,\"189\":2,\"190\":2,\"194\":5,\"199\":1,\"213\":8,\"215\":4,\"218\":1,\"221\":3,\"247\":1,\"252\":1,\"263\":4,\"266\":1,\"268\":1,\"276\":3,\"285\":1,\"290\":1,\"324\":5,\"332\":1,\"346\":3,\"364\":5,\"391\":3,\"407\":1,\"503\":2,\"515\":1,\"558\":3,\"567\":1,\"590\":2,\"618\":3,\"619\":8,\"640\":13,\"647\":6,\"656\":5,\"762\":8,\"766\":8,\"769\":3,\"773\":2,\"775\":2,\"783\":1,\"820\":3,\"840\":1,\"843\":4,\"909\":1,\"917\":2,\"925\":1,\"996\":1,\"1025\":6,\"1028\":1,\"1076\":2,\"1093\":2,\"1127\":1,\"1142\":2,\"1178\":2,\"1208\":1,\"1246\":8,\"1296\":4,\"1297\":3,\"1323\":1,\"1324\":1,\"1344\":1,\"1364\":1,\"1375\":1,\"1395\":1,\"1420\":1,\"1435\":1,\"1437\":4,\"1458\":1,\"1536\":7,\"1569\":1,\"1622\":5,\"1628\":1,\"1644\":4,\"1683\":2,\"1703\":3,\"1712\":1,\"1731\":2,\"1756\":12,\"1782\":6,\"1816\":2,\"1817\":1,\"1830\":3,\"1868\":1,\"1883\":2,\"1889\":5,\"1891\":1,\"1901\":6,\"1928\":3,\"1942\":1,\"1993\":1,\"2012\":1,\"2023\":1,\"2030\":21,\"2033\":2,\"2044\":2,\"2046\":1,\"2080\":1,\"2097\":2,\"2108\":1,\"2130\":6,\"2140\":1,\"2176\":15,\"2192\":1,\"2223\":1,\"2233\":4,\"2253\":1,\"2308\":8,\"2322\":3,\"2347\":2,\"2369\":1,\"2400\":1,\"2406\":2,\"2417\":3,\"2433\":1,\"2446\":2,\"2485\":1,\"2492\":4,\"2500\":1,\"2528\":6,\"2531\":4,\"2537\":5,\"2539\":9,\"2542\":4,\"2597\":2,\"2602\":6,\"2609\":2,\"2618\":1,\"2643\":1,\"2653\":1}}],[\"4个设备\",{\"2\":{\"2697\":1}}],[\"4h4h4h\",{\"2\":{\"2579\":2}}],[\"4φ\",{\"2\":{\"2621\":1}}],[\"4φ4\",{\"2\":{\"2276\":1,\"2621\":2}}],[\"4φ+4φ+4φ\",{\"2\":{\"2161\":2}}],[\"4+4+4\",{\"2\":{\"2192\":2}}],[\"46\",{\"2\":{\"2090\":1}}],[\"4章中有所涵盖\",{\"2\":{\"1956\":1}}],[\"48gb\",{\"2\":{\"1735\":1,\"2065\":1}}],[\"4500\",{\"2\":{\"1324\":1}}],[\"42\",{\"2\":{\"1324\":1}}],[\"4周\",{\"2\":{\"1324\":1}}],[\"4×1022flops\",{\"2\":{\"1232\":1}}],[\"4×1022flops总预算\",{\"2\":{\"1232\":1}}],[\"4t\",{\"2\":{\"1211\":1}}],[\"41\",{\"2\":{\"917\":1}}],[\"4d并行技术在llama3中的应用\",{\"0\":{\"2711\":1}}],[\"4d\",{\"2\":{\"917\":1,\"2167\":1}}],[\"4k\",{\"2\":{\"847\":1,\"1069\":1,\"1398\":1}}],[\"4位整数\",{\"2\":{\"768\":1}}],[\"4️⃣\",{\"0\":{\"531\":1}}],[\"4o\",{\"2\":{\"479\":1,\"2603\":1,\"2617\":1}}],[\"4等大模型进行解析\",{\"2\":{\"465\":1}}],[\"4倍输入维度\",{\"2\":{\"220\":1}}],[\"4列表示头部数量\",{\"2\":{\"156\":1}}],[\"44\",{\"2\":{\"56\":1}}],[\"49\",{\"2\":{\"56\":1}}],[\"40m\",{\"2\":{\"1419\":1}}],[\"40m到16b参数\",{\"2\":{\"1329\":1}}],[\"40gb\",{\"2\":{\"2077\":1}}],[\"40g\",{\"2\":{\"1395\":1,\"1416\":1}}],[\"400\",{\"2\":{\"1201\":1,\"1393\":1}}],[\"4090\",{\"2\":{\"2145\":1}}],[\"4090上\",{\"2\":{\"483\":1}}],[\"4096\",{\"2\":{\"220\":1,\"266\":2,\"2692\":1}}],[\"40\",{\"2\":{\"40\":1,\"56\":1,\"471\":1,\"917\":1,\"1178\":1,\"1211\":1,\"1949\":3}}],[\"4\",{\"0\":{\"9\":1,\"164\":1,\"186\":1,\"243\":1,\"287\":1,\"471\":1,\"567\":1,\"760\":1,\"1382\":1,\"1388\":1,\"1588\":1,\"1701\":1,\"1775\":1,\"1889\":1,\"1894\":1,\"1904\":1,\"2089\":1,\"2091\":1,\"2250\":1,\"2455\":1,\"2529\":1},\"1\":{\"13\":1,\"18\":1,\"207\":1,\"230\":1,\"1949\":1,\"2000\":1,\"2051\":1},\"2\":{\"11\":1,\"18\":1,\"246\":1,\"474\":4,\"568\":1,\"647\":2,\"656\":3,\"705\":1,\"768\":1,\"837\":1,\"909\":1,\"1008\":1,\"1119\":4,\"1138\":1,\"1186\":1,\"1232\":1,\"1290\":1,\"1324\":1,\"1409\":2,\"1458\":1,\"1793\":1,\"2130\":6,\"2161\":4,\"2192\":4,\"2210\":1,\"2338\":1,\"2539\":4,\"2653\":1,\"2697\":1,\"2699\":1}}],[\"关联强度\",{\"2\":{\"499\":1}}],[\"关注梯度回传\",{\"2\":{\"2585\":1}}],[\"关注deepspeed在处理大规模模型训练中的新特性\",{\"2\":{\"2432\":1}}],[\"关注c4语料库的更新和扩展\",{\"2\":{\"1257\":1}}],[\"关注其他数值格式\",{\"2\":{\"734\":1}}],[\"关注最新硬件\",{\"2\":{\"698\":1}}],[\"关注图像\",{\"2\":{\"669\":1}}],[\"关注\",{\"2\":{\"548\":1}}],[\"关注transformer模型在更大规模数据集上的性能优化\",{\"2\":{\"350\":1}}],[\"关注llm在不同领域的应用案例\",{\"2\":{\"153\":1}}],[\"关注算法和数据结构的通用性\",{\"2\":{\"15\":1}}],[\"关键段落\",{\"0\":{\"2020\":1},\"1\":{\"2070\":1,\"2122\":1,\"2169\":1,\"2211\":1}}],[\"关键技术改进\",{\"0\":{\"1884\":1}}],[\"关键操作\",{\"0\":{\"1830\":1}}],[\"关键组成部分是门控机制\",{\"2\":{\"1704\":1}}],[\"关键流程与技术\",{\"0\":{\"1579\":1},\"1\":{\"1631\":1,\"1685\":1}}],[\"关键在于如何通过某条神经元的线索\",{\"2\":{\"1420\":1}}],[\"关键注意事项\",{\"2\":{\"1227\":1}}],[\"关键步骤\",{\"0\":{\"649\":1,\"1502\":1,\"1721\":1,\"2206\":1}}],[\"关键点\",{\"0\":{\"936\":1},\"1\":{\"978\":1,\"1019\":1,\"1062\":1},\"2\":{\"501\":1,\"1297\":1}}],[\"关键词筛选\",{\"2\":{\"532\":1}}],[\"关键词爬取\",{\"2\":{\"384\":1}}],[\"关键词匹配技术\",{\"2\":{\"207\":1}}],[\"关键瓶颈\",{\"0\":{\"376\":1}}],[\"关键内容解析\",{\"0\":{\"158\":1,\"179\":1,\"195\":1},\"1\":{\"178\":1,\"199\":1,\"200\":1,\"216\":1,\"220\":1,\"221\":1,\"239\":1,\"243\":1,\"244\":1,\"263\":1,\"267\":1,\"287\":1,\"290\":1,\"312\":1,\"335\":1}}],[\"关键概念\",{\"2\":{\"12\":1,\"15\":1}}],[\"关键字来避免每次写完整命名空间\",{\"2\":{\"10\":1}}],[\"关键字允许你在特定的范围内直接使用某个命名空间中的成员\",{\"2\":{\"10\":1}}],[\"关键字\",{\"2\":{\"10\":1}}],[\"关键字和名称空间\",{\"2\":{\"7\":1}}],[\"关于rag的详细综述可以参考以下文献\",{\"2\":{\"2395\":1}}],[\"关于这方面的详细信息\",{\"2\":{\"2218\":1,\"2253\":1}}],[\"关于混合精度训练的详细信息\",{\"2\":{\"2059\":1}}],[\"关于事实和概括的记忆\",{\"2\":{\"2049\":1}}],[\"关于事件和经历的记忆\",{\"2\":{\"2049\":1}}],[\"关于\",{\"2\":{\"1344\":1,\"2379\":1}}],[\"关于位置内插法及其在语言模型中的应用分析\",{\"2\":{\"413\":1}}],[\"关于逻辑回归的思考\",{\"0\":{\"36\":1},\"1\":{\"42\":1,\"51\":1,\"58\":1,\"66\":1,\"76\":1,\"90\":1,\"105\":1,\"123\":1,\"143\":1,\"164\":1,\"185\":1}}],[\"关于逻辑回归中的代价函数\",{\"0\":{\"33\":1}}],[\"关于过程编程\",{\"0\":{\"8\":1},\"1\":{\"12\":1}}],[\"关于大语言模型学习导航\",{\"0\":{\"5\":1}}],[\"中各做一次\",{\"2\":{\"2641\":1}}],[\"中大于等于0\",{\"2\":{\"2589\":1}}],[\"中重新生成句子\",{\"2\":{\"2578\":1}}],[\"中效果并不理想\",{\"2\":{\"2546\":1}}],[\"中存储着某\",{\"2\":{\"2286\":3}}],[\"中存在一些离群值\",{\"2\":{\"1982\":1}}],[\"中英文多轮对话\",{\"2\":{\"2223\":1}}],[\"中定义的分割符顺序\",{\"2\":{\"2141\":1}}],[\"中详细描述了解题步骤\",{\"2\":{\"1940\":1}}],[\"中被提出\",{\"2\":{\"1633\":1}}],[\"中期稳定阶段\",{\"2\":{\"1436\":1}}],[\"中等数据\",{\"2\":{\"1419\":1}}],[\"中等模型\",{\"2\":{\"1419\":1}}],[\"中间动作处的奖励视为0\",{\"2\":{\"2462\":1,\"2481\":1}}],[\"中间激活\",{\"2\":{\"2447\":1}}],[\"中间层的块大小为$$512$$\",{\"2\":{\"2271\":1}}],[\"中间层创建了一些\",{\"2\":{\"2234\":1}}],[\"中间层维度缩减是否会影响模型的泛化能力\",{\"2\":{\"289\":1}}],[\"中间层维度\",{\"2\":{\"220\":2}}],[\"中间过程计算得到的k\",{\"2\":{\"1782\":2}}],[\"中间推理步骤\",{\"2\":{\"1766\":1}}],[\"中间推理步骤蒸馏\",{\"0\":{\"1224\":1}}],[\"中移除优先级较低的权重\",{\"2\":{\"1050\":1}}],[\"中未正确处理溢出情况\",{\"2\":{\"657\":1}}],[\"中国的首都是\",{\"2\":{\"626\":1}}],[\"中应用强化学习\",{\"2\":{\"514\":1}}],[\"中文nlp任务\",{\"2\":{\"2223\":1}}],[\"中文nlp\",{\"2\":{\"2088\":1}}],[\"中文支持现状\",{\"0\":{\"1719\":1}}],[\"中文预训练的独特挑战\",{\"0\":{\"1349\":1},\"1\":{\"1394\":1}}],[\"中文预训练\",{\"2\":{\"1103\":1}}],[\"中文语料采样\",{\"0\":{\"837\":1}}],[\"中文语料与长文本语料相结合\",{\"2\":{\"534\":1}}],[\"中文数据占比需超过50\",{\"2\":{\"474\":1}}],[\"中文\",{\"2\":{\"474\":2,\"803\":1}}],[\"中文模型建议中文占比超过50\",{\"2\":{\"422\":1}}],[\"中引入rope或alibi\",{\"2\":{\"414\":1}}],[\"中需要保留句子内的分布信息\",{\"2\":{\"205\":1}}],[\"中的技术范式\",{\"2\":{\"2469\":1}}],[\"中的图是一个有向无环图\",{\"2\":{\"2188\":1}}],[\"中的每个token视为一个动作\",{\"2\":{\"1848\":1}}],[\"中的位置编码方法\",{\"2\":{\"1606\":1}}],[\"中的kl约束来优化策略\",{\"2\":{\"1596\":1}}],[\"中的一些缺点\",{\"2\":{\"1495\":1}}],[\"中的具体应用\",{\"2\":{\"1308\":1}}],[\"中的具体实现\",{\"2\":{\"93\":1}}],[\"中的表现\",{\"2\":{\"1261\":1}}],[\"中的应用\",{\"0\":{\"1776\":1},\"1\":{\"1837\":1}}],[\"中的应用效果\",{\"2\":{\"765\":1}}],[\"中的应用潜力\",{\"2\":{\"707\":1}}],[\"中的关键步骤\",{\"2\":{\"373\":1}}],[\"中的关键组件\",{\"2\":{\"162\":1}}],[\"中的收敛加速器\",{\"0\":{\"205\":1}}],[\"中的成员\",{\"2\":{\"10\":1}}],[\"中的\",{\"0\":{\"2492\":1},\"1\":{\"2505\":1,\"2517\":1,\"2528\":1,\"2539\":1,\"2549\":1},\"2\":{\"10\":1,\"121\":1,\"2492\":1}}],[\"中\",{\"2\":{\"7\":1,\"11\":1,\"138\":1,\"247\":1,\"319\":1,\"469\":1,\"670\":1,\"996\":1,\"1125\":1,\"1164\":1,\"1367\":1,\"1587\":1,\"1695\":1,\"2042\":1,\"2089\":1,\"2144\":1,\"2289\":1,\"2374\":1,\"2546\":1}}],[\"在稳定的时候也是1f1b的形式\",{\"2\":{\"2697\":1}}],[\"在步骤中间的稳定阶段形成1前向1反向\",{\"2\":{\"2694\":1}}],[\"在qwen2\",{\"2\":{\"2692\":1}}],[\"在最后一个设备上计算出梯度并更新对应层的参数\",{\"2\":{\"2691\":1}}],[\"在最小化通信量时\",{\"2\":{\"2422\":1}}],[\"在不考虑已有知识的情况下\",{\"2\":{\"2690\":1}}],[\"在不同应用场景下\",{\"2\":{\"2476\":1}}],[\"在不同领域模型微调时\",{\"2\":{\"2350\":1}}],[\"在不同领域中\",{\"2\":{\"740\":1}}],[\"在不同nlp任务中\",{\"2\":{\"1897\":1}}],[\"在不同场景下\",{\"2\":{\"1819\":1}}],[\"在不同上下文中\",{\"2\":{\"1600\":1}}],[\"在不同预算下\",{\"2\":{\"1329\":1}}],[\"在不同的应用场景中\",{\"2\":{\"965\":1}}],[\"在不同任务中\",{\"2\":{\"356\":1}}],[\"在用梯度更新word\",{\"2\":{\"2656\":1}}],[\"在用户反馈方面经济高效\",{\"2\":{\"1687\":1}}],[\"在backward过程中\",{\"2\":{\"2656\":1}}],[\"在bwd过程中使用allreduce更新梯度\",{\"2\":{\"1502\":1}}],[\"在bwd过程中\",{\"2\":{\"1456\":1}}],[\"在算法第12行\",{\"2\":{\"2643\":1}}],[\"在算法第9行\",{\"2\":{\"2643\":1}}],[\"在所有指标上超越\",{\"2\":{\"2622\":1}}],[\"在所有评估指标上均超越了\",{\"2\":{\"2603\":1}}],[\"在mlp层中\",{\"2\":{\"2609\":1,\"2621\":1}}],[\"在mdp建模阶段\",{\"2\":{\"684\":1}}],[\"在蒸馏实验中\",{\"2\":{\"2603\":1}}],[\"在重要性采样中忽略clip操作可能导致梯度计算错误\",{\"2\":{\"2593\":1}}],[\"在arenahard上的平均长度为689个token\",{\"2\":{\"2588\":1}}],[\"在alpacaeval\",{\"2\":{\"2076\":1}}],[\"在利用上下文方面的效率会显著下降\",{\"2\":{\"2582\":1}}],[\"在利用外部存储器缓解关注范围有限的问题时\",{\"2\":{\"2102\":1}}],[\"在内层循环中\",{\"2\":{\"2573\":1}}],[\"在compute\",{\"2\":{\"2561\":1}}],[\"在开源社区中\",{\"2\":{\"2550\":1}}],[\"在分块计算的过程中\",{\"2\":{\"2505\":1}}],[\"在检索到的文档中\",{\"2\":{\"2493\":1}}],[\"在检索阶段\",{\"2\":{\"2465\":1}}],[\"在检索环节\",{\"2\":{\"1590\":1}}],[\"在噪音评估中\",{\"2\":{\"2458\":1}}],[\"在基于值的方法中\",{\"2\":{\"2455\":1}}],[\"在基于语义相似度的方法中\",{\"2\":{\"910\":1}}],[\"在向量数据库中\",{\"2\":{\"2669\":1}}],[\"在向量化过程中\",{\"2\":{\"2444\":1}}],[\"在向量空间中\",{\"2\":{\"1663\":1}}],[\"在专业数据集\",{\"2\":{\"2424\":1}}],[\"在专家并行处理时\",{\"2\":{\"1030\":1}}],[\"在合并样本时\",{\"2\":{\"2390\":1}}],[\"在正常情况下\",{\"2\":{\"2379\":1}}],[\"在结构和功能上更加灵活\",{\"2\":{\"2366\":1}}],[\"在结果奖励监督rl中\",{\"2\":{\"2306\":1}}],[\"在结果列表中\",{\"2\":{\"1644\":1}}],[\"在naive\",{\"2\":{\"2366\":1}}],[\"在nvidia\",{\"2\":{\"483\":1}}],[\"在必要时\",{\"2\":{\"2363\":1}}],[\"在后文对分块计算细节的讲解中\",{\"2\":{\"2349\":1}}],[\"在未来的发展中\",{\"2\":{\"2325\":1}}],[\"在目前主流的基于检索增强生成\",{\"2\":{\"2323\":1}}],[\"在当今大数据和深度学习的时代\",{\"2\":{\"2320\":1}}],[\"在指令嵌入上使用\",{\"2\":{\"2314\":1}}],[\"在指数项和kl散度项中需严格区分β\",{\"2\":{\"2098\":1}}],[\"在新版megatron\",{\"2\":{\"2300\":1}}],[\"在新样本推断时\",{\"2\":{\"1368\":1}}],[\"在启动训练时\",{\"2\":{\"2268\":1}}],[\"在研究这些开源数据集时\",{\"2\":{\"2258\":1}}],[\"在研究中\",{\"2\":{\"1491\":1}}],[\"在初始化价值模型时\",{\"2\":{\"2239\":1}}],[\"在初始化随机矩阵时\",{\"2\":{\"1975\":1}}],[\"在搜索过程中\",{\"2\":{\"2195\":1}}],[\"在某种程度上模拟了哈希函数的作用\",{\"2\":{\"2195\":1}}],[\"在某些复杂搜索任务中\",{\"2\":{\"2294\":1}}],[\"在某些场景下\",{\"2\":{\"1949\":1}}],[\"在某些场景下是否会有局限性\",{\"2\":{\"660\":1}}],[\"在某些情况下\",{\"2\":{\"949\":1}}],[\"在混合精度训练中\",{\"2\":{\"2192\":1}}],[\"在编程产品开发中\",{\"2\":{\"2185\":1}}],[\"在编程领域中\",{\"2\":{\"2139\":1}}],[\"在编码任务中\",{\"2\":{\"1181\":1}}],[\"在前向传播时\",{\"2\":{\"2691\":1}}],[\"在前向和后向传递的时候做一次all\",{\"2\":{\"2609\":1}}],[\"在前向过程同时计算\",{\"2\":{\"2115\":1}}],[\"在前面提到的5\",{\"2\":{\"1375\":1}}],[\"在前面讲gpt系列模型的时候\",{\"2\":{\"477\":1}}],[\"在减少模型数量时\",{\"2\":{\"2106\":1}}],[\"在flashattention中\",{\"2\":{\"2080\":1}}],[\"在fwd过程中使用all2all通讯发送token\",{\"2\":{\"1502\":1}}],[\"在fwd过程中\",{\"2\":{\"1456\":1}}],[\"在无需大幅修改代码的情况下完成并行化\",{\"2\":{\"2055\":1}}],[\"在移除kl散度约束时\",{\"2\":{\"2041\":1}}],[\"在移动设备或嵌入式系统上运行深度学习模型时\",{\"2\":{\"794\":1}}],[\"在高层目标规划上的推理能力\",{\"2\":{\"2011\":1}}],[\"在高价值任务中表现卓越\",{\"2\":{\"1429\":1}}],[\"在回答多方面或复杂问题时\",{\"2\":{\"2000\":1}}],[\"在激活值\",{\"2\":{\"1982\":1}}],[\"在没有安全强化学习的情况下\",{\"2\":{\"2580\":1}}],[\"在没有周围上下文的情况下\",{\"2\":{\"2364\":1}}],[\"在没有专家参与的情况下\",{\"2\":{\"1973\":1}}],[\"在没有外部知识的情况下生成一个假设性的回复\",{\"2\":{\"1717\":1}}],[\"在调整秩时\",{\"2\":{\"1988\":1}}],[\"在调整学习率时\",{\"2\":{\"1946\":1}}],[\"在调试过程中观察梯度变化是否出现梯度消失或爆炸\",{\"2\":{\"380\":1}}],[\"在有条件进行sft\",{\"2\":{\"1932\":1}}],[\"在句子前面添加前缀\",{\"2\":{\"1922\":1}}],[\"在句子结尾\",{\"2\":{\"1470\":1}}],[\"在reinforce中\",{\"2\":{\"2415\":1,\"2441\":1}}],[\"在reward\",{\"2\":{\"1741\":1}}],[\"在rolling\",{\"2\":{\"2356\":1}}],[\"在rag系统中\",{\"2\":{\"2198\":1}}],[\"在rloo中\",{\"2\":{\"1901\":1}}],[\"在具体的检索过程中\",{\"2\":{\"1894\":1}}],[\"在具体应用中的潜力\",{\"2\":{\"807\":1}}],[\"在人脑中\",{\"2\":{\"1892\":1}}],[\"在人工智能领域\",{\"2\":{\"1139\":1,\"2269\":1}}],[\"在人工智能\",{\"2\":{\"1136\":1}}],[\"在gpu显存上预先为一条请求开辟一块连续的矩形存储空间\",{\"2\":{\"1978\":1}}],[\"在gpt\",{\"2\":{\"1278\":1}}],[\"在grpo算法中\",{\"2\":{\"1884\":1}}],[\"在xloralinearlayer类中\",{\"2\":{\"1871\":1}}],[\"在介绍标准attention之前\",{\"2\":{\"1868\":1}}],[\"在已有模型上进行小幅度的训练\",{\"2\":{\"1866\":1}}],[\"在奖励计算时\",{\"2\":{\"1802\":1}}],[\"在单步mdp中\",{\"2\":{\"1787\":1,\"1958\":1}}],[\"在离线方法中\",{\"2\":{\"1778\":1}}],[\"在上下文学习中\",{\"2\":{\"1772\":1}}],[\"在召回粒度\",{\"2\":{\"1763\":1}}],[\"在设备数量不变的情况下\",{\"2\":{\"2697\":1}}],[\"在设备数量不变的前提下\",{\"2\":{\"2688\":1}}],[\"在设计评估指标时\",{\"2\":{\"2301\":1}}],[\"在设计奖励机制时\",{\"2\":{\"2009\":1}}],[\"在设计奖励函数时\",{\"2\":{\"1743\":1}}],[\"在设置过长回答阈值时\",{\"2\":{\"2698\":1}}],[\"在设置\",{\"2\":{\"2000\":1}}],[\"在设定kl\",{\"2\":{\"1174\":1}}],[\"在默认实验设置中\",{\"2\":{\"1740\":1}}],[\"在损失计算中掩盖沙盒环境的输出\",{\"2\":{\"1740\":1}}],[\"在损失最小\",{\"2\":{\"1201\":1}}],[\"在每块gpu上\",{\"2\":{\"2673\":1}}],[\"在每个内循环中\",{\"2\":{\"2653\":1}}],[\"在每个外循环中\",{\"2\":{\"2653\":1}}],[\"在每个训练步骤开始前\",{\"2\":{\"2519\":1}}],[\"在每个网络层添加适配器以优化内存使用\",{\"2\":{\"1855\":1}}],[\"在每一次迭代\",{\"2\":{\"2374\":1}}],[\"在每一层加入\",{\"2\":{\"1856\":1}}],[\"在每一层加入提示令可学习参数增加\",{\"2\":{\"1736\":1}}],[\"在每层都加上prompt的参数以提高性能\",{\"2\":{\"2074\":1}}],[\"在每次采样后\",{\"2\":{\"747\":1}}],[\"在dpo中\",{\"2\":{\"1727\":1}}],[\"在deepseek\",{\"2\":{\"1146\":1}}],[\"在loralayer类中\",{\"2\":{\"2425\":1}}],[\"在lora微调过程中\",{\"2\":{\"2311\":1}}],[\"在langchain中\",{\"2\":{\"1716\":1}}],[\"在llm中常用的优化器是adam\",{\"2\":{\"2192\":1}}],[\"在llm中\",{\"2\":{\"1954\":1}}],[\"在llm\",{\"2\":{\"1910\":1}}],[\"在llm训练完成后对其参数进行量化\",{\"2\":{\"1874\":1}}],[\"在llm内部整合了推理\",{\"2\":{\"1608\":1}}],[\"在llama3的技术报告中\",{\"2\":{\"2711\":1}}],[\"在llama\",{\"2\":{\"750\":1}}],[\"在任务中不断迭代优化\",{\"2\":{\"2113\":1}}],[\"在任务执行中不断学习和优化自身行为\",{\"2\":{\"1904\":1}}],[\"在任务执行过程中\",{\"2\":{\"1454\":1,\"1594\":1}}],[\"在任意中间步骤\",{\"2\":{\"1702\":1}}],[\"在参数高效微调\",{\"2\":{\"1695\":1}}],[\"在参数量极大的模型中\",{\"2\":{\"495\":1}}],[\"在系统中承担了多大程度的自主性和决策能力\",{\"2\":{\"1672\":1}}],[\"在行业特定术语和深度知识方面\",{\"2\":{\"1664\":1}}],[\"在切分文本时\",{\"2\":{\"1652\":1}}],[\"在收集人类偏好标签时\",{\"2\":{\"1639\":1}}],[\"在收敛速度和稳定性上有何不同\",{\"2\":{\"754\":1}}],[\"在问答场景下\",{\"2\":{\"1598\":1}}],[\"在相邻文本块之间引入一定的重叠部分\",{\"2\":{\"1598\":1}}],[\"在相同大小下\",{\"2\":{\"479\":1}}],[\"在代码实现中\",{\"2\":{\"1591\":1,\"1699\":1}}],[\"在中文预训练中\",{\"2\":{\"1580\":1}}],[\"在中小规模数据集上测试swiglu和geglu\",{\"2\":{\"334\":1}}],[\"在位置敏感哈希算法中\",{\"2\":{\"1559\":1}}],[\"在位置编码上提出了创新方法\",{\"2\":{\"1088\":1}}],[\"在现实世界中的任务中\",{\"2\":{\"1557\":1}}],[\"在现代深度学习中\",{\"2\":{\"2609\":1}}],[\"在现代深度学习模型中\",{\"2\":{\"2547\":1}}],[\"在现代的深度学习训练中\",{\"2\":{\"2344\":1}}],[\"在现代人工智能任务中\",{\"2\":{\"2089\":1}}],[\"在现代gpu中\",{\"2\":{\"1869\":1}}],[\"在现代计算中\",{\"2\":{\"1807\":1,\"2175\":1}}],[\"在现代信息检索系统中\",{\"2\":{\"1235\":1}}],[\"在现代自然语言处理任务中\",{\"2\":{\"875\":1}}],[\"在现代大规模语言模型\",{\"2\":{\"138\":1}}],[\"在现代开发中\",{\"2\":{\"137\":1}}],[\"在显存不足时强行引入复杂并行技术\",{\"2\":{\"1482\":1}}],[\"在整合prompt的时候\",{\"2\":{\"1413\":1}}],[\"在推荐系统中\",{\"2\":{\"1377\":1}}],[\"在推理过程中只选择最相关的两个专家进行计算\",{\"2\":{\"1031\":1}}],[\"在推理过程中应用\",{\"2\":{\"1022\":1}}],[\"在推理前就计算好激活的量化系数\",{\"2\":{\"1022\":1}}],[\"在推理时也可以使用高效的\",{\"2\":{\"768\":1}}],[\"在推理阶段\",{\"2\":{\"353\":1}}],[\"在推理或训练阶段直接使用优化后的嵌入\",{\"2\":{\"276\":1}}],[\"在查询阶段\",{\"2\":{\"1377\":1}}],[\"在知识库中\",{\"2\":{\"1376\":1}}],[\"在知识蒸馏领域\",{\"2\":{\"749\":1}}],[\"在论文里给出的结论是\",{\"2\":{\"2643\":1}}],[\"在论文\",{\"2\":{\"1367\":1}}],[\"在此基础上\",{\"2\":{\"1355\":1,\"2085\":1}}],[\"在低资源场景下\",{\"2\":{\"1593\":1}}],[\"在低资源语言或小规模数据集上\",{\"2\":{\"1481\":1}}],[\"在低资源语言场景下\",{\"2\":{\"1354\":1}}],[\"在低显存设备上部署未优化的mha模型\",{\"2\":{\"378\":1}}],[\"在灾难救援中\",{\"2\":{\"1338\":1}}],[\"在一般推理中\",{\"2\":{\"2642\":1}}],[\"在一定点之后\",{\"2\":{\"2402\":1}}],[\"在一定程度上扩充了特征空间\",{\"2\":{\"943\":1}}],[\"在一个多轮对话session里\",{\"2\":{\"2166\":1}}],[\"在一个列表中\",{\"2\":{\"2087\":1}}],[\"在一个机器人团队中\",{\"2\":{\"1338\":1}}],[\"在规划过程中\",{\"2\":{\"1330\":1}}],[\"在输入层中也会计算一次梯度\",{\"2\":{\"2656\":1}}],[\"在输入文本中添加特殊\",{\"2\":{\"2082\":1}}],[\"在输入文本中随机删除连续的tokens\",{\"2\":{\"1004\":1}}],[\"在输入数据前添加的一段可调整的虚拟数据\",{\"2\":{\"2024\":1}}],[\"在输入数据后接一层\",{\"2\":{\"1328\":1}}],[\"在完成文本向量化后\",{\"2\":{\"2666\":1}}],[\"在完成demonstrations的选择后\",{\"2\":{\"1322\":1}}],[\"在完成块内注意力后\",{\"2\":{\"116\":1}}],[\"在选择\",{\"2\":{\"2699\":1}}],[\"在选择需要微调的参数时\",{\"2\":{\"2086\":1}}],[\"在选择框架时\",{\"2\":{\"1392\":1}}],[\"在选择参数规模时\",{\"2\":{\"1301\":1}}],[\"在选择第二个expert时\",{\"2\":{\"1119\":1}}],[\"在元数据无法充分区分不同上下文类型的情况下\",{\"2\":{\"1285\":1}}],[\"在文本中恢复表格结构\",{\"2\":{\"1284\":1}}],[\"在文本中使用的特定符号\",{\"2\":{\"1249\":1}}],[\"在执行数据合成时\",{\"2\":{\"1280\":1}}],[\"在原输入的基础上\",{\"2\":{\"1273\":1}}],[\"在原有的语义相似度基础上\",{\"2\":{\"949\":1}}],[\"在数学任务aime2024上\",{\"2\":{\"2689\":1}}],[\"在数学和科学工程问题上的痛点进行了专门调整\",{\"2\":{\"1252\":1}}],[\"在数据合成过程中\",{\"2\":{\"2403\":1}}],[\"在数据质量过滤中\",{\"2\":{\"2345\":1}}],[\"在数据质量评估中的应用案例\",{\"2\":{\"851\":1}}],[\"在数据并行中\",{\"2\":{\"2178\":1}}],[\"在数据多样性探索中\",{\"2\":{\"2165\":1}}],[\"在数据混合过程中\",{\"2\":{\"1352\":1}}],[\"在数据清洗过程中\",{\"2\":{\"1234\":1}}],[\"在数据量有限的情况下\",{\"2\":{\"719\":1}}],[\"在数据量较小时使用耗资源的激活函数\",{\"2\":{\"354\":1}}],[\"在这个阶段\",{\"2\":{\"2694\":1}}],[\"在这个阶段中我们会把prompt过\",{\"2\":{\"1870\":1}}],[\"在这个阶段中\",{\"2\":{\"1870\":1,\"1927\":1}}],[\"在这个部分\",{\"2\":{\"1868\":1}}],[\"在这篇博客笔记中\",{\"2\":{\"2138\":1}}],[\"在这篇博客文章中\",{\"2\":{\"1750\":1}}],[\"在这篇博客中\",{\"2\":{\"1523\":1}}],[\"在这一工作流中\",{\"2\":{\"2224\":1}}],[\"在这一视角中\",{\"2\":{\"1673\":1}}],[\"在这一阶段\",{\"2\":{\"1235\":1,\"2171\":1,\"2272\":1,\"2666\":1}}],[\"在这里用于限制策略变化\",{\"2\":{\"1939\":1}}],[\"在这里\",{\"2\":{\"1309\":1}}],[\"在这种模式下\",{\"2\":{\"2704\":1}}],[\"在这种策略中\",{\"2\":{\"2560\":1}}],[\"在这种视角下\",{\"2\":{\"1673\":1}}],[\"在这种系统中\",{\"2\":{\"1569\":1}}],[\"在这种方法中\",{\"2\":{\"1035\":1,\"1075\":1}}],[\"在这种情况下\",{\"2\":{\"677\":1,\"2493\":1,\"2672\":1}}],[\"在提示中加入了中间推理步骤\",{\"2\":{\"1224\":1}}],[\"在验证集中的准确率\",{\"2\":{\"1222\":1}}],[\"在发生溢出时\",{\"2\":{\"1219\":1}}],[\"在标准transformer模型中\",{\"2\":{\"1215\":1}}],[\"在微调阶段\",{\"2\":{\"1923\":1}}],[\"在微调阶段测试模型性能\",{\"2\":{\"359\":1}}],[\"在微调过程中对大型语言模型\",{\"2\":{\"1494\":1}}],[\"在微调过程中\",{\"2\":{\"1293\":1,\"1804\":1,\"2164\":1}}],[\"在微调过程中也会引入量化的意识\",{\"2\":{\"1209\":1}}],[\"在进行gpu计算时\",{\"2\":{\"2175\":1}}],[\"在进行数据类型修改时\",{\"2\":{\"2172\":1}}],[\"在进行大模型训练时\",{\"2\":{\"2163\":1}}],[\"在进行前向传播\",{\"2\":{\"2059\":1}}],[\"在进行模型加载时\",{\"2\":{\"1192\":1}}],[\"在进行推理机制优化时\",{\"2\":{\"546\":1}}],[\"在应用lora处理时\",{\"2\":{\"1945\":1}}],[\"在应用自回归填空任务时\",{\"2\":{\"1189\":1}}],[\"在应用场景中\",{\"2\":{\"255\":1}}],[\"在zero\",{\"2\":{\"1154\":1}}],[\"在其他模型中的应用\",{\"2\":{\"1140\":1}}],[\"在特定任务上的表现\",{\"2\":{\"1578\":1}}],[\"在特定任务上微调\",{\"2\":{\"1578\":1}}],[\"在特定场景下的行为\",{\"2\":{\"1578\":1}}],[\"在特定场景下引入绝对位置编码以增强模型表现\",{\"2\":{\"1088\":1}}],[\"在特定领域\",{\"2\":{\"196\":1,\"1441\":1}}],[\"在以下几个方面对模型结构进行了优化\",{\"2\":{\"1069\":1}}],[\"在1\",{\"2\":{\"1041\":1}}],[\"在1000步后\",{\"2\":{\"245\":1}}],[\"在67b参数模型中使用以降低推理成本\",{\"2\":{\"1002\":1}}],[\"在动态环境中\",{\"2\":{\"994\":1}}],[\"在动态规划中\",{\"2\":{\"691\":1}}],[\"在sram中进行计算\",{\"2\":{\"2128\":1}}],[\"在sram中执行所有的计算操作\",{\"2\":{\"2080\":1}}],[\"在sft阶段注入过多知识可能导致对齐税问题\",{\"2\":{\"2290\":1}}],[\"在sft阶段进行过多的知识注入\",{\"2\":{\"1346\":1}}],[\"在sft\",{\"2\":{\"2177\":1,\"2180\":1,\"2278\":1}}],[\"在sft模型上添加value\",{\"2\":{\"1744\":1}}],[\"在sft基础上进一步帮助缓解响应拒绝\",{\"2\":{\"967\":1}}],[\"在softmax前添加线性偏置\",{\"2\":{\"315\":1}}],[\"在非动态环境中\",{\"2\":{\"966\":1}}],[\"在白盒知识蒸馏中\",{\"2\":{\"916\":1}}],[\"在预测答案一下\",{\"2\":{\"881\":1}}],[\"在预训练模型基础上进行小规模调整以适应特定任务\",{\"2\":{\"1722\":1}}],[\"在预训练模型开发过程中\",{\"2\":{\"425\":1}}],[\"在预训练阶段\",{\"2\":{\"847\":1}}],[\"在随机性策略中误解概率分布的意义\",{\"2\":{\"879\":1}}],[\"在什么情况下td方法优于其他无模型强化学习方法\",{\"2\":{\"850\":1}}],[\"在什么情况下可能不适用\",{\"2\":{\"299\":1}}],[\"在概率探针测试中\",{\"2\":{\"834\":1}}],[\"在许多情况下\",{\"2\":{\"825\":1}}],[\"在训练集上进行分类任务微调\",{\"2\":{\"2608\":1}}],[\"在训练大模型时\",{\"2\":{\"2132\":1}}],[\"在训练完成后\",{\"2\":{\"1974\":1}}],[\"在训练时使用prompt\",{\"2\":{\"1796\":1}}],[\"在训练奖励函数模型时\",{\"2\":{\"1696\":1}}],[\"在训练初期稳定训练动态\",{\"2\":{\"1162\":1}}],[\"在训练方式上无区别\",{\"2\":{\"1150\":1}}],[\"在训练过程中监控方差和偏差\",{\"2\":{\"2200\":1}}],[\"在训练过程中冻结主参数\",{\"2\":{\"2115\":1}}],[\"在训练过程中仅更新prefix部分参数\",{\"2\":{\"2074\":1}}],[\"在训练过程中被更新优化\",{\"2\":{\"1873\":1}}],[\"在训练过程中更新embedding层中virtual\",{\"2\":{\"1858\":1}}],[\"在训练过程中能适应低精度表示\",{\"2\":{\"1355\":1}}],[\"在训练过程中\",{\"2\":{\"997\":1,\"1160\":1,\"1236\":1,\"1796\":1,\"1851\":1,\"1853\":1,\"1865\":1,\"1877\":1,\"1962\":1,\"2059\":1,\"2243\":1}}],[\"在训练过程中动态评估权重的重要性\",{\"2\":{\"826\":1}}],[\"在训练深度学习模型时\",{\"2\":{\"799\":1}}],[\"在训练后期\",{\"2\":{\"589\":1}}],[\"在传统的数据并行中\",{\"2\":{\"2276\":1}}],[\"在传统的模型训练中\",{\"2\":{\"782\":1}}],[\"在传统环境中\",{\"2\":{\"1954\":1}}],[\"在传统attention公式中\",{\"2\":{\"1405\":1}}],[\"在传统注意力权重计算中\",{\"2\":{\"228\":1}}],[\"在强化学习过程中忽视语言一致性可能导致推理结果不准确或混乱\",{\"2\":{\"2538\":1}}],[\"在强化学习训练中引入语言一致性奖励与推理正确性奖励\",{\"2\":{\"2491\":1}}],[\"在强化学习\",{\"2\":{\"1460\":1}}],[\"在强化学习领域\",{\"2\":{\"1765\":1,\"1841\":1}}],[\"在强化学习领域的新进展\",{\"2\":{\"841\":1}}],[\"在强化学习领域中\",{\"2\":{\"585\":1}}],[\"在强化学习中\",{\"2\":{\"776\":1,\"911\":1,\"1522\":1,\"1533\":1,\"1656\":1,\"2081\":1,\"2306\":1}}],[\"在prefix层前面加了mlp结构\",{\"2\":{\"1974\":1}}],[\"在prompt长度相对较长的情况下\",{\"2\":{\"1910\":1}}],[\"在prm过程中\",{\"2\":{\"1905\":1}}],[\"在pagedattention中的不同序列通过将逻辑块映射到一样的物理块上可以实现共享块\",{\"2\":{\"750\":1}}],[\"在ppo的实现中\",{\"2\":{\"1899\":1}}],[\"在ppo训练过程中\",{\"2\":{\"1621\":1}}],[\"在ppo训练中加入per\",{\"2\":{\"1790\":1}}],[\"在ppo训练中\",{\"2\":{\"603\":1}}],[\"在ppo\",{\"2\":{\"1533\":1}}],[\"在ppo中加入sft损失以保留模型能力\",{\"2\":{\"637\":1}}],[\"在ppo模型训练中\",{\"2\":{\"505\":1}}],[\"在并行采样的时候\",{\"2\":{\"750\":1}}],[\"在使用这些模型时\",{\"2\":{\"2655\":1}}],[\"在使用传统sample\",{\"2\":{\"2619\":1,\"2668\":1}}],[\"在使用reinforce方法时\",{\"2\":{\"2480\":1,\"2496\":1}}],[\"在使用roberta时\",{\"2\":{\"1194\":1}}],[\"在使用多轮对话数据集时\",{\"2\":{\"2355\":1}}],[\"在使用多向量查询的情况下\",{\"2\":{\"2304\":1}}],[\"在使用deepspeed时\",{\"2\":{\"2287\":1}}],[\"在使用之前\",{\"2\":{\"2051\":1}}],[\"在使用预训练模型时\",{\"2\":{\"1463\":1}}],[\"在使用大语言模型\",{\"2\":{\"1321\":1}}],[\"在使用zero\",{\"2\":{\"1254\":1}}],[\"在使用t5进行任务转换时\",{\"2\":{\"1157\":1}}],[\"在使用td方法时\",{\"2\":{\"678\":1}}],[\"在使用\",{\"2\":{\"1091\":1,\"2133\":1}}],[\"在使用bert进行微调时\",{\"2\":{\"1080\":1}}],[\"在使用off\",{\"2\":{\"758\":1}}],[\"在使用ppo时\",{\"2\":{\"731\":1}}],[\"在过去的几年中\",{\"2\":{\"728\":1}}],[\"在icl中\",{\"2\":{\"708\":1,\"742\":1}}],[\"在小数据量或特定困难的数据上\",{\"2\":{\"2310\":1}}],[\"在小世界网络中\",{\"2\":{\"2234\":1}}],[\"在小规模实验中测试新的数据混合策略\",{\"2\":{\"1327\":1}}],[\"在小规模模型上实验以优化数据混合\",{\"2\":{\"1130\":1}}],[\"在小规模数据集上\",{\"2\":{\"702\":1}}],[\"在小模型上先进行多组数据配比实验\",{\"2\":{\"533\":1}}],[\"在计算强度和通信强度中间取一个平衡\",{\"2\":{\"2697\":1}}],[\"在计算归一化奖励时\",{\"2\":{\"2367\":1}}],[\"在计算模型显存时\",{\"2\":{\"2299\":1}}],[\"在计算基线值时\",{\"2\":{\"2056\":1}}],[\"在计算时通常会减去最大值\",{\"2\":{\"1925\":1}}],[\"在计算相似性分数时\",{\"2\":{\"1845\":1}}],[\"在计算该过程时\",{\"2\":{\"1782\":1}}],[\"在计算critic损失时\",{\"2\":{\"1757\":1}}],[\"在计算\",{\"2\":{\"1201\":1}}],[\"在计算转移概率时\",{\"2\":{\"866\":1}}],[\"在计算过程中\",{\"2\":{\"809\":1}}],[\"在计算kl散度时\",{\"2\":{\"671\":1}}],[\"在计算注意力权重时\",{\"2\":{\"184\":1}}],[\"在少样本学习\",{\"2\":{\"670\":1}}],[\"在更新网络参数时\",{\"2\":{\"777\":1}}],[\"在更新过程中\",{\"2\":{\"647\":1}}],[\"在更新权重前\",{\"2\":{\"553\":1}}],[\"在更新权重时\",{\"2\":{\"435\":1,\"523\":1}}],[\"在跨语种数据处理中\",{\"2\":{\"632\":1}}],[\"在硬件支持下\",{\"2\":{\"625\":1}}],[\"在与环境交互时\",{\"2\":{\"618\":1}}],[\"在困惑度下降趋于稳定后\",{\"2\":{\"616\":1}}],[\"在反向传播时重新计算\",{\"2\":{\"2252\":1}}],[\"在反向传播时副本之间交换梯度\",{\"2\":{\"2178\":1}}],[\"在反向传播时\",{\"2\":{\"553\":1,\"2691\":1}}],[\"在继续预训练中\",{\"2\":{\"772\":1}}],[\"在继续预训练\",{\"2\":{\"501\":1}}],[\"在获取到已过滤的url后\",{\"2\":{\"485\":1}}],[\"在深度学习的训练过程中\",{\"2\":{\"2339\":1}}],[\"在深度学习模型训练和推理过程中\",{\"2\":{\"2021\":1}}],[\"在深度学习模型训练中\",{\"2\":{\"464\":1}}],[\"在深度学习模型的训练过程中\",{\"2\":{\"2685\":1}}],[\"在深度学习模型的训练中\",{\"2\":{\"2575\":1,\"2644\":1}}],[\"在深度学习模型的训练和部署过程中\",{\"2\":{\"1308\":1}}],[\"在深度学习模型的预训练过程中\",{\"2\":{\"1197\":1}}],[\"在深度学习模型的预训练中\",{\"2\":{\"1132\":1}}],[\"在深度学习模型的部署中\",{\"2\":{\"1110\":1}}],[\"在深度学习领域\",{\"2\":{\"693\":1,\"860\":1,\"1753\":1}}],[\"在深度学习中\",{\"2\":{\"152\":1,\"203\":1,\"1972\":1,\"2151\":1,\"2539\":1}}],[\"在模型训练初期使用少量高质量数据稳定训练过程\",{\"2\":{\"2516\":1}}],[\"在模型训练中应用了\",{\"2\":{\"1152\":1}}],[\"在模型结构和训练数据上进行了多项优化\",{\"2\":{\"1026\":1}}],[\"在模型中加入了深度归一化层\",{\"2\":{\"961\":1}}],[\"在模型内部\",{\"2\":{\"917\":1}}],[\"在模型使用fp16格式时\",{\"2\":{\"429\":1}}],[\"在模型预训练阶段\",{\"2\":{\"369\":1}}],[\"在机器学习模型的训练过程中\",{\"2\":{\"2686\":1}}],[\"在机器学习模型的训练中\",{\"2\":{\"422\":1}}],[\"在机器学习领域\",{\"2\":{\"1517\":1}}],[\"在机器学习中\",{\"2\":{\"202\":1,\"1668\":1}}],[\"在扩展上下文窗口时\",{\"2\":{\"413\":1}}],[\"在长序列任务中训练一个完美的价值模型非常困难\",{\"2\":{\"2107\":1}}],[\"在长推理模型训练中\",{\"2\":{\"1884\":1}}],[\"在长文本处理任务中优化相对位置编码的计算效率\",{\"2\":{\"1427\":1}}],[\"在长文本生成任务中对比两种方法的表现\",{\"2\":{\"388\":1}}],[\"在长上下文语言模型的优化中\",{\"2\":{\"101\":1}}],[\"在语料中的出现频率\",{\"2\":{\"355\":1}}],[\"在需要深度理解的任务上表现更优\",{\"2\":{\"339\":1}}],[\"在需要中等程度优化但不希望损失太多性能时使用\",{\"2\":{\"191\":1}}],[\"在大规模模型优化中\",{\"2\":{\"2637\":1}}],[\"在大规模数据集上\",{\"2\":{\"2449\":1}}],[\"在大规模数据中\",{\"2\":{\"1163\":1}}],[\"在大多数基准测试中显著超越\",{\"2\":{\"2622\":2}}],[\"在大多数基准测试中也显著优于\",{\"2\":{\"2603\":1}}],[\"在大多数层移除偏置\",{\"2\":{\"1155\":1}}],[\"在大型模型的强化学习中有效\",{\"2\":{\"2054\":1}}],[\"在大语言模型\",{\"2\":{\"765\":1}}],[\"在大模型强化学习中\",{\"2\":{\"2415\":1,\"2441\":1}}],[\"在大模型\",{\"2\":{\"1617\":1}}],[\"在大模型的训练过程中\",{\"2\":{\"751\":1}}],[\"在大模型上的应用效果\",{\"2\":{\"667\":1}}],[\"在大模型中的应用潜力\",{\"2\":{\"311\":1}}],[\"在大数据集中找到对目标最重要的特征\",{\"2\":{\"39\":1}}],[\"在复杂语境下的应用潜力\",{\"2\":{\"2219\":1}}],[\"在复杂推理任务上的表现\",{\"2\":{\"1708\":1}}],[\"在复杂输入理解\",{\"2\":{\"1408\":1}}],[\"在复杂环境中\",{\"2\":{\"876\":1}}],[\"在复杂决策环境中有哪些优势\",{\"2\":{\"776\":1}}],[\"在复杂任务中表现更优\",{\"2\":{\"307\":1}}],[\"在复杂分类任务中表现可能不够优秀\",{\"2\":{\"261\":1}}],[\"在构建一个高效的rag系统时\",{\"2\":{\"2001\":1}}],[\"在构建rag\",{\"2\":{\"1609\":1}}],[\"在构建基于大型语言模型\",{\"2\":{\"2681\":1}}],[\"在构建基于\",{\"2\":{\"1185\":1}}],[\"在构建霍夫曼树时优先考虑类别分布\",{\"2\":{\"1159\":1}}],[\"在构建中文语言模型时\",{\"2\":{\"1153\":1}}],[\"在构建\",{\"2\":{\"275\":1,\"2303\":1,\"2419\":1}}],[\"在处理矩阵\",{\"2\":{\"2616\":1}}],[\"在处理大规模模型训练和推理时\",{\"2\":{\"2129\":1}}],[\"在处理浮点数时\",{\"2\":{\"1925\":1}}],[\"在处理长内容时\",{\"2\":{\"1513\":1}}],[\"在处理长序列时难以捕捉重要信息的问题\",{\"2\":{\"97\":1}}],[\"在处理文档内容时\",{\"2\":{\"1334\":1}}],[\"在处理多轮对话时\",{\"2\":{\"1047\":1}}],[\"在处理超大范围数字时\",{\"2\":{\"337\":1}}],[\"在处理非语言类序列数据时\",{\"2\":{\"260\":1}}],[\"在自然语言生成\",{\"2\":{\"2222\":1}}],[\"在自然语言处理和文本处理的过程中\",{\"2\":{\"2552\":1}}],[\"在自然语言处理中\",{\"2\":{\"1113\":1}}],[\"在自然语言处理\",{\"2\":{\"514\":1,\"804\":1,\"1515\":1,\"1618\":1}}],[\"在自然语言处理领域\",{\"2\":{\"253\":1,\"1990\":1}}],[\"在自我指令创建过程中\",{\"2\":{\"2127\":1}}],[\"在自回归生成中\",{\"2\":{\"107\":1}}],[\"在yarn中\",{\"2\":{\"252\":1}}],[\"在生成式语言模型中\",{\"2\":{\"249\":1}}],[\"在生成第一个token时\",{\"2\":{\"125\":1}}],[\"在实施qlora时\",{\"2\":{\"1911\":1}}],[\"在实施设备限制路由机制时\",{\"2\":{\"1171\":1}}],[\"在实践中可能出现选择和拒绝概率同时下降的情况\",{\"2\":{\"1850\":1}}],[\"在实践中\",{\"2\":{\"1763\":1}}],[\"在实验中\",{\"2\":{\"1076\":1,\"2277\":1}}],[\"在实现grpo时\",{\"2\":{\"2513\":1}}],[\"在实现lora微调时\",{\"2\":{\"2450\":1}}],[\"在实现滑动窗口注意力机制时\",{\"2\":{\"2438\":1}}],[\"在实现策略优化时\",{\"2\":{\"1791\":1}}],[\"在实现ppo算法时\",{\"2\":{\"1733\":1}}],[\"在实现tdpo时\",{\"2\":{\"1703\":1,\"1821\":1}}],[\"在实现\",{\"2\":{\"1399\":1}}],[\"在实现未绑定嵌入时\",{\"2\":{\"1351\":1}}],[\"在实现bart时\",{\"2\":{\"1051\":1}}],[\"在实现reinforce算法时\",{\"2\":{\"856\":1}}],[\"在实现rope时\",{\"2\":{\"338\":1}}],[\"在实现q\",{\"2\":{\"806\":1}}],[\"在实现sarsa算法时\",{\"2\":{\"720\":1}}],[\"在实现swiglu或geglu时未正确替换激活函数\",{\"2\":{\"243\":1}}],[\"在实现强化学习时\",{\"2\":{\"673\":1}}],[\"在实际场景中创造价值\",{\"2\":{\"2255\":1}}],[\"在实际操作中需要合理控制上下文长度\",{\"2\":{\"1504\":1}}],[\"在实际使用bbpe时\",{\"2\":{\"417\":1}}],[\"在实际应用中\",{\"2\":{\"217\":1,\"258\":1,\"453\":1,\"466\":1,\"647\":1,\"727\":1,\"728\":1,\"754\":1,\"764\":1,\"770\":1,\"1176\":1,\"1282\":1,\"1288\":1,\"1606\":1,\"1925\":1,\"2543\":1,\"2710\":1}}],[\"在实际项目中应用并调整模型参数以优化性能\",{\"2\":{\"133\":1}}],[\"在解码器中未正确应用masked\",{\"2\":{\"209\":1}}],[\"在通道维度\",{\"2\":{\"205\":1}}],[\"在样本批次维度\",{\"2\":{\"205\":1}}],[\"在transformer解码器中\",{\"2\":{\"188\":1}}],[\"在项目中实施并测试不同的模型架构\",{\"2\":{\"153\":1}}],[\"在线方法\",{\"2\":{\"1721\":1}}],[\"在线方法能够让模型实时适应变化的环境\",{\"2\":{\"1614\":1}}],[\"在线方法的核心是让模型自行生成输出\",{\"2\":{\"1614\":1}}],[\"在线\",{\"0\":{\"1614\":1},\"2\":{\"1564\":1}}],[\"在线与离线rlhf的核心思想\",{\"0\":{\"1564\":1},\"1\":{\"1614\":1,\"1667\":1}}],[\"在线与离线rlhf的比较与应用\",{\"0\":{\"1516\":1},\"1\":{\"1564\":1,\"1614\":1,\"1667\":1,\"1721\":1,\"1778\":1,\"1839\":1},\"2\":{\"151\":1}}],[\"在线学习\",{\"2\":{\"1516\":1}}],[\"在线训练阶段\",{\"2\":{\"1230\":1}}],[\"在线环境下需要动态更新模型\",{\"2\":{\"995\":1}}],[\"在线资源\",{\"2\":{\"454\":1}}],[\"在线课程\",{\"2\":{\"67\":1,\"106\":1,\"165\":1,\"230\":1,\"302\":1}}],[\"在半注意力头中\",{\"2\":{\"136\":1}}],[\"在递归生成过程中\",{\"2\":{\"125\":1}}],[\"在多步mdp中\",{\"2\":{\"1958\":1}}],[\"在多个步骤中动态调整任务流程\",{\"2\":{\"1786\":1}}],[\"在多轮对话中\",{\"2\":{\"1663\":1}}],[\"在多任务预训练中平衡文档级和句子级目标\",{\"2\":{\"1137\":1}}],[\"在多智能体环境中\",{\"2\":{\"913\":1}}],[\"在多语种模型中\",{\"2\":{\"635\":1}}],[\"在多语言数据集上训练\",{\"2\":{\"1083\":1}}],[\"在多语言模型中\",{\"2\":{\"631\":1,\"1971\":1}}],[\"在多语言环境下\",{\"2\":{\"490\":1}}],[\"在多语言任务中试验bbpe\",{\"2\":{\"442\":1}}],[\"在多语言任务中\",{\"2\":{\"318\":1}}],[\"在多语言处理和文本压缩等场景中表现出色\",{\"2\":{\"296\":1}}],[\"在多模态场景下\",{\"2\":{\"2443\":1}}],[\"在多模态学习中结合视觉特征的位置关系\",{\"2\":{\"1427\":1}}],[\"在多模态学习中具有更广泛的应用潜力\",{\"2\":{\"326\":1}}],[\"在多模态任务中\",{\"2\":{\"1447\":1}}],[\"在多模态任务\",{\"2\":{\"469\":1}}],[\"在多模态模型中\",{\"2\":{\"300\":1}}],[\"在多服务集成中\",{\"2\":{\"219\":1}}],[\"在多头注意力\",{\"2\":{\"121\":1}}],[\"在多维空间中\",{\"2\":{\"32\":1}}],[\"在头文件中或大型项目中\",{\"2\":{\"27\":1}}],[\"在学习\",{\"2\":{\"27\":1}}],[\"在\",{\"0\":{\"1188\":1,\"1776\":1},\"1\":{\"1238\":1,\"1289\":1,\"1336\":1,\"1382\":1,\"1429\":1,\"1837\":1},\"2\":{\"7\":1,\"11\":7,\"205\":1,\"811\":1,\"996\":1,\"1065\":1,\"1164\":1,\"1578\":1,\"1592\":1,\"1610\":1,\"1819\":3,\"1878\":1,\"2042\":1,\"2079\":1,\"2089\":1,\"2144\":1,\"2145\":1,\"2218\":1,\"2289\":1,\"2308\":1,\"2334\":1,\"2408\":2,\"2486\":1,\"2690\":1}}],[\"utils\",{\"2\":{\"2201\":1,\"2252\":2}}],[\"ut​\",{\"2\":{\"1364\":2}}],[\"ut\",{\"2\":{\"1364\":2}}],[\"utf\",{\"2\":{\"318\":1,\"391\":1}}],[\"usage\",{\"2\":{\"2347\":1}}],[\"use\",{\"0\":{\"1520\":1,\"2269\":1},\"1\":{\"1569\":1,\"1619\":1},\"2\":{\"1367\":1,\"1674\":1,\"1912\":1}}],[\"user\",{\"2\":{\"1329\":2,\"2117\":1}}],[\"using\",{\"0\":{\"22\":1,\"27\":1},\"2\":{\"7\":1,\"10\":3,\"11\":3,\"17\":1,\"22\":3,\"27\":8,\"2050\":3,\"2218\":1,\"2253\":1,\"2449\":1}}],[\"using和namespace|using和namespace\",{\"2\":{\"17\":1}}],[\"using和namespace\",{\"0\":{\"7\":1},\"1\":{\"10\":1}}],[\"ui​∣ui−k​\",{\"2\":{\"1093\":1}}],[\"ui−1​\",{\"2\":{\"1093\":1}}],[\"ui−1\",{\"2\":{\"1093\":1}}],[\"ui∣ui−k\",{\"2\":{\"1093\":1}}],[\"ultrachat\",{\"2\":{\"2223\":1}}],[\"ul2\",{\"2\":{\"1057\":1,\"1102\":2,\"1441\":1}}],[\"ulm输出多个分词结果是否会增加模型复杂度\",{\"2\":{\"564\":1}}],[\"ulm是否适用于多语言场景\",{\"2\":{\"563\":1}}],[\"ulm通过保留多个分词可能性\",{\"2\":{\"445\":1}}],[\"ulm通过以下步骤实现子词优化\",{\"2\":{\"393\":1}}],[\"ulm操作流程示例\",{\"0\":{\"444\":1}}],[\"ulm子词算法\",{\"2\":{\"426\":1}}],[\"ulm的优势与挑战\",{\"0\":{\"419\":1}}],[\"ulm的核心思路\",{\"0\":{\"393\":1}}],[\"ulm\",{\"0\":{\"298\":1},\"1\":{\"320\":1,\"343\":1,\"367\":1,\"393\":1,\"419\":1,\"444\":1,\"471\":1,\"498\":1,\"530\":1,\"563\":1},\"2\":{\"5\":2,\"343\":1,\"344\":1,\"373\":1,\"445\":1,\"563\":1}}],[\"url\",{\"0\":{\"456\":1},\"2\":{\"485\":3}}],[\"ug\",{\"2\":{\"444\":3}}],[\"u+2581\",{\"2\":{\"426\":1}}],[\"update\",{\"2\":{\"391\":1,\"619\":1,\"640\":4,\"646\":1,\"766\":1,\"820\":1,\"1883\":1,\"2400\":1}}],[\"u\",{\"2\":{\"363\":1,\"444\":2,\"480\":1,\"595\":1,\"783\":1,\"1093\":6,\"1359\":1,\"1364\":3}}],[\"uv\",{\"2\":{\"283\":2}}],[\"uk\",{\"2\":{\"283\":2}}],[\"udacity\",{\"2\":{\"165\":1}}],[\"unwrap\",{\"2\":{\"2201\":1,\"2500\":1}}],[\"unwrapped\",{\"2\":{\"2201\":3,\"2500\":2}}],[\"unless\",{\"2\":{\"2050\":1}}],[\"unstructured工具的fast模式会按照文字边界切分\",{\"2\":{\"2235\":1}}],[\"unstructured\",{\"2\":{\"2235\":1}}],[\"unsqueeze\",{\"2\":{\"1703\":2}}],[\"unsupervised\",{\"2\":{\"1395\":1,\"1665\":1}}],[\"until\",{\"2\":{\"1458\":2}}],[\"unknown\",{\"2\":{\"1458\":2}}],[\"union\",{\"2\":{\"2500\":2}}],[\"university\",{\"2\":{\"1658\":1}}],[\"unit之间去重\",{\"2\":{\"644\":1}}],[\"unit自身去重\",{\"2\":{\"644\":1}}],[\"unit\",{\"2\":{\"644\":1}}],[\"units\",{\"2\":{\"631\":1}}],[\"unicode正规化\",{\"2\":{\"480\":2}}],[\"unigram\",{\"2\":{\"368\":1}}],[\"unigram语言模型\",{\"2\":{\"320\":1,\"343\":1}}],[\"understanding\",{\"2\":{\"230\":1,\"1385\":1}}],[\"uncased\",{\"2\":{\"49\":1}}],[\"unordered\",{\"2\":{\"18\":3}}],[\"umap\",{\"2\":{\"39\":1}}],[\"3层放在device2\",{\"2\":{\"2697\":1}}],[\"3层放device1\",{\"2\":{\"2697\":1}}],[\"3进行初步训练\",{\"2\":{\"1631\":1}}],[\"3章节中的observation\",{\"2\":{\"1608\":1}}],[\"3不仅在模型结构上进行了创新\",{\"2\":{\"1462\":1}}],[\"3在实际应用中的性能表现\",{\"2\":{\"1370\":1}}],[\"3没有采用moe结构\",{\"2\":{\"1314\":1}}],[\"3最大模型参数为1750亿\",{\"2\":{\"1278\":1}}],[\"3的数据量远大于gpt\",{\"2\":{\"1278\":1}}],[\"3的模型结构\",{\"2\":{\"1028\":1}}],[\"3600\",{\"2\":{\"1232\":1}}],[\"3和微调后的模型llama\",{\"2\":{\"1216\":1}}],[\"3系列包括两个模型\",{\"2\":{\"1216\":1}}],[\"3系列模型是meta公司推出的最新人工智能模型\",{\"2\":{\"1028\":1}}],[\"356\",{\"2\":{\"1225\":1}}],[\"35\",{\"2\":{\"1211\":1}}],[\"3项\",{\"2\":{\"1187\":1}}],[\"3采用了精心设计的预训练语料库\",{\"2\":{\"1117\":1}}],[\"3采用了sparse\",{\"2\":{\"1082\":1}}],[\"3主推few\",{\"2\":{\"1082\":1,\"1228\":1}}],[\"3显著提升了处理复杂任务的能力\",{\"2\":{\"1071\":1}}],[\"3x6zz972bchmvqe\",{\"2\":{\"559\":1}}],[\"3xf8enb8dbj6uig\",{\"2\":{\"559\":1}}],[\"32b模型上进行的实验表明\",{\"2\":{\"2692\":1}}],[\"32b模型上进行了实验验证\",{\"2\":{\"2686\":1}}],[\"32b在所有基准测试中明显优于deepseek\",{\"2\":{\"2642\":1}}],[\"32b基础模型通过大规模强化学习训练后\",{\"2\":{\"2642\":1}}],[\"32bpreview\",{\"2\":{\"2603\":1,\"2622\":1}}],[\"32b和dapo\",{\"2\":{\"1955\":1}}],[\"32b\",{\"2\":{\"1917\":1,\"2338\":1,\"2603\":1,\"2622\":1,\"2642\":2}}],[\"3200\",{\"2\":{\"1324\":1}}],[\"32gb\",{\"2\":{\"1178\":1}}],[\"32k\",{\"2\":{\"889\":1,\"1398\":1}}],[\"32k语料只需用4k规模的打分器即可\",{\"2\":{\"507\":1}}],[\"32\",{\"2\":{\"729\":1,\"768\":1,\"873\":1}}],[\"32位浮点数\",{\"2\":{\"488\":1,\"768\":1}}],[\"3️⃣\",{\"0\":{\"499\":1}}],[\"300\",{\"2\":{\"1763\":1}}],[\"300b\",{\"2\":{\"1211\":1}}],[\"30k字符级别\",{\"2\":{\"1341\":1}}],[\"30\",{\"2\":{\"405\":1,\"1232\":1,\"1998\":1}}],[\"31\",{\"2\":{\"398\":1}}],[\"3⋅浏览时长−5\",{\"2\":{\"164\":1}}],[\"3⋅浏览时长−5z\",{\"2\":{\"164\":1}}],[\"3e\",{\"2\":{\"49\":1}}],[\"3d并行技术是混合数据并行\",{\"2\":{\"2710\":1}}],[\"3d并行技术的混合应用\",{\"0\":{\"2710\":1}}],[\"3d并行\",{\"0\":{\"2700\":1}}],[\"3d\",{\"2\":{\"39\":1,\"2081\":2,\"2129\":1}}],[\"3\",{\"0\":{\"6\":1,\"58\":1,\"124\":1,\"220\":1,\"263\":1,\"276\":1,\"315\":1,\"444\":1,\"534\":1,\"568\":1,\"576\":1,\"726\":1,\"860\":1,\"880\":1,\"896\":1,\"921\":1,\"945\":1,\"1035\":1,\"1079\":1,\"1329\":1,\"1336\":1,\"1343\":1,\"1376\":1,\"1512\":1,\"1540\":1,\"1545\":1,\"1600\":1,\"1610\":1,\"1648\":1,\"1718\":1,\"1769\":1,\"1847\":1,\"1866\":1,\"1985\":1,\"2039\":1,\"2062\":1,\"2213\":1,\"2430\":1,\"2483\":1,\"2518\":1,\"2533\":1,\"2582\":1},\"1\":{\"9\":1,\"13\":1,\"18\":1,\"66\":1,\"76\":1,\"90\":1,\"105\":1,\"123\":1,\"143\":1,\"144\":1,\"165\":1,\"931\":1,\"958\":1,\"969\":1,\"987\":1,\"999\":1,\"1010\":1,\"1028\":1,\"1039\":1,\"1050\":1,\"1071\":1,\"1082\":1,\"1094\":1,\"1117\":1,\"1128\":1,\"1143\":1,\"1167\":1,\"1179\":1,\"1216\":1,\"1228\":1,\"1267\":1,\"1278\":1,\"1314\":1,\"1325\":1,\"1360\":1,\"1370\":1,\"1406\":1,\"1416\":1,\"1462\":1,\"1663\":1,\"1717\":1,\"1774\":1,\"1830\":1,\"1835\":1,\"2037\":1},\"2\":{\"11\":1,\"12\":2,\"15\":2,\"18\":5,\"20\":1,\"40\":1,\"49\":2,\"135\":1,\"164\":1,\"172\":2,\"218\":1,\"220\":1,\"324\":3,\"443\":1,\"470\":2,\"497\":2,\"647\":2,\"728\":1,\"769\":1,\"873\":2,\"894\":1,\"999\":1,\"1102\":1,\"1142\":1,\"1216\":1,\"1324\":1,\"1360\":2,\"1406\":1,\"1416\":1,\"1458\":1,\"1756\":3,\"1795\":3,\"1956\":1,\"2059\":1,\"2130\":6,\"2233\":1,\"2281\":1,\"2313\":1,\"2322\":3,\"2434\":2,\"2539\":2}}],[\"fsdp\",{\"2\":{\"2118\":1}}],[\"func\",{\"2\":{\"2417\":1}}],[\"func来实现精确的损失计算\",{\"2\":{\"2300\":1}}],[\"functions\",{\"2\":{\"1902\":1}}],[\"functional\",{\"2\":{\"135\":1,\"2201\":1}}],[\"function\",{\"0\":{\"2039\":1,\"2384\":1,\"2518\":1},\"2\":{\"10\":7,\"1572\":1,\"1650\":1,\"1823\":1,\"2004\":1,\"2039\":1,\"2323\":1,\"2384\":1,\"2443\":1,\"2518\":1}}],[\"full\",{\"2\":{\"1458\":1,\"2500\":1}}],[\"fc2\",{\"2\":{\"766\":4,\"820\":2}}],[\"fc1\",{\"2\":{\"766\":4,\"820\":2}}],[\"ft\",{\"2\":{\"515\":2}}],[\"feedback\",{\"2\":{\"1564\":1,\"1634\":1,\"1902\":1,\"1971\":1,\"2202\":1}}],[\"feed\",{\"0\":{\"2579\":1},\"2\":{\"1069\":1,\"2218\":1,\"2579\":1}}],[\"feedforward\",{\"2\":{\"162\":1}}],[\"features=out\",{\"2\":{\"2400\":1}}],[\"features=in\",{\"2\":{\"2400\":1}}],[\"features\",{\"2\":{\"1831\":2,\"1883\":2,\"2400\":6,\"2425\":2}}],[\"feature\",{\"0\":{\"845\":1},\"2\":{\"780\":1,\"845\":1,\"880\":1}}],[\"few\",{\"0\":{\"1826\":1,\"1940\":1},\"1\":{\"1885\":1,\"1940\":1},\"2\":{\"670\":1,\"999\":1,\"1462\":1,\"1826\":1,\"1924\":1,\"1940\":1,\"2546\":1,\"2693\":1}}],[\"fetch\",{\"2\":{\"485\":1}}],[\"fwd与bwd过程\",{\"0\":{\"1456\":1},\"1\":{\"1502\":1}}],[\"fwd\",{\"2\":{\"435\":1}}],[\"fp8\",{\"0\":{\"1065\":1},\"2\":{\"1065\":1,\"2192\":3}}],[\"fp32的模型参数\",{\"2\":{\"2447\":1}}],[\"fp32=1024×1024×10244×params​\",{\"2\":{\"2192\":1}}],[\"fp32=4×params1024×1024×1024\",{\"2\":{\"2192\":1}}],[\"fp32\",{\"2\":{\"382\":1,\"408\":1,\"433\":1,\"435\":4,\"462\":1,\"488\":2,\"523\":1,\"553\":1,\"589\":1,\"591\":1,\"660\":1,\"730\":1,\"768\":10,\"2059\":2,\"2161\":4,\"2192\":1}}],[\"fp16的模型参数\",{\"2\":{\"2447\":1}}],[\"fp16\",{\"2\":{\"382\":1,\"405\":1,\"408\":1,\"433\":1,\"435\":4,\"462\":2,\"483\":1,\"488\":3,\"523\":2,\"553\":1,\"556\":1,\"657\":1,\"730\":1,\"768\":1,\"2059\":2,\"2145\":1,\"2161\":2,\"2192\":4,\"2266\":1,\"2486\":1}}],[\"float16\",{\"2\":{\"733\":3}}],[\"float32float32float32\",{\"2\":{\"1925\":1}}],[\"float32\",{\"2\":{\"733\":3}}],[\"float\",{\"2\":{\"619\":5,\"640\":5,\"766\":5,\"820\":2,\"1622\":1,\"1731\":2,\"1817\":1,\"1883\":2,\"2400\":1,\"2417\":3}}],[\"flops预算范围\",{\"2\":{\"1419\":1}}],[\"flops$$\",{\"2\":{\"1329\":1}}],[\"flops\",{\"0\":{\"1201\":1},\"2\":{\"376\":1,\"1201\":1,\"1232\":5,\"1329\":1,\"1419\":1,\"1926\":2,\"1957\":1,\"1963\":3,\"2043\":1,\"2263\":8}}],[\"flare\",{\"2\":{\"2570\":1,\"2578\":1}}],[\"flag\",{\"2\":{\"2050\":1}}],[\"flash\",{\"0\":{\"2286\":1},\"1\":{\"2318\":1,\"2349\":1,\"2379\":1,\"2406\":1,\"2431\":1,\"2456\":1,\"2475\":1},\"2\":{\"502\":1,\"1490\":1,\"2233\":1,\"2449\":1,\"2643\":1,\"2648\":2,\"2653\":1}}],[\"flashattention的创新在于它通过改变计算顺序和数据处理方式来优化资源使用\",{\"2\":{\"2240\":1}}],[\"flashattention的做法\",{\"0\":{\"1929\":1},\"1\":{\"1980\":1,\"2030\":1}}],[\"flashattention与原生注意力的结果完全等价\",{\"2\":{\"2057\":1}}],[\"flashattention引入了额外的统计量\",{\"2\":{\"1980\":1}}],[\"flashattention通过io感知减少hbm访问次数来加快计算速度\",{\"2\":{\"1957\":1}}],[\"flashattention通过引入额外的统计量\",{\"2\":{\"1750\":1}}],[\"flashattention在保持结果精确的同时减少了显存复杂度和计算时间\",{\"2\":{\"1846\":1}}],[\"flashattention提出了一种创新的注意力机制\",{\"2\":{\"1846\":1}}],[\"flashattention\",{\"0\":{\"1750\":1,\"2638\":1},\"1\":{\"1810\":1,\"1872\":1,\"1929\":1,\"1980\":1,\"2030\":1,\"2080\":1,\"2130\":1,\"2176\":1,\"2216\":1,\"2643\":1,\"2648\":1,\"2653\":1},\"2\":{\"193\":1,\"1785\":1,\"2275\":1}}],[\"flan\",{\"2\":{\"339\":1}}],[\"f\",{\"2\":{\"194\":2,\"215\":2,\"238\":3,\"247\":3,\"261\":3,\"285\":2,\"307\":2,\"619\":1,\"640\":1,\"656\":1,\"704\":3,\"766\":3,\"773\":12,\"820\":2,\"1025\":1,\"1208\":1,\"1225\":2,\"1279\":1,\"1344\":4,\"1582\":2,\"1671\":17,\"1731\":2,\"1831\":1,\"2030\":11,\"2108\":1,\"2176\":3,\"2201\":2,\"2618\":1}}],[\"five\",{\"2\":{\"2433\":1}}],[\"fitted\",{\"2\":{\"2430\":1,\"2455\":1}}],[\"fidelity\",{\"2\":{\"2050\":1}}],[\"first\",{\"2\":{\"1458\":1,\"1917\":1,\"2228\":1,\"2433\":1}}],[\"fire\",{\"2\":{\"1225\":1}}],[\"firefly等\",{\"2\":{\"2258\":1}}],[\"firefly项目指令数据集\",{\"2\":{\"2184\":1}}],[\"firefly\",{\"2\":{\"741\":1,\"2184\":1,\"2223\":1}}],[\"fif\",{\"2\":{\"1279\":1,\"1326\":1}}],[\"fields\",{\"2\":{\"515\":2}}],[\"findall\",{\"2\":{\"391\":1}}],[\"finetuning\",{\"2\":{\"2471\":1}}],[\"fine\",{\"0\":{\"1209\":1,\"1588\":1},\"2\":{\"101\":1,\"508\":1,\"1213\":1,\"1224\":2,\"1403\":1,\"1582\":1,\"1867\":2,\"1917\":1,\"2151\":1,\"2278\":1}}],[\"fill\",{\"2\":{\"189\":1,\"1883\":1,\"2539\":1,\"2589\":1}}],[\"fragmentation\",{\"2\":{\"2161\":1}}],[\"franckenau\",{\"2\":{\"1458\":3}}],[\"franck\",{\"2\":{\"1458\":3}}],[\"frac\",{\"2\":{\"18\":4,\"34\":1,\"90\":1,\"164\":1,\"184\":1,\"194\":1,\"215\":1,\"222\":1,\"228\":1,\"252\":1,\"268\":1,\"276\":1,\"290\":2,\"291\":1,\"346\":2,\"537\":1,\"558\":1,\"590\":2,\"614\":1,\"622\":2,\"623\":1,\"640\":1,\"778\":1,\"1127\":1,\"1229\":1,\"1344\":1,\"1437\":1,\"1455\":1,\"1535\":1,\"1536\":1,\"1582\":1,\"1594\":1,\"1622\":2,\"1628\":2,\"1634\":1,\"1644\":3,\"1657\":2,\"1671\":1,\"1683\":1,\"1685\":1,\"1712\":2,\"1732\":2,\"1756\":8,\"1795\":3,\"1830\":4,\"1889\":4,\"1901\":4,\"1925\":1,\"1942\":1,\"1963\":1,\"1993\":1,\"1994\":1,\"2012\":1,\"2014\":1,\"2030\":1,\"2033\":1,\"2044\":2,\"2046\":4,\"2080\":1,\"2097\":2,\"2137\":1,\"2183\":1,\"2192\":4,\"2228\":2,\"2306\":1,\"2308\":7,\"2322\":1,\"2485\":2,\"2531\":1,\"2542\":1,\"2566\":1,\"2618\":2,\"2653\":1,\"2673\":1}}],[\"frequently\",{\"2\":{\"1458\":1}}],[\"freqs\",{\"2\":{\"407\":3}}],[\"freq\",{\"2\":{\"391\":3,\"407\":2}}],[\"free方法可能会在更多领域得到应用\",{\"2\":{\"857\":1}}],[\"free方法在特定任务中的性能表现\",{\"2\":{\"821\":1}}],[\"free\",{\"0\":{\"2054\":1},\"2\":{\"240\":1,\"574\":1,\"688\":1}}],[\"from\",{\"2\":{\"115\":1,\"480\":2,\"508\":1,\"919\":1,\"1008\":1,\"1111\":1,\"1458\":1,\"1633\":1,\"1646\":1,\"1837\":1,\"1902\":1,\"1920\":1,\"1951\":1,\"2108\":1,\"2201\":2,\"2202\":1}}],[\"fan\",{\"2\":{\"1248\":1,\"1298\":1,\"2400\":2}}],[\"family\",{\"2\":{\"1008\":1}}],[\"falshattention\",{\"2\":{\"889\":1}}],[\"false\",{\"2\":{\"526\":2,\"1731\":1,\"1883\":1,\"2050\":1,\"2400\":3}}],[\"fast\",{\"0\":{\"1957\":1},\"2\":{\"490\":1,\"2275\":1}}],[\"fasttext是否仍能保持高效\",{\"2\":{\"1354\":1}}],[\"fasttext是一种高效的文本分类算法\",{\"2\":{\"867\":1}}],[\"fasttext通过分层softmax显著提高效率\",{\"2\":{\"1259\":1}}],[\"fasttext通过引入n\",{\"2\":{\"867\":1}}],[\"fasttext的输入不仅包括单词\",{\"2\":{\"938\":1}}],[\"fasttext模型包含三层\",{\"2\":{\"938\":1}}],[\"fasttext算法核心概述\",{\"0\":{\"867\":1}}],[\"fasttext\",{\"0\":{\"798\":1},\"1\":{\"832\":1,\"867\":1,\"903\":1,\"938\":1,\"980\":1,\"1021\":1,\"1064\":1,\"1109\":1,\"1159\":1,\"1208\":1,\"1259\":1,\"1307\":1,\"1354\":1},\"2\":{\"46\":1,\"55\":1,\"59\":1,\"144\":1,\"207\":1,\"832\":1,\"1208\":2}}],[\"fasttext|fasttext\",{\"2\":{\"5\":1}}],[\"fairseq\",{\"2\":{\"469\":1}}],[\"factor\",{\"2\":{\"1229\":4,\"1455\":3}}],[\"factory\",{\"0\":{\"917\":1}}],[\"factorization\",{\"0\":{\"682\":1},\"2\":{\"214\":1,\"763\":1}}],[\"face框架\",{\"2\":{\"240\":1}}],[\"face\",{\"2\":{\"65\":1,\"230\":1,\"375\":1,\"2351\":1,\"2381\":1,\"2663\":1}}],[\"fa\",{\"0\":{\"1565\":1},\"2\":{\"151\":1,\"1658\":1}}],[\"f1​=\",{\"2\":{\"2176\":1}}],[\"f1=\",{\"2\":{\"2176\":1}}],[\"f1f\",{\"2\":{\"1268\":1}}],[\"f1分数\",{\"2\":{\"91\":1,\"2354\":1}}],[\"f1\",{\"2\":{\"49\":1,\"2354\":1}}],[\"follow\",{\"2\":{\"1971\":1}}],[\"following\",{\"2\":{\"1124\":1,\"1275\":1}}],[\"found\",{\"2\":{\"1816\":1}}],[\"foundation\",{\"2\":{\"740\":1,\"1310\":1,\"1403\":1}}],[\"formulas\",{\"2\":{\"2050\":1}}],[\"formatting\",{\"2\":{\"2050\":1}}],[\"formatted\",{\"2\":{\"1458\":1}}],[\"format\",{\"2\":{\"1797\":1}}],[\"form\",{\"2\":{\"1458\":1}}],[\"forward和backward阶段各会产生一次allreduce\",{\"2\":{\"2621\":1}}],[\"forward都进行切分以并行化\",{\"2\":{\"2579\":1}}],[\"forward计算代码解析\",{\"0\":{\"2539\":1}}],[\"forward具体流程\",{\"0\":{\"2251\":1},\"1\":{\"2286\":1,\"2318\":1,\"2349\":1,\"2379\":1,\"2406\":1,\"2431\":1,\"2456\":1,\"2475\":1,\"2492\":1,\"2505\":1,\"2517\":1,\"2528\":1,\"2539\":1,\"2549\":1,\"2557\":1,\"2565\":1,\"2573\":1,\"2581\":1,\"2589\":1,\"2597\":1,\"2604\":1,\"2611\":1,\"2618\":1,\"2623\":1,\"2628\":1,\"2633\":1,\"2638\":1,\"2643\":1,\"2648\":1,\"2653\":1}}],[\"forward\",{\"0\":{\"2579\":1},\"2\":{\"266\":1,\"766\":2,\"820\":1,\"932\":1,\"1069\":1,\"1582\":1,\"1596\":1,\"1622\":1,\"1703\":2,\"1731\":1,\"1817\":1,\"1831\":1,\"1912\":1,\"2059\":1,\"2218\":1,\"2539\":1,\"2563\":1,\"2579\":1,\"2641\":1}}],[\"forword流程\",{\"0\":{\"1750\":1},\"1\":{\"1810\":1,\"1872\":1,\"1929\":1,\"1980\":1,\"2030\":1,\"2080\":1,\"2130\":1,\"2176\":1,\"2216\":1},\"2\":{\"193\":1}}],[\"for\",{\"2\":{\"47\":2,\"48\":1,\"218\":2,\"230\":1,\"302\":1,\"324\":2,\"391\":3,\"407\":1,\"544\":1,\"632\":1,\"647\":7,\"656\":10,\"762\":1,\"769\":1,\"775\":4,\"783\":2,\"820\":1,\"840\":2,\"843\":2,\"917\":2,\"1025\":2,\"1354\":1,\"1420\":2,\"1458\":7,\"1582\":1,\"1622\":1,\"1816\":2,\"1823\":1,\"1837\":1,\"1902\":1,\"1936\":2,\"1951\":1,\"1984\":2,\"2050\":2,\"2201\":3,\"2202\":2,\"2229\":1,\"2265\":1,\"2368\":1,\"2395\":1,\"2406\":2,\"2433\":3,\"2434\":1,\"2500\":3,\"2539\":2,\"2565\":1,\"2573\":1,\"2600\":1}}],[\"footers\",{\"2\":{\"2050\":1}}],[\"footnote\",{\"2\":{\"18\":7}}],[\"foo\",{\"0\":{\"25\":1},\"2\":{\"19\":1,\"23\":1}}],[\"ffn的作用\",{\"2\":{\"178\":1}}],[\"ffn结构与激活函数基础\",{\"0\":{\"178\":1}}],[\"ffn结构\",{\"2\":{\"119\":1}}],[\"ffn\",{\"0\":{\"73\":1,\"89\":1,\"162\":1},\"1\":{\"104\":1,\"121\":1,\"141\":1,\"162\":1,\"183\":1,\"205\":1,\"227\":1,\"251\":1,\"275\":1,\"299\":1},\"2\":{\"5\":7,\"34\":1,\"73\":1,\"121\":2,\"138\":1,\"162\":2,\"178\":1,\"251\":1,\"275\":1,\"299\":1,\"467\":1,\"495\":1,\"1069\":2,\"1264\":1,\"1364\":2}}],[\"wqw\",{\"2\":{\"2164\":1,\"2636\":1}}],[\"wk\",{\"2\":{\"1870\":1}}],[\"wkw\",{\"2\":{\"1246\":1,\"2636\":1}}],[\"wyw​\",{\"2\":{\"1582\":1}}],[\"w∼n\",{\"2\":{\"1437\":2}}],[\"ww≤s\",{\"2\":{\"1344\":1}}],[\"www\",{\"2\":{\"559\":1,\"981\":1,\"2641\":1}}],[\"w≤s\",{\"2\":{\"1344\":1}}],[\"wη\",{\"2\":{\"1344\":1}}],[\"wsd\",{\"0\":{\"1344\":1},\"2\":{\"1577\":1,\"1629\":1}}],[\"wsd调度器\",{\"2\":{\"1197\":1}}],[\"w2dmodel​−1​t\",{\"2\":{\"1246\":2}}],[\"w2dmodel−1t\",{\"2\":{\"1246\":2}}],[\"w1​t\",{\"2\":{\"1246\":2}}],[\"w1t\",{\"2\":{\"1246\":2}}],[\"w0xw\",{\"2\":{\"2115\":1}}],[\"w0w\",{\"2\":{\"2115\":1}}],[\"w0∈rd×kw\",{\"2\":{\"2013\":1}}],[\"w0​∈rd×k\",{\"2\":{\"2013\":1}}],[\"w0​+δw=w0​+ba\",{\"2\":{\"2013\":1}}],[\"w0​t\",{\"2\":{\"1246\":2}}],[\"w0+δw=w0+baw\",{\"2\":{\"2013\":1}}],[\"w0t\",{\"2\":{\"1246\":2}}],[\"wv​\",{\"2\":{\"1870\":1}}],[\"wvw\",{\"2\":{\"1870\":1,\"2164\":1,\"2636\":1}}],[\"wv\",{\"2\":{\"1111\":1}}],[\"wg​⋅x+bg​\",{\"2\":{\"998\":1}}],[\"wg⋅x+bg\",{\"2\":{\"998\":1}}],[\"wholemodel\",{\"2\":{\"2433\":2}}],[\"where\",{\"2\":{\"1458\":1}}],[\"whenever\",{\"2\":{\"1458\":1}}],[\"what\",{\"0\":{\"813\":1},\"1\":{\"847\":1,\"881\":1},\"2\":{\"1367\":1,\"1420\":1}}],[\"why\",{\"0\":{\"782\":1}}],[\"whitebox知识蒸馏\",{\"2\":{\"677\":1}}],[\"whitespace\",{\"2\":{\"508\":2}}],[\"while\",{\"2\":{\"47\":1,\"391\":1,\"656\":2}}],[\"wudaocorporatext\",{\"2\":{\"741\":1}}],[\"wait\",{\"2\":{\"2201\":1}}],[\"was\",{\"2\":{\"1458\":5}}],[\"warmup\",{\"2\":{\"1344\":1,\"1436\":1}}],[\"warmup策略\",{\"2\":{\"1162\":1}}],[\"wanda\",{\"2\":{\"1050\":2}}],[\"wangyizhen\",{\"2\":{\"469\":1}}],[\"wayne\",{\"2\":{\"454\":1}}],[\"wrapped\",{\"2\":{\"1832\":1}}],[\"wrapper\",{\"2\":{\"18\":1}}],[\"writes\",{\"2\":{\"1458\":2}}],[\"write\",{\"2\":{\"846\":1,\"1420\":1}}],[\"write机制\",{\"2\":{\"750\":1}}],[\"writing\",{\"2\":{\"454\":1}}],[\"wizard\",{\"2\":{\"2280\":1}}],[\"wise之间\",{\"2\":{\"1022\":1}}],[\"wise\",{\"0\":{\"1065\":2},\"2\":{\"981\":1,\"1065\":2,\"1982\":1}}],[\"wiki\",{\"2\":{\"837\":1,\"873\":1}}],[\"wikipedia中文20230720\",{\"2\":{\"741\":1,\"909\":1}}],[\"window等于sliding\",{\"2\":{\"2386\":1}}],[\"window=5\",{\"2\":{\"1111\":2}}],[\"window\",{\"2\":{\"740\":1,\"2386\":1}}],[\"wi−1​\",{\"2\":{\"558\":1}}],[\"wi−1\",{\"2\":{\"558\":1}}],[\"wi∣w1\",{\"2\":{\"558\":1}}],[\"wider\",{\"2\":{\"443\":1}}],[\"wi​∣w1​\",{\"2\":{\"558\":1}}],[\"wi​\",{\"2\":{\"268\":1}}],[\"wi\",{\"2\":{\"268\":1,\"2356\":2}}],[\"without\",{\"2\":{\"1902\":2}}],[\"with\",{\"0\":{\"1619\":1},\"2\":{\"67\":1,\"106\":1,\"469\":1,\"544\":1,\"631\":1,\"1088\":1,\"1225\":1,\"1239\":1,\"1287\":1,\"1455\":1,\"1458\":1,\"1527\":1,\"1564\":1,\"1634\":1,\"1902\":1,\"1971\":1,\"2050\":3,\"2275\":1,\"2449\":1,\"2500\":1}}],[\"were\",{\"2\":{\"1458\":1}}],[\"west\",{\"2\":{\"1458\":2}}],[\"we\",{\"2\":{\"1367\":1,\"2449\":1}}],[\"webarena\",{\"2\":{\"1701\":1}}],[\"web\",{\"2\":{\"1217\":1}}],[\"weight\",{\"2\":{\"593\":1,\"799\":1,\"1771\":7,\"1831\":4,\"1936\":2,\"2118\":1,\"2400\":1}}],[\"weights\",{\"2\":{\"213\":2,\"1883\":1,\"1936\":2,\"2400\":3}}],[\"welcome🎉\",{\"0\":{\"2\":1},\"1\":{\"5\":1}}],[\"w₂\",{\"2\":{\"178\":1}}],[\"w\",{\"2\":{\"76\":6,\"123\":2,\"263\":5,\"268\":1,\"283\":6,\"470\":1,\"497\":1,\"558\":3,\"622\":4,\"640\":2,\"998\":1,\"1187\":6,\"1207\":2,\"1246\":6,\"1266\":3,\"1344\":3,\"1359\":8,\"1437\":1,\"1582\":3,\"1795\":5,\"1870\":1,\"1936\":1,\"2013\":2,\"2033\":2,\"2140\":1,\"2356\":1}}],[\"workhorse\",{\"2\":{\"2433\":3}}],[\"worker\",{\"2\":{\"2374\":3}}],[\"workers\",{\"0\":{\"2089\":1},\"2\":{\"2089\":3,\"2139\":2,\"2185\":2,\"2224\":1,\"2325\":2}}],[\"workflow\",{\"0\":{\"1269\":1,\"1595\":1},\"1\":{\"1649\":1,\"1702\":1,\"1760\":1,\"1820\":1,\"1879\":1,\"1935\":1,\"1985\":1,\"2037\":1,\"2089\":1,\"2139\":1,\"2185\":1,\"2224\":1,\"2259\":1,\"2294\":1}}],[\"world\",{\"0\":{\"2234\":1},\"2\":{\"11\":2,\"22\":1,\"27\":1,\"562\":3}}],[\"word文档\",{\"2\":{\"2001\":1}}],[\"wordngrams=2\",{\"2\":{\"1208\":1}}],[\"word\",{\"2\":{\"391\":3,\"426\":1,\"1025\":11,\"1261\":1}}],[\"words\",{\"2\":{\"391\":2,\"631\":1,\"867\":1,\"870\":1}}],[\"wordpiece算法\",{\"2\":{\"1531\":1}}],[\"wordpiece是否需要特殊优化\",{\"2\":{\"490\":1}}],[\"wordpiece是一种常见的分词算法\",{\"2\":{\"308\":1}}],[\"wordpiece与ulm的对比\",{\"0\":{\"445\":1}}],[\"wordpiece与bpe的对比\",{\"0\":{\"420\":1}}],[\"wordpiece的实现步骤\",{\"0\":{\"381\":1}}],[\"wordpiece的核心思想\",{\"0\":{\"355\":1}}],[\"wordpiece通过计算子词间的互信息来决定合并顺序\",{\"2\":{\"355\":1}}],[\"wordpiece从一个基础词表出发\",{\"2\":{\"355\":1}}],[\"wordpiece分词算法简介\",{\"0\":{\"308\":1}}],[\"wordpiece分词算法解析与实践\",{\"0\":{\"262\":1},\"1\":{\"286\":1,\"308\":1,\"331\":1,\"355\":1,\"381\":1,\"407\":1,\"434\":1,\"461\":1,\"490\":1,\"522\":1,\"555\":1}}],[\"wordpiece分词算法解析与实践|wordpiece分词算法解析与实践\",{\"2\":{\"5\":1}}],[\"wordpiece\",{\"2\":{\"286\":1,\"344\":1,\"368\":1,\"420\":1,\"445\":1,\"490\":1}}],[\"word2vec的加速方法\",{\"0\":{\"906\":1},\"1\":{\"941\":1,\"983\":1}}],[\"word2vec主要有两种任务类型\",{\"2\":{\"870\":1}}],[\"word2vec是一种用于生成词向量的模型\",{\"2\":{\"870\":1}}],[\"word2vec\",{\"0\":{\"801\":1},\"1\":{\"835\":1,\"870\":1,\"906\":1,\"941\":1,\"983\":1,\"1023\":1,\"1066\":1,\"1111\":1,\"1161\":1,\"1210\":1,\"1261\":1},\"2\":{\"46\":1,\"55\":1,\"59\":1,\"144\":1,\"835\":1,\"1111\":3,\"2155\":1}}],[\"word2vec|word2vec\",{\"2\":{\"5\":1}}],[\"ghost\",{\"0\":{\"2370\":1},\"1\":{\"2398\":1}}],[\"g=n1​i=1∑n​t=0∑t​\",{\"2\":{\"2531\":1,\"2542\":1}}],[\"g=n1​i=1∑n​t=0∑t​ψti​∇θ​logπθ​\",{\"2\":{\"1942\":1,\"1993\":1}}],[\"g=n1​i=1∑n​m1​j=0∑m​​​r\",{\"2\":{\"1901\":1}}],[\"g=1n∑i=1n∑t=0t\",{\"2\":{\"2531\":1,\"2542\":1}}],[\"g=1n∑i=1n∑t=0tψti∇θlog⁡πθ\",{\"2\":{\"1942\":1,\"1993\":1}}],[\"g=1n∑i=1n1m∑j=0m\",{\"2\":{\"1901\":1}}],[\"g=eπθ​​\",{\"2\":{\"1942\":1,\"1993\":1}}],[\"g=eπθ\",{\"2\":{\"1942\":1,\"1993\":1}}],[\"g=c⋅∣∣g∣∣g​\",{\"2\":{\"622\":1}}],[\"g=c⋅g∣∣g∣∣g\",{\"2\":{\"622\":1}}],[\"ggg\",{\"2\":{\"2520\":1,\"2532\":1}}],[\"gg\",{\"2\":{\"1891\":1}}],[\"gnn\",{\"2\":{\"1606\":1}}],[\"giant\",{\"2\":{\"1455\":1,\"2253\":1}}],[\"gi\",{\"2\":{\"1364\":2,\"2347\":1}}],[\"gi​=∂wi​∂j\",{\"2\":{\"622\":1}}],[\"gi=∂j\",{\"2\":{\"622\":1}}],[\"gitm还使用了外部知识库来辅助目标分解以及存储经验\",{\"2\":{\"2370\":1}}],[\"gitm通过llm将一开始的目标\",{\"2\":{\"2370\":1}}],[\"gitm\",{\"0\":{\"2370\":1},\"1\":{\"2398\":1}}],[\"gitee\",{\"2\":{\"469\":1}}],[\"github70v1\",{\"2\":{\"909\":1}}],[\"github代码\",{\"2\":{\"644\":1,\"1290\":1}}],[\"github项目链接\",{\"2\":{\"628\":1}}],[\"github地址\",{\"2\":{\"358\":1}}],[\"github\",{\"2\":{\"327\":1,\"535\":2,\"1140\":1,\"1339\":1,\"1878\":1,\"2345\":1}}],[\"github仓库\",{\"2\":{\"240\":1}}],[\"git的二十页笔记\",{\"2\":{\"56\":1}}],[\"gaokao\",{\"2\":{\"2184\":2,\"2258\":1}}],[\"gain\",{\"2\":{\"2035\":1}}],[\"gair\",{\"0\":{\"1630\":1},\"1\":{\"1684\":1,\"1740\":1},\"2\":{\"1684\":1}}],[\"gardens\",{\"2\":{\"1458\":1}}],[\"gamma$$\",{\"2\":{\"879\":1}}],[\"gamma$$为折扣因子\",{\"2\":{\"611\":1}}],[\"gammaγ\",{\"2\":{\"856\":1,\"876\":1,\"965\":1,\"1076\":1,\"1123\":1,\"1323\":1,\"2124\":1}}],[\"gamma^t\",{\"2\":{\"2124\":1}}],[\"gamma^\",{\"2\":{\"757\":1}}],[\"gamma^n\",{\"2\":{\"672\":1}}],[\"gamma\",{\"2\":{\"608\":1,\"611\":1,\"619\":4,\"640\":3,\"646\":4,\"647\":3,\"656\":6,\"672\":1,\"676\":1,\"710\":1,\"732\":2,\"748\":1,\"766\":4,\"767\":3,\"779\":1,\"810\":1,\"820\":4,\"840\":3,\"843\":2,\"1076\":1,\"1591\":1,\"1685\":1,\"2430\":1}}],[\"gae用于估计逐个token的奖励\",{\"2\":{\"570\":1}}],[\"gae\",{\"0\":{\"570\":1},\"2\":{\"505\":1,\"1645\":1}}],[\"gate机制\",{\"2\":{\"1119\":1}}],[\"gate\",{\"2\":{\"415\":1,\"998\":3,\"1170\":1,\"1702\":1}}],[\"gather操作会产生额外的通讯量\",{\"2\":{\"2660\":1}}],[\"gather操作\",{\"2\":{\"2660\":1}}],[\"gather\",{\"2\":{\"364\":2,\"619\":1,\"640\":1,\"820\":1,\"1703\":2,\"2308\":1,\"2621\":1}}],[\"gb\",{\"2\":{\"429\":1,\"2145\":1,\"2192\":1}}],[\"g\",{\"2\":{\"222\":2,\"444\":4,\"622\":2,\"748\":1,\"778\":1,\"779\":1,\"820\":4,\"843\":4,\"998\":2,\"1225\":2,\"1364\":1,\"1458\":1,\"1628\":1,\"1683\":2,\"1891\":2,\"1901\":1,\"1936\":1,\"1942\":2,\"1993\":2,\"2140\":1,\"2446\":2,\"2485\":1,\"2531\":1,\"2542\":1,\"2577\":1}}],[\"gqa技术应用\",{\"2\":{\"1071\":1}}],[\"gqa与yarn+双块注意力\",{\"2\":{\"1041\":1}}],[\"gqa减少了mha的参数量\",{\"2\":{\"894\":1}}],[\"gqa\",{\"0\":{\"191\":1},\"2\":{\"1002\":1,\"1069\":2,\"1156\":1,\"1264\":1,\"1265\":1,\"1358\":1,\"1360\":1,\"1403\":1,\"1542\":1}}],[\"gshard通过条件计算和自动分片的结合\",{\"2\":{\"1317\":1}}],[\"gshard引入了drop\",{\"2\":{\"1072\":1}}],[\"gshard是一个用于扩展巨型模型的架构\",{\"2\":{\"1072\":1}}],[\"gshard\",{\"0\":{\"946\":1},\"1\":{\"988\":1,\"1029\":1,\"1072\":1,\"1119\":1,\"1170\":1,\"1219\":1,\"1270\":1,\"1317\":1,\"1363\":1,\"1409\":1,\"1455\":1},\"2\":{\"172\":1,\"988\":1,\"1455\":1}}],[\"global\",{\"2\":{\"2077\":1,\"2217\":3}}],[\"glove\",{\"2\":{\"59\":1,\"144\":1}}],[\"glue数据集\",{\"2\":{\"549\":1}}],[\"glue\",{\"2\":{\"549\":1}}],[\"glu\",{\"2\":{\"199\":2}}],[\"glu与其变种\",{\"0\":{\"199\":1}}],[\"glmblock\",{\"2\":{\"1048\":1}}],[\"glm\",{\"2\":{\"363\":1,\"595\":1,\"925\":1,\"1008\":2,\"1239\":1}}],[\"glm4\",{\"0\":{\"859\":1},\"1\":{\"894\":1,\"929\":1,\"967\":1,\"1008\":1},\"2\":{\"172\":1}}],[\"glm3\",{\"0\":{\"855\":1},\"1\":{\"890\":1,\"926\":1,\"964\":1,\"1007\":1,\"1048\":1,\"1092\":1,\"1141\":1,\"1192\":1,\"1242\":1,\"1292\":1,\"1339\":1},\"2\":{\"172\":1}}],[\"glm2\",{\"0\":{\"854\":1},\"1\":{\"889\":1,\"925\":1,\"963\":1,\"1006\":1,\"1047\":1,\"1091\":1,\"1140\":1},\"2\":{\"172\":1}}],[\"glm1采用多任务预训练策略\",{\"2\":{\"1089\":1}}],[\"glm1采用二维位置编码技术\",{\"2\":{\"1045\":1}}],[\"glm1通过自回归填空任务预训练语言模型\",{\"2\":{\"961\":1}}],[\"glm1使用了prefix\",{\"2\":{\"961\":1}}],[\"glm1是一种基于transformer的语言模型\",{\"2\":{\"923\":1}}],[\"glm1\",{\"0\":{\"853\":1},\"1\":{\"887\":1,\"923\":1,\"961\":1,\"1004\":1,\"1045\":1,\"1089\":1,\"1137\":1,\"1189\":1,\"1239\":1},\"2\":{\"172\":1,\"887\":1}}],[\"gmail\",{\"2\":{\"118\":1}}],[\"géron\",{\"2\":{\"106\":1}}],[\"gpipe方法将transformer层按层切分放到不同的设备上\",{\"2\":{\"2691\":1}}],[\"gpipe\",{\"0\":{\"2691\":1},\"2\":{\"2253\":1}}],[\"gpu上的局部计算\",{\"0\":{\"2667\":1}}],[\"gpu1在干嘛\",{\"2\":{\"2688\":1}}],[\"gpu1\",{\"2\":{\"2526\":1,\"2688\":1}}],[\"gpu0在干嘛\",{\"2\":{\"2688\":1}}],[\"gpu0\",{\"2\":{\"2526\":1,\"2688\":1}}],[\"gpu有大量的线程来执行某个操作\",{\"2\":{\"2128\":1}}],[\"gpu运行模式\",{\"0\":{\"2128\":1}}],[\"gpu内存由多个不同大小和不同读写速度的内存组成\",{\"2\":{\"2077\":1}}],[\"gpu内存分级\",{\"0\":{\"2077\":1}}],[\"gpu是可以做并行计算的\",{\"2\":{\"2030\":1}}],[\"gpu显存利用不足\",{\"2\":{\"1978\":1}}],[\"gpu半精度浮点算力​\",{\"2\":{\"1963\":1}}],[\"gpu半精度浮点算力\",{\"2\":{\"1963\":1}}],[\"gpu数量\",{\"2\":{\"1341\":1}}],[\"gpu进行模型训练\",{\"2\":{\"1145\":1}}],[\"gpu进行训练\",{\"2\":{\"933\":1}}],[\"gpu训练一天时间\",{\"2\":{\"1012\":1}}],[\"gpu\",{\"2\":{\"65\":2,\"1272\":1,\"1919\":1,\"2014\":2,\"2079\":1,\"2081\":1,\"2108\":2,\"2129\":1,\"2253\":2,\"2281\":1,\"2288\":1,\"2308\":2,\"2313\":2,\"2347\":2,\"2374\":1,\"2397\":1,\"2402\":4,\"2427\":1,\"2433\":1,\"2447\":1,\"2468\":1,\"2486\":1,\"2667\":3}}],[\"gptq\",{\"2\":{\"2085\":1}}],[\"gpt1通过结合自监督和有监督学习\",{\"2\":{\"1340\":1}}],[\"gpt1采用自监督的语言模型目标函数\",{\"2\":{\"1093\":1}}],[\"gpt1采用的是transformer的decoder\",{\"2\":{\"1009\":1}}],[\"gpt1在位置编码上进行了可训练的改进\",{\"2\":{\"1009\":1}}],[\"gpt1模型通过生成性预训练来提升语言理解能力\",{\"2\":{\"968\":1}}],[\"gpt1\",{\"2\":{\"930\":1}}],[\"gpt系列模型通过无监督学习进行预训练\",{\"2\":{\"115\":1}}],[\"gpt系列\",{\"2\":{\"115\":1,\"2155\":1}}],[\"gpt\",{\"0\":{\"895\":1,\"900\":1,\"921\":1,\"1024\":1,\"1440\":1,\"2085\":1},\"1\":{\"930\":1,\"935\":1,\"958\":1,\"968\":1,\"975\":1,\"999\":1,\"1009\":1,\"1016\":1,\"1039\":1,\"1049\":1,\"1059\":1,\"1082\":1,\"1093\":1,\"1104\":1,\"1128\":1,\"1142\":1,\"1154\":1,\"1179\":1,\"1193\":1,\"1203\":1,\"1228\":1,\"1243\":1,\"1254\":1,\"1278\":1,\"1293\":1,\"1303\":1,\"1325\":1,\"1340\":1,\"1350\":1,\"1370\":1,\"1385\":1,\"1395\":1,\"1416\":1,\"1462\":1,\"1486\":1,\"1530\":1,\"1579\":1,\"1631\":1,\"1685\":1,\"1741\":1,\"1799\":1,\"1861\":1,\"1918\":1,\"1971\":1},\"2\":{\"31\":1,\"34\":1,\"40\":2,\"49\":2,\"85\":1,\"99\":1,\"115\":1,\"133\":1,\"151\":1,\"172\":3,\"294\":1,\"595\":1,\"728\":1,\"935\":1,\"975\":1,\"999\":1,\"1059\":1,\"1082\":2,\"1102\":1,\"1104\":1,\"1228\":1,\"1278\":3,\"1303\":1,\"1395\":2,\"1416\":2,\"1462\":1,\"1485\":1,\"1569\":1,\"1682\":1,\"1813\":1,\"1917\":1,\"2085\":1,\"2118\":1,\"2210\":1,\"2281\":1,\"2313\":1,\"2603\":1,\"2617\":1,\"2699\":2}}],[\"goal\",{\"2\":{\"2370\":1}}],[\"got\",{\"0\":{\"2144\":1,\"2188\":1,\"2227\":1},\"1\":{\"2188\":1,\"2227\":1,\"2262\":2},\"2\":{\"1917\":1,\"1990\":1,\"2144\":2,\"2188\":3,\"2227\":1}}],[\"gorilla\",{\"2\":{\"1569\":1}}],[\"goo\",{\"2\":{\"2262\":3}}],[\"goodfellow\",{\"2\":{\"165\":1}}],[\"google论文关于相对位置编码\",{\"2\":{\"1647\":1}}],[\"google提出了一种改进方法\",{\"2\":{\"1215\":1}}],[\"google\",{\"2\":{\"65\":1,\"454\":1,\"544\":1,\"1658\":1}}],[\"go\",{\"2\":{\"56\":1}}],[\"gt​∣st​=s\",{\"2\":{\"748\":1,\"779\":1}}],[\"gt∣st=s\",{\"2\":{\"748\":1,\"779\":1}}],[\"gt\",{\"2\":{\"40\":1,\"47\":1,\"164\":1,\"166\":2,\"187\":2,\"245\":1,\"246\":1,\"285\":3,\"293\":1,\"416\":1,\"618\":3,\"622\":3,\"1047\":3,\"1394\":1,\"1735\":1,\"1782\":1,\"2065\":1,\"2576\":1,\"2581\":3,\"2597\":3,\"2599\":1,\"2709\":4}}],[\"grg​\",{\"2\":{\"2446\":1}}],[\"greg\",{\"2\":{\"2408\":1}}],[\"greet\",{\"2\":{\"11\":6}}],[\"greedy\",{\"0\":{\"229\":1,\"301\":1},\"1\":{\"253\":1,\"277\":1,\"301\":1,\"324\":1,\"348\":1,\"374\":1,\"400\":1,\"427\":1,\"453\":1,\"481\":1,\"510\":1},\"2\":{\"5\":2,\"98\":1,\"253\":2,\"400\":1,\"917\":1}}],[\"grs\",{\"2\":{\"2262\":2}}],[\"grounding\",{\"0\":{\"1594\":1},\"2\":{\"1594\":5,\"1759\":1}}],[\"group中的allreduce来更新梯度结果\",{\"2\":{\"1456\":1}}],[\"group内的all2all通讯将token发送到对应的专家\",{\"2\":{\"1456\":1}}],[\"group\",{\"0\":{\"1022\":1},\"2\":{\"218\":8,\"324\":1,\"1240\":1,\"1912\":2,\"1954\":1}}],[\"grouped\",{\"0\":{\"191\":1},\"2\":{\"111\":1,\"1358\":1,\"1771\":2}}],[\"groupsize=\",{\"2\":{\"1022\":1}}],[\"groupsize=1\",{\"2\":{\"1022\":1}}],[\"groups\",{\"2\":{\"18\":1,\"218\":4}}],[\"grassland\",{\"2\":{\"1458\":1}}],[\"granularity\",{\"2\":{\"1367\":1}}],[\"graph\",{\"0\":{\"2144\":1},\"1\":{\"2188\":1,\"2227\":1,\"2262\":1},\"2\":{\"1225\":1,\"1917\":1,\"1990\":1,\"2144\":1,\"2188\":1}}],[\"grad=true\",{\"2\":{\"2539\":4}}],[\"grad=false\",{\"2\":{\"1883\":1}}],[\"gradient\",{\"0\":{\"2503\":1},\"2\":{\"1917\":1,\"2213\":1,\"2217\":2,\"2233\":1,\"2319\":1,\"2545\":1}}],[\"gradients\",{\"0\":{\"622\":1},\"2\":{\"435\":1,\"799\":1}}],[\"grad\",{\"2\":{\"619\":2,\"640\":1,\"820\":1,\"1883\":1,\"2201\":1,\"2400\":1}}],[\"gram生成策略\",{\"2\":{\"1307\":1}}],[\"gram模型的应用场景\",{\"2\":{\"1161\":1}}],[\"gram模式\",{\"2\":{\"1111\":1}}],[\"gram窗口大小\",{\"2\":{\"1109\":1,\"1159\":1}}],[\"gram适合大数据集\",{\"2\":{\"1066\":1}}],[\"gram的应用将更加普遍\",{\"2\":{\"1021\":1}}],[\"gram的初始词表\",{\"2\":{\"393\":1}}],[\"gram特征生成\",{\"2\":{\"1021\":1}}],[\"gram特征与优化点\",{\"0\":{\"1021\":1}}],[\"gram特征\",{\"2\":{\"938\":2,\"1259\":1}}],[\"gram特征和分层softmax优化了传统文本分类的效率\",{\"2\":{\"867\":1}}],[\"gram特征来表示文本内容\",{\"2\":{\"867\":1}}],[\"grams\",{\"2\":{\"575\":1}}],[\"gram\",{\"2\":{\"59\":1,\"870\":1,\"880\":1,\"1021\":1}}],[\"grpo代码优化与重要性采样分析\",{\"0\":{\"2535\":1},\"1\":{\"2545\":1,\"2553\":1,\"2561\":1,\"2569\":1,\"2577\":1,\"2585\":1,\"2593\":1,\"2600\":1,\"2607\":1,\"2614\":1}}],[\"grpo通过引入无偏估计的kl散度来优化策略\",{\"2\":{\"2485\":1}}],[\"grpo的策略更新公式如下\",{\"2\":{\"2485\":1}}],[\"grpo的创新点\",{\"2\":{\"1954\":1}}],[\"grpo策略更新公式\",{\"0\":{\"2485\":1}}],[\"grpo策略更新与实现\",{\"0\":{\"2467\":1},\"1\":{\"2485\":1,\"2500\":1,\"2513\":1,\"2524\":1}}],[\"grpo将整个优势值应用于输出中每个token上\",{\"2\":{\"2306\":1}}],[\"grpo优势函数估计与奖励监督rl\",{\"0\":{\"2238\":1},\"1\":{\"2273\":1,\"2306\":1,\"2337\":1,\"2367\":1,\"2396\":1,\"2421\":1,\"2446\":1}}],[\"grpo算法\",{\"2\":{\"1939\":1}}],[\"grpo算法使用自家的ppo算法进行优化\",{\"2\":{\"1576\":1}}],[\"grpo从旧策略中采样一组输出\",{\"2\":{\"1576\":1}}],[\"grpo\",{\"0\":{\"1669\":1,\"1780\":1},\"1\":{\"1723\":1,\"1780\":1,\"1841\":1,\"1899\":1,\"1954\":1,\"2004\":1,\"2053\":1,\"2106\":1,\"2156\":1,\"2199\":1},\"2\":{\"151\":1,\"1628\":1,\"1917\":1,\"1954\":1,\"2213\":1,\"2238\":1,\"2273\":1,\"2467\":2,\"2485\":1,\"2535\":1,\"2577\":1}}],[\"ge\",{\"2\":{\"2539\":1,\"2589\":1}}],[\"gemms列并行是一种将矩阵\",{\"2\":{\"2555\":1}}],[\"gemms列并行\",{\"0\":{\"2555\":1}}],[\"gemms列并行与transformer中的张量并行\",{\"0\":{\"2547\":1}}],[\"gemms行并行\",{\"0\":{\"2537\":1}}],[\"gemms\",{\"2\":{\"2526\":1}}],[\"german\",{\"2\":{\"1458\":1}}],[\"germany\",{\"2\":{\"1458\":4}}],[\"georg\",{\"2\":{\"1458\":3}}],[\"geq\",{\"2\":{\"1227\":1,\"1925\":1,\"1963\":1,\"2014\":1}}],[\"genai\",{\"2\":{\"1184\":1}}],[\"gensim\",{\"2\":{\"1111\":1}}],[\"generate\",{\"2\":{\"2500\":1}}],[\"generations\",{\"2\":{\"2500\":1}}],[\"generation等\",{\"2\":{\"1368\":1}}],[\"generation\",{\"0\":{\"1674\":1},\"1\":{\"1730\":1,\"1788\":1,\"1849\":1},\"2\":{\"1185\":1,\"1285\":1,\"1309\":1,\"1333\":1,\"1368\":1,\"1609\":1,\"1610\":1,\"2000\":1,\"2303\":1,\"2323\":1,\"2395\":1,\"2469\":1,\"2500\":3,\"2550\":1,\"2601\":1,\"2690\":1}}],[\"generative\",{\"2\":{\"115\":1,\"1385\":1,\"1485\":1}}],[\"general\",{\"2\":{\"1239\":1}}],[\"generalization\",{\"0\":{\"1368\":1},\"2\":{\"949\":1,\"1460\":1}}],[\"generalized\",{\"0\":{\"570\":1},\"2\":{\"1069\":1,\"2273\":1,\"2467\":1}}],[\"generic\",{\"0\":{\"15\":1}}],[\"getaverages\",{\"2\":{\"762\":1}}],[\"get\",{\"2\":{\"515\":1,\"526\":3,\"647\":2,\"1025\":1,\"1435\":2,\"1832\":1,\"1928\":1,\"2433\":4}}],[\"geglu\",{\"0\":{\"199\":1},\"2\":{\"199\":2}}],[\"geglu及其应用解析\",{\"0\":{\"103\":1},\"1\":{\"119\":1,\"138\":1,\"158\":1,\"178\":1,\"199\":1,\"220\":1,\"243\":1,\"266\":1,\"289\":1,\"311\":1,\"334\":1},\"2\":{\"5\":1,\"73\":1}}],[\"geglu及其应用解析|激活函数与ffn结构优化\",{\"2\":{\"5\":1}}],[\"gelu计算中的行列切割策略\",{\"0\":{\"2616\":1}}],[\"gelu激活函数\",{\"2\":{\"970\":1}}],[\"gelu\",{\"2\":{\"119\":1,\"199\":2,\"889\":1,\"1092\":1,\"1292\":1,\"2587\":1,\"2602\":6,\"2609\":6}}],[\"解释为什么例子是positive或negative\",{\"2\":{\"1368\":1}}],[\"解释\",{\"2\":{\"1187\":1}}],[\"解决显存压力问题\",{\"2\":{\"2386\":1}}],[\"解决可能出现的问题\",{\"2\":{\"1334\":1}}],[\"解决属性数据处理问题\",{\"2\":{\"943\":1}}],[\"解决\",{\"0\":{\"593\":1},\"2\":{\"1606\":1}}],[\"解决方法\",{\"2\":{\"591\":1}}],[\"解决方案\",{\"0\":{\"198\":1,\"1561\":1},\"2\":{\"111\":1,\"465\":1,\"523\":1,\"556\":1,\"568\":1,\"1505\":1,\"2331\":1}}],[\"解决越界与局部关系损害问题\",{\"2\":{\"412\":1}}],[\"解决梯度消失问题\",{\"2\":{\"330\":1}}],[\"解决了多轮交互和随机环境中的关键挑战\",{\"2\":{\"2022\":1}}],[\"解决了在训练长推理模型过程中策略偏离初始策略的问题\",{\"2\":{\"1825\":1}}],[\"解决了注意力计算中softmax分块计算的难题\",{\"2\":{\"1750\":1}}],[\"解决了好答案和坏答案同时被采样概率降低的问题\",{\"2\":{\"1681\":1}}],[\"解决了传统one\",{\"2\":{\"870\":1}}],[\"解决了传统方法信息传递效率低的问题\",{\"2\":{\"150\":1}}],[\"解决了样本利用效率低的问题\",{\"2\":{\"521\":1}}],[\"解决了梯度消失问题\",{\"2\":{\"238\":1}}],[\"解决不同维度嵌入在缩放过程中的不均匀分布问题\",{\"2\":{\"159\":1}}],[\"解码器架构模型\",{\"2\":{\"1922\":1}}],[\"解码器架构的选择\",{\"0\":{\"963\":1},\"1\":{\"1006\":1,\"1047\":1}}],[\"解码器架构的预训练语言模型\",{\"2\":{\"901\":1}}],[\"解码器的各层对编码器最终隐藏层额外执行cross\",{\"2\":{\"932\":1}}],[\"解码器\",{\"2\":{\"854\":1}}],[\"解码器注意力层\",{\"2\":{\"34\":1}}],[\"解码时可能存在歧义问题\",{\"2\":{\"529\":1}}],[\"解码歧义问题\",{\"2\":{\"341\":1}}],[\"解码策略详解\",{\"0\":{\"277\":1},\"1\":{\"301\":1,\"324\":1}}],[\"解码策略\",{\"2\":{\"229\":1,\"400\":1}}],[\"解码结构\",{\"2\":{\"34\":1}}],[\"解码采样策略\",{\"0\":{\"229\":1},\"1\":{\"253\":1,\"277\":1,\"301\":1,\"324\":1,\"348\":1,\"374\":1,\"400\":1,\"427\":1,\"453\":1,\"481\":1,\"510\":1},\"2\":{\"5\":1,\"98\":1}}],[\"解析器\",{\"2\":{\"2227\":1}}],[\"解析效果较差\",{\"2\":{\"1834\":1}}],[\"解析效果较为理想\",{\"2\":{\"1773\":1}}],[\"解析pdf文件的主流方法详解\",{\"0\":{\"1609\":1}}],[\"解析pdf可能成本过高\",{\"2\":{\"568\":1}}],[\"解析复杂\",{\"2\":{\"568\":1}}],[\"解析\",{\"0\":{\"204\":1},\"1\":{\"225\":1,\"248\":1,\"271\":1,\"294\":1,\"316\":1,\"339\":1,\"363\":1,\"389\":1,\"415\":1,\"440\":1,\"467\":1,\"495\":1,\"527\":1,\"560\":1,\"595\":1,\"629\":1,\"664\":1,\"702\":1,\"738\":1},\"2\":{\"5\":1,\"98\":1}}],[\"解析|大模型结构与混合专家\",{\"2\":{\"5\":1}}],[\"k和v的分块数\",{\"2\":{\"2406\":1}}],[\"k和cache\",{\"2\":{\"1870\":1}}],[\"kt\",{\"2\":{\"2286\":1}}],[\"k个缩放值\",{\"2\":{\"1809\":1}}],[\"k缩放\",{\"2\":{\"1809\":1}}],[\"kwargs\",{\"2\":{\"1771\":1,\"1832\":3,\"2400\":3}}],[\"kwk​\",{\"2\":{\"1246\":1,\"2636\":1}}],[\"kappa\",{\"2\":{\"1535\":1}}],[\"kaggle\",{\"2\":{\"544\":1}}],[\"kr​\",{\"2\":{\"1364\":1}}],[\"kr\",{\"2\":{\"1364\":1}}],[\"krk\",{\"2\":{\"1318\":1}}],[\"kjk\",{\"2\":{\"2565\":1}}],[\"kj\",{\"2\":{\"2539\":2,\"2565\":1,\"2581\":3}}],[\"kjt​∈rd×bc​\",{\"2\":{\"2643\":1}}],[\"kjt∈rd×bcq\",{\"2\":{\"2643\":1}}],[\"kjt\",{\"2\":{\"2286\":3}}],[\"kj​=xi​wq​wkt​xkj​+xi​wq​wkt​ri\",{\"2\":{\"1187\":1}}],[\"kj=xiwqwktxkj+xiwqwktri\",{\"2\":{\"1187\":1}}],[\"k^i\",{\"2\":{\"1901\":2}}],[\"k^\",{\"2\":{\"1207\":1,\"1359\":4}}],[\"k^j$$\",{\"2\":{\"1187\":1}}],[\"k^j\",{\"2\":{\"1187\":2}}],[\"k^t\",{\"2\":{\"130\":1,\"189\":2,\"1187\":3,\"1868\":1}}],[\"k=2\",{\"2\":{\"1936\":1}}],[\"k=self\",{\"2\":{\"1928\":1}}],[\"k=1\",{\"2\":{\"1127\":1}}],[\"k=mk\",{\"2\":{\"1127\":1}}],[\"k​=mk​\",{\"2\":{\"1127\":1}}],[\"kkk\",{\"2\":{\"1022\":2,\"1075\":2,\"1273\":1,\"1933\":1,\"2102\":1,\"2145\":2}}],[\"knapsack\",{\"2\":{\"917\":2}}],[\"knapsacks\",{\"2\":{\"917\":2}}],[\"knowledge\",{\"0\":{\"677\":1,\"1569\":1},\"1\":{\"715\":1},\"2\":{\"214\":1,\"677\":1,\"715\":1,\"763\":1,\"1569\":1}}],[\"kdim​\",{\"2\":{\"2636\":1}}],[\"kdim\",{\"2\":{\"2636\":1}}],[\"kd\",{\"2\":{\"677\":1,\"1124\":1,\"2195\":1}}],[\"k+1\",{\"2\":{\"647\":1,\"773\":4}}],[\"kl计算的准确性\",{\"2\":{\"1821\":1}}],[\"kl值\",{\"2\":{\"1761\":1}}],[\"kl的计算方式可以通过以下代码实现\",{\"2\":{\"1703\":1}}],[\"kl进行训练\",{\"2\":{\"1650\":1}}],[\"kl则专注于拟合分布中的某一部分\",{\"2\":{\"1596\":1}}],[\"kl旨在尽可能覆盖整个分布的大部分\",{\"2\":{\"1596\":1}}],[\"kl来计算kl惩罚\",{\"2\":{\"1596\":1}}],[\"kl约束在ppo训练中的应用\",{\"0\":{\"1621\":1}}],[\"kl约束被用于防止策略偏离预训练模型太远\",{\"2\":{\"1522\":1}}],[\"kl约束\",{\"2\":{\"1478\":1,\"1546\":1}}],[\"kl散度最小化\",{\"0\":{\"1944\":1}}],[\"kl散度约束用于限制策略偏离初始策略的幅度\",{\"2\":{\"1884\":1}}],[\"kl散度\",{\"2\":{\"1461\":1,\"1552\":1,\"1939\":1}}],[\"kl散度系数\",{\"2\":{\"1323\":1}}],[\"kl散度用于计算rl模型与sft模型在每个token上的响应分布差异\",{\"2\":{\"537\":1}}],[\"kl\",{\"0\":{\"537\":1,\"1033\":1},\"2\":{\"537\":5,\"911\":1,\"1033\":1,\"1552\":2,\"1596\":1,\"1628\":1,\"1657\":1,\"1676\":1,\"1703\":2,\"1720\":1,\"1944\":1,\"2485\":1,\"2577\":1}}],[\"klein\",{\"2\":{\"67\":1}}],[\"kx\",{\"2\":{\"513\":1}}],[\"k采样\",{\"2\":{\"481\":1}}],[\"kpt\",{\"0\":{\"441\":1},\"1\":{\"468\":1},\"2\":{\"468\":2,\"739\":1}}],[\"k$$\",{\"2\":{\"228\":1}}],[\"k是key向量的维度\",{\"2\":{\"130\":1}}],[\"k代表key向量\",{\"2\":{\"130\":1}}],[\"kernel来执行注意力的所有操作\",{\"2\":{\"2080\":1}}],[\"kernel融合是一种优化策略\",{\"2\":{\"2175\":1}}],[\"kernel融合\",{\"0\":{\"2080\":1,\"2175\":1}}],[\"keras官方文档\",{\"2\":{\"302\":1}}],[\"keras\",{\"2\":{\"106\":1,\"278\":1}}],[\"keepdims\",{\"2\":{\"2597\":2}}],[\"keepdims=true\",{\"2\":{\"213\":1,\"2539\":1,\"2597\":4}}],[\"keepdim=true\",{\"2\":{\"364\":1,\"1831\":2}}],[\"key\",{\"2\":{\"112\":1,\"515\":2,\"1912\":6,\"2043\":1,\"2233\":2,\"2286\":1}}],[\"k\",{\"0\":{\"226\":1,\"272\":1,\"1467\":1},\"1\":{\"249\":1,\"272\":1,\"295\":2,\"317\":1,\"340\":1,\"364\":1,\"390\":1,\"416\":1,\"441\":1,\"468\":1,\"496\":1,\"528\":1,\"561\":1,\"596\":1,\"630\":1,\"665\":1,\"703\":1,\"739\":1,\"771\":1},\"2\":{\"5\":2,\"34\":2,\"39\":1,\"47\":6,\"98\":1,\"107\":1,\"130\":3,\"135\":1,\"166\":1,\"187\":1,\"188\":1,\"189\":4,\"208\":4,\"213\":8,\"228\":2,\"283\":1,\"293\":2,\"295\":2,\"427\":1,\"468\":1,\"590\":6,\"630\":1,\"647\":1,\"665\":1,\"695\":1,\"762\":10,\"769\":5,\"771\":1,\"773\":2,\"783\":4,\"1093\":1,\"1127\":4,\"1187\":1,\"1227\":1,\"1266\":1,\"1359\":1,\"1364\":1,\"1455\":1,\"1467\":1,\"1535\":3,\"1782\":2,\"1870\":3,\"1901\":2,\"1928\":2,\"1936\":1,\"2013\":5,\"2044\":5,\"2080\":1,\"2097\":5,\"2137\":2,\"2145\":1,\"2286\":4,\"2314\":1,\"2539\":8,\"2565\":2,\"2636\":1,\"2643\":2,\"2653\":3}}],[\"kv缓存需求对比\",{\"0\":{\"259\":1}}],[\"kv缓存\",{\"2\":{\"96\":1}}],[\"kv\",{\"0\":{\"68\":1,\"78\":1,\"107\":1,\"125\":1,\"145\":1,\"455\":1},\"1\":{\"78\":1,\"92\":1,\"107\":1,\"125\":1,\"145\":1,\"166\":2,\"187\":2,\"208\":1,\"231\":1,\"255\":1,\"279\":1,\"303\":1},\"2\":{\"5\":1,\"63\":1,\"92\":1,\"107\":2,\"125\":1,\"149\":1,\"187\":1,\"189\":5,\"255\":2,\"279\":1,\"283\":3,\"303\":1,\"799\":2,\"917\":1,\"1912\":6,\"1991\":1,\"2118\":1,\"2145\":2,\"2539\":4}}],[\"md2≪1\",{\"2\":{\"2653\":1}}],[\"mdp不同\",{\"2\":{\"1787\":1}}],[\"mdp模型\",{\"2\":{\"1568\":1}}],[\"mdp模型将更为复杂和精确\",{\"2\":{\"953\":1}}],[\"mdp建模\",{\"0\":{\"1613\":1},\"2\":{\"1471\":1}}],[\"mdp由五元组\",{\"2\":{\"676\":1}}],[\"mdp的四个核心要素\",{\"2\":{\"514\":1}}],[\"mdp\",{\"0\":{\"2124\":1},\"2\":{\"514\":1,\"612\":1,\"676\":1,\"1222\":1,\"1515\":1,\"1618\":1,\"2022\":1,\"2124\":1}}],[\"mn2d2\",{\"2\":{\"2653\":2}}],[\"m4ndnd\",{\"2\":{\"2653\":2}}],[\"m^\",{\"2\":{\"2528\":12}}],[\"m^t\",{\"2\":{\"228\":1,\"293\":2}}],[\"my\",{\"2\":{\"2201\":1}}],[\"m1=max⁡\",{\"2\":{\"2176\":1}}],[\"m=max\",{\"2\":{\"1925\":1}}],[\"m=max⁡\",{\"2\":{\"1925\":1}}],[\"m=βd\",{\"2\":{\"221\":2}}],[\"mp\",{\"0\":{\"2489\":1},\"1\":{\"2503\":1},\"2\":{\"1832\":2}}],[\"mmm的取值在100kb左右\",{\"2\":{\"2653\":1}}],[\"mmm\",{\"2\":{\"1770\":1,\"1925\":1,\"2505\":1,\"2549\":1}}],[\"mmlu数据集\",{\"2\":{\"549\":1}}],[\"mmlu\",{\"2\":{\"549\":1}}],[\"mteb\",{\"2\":{\"2663\":1}}],[\"mt+1\",{\"2\":{\"1976\":1}}],[\"mt\",{\"2\":{\"1224\":2}}],[\"mtp\",{\"0\":{\"1127\":1},\"2\":{\"1127\":1}}],[\"mlp层的总通信量为\",{\"2\":{\"2621\":1}}],[\"mlp的第一部分是gemm\",{\"2\":{\"2587\":1}}],[\"mlp结构\",{\"2\":{\"2024\":1}}],[\"mlp\",{\"2\":{\"1451\":1,\"1592\":1,\"1700\":1,\"1912\":1,\"2121\":2}}],[\"mlm\",{\"0\":{\"997\":1},\"2\":{\"919\":1}}],[\"mla在多模态任务中是否有类似的表现\",{\"2\":{\"432\":1}}],[\"mla是否适合非transformer架构\",{\"2\":{\"404\":1}}],[\"mla核心公式\",{\"0\":{\"283\":1}}],[\"mla\",{\"0\":{\"212\":1},\"2\":{\"259\":1}}],[\"mcts\",{\"2\":{\"1917\":1,\"2378\":1}}],[\"mcts和beam\",{\"2\":{\"1013\":1}}],[\"mc\",{\"2\":{\"586\":1,\"843\":1}}],[\"mcp介绍\",{\"2\":{\"219\":1}}],[\"mcp客户端\",{\"2\":{\"118\":1}}],[\"mcp服务器\",{\"2\":{\"118\":1}}],[\"mcp核心\",{\"2\":{\"118\":1}}],[\"mcp系统组成\",{\"0\":{\"118\":1}}],[\"mcp架构与api集成挑战\",{\"2\":{\"219\":1}}],[\"mcp架构概览\",{\"0\":{\"102\":1},\"1\":{\"118\":1}}],[\"mcp架构\",{\"2\":{\"88\":1,\"102\":1}}],[\"ms\",{\"2\":{\"349\":1,\"375\":1,\"1324\":1}}],[\"mse\",{\"2\":{\"39\":1,\"619\":1,\"640\":1}}],[\"mutual\",{\"2\":{\"308\":1,\"499\":1}}],[\"multihead\",{\"2\":{\"1782\":1}}],[\"multilingual\",{\"2\":{\"1665\":1}}],[\"multitask\",{\"2\":{\"1395\":1}}],[\"multiagent\",{\"0\":{\"1291\":1},\"1\":{\"1338\":1,\"1384\":1,\"1431\":1},\"2\":{\"1139\":1,\"1291\":1}}],[\"multinli数据集\",{\"2\":{\"549\":1}}],[\"multinli\",{\"2\":{\"549\":1}}],[\"multinomial\",{\"2\":{\"364\":1}}],[\"multi\",{\"0\":{\"149\":1,\"170\":1,\"212\":1,\"1835\":1,\"2571\":1},\"2\":{\"102\":1,\"111\":3,\"1009\":2,\"1912\":2,\"2050\":1,\"2218\":1,\"2546\":1,\"2571\":1,\"2579\":1}}],[\"m\",{\"2\":{\"221\":4,\"222\":4,\"247\":9,\"291\":1,\"508\":1,\"778\":3,\"1119\":6,\"1127\":1,\"1142\":1,\"1455\":1,\"1456\":1,\"1831\":2,\"1901\":5,\"1925\":3,\"1980\":3,\"2030\":18,\"2121\":3,\"2539\":8,\"2549\":2,\"2573\":1,\"2597\":4,\"2604\":11,\"2611\":2,\"2618\":6,\"2623\":1,\"2628\":2,\"2648\":1,\"2653\":10}}],[\"m$$\",{\"0\":{\"270\":1},\"1\":{\"293\":1,\"315\":1},\"2\":{\"221\":1,\"228\":1,\"291\":1}}],[\"mrr代码实现\",{\"0\":{\"1816\":1}}],[\"mrr的意义\",{\"0\":{\"1698\":1}}],[\"mrr=31​\",{\"2\":{\"1756\":1}}],[\"mrr=13\",{\"2\":{\"1756\":1}}],[\"mrr=1∣q∣∑i=1∣q∣1rankimrr\",{\"2\":{\"1644\":1}}],[\"mrr=∣q∣1​i=1∑∣q∣​ranki​1​\",{\"2\":{\"1644\":1}}],[\"mrr计算方法\",{\"0\":{\"1644\":1}}],[\"mrr\",{\"0\":{\"1876\":1},\"2\":{\"1590\":2,\"1644\":1,\"1698\":3,\"1756\":1,\"1816\":4,\"1876\":1}}],[\"mrr等\",{\"2\":{\"91\":1}}],[\"mrkl系统\",{\"2\":{\"1569\":1}}],[\"mrkl\",{\"0\":{\"1569\":1}}],[\"mrc\",{\"2\":{\"207\":1}}],[\"mi−mi\",{\"2\":{\"2604\":1,\"2618\":1}}],[\"mi​−mi​\",{\"2\":{\"2604\":1,\"2618\":1}}],[\"mi​\",{\"2\":{\"2604\":2}}],[\"mim\",{\"2\":{\"2573\":1,\"2604\":1,\"2623\":1}}],[\"mips\",{\"0\":{\"2102\":1},\"1\":{\"2152\":1,\"2195\":1,\"2234\":1},\"2\":{\"2102\":1}}],[\"microsoft\",{\"2\":{\"1658\":1}}],[\"micro\",{\"2\":{\"1646\":1,\"2233\":1,\"2374\":2}}],[\"michael\",{\"2\":{\"165\":1,\"1658\":1}}],[\"mixture\",{\"2\":{\"1364\":1,\"1658\":1}}],[\"mixtral模型通过仅使用部分专家进行推理\",{\"2\":{\"1986\":1}}],[\"mixtral模型由8个小模型组成\",{\"2\":{\"1121\":1}}],[\"mixtral\",{\"2\":{\"1031\":1,\"2140\":1}}],[\"mixed\",{\"2\":{\"734\":1}}],[\"mini\",{\"2\":{\"2603\":1,\"2622\":2}}],[\"minecraft\",{\"0\":{\"2370\":1},\"1\":{\"2398\":1}}],[\"min\",{\"2\":{\"590\":2,\"655\":1,\"868\":1,\"1111\":2,\"1405\":1,\"1455\":3,\"1499\":1,\"1622\":2,\"1628\":2,\"1712\":1,\"1830\":1,\"1944\":1,\"2013\":1,\"2044\":2,\"2097\":2,\"2485\":2}}],[\"min⁡πex∼d\",{\"2\":{\"1712\":1,\"1830\":1,\"1944\":1}}],[\"min⁡\",{\"2\":{\"590\":1,\"1628\":1,\"2044\":1,\"2097\":1,\"2485\":1}}],[\"middle\",{\"2\":{\"2484\":1}}],[\"mid\",{\"2\":{\"581\":1,\"614\":3,\"732\":4,\"748\":2,\"767\":3,\"779\":2,\"810\":2,\"1093\":1,\"1142\":1,\"1364\":1,\"1613\":1,\"1685\":2,\"1720\":2,\"1732\":4,\"2289\":1,\"2357\":1,\"2531\":1,\"2542\":1}}],[\"mi\",{\"2\":{\"420\":1,\"499\":1,\"2539\":1,\"2573\":1,\"2604\":2,\"2623\":1}}],[\"mistral\",{\"0\":{\"948\":1},\"1\":{\"990\":1,\"1031\":1,\"1074\":1,\"1121\":1},\"2\":{\"172\":1}}],[\"mqa\",{\"0\":{\"170\":1},\"2\":{\"259\":1,\"889\":1,\"1140\":1,\"1782\":1}}],[\"mha将输入的嵌入向量分成多个子空间\",{\"2\":{\"149\":1}}],[\"mha\",{\"0\":{\"149\":1},\"2\":{\"111\":1,\"121\":1,\"162\":1,\"259\":1,\"889\":1}}],[\"moment\",{\"0\":{\"2248\":1},\"1\":{\"2283\":1,\"2315\":1,\"2346\":1}}],[\"momentum\",{\"2\":{\"2161\":1}}],[\"moss\",{\"2\":{\"2223\":1}}],[\"most\",{\"2\":{\"391\":2}}],[\"monte\",{\"2\":{\"675\":1,\"1917\":1,\"2378\":1}}],[\"more\",{\"2\":{\"632\":1,\"2434\":1}}],[\"modify\",{\"2\":{\"2050\":1}}],[\"modifier\",{\"2\":{\"1458\":1}}],[\"modular\",{\"0\":{\"1569\":1,\"2366\":1,\"2523\":1},\"1\":{\"2534\":1,\"2544\":1},\"2\":{\"1569\":1,\"2366\":1,\"2523\":1}}],[\"module\",{\"2\":{\"266\":1,\"619\":1,\"766\":2,\"820\":1,\"1582\":1,\"1622\":1,\"1731\":1,\"1817\":1,\"1831\":1,\"1912\":1}}],[\"modelmem\",{\"2\":{\"2192\":1}}],[\"modelmem=typesize×params\",{\"2\":{\"2192\":2}}],[\"modelmemory\",{\"2\":{\"2023\":1}}],[\"model替换方案\",{\"2\":{\"2053\":1}}],[\"model是必须保留的\",{\"2\":{\"2053\":1}}],[\"model的重要性\",{\"2\":{\"2053\":1}}],[\"model的方法\",{\"2\":{\"1954\":1,\"2053\":1}}],[\"model的可能性\",{\"2\":{\"1954\":2}}],[\"model的作用是防止策略偏离参考策略\",{\"2\":{\"1954\":1}}],[\"model的考虑\",{\"2\":{\"1954\":1}}],[\"model在ppo中的表现差异\",{\"2\":{\"1921\":1}}],[\"model参数\",{\"2\":{\"1744\":1}}],[\"model提供的奖励值进行优化\",{\"2\":{\"1631\":1}}],[\"model构建时\",{\"2\":{\"1741\":1}}],[\"model构建\",{\"2\":{\"1631\":1}}],[\"model构建以及ppo算法优化\",{\"2\":{\"1530\":1}}],[\"model初始化\",{\"2\":{\"1591\":1,\"1699\":1}}],[\"model对这些回答给予奖励值\",{\"2\":{\"1576\":1}}],[\"modeling\",{\"2\":{\"1527\":1,\"1902\":1}}],[\"model\",{\"0\":{\"1433\":1,\"1478\":1,\"1489\":1,\"1497\":1,\"2054\":2,\"2107\":1,\"2489\":1},\"1\":{\"1479\":1,\"1522\":1,\"1523\":1,\"1533\":1,\"1541\":1,\"1571\":1,\"1572\":1,\"1582\":1,\"1591\":1,\"1621\":1,\"1622\":1,\"1634\":1,\"1645\":1,\"1676\":1,\"1677\":1,\"1688\":1,\"1699\":1,\"1732\":1,\"1733\":1,\"1744\":1,\"1757\":1,\"1790\":1,\"1791\":1,\"1802\":1,\"1817\":1,\"1851\":1,\"1852\":1,\"1864\":1,\"1877\":1,\"1908\":1,\"1921\":1,\"1934\":1,\"1961\":1,\"2503\":1},\"2\":{\"151\":4,\"153\":1,\"266\":2,\"268\":3,\"332\":6,\"368\":1,\"499\":1,\"515\":4,\"558\":3,\"574\":1,\"621\":1,\"688\":2,\"749\":2,\"917\":4,\"919\":1,\"1111\":3,\"1149\":1,\"1208\":3,\"1239\":1,\"1246\":3,\"1364\":1,\"1435\":4,\"1533\":1,\"1576\":1,\"1582\":1,\"1617\":1,\"1646\":2,\"1747\":1,\"1814\":2,\"1832\":4,\"1902\":2,\"1912\":1,\"1948\":1,\"1954\":4,\"1955\":2,\"2004\":4,\"2011\":1,\"2081\":2,\"2108\":5,\"2148\":1,\"2156\":1,\"2161\":1,\"2177\":1,\"2201\":13,\"2218\":1,\"2273\":1,\"2333\":1,\"2388\":1,\"2416\":1,\"2434\":1,\"2500\":4,\"2600\":2,\"2636\":1,\"2659\":1}}],[\"models生成响应\",{\"2\":{\"1134\":1}}],[\"models\",{\"0\":{\"172\":1,\"1588\":1},\"2\":{\"101\":1,\"230\":1,\"240\":1,\"740\":2,\"1008\":1,\"1111\":1,\"1287\":1,\"1310\":1,\"1395\":1,\"1403\":1,\"1406\":1,\"1455\":1,\"1462\":1,\"1658\":1,\"1788\":1,\"1902\":1,\"1971\":1,\"2078\":1,\"2199\":1,\"2202\":1,\"2218\":1,\"2229\":1,\"2265\":1,\"2395\":1,\"2434\":1}}],[\"moe推理优化\",{\"0\":{\"2186\":1},\"1\":{\"2225\":1,\"2260\":1,\"2295\":1,\"2326\":1,\"2356\":1,\"2386\":1,\"2413\":1,\"2438\":1,\"2460\":1,\"2478\":1}}],[\"moe层\",{\"2\":{\"1456\":1}}],[\"moe并行训练\",{\"0\":{\"1172\":1},\"1\":{\"1221\":1,\"1272\":1,\"1319\":1,\"1365\":1,\"1410\":1,\"1456\":1,\"1502\":1,\"1547\":1,\"1597\":1,\"1651\":1,\"1704\":1,\"1762\":1,\"1822\":1,\"1881\":1,\"1936\":1,\"1986\":1,\"2038\":1,\"2090\":1,\"2140\":1}}],[\"moe模型\",{\"2\":{\"1000\":1}}],[\"moe结构\",{\"2\":{\"920\":1}}],[\"moe\",{\"0\":{\"204\":1,\"389\":1,\"415\":1},\"1\":{\"225\":1,\"248\":1,\"271\":1,\"294\":1,\"316\":1,\"339\":1,\"363\":1,\"389\":1,\"415\":2,\"440\":2,\"467\":2,\"495\":2,\"527\":1,\"560\":1,\"595\":1,\"629\":1,\"664\":1,\"702\":1,\"738\":1},\"2\":{\"5\":2,\"98\":1,\"225\":1,\"248\":2,\"415\":1,\"467\":1,\"495\":1,\"527\":1,\"560\":2,\"629\":1,\"664\":1,\"702\":1,\"738\":2,\"990\":1,\"1083\":1,\"1272\":1,\"1365\":1,\"1398\":1}}],[\"memory\",{\"0\":{\"1588\":1,\"1661\":1,\"2008\":1},\"1\":{\"1715\":1,\"1772\":1,\"1833\":1,\"1892\":1,\"1947\":1,\"1998\":1,\"2049\":1,\"2102\":1,\"2152\":1,\"2195\":1,\"2234\":1},\"2\":{\"1658\":1,\"1977\":1,\"2027\":1,\"2077\":1,\"2108\":2,\"2118\":1,\"2275\":1,\"2347\":1,\"2505\":1}}],[\"medicine\",{\"2\":{\"1458\":2}}],[\"metagpt\",{\"2\":{\"1485\":1}}],[\"metacognition\",{\"2\":{\"1420\":1}}],[\"meta开发了一系列数据过滤工具\",{\"2\":{\"1167\":1}}],[\"meta\",{\"2\":{\"1114\":1,\"2233\":2}}],[\"methods\",{\"2\":{\"675\":1}}],[\"method\",{\"0\":{\"1434\":1},\"1\":{\"1480\":1,\"1525\":1,\"1576\":1,\"1628\":1,\"1683\":1,\"1739\":1,\"1797\":1,\"1859\":1,\"1915\":1,\"1968\":1,\"2020\":1,\"2070\":1,\"2122\":1,\"2169\":1,\"2211\":1,\"2248\":1,\"2283\":1,\"2315\":1,\"2346\":1,\"2376\":1,\"2404\":1,\"2429\":1,\"2454\":1,\"2474\":1,\"2491\":1,\"2504\":1,\"2516\":1,\"2527\":1,\"2538\":1,\"2548\":1,\"2556\":1,\"2564\":1},\"2\":{\"163\":1,\"2229\":1,\"2265\":1,\"2378\":1}}],[\"mean\",{\"2\":{\"619\":2,\"640\":1,\"1582\":1,\"1590\":1,\"1622\":4,\"1683\":1,\"1731\":1,\"1816\":1,\"1817\":2,\"2306\":1}}],[\"means算法进行聚类\",{\"2\":{\"421\":1}}],[\"means聚类的多样性采样\",{\"0\":{\"421\":1}}],[\"means\",{\"0\":{\"1467\":1},\"2\":{\"39\":1,\"1467\":1,\"2314\":1}}],[\"merges\",{\"2\":{\"391\":1}}],[\"mergenodes\",{\"2\":{\"48\":1}}],[\"megatron中的流水线并行实现略有不同\",{\"2\":{\"2688\":1}}],[\"megatron把masked\",{\"2\":{\"2579\":1}}],[\"megatron的ffn是一个两层mlp\",{\"2\":{\"2579\":1}}],[\"megatron和deepspeed后端实现的区别\",{\"0\":{\"2029\":1},\"1\":{\"2079\":1,\"2129\":1},\"2\":{\"193\":1}}],[\"megatron\",{\"0\":{\"1214\":1,\"2016\":1,\"2066\":1,\"2118\":1,\"2129\":1,\"2167\":1,\"2320\":1,\"2351\":1},\"1\":{\"2066\":1,\"2118\":2,\"2167\":2,\"2209\":2,\"2246\":1,\"2281\":1,\"2313\":1,\"2344\":1,\"2351\":1,\"2374\":1,\"2381\":1,\"2402\":1,\"2408\":1,\"2427\":1,\"2433\":1,\"2452\":1,\"2472\":1,\"2489\":1,\"2503\":1,\"2515\":1,\"2526\":1,\"2537\":1,\"2547\":1,\"2555\":1,\"2563\":1,\"2571\":1,\"2579\":1,\"2587\":1,\"2595\":1,\"2602\":1,\"2609\":1,\"2616\":1,\"2621\":1,\"2626\":1,\"2631\":1,\"2636\":1,\"2641\":1,\"2646\":1,\"2651\":1,\"2656\":1,\"2660\":1,\"2664\":1,\"2667\":1,\"2670\":1,\"2673\":1,\"2676\":1,\"2679\":1,\"2682\":1},\"2\":{\"193\":1,\"660\":1,\"1404\":2,\"1542\":2,\"1592\":1,\"1646\":5,\"1700\":1,\"1758\":1,\"1818\":1,\"1878\":2,\"2066\":1,\"2081\":3,\"2118\":4,\"2129\":5,\"2167\":1,\"2218\":1,\"2320\":1,\"2351\":2}}],[\"master\",{\"2\":{\"2118\":1}}],[\"mask的应用场景\",{\"2\":{\"2510\":1}}],[\"mask=prompt\",{\"2\":{\"2500\":1}}],[\"mask=none\",{\"2\":{\"189\":1}}],[\"mask可以在不增加计算复杂度的情况下合并样本\",{\"2\":{\"2442\":1}}],[\"mask和dropout操作\",{\"2\":{\"2349\":1}}],[\"mask实现等效计算\",{\"2\":{\"2300\":1}}],[\"mask都是内存受限的\",{\"2\":{\"2027\":1}}],[\"mask等其他计算\",{\"2\":{\"1868\":1}}],[\"masks\",{\"2\":{\"917\":2}}],[\"masked\",{\"0\":{\"997\":1,\"2571\":1},\"2\":{\"189\":1,\"304\":1,\"326\":1,\"364\":5,\"919\":1,\"1622\":2,\"1817\":1,\"2080\":2,\"2539\":1,\"2571\":1,\"2589\":1}}],[\"mask\",{\"0\":{\"2349\":1},\"2\":{\"189\":6,\"881\":1,\"917\":6,\"997\":2,\"1006\":1,\"1237\":1,\"1622\":6,\"1817\":2,\"1872\":1,\"1928\":6,\"2027\":1,\"2080\":2,\"2417\":3,\"2482\":1,\"2500\":7,\"2539\":2,\"2578\":1,\"2589\":2,\"2600\":4}}],[\"make\",{\"2\":{\"1458\":1}}],[\"maybe\",{\"2\":{\"1928\":1,\"2500\":1}}],[\"may\",{\"2\":{\"1458\":1}}],[\"majority\",{\"0\":{\"561\":1},\"2\":{\"2042\":1}}],[\"max​q\",{\"2\":{\"2430\":1}}],[\"max​qw​\",{\"2\":{\"640\":1}}],[\"maximum\",{\"0\":{\"2102\":1},\"1\":{\"2152\":1,\"2195\":1,\"2234\":1},\"2\":{\"2604\":3}}],[\"maxmax\",{\"2\":{\"1545\":1,\"2215\":1}}],[\"maxlength\",{\"2\":{\"847\":1}}],[\"maxvowels\",{\"2\":{\"783\":1}}],[\"max⁡s\",{\"2\":{\"2651\":1}}],[\"max⁡πex∼d\",{\"2\":{\"1552\":1,\"1657\":1}}],[\"max⁡\",{\"2\":{\"847\":1,\"1545\":1,\"2215\":1}}],[\"max⁡a\",{\"2\":{\"767\":1}}],[\"max⁡x∈r\",{\"2\":{\"704\":1}}],[\"max⁡θes∼νβ\",{\"2\":{\"590\":1}}],[\"maxq\",{\"2\":{\"647\":3}}],[\"max\",{\"2\":{\"189\":1,\"238\":1,\"261\":1,\"324\":1,\"526\":3,\"590\":1,\"614\":2,\"640\":5,\"647\":7,\"653\":2,\"655\":1,\"656\":8,\"704\":1,\"710\":1,\"767\":3,\"783\":1,\"840\":3,\"847\":1,\"868\":1,\"1405\":1,\"1455\":1,\"1499\":1,\"1552\":1,\"1657\":1,\"1666\":1,\"1720\":1,\"1795\":1,\"1817\":1,\"1925\":1,\"1978\":1,\"2030\":1,\"2033\":2,\"2044\":1,\"2097\":1,\"2176\":1,\"2233\":3,\"2252\":1,\"2430\":1,\"2500\":3,\"2539\":1,\"2597\":3,\"2651\":1,\"2692\":1}}],[\"matrix\",{\"2\":{\"1636\":1}}],[\"matthes\",{\"2\":{\"302\":1}}],[\"mathbf\",{\"2\":{\"2286\":12}}],[\"mathbb\",{\"2\":{\"590\":1,\"623\":1,\"655\":2,\"704\":1,\"1227\":1,\"1536\":1,\"1552\":1,\"1657\":3,\"1712\":2,\"1795\":1,\"1830\":2,\"1944\":1,\"2013\":3,\"2080\":5,\"2485\":1,\"2643\":4,\"2653\":2}}],[\"mathpix在公式识别方面表现出色\",{\"2\":{\"2270\":1}}],[\"mathpix\",{\"2\":{\"2270\":1}}],[\"mathrm\",{\"2\":{\"1795\":5}}],[\"math项目文档\",{\"2\":{\"1475\":1}}],[\"math项目的主要贡献\",{\"2\":{\"1046\":1}}],[\"mathcal\",{\"2\":{\"1127\":3,\"1795\":1,\"2436\":2}}],[\"math技术报告\",{\"2\":{\"685\":1}}],[\"math\",{\"0\":{\"888\":1},\"1\":{\"924\":1,\"962\":1,\"1005\":1,\"1046\":1,\"1090\":1,\"1138\":1,\"1190\":1,\"1240\":1,\"1290\":1,\"1337\":1,\"1383\":1,\"1430\":1,\"1475\":1},\"2\":{\"172\":1,\"1008\":1,\"1977\":1,\"2027\":1}}],[\"mathematical\",{\"2\":{\"18\":1,\"2199\":1}}],[\"matmul\",{\"2\":{\"135\":2}}],[\"machine\",{\"0\":{\"1847\":1},\"2\":{\"106\":3,\"302\":1,\"469\":1,\"631\":1,\"1847\":1}}],[\"map=\",{\"2\":{\"2108\":1}}],[\"map设置为自动的最方便了\",{\"2\":{\"2108\":1}}],[\"maps\",{\"2\":{\"880\":1}}],[\"map\",{\"2\":{\"91\":1,\"2108\":2}}],[\"margin\",{\"2\":{\"1582\":3}}],[\"marco数据集\",{\"2\":{\"375\":1}}],[\"marco\",{\"2\":{\"349\":1}}],[\"martin\",{\"2\":{\"67\":1}}],[\"marker\",{\"2\":{\"2270\":1}}],[\"markers\",{\"2\":{\"2050\":1}}],[\"markov\",{\"2\":{\"1864\":1}}],[\"mark\",{\"2\":{\"18\":1}}],[\"markdown\",{\"0\":{\"1\":1},\"1\":{\"3\":1,\"6\":1,\"9\":1,\"13\":1,\"18\":1},\"2\":{\"1324\":1,\"2050\":1,\"2640\":2}}],[\"maintain\",{\"2\":{\"1458\":1,\"2050\":1}}],[\"main\",{\"2\":{\"10\":2,\"11\":11,\"12\":1,\"15\":1,\"18\":1,\"22\":1,\"27\":1,\"1127\":1,\"2201\":1}}],[\"大量的短文本块会导致信息碎片化\",{\"2\":{\"2533\":1}}],[\"大量数据\",{\"2\":{\"1419\":1}}],[\"大家不用太纠结符号\",{\"2\":{\"2349\":1}}],[\"大约需要耗时\",{\"2\":{\"2313\":1}}],[\"大约需要\",{\"2\":{\"2145\":1}}],[\"大脑\",{\"0\":{\"1567\":1}}],[\"大多数现有评估框架更注重单轮任务的完成情况\",{\"2\":{\"1453\":1}}],[\"大多数中文模型的数据配比为\",{\"2\":{\"474\":1}}],[\"大部分为汉字\",{\"2\":{\"1442\":1}}],[\"大部分就是传统的直接拼接\",{\"2\":{\"847\":1}}],[\"大规模模型的对比结果\",{\"0\":{\"2622\":1}}],[\"大规模模型在性能上表现更优\",{\"2\":{\"2250\":1}}],[\"大规模语言模型对上下文长度有一定限制\",{\"2\":{\"1504\":1}}],[\"大规模文本分类\",{\"2\":{\"1259\":1}}],[\"大规模数据集上构建词汇表可能时间较长\",{\"2\":{\"417\":1}}],[\"大参数模型引入了\",{\"2\":{\"1069\":1}}],[\"大幅降低了计算成本\",{\"2\":{\"1986\":1}}],[\"大幅减少了计算资源的消耗\",{\"2\":{\"1804\":1}}],[\"大幅减少参数数量\",{\"2\":{\"763\":1}}],[\"大幅提升性能\",{\"2\":{\"996\":1}}],[\"大型模型训练的挑战\",{\"0\":{\"2246\":1},\"1\":{\"2281\":1,\"2313\":1,\"2344\":1}}],[\"大型模型能够提供更精准和强大的语义理解与推理能力\",{\"2\":{\"2066\":1}}],[\"大型预训练语言模型\",{\"2\":{\"954\":1}}],[\"大型语言模型的解码器部分通过预测下一个词来生成完整的回答\",{\"2\":{\"2687\":1}}],[\"大型语言模型\",{\"2\":{\"85\":1,\"99\":1,\"436\":1,\"1269\":1,\"1589\":1,\"1767\":1,\"1829\":1,\"1910\":1,\"2582\":1}}],[\"大小的块上表现最佳\",{\"2\":{\"2655\":1}}],[\"大小向量\",{\"2\":{\"1770\":1}}],[\"大小\",{\"2\":{\"1450\":1}}],[\"大小为\",{\"2\":{\"847\":1}}],[\"大小为k平均值大于等于阈值的子数组个数\",{\"0\":{\"769\":1}}],[\"大小等于原来的\",{\"2\":{\"847\":1}}],[\"大大降至\",{\"2\":{\"2676\":1}}],[\"大大降低了采样算法的内存开销\",{\"2\":{\"750\":1}}],[\"大大提升了系统性能和资源利用率\",{\"2\":{\"846\":1}}],[\"大海捞针测试是一种评估大型语言模型\",{\"2\":{\"492\":1}}],[\"大海捞针测试\",{\"0\":{\"463\":1},\"1\":{\"492\":1,\"524\":1}}],[\"大语言模型会根据提示模板生成最终答案并输出\",{\"2\":{\"2305\":1}}],[\"大语言模型拥有极小的内在维度\",{\"2\":{\"1853\":1}}],[\"大语言模型也不例外\",{\"2\":{\"1468\":1}}],[\"大语言模型\",{\"0\":{\"1678\":1},\"2\":{\"225\":2,\"859\":1,\"1015\":1,\"1118\":1,\"1333\":3,\"1376\":1,\"1378\":1,\"1663\":1,\"2483\":1,\"2514\":1}}],[\"大语言模型学习\",{\"0\":{\"2678\":1},\"1\":{\"2681\":1,\"2684\":1,\"2687\":1,\"2690\":1,\"2693\":1,\"2696\":1,\"2699\":1,\"2702\":1},\"2\":{\"5\":74,\"660\":1,\"682\":1,\"685\":1,\"819\":1,\"2202\":1,\"2476\":1,\"2576\":1,\"2599\":1}}],[\"大语言模型学习|大语言模型学习\",{\"2\":{\"5\":1}}],[\"大模型会基于输入生成一个回答\",{\"2\":{\"2333\":1}}],[\"大模型并行训练\",{\"0\":{\"2132\":1},\"1\":{\"2178\":1,\"2218\":1,\"2253\":1,\"2288\":1}}],[\"大模型训练\",{\"2\":{\"2114\":1}}],[\"大模型往往难以直接给出正确答案\",{\"2\":{\"1708\":1}}],[\"大模型+小数据\",{\"2\":{\"1282\":1}}],[\"大模型可以纯靠强化学习学习\",{\"2\":{\"1146\":1}}],[\"大模型推理的性能瓶颈主要来自于内存\",{\"2\":{\"750\":1}}],[\"大模型在大量数据上预训练时\",{\"2\":{\"533\":1}}],[\"大模型的训练通常采用\",{\"2\":{\"2081\":1}}],[\"大模型的推理能力\",{\"2\":{\"1885\":1}}],[\"大模型的推理速度将继续提升\",{\"2\":{\"648\":1}}],[\"大模型的预训练旨在通过在大规模数据集上进行自监督学习\",{\"2\":{\"449\":1}}],[\"大模型的packing技巧\",{\"0\":{\"751\":1},\"1\":{\"782\":1,\"813\":1,\"847\":1,\"881\":1,\"917\":1},\"2\":{\"193\":1}}],[\"大模型\",{\"0\":{\"1755\":1},\"2\":{\"424\":1,\"701\":1,\"1376\":1,\"1419\":1,\"1919\":1}}],[\"大模型应用\",{\"0\":{\"237\":1,\"2678\":1},\"1\":{\"2681\":1,\"2684\":1,\"2687\":1,\"2690\":1,\"2693\":1,\"2696\":1,\"2699\":1,\"2702\":1},\"2\":{\"2576\":1,\"2599\":1}}],[\"大模型生成文本时需要选择解码策略以确保生成的质量和多样性\",{\"2\":{\"253\":1}}],[\"大模型生成\",{\"2\":{\"229\":1}}],[\"大模型通常对ffn的中间层维度进行调整\",{\"2\":{\"220\":1}}],[\"大模型结构与混合专家\",{\"0\":{\"204\":1},\"1\":{\"225\":1,\"248\":1,\"271\":1,\"294\":1,\"316\":1,\"339\":1,\"363\":1,\"389\":1,\"415\":1,\"440\":1,\"467\":1,\"495\":1,\"527\":1,\"560\":1,\"595\":1,\"629\":1,\"664\":1,\"702\":1,\"738\":1},\"2\":{\"5\":1,\"98\":1,\"738\":1}}],[\"lcache​=4096\",{\"2\":{\"2692\":1}}],[\"lcache=4096l\",{\"2\":{\"2692\":1}}],[\"l7\",{\"2\":{\"2688\":1}}],[\"l6\",{\"2\":{\"2688\":1}}],[\"l5\",{\"2\":{\"2688\":1}}],[\"lq\",{\"2\":{\"2653\":2}}],[\"lxl\",{\"2\":{\"2579\":1}}],[\"l^\",{\"2\":{\"2528\":8}}],[\"l0\",{\"2\":{\"2526\":3,\"2688\":1}}],[\"l+n+1\",{\"2\":{\"1782\":3}}],[\"l4\",{\"2\":{\"1617\":1,\"2688\":1}}],[\"lyl​\",{\"2\":{\"1582\":1}}],[\"lsh\",{\"0\":{\"2152\":1},\"2\":{\"1559\":1,\"2152\":1}}],[\"lstm\",{\"2\":{\"144\":2,\"207\":1,\"2121\":6}}],[\"l3​\",{\"2\":{\"1142\":1}}],[\"l3\",{\"2\":{\"1142\":1,\"2688\":1}}],[\"l1=∑f1=e−1+e0l\",{\"2\":{\"2176\":1}}],[\"l1​\",{\"2\":{\"1093\":1}}],[\"l1\",{\"2\":{\"1093\":1,\"1617\":1,\"2526\":3,\"2688\":1}}],[\"l2​\",{\"2\":{\"1142\":1}}],[\"l2\",{\"2\":{\"622\":1,\"1142\":1,\"2526\":3,\"2688\":1}}],[\"lr=1\",{\"2\":{\"1208\":1}}],[\"lr=learning\",{\"2\":{\"820\":1}}],[\"lr=critic\",{\"2\":{\"619\":1,\"766\":1}}],[\"lr=actor\",{\"2\":{\"619\":1,\"766\":1}}],[\"lr\",{\"2\":{\"619\":4,\"766\":4,\"1344\":2,\"1771\":11,\"1832\":6,\"2177\":1}}],[\"ldpop​\",{\"2\":{\"1795\":1}}],[\"ldpop\",{\"2\":{\"1795\":1}}],[\"ldqn​=2n1​i=1∑n​\",{\"2\":{\"640\":1}}],[\"ldqn=12n∑i=1n\",{\"2\":{\"640\":1}}],[\"ldots\",{\"2\":{\"618\":1,\"778\":1,\"1093\":1,\"1142\":1,\"1246\":1,\"1683\":2,\"2492\":1}}],[\"lda\",{\"2\":{\"39\":1}}],[\"l=−n=1∑n​logp\",{\"2\":{\"503\":1}}],[\"l=−∑n=1nlog⁡p\",{\"2\":{\"503\":1}}],[\"l$$\",{\"2\":{\"222\":1}}],[\"l​\",{\"2\":{\"222\":1}}],[\"lmax​=20480\",{\"2\":{\"2692\":1}}],[\"lmax⁡=20480\",{\"2\":{\"2692\":1}}],[\"lm框架中\",{\"2\":{\"2300\":1}}],[\"lm是一种将问题直接转换为代码\",{\"2\":{\"1730\":1}}],[\"lm的原因\",{\"0\":{\"1451\":1}}],[\"lm作为预训练框架\",{\"2\":{\"1265\":1}}],[\"lmbda\",{\"2\":{\"766\":3}}],[\"lm\",{\"0\":{\"363\":1,\"997\":1,\"1214\":1,\"1730\":1,\"2016\":1,\"2066\":1,\"2118\":1,\"2167\":1,\"2320\":1,\"2351\":1},\"1\":{\"2066\":1,\"2118\":2,\"2167\":2,\"2209\":2,\"2246\":1,\"2281\":1,\"2313\":1,\"2344\":1,\"2351\":1,\"2374\":1,\"2381\":1,\"2402\":1,\"2408\":1,\"2427\":1,\"2433\":1,\"2452\":1,\"2472\":1,\"2489\":1,\"2503\":1,\"2515\":1,\"2526\":1,\"2537\":1,\"2547\":1,\"2555\":1,\"2563\":1,\"2571\":1,\"2579\":1,\"2587\":1,\"2595\":1,\"2602\":1,\"2609\":1,\"2616\":1,\"2621\":1,\"2626\":1,\"2631\":1,\"2636\":1,\"2641\":1,\"2646\":1,\"2651\":1,\"2656\":1,\"2660\":1,\"2664\":1,\"2667\":1,\"2670\":1,\"2673\":1,\"2676\":1,\"2679\":1,\"2682\":1},\"2\":{\"193\":1,\"595\":1,\"629\":1,\"702\":1,\"738\":1,\"1404\":1,\"1542\":1,\"1592\":1,\"1646\":2,\"1700\":1,\"1758\":1,\"1818\":1,\"2066\":1,\"2118\":3,\"2167\":1,\"2218\":1,\"2320\":1,\"2351\":2,\"2546\":1,\"2570\":1,\"2648\":2,\"2653\":2}}],[\"l\",{\"2\":{\"190\":1,\"222\":3,\"259\":4,\"291\":2,\"381\":2,\"470\":1,\"497\":1,\"503\":1,\"735\":1,\"1093\":1,\"1127\":3,\"1142\":4,\"1297\":1,\"1582\":2,\"1782\":6,\"1795\":4,\"1980\":3,\"2030\":12,\"2176\":1,\"2322\":3,\"2528\":16,\"2539\":6,\"2549\":2,\"2573\":1,\"2597\":2,\"2604\":2,\"2618\":3,\"2623\":1,\"2628\":2,\"2648\":1,\"2653\":3,\"2692\":1}}],[\"ll\",{\"2\":{\"2013\":1,\"2653\":1}}],[\"lll\",{\"2\":{\"1782\":1,\"1843\":2,\"2505\":1,\"2549\":1,\"2579\":1}}],[\"llo\",{\"2\":{\"562\":1}}],[\"llama新增了17953个tokens\",{\"2\":{\"1442\":1}}],[\"llama与原始llama的tokenizer\",{\"2\":{\"1442\":1}}],[\"llamaindex\",{\"0\":{\"1458\":1},\"2\":{\"1250\":2,\"1412\":1,\"1458\":1,\"2702\":1}}],[\"llama架构\",{\"0\":{\"1214\":1},\"2\":{\"1358\":1}}],[\"llama3团队通过实验验证了scaling\",{\"2\":{\"1329\":1}}],[\"llama3进行了以下改进\",{\"2\":{\"1071\":1}}],[\"llama3\",{\"0\":{\"1065\":1},\"2\":{\"987\":1,\"1065\":1,\"1071\":1,\"1508\":1,\"2233\":1}}],[\"llama模型的推荐公式\",{\"0\":{\"276\":1}}],[\"llama2\",{\"2\":{\"220\":1}}],[\"llama2中的参数优化\",{\"0\":{\"220\":1}}],[\"llama1在海量无标注数据上进行自监督学习\",{\"2\":{\"1211\":1}}],[\"llama1在模型结构上做出了一些关键改动\",{\"2\":{\"1112\":1}}],[\"llama1使用自监督学习模式\",{\"2\":{\"1162\":1}}],[\"llama1提升了训练稳定性和性能\",{\"2\":{\"1067\":1}}],[\"llama1模型是一个开源且高效的基础语言模型\",{\"2\":{\"1067\":1}}],[\"llama1\",{\"0\":{\"942\":1,\"1024\":1},\"1\":{\"984\":1,\"1024\":1,\"1067\":1,\"1112\":1,\"1162\":1,\"1211\":1,\"1262\":1,\"1310\":1},\"2\":{\"172\":1,\"1026\":1,\"1069\":1}}],[\"llama\",{\"0\":{\"917\":1,\"944\":1,\"945\":1,\"1615\":1},\"1\":{\"986\":1,\"987\":1,\"1026\":1,\"1028\":1,\"1069\":1,\"1071\":1,\"1114\":1,\"1117\":1,\"1164\":1,\"1167\":1,\"1213\":1,\"1216\":1,\"1264\":1,\"1267\":1,\"1311\":1,\"1314\":1,\"1357\":1,\"1360\":1,\"1403\":1,\"1406\":1,\"1668\":1,\"1722\":1,\"1779\":1,\"1840\":1,\"1898\":1,\"1953\":1},\"2\":{\"142\":1,\"151\":1,\"172\":2,\"294\":1,\"501\":1,\"595\":1,\"922\":1,\"986\":1,\"1026\":2,\"1028\":1,\"1069\":1,\"1071\":1,\"1114\":1,\"1117\":1,\"1216\":1,\"1310\":1,\"1314\":1,\"1360\":2,\"1403\":1,\"1406\":1,\"1451\":1,\"1487\":1,\"1542\":1,\"1615\":1,\"1668\":1,\"1722\":1,\"1758\":1,\"2118\":1,\"2233\":2,\"2434\":1,\"2699\":1}}],[\"llama系列是另一类重要的语言模型\",{\"2\":{\"115\":1}}],[\"llama系列\",{\"2\":{\"115\":1}}],[\"llama等在学术界和工业界中广泛应用\",{\"2\":{\"99\":1}}],[\"llm分别为每个检索到的知识块生成答案\",{\"2\":{\"2365\":1}}],[\"llm将调用外部检索模块查找相关文档\",{\"2\":{\"2365\":1}}],[\"llm将问题翻译为pddl格式的问题描述\",{\"2\":{\"1465\":1}}],[\"llm快速从trial\",{\"2\":{\"2113\":1}}],[\"llm进行batch推理还有难点需要处理\",{\"2\":{\"1843\":1}}],[\"llm与pddl结合的规划方法\",{\"0\":{\"1465\":1}}],[\"llm本身的局限性\",{\"0\":{\"1378\":1},\"1\":{\"1423\":1,\"1468\":1,\"1512\":1}}],[\"llm可以在不需要显式梯度更新的情况下掌握和执行新任务\",{\"2\":{\"1175\":1}}],[\"llms\",{\"2\":{\"1008\":1,\"1708\":1,\"1726\":1,\"2202\":1}}],[\"llm\",{\"0\":{\"204\":1,\"991\":1,\"1233\":1,\"1362\":1,\"1448\":1,\"1578\":1,\"1780\":1,\"1982\":1,\"2423\":1,\"2699\":1},\"1\":{\"225\":1,\"248\":1,\"271\":1,\"294\":1,\"316\":1,\"339\":1,\"363\":1,\"389\":1,\"415\":1,\"440\":1,\"467\":1,\"495\":1,\"527\":1,\"560\":1,\"595\":1,\"629\":1,\"664\":1,\"702\":1,\"738\":1,\"1032\":1,\"1075\":1},\"2\":{\"5\":2,\"98\":1,\"99\":1,\"248\":1,\"346\":1,\"457\":1,\"492\":1,\"632\":1,\"683\":1,\"738\":1,\"745\":1,\"765\":1,\"773\":2,\"776\":1,\"807\":1,\"841\":1,\"931\":1,\"1032\":1,\"1050\":1,\"1094\":1,\"1124\":1,\"1143\":3,\"1164\":1,\"1175\":1,\"1184\":4,\"1224\":3,\"1233\":6,\"1250\":1,\"1252\":1,\"1269\":1,\"1275\":2,\"1287\":1,\"1308\":1,\"1309\":1,\"1316\":1,\"1321\":4,\"1333\":1,\"1355\":1,\"1362\":1,\"1376\":1,\"1378\":1,\"1392\":1,\"1408\":1,\"1412\":1,\"1423\":1,\"1448\":2,\"1453\":1,\"1458\":1,\"1494\":1,\"1500\":1,\"1514\":1,\"1539\":1,\"1544\":1,\"1560\":1,\"1569\":1,\"1578\":6,\"1589\":1,\"1594\":4,\"1595\":1,\"1611\":1,\"1617\":2,\"1663\":2,\"1672\":2,\"1684\":2,\"1702\":1,\"1717\":2,\"1728\":3,\"1753\":1,\"1760\":1,\"1786\":2,\"1813\":3,\"1835\":1,\"1841\":1,\"1885\":1,\"1982\":1,\"1990\":1,\"2033\":1,\"2037\":5,\"2085\":1,\"2089\":2,\"2094\":1,\"2139\":1,\"2144\":2,\"2145\":1,\"2154\":3,\"2187\":1,\"2197\":2,\"2224\":2,\"2227\":3,\"2228\":1,\"2236\":1,\"2259\":2,\"2262\":2,\"2294\":2,\"2333\":1,\"2345\":1,\"2443\":1,\"2449\":1,\"2483\":1,\"2514\":1,\"2582\":1,\"2590\":1,\"2681\":3,\"2687\":1,\"2693\":1,\"2699\":1,\"2702\":2}}],[\"latency\",{\"2\":{\"2228\":1}}],[\"latency=ttft+tpot×输出\",{\"2\":{\"2228\":2}}],[\"latent\",{\"0\":{\"212\":1},\"2\":{\"111\":1}}],[\"latex\",{\"2\":{\"2050\":1,\"2640\":2}}],[\"layout\",{\"2\":{\"2235\":1}}],[\"layouts\",{\"2\":{\"2050\":1}}],[\"layer很大\",{\"2\":{\"2515\":1}}],[\"layer函数设置降维矩阵\",{\"2\":{\"2425\":1}}],[\"layers\",{\"2\":{\"1912\":4}}],[\"layer\",{\"0\":{\"169\":1,\"190\":1,\"227\":1,\"2515\":1,\"2685\":1},\"1\":{\"2526\":1,\"2537\":1,\"2688\":1,\"2691\":1,\"2694\":1,\"2697\":1,\"2700\":1,\"2703\":1,\"2704\":1,\"2705\":1,\"2706\":1,\"2707\":1,\"2708\":1,\"2709\":1,\"2710\":1,\"2711\":1},\"2\":{\"110\":1,\"128\":1,\"190\":1,\"205\":4,\"227\":1,\"275\":1,\"299\":1,\"932\":1,\"1129\":1,\"1883\":1,\"1912\":1,\"1928\":1,\"2108\":1,\"2142\":1,\"2218\":1,\"2253\":1,\"2400\":2}}],[\"lapwing\",{\"2\":{\"1458\":1}}],[\"laid\",{\"2\":{\"1458\":1}}],[\"laux​=e=1∑e​ce​s​×me​\",{\"2\":{\"1455\":1}}],[\"laux=∑e=1esce×mel\",{\"2\":{\"1455\":1}}],[\"labels\",{\"2\":{\"917\":4}}],[\"label\",{\"2\":{\"515\":1,\"1731\":5,\"2417\":1}}],[\"langsmith\",{\"0\":{\"2590\":1},\"2\":{\"2590\":1}}],[\"langle\",{\"2\":{\"1708\":2}}],[\"langgraph\",{\"2\":{\"1250\":1}}],[\"langchain\",{\"0\":{\"1705\":1,\"1776\":1},\"1\":{\"1763\":1,\"1837\":1},\"2\":{\"1250\":1,\"1412\":1,\"1763\":1,\"1776\":1,\"1837\":1,\"1896\":1,\"1951\":1,\"2590\":1,\"2606\":1,\"2640\":1,\"2702\":1}}],[\"lang\",{\"2\":{\"515\":6}}],[\"language\",{\"0\":{\"1368\":1,\"1569\":1,\"1588\":1},\"2\":{\"67\":3,\"101\":1,\"153\":1,\"230\":1,\"240\":1,\"368\":1,\"499\":1,\"740\":1,\"919\":1,\"1008\":1,\"1149\":1,\"1239\":1,\"1287\":1,\"1310\":1,\"1364\":1,\"1385\":1,\"1395\":1,\"1462\":1,\"1465\":1,\"1527\":1,\"1569\":1,\"1612\":1,\"1617\":1,\"1658\":1,\"1747\":1,\"1788\":1,\"1814\":1,\"1902\":1,\"1948\":1,\"1971\":1,\"2011\":1,\"2078\":1,\"2199\":1,\"2202\":1,\"2218\":1,\"2229\":1,\"2265\":1,\"2333\":1,\"2395\":1,\"2434\":1}}],[\"lambda=1λ=1\",{\"2\":{\"570\":1}}],[\"lambda\",{\"2\":{\"221\":2,\"266\":1,\"290\":1,\"293\":2,\"1127\":1,\"1142\":1,\"1795\":1,\"1891\":2}}],[\"lambda$$\",{\"2\":{\"221\":2,\"293\":1,\"338\":1,\"359\":1,\"439\":1}}],[\"large\",{\"0\":{\"1588\":1},\"2\":{\"101\":1,\"153\":1,\"240\":1,\"740\":1,\"1008\":1,\"1617\":1,\"1658\":1,\"2011\":1,\"2078\":1,\"2202\":1,\"2229\":1,\"2265\":1,\"2333\":1,\"2395\":1}}],[\"law在大规模项目中的适用性\",{\"2\":{\"1607\":1}}],[\"law公式优化现有项目的资源分配\",{\"2\":{\"1556\":1}}],[\"law是否适用于特定领域\",{\"2\":{\"1508\":1}}],[\"law可能进一步优化\",{\"2\":{\"1464\":1}}],[\"law实验结果\",{\"0\":{\"1329\":1},\"2\":{\"1374\":1}}],[\"law\",{\"0\":{\"1086\":1,\"1152\":1},\"1\":{\"1132\":1,\"1183\":1,\"1201\":1,\"1232\":1,\"1282\":1,\"1329\":1,\"1374\":1,\"1419\":1,\"1464\":1,\"1508\":1,\"1556\":1,\"1607\":1},\"2\":{\"5\":1,\"113\":1,\"533\":1,\"667\":1,\"1086\":1,\"1132\":1,\"1152\":1,\"1329\":1,\"1348\":1,\"1441\":1,\"1508\":1}}],[\"law|预训练的scaling\",{\"2\":{\"5\":1}}],[\"ltm\",{\"0\":{\"2049\":1}}],[\"ltotal​=lmain​+dλ​k=1∑d​lmtpk​\",{\"2\":{\"1127\":1}}],[\"ltotal=lmain+λd∑k=1dlmtpk\",{\"2\":{\"1127\":1}}],[\"lt\",{\"2\":{\"40\":1,\"47\":2,\"105\":1,\"166\":2,\"187\":2,\"245\":1,\"416\":1,\"618\":3,\"647\":1,\"1076\":3,\"1323\":1,\"1344\":10,\"1735\":1,\"1782\":1,\"1843\":1,\"2065\":1,\"2485\":12}}],[\"lo\",{\"2\":{\"2653\":2}}],[\"lost\",{\"2\":{\"2484\":1}}],[\"loss对其他深度学习任务的适用性\",{\"2\":{\"2629\":1,\"2674\":1}}],[\"loss在不同模型中的应用案例\",{\"2\":{\"2629\":1,\"2674\":1}}],[\"loss不仅提升了训练过程的稳定性\",{\"2\":{\"2624\":1,\"2671\":1}}],[\"loss时\",{\"2\":{\"2619\":1,\"2668\":1}}],[\"loss转换为token\",{\"2\":{\"2605\":1,\"2662\":1}}],[\"loss后\",{\"2\":{\"2598\":1,\"2658\":1}}],[\"loss可能导致的长样本贡献不均衡的问题\",{\"2\":{\"2591\":1,\"2654\":1}}],[\"loss通过对每个token单独计算损失\",{\"2\":{\"2591\":1,\"2654\":1}}],[\"loss的优势\",{\"0\":{\"2591\":1,\"2654\":1}}],[\"loss的计算方法可以有效地提升长样本对模型训练的影响\",{\"2\":{\"2575\":1,\"2644\":1}}],[\"loss函数中\",{\"2\":{\"2561\":1}}],[\"losses=\",{\"2\":{\"2012\":2}}],[\"losses\",{\"2\":{\"1731\":3,\"2417\":1}}],[\"loss计算\",{\"2\":{\"1591\":1}}],[\"loss=31​\",{\"2\":{\"2322\":1}}],[\"loss=13\",{\"2\":{\"2322\":1}}],[\"loss=−min\",{\"2\":{\"1622\":1}}],[\"loss=−min⁡\",{\"2\":{\"1622\":1}}],[\"loss=−e\",{\"2\":{\"1582\":2,\"1634\":2,\"1727\":2}}],[\"loss=\",{\"2\":{\"1591\":2}}],[\"loss=α⋅n⋅i=1∑n​fi​⋅pi​\",{\"2\":{\"1279\":1}}],[\"loss=α⋅n⋅∑i=1nfi⋅pi\",{\"2\":{\"1279\":1}}],[\"loss系数\",{\"2\":{\"1123\":1,\"1323\":1}}],[\"loss正则化技术\",{\"2\":{\"662\":1}}],[\"loss正则化\",{\"2\":{\"593\":1,\"736\":1}}],[\"loss突然激增或激减可能是数据问题的信号\",{\"2\":{\"525\":1}}],[\"loss监控\",{\"2\":{\"464\":1}}],[\"loss\",{\"0\":{\"520\":1,\"525\":1,\"593\":1,\"603\":1,\"1076\":1,\"2559\":1,\"2634\":1},\"1\":{\"553\":1,\"589\":1,\"2567\":1,\"2575\":1,\"2583\":1,\"2591\":1,\"2598\":1,\"2605\":1,\"2612\":1,\"2619\":1,\"2624\":1,\"2629\":1,\"2639\":1,\"2644\":1,\"2649\":1,\"2654\":1,\"2658\":1,\"2662\":1,\"2665\":1,\"2668\":1,\"2671\":1,\"2674\":1},\"2\":{\"393\":1,\"405\":1,\"433\":1,\"435\":3,\"437\":1,\"516\":1,\"525\":2,\"533\":1,\"553\":3,\"589\":4,\"619\":5,\"640\":3,\"657\":1,\"694\":1,\"730\":2,\"765\":1,\"820\":2,\"875\":1,\"881\":2,\"1152\":1,\"1225\":1,\"1279\":1,\"1297\":1,\"1536\":3,\"1582\":5,\"1591\":1,\"1622\":6,\"1634\":1,\"1727\":1,\"1731\":3,\"1817\":5,\"2163\":1,\"2201\":3,\"2322\":1,\"2417\":7,\"2482\":2,\"2567\":1,\"2600\":1,\"2605\":1,\"2612\":1,\"2639\":1,\"2662\":1,\"2665\":1,\"2673\":1,\"2676\":1}}],[\"locally\",{\"2\":{\"2434\":1}}],[\"locality\",{\"2\":{\"1559\":1}}],[\"look\",{\"2\":{\"1458\":1}}],[\"lookup\",{\"2\":{\"996\":1}}],[\"load\",{\"2\":{\"640\":1,\"2201\":2,\"2233\":1}}],[\"loper\",{\"2\":{\"67\":1}}],[\"lower\",{\"2\":{\"515\":1}}],[\"lowercase\",{\"2\":{\"480\":2}}],[\"lowest\",{\"2\":{\"443\":1}}],[\"low\",{\"0\":{\"682\":1},\"2\":{\"57\":1,\"214\":1,\"443\":1,\"763\":1,\"1636\":1,\"1658\":2,\"1792\":1,\"2050\":1,\"2078\":1,\"2327\":1}}],[\"lora微调\",{\"2\":{\"2279\":1}}],[\"lora展示了如何通过低秩分解和内在维度的利用\",{\"2\":{\"2207\":1}}],[\"lora在不同领域任务中的性能表现\",{\"2\":{\"2078\":1}}],[\"lora结合的可能性\",{\"2\":{\"2078\":1}}],[\"lora认为在参数更新过程中存在一个内在秩\",{\"2\":{\"2013\":1}}],[\"lora的核心在于loramodel类\",{\"2\":{\"2400\":1}}],[\"lora的核心思想是利用预训练模型的内在低维度特性\",{\"2\":{\"1792\":1}}],[\"lora的实现\",{\"0\":{\"1962\":1}}],[\"lora使用低秩矩阵来表示参数增量\",{\"2\":{\"1853\":1}}],[\"lora使用一个动态缩放机制来调整每个lora模型在最终输出中的贡献\",{\"2\":{\"1809\":1}}],[\"lora通过使用低秩矩阵来编码参数增量\",{\"2\":{\"1962\":1}}],[\"lora通过低秩分解来更新参数\",{\"2\":{\"1853\":1}}],[\"lora通过加载预训练参数进行初始化\",{\"2\":{\"1853\":1}}],[\"lora通过结合多个不同领域的预训练的lora模型\",{\"2\":{\"1692\":1}}],[\"loraplustrainer\",{\"2\":{\"1832\":1}}],[\"lorap\",{\"2\":{\"1832\":2}}],[\"loraprune\",{\"2\":{\"1050\":2}}],[\"loralayer\",{\"2\":{\"1831\":1,\"1883\":1,\"2400\":2}}],[\"lora|lora\",{\"2\":{\"682\":1}}],[\"lora及其变体\",{\"2\":{\"682\":1}}],[\"lora+优化器通过设置不同的学习率来实现更高效的训练\",{\"2\":{\"1771\":1}}],[\"lora+优化器创建\",{\"0\":{\"1771\":1}}],[\"lora+是一种针对lora适配器的优化方法\",{\"2\":{\"1660\":1}}],[\"lora+\",{\"0\":{\"1554\":1},\"1\":{\"1605\":1,\"1660\":1,\"1714\":1,\"1771\":1,\"1832\":1,\"1891\":1,\"1946\":1,\"1997\":1},\"2\":{\"151\":1,\"1658\":1}}],[\"lora\",{\"0\":{\"1565\":1,\"1573\":1,\"1585\":1,\"1678\":1,\"2279\":1,\"2400\":1,\"2425\":1},\"1\":{\"1623\":1,\"1638\":1,\"1678\":1,\"1692\":1,\"1734\":1,\"1749\":1,\"1792\":1,\"1809\":1,\"1853\":1,\"1871\":1,\"1909\":1,\"1928\":1,\"1962\":1,\"1979\":1,\"2013\":1,\"2028\":1,\"2062\":1,\"2078\":1,\"2115\":1,\"2164\":1,\"2207\":1,\"2244\":1,\"2311\":1,\"2342\":1,\"2372\":1,\"2400\":1,\"2425\":1,\"2450\":1,\"2471\":1},\"2\":{\"57\":1,\"151\":3,\"1050\":1,\"1583\":1,\"1604\":1,\"1605\":1,\"1624\":1,\"1638\":1,\"1658\":3,\"1771\":4,\"1792\":1,\"1793\":1,\"1831\":6,\"1832\":6,\"1883\":8,\"1928\":2,\"1997\":2,\"2048\":1,\"2078\":1,\"2092\":1,\"2400\":7,\"2425\":2,\"2471\":1}}],[\"longtermism\",{\"2\":{\"1287\":1}}],[\"longalign\",{\"2\":{\"1008\":1}}],[\"longlora\",{\"2\":{\"87\":1,\"101\":1}}],[\"long\",{\"2\":{\"18\":4,\"101\":1,\"240\":1,\"740\":1,\"762\":3,\"1939\":1,\"2408\":1}}],[\"logging\",{\"2\":{\"2233\":1}}],[\"logσ\",{\"2\":{\"1795\":1}}],[\"logπθ​\",{\"2\":{\"1795\":1}}],[\"logπ\",{\"2\":{\"1732\":2}}],[\"logπref​\",{\"2\":{\"1657\":1,\"1712\":1}}],[\"logratios\",{\"2\":{\"1731\":4}}],[\"logp\",{\"2\":{\"1727\":1}}],[\"logps\",{\"2\":{\"1703\":8,\"1731\":12,\"2561\":6}}],[\"logp^\",{\"2\":{\"1536\":2}}],[\"logsigmoid\",{\"2\":{\"1582\":2,\"1731\":2}}],[\"log⁡2\",{\"2\":{\"2137\":1}}],[\"log⁡σ\",{\"2\":{\"1795\":1}}],[\"log⁡p\",{\"2\":{\"1727\":1}}],[\"log⁡p^\",{\"2\":{\"1536\":2}}],[\"log⁡πref\",{\"2\":{\"1732\":2,\"1795\":1}}],[\"log⁡π\",{\"2\":{\"1657\":1,\"1712\":1,\"1830\":1}}],[\"log⁡\",{\"2\":{\"1582\":1,\"1634\":1,\"1685\":1}}],[\"log⁡y\",{\"2\":{\"18\":2}}],[\"logn\",{\"2\":{\"1255\":1}}],[\"logits−2β1​\",{\"2\":{\"2012\":1}}],[\"logits−12β\",{\"2\":{\"2012\":1}}],[\"logits\",{\"2\":{\"881\":1,\"1703\":2,\"1731\":4,\"2012\":1}}],[\"logy\",{\"2\":{\"18\":2}}],[\"log\",{\"2\":{\"18\":2,\"268\":1,\"332\":1,\"503\":1,\"537\":1,\"558\":1,\"586\":1,\"614\":1,\"619\":3,\"723\":1,\"757\":1,\"820\":3,\"941\":1,\"1093\":1,\"1142\":1,\"1179\":1,\"1435\":1,\"1535\":1,\"1536\":2,\"1582\":2,\"1622\":4,\"1634\":2,\"1657\":2,\"1671\":1,\"1685\":3,\"1703\":2,\"1712\":1,\"1727\":1,\"1732\":2,\"1795\":4,\"1830\":2,\"1901\":1,\"1942\":2,\"1944\":1,\"1993\":2,\"1994\":2,\"2046\":4,\"2137\":1,\"2531\":1,\"2542\":1,\"2600\":1}}],[\"li​\",{\"2\":{\"2604\":1}}],[\"lil\",{\"2\":{\"2573\":1,\"2604\":1,\"2623\":1}}],[\"li\",{\"2\":{\"2539\":1,\"2573\":1,\"2604\":1,\"2618\":1,\"2623\":1}}],[\"library\",{\"2\":{\"2277\":1}}],[\"lifelong\",{\"0\":{\"2242\":1},\"1\":{\"2277\":1,\"2309\":1,\"2340\":1},\"2\":{\"2242\":1}}],[\"like\",{\"2\":{\"1928\":1,\"2539\":1}}],[\"limlim\",{\"2\":{\"2215\":1}}],[\"lim⁡\",{\"2\":{\"2215\":1}}],[\"limits\",{\"2\":{\"704\":1,\"2199\":1}}],[\"lima\",{\"2\":{\"632\":1,\"2434\":1}}],[\"light\",{\"2\":{\"683\":1,\"2145\":1}}],[\"lightgbm\",{\"2\":{\"39\":1}}],[\"line\",{\"2\":{\"644\":1}}],[\"linear层\",{\"2\":{\"2526\":1}}],[\"linear的属性\",{\"2\":{\"2400\":1}}],[\"linearwithdoramerged\",{\"2\":{\"1831\":1}}],[\"linear2\",{\"2\":{\"266\":2}}],[\"linear1\",{\"2\":{\"266\":2}}],[\"linear\",{\"0\":{\"189\":1},\"2\":{\"94\":1,\"189\":2,\"203\":1,\"233\":1,\"257\":1,\"266\":2,\"293\":1,\"305\":1,\"327\":1,\"766\":4,\"820\":2,\"1831\":9,\"1912\":2,\"2217\":1,\"2400\":4,\"2425\":2}}],[\"link\",{\"2\":{\"18\":2}}],[\"links\",{\"2\":{\"18\":2}}],[\"lists\",{\"2\":{\"1816\":3,\"2050\":1}}],[\"listnode\",{\"2\":{\"47\":7,\"48\":2}}],[\"list\",{\"2\":{\"18\":10,\"647\":8,\"656\":3,\"820\":7,\"1458\":1,\"1771\":4,\"1816\":2,\"2539\":3,\"2549\":3}}],[\"let\",{\"2\":{\"1885\":3}}],[\"letter\",{\"2\":{\"407\":2}}],[\"le\",{\"2\":{\"1364\":2}}],[\"less\",{\"2\":{\"632\":1,\"2434\":1}}],[\"level的优势函数可以提高模型的精度和稳定性\",{\"2\":{\"1791\":1}}],[\"level的任务描述\",{\"2\":{\"1368\":1}}],[\"level句子级\",{\"2\":{\"1089\":1}}],[\"level文档级\",{\"2\":{\"1089\":1}}],[\"level\",{\"0\":{\"537\":1,\"1238\":1,\"1289\":1,\"1336\":1,\"1382\":1,\"1429\":1,\"2559\":1,\"2591\":1,\"2634\":1,\"2654\":1},\"1\":{\"2567\":1,\"2575\":1,\"2583\":1,\"2591\":1,\"2598\":1,\"2605\":1,\"2612\":1,\"2619\":1,\"2624\":1,\"2629\":1,\"2639\":1,\"2644\":1,\"2649\":1,\"2654\":1,\"2658\":1,\"2662\":1,\"2665\":1,\"2668\":1,\"2671\":1,\"2674\":1},\"2\":{\"296\":1,\"469\":1,\"644\":1,\"1522\":1,\"1676\":1,\"1762\":3,\"2567\":1,\"2575\":1,\"2591\":2,\"2598\":1,\"2605\":2,\"2612\":1,\"2619\":1,\"2624\":1,\"2629\":2,\"2639\":1,\"2644\":1,\"2654\":2,\"2658\":1,\"2662\":2,\"2665\":1,\"2668\":1,\"2671\":1,\"2674\":2}}],[\"leq\",{\"2\":{\"285\":1,\"1344\":3}}],[\"leave\",{\"2\":{\"1783\":1}}],[\"leaky\",{\"0\":{\"261\":1},\"2\":{\"330\":1}}],[\"learners\",{\"2\":{\"1395\":1,\"1462\":1}}],[\"learn官方文档\",{\"2\":{\"106\":1}}],[\"learn\",{\"2\":{\"106\":1}}],[\"learning在连续状态空间中的应用\",{\"2\":{\"951\":1}}],[\"learning在相同任务中的表现\",{\"2\":{\"817\":1}}],[\"learning通过选择价值最高的动作来优化策略\",{\"2\":{\"840\":1}}],[\"learning时\",{\"2\":{\"806\":1}}],[\"learning每次选择下一个状态动作价值最高的值和即时奖励来作为当前状态最优动作价值的估计\",{\"2\":{\"710\":1}}],[\"learning基于最优贝尔曼方程估计最优动作价值\",{\"2\":{\"710\":1}}],[\"learning算法分析\",{\"2\":{\"876\":1}}],[\"learning算法流程\",{\"0\":{\"775\":1}}],[\"learning算法\",{\"0\":{\"710\":1},\"2\":{\"840\":1}}],[\"learning算法使用当前行为策略采样的四元组\",{\"2\":{\"653\":1}}],[\"learning算法的扩展\",{\"2\":{\"606\":1}}],[\"learning的更新方式\",{\"0\":{\"640\":1}}],[\"learning是两种常见的强化学习算法\",{\"2\":{\"638\":1}}],[\"learning\",{\"0\":{\"2242\":1},\"1\":{\"2277\":1,\"2309\":1,\"2340\":1},\"2\":{\"106\":3,\"165\":3,\"302\":1,\"477\":2,\"544\":1,\"571\":1,\"573\":1,\"670\":1,\"754\":1,\"815\":1,\"820\":1,\"928\":1,\"934\":1,\"999\":1,\"1082\":1,\"1175\":1,\"1228\":1,\"1333\":1,\"1517\":1,\"1550\":1,\"1564\":1,\"1633\":1,\"1634\":1,\"1902\":4,\"1920\":1,\"2187\":1,\"2202\":1,\"2229\":1,\"2233\":1,\"2242\":1,\"2265\":1,\"2368\":1,\"2418\":1,\"2545\":1,\"2546\":1,\"2647\":1,\"2693\":1}}],[\"learning对比\",{\"0\":{\"506\":1},\"1\":{\"538\":1,\"571\":1,\"604\":1,\"638\":1,\"672\":1,\"710\":1,\"744\":1,\"775\":1,\"806\":1,\"840\":1,\"876\":1,\"912\":1,\"951\":1},\"2\":{\"5\":1,\"151\":1}}],[\"learning对比|sarsa\",{\"2\":{\"5\":1}}],[\"lenseq\",{\"2\":{\"1868\":2}}],[\"length×模型参数量\",{\"2\":{\"2263\":2}}],[\"lengths\",{\"2\":{\"917\":1}}],[\"length\",{\"0\":{\"2039\":1},\"2\":{\"847\":2,\"917\":8,\"1823\":1,\"1912\":2,\"2039\":1,\"2263\":1,\"2500\":6}}],[\"length=10\",{\"2\":{\"324\":1}}],[\"len\",{\"2\":{\"218\":1,\"332\":5,\"391\":2,\"656\":1,\"820\":1,\"843\":1,\"917\":10,\"1025\":1,\"1435\":3,\"1816\":1,\"1823\":1,\"1868\":1,\"1912\":2,\"1978\":1,\"1984\":4,\"2039\":1,\"2233\":1,\"2252\":1,\"2539\":7}}],[\"leftarrow\",{\"2\":{\"608\":1,\"611\":1,\"640\":1,\"672\":1,\"710\":1,\"775\":1,\"778\":2,\"1891\":2}}],[\"left\",{\"2\":{\"18\":3,\"34\":1,\"228\":1,\"268\":1,\"537\":1,\"558\":1,\"590\":3,\"647\":1,\"656\":1,\"732\":1,\"757\":2,\"767\":1,\"1127\":1,\"1229\":1,\"1535\":1,\"1552\":2,\"1582\":2,\"1622\":2,\"1628\":4,\"1634\":2,\"1657\":3,\"1685\":1,\"1712\":2,\"1727\":1,\"1732\":2,\"1756\":1,\"1795\":1,\"1830\":4,\"1883\":1,\"1889\":2,\"1901\":2,\"1942\":1,\"1944\":2,\"1993\":1,\"2044\":3,\"2046\":2,\"2097\":3,\"2322\":1,\"2485\":4,\"2500\":1,\"2531\":1,\"2542\":1,\"2577\":2}}],[\"ln\",{\"0\":{\"73\":1,\"89\":1,\"205\":1},\"1\":{\"104\":1,\"121\":1,\"141\":1,\"162\":1,\"183\":1,\"205\":1,\"227\":1,\"251\":1,\"275\":1,\"299\":1},\"2\":{\"5\":8,\"73\":1,\"121\":2,\"184\":1,\"276\":1,\"346\":1}}],[\"训练稳定性\",{\"2\":{\"2494\":1,\"2567\":1,\"2639\":1}}],[\"训练策略\",{\"0\":{\"2341\":1},\"1\":{\"2371\":1,\"2399\":1,\"2424\":1}}],[\"训练一个小的判别模型来判断session中的每个turn是否连续\",{\"2\":{\"2256\":1}}],[\"训练一个retriever\",{\"2\":{\"1075\":1}}],[\"训练大型模型面临的挑战主要包括显存限制\",{\"2\":{\"2246\":1}}],[\"训练技巧\",{\"0\":{\"2163\":1},\"1\":{\"2206\":1,\"2243\":1}}],[\"训练技巧和训练策略\",{\"0\":{\"2114\":1},\"1\":{\"2163\":1,\"2206\":1,\"2243\":1,\"2278\":1,\"2310\":1,\"2341\":1,\"2371\":1,\"2399\":1,\"2424\":1,\"2449\":1,\"2470\":1,\"2488\":1,\"2502\":1},\"2\":{\"131\":1}}],[\"训练技巧和训练策略|训练技巧和训练策略\",{\"2\":{\"5\":1}}],[\"训练和评估是提升模型性能的重要环节\",{\"2\":{\"2151\":1}}],[\"训练失败\",{\"2\":{\"2118\":1}}],[\"训练这样规模庞大的模型面临着一些挑战\",{\"2\":{\"2066\":1}}],[\"训练这些模型所需的计算资源也急剧增加\",{\"2\":{\"728\":1}}],[\"训练脚本\",{\"2\":{\"2055\":1}}],[\"训练模板设计\",{\"0\":{\"1859\":1}}],[\"训练模型\",{\"0\":{\"123\":1},\"2\":{\"185\":1,\"795\":1,\"1203\":1}}],[\"训练接口可用\",{\"2\":{\"1719\":1}}],[\"训练奖励函数模型\",{\"2\":{\"1642\":1}}],[\"训练\",{\"2\":{\"1605\":1,\"2081\":2}}],[\"训练优化\",{\"2\":{\"1405\":1}}],[\"训练框架推荐\",{\"0\":{\"1404\":1}}],[\"训练框架及参数设置\",{\"0\":{\"2131\":1},\"1\":{\"2177\":1,\"2217\":1,\"2252\":1,\"2287\":1,\"2319\":1,\"2350\":1,\"2380\":1,\"2407\":1,\"2432\":1},\"2\":{\"131\":1}}],[\"训练框架及参数设置|训练框架及参数设置\",{\"2\":{\"5\":1}}],[\"训练步数增多且损失函数下降受限\",{\"2\":{\"1297\":1}}],[\"训练阶段\",{\"2\":{\"1288\":1}}],[\"训练阶段的显存分析\",{\"0\":{\"1995\":1},\"1\":{\"2047\":1,\"2099\":1,\"2149\":1,\"2192\":1,\"2231\":1,\"2266\":1,\"2299\":1,\"2330\":1,\"2360\":1},\"2\":{\"193\":1}}],[\"训练后量化\",{\"0\":{\"1260\":1,\"1753\":1,\"1874\":1},\"1\":{\"1813\":1,\"1874\":1,\"1931\":2,\"1982\":2,\"2033\":2,\"2085\":2},\"2\":{\"1260\":1}}],[\"训练设置\",{\"0\":{\"1248\":1}}],[\"训练设置和优化策略\",{\"2\":{\"1149\":1}}],[\"训练了两个蒸馏模型\",{\"2\":{\"1224\":1}}],[\"训练流程\",{\"0\":{\"1216\":1},\"1\":{\"1267\":1}}],[\"训练fasttext模型\",{\"2\":{\"1208\":1,\"1337\":1}}],[\"训练时使用\",{\"2\":{\"2069\":1}}],[\"训练时使用所有8个模型\",{\"2\":{\"1121\":1}}],[\"训练时为2048\",{\"2\":{\"1204\":1}}],[\"训练采用标准自回归语言模型目标\",{\"2\":{\"1204\":1}}],[\"训练速度比\",{\"2\":{\"2118\":1}}],[\"训练速度加快\",{\"2\":{\"1932\":1}}],[\"训练速度\",{\"2\":{\"1178\":1}}],[\"训练速度快\",{\"2\":{\"867\":1,\"1451\":1}}],[\"训练方式\",{\"0\":{\"1162\":1}}],[\"训练方法改进\",{\"2\":{\"933\":1}}],[\"训练方法\",{\"2\":{\"503\":1,\"593\":1}}],[\"训练retriever\",{\"2\":{\"1075\":1}}],[\"训练范式采用预训练加zero\",{\"2\":{\"1059\":1}}],[\"训练范式\",{\"0\":{\"1049\":1,\"1228\":1},\"1\":{\"1093\":1,\"1142\":1,\"1193\":1}}],[\"训练语料库约24gb\",{\"2\":{\"1002\":1}}],[\"训练语言模型\",{\"2\":{\"381\":1}}],[\"训练数据与来源\",{\"0\":{\"1138\":1}}],[\"训练数据与方法\",{\"0\":{\"1052\":1}}],[\"训练数据策略\",{\"0\":{\"1114\":1}}],[\"训练数据及训练流程\",{\"2\":{\"1028\":1}}],[\"训练数据和测试数据可能存在较大的分布差异\",{\"2\":{\"949\":1}}],[\"训练数据\",{\"0\":{\"1117\":1,\"1211\":1},\"1\":{\"1167\":1},\"2\":{\"933\":1}}],[\"训练数据集内部重复\",{\"2\":{\"575\":1}}],[\"训练目标差异\",{\"2\":{\"1199\":1}}],[\"训练目标\",{\"0\":{\"925\":1}}],[\"训练与测试集的重复\",{\"2\":{\"575\":1}}],[\"训练迭代设置的重复\",{\"2\":{\"575\":1}}],[\"训练ocr模型\",{\"2\":{\"568\":1}}],[\"训练打分器的注意事项\",{\"0\":{\"507\":1}}],[\"训练监控\",{\"2\":{\"437\":1}}],[\"训练推理优化\",{\"0\":{\"193\":1}}],[\"训练过程变得更加稳定\",{\"2\":{\"2598\":1,\"2658\":1}}],[\"训练过程的稳定性\",{\"0\":{\"2598\":1,\"2658\":1}}],[\"训练过程的阶段划分\",{\"0\":{\"1230\":1}}],[\"训练过程\",{\"0\":{\"1043\":1},\"1\":{\"1087\":1,\"1134\":1}}],[\"训练过程中需要平衡提示多样性与数据新鲜性\",{\"2\":{\"2250\":1}}],[\"训练过程中冻结reward\",{\"2\":{\"1744\":1}}],[\"训练过程中\",{\"2\":{\"1533\":1,\"2177\":1}}],[\"训练过程中的异常监控将更加重要\",{\"2\":{\"700\":1}}],[\"训练过程中可能出现不稳定\",{\"2\":{\"169\":1}}],[\"训练过程是通过\",{\"2\":{\"123\":1}}],[\"训练较为稳定\",{\"2\":{\"169\":1}}],[\"训练初期不稳定\",{\"2\":{\"169\":1}}],[\"训练启动脚本\",{\"0\":{\"2101\":1},\"1\":{\"2151\":1,\"2194\":1,\"2233\":1,\"2268\":1,\"2301\":1,\"2332\":1,\"2362\":1,\"2391\":1},\"2\":{\"131\":1}}],[\"训练启动脚本|训练启动脚本\",{\"2\":{\"5\":1}}],[\"训练容灾及训练监控\",{\"0\":{\"410\":1},\"1\":{\"437\":1,\"464\":1,\"493\":1,\"525\":1,\"558\":1,\"593\":1,\"627\":1,\"662\":1,\"700\":1,\"736\":1},\"2\":{\"113\":1}}],[\"训练容灾及训练监控|训练容灾及训练监控\",{\"2\":{\"5\":1}}],[\"训练tokenizer\",{\"0\":{\"1058\":1},\"1\":{\"1103\":1,\"1153\":1,\"1202\":1,\"1253\":1,\"1302\":1,\"1349\":1,\"1394\":1,\"1442\":1,\"1487\":1,\"1531\":1,\"1580\":1,\"1632\":1,\"1686\":1,\"1742\":1,\"1800\":1},\"2\":{\"113\":1}}],[\"训练tokenizer|训练tokenizer\",{\"2\":{\"5\":1}}],[\"数秒到数十秒\",{\"2\":{\"1843\":1}}],[\"数量​\",{\"2\":{\"2228\":1}}],[\"数量输出\",{\"2\":{\"2228\":1}}],[\"数量tps\",{\"2\":{\"2228\":1}}],[\"数量ttft+tpot×输出\",{\"2\":{\"2228\":1}}],[\"数量呈正相关\",{\"2\":{\"2145\":1}}],[\"数量\",{\"2\":{\"1232\":1,\"1409\":2,\"2228\":6}}],[\"数更接近最大长度限制\",{\"2\":{\"813\":1}}],[\"数值范围更广\",{\"2\":{\"768\":1}}],[\"数值范围比\",{\"2\":{\"768\":1}}],[\"数值计算\",{\"2\":{\"641\":1}}],[\"数值越低表示模型预测越准确\",{\"2\":{\"583\":1}}],[\"数学\",{\"2\":{\"2424\":1}}],[\"数学推理和综合能力数据集\",{\"2\":{\"2399\":1}}],[\"数学和多语言数据\",{\"2\":{\"1130\":1}}],[\"数学预训练\",{\"0\":{\"962\":1}}],[\"数学等领域的预测任务\",{\"2\":{\"503\":1}}],[\"数学实现\",{\"0\":{\"263\":1}}],[\"数学表达以及其在实际应用中的特点\",{\"2\":{\"174\":1}}],[\"数字切分问题需特别关注\",{\"2\":{\"1632\":1}}],[\"数字切分错误\",{\"2\":{\"1394\":1}}],[\"数字卡牌游戏\",{\"2\":{\"1217\":1}}],[\"数字被分解为单独的字符\",{\"2\":{\"1112\":1}}],[\"数字跨度变大\",{\"2\":{\"292\":1}}],[\"数字输入的进制表示与直接外推\",{\"0\":{\"223\":1}}],[\"数字输入优化的核心方法\",{\"0\":{\"202\":1},\"1\":{\"223\":1,\"246\":1}}],[\"数字输入优化与外推方法解析\",{\"0\":{\"161\":1},\"1\":{\"181\":1,\"202\":1,\"223\":1,\"246\":1,\"269\":1,\"292\":1,\"314\":1,\"337\":1,\"361\":1},\"2\":{\"84\":1}}],[\"数字输入优化与外推方法解析|数字输入优化与外推方法解析\",{\"2\":{\"5\":1}}],[\"数字编码\",{\"2\":{\"181\":1}}],[\"数组基础\",{\"2\":{\"30\":1}}],[\"数据块的拆分\",{\"0\":{\"2549\":1}}],[\"数据索引优化\",{\"2\":{\"2484\":1}}],[\"数据汇总\",{\"2\":{\"2452\":1}}],[\"数据卸载策略\",{\"0\":{\"2447\":1}}],[\"数据独立计算梯度\",{\"2\":{\"2374\":1}}],[\"数据形式的多样化\",{\"0\":{\"2280\":1}}],[\"数据形式和数据语义三个维度\",{\"2\":{\"2165\":1}}],[\"数据存储和处理\",{\"2\":{\"2255\":1}}],[\"数据用途的多样化\",{\"0\":{\"2245\":1}}],[\"数据通信量分析\",{\"0\":{\"2241\":1},\"1\":{\"2276\":1,\"2308\":1,\"2339\":1,\"2369\":1,\"2397\":1,\"2422\":1,\"2447\":1,\"2468\":1,\"2486\":1}}],[\"数据反馈和增强\",{\"2\":{\"2255\":1}}],[\"数据反馈\",{\"2\":{\"2220\":1}}],[\"数据应用\",{\"2\":{\"2220\":1,\"2255\":1}}],[\"数据收集与处理\",{\"0\":{\"2504\":1}}],[\"数据收集\",{\"2\":{\"2220\":1,\"2255\":1}}],[\"数据在模型副本之间分摊\",{\"2\":{\"2178\":1}}],[\"数据并行是一种计算效率极高且实现简单的并行技术\",{\"2\":{\"2704\":1}}],[\"数据并行是一种常用的策略\",{\"2\":{\"2344\":1}}],[\"数据并行\",{\"0\":{\"2178\":1,\"2374\":1,\"2703\":1},\"1\":{\"2402\":1,\"2704\":1},\"2\":{\"2177\":1,\"2374\":1,\"2709\":2}}],[\"数据并行方式进行的训练\",{\"2\":{\"2079\":1}}],[\"数据的质量和多样性比数据量更为重要\",{\"2\":{\"2180\":1}}],[\"数据的质量和多样性直接影响模型的通用能力与性能\",{\"2\":{\"403\":1}}],[\"数据的质量和多样性直接影响模型的表现\",{\"2\":{\"369\":1}}],[\"数据的\",{\"2\":{\"2145\":1}}],[\"数据构造\",{\"2\":{\"2135\":1}}],[\"数据飞轮机制有助于持续优化模型\",{\"2\":{\"2383\":1}}],[\"数据飞轮在其他ai应用领域中有哪些潜在的应用\",{\"2\":{\"2382\":1}}],[\"数据飞轮在sft中的应用与优化\",{\"0\":{\"2083\":1},\"1\":{\"2134\":1,\"2180\":1,\"2220\":1,\"2255\":1,\"2290\":1,\"2321\":1,\"2352\":1,\"2382\":1,\"2409\":1,\"2434\":1},\"2\":{\"131\":1}}],[\"数据飞轮在sft中的应用与优化|数据飞轮在sft中的应用与优化\",{\"2\":{\"5\":1}}],[\"数据飞轮不仅限于模型训练\",{\"2\":{\"2352\":1}}],[\"数据飞轮将成为提高模型性能的重要工具\",{\"2\":{\"2321\":1}}],[\"数据飞轮通过收集真实用户的prompt\",{\"2\":{\"2220\":1}}],[\"数据飞轮的应用\",{\"2\":{\"2220\":1}}],[\"数据飞轮的使用能够提升prompt的多样性和质量\",{\"2\":{\"2180\":1}}],[\"数据飞轮\",{\"2\":{\"2134\":1}}],[\"数据生产合成的核心在于通过多样化的\",{\"2\":{\"2119\":1}}],[\"数据生产合成\",{\"0\":{\"2119\":1},\"1\":{\"2168\":1,\"2210\":1}}],[\"数据生产合成与质量过滤\",{\"0\":{\"2067\":1},\"1\":{\"2119\":1,\"2168\":1,\"2210\":1,\"2247\":1,\"2282\":1,\"2314\":1,\"2345\":1,\"2375\":1,\"2403\":1,\"2428\":1,\"2453\":1,\"2473\":1,\"2490\":1},\"2\":{\"131\":1}}],[\"数据生产合成与质量过滤|数据生产合成与质量过滤\",{\"2\":{\"5\":1}}],[\"数据隐私和安全保障\",{\"0\":{\"1718\":1}}],[\"数据安全至关重要\",{\"2\":{\"1512\":1}}],[\"数据安全性\",{\"0\":{\"1512\":1}}],[\"数据增强\",{\"0\":{\"1466\":1}}],[\"数据首先通过non\",{\"2\":{\"1456\":1}}],[\"数据文件类型的收集\",{\"2\":{\"1450\":1}}],[\"数据去污染策略有效防止了基准测试的污染\",{\"2\":{\"1430\":1}}],[\"数据去重流程\",{\"0\":{\"609\":1},\"1\":{\"644\":1}}],[\"数据去重的三大类别\",{\"0\":{\"541\":1},\"1\":{\"575\":1}}],[\"数据呈现\",{\"0\":{\"1373\":1}}],[\"数据和计算量增加\",{\"2\":{\"1297\":1}}],[\"数据和功能分离\",{\"2\":{\"12\":1}}],[\"数据实验表明\",{\"2\":{\"1297\":1}}],[\"数据转换\",{\"0\":{\"1226\":1,\"1318\":1,\"1395\":1,\"1409\":1,\"1490\":1,\"1960\":1,\"2065\":1,\"2069\":1,\"2090\":1,\"2092\":1,\"2143\":1,\"2254\":1,\"2338\":1,\"2446\":1,\"2479\":1,\"2482\":1,\"2520\":1,\"2532\":1,\"2564\":1,\"2614\":1}}],[\"数据库场景\",{\"2\":{\"1268\":1}}],[\"数据库和知识图谱属于编码类型\",{\"2\":{\"1217\":1}}],[\"数据库设计\",{\"2\":{\"54\":1}}],[\"数据混合策略通过对不同领域内容进行分类与平衡\",{\"2\":{\"1205\":1}}],[\"数据经过qwen2\",{\"2\":{\"1205\":1}}],[\"数据再利用\",{\"2\":{\"1181\":1}}],[\"数据过滤流程\",{\"0\":{\"1167\":1}}],[\"数据扩展\",{\"2\":{\"1130\":1}}],[\"数据\",{\"2\":{\"1114\":1,\"1232\":1,\"1436\":1,\"2474\":1}}],[\"数据合成和质量过滤技术将会更加智能化和自动化\",{\"2\":{\"2473\":1}}],[\"数据合成的重要性\",{\"2\":{\"2220\":1}}],[\"数据合成\",{\"2\":{\"1001\":1,\"2067\":1}}],[\"数据资源概览\",{\"0\":{\"741\":1}}],[\"数据比例如何影响继续预训练的效果\",{\"2\":{\"740\":1}}],[\"数据类型\",{\"2\":{\"2564\":1}}],[\"数据类型修改\",{\"2\":{\"2073\":1}}],[\"数据类型修改等\",{\"2\":{\"1972\":1}}],[\"数据类型会转换为\",{\"2\":{\"2059\":1}}],[\"数据类型与来源\",{\"0\":{\"690\":1}}],[\"数据类型对模型参数大小的影响\",{\"2\":{\"488\":1}}],[\"数据支持\",{\"0\":{\"591\":1}}],[\"数据重复类型\",{\"0\":{\"575\":1}}],[\"数据分发\",{\"2\":{\"2452\":1}}],[\"数据分析和洞察\",{\"2\":{\"2255\":1}}],[\"数据分析\",{\"2\":{\"2220\":1}}],[\"数据分布比例\",{\"0\":{\"803\":1}}],[\"数据分布\",{\"2\":{\"552\":1,\"655\":1,\"1138\":1}}],[\"数据分类器不要求特别精准\",{\"2\":{\"566\":1}}],[\"数据分类与配比方法\",{\"0\":{\"474\":1}}],[\"数据分类需精细化\",{\"2\":{\"422\":1}}],[\"数据采样与分布策略\",{\"0\":{\"772\":1},\"1\":{\"803\":1,\"837\":1,\"873\":1,\"909\":1}}],[\"数据采样\",{\"2\":{\"550\":1}}],[\"数据采集与处理\",{\"2\":{\"384\":1}}],[\"数据地址\",{\"2\":{\"549\":1}}],[\"数据来源包括30多种语言\",{\"2\":{\"1117\":1}}],[\"数据来源多样化将进一步增加去重难度\",{\"2\":{\"753\":1}}],[\"数据来源以及学习方式上存在显著差异\",{\"2\":{\"587\":1}}],[\"数据来源\",{\"2\":{\"535\":2,\"1211\":1,\"1290\":1}}],[\"数据组成形式\",{\"2\":{\"1199\":1}}],[\"数据组成\",{\"2\":{\"534\":1}}],[\"数据量达115万\",{\"2\":{\"2184\":1}}],[\"数据量与模型尺寸成反比\",{\"2\":{\"1282\":1}}],[\"数据量和模型尺寸之间存在紧密关系\",{\"2\":{\"1132\":1}}],[\"数据量级\",{\"2\":{\"535\":1}}],[\"数据量\",{\"2\":{\"534\":1,\"685\":1,\"1211\":1,\"1278\":1,\"1395\":1,\"1416\":1,\"1419\":1,\"2223\":1,\"2564\":1}}],[\"数据量分析\",{\"0\":{\"429\":1}}],[\"数据训练顺序需经过充分实验验证\",{\"2\":{\"566\":1}}],[\"数据训练顺序的重要性\",{\"2\":{\"533\":1}}],[\"数据训练顺序与课程学习\",{\"0\":{\"533\":1}}],[\"数据准备\",{\"2\":{\"516\":1,\"567\":1,\"1302\":1}}],[\"数据准备与增强\",{\"2\":{\"40\":1}}],[\"数据规模\",{\"2\":{\"1487\":1}}],[\"数据规模不必完全匹配\",{\"2\":{\"507\":1}}],[\"数据规模建议控制在约\",{\"2\":{\"474\":1}}],[\"数据需要约14\",{\"2\":{\"483\":1}}],[\"数据按照任务类型进行精细划分\",{\"2\":{\"474\":1}}],[\"数据点\",{\"2\":{\"471\":1}}],[\"数据处理步骤如下\",{\"2\":{\"929\":1}}],[\"数据处理的挑战\",{\"0\":{\"568\":1}}],[\"数据处理与特征工程\",{\"2\":{\"836\":1}}],[\"数据处理与筛选流程\",{\"0\":{\"532\":1}}],[\"数据处理与机器学习\",{\"2\":{\"398\":1}}],[\"数据处理\",{\"0\":{\"962\":1},\"2\":{\"424\":1,\"1101\":1,\"2220\":1}}],[\"数据处理工具\",{\"2\":{\"278\":1}}],[\"数据配比和顺序\",{\"2\":{\"705\":1}}],[\"数据配比和训练顺序至关重要\",{\"2\":{\"422\":1}}],[\"数据配比对不同任务类型的影响是否可以通过统一指标量化\",{\"2\":{\"705\":1}}],[\"数据配比对于模型性能影响显著\",{\"2\":{\"422\":1}}],[\"数据配比不合理可能导致领域知识注入不足或模型泛化能力下降\",{\"2\":{\"600\":1}}],[\"数据配比\",{\"2\":{\"396\":1}}],[\"数据配比与训练顺序优化指南\",{\"0\":{\"370\":1},\"1\":{\"396\":1,\"422\":1,\"447\":1,\"474\":1,\"501\":1,\"533\":1,\"566\":1,\"599\":1,\"633\":1,\"667\":1,\"705\":1},\"2\":{\"113\":1}}],[\"数据配比与训练顺序优化指南|数据配比与训练顺序优化指南\",{\"2\":{\"5\":1}}],[\"数据质量过滤通过指令辨别能力提高整体数据集质量\",{\"2\":{\"2428\":1}}],[\"数据质量过滤的关键在于根据指令跟踪难度筛选数据\",{\"2\":{\"2282\":1}}],[\"数据质量过滤\",{\"0\":{\"2247\":1},\"1\":{\"2282\":1,\"2314\":1}}],[\"数据质量比数量更重要\",{\"2\":{\"1357\":1}}],[\"数据质量评估与打分\",{\"0\":{\"451\":1},\"1\":{\"479\":1,\"507\":1}}],[\"数据质量直接影响模型性能\",{\"2\":{\"425\":1,\"601\":1}}],[\"数据质量\",{\"2\":{\"377\":1,\"685\":1,\"986\":1}}],[\"数据集格式与内容\",{\"0\":{\"2223\":1}}],[\"数据集应包含与模型水平相当的样本\",{\"2\":{\"1667\":1}}],[\"数据集大小\",{\"2\":{\"1341\":1}}],[\"数据集收集和清洗过程\",{\"0\":{\"1190\":1}}],[\"数据集来自reddit\",{\"2\":{\"1104\":1}}],[\"数据集名称\",{\"2\":{\"741\":1,\"837\":1,\"873\":1,\"909\":1,\"2223\":1}}],[\"数据集存在来源重复\",{\"2\":{\"575\":1}}],[\"数据集\",{\"2\":{\"375\":1,\"1516\":1,\"2194\":1,\"2338\":1}}],[\"数据集划分\",{\"2\":{\"349\":1}}],[\"数据集的加载与处理\",{\"2\":{\"349\":1}}],[\"数据集与实验设计\",{\"0\":{\"325\":1},\"1\":{\"349\":1,\"375\":1},\"2\":{\"578\":1}}],[\"数据科学与人工智能\",{\"2\":{\"2088\":1}}],[\"数据科学与机器学习基础\",{\"2\":{\"302\":1}}],[\"数据科学竞赛平台\",{\"2\":{\"544\":1}}],[\"数据科学\",{\"2\":{\"345\":1,\"2067\":1,\"2116\":1}}],[\"数据与模型尺寸的平衡\",{\"0\":{\"1282\":1}}],[\"数据与实验\",{\"0\":{\"1104\":1}}],[\"数据与采样\",{\"0\":{\"534\":1}}],[\"数据与趋势📈\",{\"0\":{\"471\":1}}],[\"数据与公式\",{\"0\":{\"374\":1,\"1390\":1},\"1\":{\"400\":1,\"427\":1,\"1437\":1,\"1483\":1}}],[\"数据与公式解读\",{\"0\":{\"235\":1},\"1\":{\"259\":1,\"283\":1,\"306\":1}}],[\"数据与示例\",{\"0\":{\"176\":1},\"1\":{\"197\":1,\"218\":1}}],[\"数据对比表\",{\"0\":{\"227\":1}}],[\"数据表格示例\",{\"0\":{\"346\":1,\"400\":1,\"595\":1,\"1323\":1,\"1487\":1}}],[\"数据表格\",{\"0\":{\"197\":1,\"305\":1,\"1186\":1,\"1290\":1,\"1292\":1,\"1326\":1,\"1341\":1,\"1360\":1,\"1393\":1,\"1398\":1,\"1416\":1,\"1419\":1,\"1483\":1,\"1499\":1,\"2347\":1}}],[\"数据总结与优势\",{\"0\":{\"155\":1}}],[\"数据清洗和去重算法将更加智能化\",{\"2\":{\"753\":1}}],[\"数据清洗中如何平衡\",{\"2\":{\"685\":1}}],[\"数据清洗技术将更加关注以下方向\",{\"2\":{\"650\":1}}],[\"数据清洗易犯错误\",{\"2\":{\"582\":1}}],[\"数据清洗是预训练模型构建过程中最重要的环节之一\",{\"2\":{\"403\":1}}],[\"数据清洗\",{\"0\":{\"352\":1,\"1234\":1},\"1\":{\"377\":1,\"403\":1,\"430\":1,\"456\":1,\"485\":1,\"515\":1,\"548\":1,\"582\":1,\"615\":1,\"650\":1,\"685\":1,\"1284\":1,\"1331\":1,\"1376\":1},\"2\":{\"113\":1,\"377\":1,\"398\":1}}],[\"数据清洗|数据清洗\",{\"2\":{\"5\":1}}],[\"数据爬取是现代信息处理的重要环节\",{\"2\":{\"411\":1}}],[\"数据爬取\",{\"0\":{\"357\":1},\"1\":{\"384\":1,\"411\":1,\"438\":1,\"465\":1,\"494\":1,\"526\":1,\"559\":1,\"594\":1,\"628\":1,\"663\":1,\"701\":1,\"737\":1},\"2\":{\"113\":1,\"384\":1}}],[\"数据爬取|数据爬取\",{\"2\":{\"5\":1}}],[\"数据充足\",{\"2\":{\"40\":1}}],[\"数据极少\",{\"2\":{\"40\":1}}],[\"数据没有标注\",{\"2\":{\"39\":1}}],[\"数据可视化\",{\"2\":{\"39\":1}}],[\"数据聚类\",{\"2\":{\"39\":1}}],[\"数据有明确的输入和输出标签\",{\"2\":{\"39\":1}}],[\"数据多样性将成为提升模型性能的关键因素之一\",{\"2\":{\"2426\":1}}],[\"数据多样性不仅提升模型泛化能力\",{\"2\":{\"369\":1}}],[\"数据多样性是大模型建设中的重要环节\",{\"2\":{\"369\":1}}],[\"数据多样性的核心价值\",{\"0\":{\"369\":1}}],[\"数据多样性\",{\"2\":{\"345\":1,\"2116\":1}}],[\"数据多样性探索\",{\"0\":{\"2063\":1},\"1\":{\"2116\":1,\"2165\":1,\"2208\":1,\"2245\":1,\"2280\":1,\"2312\":1,\"2343\":1,\"2373\":1,\"2401\":1,\"2426\":1,\"2451\":1},\"2\":{\"131\":1}}],[\"数据多样性探索|数据多样性探索\",{\"2\":{\"5\":1}}],[\"数据多样性与模型优化探索\",{\"0\":{\"345\":1},\"1\":{\"369\":1,\"395\":1,\"421\":1,\"446\":1,\"473\":1,\"500\":1,\"532\":1,\"565\":1,\"598\":1,\"632\":1,\"666\":1,\"704\":1},\"2\":{\"113\":1}}],[\"数据多样性与模型优化探索|数据多样性与模型优化探索\",{\"2\":{\"5\":1}}],[\"b×s+n\",{\"2\":{\"2676\":1}}],[\"b×s+nb\",{\"2\":{\"2676\":1}}],[\"b×s\",{\"2\":{\"2670\":1}}],[\"b×sb\",{\"2\":{\"2670\":1}}],[\"b×s×v\",{\"2\":{\"2660\":1,\"2676\":1}}],[\"b×s×vb\",{\"2\":{\"2660\":1,\"2676\":1}}],[\"b1\",{\"2\":{\"2526\":1}}],[\"b0\",{\"2\":{\"2526\":1}}],[\"bcnnd\",{\"2\":{\"2653\":1}}],[\"bc​nnd\",{\"2\":{\"2653\":1}}],[\"bc​br​n2br​bc​d\",{\"2\":{\"2643\":1}}],[\"bc​\",{\"2\":{\"2286\":2}}],[\"bc\",{\"2\":{\"2286\":2}}],[\"bcbrn2brbcd\",{\"2\":{\"2643\":1}}],[\"bcb\",{\"2\":{\"2286\":4,\"2318\":1,\"2379\":1}}],[\"bxb\",{\"2\":{\"2263\":1}}],[\"bge系列\",{\"2\":{\"2155\":1}}],[\"b∈rd×r\",{\"2\":{\"2013\":1}}],[\"b∈rd×rb\",{\"2\":{\"2013\":1}}],[\"bm25基于统计输入短语中的单词频率\",{\"2\":{\"1949\":1}}],[\"bm25\",{\"2\":{\"1949\":1}}],[\"bmatrix\",{\"2\":{\"247\":4,\"2537\":4}}],[\"bθ​\",{\"2\":{\"1901\":1,\"2520\":1,\"2532\":1}}],[\"bθ\",{\"2\":{\"1901\":1,\"2520\":1,\"2532\":1}}],[\"b←b−λη×gb​\",{\"2\":{\"1891\":1}}],[\"b←b−λη×gb\",{\"2\":{\"1891\":1}}],[\"brockman\",{\"2\":{\"2408\":1}}],[\"br​bc​d\",{\"2\":{\"2643\":2}}],[\"br​\",{\"2\":{\"2286\":1}}],[\"br\",{\"2\":{\"2286\":1}}],[\"brbcd\",{\"2\":{\"2643\":2}}],[\"brb\",{\"2\":{\"2286\":2,\"2318\":1,\"2379\":2}}],[\"brpo\",{\"2\":{\"2213\":1}}],[\"bradley\",{\"2\":{\"1461\":1,\"1536\":1}}],[\"britain\",{\"2\":{\"1458\":1}}],[\"break\",{\"2\":{\"647\":1,\"656\":2,\"1816\":1}}],[\"bucket\",{\"2\":{\"2308\":1}}],[\"bug\",{\"2\":{\"2118\":1}}],[\"budgeted\",{\"2\":{\"2455\":1}}],[\"budget\",{\"2\":{\"1658\":1}}],[\"bunny\",{\"2\":{\"1458\":1}}],[\"but\",{\"2\":{\"1458\":1}}],[\"buffer时\",{\"2\":{\"1270\":1}}],[\"buffer以处理溢出情况\",{\"2\":{\"1219\":1}}],[\"buffer来处理token溢出\",{\"2\":{\"1119\":1}}],[\"buffer的采样策略\",{\"2\":{\"842\":1}}],[\"buffer和target\",{\"2\":{\"808\":1}}],[\"buffer\",{\"0\":{\"712\":1,\"2356\":1},\"2\":{\"712\":1,\"1170\":1,\"2161\":1,\"2356\":1,\"2413\":1}}],[\"b6\",{\"2\":{\"1329\":2}}],[\"bb\",{\"2\":{\"1329\":2}}],[\"bbb\",{\"2\":{\"1279\":1,\"2062\":1,\"2115\":2,\"2145\":2,\"2425\":1,\"2609\":1,\"2616\":1}}],[\"bbpe算法\",{\"2\":{\"1002\":1}}],[\"bbpe是否能通过统一编码提升跨模态理解能力\",{\"2\":{\"469\":1}}],[\"bbpe是否能进一步优化以减少编码序列长度\",{\"2\":{\"469\":1}}],[\"bbpe代码实现示例\",{\"0\":{\"391\":1}}],[\"bbpe在多语言共享和压缩效率上的优势将进一步推动其应用\",{\"2\":{\"365\":1}}],[\"bbpe与bpe的对比\",{\"0\":{\"365\":1}}],[\"bbpe根据文本中的重复模式动态生成词汇表\",{\"2\":{\"318\":1}}],[\"bbpe的编码序列可能略长于传统bpe\",{\"2\":{\"341\":1}}],[\"bbpe的局限性与挑战\",{\"0\":{\"341\":1}}],[\"bbpe的主要特点和优势如下\",{\"2\":{\"318\":1}}],[\"bbpe的核心特点与优势\",{\"0\":{\"318\":1}}],[\"bbpe\",{\"0\":{\"250\":1,\"296\":1},\"1\":{\"273\":1,\"296\":1,\"318\":2,\"341\":2,\"365\":2,\"391\":2,\"417\":2,\"442\":2,\"469\":1},\"2\":{\"5\":1,\"273\":1,\"365\":1,\"631\":1,\"1225\":1,\"1302\":1,\"1531\":1}}],[\"bs=l⋅6\",{\"2\":{\"1297\":2}}],[\"bs\",{\"2\":{\"917\":3,\"1297\":1}}],[\"bf16=1024×1024×10242×params​\",{\"2\":{\"2192\":1}}],[\"bf16=2×params1024×1024×1024\",{\"2\":{\"2192\":1}}],[\"bf16和int8等\",{\"2\":{\"2192\":1}}],[\"bf16\",{\"2\":{\"768\":1,\"2118\":1,\"2192\":1,\"2233\":1}}],[\"bfloat16bfloat16bfloat16\",{\"2\":{\"1925\":1}}],[\"bfloat16\",{\"2\":{\"734\":1}}],[\"bleu\",{\"2\":{\"2292\":1}}],[\"bleu和bertscore\",{\"2\":{\"735\":1}}],[\"blank\",{\"2\":{\"1239\":1}}],[\"blackbox知识蒸馏\",{\"2\":{\"677\":1}}],[\"bloom\",{\"2\":{\"294\":1}}],[\"blocksq\",{\"2\":{\"2573\":2}}],[\"blocksk\",{\"2\":{\"2565\":2}}],[\"blocks\",{\"2\":{\"2539\":14,\"2549\":3,\"2565\":3,\"2573\":5,\"2618\":6,\"2623\":2,\"2628\":3}}],[\"block\",{\"2\":{\"18\":1,\"2085\":1,\"2286\":1,\"2539\":12,\"2549\":6,\"2597\":9,\"2604\":9,\"2618\":3,\"2653\":1}}],[\"bv14q4y1n7jz\",{\"2\":{\"559\":1}}],[\"bv1sz4y1u77n\",{\"2\":{\"559\":1}}],[\"bv1d54y1g7db\",{\"2\":{\"559\":1}}],[\"bound\",{\"2\":{\"2027\":2,\"2505\":1}}],[\"boundary\",{\"2\":{\"1665\":1}}],[\"both\",{\"2\":{\"1458\":1}}],[\"books\",{\"2\":{\"1458\":1}}],[\"books3\",{\"2\":{\"644\":1}}],[\"bool\",{\"2\":{\"783\":1,\"1731\":1,\"1928\":1,\"2400\":2}}],[\"booth\",{\"2\":{\"454\":1}}],[\"bold\",{\"2\":{\"18\":2,\"2050\":1}}],[\"bwd\",{\"2\":{\"435\":1}}],[\"b站\",{\"2\":{\"411\":1,\"559\":1}}],[\"bde\",{\"2\":{\"189\":1}}],[\"bne\",{\"2\":{\"189\":1}}],[\"bnd\",{\"2\":{\"189\":2}}],[\"b₂\",{\"2\":{\"178\":1}}],[\"b₁\",{\"2\":{\"178\":1}}],[\"bin\",{\"2\":{\"2347\":3}}],[\"binary\",{\"2\":{\"768\":1}}],[\"billion\",{\"2\":{\"2218\":1}}],[\"bigg\",{\"2\":{\"1795\":4}}],[\"biorxiv\",{\"2\":{\"1658\":1}}],[\"biobert\",{\"2\":{\"49\":1}}],[\"bitcount\",{\"2\":{\"768\":3}}],[\"bit\",{\"0\":{\"1588\":1},\"2\":{\"763\":1,\"1679\":1,\"1793\":1,\"1855\":1,\"2015\":1}}],[\"bias=lora\",{\"2\":{\"2425\":1}}],[\"bias=false\",{\"2\":{\"2425\":1}}],[\"bias动态路由达成自均衡负载\",{\"2\":{\"1277\":1}}],[\"bias\",{\"2\":{\"203\":1,\"293\":1,\"1156\":1,\"1831\":1,\"2425\":1}}],[\"bi\",{\"2\":{\"144\":1,\"207\":1}}],[\"bidirectional\",{\"2\":{\"115\":1,\"230\":1,\"919\":1}}],[\"bird\",{\"2\":{\"67\":1}}],[\"belle\",{\"2\":{\"1487\":1}}],[\"belle模型在120万行中文文本上训练了一个规模为5万的token集合\",{\"2\":{\"1442\":1}}],[\"between\",{\"2\":{\"1458\":1}}],[\"beta^\",{\"2\":{\"2046\":2}}],[\"betaβ的位置\",{\"2\":{\"2098\":1}}],[\"betaβ的大小\",{\"2\":{\"1033\":1}}],[\"betaβ系数误用\",{\"2\":{\"2098\":1}}],[\"betaβ值对奖励机制的影响\",{\"2\":{\"1961\":1}}],[\"betaβ自动调节专家负载\",{\"2\":{\"998\":1}}],[\"betaβ\",{\"2\":{\"709\":1,\"911\":1,\"1033\":1,\"1123\":1,\"1323\":1,\"1552\":1,\"1789\":1,\"1907\":1,\"1960\":1,\"2215\":1,\"2524\":1}}],[\"beta\",{\"2\":{\"221\":3,\"537\":1,\"590\":1,\"614\":1,\"998\":1,\"1162\":2,\"1204\":2,\"1207\":2,\"1353\":1,\"1552\":1,\"1628\":1,\"1657\":1,\"1676\":1,\"1685\":1,\"1712\":1,\"1720\":1,\"1731\":8,\"1732\":2,\"1795\":2,\"1830\":2,\"1889\":2,\"1994\":2,\"2012\":1,\"2044\":1,\"2046\":4,\"2097\":1,\"2485\":1,\"2577\":1}}],[\"be\",{\"2\":{\"917\":1}}],[\"best\",{\"0\":{\"528\":1},\"2\":{\"840\":1}}],[\"begin\",{\"2\":{\"247\":2,\"285\":1,\"762\":4,\"1344\":1,\"1364\":1,\"1795\":1,\"2537\":2}}],[\"benchmark上的性能随着训练进展而稳定提升\",{\"2\":{\"1915\":1}}],[\"benchmark测试结果如何反映在实际应用中\",{\"2\":{\"616\":1}}],[\"benchmark评估\",{\"0\":{\"549\":1}}],[\"benchmark\",{\"2\":{\"431\":1,\"583\":1,\"1436\":1}}],[\"benchmarks\",{\"2\":{\"153\":1}}],[\"bengio\",{\"2\":{\"165\":1}}],[\"beam大小\",{\"2\":{\"348\":1}}],[\"beams=3\",{\"2\":{\"324\":1}}],[\"beams\",{\"2\":{\"324\":4}}],[\"beam\",{\"0\":{\"324\":1},\"2\":{\"49\":1,\"229\":1,\"253\":1,\"324\":20,\"348\":1,\"400\":1,\"427\":1}}],[\"bert位置编码的限制\",{\"2\":{\"1463\":1}}],[\"bert位置编码\",{\"2\":{\"1373\":1}}],[\"bert的位置编码\",{\"2\":{\"1418\":1}}],[\"bert的位置编码方法更适合并行处理\",{\"2\":{\"1131\":1}}],[\"bert的可学习位置编码\",{\"0\":{\"1281\":1}}],[\"bert的可学习位置编码和基于rnn的递归式位置编码\",{\"2\":{\"1131\":1}}],[\"bert的输入编码向量由三个嵌入特征组成\",{\"2\":{\"956\":1}}],[\"bert通过双向语境学习解决了一词多义的问题\",{\"2\":{\"1126\":1}}],[\"bert通过成对的句子进行训练\",{\"2\":{\"1037\":1}}],[\"bert在词预测之前使用了额外的feed\",{\"2\":{\"932\":1}}],[\"bert可以学习更丰富的文本表征\",{\"2\":{\"919\":1}}],[\"bert结构的表征能力优于transformer\",{\"2\":{\"479\":1}}],[\"bert模型优先\",{\"2\":{\"479\":1}}],[\"bert论文\",{\"2\":{\"230\":1}}],[\"bert及其变体\",{\"2\":{\"115\":1}}],[\"bert与rnn位置编码的对比与应用\",{\"0\":{\"1042\":1},\"1\":{\"1085\":1,\"1131\":1,\"1182\":1,\"1231\":1,\"1281\":1,\"1328\":1,\"1373\":1,\"1418\":1,\"1463\":1,\"1507\":1,\"1555\":1,\"1606\":1},\"2\":{\"84\":1}}],[\"bert与rnn位置编码的对比与应用|bert与rnn位置编码的对比与应用\",{\"2\":{\"5\":1}}],[\"bert\",{\"0\":{\"956\":1},\"2\":{\"31\":1,\"34\":1,\"40\":3,\"49\":2,\"85\":1,\"115\":1,\"230\":1,\"316\":1,\"474\":1,\"544\":1,\"595\":1,\"862\":1,\"883\":1,\"919\":1,\"954\":1,\"1085\":1,\"1088\":1,\"1341\":1,\"1507\":1,\"1555\":1,\"1606\":1,\"2155\":1}}],[\"basics\",{\"2\":{\"2202\":1}}],[\"base上进行大规模强化学习\",{\"2\":{\"1146\":1}}],[\"base模型的encoder和decoder各有6层\",{\"2\":{\"932\":1}}],[\"based方法\",{\"0\":{\"991\":1},\"1\":{\"1032\":1,\"1075\":1}}],[\"based方法在复杂环境中的适用性\",{\"2\":{\"821\":1}}],[\"based与policy\",{\"2\":{\"821\":1}}],[\"based与model\",{\"2\":{\"821\":1}}],[\"based\",{\"0\":{\"811\":1,\"845\":1,\"880\":1,\"1906\":1,\"2054\":1},\"2\":{\"544\":1,\"621\":1,\"688\":1,\"724\":2,\"745\":1,\"776\":1,\"780\":3,\"807\":1,\"811\":1,\"845\":3,\"880\":1,\"1124\":1,\"1233\":4,\"1608\":1,\"1636\":1,\"1902\":1,\"1917\":1,\"1955\":1,\"2213\":1,\"2405\":1}}],[\"base\",{\"2\":{\"49\":1,\"1361\":1,\"1436\":1}}],[\"baxbaxbax\",{\"2\":{\"2115\":1}}],[\"ba\",{\"2\":{\"2013\":1}}],[\"bandwidth\",{\"2\":{\"1977\":2}}],[\"banana\",{\"2\":{\"985\":1,\"1025\":2}}],[\"babyai\",{\"2\":{\"1819\":1}}],[\"babyagi\",{\"2\":{\"1439\":1}}],[\"back\",{\"0\":{\"1774\":1},\"2\":{\"2202\":1}}],[\"backward\",{\"2\":{\"619\":2,\"640\":1,\"820\":1,\"2059\":1,\"2201\":2,\"2641\":1}}],[\"balanced\",{\"2\":{\"1302\":1,\"2213\":1}}],[\"bag\",{\"2\":{\"867\":1,\"870\":1,\"1354\":1}}],[\"baike\",{\"2\":{\"837\":1}}],[\"baidu\",{\"2\":{\"837\":1}}],[\"bailey\",{\"2\":{\"454\":1}}],[\"batch的激活值\",{\"2\":{\"2694\":1}}],[\"batch的梯度全是短文本的梯度\",{\"2\":{\"2310\":1}}],[\"batch从第一个设备流向最后一个设备\",{\"2\":{\"2691\":1}}],[\"batch=none\",{\"2\":{\"2600\":1}}],[\"batchsize\",{\"2\":{\"2108\":1}}],[\"batchsize=1\",{\"2\":{\"1843\":1}}],[\"batchnumber\",{\"2\":{\"1229\":1}}],[\"batch\",{\"0\":{\"227\":1,\"1297\":1},\"2\":{\"205\":2,\"227\":1,\"251\":1,\"275\":1,\"299\":1,\"324\":15,\"813\":2,\"917\":3,\"1197\":1,\"1229\":2,\"1297\":3,\"1482\":1,\"1577\":1,\"1629\":1,\"1646\":1,\"1868\":1,\"1912\":3,\"1978\":1,\"2027\":1,\"2217\":6,\"2233\":2,\"2263\":2,\"2374\":3,\"2519\":1,\"2688\":1,\"2691\":1}}],[\"bart在文本生成任务中的双向上下文语境信息是其优于gpt的一大创新点\",{\"2\":{\"1095\":1}}],[\"bart增加了双向上下文语境信息\",{\"2\":{\"932\":1}}],[\"bart使用gelu激活函数\",{\"2\":{\"932\":1}}],[\"bart采用标准的encoder\",{\"2\":{\"932\":1}}],[\"bart是一种基于transformer架构的模型\",{\"2\":{\"897\":1}}],[\"bart\",{\"0\":{\"827\":1},\"1\":{\"861\":1,\"897\":1,\"932\":1,\"970\":1,\"1011\":1,\"1051\":1,\"1095\":1,\"1144\":1},\"2\":{\"34\":1,\"172\":1,\"339\":1,\"595\":1,\"861\":1,\"932\":1}}],[\"bar\",{\"0\":{\"23\":1},\"2\":{\"19\":1,\"25\":1}}],[\"badge\",{\"2\":{\"18\":1}}],[\"b\",{\"2\":{\"10\":12,\"11\":2,\"12\":6,\"15\":2,\"18\":2,\"76\":2,\"123\":2,\"190\":1,\"199\":1,\"223\":2,\"290\":1,\"381\":1,\"391\":2,\"513\":1,\"837\":1,\"873\":1,\"909\":1,\"998\":1,\"1225\":2,\"1771\":2,\"1831\":1,\"1883\":1,\"1891\":2,\"1992\":3,\"2045\":3,\"2145\":1,\"2286\":3,\"2372\":2,\"2417\":2,\"2425\":1,\"2520\":1,\"2531\":1,\"2532\":1,\"2542\":1,\"2621\":1,\"2641\":1,\"2643\":13,\"2653\":1}}],[\"bpe如何适配不同语言的特性\",{\"2\":{\"631\":1}}],[\"bpe仅考虑当前最优合并对\",{\"2\":{\"562\":1}}],[\"bpe的操作步骤\",{\"0\":{\"392\":1}}],[\"bpe的核心思想\",{\"0\":{\"366\":1}}],[\"bpe从一个基础的小型词表出发\",{\"2\":{\"366\":1}}],[\"bpe通过贪婪算法逐步构建子词表\",{\"2\":{\"319\":1}}],[\"bpe\",{\"0\":{\"274\":1},\"1\":{\"297\":1,\"319\":1,\"342\":1,\"366\":1,\"392\":1,\"418\":1,\"443\":1,\"470\":1,\"497\":1,\"529\":1,\"562\":1,\"597\":1,\"631\":1},\"2\":{\"5\":2,\"273\":1,\"296\":1,\"297\":1,\"319\":1,\"320\":1,\"344\":1,\"365\":1,\"368\":1,\"420\":1,\"631\":1,\"933\":1,\"1096\":1,\"1531\":1}}],[\"byte\",{\"2\":{\"296\":1,\"308\":1,\"319\":1,\"368\":1,\"391\":2,\"393\":1,\"426\":1,\"469\":1,\"1302\":2}}],[\"by\",{\"0\":{\"120\":1,\"267\":1,\"359\":1},\"1\":{\"139\":1,\"159\":1,\"179\":1,\"200\":1,\"221\":1,\"244\":1,\"267\":1,\"290\":2,\"312\":2,\"335\":1,\"359\":1,\"386\":1,\"412\":1,\"439\":1,\"466\":1},\"2\":{\"5\":2,\"67\":3,\"84\":1,\"106\":3,\"159\":2,\"165\":3,\"184\":1,\"230\":1,\"302\":2,\"359\":1,\"386\":1,\"454\":2,\"1385\":1,\"1458\":4,\"1885\":3,\"2601\":1}}],[\"深入研究幂律定则在其他机器学习任务中的应用\",{\"2\":{\"1556\":1}}],[\"深入研究贝尔曼方程在不同环境中的应用\",{\"2\":{\"902\":1}}],[\"深入研究基于模糊匹配算法的数据去重方法\",{\"2\":{\"851\":1}}],[\"深入研究ocr模型训练方法\",{\"2\":{\"737\":1}}],[\"深入研究自动损失缩放算法\",{\"2\":{\"734\":1}}],[\"深入研究自监督学习在非语言任务\",{\"2\":{\"707\":1}}],[\"深入研究加权采样方法对模型微调效果的提升\",{\"2\":{\"704\":1}}],[\"深入研究\",{\"2\":{\"667\":1,\"738\":1,\"1140\":1}}],[\"深入研究ulm对多样性分词输出的具体应用场景\",{\"2\":{\"531\":1}}],[\"深入研究相对位置编码\",{\"2\":{\"383\":1}}],[\"深入研究masked\",{\"2\":{\"350\":1}}],[\"深入研究sandwich\",{\"2\":{\"282\":1}}],[\"深入研究sparse\",{\"2\":{\"281\":1}}],[\"深入分析s2\",{\"2\":{\"385\":1}}],[\"深入分析\",{\"2\":{\"334\":1}}],[\"深入探索dca在不同领域\",{\"2\":{\"240\":1}}],[\"深入理解\",{\"0\":{\"2339\":1},\"1\":{\"2369\":1,\"2397\":1,\"2422\":1,\"2447\":1,\"2468\":1,\"2486\":1},\"2\":{\"275\":1}}],[\"深入理解prompt到response的mdp模型分析\",{\"0\":{\"1519\":1},\"1\":{\"1568\":1,\"1618\":1,\"1673\":1,\"1729\":1,\"1787\":1,\"1848\":1,\"1905\":1,\"1958\":1,\"2009\":1,\"2058\":1,\"2111\":1},\"2\":{\"151\":1}}],[\"深入理解transformer机制\",{\"0\":{\"1027\":1},\"1\":{\"1070\":1,\"1116\":1,\"1166\":1,\"1215\":1,\"1266\":1,\"1313\":1,\"1359\":1,\"1405\":1,\"1452\":1,\"1499\":1,\"1543\":1,\"1593\":1,\"1647\":1},\"2\":{\"5\":1,\"84\":1}}],[\"深入理解transformer机制|相对位置编码与xlnet位置编码详解\",{\"2\":{\"5\":1}}],[\"深层模型容易出现梯度消失\",{\"2\":{\"169\":1}}],[\"深度提示优化的引入\",{\"2\":{\"1736\":1}}],[\"深度强化学习相关文档\",{\"2\":{\"913\":1}}],[\"深度神经网络的权重和激活值通常是不均匀的\",{\"2\":{\"868\":1}}],[\"深度神经网络常面临梯度消失或爆炸问题\",{\"2\":{\"183\":1}}],[\"深度理解\",{\"2\":{\"595\":1}}],[\"深度偏好优化\",{\"0\":{\"1432\":1},\"1\":{\"1477\":1,\"1521\":1,\"1570\":1,\"1620\":1,\"1675\":1,\"1731\":1,\"1789\":1,\"1850\":1,\"1907\":1,\"1960\":1,\"2012\":1,\"2061\":1},\"2\":{\"151\":1,\"1620\":1}}],[\"深度q网络\",{\"0\":{\"573\":1},\"1\":{\"606\":1,\"640\":1,\"674\":1,\"712\":1,\"746\":1,\"777\":1,\"808\":1,\"842\":1,\"877\":1,\"913\":1},\"2\":{\"151\":1,\"606\":1}}],[\"深度q网络|深度q网络\",{\"2\":{\"5\":1}}],[\"深度学习模型\",{\"2\":{\"2567\":1,\"2639\":1}}],[\"深度学习模型的规模呈指数级增长\",{\"2\":{\"728\":1}}],[\"深度学习损失函数解析\",{\"2\":{\"2061\":1}}],[\"深度学习显存优化\",{\"2\":{\"1919\":1}}],[\"深度学习显存优化与梯度处理\",{\"2\":{\"694\":1}}],[\"深度学习预训练策略文档\",{\"2\":{\"1577\":1}}],[\"深度学习相关文档与技术资料整理\",{\"2\":{\"406\":1}}],[\"深度学习框架将越来越注重对大规模模型加载和调试效率的优化\",{\"2\":{\"1700\":1}}],[\"深度学习框架\",{\"0\":{\"1214\":1},\"2\":{\"278\":1}}],[\"深度学习纳米学位\",{\"2\":{\"165\":1}}],[\"深度学习专项课程\",{\"2\":{\"165\":1}}],[\"深度学习基础\",{\"0\":{\"124\":1},\"1\":{\"144\":1,\"165\":1},\"2\":{\"132\":1,\"578\":1}}],[\"深度学习优化\",{\"2\":{\"104\":1,\"382\":1,\"405\":1,\"1086\":1,\"1604\":1,\"1969\":1,\"2225\":1}}],[\"深度学习技术报告及相关文档\",{\"2\":{\"685\":1}}],[\"深度学习技术\",{\"2\":{\"92\":1}}],[\"深度学习\",{\"0\":{\"44\":1,\"1214\":1},\"2\":{\"39\":1,\"71\":2,\"74\":1,\"80\":2,\"85\":1,\"87\":1,\"94\":1,\"96\":2,\"104\":1,\"110\":1,\"119\":1,\"142\":1,\"154\":1,\"165\":1,\"182\":1,\"328\":1,\"437\":1,\"573\":1,\"848\":1,\"883\":1,\"899\":1,\"922\":1,\"1000\":1,\"1044\":1,\"1063\":1,\"1070\":1,\"1085\":1,\"1086\":1,\"1098\":2,\"1148\":1,\"1486\":1,\"1497\":1,\"1521\":1,\"1532\":1,\"1567\":1,\"1568\":1,\"1599\":1,\"1604\":1,\"2047\":1,\"2101\":1,\"2467\":1,\"2567\":1,\"2639\":1}}],[\"深度学习中的强化学习优化\",{\"0\":{\"2467\":1},\"1\":{\"2485\":1,\"2500\":1,\"2513\":1,\"2524\":1}}],[\"深度学习中的人类偏好学习\",{\"2\":{\"1633\":1}}],[\"深度学习中的显存优化与梯度处理方法\",{\"0\":{\"379\":1},\"1\":{\"405\":1,\"433\":1,\"459\":1,\"488\":1,\"520\":1,\"553\":1,\"589\":1,\"622\":1,\"657\":1,\"694\":1,\"730\":1,\"765\":1},\"2\":{\"113\":1}}],[\"深度学习中的显存优化与梯度处理方法|深度学习中的显存优化与梯度处理方法\",{\"2\":{\"5\":1,\"660\":1}}],[\"深度学习中的位置嵌入优化\",{\"0\":{\"182\":1},\"1\":{\"203\":1,\"224\":1,\"247\":1,\"270\":1,\"293\":1,\"315\":1,\"338\":1,\"362\":1,\"388\":1,\"414\":1},\"2\":{\"5\":1,\"84\":1}}],[\"深度学习中的位置嵌入优化|旋转位置编码与alibi\",{\"2\":{\"5\":1}}],[\"深度学习中的layer\",{\"0\":{\"95\":1},\"1\":{\"110\":1,\"128\":1,\"148\":1,\"169\":1,\"190\":1,\"211\":1,\"234\":1,\"258\":1,\"282\":1},\"2\":{\"5\":1,\"73\":1}}],[\"深度学习中的注意力机制优化\",{\"0\":{\"82\":1},\"1\":{\"96\":1,\"111\":1,\"129\":1,\"149\":1,\"170\":1,\"191\":1,\"212\":1,\"235\":1,\"259\":1,\"283\":1,\"306\":1,\"329\":1,\"353\":1,\"378\":1,\"404\":1,\"432\":1},\"2\":{\"5\":1,\"63\":1}}],[\"深度解析语言模型采样方法\",{\"0\":{\"226\":1},\"1\":{\"249\":1,\"272\":1,\"295\":1,\"317\":1,\"340\":1,\"364\":1,\"390\":1,\"416\":1,\"441\":1,\"468\":1,\"496\":1,\"528\":1,\"561\":1,\"596\":1,\"630\":1,\"665\":1,\"703\":1,\"739\":1,\"771\":1},\"2\":{\"5\":1,\"98\":1}}],[\"t−βdkl\",{\"2\":{\"2577\":1}}],[\"t−1i​\",{\"2\":{\"2531\":1,\"2542\":1}}],[\"t−1i\",{\"2\":{\"2531\":1,\"2542\":1}}],[\"t∣q\",{\"2\":{\"2485\":4}}],[\"t∣1≤j≤nr\",{\"2\":{\"1364\":1}}],[\"tc​nd\",{\"2\":{\"2653\":2}}],[\"tcnd\",{\"2\":{\"2653\":2}}],[\"tc\",{\"2\":{\"2406\":2,\"2539\":2,\"2565\":1}}],[\"tct\",{\"2\":{\"2286\":2,\"2431\":1,\"2653\":1}}],[\"tp和dp\",{\"2\":{\"2711\":1}}],[\"tpot\",{\"2\":{\"2228\":3}}],[\"tps=ttft+tpot×输出\",{\"2\":{\"2228\":1}}],[\"tps=输出\",{\"2\":{\"2228\":1}}],[\"tps=总延迟时间\",{\"2\":{\"2228\":1}}],[\"tps=生成的\",{\"2\":{\"2228\":1}}],[\"tps\",{\"0\":{\"2189\":1,\"2228\":1,\"2263\":1},\"1\":{\"2228\":1},\"2\":{\"2228\":3}}],[\"tp\",{\"0\":{\"2218\":1},\"2\":{\"2081\":1,\"2710\":1}}],[\"tψt​\",{\"2\":{\"1942\":1,\"1992\":1,\"1993\":1,\"2045\":1}}],[\"two\",{\"2\":{\"1912\":1}}],[\"twitter\",{\"2\":{\"18\":1}}],[\"tvt​\",{\"2\":{\"1541\":1}}],[\"t​−βdkl​\",{\"2\":{\"2577\":1}}],[\"t​∣q\",{\"2\":{\"2485\":4}}],[\"t​∣1≤j≤nr​\",{\"2\":{\"1364\":1}}],[\"t​∈topk\",{\"2\":{\"1364\":1}}],[\"t​\",{\"2\":{\"1364\":1,\"2357\":2,\"2446\":4,\"2485\":6}}],[\"t​=std\",{\"2\":{\"2306\":1}}],[\"t​=\",{\"2\":{\"1364\":1}}],[\"t​ffni\",{\"2\":{\"1364\":1}}],[\"t∈topk\",{\"2\":{\"1364\":1}}],[\"tδt\",{\"2\":{\"1343\":1}}],[\"typesize\",{\"2\":{\"2192\":1}}],[\"type\",{\"2\":{\"1324\":1,\"2163\":1,\"2168\":1,\"2245\":1,\"2347\":1,\"2401\":1}}],[\"typename\",{\"2\":{\"15\":1}}],[\"ttft\",{\"2\":{\"2228\":3}}],[\"tt=t时\",{\"2\":{\"1732\":1}}],[\"tt=1→t\",{\"2\":{\"775\":1}}],[\"tt=t时\",{\"2\":{\"1732\":1}}],[\"ttt\",{\"2\":{\"1246\":1,\"1279\":1,\"1326\":1,\"2124\":1}}],[\"txt文件\",{\"2\":{\"2001\":1}}],[\"txt\",{\"2\":{\"1208\":2}}],[\"t=1\",{\"2\":{\"2485\":1,\"2577\":1}}],[\"t=1→tt\",{\"2\":{\"775\":1}}],[\"t=ri−mean\",{\"2\":{\"2306\":1}}],[\"t=\",{\"2\":{\"1364\":1}}],[\"t=0∑t​ψt​∇θ​logπθ​\",{\"2\":{\"1942\":1,\"1993\":1}}],[\"t=0∑t​\",{\"2\":{\"757\":1}}],[\"t=0\",{\"2\":{\"757\":1,\"1942\":2,\"1993\":2,\"2124\":1,\"2531\":1,\"2542\":1}}],[\"t|s\",{\"2\":{\"757\":1,\"1622\":4}}],[\"t+\",{\"2\":{\"1343\":1}}],[\"t+n\",{\"2\":{\"672\":2}}],[\"t+1\",{\"2\":{\"608\":1,\"611\":2,\"640\":1,\"672\":1,\"710\":1,\"748\":1,\"779\":2,\"1591\":1}}],[\"tst​\",{\"2\":{\"581\":1,\"1613\":1}}],[\"td误差目标\",{\"2\":{\"640\":1}}],[\"td与mc方法的比较\",{\"2\":{\"608\":1}}],[\"td与蒙特卡洛和动态规划的结合\",{\"2\":{\"608\":1}}],[\"td方法将会在更多复杂环境中展现其优势\",{\"2\":{\"784\":1}}],[\"td方法为强化学习提供了一种灵活且高效的策略学习途径\",{\"2\":{\"717\":1}}],[\"td方法使用即时奖励加上下一步状态价值的折扣和来估计当前状态的期望回报\",{\"2\":{\"608\":1}}],[\"td方法通过采样数据来学习策略\",{\"2\":{\"574\":1}}],[\"td\",{\"2\":{\"574\":1,\"577\":1,\"619\":5,\"640\":1,\"646\":2,\"766\":1,\"1225\":1,\"1645\":1}}],[\"tdpo在多样性输出上的优势使其在需要多种可能性探索的任务中表现更佳\",{\"2\":{\"1650\":1}}],[\"tdpo的优势\",{\"0\":{\"1650\":1}}],[\"tdpo采用forward\",{\"2\":{\"1596\":1}}],[\"tdpo与ppo中的kl约束\",{\"0\":{\"1596\":1}}],[\"tdpo\",{\"0\":{\"1546\":1},\"1\":{\"1596\":1,\"1650\":1,\"1703\":1,\"1761\":1,\"1821\":1,\"1880\":1},\"2\":{\"151\":1,\"1546\":1,\"1596\":1}}],[\"t^i\",{\"2\":{\"1942\":3,\"1993\":3,\"2531\":1,\"2542\":1}}],[\"t^+\",{\"2\":{\"1634\":4}}],[\"t^2\",{\"2\":{\"1536\":2}}],[\"t^1\",{\"2\":{\"1536\":4}}],[\"t^t\",{\"2\":{\"1343\":2}}],[\"t^c\",{\"2\":{\"283\":2}}],[\"t^\",{\"2\":{\"283\":3,\"778\":1,\"1634\":2}}],[\"t⋅dk​​qmt​kn​​\",{\"2\":{\"228\":1}}],[\"t⋅qmtkndk\",{\"2\":{\"228\":1}}],[\"tgi\",{\"0\":{\"1725\":1},\"1\":{\"1782\":1,\"1843\":1},\"2\":{\"193\":1}}],[\"t1​=0\",{\"2\":{\"184\":1,\"276\":1}}],[\"t$$为即时奖励\",{\"2\":{\"611\":1}}],[\"t$$\",{\"2\":{\"184\":1,\"276\":1,\"778\":1}}],[\"trl实现中省略了多次更新epoch的步骤\",{\"2\":{\"2577\":1}}],[\"trl实现的简化\",{\"0\":{\"2577\":1}}],[\"trl库中的grpo实现\",{\"2\":{\"2524\":1}}],[\"trl\",{\"2\":{\"2500\":1}}],[\"trlx\",{\"2\":{\"2081\":2}}],[\"tr\",{\"2\":{\"2406\":2,\"2539\":2,\"2573\":1}}],[\"trt\",{\"2\":{\"2286\":1,\"2431\":1}}],[\"trt​\",{\"2\":{\"2124\":1}}],[\"tree\",{\"0\":{\"2094\":1},\"2\":{\"1420\":1,\"1917\":3,\"1990\":1,\"2094\":1,\"2378\":1}}],[\"trends\",{\"2\":{\"153\":1}}],[\"tricks\",{\"2\":{\"1354\":1,\"1997\":1}}],[\"trial\",{\"2\":{\"572\":1}}],[\"trust\",{\"2\":{\"1596\":1}}],[\"truth\",{\"2\":{\"699\":1}}],[\"true\",{\"2\":{\"526\":1,\"656\":2,\"1928\":1,\"2400\":1}}],[\"tradition\",{\"2\":{\"1458\":2}}],[\"trafilatura\",{\"2\":{\"485\":3}}],[\"trafilatura库\",{\"2\":{\"485\":1}}],[\"trans\",{\"2\":{\"1912\":2}}],[\"transformation\",{\"2\":{\"1650\":1}}],[\"transformerblock中的通信优化\",{\"0\":{\"2679\":1}}],[\"transformer处理输入\",{\"2\":{\"1704\":1}}],[\"transformer文档\",{\"2\":{\"1417\":1}}],[\"transformer在不同任务中的应用效果\",{\"2\":{\"1417\":1}}],[\"transformer位置编码是通过正弦函数和余弦函数交替生成的\",{\"2\":{\"1246\":1}}],[\"transformer通过将transformer每层的ffn替换为moe层\",{\"2\":{\"1129\":1}}],[\"transformer实现了性能提升\",{\"2\":{\"1040\":1}}],[\"transformer是一种基于t5开发的encoder\",{\"2\":{\"1040\":1}}],[\"transformer中的张量并行\",{\"0\":{\"2563\":1},\"1\":{\"2571\":1,\"2579\":1}}],[\"transformer中的大部分计算操作的瓶颈是显存访问\",{\"2\":{\"1869\":1}}],[\"transformer中的位置编码机制\",{\"2\":{\"409\":1}}],[\"transformer中的attention机制解析\",{\"2\":{\"350\":1}}],[\"transformer中的attention详解与应用指南\",{\"0\":{\"70\":1},\"1\":{\"80\":1,\"93\":1,\"108\":1,\"126\":1,\"146\":1,\"167\":1,\"188\":1,\"209\":1,\"232\":1,\"256\":1,\"280\":1,\"304\":1,\"326\":1,\"350\":1},\"2\":{\"63\":1}}],[\"transformer中的attention详解与应用指南|transformer中的attention详解与应用指南\",{\"2\":{\"5\":1}}],[\"transformer中使用正弦函数\",{\"2\":{\"263\":1}}],[\"transformer论文\",{\"2\":{\"230\":1}}],[\"transformer模型的self\",{\"2\":{\"1807\":1}}],[\"transformer模型中的绝对位置编码是通过正弦和余弦函数构造的一种固定编码方式\",{\"2\":{\"1147\":1}}],[\"transformer模型中的attention机制是深度学习领域的一项重要技术\",{\"2\":{\"93\":1}}],[\"transformer模型与rnn不同\",{\"2\":{\"216\":1}}],[\"transformer优化\",{\"2\":{\"94\":1,\"96\":1}}],[\"transformer绝对位置编码详解与改进分析\",{\"0\":{\"1054\":1},\"1\":{\"1098\":1,\"1147\":1,\"1196\":1,\"1246\":1,\"1296\":1,\"1343\":1,\"1388\":1,\"1435\":1,\"1481\":1},\"2\":{\"84\":1}}],[\"transformer绝对位置编码详解与改进分析|transformer绝对位置编码详解与改进分析\",{\"2\":{\"5\":1}}],[\"transformers高24倍的吞吐量\",{\"2\":{\"1808\":1}}],[\"transformers库文档\",{\"2\":{\"230\":1}}],[\"transformers\",{\"2\":{\"65\":1,\"115\":1,\"230\":1,\"919\":1}}],[\"transformer\",{\"0\":{\"29\":1,\"34\":1,\"959\":1},\"1\":{\"34\":1,\"40\":1,\"49\":1,\"57\":1,\"65\":1,\"1000\":1,\"1040\":1,\"1083\":1,\"1129\":1,\"1180\":1,\"1229\":1,\"1279\":1,\"1326\":1,\"1371\":1,\"1417\":1},\"2\":{\"57\":1,\"65\":1,\"80\":1,\"92\":1,\"104\":1,\"115\":1,\"121\":1,\"154\":1,\"162\":2,\"172\":1,\"182\":1,\"225\":1,\"299\":1,\"467\":1,\"560\":1,\"861\":1,\"887\":1,\"901\":1,\"917\":1,\"930\":1,\"990\":1,\"1000\":1,\"1017\":1,\"1055\":1,\"1070\":1,\"1098\":1,\"1225\":2,\"1328\":1,\"1493\":1,\"1537\":1,\"1555\":1,\"1587\":1,\"1615\":1,\"1647\":1,\"1689\":1,\"1722\":1,\"1785\":1,\"2066\":1,\"2201\":1,\"2218\":1,\"2545\":1}}],[\"transformer架构包含了self\",{\"2\":{\"2563\":1}}],[\"transformer架构\",{\"2\":{\"28\":1}}],[\"transformer核心模块解析\",{\"0\":{\"89\":1},\"1\":{\"104\":1,\"121\":1,\"141\":1,\"162\":1,\"183\":1,\"205\":1,\"227\":1,\"251\":1,\"275\":1,\"299\":1},\"2\":{\"5\":1,\"73\":1}}],[\"transfer\",{\"2\":{\"901\":1}}],[\"transition\",{\"2\":{\"619\":6,\"640\":6,\"766\":6,\"820\":4}}],[\"translation\",{\"2\":{\"469\":1,\"631\":1}}],[\"transpose\",{\"2\":{\"135\":1}}],[\"trainer\",{\"2\":{\"1832\":2}}],[\"trained\",{\"2\":{\"115\":1}}],[\"train\",{\"2\":{\"475\":1,\"1208\":2,\"1460\":1,\"1646\":2,\"2079\":1,\"2201\":1,\"2223\":1,\"2233\":3}}],[\"training提高推理任务准确性\",{\"2\":{\"1013\":1}}],[\"training\",{\"0\":{\"113\":1,\"1160\":1,\"1260\":1},\"2\":{\"5\":20,\"230\":1,\"240\":1,\"660\":1,\"685\":1,\"819\":1,\"1308\":1,\"1385\":1,\"1917\":1,\"1971\":1,\"2218\":1,\"2253\":1,\"2449\":1}}],[\"ti​\",{\"2\":{\"2531\":1,\"2542\":1}}],[\"ti\",{\"2\":{\"2531\":1,\"2542\":1}}],[\"tilling\",{\"0\":{\"2492\":1},\"1\":{\"2505\":1,\"2517\":1,\"2528\":1,\"2539\":1,\"2549\":1},\"2\":{\"2492\":1}}],[\"tiling分块计算使得可以用一个cuda\",{\"2\":{\"2080\":1}}],[\"tiling\",{\"0\":{\"1810\":1},\"2\":{\"1957\":1,\"2110\":1}}],[\"title\",{\"2\":{\"1368\":1,\"1458\":1}}],[\"ti+k​\",{\"2\":{\"1127\":1}}],[\"ti+k\",{\"2\":{\"1127\":1}}],[\"time\",{\"2\":{\"1013\":2,\"2228\":2}}],[\"times\",{\"2\":{\"147\":1,\"259\":6,\"1050\":1,\"1229\":1,\"1232\":8,\"1297\":1,\"1329\":1,\"1455\":4,\"1756\":1,\"1891\":2,\"1991\":1,\"2013\":3,\"2023\":1,\"2080\":5,\"2192\":13,\"2217\":2,\"2228\":2,\"2263\":6,\"2433\":1,\"2604\":2,\"2618\":3,\"2643\":4,\"2653\":2,\"2660\":2,\"2670\":1,\"2676\":3}}],[\"tinybert\",{\"2\":{\"57\":1,\"954\":1}}],[\"tffni\",{\"2\":{\"1364\":1}}],[\"tflops\",{\"2\":{\"1232\":1}}],[\"tf\",{\"2\":{\"59\":1}}],[\"turn\",{\"2\":{\"2417\":1,\"2482\":1}}],[\"turbo经过四个阶段达到256k\",{\"2\":{\"1305\":1}}],[\"turbo经过四个阶段训练\",{\"2\":{\"1256\":1}}],[\"turbo和qwen2\",{\"2\":{\"1156\":1}}],[\"turbo\",{\"2\":{\"49\":1,\"1398\":1}}],[\"tuple\",{\"2\":{\"1731\":1}}],[\"tupe\",{\"2\":{\"1493\":1,\"1587\":1}}],[\"tuners\",{\"2\":{\"2048\":1,\"2142\":1}}],[\"tuned\",{\"2\":{\"1403\":1}}],[\"tune\",{\"2\":{\"1224\":2}}],[\"tuning通过优化embedding层而非整个模型\",{\"2\":{\"1967\":1}}],[\"tuning通过在输入token前构造任务相关的连续virtual\",{\"2\":{\"1865\":1}}],[\"tuning通过在transformer层中加入额外模块进行微调\",{\"2\":{\"1722\":1}}],[\"tuning的具体实现\",{\"2\":{\"2215\":1}}],[\"tuning的实现及其对gpt性能提升的作用\",{\"2\":{\"2121\":1}}],[\"tuning的实现\",{\"0\":{\"1865\":1}}],[\"tuning的核心思想\",{\"2\":{\"1722\":1}}],[\"tuning采用了一层rnn作为prompt\",{\"2\":{\"1796\":1}}],[\"tuning是一种通过在输入token前构造任务相关的连续virtual\",{\"2\":{\"1745\":1}}],[\"tuning是一种通过优化embedding层来增强gpt在自然语言理解任务中的方法\",{\"2\":{\"1738\":1}}],[\"tuning是一种通过引入额外模块来适配下游任务的方法\",{\"2\":{\"1668\":1}}],[\"tuning方法的改进\",{\"2\":{\"1668\":1}}],[\"tuning\",{\"0\":{\"1209\":1,\"1588\":1,\"1625\":1,\"1627\":1,\"1635\":1,\"1640\":1,\"1873\":1},\"1\":{\"1680\":1,\"1682\":1,\"1689\":1,\"1694\":1,\"1736\":1,\"1738\":1,\"1745\":1,\"1752\":1,\"1794\":1,\"1796\":1,\"1803\":1,\"1812\":1,\"1856\":1,\"1858\":1,\"1865\":1,\"1873\":1,\"1912\":1,\"1914\":1,\"1922\":1,\"1930\":1,\"1965\":1,\"1967\":1,\"1974\":1,\"1981\":1,\"2017\":1,\"2019\":1,\"2024\":1,\"2032\":1,\"2069\":1,\"2074\":1,\"2082\":1,\"2121\":1,\"2126\":1,\"2133\":1,\"2173\":1,\"2179\":1,\"2215\":1,\"2219\":1,\"2254\":1,\"2289\":1},\"2\":{\"57\":1,\"101\":1,\"151\":4,\"1213\":1,\"1582\":1,\"1615\":1,\"1625\":1,\"1680\":2,\"1682\":1,\"1689\":2,\"1694\":1,\"1752\":1,\"1794\":1,\"1867\":2,\"1873\":1,\"1912\":2,\"1917\":1,\"2017\":2,\"2032\":1,\"2151\":1,\"2179\":1,\"2278\":1,\"2289\":2}}],[\"t5对相对位置\",{\"2\":{\"1258\":1}}],[\"t5采用掩码语言模型的方法进行训练\",{\"2\":{\"1062\":1}}],[\"t5还贡献了一个名为c4\",{\"2\":{\"1019\":1}}],[\"t5主要关注以下四个任务\",{\"2\":{\"1019\":1}}],[\"t5的训练方式类似于bert\",{\"2\":{\"901\":1}}],[\"t5模型实现了更高效的注意力机制\",{\"2\":{\"1207\":1}}],[\"t5模型通过统一的文本到文本转换方法简化了多任务处理流程\",{\"2\":{\"1206\":1}}],[\"t5模型采用了一种简化的相对位置编码方式\",{\"2\":{\"1108\":1}}],[\"t5模型的相对位置编码基于以下公式\",{\"2\":{\"1207\":1}}],[\"t5模型的基本思想是将自然语言问题转化为\",{\"2\":{\"978\":1}}],[\"t5模型的核心思想\",{\"0\":{\"978\":1}}],[\"t5模型\",{\"2\":{\"865\":1,\"1063\":1}}],[\"t5模型与相对位置编码优化解析\",{\"0\":{\"1020\":1},\"1\":{\"1063\":1,\"1108\":1,\"1158\":1,\"1207\":1,\"1258\":1,\"1306\":1,\"1353\":1,\"1399\":1,\"1447\":1,\"1493\":1,\"1537\":1,\"1587\":1},\"2\":{\"84\":1}}],[\"t5模型与相对位置编码优化解析|t5模型与相对位置编码优化解析\",{\"2\":{\"5\":1}}],[\"t5\",{\"0\":{\"830\":1},\"1\":{\"865\":1,\"901\":1,\"936\":1,\"978\":1,\"1019\":1,\"1062\":1,\"1107\":1,\"1157\":1,\"1206\":1,\"1257\":1},\"2\":{\"31\":1,\"34\":1,\"49\":1,\"172\":1,\"339\":2,\"575\":1,\"595\":1,\"901\":1,\"1381\":1,\"1493\":2,\"1537\":1,\"1587\":3}}],[\"tot\",{\"0\":{\"2094\":1},\"2\":{\"1917\":1,\"1990\":1,\"2094\":3,\"2144\":1,\"2188\":2}}],[\"total\",{\"2\":{\"917\":3,\"1127\":1}}],[\"torl\",{\"0\":{\"1630\":1},\"1\":{\"1684\":1,\"1740\":1},\"2\":{\"1684\":1}}],[\"torchtitan\",{\"2\":{\"2118\":1}}],[\"torch\",{\"2\":{\"135\":4,\"189\":3,\"266\":4,\"324\":4,\"364\":2,\"619\":13,\"640\":7,\"766\":15,\"820\":9,\"996\":2,\"1622\":6,\"1703\":2,\"1731\":7,\"1817\":6,\"1883\":4,\"1912\":9,\"1928\":4,\"2108\":1,\"2201\":6,\"2252\":2,\"2381\":1,\"2500\":3,\"2539\":19,\"2549\":3,\"2561\":3,\"2581\":1,\"2589\":1,\"2597\":4,\"2604\":3,\"2611\":1,\"2618\":2,\"2628\":3}}],[\"toys\",{\"2\":{\"1458\":1}}],[\"toollearning\",{\"2\":{\"2384\":1}}],[\"toolkit\",{\"2\":{\"1612\":1}}],[\"toolkengpt\",{\"2\":{\"1569\":1}}],[\"toolformer\",{\"2\":{\"1569\":1}}],[\"tool\",{\"0\":{\"1520\":1,\"1619\":1,\"1788\":1,\"2269\":1},\"1\":{\"1569\":1,\"1619\":1},\"2\":{\"1701\":1,\"1788\":1}}],[\"toolemu包括以下两个主要模块\",{\"2\":{\"1407\":1}}],[\"toolemu主要是对基于大模型agent的安全性进行测试\",{\"2\":{\"1361\":1}}],[\"toolemu\",{\"0\":{\"1315\":1},\"1\":{\"1361\":1,\"1407\":1}}],[\"tools\",{\"2\":{\"1008\":1}}],[\"token生成\",{\"2\":{\"2261\":1}}],[\"token可能导致优化到局部最优值\",{\"2\":{\"1914\":1}}],[\"token可以看成字节\",{\"2\":{\"750\":1}}],[\"token的数量及past\",{\"2\":{\"1912\":1}}],[\"token的部分参数\",{\"2\":{\"1858\":1}}],[\"token的kl约束项\",{\"2\":{\"1522\":1,\"1621\":1,\"1790\":1}}],[\"token的预训练数据\",{\"2\":{\"1211\":1}}],[\"token上下文长度\",{\"2\":{\"1256\":1,\"1305\":1}}],[\"token数量\",{\"2\":{\"1232\":2,\"1326\":1,\"1360\":1}}],[\"token嵌入\",{\"2\":{\"956\":1,\"1226\":1}}],[\"token奖励\",{\"2\":{\"478\":1}}],[\"tokenize\",{\"2\":{\"508\":1,\"1612\":1,\"1665\":1}}],[\"tokenizer训练步骤\",{\"0\":{\"1302\":1}}],[\"tokenizer的作用与训练方法\",{\"0\":{\"1253\":1},\"1\":{\"1302\":1}}],[\"tokenizer的训练与优化直接影响模型的性能与适用性\",{\"2\":{\"1153\":1}}],[\"tokenizer使用bbpe\",{\"2\":{\"1156\":1}}],[\"tokenizer由sentencepiece更换为tiktoken\",{\"2\":{\"1071\":1}}],[\"tokenizer\",{\"2\":{\"508\":2,\"1103\":1,\"1253\":1}}],[\"tokenizers\",{\"2\":{\"480\":2,\"508\":2}}],[\"tokenizers库文档\",{\"2\":{\"719\":1}}],[\"tokenizers库如何与主流深度学习框架\",{\"2\":{\"719\":1}}],[\"tokenizers库的学习曲线稍陡\",{\"2\":{\"610\":1}}],[\"tokenizers库的编码流程\",{\"0\":{\"452\":1},\"1\":{\"480\":1,\"508\":1,\"542\":1}}],[\"tokenizers库灵活可扩展\",{\"2\":{\"610\":1}}],[\"tokenizers库在文本分词时\",{\"2\":{\"452\":1}}],[\"tokenizers库\",{\"2\":{\"347\":1,\"373\":1}}],[\"tokenization\",{\"0\":{\"508\":1},\"2\":{\"286\":1,\"426\":1,\"490\":1}}],[\"tokens=false\",{\"2\":{\"2500\":1}}],[\"tokens不对应于真实tokens\",{\"2\":{\"1865\":1}}],[\"tokens作为prefix\",{\"2\":{\"1865\":1,\"2074\":1}}],[\"tokens作为prefix的方法\",{\"2\":{\"1745\":1}}],[\"tokens量级的数据进行预训练\",{\"2\":{\"1205\":1}}],[\"tokens和zero\",{\"2\":{\"1072\":1}}],[\"tokens数量\",{\"2\":{\"837\":1,\"873\":1,\"909\":1}}],[\"tokens计算相似度\",{\"2\":{\"532\":1}}],[\"tokens\",{\"2\":{\"218\":3,\"324\":6,\"535\":2,\"1117\":1,\"1170\":1,\"1229\":2,\"1282\":2,\"1324\":1,\"1419\":1,\"1752\":1,\"1856\":1,\"1873\":2,\"1912\":6,\"2082\":1,\"2228\":1}}],[\"token\",{\"0\":{\"537\":1,\"981\":1,\"2145\":1,\"2559\":1,\"2591\":1,\"2634\":1,\"2654\":1},\"1\":{\"2567\":1,\"2575\":1,\"2583\":1,\"2591\":1,\"2598\":1,\"2605\":1,\"2612\":1,\"2619\":1,\"2624\":1,\"2629\":1,\"2639\":1,\"2644\":1,\"2649\":1,\"2654\":1,\"2658\":1,\"2662\":1,\"2665\":1,\"2668\":1,\"2671\":1,\"2674\":1},\"2\":{\"121\":1,\"162\":4,\"251\":1,\"324\":3,\"391\":2,\"424\":1,\"427\":3,\"449\":1,\"503\":1,\"594\":1,\"782\":1,\"813\":2,\"847\":1,\"881\":4,\"981\":1,\"1114\":1,\"1225\":2,\"1232\":1,\"1249\":2,\"1256\":2,\"1305\":2,\"1409\":2,\"1676\":1,\"1703\":2,\"1762\":1,\"1912\":1,\"1936\":3,\"1941\":1,\"1982\":1,\"2081\":1,\"2145\":8,\"2163\":1,\"2228\":17,\"2286\":3,\"2417\":3,\"2482\":1,\"2500\":1,\"2561\":6,\"2567\":1,\"2570\":2,\"2578\":1,\"2591\":1,\"2600\":1,\"2608\":1,\"2624\":1,\"2639\":1,\"2654\":1,\"2671\":1}}],[\"to\",{\"2\":{\"18\":4,\"619\":8,\"640\":6,\"766\":8,\"820\":4,\"901\":1,\"917\":1,\"1008\":1,\"1025\":4,\"1083\":1,\"1368\":1,\"1458\":5,\"1912\":2,\"1928\":1,\"1971\":1,\"2050\":1,\"2085\":1,\"2201\":3,\"2202\":1,\"2228\":1,\"2539\":3}}],[\"tolong\",{\"2\":{\"18\":1}}],[\"topk\",{\"0\":{\"2000\":1},\"2\":{\"1364\":1,\"1928\":5,\"2000\":2}}],[\"top\",{\"0\":{\"226\":2,\"272\":1,\"317\":1},\"1\":{\"249\":2,\"272\":2,\"295\":3,\"317\":2,\"340\":3,\"364\":3,\"390\":2,\"416\":2,\"441\":2,\"468\":2,\"496\":2,\"528\":2,\"561\":2,\"596\":2,\"630\":2,\"665\":2,\"703\":2,\"739\":2,\"771\":2},\"2\":{\"5\":4,\"98\":2,\"295\":1,\"340\":1,\"427\":1,\"468\":2,\"1207\":2,\"1266\":1,\"1359\":9,\"1535\":1,\"1671\":4,\"1928\":2,\"1936\":1,\"2140\":3}}],[\"ta\",{\"2\":{\"2357\":1}}],[\"table\",{\"2\":{\"646\":5,\"840\":4}}],[\"tables\",{\"2\":{\"18\":1,\"2050\":1}}],[\"targets\",{\"2\":{\"640\":2,\"2201\":4}}],[\"target\",{\"0\":{\"746\":1},\"2\":{\"619\":3,\"640\":6,\"766\":1,\"2400\":1}}],[\"take\",{\"2\":{\"619\":1,\"640\":1,\"646\":1,\"766\":1,\"820\":1,\"840\":1}}],[\"tat​\",{\"2\":{\"581\":1,\"1613\":1}}],[\"tanh等\",{\"2\":{\"2526\":1}}],[\"tanh\",{\"0\":{\"215\":1},\"2\":{\"199\":1,\"330\":1,\"1912\":1}}],[\"tail\",{\"2\":{\"48\":6}}],[\"tasks\",{\"2\":{\"2368\":1,\"2433\":2}}],[\"taskweaver同样是一种类似pal的方法\",{\"2\":{\"1849\":1}}],[\"taskweaver\",{\"0\":{\"1849\":1}}],[\"task\",{\"0\":{\"1368\":1},\"2\":{\"18\":4,\"1762\":1,\"2163\":1,\"2168\":1,\"2245\":1,\"2401\":1}}],[\"ten\",{\"2\":{\"2433\":1}}],[\"tensors=\",{\"2\":{\"2500\":1}}],[\"tensor\",{\"0\":{\"939\":1,\"1065\":1,\"2218\":1,\"2515\":1},\"1\":{\"2526\":1,\"2537\":1},\"2\":{\"266\":2,\"462\":1,\"619\":6,\"640\":6,\"698\":1,\"766\":6,\"820\":3,\"996\":1,\"1022\":1,\"1065\":1,\"1389\":1,\"1451\":1,\"1592\":1,\"1622\":8,\"1646\":1,\"1731\":7,\"1817\":5,\"1912\":1,\"1928\":1,\"2033\":1,\"2417\":2,\"2482\":1,\"2500\":2}}],[\"tensorflow官方文档\",{\"2\":{\"165\":1}}],[\"tensorflow\",{\"2\":{\"65\":1,\"106\":1,\"278\":1}}],[\"terry\",{\"2\":{\"1536\":1}}],[\"terry模型\",{\"2\":{\"1461\":1,\"2046\":1}}],[\"term\",{\"2\":{\"332\":3,\"1435\":3}}],[\"test\",{\"2\":{\"910\":1,\"1208\":2}}],[\"teacher\",{\"2\":{\"715\":1,\"749\":1}}],[\"technical\",{\"2\":{\"1324\":1,\"1372\":1,\"1492\":1,\"1535\":1,\"2434\":1}}],[\"tech\",{\"0\":{\"450\":1},\"1\":{\"477\":1,\"504\":1,\"536\":1,\"569\":1,\"602\":1,\"636\":1,\"670\":1,\"708\":1,\"742\":1,\"773\":1,\"804\":1,\"838\":1,\"874\":1,\"910\":1,\"949\":1,\"991\":1,\"1032\":1,\"1075\":1,\"1122\":1,\"1173\":1,\"1222\":1,\"1273\":1,\"1322\":1,\"1368\":1,\"1413\":1,\"1459\":1,\"1504\":1,\"1550\":1,\"1600\":1},\"2\":{\"237\":1}}],[\"textmonkey\",{\"2\":{\"2270\":1}}],[\"texts\",{\"2\":{\"1823\":2,\"1837\":2,\"1951\":2}}],[\"text\",{\"2\":{\"18\":7,\"34\":2,\"164\":3,\"228\":1,\"252\":1,\"261\":1,\"307\":2,\"426\":2,\"427\":3,\"485\":2,\"515\":3,\"553\":2,\"558\":1,\"589\":3,\"590\":1,\"614\":3,\"622\":2,\"655\":17,\"704\":1,\"733\":4,\"768\":5,\"847\":1,\"868\":4,\"901\":2,\"998\":3,\"1050\":3,\"1127\":6,\"1229\":4,\"1233\":5,\"1266\":1,\"1279\":1,\"1333\":3,\"1354\":1,\"1364\":5,\"1405\":2,\"1499\":2,\"1535\":2,\"1536\":1,\"1552\":4,\"1582\":1,\"1591\":1,\"1594\":3,\"1622\":4,\"1628\":1,\"1634\":1,\"1657\":3,\"1683\":2,\"1685\":2,\"1688\":1,\"1708\":5,\"1712\":1,\"1720\":1,\"1727\":1,\"1795\":1,\"1823\":3,\"1830\":2,\"1837\":6,\"1889\":2,\"1944\":1,\"1951\":6,\"1963\":3,\"1994\":1,\"2014\":3,\"2030\":1,\"2033\":2,\"2044\":1,\"2046\":3,\"2050\":2,\"2080\":8,\"2085\":3,\"2097\":1,\"2137\":2,\"2140\":3,\"2142\":2,\"2183\":1,\"2187\":2,\"2192\":11,\"2217\":4,\"2228\":10,\"2263\":8,\"2306\":2,\"2322\":1,\"2436\":1,\"2485\":1,\"2500\":2,\"2528\":9,\"2561\":1,\"2566\":3,\"2577\":3,\"2581\":1,\"2587\":1,\"2597\":8,\"2602\":4,\"2604\":7,\"2609\":2,\"2618\":6,\"2655\":1,\"2692\":1}}],[\"temporal\",{\"2\":{\"574\":1}}],[\"temperature\",{\"0\":{\"390\":1},\"1\":{\"416\":1},\"2\":{\"468\":1}}],[\"temperature及综合策略\",{\"0\":{\"226\":1},\"1\":{\"249\":1,\"272\":1,\"295\":1,\"317\":1,\"340\":1,\"364\":1,\"390\":1,\"416\":1,\"441\":1,\"468\":1,\"496\":1,\"528\":1,\"561\":1,\"596\":1,\"630\":1,\"665\":1,\"703\":1,\"739\":1,\"771\":1},\"2\":{\"5\":1,\"98\":1}}],[\"temperature及综合策略|深度解析语言模型采样方法\",{\"2\":{\"5\":1}}],[\"temp\",{\"2\":{\"47\":4}}],[\"template\",{\"2\":{\"15\":1,\"2500\":1}}],[\"t\",{\"2\":{\"15\":3,\"39\":1,\"184\":1,\"208\":2,\"213\":1,\"228\":1,\"252\":1,\"263\":6,\"276\":1,\"283\":2,\"346\":2,\"470\":1,\"497\":1,\"537\":14,\"581\":2,\"608\":3,\"611\":7,\"618\":3,\"640\":7,\"654\":1,\"672\":7,\"710\":7,\"748\":4,\"757\":8,\"779\":6,\"1127\":1,\"1246\":7,\"1343\":3,\"1364\":10,\"1591\":2,\"1613\":2,\"1622\":10,\"1732\":10,\"1831\":1,\"1942\":5,\"1992\":2,\"1993\":5,\"2045\":2,\"2124\":2,\"2306\":3,\"2357\":3,\"2446\":8,\"2485\":16,\"2531\":3,\"2542\":3,\"2577\":1,\"2653\":2}}],[\"t>\",{\"2\":{\"15\":1}}],[\"thompson\",{\"2\":{\"1658\":1}}],[\"thoughts\",{\"0\":{\"2094\":1,\"2144\":1},\"1\":{\"2188\":1,\"2227\":1,\"2262\":1},\"2\":{\"1917\":2,\"1990\":2}}],[\"thought\",{\"0\":{\"1655\":1},\"1\":{\"1708\":1,\"1766\":1,\"1826\":1,\"1885\":1,\"1940\":1,\"1990\":1,\"2042\":1,\"2094\":1,\"2144\":1,\"2188\":1,\"2227\":1,\"2262\":1},\"2\":{\"1224\":1,\"1375\":1,\"1420\":1,\"1708\":1,\"1788\":1,\"1990\":1,\"2011\":1}}],[\"throughout\",{\"2\":{\"1458\":1}}],[\"threshold\",{\"2\":{\"769\":2}}],[\"thus\",{\"2\":{\"1458\":1}}],[\"that\",{\"2\":{\"1458\":4}}],[\"thank\",{\"2\":{\"508\":1}}],[\"think\",{\"2\":{\"1885\":3}}],[\"things\",{\"2\":{\"1368\":1}}],[\"this\",{\"2\":{\"10\":7,\"18\":4,\"1458\":2}}],[\"these\",{\"2\":{\"2433\":2}}],[\"then\",{\"2\":{\"1458\":1}}],[\"there\",{\"2\":{\"1458\":2}}],[\"theories\",{\"2\":{\"1458\":1}}],[\"they\",{\"2\":{\"1458\":3}}],[\"thetaθ\",{\"2\":{\"695\":1,\"789\":1}}],[\"theta$$\",{\"2\":{\"247\":1,\"502\":1}}],[\"theta\",{\"2\":{\"247\":4,\"290\":1,\"503\":1,\"537\":1,\"586\":6,\"590\":10,\"647\":1,\"656\":4,\"695\":1,\"723\":6,\"757\":5,\"1093\":1,\"1628\":6,\"1795\":4,\"1901\":3,\"1942\":5,\"1993\":5,\"2044\":8,\"2097\":8,\"2357\":2,\"2485\":6,\"2520\":1,\"2531\":3,\"2532\":1,\"2542\":3,\"2577\":2}}],[\"the\",{\"0\":{\"2370\":1},\"1\":{\"2398\":1},\"2\":{\"11\":1,\"741\":1,\"917\":2,\"1406\":1,\"1420\":1,\"1458\":27,\"1883\":1,\"1885\":1,\"1912\":3,\"2050\":1,\"2199\":1,\"2433\":2,\"2434\":1,\"2471\":1,\"2484\":1,\"2600\":2}}],[\"n1⋅l1+n2⋅l2+n3⋅l3\",{\"2\":{\"2322\":1}}],[\"n1​⋅l1​+n2​⋅l2​+n3​⋅l3​\",{\"2\":{\"2322\":1}}],[\"n1​\",{\"2\":{\"1644\":1,\"2308\":3}}],[\"nccl\",{\"2\":{\"2081\":1,\"2129\":1}}],[\"ncol\",{\"2\":{\"646\":2,\"647\":2,\"656\":5,\"840\":2}}],[\"nd\",{\"2\":{\"2653\":6}}],[\"ndcg=idcgdcg​\",{\"2\":{\"2183\":1}}],[\"ndcg=dcgidcgndcg\",{\"2\":{\"2183\":1}}],[\"ndcg\",{\"0\":{\"2035\":1,\"2183\":1},\"1\":{\"2087\":1,\"2137\":1,\"2183\":1},\"2\":{\"2035\":1,\"2183\":1}}],[\"nd^2\",{\"2\":{\"189\":1,\"305\":1}}],[\"nineteenth\",{\"2\":{\"1458\":1}}],[\"nin​1​\",{\"2\":{\"1437\":1}}],[\"nielsen\",{\"2\":{\"165\":1}}],[\"n^\",{\"2\":{\"1329\":1}}],[\"n^2d\",{\"2\":{\"189\":1}}],[\"n^2\",{\"2\":{\"57\":1,\"147\":1,\"305\":1,\"1179\":1,\"2008\":1,\"2643\":3,\"2648\":1,\"2653\":1}}],[\"nrn\",{\"2\":{\"1318\":1}}],[\"nrow\",{\"2\":{\"646\":2,\"647\":2,\"656\":5,\"840\":2}}],[\"n⋅logn\",{\"2\":{\"1179\":1}}],[\"n⋅log⁡n\",{\"2\":{\"1179\":1}}],[\"n2d\",{\"2\":{\"2643\":2}}],[\"n2\",{\"2\":{\"1179\":2,\"2008\":2,\"2643\":2,\"2648\":2}}],[\"nsn\",{\"2\":{\"1318\":1}}],[\"nsfw过滤器\",{\"2\":{\"1167\":1}}],[\"nsp\",{\"0\":{\"1037\":1},\"2\":{\"919\":1,\"933\":1,\"1145\":1}}],[\"nvidia工具\",{\"2\":{\"1969\":1}}],[\"nvidia\",{\"2\":{\"698\":1,\"765\":1,\"2145\":1,\"2284\":1,\"2313\":1}}],[\"n=1\",{\"2\":{\"503\":1}}],[\"nfd\",{\"2\":{\"480\":2}}],[\"ntp方法不仅适用于语言\",{\"2\":{\"503\":1}}],[\"ntp\",{\"2\":{\"449\":1,\"503\":1}}],[\"ntk\",{\"0\":{\"200\":1,\"267\":1},\"1\":{\"221\":1,\"244\":1,\"290\":1,\"312\":1},\"2\":{\"159\":2,\"359\":1,\"386\":2,\"466\":1}}],[\"ntk插值\",{\"2\":{\"139\":1,\"466\":1}}],[\"ntk插值方法解析与优化\",{\"0\":{\"120\":1},\"1\":{\"139\":1,\"159\":1,\"179\":1,\"200\":1,\"221\":1,\"244\":1,\"267\":1,\"290\":1,\"312\":1,\"335\":1,\"359\":1,\"386\":1,\"412\":1,\"439\":1,\"466\":1},\"2\":{\"5\":1,\"84\":1}}],[\"nmt\",{\"2\":{\"319\":1}}],[\"n|\",{\"2\":{\"293\":1}}],[\"n$$\",{\"2\":{\"228\":1}}],[\"np\",{\"2\":{\"213\":10,\"332\":9,\"640\":2,\"646\":4,\"840\":5,\"1435\":9}}],[\"nu\",{\"2\":{\"590\":1,\"723\":1,\"2044\":1,\"2097\":1}}],[\"numerator\",{\"2\":{\"1831\":3}}],[\"number\",{\"2\":{\"1229\":2,\"1928\":1}}],[\"numofsubarrays\",{\"2\":{\"769\":1}}],[\"nums\",{\"2\":{\"762\":8}}],[\"num\",{\"2\":{\"324\":5,\"526\":1,\"917\":3,\"1912\":9,\"2217\":1,\"2417\":4,\"2482\":2,\"2500\":1,\"2600\":1}}],[\"numpy官方文档\",{\"2\":{\"302\":1}}],[\"numpy\",{\"2\":{\"213\":1,\"278\":1,\"332\":1,\"1435\":1}}],[\"nullptr\",{\"2\":{\"47\":5,\"48\":1}}],[\"nonzero\",{\"2\":{\"1928\":5}}],[\"none\",{\"2\":{\"189\":2,\"1582\":1,\"1622\":3,\"1731\":1,\"1817\":4,\"1832\":1,\"1928\":1,\"2500\":1,\"2539\":2}}],[\"no\",{\"2\":{\"1771\":1,\"1902\":1}}],[\"notation\",{\"2\":{\"2050\":1}}],[\"not\",{\"2\":{\"1582\":1,\"1817\":1,\"1928\":1,\"2500\":1}}],[\"notes\",{\"2\":{\"526\":1}}],[\"nouns\",{\"2\":{\"1458\":1}}],[\"normalfloat和双重量化的技术细节\",{\"2\":{\"2015\":1}}],[\"normalfloat以减少浮点数存储空间\",{\"2\":{\"1855\":1}}],[\"normalfloat\",{\"2\":{\"1679\":1,\"1793\":1}}],[\"normalize\",{\"2\":{\"480\":1}}],[\"normalizer\",{\"2\":{\"480\":2}}],[\"normalizers\",{\"2\":{\"480\":3}}],[\"normalized\",{\"2\":{\"426\":2,\"2035\":1}}],[\"normalization和layer\",{\"2\":{\"2027\":1}}],[\"normalization\",{\"0\":{\"480\":1},\"2\":{\"205\":2,\"2027\":1}}],[\"norm结构\",{\"2\":{\"1203\":1}}],[\"norm中的偏差项\",{\"2\":{\"1198\":1}}],[\"norm改为pre\",{\"2\":{\"1059\":1}}],[\"norm在大规模模型中的效果差异\",{\"2\":{\"282\":1}}],[\"norm在不同位置\",{\"2\":{\"128\":1}}],[\"norm和post\",{\"2\":{\"258\":1}}],[\"norm和sandwich\",{\"2\":{\"128\":1}}],[\"norm与post\",{\"2\":{\"282\":1}}],[\"norm与layer\",{\"2\":{\"234\":1}}],[\"norm与sandwich\",{\"0\":{\"95\":1},\"1\":{\"110\":1,\"128\":1,\"148\":1,\"169\":1,\"190\":1,\"211\":1,\"234\":1,\"258\":1,\"282\":1},\"2\":{\"5\":2,\"73\":1}}],[\"norm位置的最佳选择\",{\"2\":{\"234\":1}}],[\"norm位置对训练稳定性的影响\",{\"2\":{\"211\":1}}],[\"norm模型难以训练\",{\"2\":{\"211\":1}}],[\"norm针对每个样本的所有特征进行归一化\",{\"2\":{\"190\":1}}],[\"norm的潜在应用场景及优化策略\",{\"2\":{\"282\":1}}],[\"norm的优势\",{\"2\":{\"258\":1}}],[\"norm的训练稳定性\",{\"2\":{\"234\":1}}],[\"norm的计算公式\",{\"0\":{\"190\":1}}],[\"norm的位置对模型的影响\",{\"0\":{\"169\":1}}],[\"norm是一种常用于深度学习模型中的归一化技术\",{\"2\":{\"128\":1}}],[\"norm比较\",{\"0\":{\"95\":1},\"1\":{\"110\":1,\"128\":1,\"148\":1,\"169\":1,\"190\":1,\"211\":1,\"234\":1,\"258\":1,\"282\":1},\"2\":{\"5\":1,\"73\":1}}],[\"norm比较|深度学习中的layer\",{\"2\":{\"5\":1}}],[\"norm\",{\"0\":{\"95\":1,\"227\":2},\"1\":{\"110\":1,\"128\":1,\"148\":1,\"169\":1,\"190\":1,\"211\":1,\"234\":1,\"258\":1,\"282\":1},\"2\":{\"5\":2,\"73\":1,\"110\":1,\"128\":2,\"169\":5,\"205\":4,\"227\":2,\"234\":1,\"251\":1,\"275\":2,\"299\":2,\"961\":1,\"1059\":1,\"1265\":1,\"1358\":1,\"1831\":2}}],[\"norm设计\",{\"0\":{\"95\":1},\"1\":{\"110\":1,\"128\":1,\"148\":1,\"169\":1,\"190\":1,\"211\":1,\"234\":1,\"258\":1,\"282\":1},\"2\":{\"5\":2,\"73\":1}}],[\"nnn\",{\"2\":{\"1279\":1,\"1326\":1,\"1644\":1,\"1782\":1,\"1846\":1,\"1868\":1,\"2218\":2,\"2253\":1,\"2374\":2,\"2579\":1,\"2641\":1}}],[\"nn\",{\"2\":{\"135\":1,\"266\":5,\"619\":1,\"766\":6,\"820\":3,\"996\":4,\"1125\":1,\"1225\":1,\"1582\":1,\"1622\":1,\"1731\":1,\"1817\":1,\"1831\":2,\"1883\":4,\"1912\":8,\"2201\":2,\"2400\":3,\"2425\":2,\"2611\":1}}],[\"ng\",{\"2\":{\"106\":1,\"165\":1,\"230\":1,\"1617\":1}}],[\"nlg\",{\"2\":{\"2222\":1}}],[\"nlu\",{\"2\":{\"1682\":1}}],[\"nltktextsplitter\",{\"2\":{\"1837\":2,\"1951\":1}}],[\"nltk\",{\"0\":{\"1612\":1},\"1\":{\"1665\":1,\"1719\":1},\"2\":{\"278\":1,\"1612\":1,\"1719\":2,\"1776\":1,\"2584\":1}}],[\"nltk官方文档\",{\"2\":{\"67\":1}}],[\"nlp任务\",{\"2\":{\"2116\":1}}],[\"nlp优化\",{\"2\":{\"832\":1}}],[\"nlp中的mdp建模\",{\"0\":{\"581\":1}}],[\"nlp工具\",{\"2\":{\"347\":1}}],[\"nlp模型可能会进一步优化位置编码方式\",{\"2\":{\"1427\":1}}],[\"nlp模型\",{\"2\":{\"286\":1}}],[\"nlp\",{\"0\":{\"52\":1,\"205\":1,\"1613\":1},\"1\":{\"59\":1,\"67\":1},\"2\":{\"74\":1,\"80\":1,\"93\":1,\"121\":1,\"154\":2,\"205\":3,\"227\":1,\"251\":1,\"273\":1,\"275\":1,\"286\":1,\"297\":1,\"299\":1,\"319\":1,\"320\":1,\"344\":1,\"347\":1,\"373\":1,\"484\":1,\"514\":1,\"544\":1,\"804\":1,\"805\":1,\"832\":1,\"835\":1,\"848\":1,\"861\":1,\"883\":1,\"1070\":1,\"1085\":1,\"1088\":1,\"1098\":1,\"1103\":1,\"1515\":1,\"1606\":1,\"1618\":1}}],[\"naive\",{\"0\":{\"2366\":1,\"2420\":1},\"1\":{\"2445\":1,\"2466\":1},\"2\":{\"2366\":1,\"2420\":1}}],[\"navigable\",{\"0\":{\"2234\":1}}],[\"named\",{\"2\":{\"1458\":1}}],[\"name\",{\"2\":{\"1324\":1,\"1458\":1,\"1883\":8,\"2347\":1,\"2400\":2,\"2425\":2}}],[\"namespace\",{\"0\":{\"10\":1,\"27\":1},\"2\":{\"7\":1,\"10\":6,\"11\":3,\"27\":6}}],[\"nas\",{\"2\":{\"763\":1}}],[\"nabla\",{\"2\":{\"586\":2,\"723\":2,\"757\":2,\"1901\":1,\"1942\":2,\"1993\":2,\"2531\":1,\"2542\":1}}],[\"nan\",{\"2\":{\"553\":1}}],[\"nanodegree\",{\"2\":{\"165\":1}}],[\"natural\",{\"0\":{\"1368\":1},\"2\":{\"67\":2,\"1612\":1}}],[\"neo\",{\"2\":{\"2699\":1}}],[\"never\",{\"2\":{\"2050\":1}}],[\"neq\",{\"2\":{\"1732\":1,\"1901\":2,\"2602\":1}}],[\"neurips\",{\"2\":{\"1658\":1}}],[\"neural\",{\"0\":{\"2579\":1},\"2\":{\"469\":1,\"631\":1,\"763\":1,\"2253\":1,\"2579\":1}}],[\"nest\",{\"2\":{\"1458\":1}}],[\"necessary\",{\"2\":{\"1458\":1}}],[\"neighbors\",{\"0\":{\"2195\":1}}],[\"neighbor\",{\"2\":{\"1377\":1}}],[\"nearest\",{\"0\":{\"2195\":1},\"2\":{\"1377\":1,\"2085\":1}}],[\"neat\",{\"2\":{\"18\":1}}],[\"net\",{\"2\":{\"640\":5,\"820\":4}}],[\"network包含多个全连接层\",{\"2\":{\"2579\":1}}],[\"networks\",{\"2\":{\"2253\":1}}],[\"network更新频率对训练效果的影响\",{\"2\":{\"842\":1}}],[\"network是提高dqn训练稳定性的重要策略\",{\"2\":{\"808\":1}}],[\"network\",{\"0\":{\"746\":1,\"2579\":1},\"2\":{\"162\":1,\"768\":1,\"928\":1,\"1069\":1,\"2218\":1,\"2430\":1,\"2563\":1}}],[\"need\",{\"2\":{\"230\":1,\"2449\":1}}],[\"newtorch\",{\"2\":{\"2618\":1}}],[\"newli​​×torch\",{\"2\":{\"2618\":1}}],[\"new×pijvjo\",{\"2\":{\"2618\":1}}],[\"new×torch\",{\"2\":{\"2618\":1}}],[\"new=torch\",{\"2\":{\"2604\":4}}],[\"news\",{\"2\":{\"933\":1,\"1052\":1}}],[\"newer\",{\"2\":{\"443\":1}}],[\"newaxis\",{\"2\":{\"332\":1,\"1435\":1}}],[\"new\",{\"2\":{\"208\":2,\"443\":1,\"647\":3,\"656\":7,\"1831\":2,\"2604\":8,\"2618\":8,\"2623\":2}}],[\"negative\",{\"0\":{\"983\":1},\"2\":{\"1023\":1,\"1368\":1}}],[\"neg\",{\"2\":{\"189\":1,\"2539\":2}}],[\"next\",{\"0\":{\"1037\":1},\"2\":{\"47\":2,\"324\":21,\"424\":1,\"427\":3,\"503\":1,\"619\":3,\"640\":5,\"647\":4,\"656\":4,\"766\":3,\"843\":1,\"919\":1}}],[\"n++\",{\"2\":{\"47\":1}}],[\"n\",{\"0\":{\"528\":1,\"1021\":1},\"2\":{\"18\":2,\"47\":3,\"59\":1,\"76\":4,\"147\":2,\"205\":1,\"227\":1,\"228\":1,\"259\":2,\"268\":1,\"293\":2,\"470\":1,\"497\":1,\"503\":2,\"515\":1,\"528\":1,\"558\":1,\"575\":1,\"640\":1,\"646\":5,\"762\":5,\"778\":3,\"783\":2,\"840\":7,\"843\":4,\"932\":3,\"1011\":3,\"1021\":1,\"1179\":2,\"1259\":1,\"1279\":2,\"1364\":3,\"1437\":3,\"1535\":1,\"1644\":1,\"1823\":1,\"1901\":2,\"1942\":2,\"1993\":2,\"2008\":3,\"2080\":9,\"2085\":1,\"2091\":1,\"2140\":1,\"2141\":1,\"2253\":1,\"2308\":9,\"2322\":3,\"2347\":6,\"2531\":2,\"2542\":2,\"2606\":3,\"2618\":1,\"2648\":3,\"2653\":11,\"2676\":1}}],[\"从嵌入向量的角度来看\",{\"2\":{\"2672\":1}}],[\"从嵌入维度的角度进一步优化了上下文扩展性能\",{\"2\":{\"386\":1}}],[\"从小到大分块\",{\"0\":{\"2625\":1},\"1\":{\"2630\":1,\"2635\":1}}],[\"从小到大逐步合并\",{\"2\":{\"445\":1}}],[\"从mlp开始\",{\"2\":{\"2587\":1}}],[\"从mha到mla\",{\"0\":{\"82\":1},\"1\":{\"96\":1,\"111\":1,\"129\":1,\"149\":1,\"170\":1,\"191\":1,\"212\":1,\"235\":1,\"259\":1,\"283\":1,\"306\":1,\"329\":1,\"353\":1,\"378\":1,\"404\":1,\"432\":1},\"2\":{\"5\":1,\"63\":1}}],[\"从mha到mla|深度学习中的注意力机制优化\",{\"2\":{\"5\":1}}],[\"从外部来源检索信息的范式\",{\"0\":{\"2469\":1},\"1\":{\"2501\":1,\"2514\":1,\"2525\":1,\"2536\":1,\"2546\":1,\"2554\":1,\"2562\":1,\"2570\":1,\"2578\":1,\"2586\":1,\"2594\":1,\"2601\":1,\"2608\":1,\"2615\":1}}],[\"从策略梯度中的reinforce方法出发\",{\"2\":{\"2462\":1,\"2481\":1}}],[\"从简单经验中学习\",{\"2\":{\"2314\":1}}],[\"从简单的对话系统到能够自主行动的复杂系统\",{\"2\":{\"1136\":1}}],[\"从输入到生成第一个\",{\"2\":{\"2228\":1}}],[\"从输入直接映射到输出\",{\"2\":{\"1708\":1}}],[\"从用户行为\",{\"2\":{\"2220\":1}}],[\"从hbm中加载输入数据\",{\"2\":{\"2080\":1}}],[\"从\",{\"2\":{\"2079\":1}}],[\"从几天到几十年不等\",{\"2\":{\"2049\":1}}],[\"从中提取答案并取多数答案作为最终答案\",{\"2\":{\"2042\":1}}],[\"从π∗\",{\"2\":{\"1994\":1}}],[\"从自我指令创建过程中生成的数据中选择偏好对\",{\"2\":{\"1976\":1}}],[\"从种子ift数据中生成新的指令提示\",{\"2\":{\"1924\":1}}],[\"从技术上讲\",{\"2\":{\"1885\":1}}],[\"从计算维度可以看出\",{\"2\":{\"1843\":1}}],[\"从给定的缩放矩阵中提取特定层的缩放值\",{\"2\":{\"1809\":1}}],[\"从第2个token开始\",{\"2\":{\"1782\":1}}],[\"从错误中学习\",{\"2\":{\"1557\":1}}],[\"从行为约束的强化学习目标出发\",{\"2\":{\"1552\":1}}],[\"从多个角度对\",{\"2\":{\"1500\":1}}],[\"从多样化的数据集中获取自然语言描述示例\",{\"2\":{\"1203\":1}}],[\"从根本上讲\",{\"2\":{\"1465\":1}}],[\"从根本来说我不知道cpp是如何在底层运行的\",{\"2\":{\"56\":1}}],[\"从应用角度来看\",{\"2\":{\"1377\":1}}],[\"从common\",{\"2\":{\"1337\":1}}],[\"从架构上看\",{\"0\":{\"1218\":1},\"1\":{\"1269\":1,\"1316\":1,\"1362\":1}}],[\"从原始长度的50\",{\"2\":{\"1089\":1}}],[\"从0\",{\"2\":{\"1061\":1}}],[\"从deepseek\",{\"2\":{\"1053\":1,\"1245\":1}}],[\"从字粒度转向词粒度以提高语义表达能力\",{\"2\":{\"1021\":1}}],[\"从relu切换到gelu\",{\"2\":{\"961\":1}}],[\"从最后一步算起\",{\"2\":{\"820\":1}}],[\"从当前策略中采样动作和状态\",{\"2\":{\"695\":1}}],[\"从抽样结果中归纳出目标的数值估计\",{\"2\":{\"675\":1}}],[\"从某一状态开始的期望回报\",{\"2\":{\"647\":1}}],[\"从优化器层面减少梯度更新幅度\",{\"2\":{\"593\":1}}],[\"从通用数据中筛选出与种子数据相似度最高的前10条内容\",{\"2\":{\"532\":1}}],[\"从10000调整到1000000\",{\"2\":{\"502\":1}}],[\"从长文本中提取关键信息的能力的方法\",{\"2\":{\"492\":1}}],[\"从大到小逐步删除\",{\"2\":{\"445\":1}}],[\"从不同聚类簇中采样核心样本\",{\"2\":{\"421\":1}}],[\"从语料库中生成子词表\",{\"0\":{\"418\":1},\"1\":{\"443\":1,\"470\":1,\"497\":1}}],[\"从所有可能的子词对中选择\",{\"2\":{\"381\":1}}],[\"从候选词中随机选择一个词\",{\"2\":{\"364\":1}}],[\"从满足该阈值的最小词集合中随机采样\",{\"2\":{\"340\":1}}],[\"从入门到实践\",{\"2\":{\"302\":1}}],[\"从左到右\",{\"2\":{\"294\":1}}],[\"从平方复杂度到线性复杂度\",{\"0\":{\"189\":1}}],[\"从而确保系统行为符合预期\",{\"2\":{\"2702\":1}}],[\"从而可以有效降低空泡占比\",{\"2\":{\"2694\":1}}],[\"从而稳定训练过程并提升模型性能\",{\"2\":{\"2689\":1}}],[\"从而显著提高搜索结果的相关性\",{\"2\":{\"2672\":1}}],[\"从而显著减少\",{\"2\":{\"2397\":1}}],[\"从而显著减少模型的存储空间\",{\"2\":{\"729\":1}}],[\"从而为开发者提供更强大的调试和监控能力\",{\"2\":{\"2590\":1}}],[\"从而解决gpu内存容量和计算限制的问题\",{\"2\":{\"2503\":1}}],[\"从而与现实环境进行进一步交互\",{\"2\":{\"2443\":1}}],[\"从而更高效地找到与用户查询最相关的文档部分\",{\"2\":{\"2303\":1}}],[\"从而更好地适配大语言模型的输入要求\",{\"2\":{\"1561\":1}}],[\"从而不断优化最终输出\",{\"2\":{\"2294\":1}}],[\"从而使译文更加贴合原文意境\",{\"2\":{\"2294\":1}}],[\"从而使gpt更好地应用于nlu任务\",{\"2\":{\"1738\":1}}],[\"从而估计优势函数\",{\"2\":{\"2273\":1}}],[\"从而构建出多个推理数据并行组\",{\"2\":{\"2079\":1}}],[\"从而允许每个设备只需要储存数据的一部分\",{\"2\":{\"2055\":1}}],[\"从而有效识别语义上相似的句子\",{\"2\":{\"2155\":1}}],[\"从而有效地提升了答案的鲁棒性和准确性\",{\"2\":{\"2042\":1}}],[\"从而有效减少内存受限操作的运行时间\",{\"2\":{\"1810\":1}}],[\"从而获得多样化的输出\",{\"2\":{\"2037\":1}}],[\"从而优化策略\",{\"2\":{\"1955\":1}}],[\"从而优化了模型性能\",{\"2\":{\"1108\":1}}],[\"从而节省内存\",{\"2\":{\"1793\":1}}],[\"从而完成任务\",{\"2\":{\"1772\":1}}],[\"从而以牺牲延迟换取更高的准确性\",{\"2\":{\"1760\":1}}],[\"从而增强大模型的算术\",{\"2\":{\"1708\":1}}],[\"从而增加了调试难度\",{\"2\":{\"1392\":1}}],[\"从而减少通信量\",{\"2\":{\"2616\":1}}],[\"从而减少缓存压力\",{\"2\":{\"2260\":1}}],[\"从而减少了参数大小\",{\"2\":{\"1746\":1}}],[\"从而减少对人类策划工具使用模式的依赖\",{\"2\":{\"1684\":1}}],[\"从而减少存储需求和计算复杂度\",{\"2\":{\"763\":1}}],[\"从而生成更准确的回答\",{\"2\":{\"2197\":1}}],[\"从而生成更具上下文一致性的查询\",{\"2\":{\"1663\":1}}],[\"从而生成更优的分词结果\",{\"2\":{\"343\":1}}],[\"从而降低空闲时间的比率\",{\"2\":{\"2688\":1}}],[\"从而降低了模型对文本理解的准确性\",{\"2\":{\"2444\":1}}],[\"从而降低了检索的准确性\",{\"2\":{\"2334\":1}}],[\"从而降低了部署时的推理延迟并减少了所需的总体内存\",{\"2\":{\"1588\":1}}],[\"从而降低显存使用和训练耗时\",{\"2\":{\"1792\":1}}],[\"从而降低模型的存储和计算成本\",{\"2\":{\"860\":1}}],[\"从而加速\",{\"2\":{\"1578\":1}}],[\"从而简化了训练过程\",{\"2\":{\"1576\":1}}],[\"从而导致错误的均值计算\",{\"2\":{\"2056\":1}}],[\"从而导致奖励值不准确\",{\"2\":{\"2009\":1}}],[\"从而导致数据上溢的问题\",{\"2\":{\"1925\":1}}],[\"从而导致生成结果质量下降\",{\"2\":{\"1496\":1}}],[\"从而导致模型性能下降\",{\"2\":{\"1301\":1}}],[\"从而帮助开发者更好地理解并改善代理的弱点\",{\"2\":{\"1407\":1}}],[\"从而帮助模型提高对测试样本的预测能力\",{\"2\":{\"910\":1}}],[\"从而自动化地发现真实世界中的故障场景\",{\"2\":{\"1361\":1}}],[\"从而能够更加高效地完成复杂任务\",{\"2\":{\"1330\":1}}],[\"从而保持语义的完整\",{\"2\":{\"1652\":1}}],[\"从而保持性能的同时减小模型规模\",{\"2\":{\"763\":1}}],[\"从而保留表格的逻辑关系\",{\"2\":{\"1284\":1}}],[\"从而在量化所有权重的同时最小化量化误差\",{\"2\":{\"2085\":1}}],[\"从而在降低坏答案采样概率的同时\",{\"2\":{\"1626\":1}}],[\"从而在优化训练误差的同时兼顾量化误差\",{\"2\":{\"1355\":1}}],[\"从而在部署时能够更好地保持性能\",{\"2\":{\"1160\":1}}],[\"从而在不增加训练和推理计算量的情况下提升效果\",{\"2\":{\"1040\":1}}],[\"从而将能力从教师大语言模型转移到学生语言模型\",{\"2\":{\"1124\":1}}],[\"从而实现并行计算\",{\"2\":{\"2555\":1}}],[\"从而实现更高效的信息处理和决策支持\",{\"2\":{\"2443\":1}}],[\"从而实现更复杂的任务分配和处理\",{\"2\":{\"1786\":1}}],[\"从而实现快速检索\",{\"2\":{\"2152\":1}}],[\"从而实现快速且准确的文本分类\",{\"2\":{\"867\":1}}],[\"从而实现与人类偏好的对齐\",{\"2\":{\"1675\":1}}],[\"从而实现以下目标\",{\"2\":{\"1578\":1}}],[\"从而实现了显著的非结构化稀疏性\",{\"2\":{\"1050\":1}}],[\"从而实现性能提升\",{\"2\":{\"1035\":1}}],[\"从而实现负载均衡\",{\"2\":{\"1030\":1}}],[\"从而实现设备级负载均衡\",{\"2\":{\"989\":1}}],[\"从而实现高效的全局信息捕捉\",{\"2\":{\"86\":1}}],[\"从而对\",{\"2\":{\"845\":1}}],[\"从而满足实时应用的需求\",{\"2\":{\"825\":1}}],[\"从而影响生成回答的连贯性和准确性\",{\"2\":{\"2511\":1}}],[\"从而影响最终回答效果\",{\"2\":{\"2483\":1}}],[\"从而影响大模型生成答案的质量\",{\"2\":{\"2465\":1}}],[\"从而影响后续的数据分布\",{\"2\":{\"760\":1}}],[\"从而影响softmax分布的陡峭程度\",{\"2\":{\"228\":1}}],[\"从而提供更大的表达能力\",{\"2\":{\"1359\":1}}],[\"从而提高计算速度\",{\"2\":{\"2571\":1}}],[\"从而提高计算效率\",{\"2\":{\"2537\":1}}],[\"从而提高样本效率\",{\"2\":{\"2569\":1}}],[\"从而提高整体效率\",{\"2\":{\"2685\":1}}],[\"从而提高整体性能\",{\"2\":{\"2175\":1}}],[\"从而提高整个系统的效率\",{\"2\":{\"1338\":1}}],[\"从而提高决策能力\",{\"2\":{\"2113\":1}}],[\"从而提高训练效率\",{\"2\":{\"1740\":1}}],[\"从而提高\",{\"2\":{\"1698\":1}}],[\"从而提高最终结果的质量\",{\"2\":{\"1557\":1}}],[\"从而提高模型的对齐效果\",{\"2\":{\"2180\":1}}],[\"从而提高模型的稳定性和可靠性\",{\"2\":{\"1908\":1}}],[\"从而提高模型的学习能力\",{\"2\":{\"112\":1}}],[\"从而提高模型对当前输入的适配性\",{\"2\":{\"1413\":1}}],[\"从而提高效率\",{\"2\":{\"1384\":1}}],[\"从而提高推理效率并降低成本\",{\"2\":{\"1031\":1}}],[\"从而提升回答的准确性\",{\"2\":{\"2529\":1}}],[\"从而提升策略的安全性\",{\"2\":{\"2455\":1}}],[\"从而提升决策的准确性\",{\"2\":{\"2378\":1}}],[\"从而提升计算效率\",{\"2\":{\"2216\":1}}],[\"从而提升推理效率和效果\",{\"2\":{\"2188\":1}}],[\"从而提升响应质量\",{\"2\":{\"2154\":1}}],[\"从而提升人工智能系统的表现和用户满意度\",{\"2\":{\"1811\":1}}],[\"从而提升了参数效率和模型预测的直接影响\",{\"2\":{\"1736\":1}}],[\"从而提升模型在多语言环境下的推理能力\",{\"2\":{\"2491\":1}}],[\"从而提升模型性能\",{\"2\":{\"1388\":1}}],[\"从而提升模型的适应性和泛化能力\",{\"2\":{\"449\":1}}],[\"从而提升检索质量和响应速度\",{\"2\":{\"1285\":1}}],[\"从而提升用户体验\",{\"2\":{\"794\":1,\"2166\":1}}],[\"从而引入相对位置信息\",{\"2\":{\"247\":1}}],[\"从而避免重复计算\",{\"2\":{\"107\":1}}],[\"从而避免冲突\",{\"2\":{\"10\":1}}],[\"从ntk\",{\"0\":{\"120\":1},\"1\":{\"139\":1,\"159\":1,\"179\":1,\"200\":1,\"221\":1,\"244\":1,\"267\":1,\"290\":1,\"312\":1,\"335\":1,\"359\":1,\"386\":1,\"412\":1,\"439\":1,\"466\":1},\"2\":{\"5\":2,\"84\":1}}],[\"从sigmoid到swish\",{\"0\":{\"114\":1},\"1\":{\"132\":1,\"152\":1,\"173\":1,\"194\":1,\"215\":1,\"238\":1,\"261\":1,\"285\":1,\"307\":1,\"330\":1,\"354\":1,\"380\":1,\"406\":1},\"2\":{\"5\":1,\"73\":1}}],[\"从sigmoid到swish|激活函数详解与比较\",{\"2\":{\"5\":1}}],[\"src\",{\"2\":{\"2048\":1,\"2142\":1}}],[\"sram的读写速度比hbm高一个数量级\",{\"2\":{\"1810\":1}}],[\"s为小写\",{\"2\":{\"1926\":1}}],[\"s=dk​​1​qkt∈rn×n\",{\"2\":{\"2080\":1}}],[\"s=1dkqkt∈rn×ns\",{\"2\":{\"2080\":1}}],[\"s=qkt\",{\"2\":{\"1868\":1}}],[\"s=qkts\",{\"2\":{\"1868\":1}}],[\"s=l\",{\"2\":{\"222\":1}}],[\"s=ll\",{\"2\":{\"222\":1}}],[\"smi\",{\"2\":{\"2284\":1}}],[\"smi查询显存使用情况\",{\"2\":{\"2284\":1}}],[\"smi指令查看显存使用情况\",{\"2\":{\"2212\":1}}],[\"smi指令\",{\"2\":{\"2021\":1}}],[\"smaxs​\",{\"2\":{\"2651\":1}}],[\"small\",{\"0\":{\"2234\":1}}],[\"smasked​\",{\"2\":{\"2080\":1}}],[\"smasked​=mask\",{\"2\":{\"2080\":1}}],[\"smasked\",{\"2\":{\"2080\":1}}],[\"smasked=mask\",{\"2\":{\"2080\":1}}],[\"smp\",{\"2\":{\"1832\":1}}],[\"smoothquant\",{\"0\":{\"2033\":1},\"2\":{\"1813\":1,\"2033\":1,\"2085\":1}}],[\"smoothing\",{\"2\":{\"1731\":5}}],[\"svd参数化增量更新\",{\"0\":{\"1824\":1}}],[\"svm\",{\"2\":{\"39\":2}}],[\"symbolic\",{\"2\":{\"1708\":1}}],[\"system\",{\"0\":{\"1218\":1,\"1569\":1},\"1\":{\"1269\":1,\"1316\":1,\"1362\":1},\"2\":{\"2064\":2,\"2117\":1,\"2187\":1,\"2284\":1}}],[\"sj​=max\",{\"2\":{\"2033\":1}}],[\"sj=max⁡\",{\"2\":{\"2033\":1}}],[\"sjs\",{\"2\":{\"2033\":1}}],[\"sj\",{\"2\":{\"1364\":2}}],[\"s+d​\",{\"2\":{\"1344\":1}}],[\"s+dlr\",{\"2\":{\"1344\":1}}],[\"ss≤s\",{\"2\":{\"1344\":1}}],[\"sss\",{\"0\":{\"904\":1},\"1\":{\"939\":1,\"981\":1,\"1022\":1},\"2\":{\"775\":2,\"868\":1,\"1022\":1,\"2505\":2,\"2517\":1}}],[\"s≤s\",{\"2\":{\"1344\":1}}],[\"s−s\",{\"2\":{\"1344\":2}}],[\"sf\",{\"2\":{\"1344\":1}}],[\"sft阶段的packing策略\",{\"0\":{\"2278\":1},\"1\":{\"2310\":1}}],[\"sft阶段的学习率一般是预训练阶段的10倍\",{\"2\":{\"2217\":1}}],[\"sft评估需要关注模型的helpfulness\",{\"2\":{\"2194\":1}}],[\"sft策略\",{\"2\":{\"2114\":1}}],[\"sft将更广泛应用于需要高度精确指令执行的领域\",{\"2\":{\"1484\":1}}],[\"sft不适合进行大规模知识注入\",{\"2\":{\"1199\":1}}],[\"sft专注于指令遵循能力\",{\"2\":{\"1199\":1}}],[\"sft数据保持原始长度\",{\"2\":{\"1199\":1}}],[\"sft数据不需要拼接\",{\"2\":{\"1150\":1}}],[\"sft数据及处理\",{\"2\":{\"5\":4}}],[\"sft数据及处理|sft数据及处理\",{\"2\":{\"5\":1}}],[\"sft训练启动脚本\",{\"2\":{\"2194\":1}}],[\"sft训练\",{\"0\":{\"1087\":1},\"2\":{\"1631\":1,\"2101\":1,\"2131\":1}}],[\"sft\",{\"0\":{\"603\":1},\"2\":{\"369\":1,\"422\":1,\"537\":1,\"967\":1,\"1150\":1,\"1213\":2,\"1267\":1,\"1489\":1,\"1685\":1,\"1917\":1,\"2134\":1,\"2151\":1,\"2223\":1,\"2233\":2,\"2245\":1,\"2449\":1}}],[\"sft监督微调\",{\"2\":{\"5\":10,\"2476\":1}}],[\"sft监督微调|sft监督微调\",{\"2\":{\"5\":1}}],[\"sns​\",{\"2\":{\"1318\":1}}],[\"sne\",{\"2\":{\"39\":1}}],[\"sw⋅η\",{\"2\":{\"1344\":1}}],[\"swarm\",{\"2\":{\"1300\":1}}],[\"switch\",{\"0\":{\"959\":1},\"1\":{\"1000\":1,\"1040\":1,\"1083\":1,\"1129\":1,\"1180\":1,\"1229\":1,\"1279\":1,\"1326\":1,\"1371\":1,\"1417\":1},\"2\":{\"172\":1,\"1000\":1,\"1040\":2,\"1129\":1}}],[\"swish是否能完全取代relu成为新的默认选择\",{\"2\":{\"406\":1}}],[\"swish\",{\"0\":{\"307\":1},\"2\":{\"132\":1,\"199\":2,\"266\":2,\"330\":1}}],[\"swiglu激活函数\",{\"2\":{\"1198\":1}}],[\"swiglu和rope在其他模型中的应用\",{\"2\":{\"1287\":1}}],[\"swiglu和rope\",{\"2\":{\"1002\":1}}],[\"swiglu优化后\",{\"2\":{\"220\":1}}],[\"swiglu\",{\"0\":{\"103\":1,\"199\":1},\"1\":{\"119\":1,\"138\":1,\"158\":1,\"178\":1,\"199\":1,\"220\":1,\"243\":1,\"266\":1,\"289\":1,\"311\":1,\"334\":1},\"2\":{\"5\":2,\"73\":1,\"119\":1,\"199\":2,\"266\":3,\"889\":1,\"894\":1,\"1092\":1,\"1112\":1,\"1140\":1,\"1141\":1,\"1265\":1,\"1292\":2,\"1358\":1,\"2140\":1}}],[\"sg=1\",{\"2\":{\"1111\":1}}],[\"sg=0\",{\"2\":{\"1111\":1}}],[\"skill\",{\"2\":{\"2277\":1}}],[\"skipgram\",{\"2\":{\"1111\":1}}],[\"skip\",{\"2\":{\"870\":1,\"1066\":1}}],[\"skypile\",{\"2\":{\"741\":1,\"909\":1}}],[\"skywork\",{\"2\":{\"741\":1,\"909\":1}}],[\"s⋅r+z\",{\"2\":{\"868\":2}}],[\"s←s\",{\"2\":{\"775\":2}}],[\"s0​\",{\"2\":{\"1787\":1}}],[\"s0s\",{\"2\":{\"1787\":1}}],[\"s0\",{\"2\":{\"646\":3,\"778\":2,\"1787\":1}}],[\"s1​\",{\"2\":{\"618\":1}}],[\"s1\",{\"2\":{\"618\":1,\"646\":2,\"778\":2}}],[\"squeeze\",{\"2\":{\"1703\":2}}],[\"squad数据集\",{\"2\":{\"375\":1}}],[\"sqrt\",{\"2\":{\"34\":1,\"130\":1,\"213\":1,\"228\":1,\"2080\":1}}],[\"s^\",{\"2\":{\"221\":1}}],[\"shuffle=true\",{\"2\":{\"2201\":1}}],[\"she\",{\"2\":{\"1458\":1}}],[\"shard\",{\"2\":{\"2433\":1}}],[\"sharding\",{\"2\":{\"1455\":1}}],[\"share\",{\"2\":{\"2433\":1}}],[\"sharing适用于\",{\"2\":{\"2117\":1}}],[\"sharing\",{\"0\":{\"2117\":1}}],[\"shape\",{\"2\":{\"189\":1,\"213\":1,\"266\":1,\"1225\":1,\"1912\":2,\"2539\":2,\"2618\":1}}],[\"should\",{\"2\":{\"917\":1,\"1367\":1}}],[\"shot效果\",{\"2\":{\"1350\":1}}],[\"shot时\",{\"2\":{\"1254\":1}}],[\"shot设定下\",{\"2\":{\"1154\":1}}],[\"shot设定实现了多任务学习\",{\"2\":{\"975\":1}}],[\"shot学习在不同领域的效果\",{\"2\":{\"1370\":1}}],[\"shot学习\",{\"0\":{\"1154\":1},\"2\":{\"1082\":1,\"1228\":1}}],[\"shot的方式\",{\"2\":{\"1059\":1}}],[\"shot\",{\"0\":{\"1826\":2,\"1885\":1,\"1940\":1},\"1\":{\"1885\":2,\"1940\":2},\"2\":{\"294\":1,\"477\":1,\"670\":1,\"935\":1,\"999\":1,\"1154\":1,\"1228\":2,\"1462\":1,\"1826\":2,\"1885\":3,\"1924\":1,\"1940\":1,\"2546\":1,\"2693\":1}}],[\"shifted\",{\"0\":{\"136\":1},\"2\":{\"101\":1,\"218\":4}}],[\"side=\",{\"2\":{\"2500\":1}}],[\"sij=qikjts\",{\"2\":{\"2643\":1}}],[\"sij=torch\",{\"2\":{\"2581\":1}}],[\"sij−m\",{\"2\":{\"2597\":1}}],[\"sij\",{\"2\":{\"2597\":1}}],[\"sij​=qi​kjt​\",{\"2\":{\"2643\":1}}],[\"sij​=torch\",{\"2\":{\"2581\":1}}],[\"sij​−m\",{\"2\":{\"2597\":1}}],[\"sij​\",{\"2\":{\"2318\":1,\"2349\":1,\"2581\":1,\"2589\":1,\"2597\":1,\"2643\":1}}],[\"sijs\",{\"2\":{\"2318\":1,\"2349\":1,\"2581\":1,\"2589\":1,\"2643\":1}}],[\"si​\",{\"2\":{\"640\":1}}],[\"si\",{\"2\":{\"640\":3,\"1364\":4,\"2528\":18}}],[\"similar\",{\"2\":{\"1458\":1}}],[\"simpleqa中的表现不如deepseek\",{\"2\":{\"2580\":1}}],[\"simpleqa中的表现\",{\"0\":{\"2580\":1}}],[\"simple\",{\"2\":{\"1458\":2,\"1997\":1,\"2202\":1,\"2229\":1,\"2265\":1}}],[\"sim\",{\"2\":{\"590\":2,\"614\":4,\"655\":2,\"1437\":2,\"1552\":2,\"1582\":1,\"1657\":3,\"1666\":2,\"1685\":2,\"1712\":2,\"1720\":2,\"1795\":1,\"1830\":2,\"1944\":1,\"2044\":2,\"2097\":2}}],[\"singular\",{\"2\":{\"1883\":2}}],[\"singleagent\",{\"0\":{\"1241\":1},\"2\":{\"1139\":1,\"1241\":1}}],[\"singlenotes\",{\"2\":{\"526\":1}}],[\"single\",{\"2\":{\"515\":1}}],[\"since\",{\"2\":{\"1458\":1}}],[\"sin⁡\",{\"2\":{\"1246\":3}}],[\"sin\",{\"2\":{\"247\":2,\"263\":5,\"332\":1,\"1246\":6,\"1435\":1}}],[\"sigmoid\",{\"0\":{\"194\":1},\"2\":{\"199\":1,\"266\":1,\"307\":3,\"330\":1,\"2526\":1}}],[\"sigma^\",{\"2\":{\"1634\":1}}],[\"sigma^+\",{\"2\":{\"1634\":1}}],[\"sigma\",{\"2\":{\"90\":1,\"164\":1,\"307\":2,\"998\":1,\"1536\":18,\"1795\":1,\"2046\":1}}],[\"sizeq\",{\"2\":{\"2549\":2}}],[\"size等于cache\",{\"2\":{\"2386\":1}}],[\"size×模型参数量\",{\"2\":{\"2263\":2}}],[\"size×completion\",{\"2\":{\"2263\":2}}],[\"size×prompt\",{\"2\":{\"2263\":2}}],[\"size×num\",{\"2\":{\"2217\":2}}],[\"sizeemb\",{\"2\":{\"1868\":2}}],[\"sizebatch\",{\"2\":{\"1868\":2}}],[\"size设为64\",{\"2\":{\"1240\":1}}],[\"size和window\",{\"2\":{\"1161\":1}}],[\"size=gradient\",{\"2\":{\"2217\":2}}],[\"size=8\",{\"2\":{\"1646\":1}}],[\"size=2\",{\"2\":{\"1646\":1}}],[\"size=4\",{\"2\":{\"1646\":1}}],[\"size=100\",{\"2\":{\"1111\":2}}],[\"size=10000\",{\"2\":{\"996\":1}}],[\"size=\",{\"2\":{\"324\":1}}],[\"size\",{\"0\":{\"1297\":1,\"1937\":1},\"2\":{\"135\":1,\"218\":7,\"324\":6,\"391\":1,\"762\":1,\"769\":1,\"783\":1,\"898\":1,\"917\":3,\"996\":2,\"1197\":1,\"1297\":3,\"1450\":1,\"1482\":1,\"1577\":1,\"1629\":1,\"1782\":1,\"1823\":1,\"1868\":2,\"1912\":9,\"1937\":1,\"1978\":1,\"2141\":2,\"2217\":2,\"2233\":2,\"2263\":3,\"2500\":1,\"2539\":10,\"2549\":4}}],[\"sc\",{\"0\":{\"2042\":1},\"2\":{\"1990\":1,\"2042\":2}}],[\"scatter和all\",{\"2\":{\"2621\":1}}],[\"scatter\",{\"2\":{\"1928\":1,\"2308\":1}}],[\"scalar\",{\"2\":{\"2673\":1,\"2676\":1}}],[\"scale\",{\"0\":{\"520\":1},\"1\":{\"553\":1,\"589\":1},\"2\":{\"405\":1,\"433\":1,\"435\":1,\"553\":2,\"589\":4,\"657\":1,\"694\":1,\"730\":2,\"765\":1,\"1872\":1,\"2187\":1}}],[\"scaled\",{\"0\":{\"130\":1,\"213\":1},\"2\":{\"130\":1,\"213\":5,\"236\":1,\"435\":2}}],[\"scalings\",{\"2\":{\"1928\":13}}],[\"scaling等技术\",{\"2\":{\"1204\":1}}],[\"scaling\",{\"0\":{\"1152\":1,\"1329\":1},\"1\":{\"1201\":1},\"2\":{\"240\":1,\"533\":1,\"593\":1,\"667\":1,\"740\":1,\"1013\":2,\"1086\":1,\"1152\":1,\"1248\":1,\"1255\":1,\"1287\":1,\"1298\":1,\"1348\":1,\"1441\":1,\"1455\":1,\"1508\":2,\"1527\":1,\"1883\":1,\"2142\":1}}],[\"scratch\",{\"2\":{\"1458\":1}}],[\"scott\",{\"2\":{\"1224\":2}}],[\"score\",{\"2\":{\"222\":1,\"324\":2,\"355\":1,\"515\":3,\"2354\":1}}],[\"scores=topk​\",{\"2\":{\"427\":1}}],[\"scores=topk\",{\"2\":{\"427\":1}}],[\"scores\",{\"2\":{\"135\":2,\"213\":5,\"324\":7,\"407\":2,\"427\":1}}],[\"scholar\",{\"2\":{\"454\":1,\"1458\":2}}],[\"science\",{\"2\":{\"302\":1}}],[\"scikit\",{\"2\":{\"106\":2}}],[\"s2\",{\"2\":{\"101\":1}}],[\"sandbox\",{\"2\":{\"2345\":1}}],[\"sandwich\",{\"2\":{\"169\":1}}],[\"save\",{\"2\":{\"2201\":2,\"2233\":2}}],[\"safety\",{\"2\":{\"2580\":1}}],[\"safe\",{\"0\":{\"2492\":1},\"1\":{\"2505\":1,\"2517\":1,\"2528\":1,\"2539\":1,\"2549\":1},\"2\":{\"1925\":2,\"2492\":1}}],[\"samples\",{\"2\":{\"2233\":1}}],[\"sample\",{\"2\":{\"515\":5,\"619\":1,\"766\":1,\"820\":1,\"1902\":1,\"2050\":1}}],[\"sampling的性能差异\",{\"2\":{\"1161\":1}}],[\"sampling\",{\"0\":{\"272\":1,\"317\":1,\"390\":1,\"983\":1},\"1\":{\"295\":1,\"340\":1,\"364\":1,\"416\":1},\"2\":{\"295\":1,\"340\":1,\"781\":1,\"1023\":1,\"1164\":1}}],[\"sa\",{\"2\":{\"467\":1}}],[\"sagemaker\",{\"2\":{\"65\":1,\"1832\":2}}],[\"sarsa等算法将不断优化\",{\"2\":{\"852\":1}}],[\"sarsa与其他强化学习算法\",{\"2\":{\"754\":1}}],[\"sarsa算法通过结合td方法和贪婪策略\",{\"2\":{\"786\":1}}],[\"sarsa算法通过以下公式更新动作价值函数\",{\"2\":{\"611\":1}}],[\"sarsa算法在更新时需要使用当前行为策略采样得到的五元组数据\",{\"2\":{\"653\":1}}],[\"sarsa算法流程\",{\"2\":{\"646\":1}}],[\"sarsa算法是一种用于强化学习的算法\",{\"2\":{\"577\":1}}],[\"sarsa算法\",{\"0\":{\"509\":1},\"1\":{\"543\":1,\"577\":1,\"611\":1,\"646\":1,\"681\":1,\"720\":1,\"754\":1,\"786\":1,\"817\":1,\"852\":1,\"886\":1},\"2\":{\"151\":1,\"646\":1}}],[\"sarsa算法|sarsa算法\",{\"2\":{\"5\":1}}],[\"sarsa\",{\"0\":{\"506\":1,\"672\":1},\"1\":{\"538\":1,\"571\":1,\"604\":1,\"638\":1,\"672\":1,\"710\":1,\"744\":1,\"775\":1,\"806\":1,\"840\":1,\"876\":1,\"912\":1,\"951\":1},\"2\":{\"5\":1,\"151\":1,\"543\":1,\"571\":1,\"638\":1,\"646\":1,\"672\":2,\"876\":2}}],[\"s型函数\",{\"2\":{\"51\":1}}],[\"south\",{\"2\":{\"1458\":2}}],[\"source\",{\"2\":{\"1287\":1,\"2187\":1,\"2201\":4}}],[\"socratic\",{\"2\":{\"1224\":2}}],[\"soft\",{\"0\":{\"1981\":1},\"2\":{\"440\":1,\"560\":1,\"1752\":1,\"1981\":1,\"2032\":1,\"2219\":1,\"2254\":1,\"2689\":1}}],[\"softmax是一个非常重要的技巧\",{\"2\":{\"1925\":1}}],[\"softmax的计算公式如下\",{\"2\":{\"1925\":1}}],[\"softmax与negative\",{\"2\":{\"1161\":1}}],[\"softmax操作的输入为query和key的点积结果\",{\"2\":{\"228\":1}}],[\"softmax归一化\",{\"2\":{\"213\":1}}],[\"softmax\",{\"0\":{\"941\":1,\"1806\":1,\"1925\":1,\"2349\":1,\"2492\":1},\"1\":{\"1868\":1,\"1925\":1,\"2505\":1,\"2517\":1,\"2528\":1,\"2539\":1,\"2549\":1},\"2\":{\"34\":1,\"130\":1,\"135\":1,\"189\":1,\"193\":1,\"208\":2,\"228\":3,\"416\":1,\"440\":1,\"766\":1,\"820\":1,\"980\":1,\"1023\":1,\"1266\":1,\"1535\":1,\"1650\":1,\"1703\":2,\"1868\":1,\"1872\":1,\"1925\":4,\"1928\":4,\"1936\":1,\"1980\":1,\"2030\":3,\"2080\":2,\"2140\":1,\"2349\":1,\"2492\":1,\"2528\":1}}],[\"sorted\",{\"2\":{\"364\":1}}],[\"solution\",{\"2\":{\"47\":1,\"48\":1,\"762\":1,\"769\":1,\"783\":1}}],[\"session\",{\"2\":{\"2312\":1}}],[\"seed\",{\"2\":{\"2168\":1}}],[\"seen\",{\"2\":{\"1458\":2}}],[\"second\",{\"2\":{\"1977\":2,\"2228\":1}}],[\"secretly\",{\"2\":{\"1814\":1,\"1902\":1}}],[\"sectioning\",{\"2\":{\"2037\":1}}],[\"section\",{\"2\":{\"1458\":1}}],[\"sent\",{\"2\":{\"1612\":1,\"1665\":1}}],[\"sentences\",{\"2\":{\"1111\":3,\"1458\":2}}],[\"sentence\",{\"0\":{\"1037\":1},\"2\":{\"910\":1,\"919\":1,\"1089\":1,\"1458\":1,\"1665\":1,\"1762\":1,\"1782\":1,\"2601\":2}}],[\"sentencepiece官方文档\",{\"2\":{\"719\":1}}],[\"sentencepiece在处理混合语言\",{\"2\":{\"719\":1}}],[\"sentencepiece对小型数据集可能不够高效\",{\"2\":{\"610\":1}}],[\"sentencepiece无需预分词\",{\"2\":{\"610\":1}}],[\"sentencepiece\",{\"0\":{\"426\":1},\"2\":{\"347\":1,\"373\":1}}],[\"sensitive\",{\"2\":{\"1559\":1}}],[\"serially\",{\"2\":{\"2433\":1}}],[\"server\",{\"2\":{\"2288\":1}}],[\"served\",{\"2\":{\"1458\":1}}],[\"sermon\",{\"2\":{\"1458\":3}}],[\"segment嵌入\",{\"2\":{\"956\":1,\"1226\":1}}],[\"separation\",{\"2\":{\"2050\":1}}],[\"separators\",{\"0\":{\"2091\":1},\"2\":{\"1823\":1,\"2091\":1,\"2141\":1}}],[\"separate\",{\"2\":{\"1458\":1}}],[\"sep\",{\"2\":{\"542\":1,\"847\":1}}],[\"set\",{\"2\":{\"391\":1}}],[\"select\",{\"2\":{\"1936\":1}}],[\"selectionscorei​=expertscorei​+αi​⋅β\",{\"2\":{\"998\":1}}],[\"selectionscorei=expertscorei+αi⋅β\",{\"2\":{\"998\":1}}],[\"selectionscore\",{\"2\":{\"998\":1}}],[\"selection\",{\"2\":{\"804\":1}}],[\"selected\",{\"2\":{\"364\":2,\"1936\":2}}],[\"self\",{\"0\":{\"126\":1,\"147\":1,\"596\":1,\"1035\":1,\"1534\":1,\"1619\":1,\"1968\":1,\"2042\":1,\"2365\":1,\"2571\":1,\"2626\":1},\"1\":{\"146\":1,\"167\":1,\"1584\":1,\"1637\":1,\"1691\":1,\"1747\":1,\"1805\":1,\"1867\":1,\"1924\":1,\"1976\":1,\"2026\":1,\"2076\":1,\"2127\":1,\"2174\":1,\"2631\":1,\"2636\":1,\"2641\":1},\"2\":{\"34\":1,\"93\":1,\"126\":1,\"135\":1,\"151\":1,\"232\":1,\"266\":9,\"305\":1,\"326\":1,\"515\":3,\"619\":28,\"640\":24,\"646\":16,\"647\":16,\"656\":37,\"739\":1,\"766\":39,\"820\":23,\"840\":15,\"916\":1,\"1008\":1,\"1035\":1,\"1557\":1,\"1582\":1,\"1622\":5,\"1731\":13,\"1747\":1,\"1807\":1,\"1817\":6,\"1831\":12,\"1832\":9,\"1883\":10,\"1912\":13,\"1928\":4,\"1990\":1,\"2113\":1,\"2168\":1,\"2201\":1,\"2277\":1,\"2365\":1,\"2400\":6,\"2425\":4,\"2433\":7,\"2500\":11,\"2571\":1,\"2579\":1,\"2600\":1,\"2631\":1,\"2641\":1}}],[\"sequential\",{\"2\":{\"1912\":1,\"2252\":1}}],[\"sequence\",{\"2\":{\"230\":1,\"480\":1,\"917\":3}}],[\"seq\",{\"2\":{\"332\":5,\"917\":6,\"1435\":3,\"1868\":1,\"1912\":2,\"1978\":1,\"2252\":1}}],[\"search等\",{\"2\":{\"1013\":1}}],[\"search核心公式\",{\"2\":{\"427\":1}}],[\"search可能过于保守\",{\"2\":{\"348\":1}}],[\"search能有效提升生成质量\",{\"2\":{\"324\":1}}],[\"search的技术方案\",{\"2\":{\"481\":1}}],[\"search的代码并测试不同参数对生成效果的影响\",{\"2\":{\"481\":1}}],[\"search的保守问题\",{\"2\":{\"453\":1}}],[\"search的具体实现细节\",{\"2\":{\"253\":1}}],[\"search的实现与优化\",{\"0\":{\"229\":1},\"1\":{\"253\":1,\"277\":1,\"301\":1,\"324\":1,\"348\":1,\"374\":1,\"400\":1,\"427\":1,\"453\":1,\"481\":1,\"510\":1},\"2\":{\"5\":1,\"98\":1}}],[\"search的实现与优化|解码采样策略\",{\"2\":{\"5\":1}}],[\"search和beam\",{\"2\":{\"253\":1,\"481\":1}}],[\"search\",{\"0\":{\"301\":1,\"324\":1,\"2102\":1,\"2536\":1},\"1\":{\"2152\":1,\"2195\":1,\"2234\":1,\"2546\":1,\"2554\":1},\"2\":{\"49\":1,\"229\":1,\"253\":3,\"324\":1,\"400\":2,\"763\":1,\"1377\":1,\"1917\":2,\"2378\":1,\"2546\":1}}],[\"search与beam\",{\"0\":{\"229\":1},\"1\":{\"253\":1,\"277\":1,\"301\":1,\"324\":1,\"348\":1,\"374\":1,\"400\":1,\"427\":1,\"453\":1,\"481\":1,\"510\":1},\"2\":{\"5\":2,\"98\":1}}],[\"spring\",{\"2\":{\"1458\":2}}],[\"spike问题\",{\"2\":{\"736\":1}}],[\"spike可能导致模型训练失败\",{\"2\":{\"627\":1}}],[\"spike对模型有不可逆的损害\",{\"2\":{\"525\":1}}],[\"spike\",{\"0\":{\"525\":1,\"593\":1},\"2\":{\"437\":1,\"525\":1,\"662\":1}}],[\"splitter\",{\"2\":{\"1823\":1,\"1837\":3,\"1951\":3}}],[\"split\",{\"2\":{\"391\":5,\"1458\":1,\"1837\":1,\"1951\":1,\"2539\":6,\"2549\":3}}],[\"splitlisttoparts\",{\"2\":{\"47\":1}}],[\"span\",{\"2\":{\"2578\":1}}],[\"space扩展为特定任务的离散动作和语言空间的组合\",{\"2\":{\"1608\":1}}],[\"space\",{\"2\":{\"1261\":1}}],[\"spacytextsplitter\",{\"2\":{\"1951\":3}}],[\"spacy\",{\"0\":{\"1896\":1},\"1\":{\"1951\":1,\"2002\":1},\"2\":{\"278\":1,\"1896\":2,\"2002\":2,\"2584\":1}}],[\"spacy官方文档\",{\"2\":{\"67\":1}}],[\"sparsegpt\",{\"2\":{\"1050\":2}}],[\"sparse\",{\"0\":{\"75\":1,\"136\":1,\"168\":1,\"1179\":1},\"1\":{\"87\":1,\"101\":1,\"117\":1,\"136\":1,\"156\":1,\"176\":1,\"197\":1,\"218\":1,\"241\":1,\"264\":1,\"288\":1,\"310\":1,\"333\":1,\"358\":1,\"385\":1},\"2\":{\"5\":2,\"63\":1,\"94\":1,\"101\":1,\"168\":2,\"257\":1,\"305\":1,\"327\":1,\"999\":1,\"1179\":1}}],[\"specified\",{\"2\":{\"2050\":1}}],[\"specialization\",{\"2\":{\"67\":1,\"165\":1}}],[\"special\",{\"2\":{\"18\":1,\"1249\":1,\"2163\":1,\"2500\":1}}],[\"speed\",{\"2\":{\"683\":1,\"2145\":1}}],[\"speech\",{\"2\":{\"67\":1}}],[\"surr2\",{\"2\":{\"1622\":2,\"1817\":2}}],[\"surr1\",{\"2\":{\"1622\":2,\"1817\":2}}],[\"survey\",{\"2\":{\"153\":1,\"2395\":1}}],[\"succ\",{\"2\":{\"1536\":5,\"1727\":1,\"2046\":1}}],[\"suggestion\",{\"2\":{\"1368\":1}}],[\"subgoals\",{\"2\":{\"1420\":1,\"2370\":1}}],[\"subword\",{\"2\":{\"631\":1}}],[\"subwords\",{\"2\":{\"469\":1}}],[\"sub\",{\"0\":{\"1588\":1},\"2\":{\"526\":1}}],[\"subtract\",{\"2\":{\"12\":2}}],[\"supervised\",{\"2\":{\"1208\":1,\"1213\":1,\"1582\":1,\"1917\":1,\"2151\":1,\"2278\":1}}],[\"superglue数据集\",{\"2\":{\"549\":1}}],[\"superglue\",{\"2\":{\"549\":1}}],[\"super\",{\"2\":{\"266\":1,\"766\":2,\"820\":1,\"1622\":1,\"1731\":1,\"1817\":1,\"1831\":1,\"1912\":1,\"2500\":1}}],[\"sum\",{\"2\":{\"11\":1,\"18\":1,\"213\":1,\"268\":1,\"364\":1,\"503\":1,\"558\":1,\"640\":1,\"647\":1,\"656\":3,\"723\":2,\"732\":4,\"757\":2,\"762\":4,\"767\":3,\"810\":2,\"1093\":1,\"1127\":1,\"1142\":1,\"1266\":1,\"1279\":1,\"1364\":2,\"1455\":1,\"1536\":3,\"1622\":2,\"1628\":1,\"1634\":3,\"1644\":1,\"1671\":1,\"1703\":1,\"1830\":1,\"1889\":2,\"1901\":4,\"1925\":1,\"1936\":1,\"1942\":3,\"1993\":3,\"2085\":1,\"2124\":1,\"2137\":1,\"2140\":1,\"2176\":1,\"2485\":2,\"2531\":2,\"2542\":2,\"2577\":2,\"2597\":3,\"2667\":3,\"2670\":1,\"2673\":1}}],[\"s\",{\"0\":{\"2054\":1},\"2\":{\"10\":7,\"166\":2,\"184\":3,\"187\":2,\"221\":3,\"222\":2,\"276\":3,\"291\":1,\"346\":1,\"470\":1,\"497\":1,\"537\":4,\"581\":1,\"586\":3,\"590\":8,\"608\":6,\"611\":4,\"618\":2,\"640\":6,\"646\":1,\"647\":31,\"653\":12,\"654\":1,\"656\":22,\"672\":4,\"676\":1,\"695\":3,\"710\":4,\"723\":8,\"732\":34,\"748\":9,\"767\":52,\"769\":4,\"775\":8,\"778\":16,\"779\":9,\"783\":5,\"810\":22,\"843\":8,\"868\":1,\"1119\":6,\"1324\":1,\"1344\":17,\"1364\":7,\"1455\":2,\"1458\":2,\"1536\":3,\"1613\":1,\"1622\":2,\"1634\":3,\"1732\":4,\"1787\":1,\"1868\":3,\"1885\":3,\"1942\":2,\"1992\":2,\"1993\":2,\"2033\":6,\"2044\":12,\"2045\":2,\"2077\":2,\"2080\":4,\"2097\":12,\"2145\":1,\"2306\":5,\"2430\":9,\"2528\":9,\"2539\":6,\"2581\":1,\"2589\":3,\"2597\":2,\"2621\":1,\"2641\":1,\"2648\":1,\"2660\":1,\"2670\":1,\"2676\":2}}],[\"stylistic\",{\"2\":{\"2601\":1}}],[\"style\",{\"2\":{\"2202\":1}}],[\"styles\",{\"2\":{\"2050\":1}}],[\"stm\",{\"0\":{\"1998\":1}}],[\"st−​\",{\"2\":{\"1634\":1}}],[\"st−\",{\"2\":{\"1634\":1}}],[\"st2​\",{\"2\":{\"1536\":1}}],[\"st2\",{\"2\":{\"1536\":1}}],[\"st1​\",{\"2\":{\"1536\":2}}],[\"st1\",{\"2\":{\"1536\":2}}],[\"store\",{\"2\":{\"2408\":1}}],[\"storm\",{\"2\":{\"1485\":2}}],[\"story\",{\"2\":{\"1420\":1}}],[\"stage倍\",{\"2\":{\"2697\":1}}],[\"stage=2为例\",{\"2\":{\"2697\":1}}],[\"stage\",{\"2\":{\"2233\":1,\"2252\":1,\"2287\":1}}],[\"stanford\",{\"2\":{\"1658\":1}}],[\"stable\",{\"2\":{\"1344\":1}}],[\"start=1\",{\"2\":{\"1816\":1}}],[\"start\",{\"2\":{\"1193\":1}}],[\"states\",{\"2\":{\"619\":8,\"640\":6,\"766\":5,\"820\":1,\"2161\":2}}],[\"state\",{\"0\":{\"1847\":1},\"2\":{\"619\":8,\"640\":6,\"646\":2,\"647\":4,\"656\":4,\"766\":11,\"820\":12,\"840\":5,\"1222\":1,\"1847\":1,\"2201\":1,\"2433\":1}}],[\"statskeys\",{\"2\":{\"515\":2}}],[\"stats\",{\"2\":{\"515\":3}}],[\"student\",{\"2\":{\"715\":1,\"749\":1}}],[\"st+​\",{\"2\":{\"1634\":2}}],[\"st+\",{\"2\":{\"1634\":2}}],[\"st+n​\",{\"2\":{\"672\":1}}],[\"st+n\",{\"2\":{\"672\":1}}],[\"st+1​\",{\"2\":{\"608\":1,\"611\":1,\"640\":1,\"710\":1,\"748\":1,\"779\":1}}],[\"st+1\",{\"2\":{\"608\":1,\"611\":1,\"640\":1,\"710\":1,\"748\":1,\"779\":1}}],[\"sts\",{\"2\":{\"581\":1,\"1613\":1}}],[\"st​=\",{\"2\":{\"537\":1}}],[\"st​\",{\"2\":{\"537\":1,\"608\":2,\"611\":3,\"618\":1,\"640\":3,\"654\":1,\"672\":3,\"710\":3,\"1622\":2,\"1992\":2,\"2045\":2}}],[\"st=\",{\"2\":{\"537\":1}}],[\"st\",{\"2\":{\"537\":1,\"608\":2,\"611\":3,\"618\":1,\"640\":3,\"654\":1,\"672\":3,\"710\":3,\"778\":2,\"1622\":2,\"1992\":2,\"2045\":2}}],[\"steps×per\",{\"2\":{\"2217\":2}}],[\"steps\",{\"2\":{\"1420\":1,\"2217\":2,\"2233\":3,\"2319\":1}}],[\"step\",{\"0\":{\"1774\":1,\"2565\":1,\"2573\":1,\"2581\":1,\"2589\":1,\"2597\":1,\"2604\":1,\"2611\":1,\"2618\":1,\"2623\":1},\"2\":{\"619\":2,\"640\":1,\"766\":2,\"820\":1,\"1885\":6,\"2201\":1,\"2276\":1,\"2374\":1,\"2539\":9}}],[\"stephen\",{\"2\":{\"454\":1}}],[\"steven\",{\"2\":{\"67\":1}}],[\"stl\",{\"2\":{\"24\":2}}],[\"strategies\",{\"2\":{\"1917\":1}}],[\"strong\",{\"2\":{\"1364\":1}}],[\"strings\",{\"2\":{\"1458\":1}}],[\"string\",{\"2\":{\"783\":1}}],[\"stripaccents\",{\"2\":{\"480\":2}}],[\"stripes\",{\"2\":{\"18\":1}}],[\"str\",{\"2\":{\"391\":1,\"480\":1,\"508\":1,\"2400\":1,\"2500\":2}}],[\"structure\",{\"0\":{\"98\":1},\"2\":{\"5\":4}}],[\"stdcout\",{\"2\":{\"22\":1,\"27\":1}}],[\"std\",{\"0\":{\"22\":1,\"27\":1},\"2\":{\"10\":8,\"11\":3,\"12\":6,\"15\":4,\"17\":1,\"22\":5,\"27\":11,\"1683\":2,\"2306\":2}}],[\"stf训练\",{\"2\":{\"5\":5,\"2476\":1}}],[\"stf训练|stf训练\",{\"2\":{\"5\":1}}],[\"p2p\",{\"2\":{\"2129\":1,\"2708\":1}}],[\"pβ∗=σ\",{\"2\":{\"2046\":1}}],[\"pβ∗​=σ\",{\"2\":{\"2046\":1}}],[\"pβ∗​\",{\"2\":{\"2046\":1}}],[\"pβ∗\",{\"2\":{\"2046\":1}}],[\"p=p\",{\"2\":{\"2611\":1}}],[\"p=softmax\",{\"2\":{\"1868\":2,\"2080\":2}}],[\"p=2\",{\"2\":{\"1831\":2}}],[\"psi\",{\"2\":{\"1942\":3,\"1992\":1,\"1993\":3,\"2045\":1}}],[\"ps\",{\"2\":{\"1703\":3,\"2648\":2}}],[\"p^\",{\"2\":{\"1536\":2}}],[\"pdrop​\",{\"2\":{\"2080\":1}}],[\"pdropped​=dropout\",{\"2\":{\"2080\":1}}],[\"pdropped=dropout\",{\"2\":{\"2080\":1}}],[\"pdrop\",{\"2\":{\"2080\":1}}],[\"pddl\",{\"2\":{\"1465\":1}}],[\"pdfs\",{\"2\":{\"2050\":1}}],[\"pdf文件\",{\"2\":{\"2001\":1,\"2052\":1}}],[\"pdf格式数据的解析难点及解决方案\",{\"2\":{\"411\":1}}],[\"pdf解析\",{\"2\":{\"384\":1}}],[\"pdf\",{\"2\":{\"153\":1,\"469\":1,\"631\":1,\"1492\":1,\"1920\":1,\"2368\":1}}],[\"phone\",{\"2\":{\"2434\":1}}],[\"phase\",{\"2\":{\"1910\":2,\"2079\":2}}],[\"phi6φ\",{\"2\":{\"2369\":1}}],[\"phin1​⋅φ\",{\"2\":{\"2308\":1}}],[\"phi2⋅n1​⋅φ⋅n=2φ\",{\"2\":{\"2308\":2}}],[\"phi2φ+2φ+\",{\"2\":{\"2161\":1}}],[\"phi4φ\",{\"2\":{\"2276\":1,\"2621\":1}}],[\"phiφ\",{\"2\":{\"2161\":1,\"2621\":1}}],[\"phiδϕ\",{\"2\":{\"1962\":1}}],[\"phi\",{\"2\":{\"1685\":5,\"2161\":7,\"2308\":3,\"2434\":1,\"2621\":2,\"2641\":2}}],[\"phi$$\",{\"2\":{\"488\":4}}],[\"phrasing\",{\"2\":{\"1458\":1}}],[\"pymupdf\",{\"2\":{\"2270\":1}}],[\"pypdf\",{\"2\":{\"1716\":1}}],[\"py\",{\"2\":{\"1451\":1,\"1542\":1,\"1997\":1,\"2048\":1,\"2142\":1,\"2347\":3}}],[\"python代码实现\",{\"2\":{\"646\":1}}],[\"python入门课程\",{\"2\":{\"302\":1}}],[\"python数据科学手册\",{\"2\":{\"302\":1}}],[\"python编程\",{\"2\":{\"278\":1,\"302\":1}}],[\"python\",{\"2\":{\"67\":1,\"302\":1,\"1612\":1,\"1816\":1,\"2347\":3,\"2408\":3,\"2433\":1,\"2640\":1}}],[\"python自然语言处理\",{\"2\":{\"67\":1}}],[\"pytorch中默认梯度会累积\",{\"2\":{\"640\":1}}],[\"pytorch官方文档\",{\"2\":{\"165\":1}}],[\"pytorch\",{\"0\":{\"996\":1},\"2\":{\"65\":1,\"266\":1,\"278\":1,\"544\":1,\"771\":1,\"848\":1,\"996\":1,\"1125\":1,\"2055\":2,\"2066\":1,\"2118\":1,\"2178\":1,\"2252\":1}}],[\"png\",{\"2\":{\"1329\":4}}],[\"pt\",{\"2\":{\"2201\":1,\"2500\":1}}],[\"ptq方法\",{\"0\":{\"1931\":1},\"1\":{\"1982\":1,\"2033\":1,\"2085\":1}}],[\"ptq的主要优势在于其简单性和高效性\",{\"2\":{\"1874\":1}}],[\"ptq\",{\"0\":{\"1260\":1,\"1753\":1,\"1874\":1},\"1\":{\"1813\":1,\"1874\":1,\"1931\":2,\"1982\":2,\"2033\":2,\"2085\":2},\"2\":{\"1260\":4,\"1753\":1,\"1813\":1}}],[\"ptx在原有的ppo优化目标基础上增加了预训练数据集上的优化目标\",{\"2\":{\"992\":1}}],[\"ptx优化目标\",{\"0\":{\"992\":1}}],[\"ptx通过在ppo优化目标中增加预训练损失\",{\"2\":{\"911\":1}}],[\"ptx\",{\"2\":{\"875\":1,\"1323\":1}}],[\"ptx方法通过增加预训练损失有效减轻了对齐税的影响\",{\"2\":{\"1223\":1}}],[\"ptx方法\",{\"2\":{\"875\":1}}],[\"ppp\",{\"2\":{\"2349\":1,\"2505\":2,\"2517\":1}}],[\"pp\",{\"0\":{\"2253\":1},\"2\":{\"2081\":1,\"2177\":1,\"2710\":1}}],[\"ppl比较\",{\"2\":{\"626\":1}}],[\"ppl\",{\"0\":{\"516\":1},\"2\":{\"583\":1}}],[\"ppo的重要性采样处理\",{\"0\":{\"2569\":1}}],[\"ppo的四个关键模型\",{\"2\":{\"1954\":1}}],[\"ppo的实现需要大量计算资源\",{\"2\":{\"1841\":1}}],[\"ppo优化\",{\"0\":{\"1780\":1}}],[\"ppo优化与对齐税影响分析\",{\"0\":{\"743\":1},\"1\":{\"774\":1,\"805\":1,\"839\":1,\"875\":1,\"911\":1,\"950\":1,\"992\":1,\"1033\":1,\"1076\":1,\"1123\":1,\"1174\":1,\"1223\":1,\"1274\":1,\"1323\":1,\"1369\":1}}],[\"ppo存在的两个主要缺点\",{\"2\":{\"1539\":1}}],[\"ppo是一种用于策略优化的算法\",{\"2\":{\"1523\":1}}],[\"ppo在优化过程中可能引发所谓的\",{\"2\":{\"875\":1}}],[\"ppo因其稳定性和高效性\",{\"2\":{\"829\":1}}],[\"ppo中截断范围的参数\",{\"2\":{\"766\":1}}],[\"ppo通过引入clip操作简化了复杂的数学推导\",{\"2\":{\"766\":1}}],[\"ppo通过clip操作进行策略截断\",{\"2\":{\"658\":1}}],[\"ppo采用固定截断\",{\"2\":{\"658\":1}}],[\"ppo利用重要性采样提高样本利用效率\",{\"2\":{\"623\":1}}],[\"ppo基于trpo的优化目标进行了简化\",{\"2\":{\"590\":1}}],[\"ppo主要有两个版本\",{\"2\":{\"521\":1}}],[\"ppo训练后的模型输出风格趋于一致\",{\"2\":{\"1650\":1}}],[\"ppo训练中的关键技巧\",{\"0\":{\"505\":1},\"1\":{\"537\":1,\"570\":1,\"603\":1}}],[\"ppo训练的trick和问题\",{\"0\":{\"478\":1},\"1\":{\"505\":1,\"537\":1,\"570\":1,\"603\":1,\"637\":1,\"671\":1,\"709\":1},\"2\":{\"151\":1}}],[\"ppo\",{\"0\":{\"992\":1},\"2\":{\"478\":1,\"521\":2,\"766\":1,\"805\":1,\"875\":1,\"911\":1,\"992\":1,\"1223\":1,\"1449\":1,\"1486\":1,\"1489\":1,\"1495\":1,\"1546\":1,\"1589\":1,\"1622\":1,\"1841\":1,\"1917\":1,\"1955\":1,\"2081\":2,\"2535\":1}}],[\"ppo缺点\",{\"0\":{\"1401\":1},\"1\":{\"1449\":1,\"1495\":1,\"1539\":1,\"1589\":1,\"1642\":1,\"1696\":1,\"1754\":1,\"1814\":1},\"2\":{\"151\":1}}],[\"ppo算法通过剪辑机制有效地稳定了策略更新过程\",{\"2\":{\"2190\":1,\"2230\":1}}],[\"ppo算法通过计算策略的损失函数来更新actor模型\",{\"2\":{\"1572\":1}}],[\"ppo算法利用优势函数指导策略更新\",{\"2\":{\"2044\":1,\"2097\":1}}],[\"ppo算法简化\",{\"0\":{\"2044\":1,\"2097\":1}}],[\"ppo算法应用\",{\"2\":{\"1631\":1}}],[\"ppo算法中的actor损失函数定义为\",{\"2\":{\"1622\":1}}],[\"ppo算法中的损失计算涉及到优势函数\",{\"2\":{\"1572\":1}}],[\"ppo算法需要大量计算资源\",{\"2\":{\"1539\":1}}],[\"ppo算法和代码\",{\"2\":{\"864\":1}}],[\"ppo算法的基本原理\",{\"0\":{\"590\":1}}],[\"ppo算法\",{\"0\":{\"460\":1},\"1\":{\"489\":1,\"521\":1,\"554\":1,\"590\":1,\"623\":1,\"658\":1,\"695\":1,\"731\":1,\"766\":1,\"796\":1,\"829\":1,\"864\":1},\"2\":{\"151\":1,\"489\":1,\"766\":1,\"1478\":1,\"1479\":1,\"1767\":1,\"1829\":1}}],[\"p采样和温度调节对生成质量的影响\",{\"2\":{\"510\":1}}],[\"p或top\",{\"2\":{\"481\":1}}],[\"punishment机制的适用性\",{\"2\":{\"2701\":1}}],[\"punishment机制\",{\"2\":{\"2695\":1}}],[\"punishment\",{\"2\":{\"2689\":1}}],[\"pushing\",{\"2\":{\"2199\":1}}],[\"purdue\",{\"2\":{\"454\":1}}],[\"public\",{\"2\":{\"12\":1,\"47\":1,\"48\":1,\"762\":1,\"769\":1,\"783\":1}}],[\"peqa是一种新的量化感知微调技术\",{\"2\":{\"1588\":1}}],[\"peqa\",{\"0\":{\"1588\":1}}],[\"pett​⋅pet+δt​=pett​⋅pet−δt​\",{\"2\":{\"1343\":1}}],[\"pett⋅pet+δt=pett⋅pet−δtpe\",{\"2\":{\"1343\":1}}],[\"pet​=\",{\"2\":{\"1246\":1}}],[\"pet=\",{\"2\":{\"1246\":1}}],[\"peft方法展示了在资源受限环境下\",{\"2\":{\"2136\":1}}],[\"peft方法显著减少显存占用\",{\"2\":{\"1932\":1}}],[\"peft\",{\"0\":{\"1695\":1,\"1755\":1},\"2\":{\"1050\":1,\"1695\":1,\"1875\":1,\"1912\":6,\"1983\":1,\"2048\":2,\"2142\":1}}],[\"performance\",{\"2\":{\"1324\":1}}],[\"perp⊥\",{\"2\":{\"1222\":1}}],[\"perplexity\",{\"0\":{\"558\":1},\"2\":{\"180\":1,\"268\":4,\"464\":1,\"558\":3}}],[\"per\",{\"0\":{\"939\":1,\"981\":2,\"1022\":1},\"2\":{\"981\":2,\"1022\":1,\"1229\":3,\"1703\":3,\"1982\":2,\"2033\":1,\"2217\":1,\"2228\":2,\"2561\":6,\"2600\":1}}],[\"penalty\",{\"0\":{\"537\":1}}],[\"penalty和ppo\",{\"2\":{\"521\":1}}],[\"pe\",{\"2\":{\"263\":1,\"1246\":1,\"1343\":3}}],[\"pij∈rbr×bc\",{\"2\":{\"2643\":1}}],[\"pijvjp\",{\"2\":{\"2611\":1,\"2643\":1}}],[\"pij\",{\"2\":{\"2597\":2}}],[\"pij=torch\",{\"2\":{\"2597\":1}}],[\"pij​∈rbr​×bc​\",{\"2\":{\"2643\":1}}],[\"pij​vj​\",{\"2\":{\"2643\":1}}],[\"pij​=torch\",{\"2\":{\"2597\":1}}],[\"pij​\",{\"2\":{\"2349\":5,\"2597\":3}}],[\"pijp\",{\"2\":{\"2349\":5,\"2597\":1}}],[\"pid\",{\"2\":{\"2347\":1}}],[\"piπ与参考策略πref\",{\"2\":{\"1552\":1}}],[\"pipedream相对于gpipe的改进主要体现在内存方面\",{\"2\":{\"2694\":1}}],[\"pipedream\",{\"0\":{\"2694\":1}}],[\"pipeline则是减小切分粒度\",{\"2\":{\"2697\":1}}],[\"pipeline却反其道而行之\",{\"2\":{\"2697\":1}}],[\"pipeline的方法\",{\"2\":{\"2688\":1}}],[\"pipeline重用部分sft数据集\",{\"2\":{\"2504\":1}}],[\"pipeline\",{\"0\":{\"2253\":1,\"2685\":1,\"2697\":1},\"1\":{\"2688\":1,\"2691\":1,\"2694\":1,\"2697\":1,\"2700\":1,\"2703\":1,\"2704\":1,\"2705\":1,\"2706\":1,\"2707\":1,\"2708\":1,\"2709\":1,\"2710\":1,\"2711\":1},\"2\":{\"1451\":1,\"1592\":1,\"1646\":1,\"1885\":1,\"2253\":1,\"2697\":2}}],[\"pip\",{\"2\":{\"1279\":1,\"1326\":1}}],[\"pi^\",{\"0\":{\"1889\":1},\"2\":{\"767\":1,\"1889\":2,\"1944\":2,\"1994\":2,\"2046\":3}}],[\"pile\",{\"2\":{\"669\":1,\"741\":1}}],[\"pi$$\",{\"2\":{\"290\":1,\"748\":1,\"778\":1}}],[\"pi\",{\"2\":{\"180\":1,\"290\":2,\"537\":2,\"581\":1,\"586\":3,\"590\":9,\"614\":6,\"647\":3,\"656\":15,\"695\":1,\"723\":3,\"732\":8,\"748\":5,\"757\":2,\"767\":2,\"779\":5,\"810\":5,\"1552\":5,\"1566\":1,\"1613\":1,\"1622\":4,\"1628\":6,\"1657\":7,\"1666\":2,\"1685\":4,\"1712\":4,\"1720\":4,\"1731\":2,\"1732\":4,\"1795\":8,\"1830\":5,\"1889\":2,\"1901\":1,\"1942\":3,\"1944\":3,\"1993\":3,\"1994\":1,\"2044\":7,\"2046\":3,\"2097\":7,\"2306\":1,\"2357\":1,\"2485\":6,\"2528\":2,\"2531\":1,\"2542\":1,\"2577\":2}}],[\"planner\",{\"0\":{\"2423\":1}}],[\"planning步骤被外包给了外部工具\",{\"2\":{\"1465\":1}}],[\"planning\",{\"0\":{\"1283\":1},\"1\":{\"1330\":1,\"1375\":1,\"1420\":1,\"1465\":1},\"2\":{\"1420\":1,\"1465\":1,\"1594\":1,\"2378\":1,\"2405\":2}}],[\"plan\",{\"2\":{\"2370\":1,\"2601\":1,\"2608\":1}}],[\"place\",{\"2\":{\"2079\":1,\"2129\":1}}],[\"play\",{\"2\":{\"956\":1}}],[\"playing\",{\"2\":{\"956\":1,\"1225\":1}}],[\"plam2\",{\"0\":{\"974\":1},\"1\":{\"1015\":1,\"1057\":1,\"1102\":1,\"1152\":1,\"1201\":1,\"1252\":1,\"1301\":1,\"1348\":1,\"1393\":1,\"1441\":1},\"2\":{\"172\":1}}],[\"plam\",{\"0\":{\"973\":1},\"1\":{\"1014\":1,\"1055\":1,\"1100\":1,\"1149\":1,\"1198\":1,\"1248\":1,\"1298\":1,\"1345\":1,\"1390\":1,\"1437\":1,\"1483\":1,\"1527\":1},\"2\":{\"172\":1}}],[\"platform\",{\"2\":{\"102\":1}}],[\"plus\",{\"2\":{\"16\":4,\"17\":1,\"21\":4,\"24\":3,\"1156\":1,\"1997\":2}}],[\"pca\",{\"2\":{\"39\":1}}],[\"pruner\",{\"2\":{\"1143\":2}}],[\"pruning\",{\"2\":{\"763\":1}}],[\"prm过程奖励模型挑战\",{\"2\":{\"2642\":1}}],[\"prm800k\",{\"2\":{\"741\":1}}],[\"prm\",{\"2\":{\"528\":1,\"2647\":1}}],[\"principles\",{\"2\":{\"106\":1}}],[\"print\",{\"2\":{\"10\":19,\"213\":1,\"266\":1,\"324\":1,\"332\":1,\"391\":1,\"480\":1,\"485\":1,\"508\":1,\"647\":1,\"656\":2,\"1025\":2,\"1111\":1,\"1208\":2,\"1435\":1,\"1823\":1,\"1837\":1,\"1951\":1,\"2108\":2,\"2433\":2,\"2618\":5}}],[\"primer\",{\"2\":{\"16\":4,\"17\":1,\"21\":4,\"24\":3}}],[\"provided\",{\"2\":{\"2050\":1}}],[\"professional\",{\"2\":{\"2050\":1}}],[\"professor\",{\"2\":{\"1458\":2}}],[\"projection=false\",{\"2\":{\"1912\":1}}],[\"projection=true\",{\"2\":{\"1912\":1}}],[\"projection\",{\"2\":{\"1912\":4}}],[\"program\",{\"0\":{\"1730\":1},\"2\":{\"1730\":1,\"1788\":1}}],[\"programming\",{\"0\":{\"12\":1,\"15\":1},\"2\":{\"12\":1,\"2081\":2}}],[\"pronouns\",{\"2\":{\"1458\":1}}],[\"propositions\",{\"2\":{\"1458\":2}}],[\"proposition\",{\"0\":{\"1412\":1},\"2\":{\"1367\":2,\"1412\":1,\"1458\":3}}],[\"propto\",{\"2\":{\"723\":1}}],[\"proximal\",{\"2\":{\"521\":1,\"875\":1,\"1523\":1,\"1533\":1,\"1596\":1,\"1841\":1,\"1917\":1,\"2467\":1,\"2545\":1}}],[\"probabilities\",{\"2\":{\"2600\":1}}],[\"probability\",{\"2\":{\"427\":3}}],[\"prob\",{\"2\":{\"626\":1,\"820\":2}}],[\"probs\",{\"2\":{\"135\":2,\"364\":6,\"619\":4,\"766\":2,\"820\":2,\"1622\":4}}],[\"product优化梯度问题\",{\"2\":{\"236\":1}}],[\"product\",{\"0\":{\"2102\":1},\"1\":{\"2152\":1,\"2195\":1,\"2234\":1},\"2\":{\"213\":3}}],[\"product计算\",{\"0\":{\"213\":1}}],[\"product是attention机制的核心计算公式\",{\"2\":{\"130\":1}}],[\"product的计算公式\",{\"0\":{\"130\":1}}],[\"processes\",{\"2\":{\"2347\":1}}],[\"process\",{\"0\":{\"1544\":1},\"2\":{\"324\":1,\"1864\":1,\"2201\":1,\"2347\":1,\"2408\":1}}],[\"processing\",{\"2\":{\"67\":3,\"2500\":3}}],[\"procedural\",{\"0\":{\"12\":1}}],[\"prompt中第i个token在kv缓存中的存储序号为\",{\"2\":{\"2356\":1}}],[\"prompter\",{\"2\":{\"2227\":1}}],[\"prompt就是前缀\",{\"2\":{\"2117\":1}}],[\"prompt的重复计算\",{\"2\":{\"2064\":1}}],[\"prompt对应的key和value值\",{\"2\":{\"2064\":1}}],[\"prompt时\",{\"2\":{\"2064\":1}}],[\"prompt部分进行一次计算\",{\"2\":{\"2064\":1}}],[\"prompt示例\",{\"0\":{\"2050\":1}}],[\"prompt有\",{\"2\":{\"1843\":1}}],[\"prompting\",{\"0\":{\"1774\":1},\"2\":{\"1924\":1}}],[\"prompt到response的过程可以被看作是马尔可夫决策过程\",{\"2\":{\"1618\":1}}],[\"prompttemplate\",{\"2\":{\"1458\":1}}],[\"prompts\",{\"2\":{\"1412\":1,\"1680\":1,\"1856\":1,\"1873\":1,\"1930\":2,\"2082\":2,\"2500\":3}}],[\"prompt由state和action构成的新demonstrations\",{\"2\":{\"1222\":1}}],[\"prompt\",{\"0\":{\"450\":1,\"1640\":1,\"1649\":1,\"1873\":1,\"1930\":1,\"1981\":2,\"2064\":1,\"2166\":1,\"2168\":1},\"1\":{\"477\":1,\"504\":1,\"536\":1,\"569\":1,\"602\":1,\"636\":1,\"670\":1,\"708\":1,\"742\":1,\"773\":1,\"804\":1,\"838\":1,\"874\":1,\"910\":1,\"949\":1,\"991\":1,\"1032\":1,\"1075\":1,\"1122\":1,\"1173\":1,\"1222\":1,\"1273\":1,\"1322\":1,\"1368\":1,\"1413\":1,\"1459\":1,\"1504\":1,\"1550\":1,\"1600\":1,\"1694\":1,\"1702\":1,\"1752\":1,\"1760\":1,\"1812\":1,\"1820\":1,\"1873\":1,\"1930\":1,\"1981\":1,\"2032\":1,\"2082\":1,\"2117\":1,\"2133\":1,\"2166\":1,\"2179\":1,\"2219\":1,\"2254\":1,\"2289\":1},\"2\":{\"49\":1,\"57\":1,\"151\":1,\"237\":1,\"881\":1,\"1175\":1,\"1333\":1,\"1368\":1,\"1392\":1,\"1439\":1,\"1458\":1,\"1582\":1,\"1619\":1,\"1682\":1,\"1689\":1,\"1694\":1,\"1702\":1,\"1708\":2,\"1752\":4,\"1766\":1,\"1794\":1,\"1796\":1,\"1848\":1,\"1873\":1,\"1885\":1,\"1912\":2,\"1930\":1,\"1935\":1,\"1940\":1,\"1981\":2,\"2032\":3,\"2042\":1,\"2064\":1,\"2069\":1,\"2082\":1,\"2094\":1,\"2117\":3,\"2119\":1,\"2133\":1,\"2145\":1,\"2166\":4,\"2168\":2,\"2179\":1,\"2219\":3,\"2228\":1,\"2254\":2,\"2263\":1,\"2280\":3,\"2289\":2,\"2291\":1,\"2343\":1,\"2345\":1,\"2373\":1,\"2401\":1,\"2451\":1,\"2453\":1,\"2469\":1,\"2500\":27,\"2546\":1,\"2578\":1,\"2600\":4,\"2687\":1}}],[\"preview相当\",{\"2\":{\"2642\":1}}],[\"prepare\",{\"2\":{\"2201\":1,\"2500\":2}}],[\"preserve\",{\"2\":{\"2050\":1}}],[\"present\",{\"2\":{\"1458\":1}}],[\"preferred\",{\"2\":{\"2050\":1}}],[\"preferences\",{\"2\":{\"1633\":1,\"1920\":1}}],[\"preference\",{\"2\":{\"1495\":1,\"1517\":1,\"1814\":1,\"1902\":4,\"1976\":2}}],[\"prefill=2×batch\",{\"2\":{\"2263\":2}}],[\"prefilling\",{\"2\":{\"2228\":1,\"2263\":1}}],[\"prefill\",{\"0\":{\"1870\":1},\"2\":{\"1910\":1,\"2263\":1}}],[\"prefill环节在prompt较长时计算强度足够高\",{\"2\":{\"1843\":1}}],[\"prefill是将1个请求的prompt一次性转换为kv\",{\"2\":{\"1782\":1}}],[\"prefill和decode\",{\"0\":{\"1782\":1}}],[\"prefill阶段\",{\"0\":{\"812\":1}}],[\"prefix0\",{\"2\":{\"1922\":1}}],[\"prefixencoder\",{\"2\":{\"1912\":1}}],[\"prefixlm\",{\"2\":{\"1047\":1}}],[\"prefix\",{\"0\":{\"363\":1,\"1635\":1,\"1865\":1,\"2117\":1},\"1\":{\"1689\":1,\"1745\":1,\"1803\":1,\"1865\":1,\"1922\":1,\"1974\":1,\"2024\":1,\"2074\":1,\"2126\":1,\"2173\":1,\"2215\":1},\"2\":{\"151\":1,\"595\":1,\"629\":1,\"702\":1,\"738\":1,\"1006\":1,\"1091\":1,\"1689\":1,\"1745\":1,\"1865\":1,\"1912\":16,\"1922\":2,\"2024\":1,\"2117\":2}}],[\"pretrain\",{\"2\":{\"741\":1,\"1150\":1,\"1685\":1,\"2233\":1}}],[\"pretraining\",{\"2\":{\"501\":1,\"632\":1,\"1239\":1}}],[\"precision\",{\"0\":{\"1984\":1},\"2\":{\"734\":1,\"1208\":1,\"1984\":3,\"2354\":1}}],[\"predict\",{\"0\":{\"2536\":1},\"1\":{\"2546\":1,\"2554\":1},\"2\":{\"515\":1,\"1208\":1,\"2546\":1}}],[\"prediction\",{\"0\":{\"1037\":1},\"2\":{\"424\":1,\"449\":1,\"503\":1,\"919\":1}}],[\"pred\",{\"2\":{\"515\":3}}],[\"pre\",{\"0\":{\"95\":1,\"113\":1,\"508\":1},\"1\":{\"110\":1,\"128\":1,\"148\":1,\"169\":1,\"190\":1,\"211\":1,\"234\":1,\"258\":1,\"282\":1},\"2\":{\"5\":21,\"73\":1,\"115\":1,\"128\":1,\"169\":1,\"230\":1,\"426\":1,\"475\":1,\"508\":4,\"660\":1,\"685\":1,\"819\":1,\"889\":1,\"961\":1,\"1002\":1,\"1112\":1,\"1385\":1,\"1912\":2}}],[\"pandoc\",{\"2\":{\"2270\":1}}],[\"pandas官方文档\",{\"2\":{\"302\":1}}],[\"pandas\",{\"2\":{\"278\":1}}],[\"pal以及tool\",{\"2\":{\"1788\":1}}],[\"palm使用标准的transformer架构\",{\"2\":{\"1198\":1}}],[\"palm采用了标准的transformer架构\",{\"2\":{\"1149\":1}}],[\"palm\",{\"2\":{\"363\":1,\"495\":2,\"595\":1,\"1015\":1,\"1055\":1,\"1057\":2,\"1102\":2,\"1152\":1,\"1252\":1,\"1441\":3}}],[\"pai\",{\"2\":{\"1404\":1,\"1542\":1,\"1878\":2}}],[\"pairs\",{\"2\":{\"1976\":1}}],[\"pairwise\",{\"2\":{\"1582\":1}}],[\"pairwiseloss\",{\"2\":{\"1582\":1}}],[\"pair\",{\"0\":{\"274\":1},\"1\":{\"297\":1,\"319\":1,\"342\":1,\"366\":1,\"392\":1,\"418\":1,\"443\":1,\"470\":1,\"497\":1,\"529\":1,\"562\":1,\"597\":1,\"631\":1},\"2\":{\"5\":2,\"308\":1,\"319\":1,\"368\":1,\"391\":4,\"393\":1,\"407\":5,\"426\":1,\"933\":1,\"1096\":1,\"1302\":2}}],[\"past\",{\"2\":{\"1912\":5}}],[\"pasted\",{\"2\":{\"1329\":4}}],[\"pass\",{\"2\":{\"619\":1,\"2539\":1}}],[\"packed\",{\"2\":{\"917\":8}}],[\"pack\",{\"2\":{\"847\":3}}],[\"packing策略对模型性能影响的实验证据\",{\"2\":{\"2502\":1}}],[\"packing策略在大批量数据上对泛化效果无损\",{\"2\":{\"2278\":1}}],[\"packing可能损害泛化效果\",{\"2\":{\"2310\":1}}],[\"packing对泛化效果的影响\",{\"2\":{\"2310\":1}}],[\"packing\",{\"2\":{\"751\":1,\"813\":2,\"847\":2,\"881\":1,\"2449\":2}}],[\"padding=true\",{\"2\":{\"2500\":1}}],[\"padding机制\",{\"2\":{\"1072\":1}}],[\"padding\",{\"2\":{\"917\":1,\"1170\":1,\"2500\":1}}],[\"pad\",{\"2\":{\"782\":1}}],[\"page\",{\"2\":{\"2050\":2}}],[\"pagedattention\",{\"2\":{\"2129\":1}}],[\"pagedattention实现了高效的内存管理和共享\",{\"2\":{\"846\":1}}],[\"pagedattention跟踪物理块的引用计数\",{\"2\":{\"750\":1}}],[\"pagedattention的另外一个好处是高效内存共享\",{\"2\":{\"750\":1}}],[\"pagedattention把每个序列的kv缓存进行了分块\",{\"2\":{\"750\":1}}],[\"pagedattention灵感来自于操作系统中虚拟内存和分页的经典思想\",{\"2\":{\"750\":1}}],[\"pageattention原理\",{\"0\":{\"716\":1},\"1\":{\"750\":1,\"781\":1,\"812\":1,\"846\":1},\"2\":{\"193\":1}}],[\"path\",{\"2\":{\"2177\":3,\"2201\":1,\"2233\":1}}],[\"pathways论文分析与总结\",{\"2\":{\"1527\":1}}],[\"pathways\",{\"2\":{\"1149\":1}}],[\"patch\",{\"2\":{\"1404\":1,\"1542\":1,\"1878\":2}}],[\"pat\",{\"2\":{\"391\":1}}],[\"parse\",{\"2\":{\"2235\":1}}],[\"parser\",{\"2\":{\"2227\":1}}],[\"paraphraser\",{\"2\":{\"2601\":1}}],[\"paraphrasing\",{\"2\":{\"2601\":1}}],[\"params\",{\"2\":{\"1771\":4,\"2192\":5}}],[\"parameters\",{\"2\":{\"619\":2,\"766\":2,\"820\":1,\"1771\":6,\"2201\":1,\"2400\":1}}],[\"parameter\",{\"2\":{\"435\":1,\"1831\":1,\"1883\":4,\"2218\":1,\"2288\":1}}],[\"parallelism\",{\"0\":{\"2489\":1,\"2515\":1,\"2685\":1},\"1\":{\"2503\":1,\"2526\":1,\"2537\":1,\"2688\":1,\"2691\":1,\"2694\":1,\"2697\":1,\"2700\":1,\"2703\":1,\"2704\":1,\"2705\":1,\"2706\":1,\"2707\":1,\"2708\":1,\"2709\":1,\"2710\":1,\"2711\":1},\"2\":{\"2218\":1,\"2253\":1,\"2374\":1,\"2537\":1}}],[\"parallelization\",{\"0\":{\"1985\":1},\"1\":{\"2037\":1}}],[\"parallel的并行优化技术有望在未来进一步推广到其他领域\",{\"2\":{\"706\":1}}],[\"parallel机制\",{\"2\":{\"567\":1}}],[\"parallel\",{\"0\":{\"2178\":1,\"2218\":1,\"2253\":1},\"2\":{\"502\":1,\"634\":1,\"1389\":1,\"1451\":2,\"1552\":1,\"1592\":2,\"1646\":2,\"1720\":1,\"1944\":1,\"2433\":1,\"2711\":1}}],[\"paragraphs\",{\"2\":{\"2050\":1}}],[\"paragraph\",{\"2\":{\"18\":1}}],[\"partial\",{\"2\":{\"18\":1,\"622\":2}}],[\"partial^r\",{\"2\":{\"18\":1}}],[\"parts方法\",{\"2\":{\"184\":1}}],[\"parts插值引入波长概念\",{\"2\":{\"386\":1}}],[\"parts插值关注嵌入维度的波长与上下文长度的关系\",{\"2\":{\"159\":1}}],[\"parts插值\",{\"0\":{\"267\":1,\"359\":1},\"1\":{\"290\":1,\"312\":1},\"2\":{\"159\":1}}],[\"partsize\",{\"2\":{\"47\":3}}],[\"parts\",{\"0\":{\"120\":1},\"1\":{\"139\":1,\"159\":1,\"179\":1,\"200\":1,\"221\":1,\"244\":1,\"267\":1,\"290\":1,\"312\":1,\"335\":1,\"359\":1,\"386\":1,\"412\":1,\"439\":1,\"466\":1},\"2\":{\"5\":1,\"47\":4,\"84\":1,\"359\":1,\"1458\":2}}],[\"parts|ntk插值方法解析与优化\",{\"2\":{\"5\":1}}],[\"p\",{\"0\":{\"226\":1,\"317\":1,\"1625\":1,\"1627\":1},\"1\":{\"249\":1,\"272\":1,\"295\":1,\"317\":1,\"340\":2,\"364\":2,\"390\":1,\"416\":1,\"441\":1,\"468\":1,\"496\":1,\"528\":1,\"561\":1,\"596\":1,\"630\":1,\"665\":1,\"703\":1,\"739\":1,\"771\":1,\"1680\":1,\"1682\":1,\"1736\":1,\"1738\":1,\"1794\":1,\"1796\":1,\"1856\":1,\"1858\":1,\"1912\":1,\"1914\":1,\"1965\":1,\"1967\":1,\"2017\":1,\"2019\":1,\"2069\":1,\"2121\":1},\"2\":{\"5\":2,\"98\":1,\"151\":2,\"268\":1,\"340\":1,\"355\":4,\"444\":3,\"468\":1,\"503\":1,\"558\":1,\"623\":6,\"630\":1,\"647\":8,\"656\":7,\"665\":1,\"676\":1,\"732\":2,\"767\":3,\"771\":1,\"810\":1,\"1093\":1,\"1142\":1,\"1279\":1,\"1405\":2,\"1536\":3,\"1625\":1,\"1680\":2,\"1682\":1,\"1727\":1,\"1738\":1,\"1796\":1,\"1868\":1,\"1967\":1,\"2017\":2,\"2046\":2,\"2080\":5,\"2275\":3,\"2289\":6,\"2528\":2,\"2539\":2,\"2597\":6,\"2611\":2,\"2618\":1,\"2648\":1}}],[\"pop\",{\"2\":{\"2400\":1}}],[\"popular\",{\"2\":{\"1458\":1}}],[\"policyloss\",{\"2\":{\"1622\":1}}],[\"policy方法时\",{\"2\":{\"758\":1}}],[\"policyiteration\",{\"2\":{\"656\":1}}],[\"policynet\",{\"2\":{\"619\":2,\"766\":3,\"820\":3}}],[\"policy\",{\"0\":{\"98\":1},\"2\":{\"5\":5,\"521\":1,\"647\":2,\"653\":2,\"656\":5,\"676\":1,\"724\":1,\"820\":4,\"875\":1,\"1523\":1,\"1533\":1,\"1596\":2,\"1622\":1,\"1731\":6,\"1841\":1,\"1902\":1,\"1917\":3,\"1954\":1,\"2213\":3,\"2273\":1,\"2467\":2,\"2545\":2,\"2605\":1,\"2662\":1}}],[\"possible\",{\"2\":{\"1458\":2}}],[\"positive\",{\"2\":{\"1368\":1}}],[\"position\",{\"2\":{\"247\":1,\"332\":3,\"1435\":3,\"1703\":1}}],[\"positional\",{\"0\":{\"84\":1},\"2\":{\"5\":11,\"174\":1,\"180\":1,\"332\":2,\"383\":1,\"1435\":2}}],[\"pos\",{\"2\":{\"332\":6,\"1435\":6}}],[\"post\",{\"0\":{\"95\":1,\"1260\":1},\"1\":{\"110\":1,\"128\":1,\"148\":1,\"169\":1,\"190\":1,\"211\":1,\"234\":1,\"258\":1,\"282\":1},\"2\":{\"5\":2,\"73\":1,\"128\":1,\"169\":1,\"1013\":1,\"1917\":1}}],[\"ay=xa\",{\"2\":{\"2526\":1}}],[\"afe\",{\"0\":{\"2349\":1}}],[\"a∈rr×k\",{\"2\":{\"2013\":1}}],[\"a∈rr×ka\",{\"2\":{\"2013\":1}}],[\"a∈a∑​qπθ​​\",{\"2\":{\"723\":1}}],[\"a←a−η×ga​\",{\"2\":{\"1891\":1}}],[\"a←a−η×gaa\",{\"2\":{\"1891\":1}}],[\"america\",{\"2\":{\"1458\":1}}],[\"amp\",{\"0\":{\"73\":1,\"98\":1,\"981\":1},\"2\":{\"5\":15,\"67\":1,\"73\":1,\"98\":1,\"247\":2,\"285\":2,\"734\":1,\"1250\":1,\"1344\":3,\"1364\":2,\"1795\":3,\"2537\":1}}],[\"avoid\",{\"2\":{\"1368\":1}}],[\"agg\",{\"2\":{\"1688\":3}}],[\"agi\",{\"0\":{\"1188\":1},\"1\":{\"1238\":1,\"1289\":1,\"1336\":1,\"1382\":1,\"1429\":1},\"2\":{\"1136\":1}}],[\"agent对草稿进行修改\",{\"2\":{\"2363\":1}}],[\"agent会回顾初稿\",{\"2\":{\"2363\":1}}],[\"agent会主动获取相关信息\",{\"2\":{\"2363\":1}}],[\"agent会先询问是否需要进行一些网络研究\",{\"2\":{\"2363\":1}}],[\"agent会将一个复杂的大任务拆分为更小\",{\"2\":{\"1330\":1}}],[\"agent应用场景\",{\"2\":{\"2166\":1}}],[\"agent之间的对比图\",{\"2\":{\"1788\":1}}],[\"agent方法\",{\"2\":{\"1608\":1}}],[\"agent能够对历史动作进行自我批评和反思\",{\"2\":{\"1557\":1}}],[\"agent能够通过命令行执行任务\",{\"2\":{\"1118\":1}}],[\"agent+rl\",{\"0\":{\"1529\":1},\"1\":{\"1578\":1},\"2\":{\"1578\":1}}],[\"agentboard\",{\"0\":{\"1453\":1,\"1500\":1},\"1\":{\"1544\":1,\"1594\":1,\"1648\":1,\"1701\":1,\"1759\":1,\"1819\":1},\"2\":{\"1453\":5,\"1500\":1,\"1544\":1,\"1594\":1,\"1648\":1,\"1701\":1,\"1759\":2,\"1819\":1}}],[\"agentbench在论文中还通过一种归一化的算法\",{\"2\":{\"1268\":1}}],[\"agentbench通过对不同的llm在不同环境中的表现进行评分\",{\"2\":{\"1268\":1}}],[\"agentbench\",{\"0\":{\"1168\":1},\"1\":{\"1217\":1,\"1268\":1},\"2\":{\"1217\":1}}],[\"agent需要清楚这些步骤是什么\",{\"2\":{\"1375\":1}}],[\"agent在各种场景下的表现\",{\"2\":{\"1361\":1}}],[\"agents是能够在需要终身学习的真实世界任务中进行探索的智能体\",{\"2\":{\"2242\":1}}],[\"agents\",{\"0\":{\"1336\":1,\"2242\":1,\"2285\":1},\"1\":{\"2277\":1,\"2309\":1,\"2317\":1,\"2340\":1,\"2348\":1,\"2378\":1,\"2405\":1,\"2430\":1,\"2455\":1},\"2\":{\"1336\":1,\"1485\":1,\"2317\":1,\"2378\":1,\"2405\":1,\"2430\":1,\"2455\":1}}],[\"agent=llm+工具调用+规划+记忆\",{\"2\":{\"1233\":2}}],[\"agent可能涉及单个外部系统\",{\"2\":{\"1233\":1}}],[\"agent可以用于解决一些更复杂且更贴近现实的任务\",{\"2\":{\"1118\":1}}],[\"agentic\",{\"0\":{\"1218\":1,\"1617\":1,\"1672\":1,\"1728\":1},\"1\":{\"1269\":1,\"1316\":1,\"1362\":1,\"1672\":1,\"1728\":2,\"1786\":2,\"1847\":2,\"1904\":2},\"2\":{\"1617\":2,\"1672\":2,\"1728\":1,\"1786\":1,\"1847\":1,\"1904\":1,\"2323\":1}}],[\"agent的一类\",{\"2\":{\"1674\":1}}],[\"agent的核心组成\",{\"0\":{\"1233\":1}}],[\"agent的定义可以概括为\",{\"2\":{\"1184\":1}}],[\"agent的评估与llm的评估在本质上存在差异\",{\"2\":{\"1118\":1}}],[\"agent是一种与pal\",{\"2\":{\"1788\":1}}],[\"agent是一种超越简单文本生成的人工智能系统\",{\"2\":{\"1184\":1}}],[\"agent是一个具有复杂推理能力\",{\"2\":{\"1184\":1}}],[\"agent调用的成本更高\",{\"2\":{\"1118\":1}}],[\"agenttuning\",{\"2\":{\"1008\":1}}],[\"agent\",{\"0\":{\"1184\":1,\"1188\":1,\"1316\":1,\"1408\":1,\"1520\":1,\"1617\":1,\"1674\":1,\"1788\":1,\"1904\":2,\"1906\":1,\"2448\":1},\"1\":{\"1233\":1,\"1238\":1,\"1289\":1,\"1336\":1,\"1382\":1,\"1429\":1,\"1454\":1,\"1501\":1,\"1545\":1,\"1569\":1,\"1619\":1,\"1672\":1,\"1728\":1,\"1730\":1,\"1786\":1,\"1788\":1,\"1847\":1,\"1849\":1,\"1904\":1},\"2\":{\"514\":1,\"572\":1,\"618\":1,\"745\":1,\"776\":1,\"807\":1,\"1136\":1,\"1139\":1,\"1151\":1,\"1233\":2,\"1407\":1,\"1474\":1,\"1500\":1,\"1578\":3,\"1617\":2,\"1833\":1,\"1904\":3,\"2269\":1,\"2363\":1,\"2469\":1}}],[\"agent评估框架汇总\",{\"0\":{\"1118\":1},\"1\":{\"1168\":1,\"1217\":1,\"1268\":1,\"1315\":1,\"1361\":1,\"1407\":1,\"1453\":1,\"1500\":1,\"1544\":1,\"1594\":1,\"1648\":1,\"1701\":1,\"1759\":1,\"1819\":1},\"2\":{\"237\":1}}],[\"a3\",{\"2\":{\"1047\":3}}],[\"a中的位置\",{\"2\":{\"1045\":1}}],[\"about\",{\"2\":{\"1458\":1}}],[\"abilities\",{\"2\":{\"1008\":1,\"1124\":2}}],[\"abs\",{\"2\":{\"647\":1,\"656\":1,\"1647\":1,\"2345\":1}}],[\"a2a\",{\"2\":{\"2537\":1}}],[\"a2\",{\"2\":{\"812\":1,\"1047\":3}}],[\"aaa\",{\"2\":{\"775\":1,\"2062\":1,\"2115\":2,\"2425\":1,\"2436\":2,\"2555\":1,\"2609\":1,\"2616\":5}}],[\"aaron\",{\"2\":{\"165\":1}}],[\"a0​\",{\"2\":{\"1787\":1}}],[\"a0a\",{\"2\":{\"1787\":1}}],[\"a0\",{\"2\":{\"646\":3,\"1787\":1,\"2526\":1}}],[\"a1a\",{\"2\":{\"2537\":1}}],[\"a1a2\",{\"2\":{\"2537\":1}}],[\"a100\",{\"2\":{\"2077\":1}}],[\"a1和sample\",{\"2\":{\"812\":1}}],[\"a1​​a2​​\",{\"2\":{\"2537\":1}}],[\"a1​\",{\"2\":{\"618\":1}}],[\"a1\",{\"2\":{\"618\":1,\"646\":2,\"1047\":3,\"2526\":1,\"2531\":4,\"2542\":4}}],[\"a^g\",{\"2\":{\"2446\":2}}],[\"a^2\",{\"2\":{\"2446\":2}}],[\"a^1\",{\"2\":{\"2446\":2}}],[\"a^i\",{\"2\":{\"2306\":2,\"2446\":2,\"2485\":3,\"2577\":2}}],[\"a^\",{\"2\":{\"590\":2,\"695\":1}}],[\"aπθka^\",{\"2\":{\"590\":1}}],[\"aπθk​​​\",{\"2\":{\"2044\":1,\"2097\":1}}],[\"aπθk​​为critic提供的优势函数估计\",{\"2\":{\"590\":1}}],[\"aπθk​​\",{\"2\":{\"590\":1,\"695\":1}}],[\"aπθk\",{\"2\":{\"590\":2,\"2044\":2,\"2097\":2}}],[\"a∼πθk​​\",{\"2\":{\"590\":1,\"2044\":1,\"2097\":1}}],[\"a∼πθk\",{\"2\":{\"590\":1,\"2044\":1,\"2097\":1}}],[\"a|s\",{\"2\":{\"586\":1,\"590\":4,\"656\":1,\"723\":1}}],[\"a∣s\",{\"2\":{\"586\":2,\"590\":8,\"656\":2,\"723\":2,\"732\":2,\"810\":2,\"2044\":8,\"2097\":8}}],[\"ati​∣\",{\"2\":{\"2531\":1,\"2542\":1}}],[\"ati​∣sti​\",{\"2\":{\"1942\":1,\"1993\":1}}],[\"ati∣\",{\"2\":{\"2531\":1,\"2542\":1}}],[\"ati∣sti\",{\"2\":{\"1942\":1,\"1993\":1}}],[\"at−​\",{\"2\":{\"1634\":1}}],[\"at−\",{\"2\":{\"1634\":1}}],[\"at2​\",{\"2\":{\"1536\":1}}],[\"at2\",{\"2\":{\"1536\":1}}],[\"at1​\",{\"2\":{\"1536\":2}}],[\"at1\",{\"2\":{\"1536\":2}}],[\"atomic\",{\"2\":{\"1367\":1}}],[\"at=a\",{\"2\":{\"779\":2}}],[\"at+​\",{\"2\":{\"1634\":2}}],[\"at+\",{\"2\":{\"1634\":2}}],[\"at+n​\",{\"2\":{\"672\":1}}],[\"at+n\",{\"2\":{\"672\":1}}],[\"at+1​\",{\"2\":{\"611\":1,\"779\":1}}],[\"at+1\",{\"2\":{\"611\":1,\"779\":1}}],[\"ata\",{\"2\":{\"581\":1,\"1613\":1}}],[\"at∣st\",{\"2\":{\"537\":2,\"581\":1,\"757\":1,\"1613\":1,\"1622\":4,\"1732\":4,\"1942\":1,\"1993\":1}}],[\"at​=a\",{\"2\":{\"779\":2}}],[\"at​∣st​\",{\"2\":{\"537\":2,\"581\":1,\"757\":1,\"1613\":1,\"1622\":4,\"1732\":4,\"1942\":1,\"1993\":1}}],[\"at​\",{\"2\":{\"537\":1,\"611\":3,\"618\":1,\"640\":3,\"672\":3,\"710\":3,\"1622\":2}}],[\"at\",{\"2\":{\"537\":1,\"611\":3,\"618\":1,\"640\":3,\"672\":3,\"710\":3,\"1622\":2,\"2187\":1}}],[\"att\",{\"2\":{\"208\":2}}],[\"attn\",{\"2\":{\"135\":8,\"189\":1,\"2233\":1}}],[\"attention明显降低了对显存的需求\",{\"2\":{\"2648\":1}}],[\"attention只需要存储\",{\"2\":{\"2648\":1}}],[\"attention涉及到大量的矩阵乘法操作\",{\"2\":{\"2571\":1}}],[\"attention块\",{\"2\":{\"2027\":1}}],[\"attention块的计算复杂度和空间复杂度与序列长度n的二次方成正比\",{\"2\":{\"1807\":1}}],[\"attention块是一个关键组件\",{\"2\":{\"1807\":1}}],[\"attention时\",{\"2\":{\"1325\":1}}],[\"attention权重计算\",{\"2\":{\"1266\":1}}],[\"attention不仅节约了显存和耗时\",{\"2\":{\"1179\":1}}],[\"attention技术提升了效率和性能\",{\"2\":{\"1462\":1}}],[\"attention技术提高计算效率\",{\"2\":{\"1304\":1}}],[\"attention技术\",{\"2\":{\"1082\":1}}],[\"attention技术等\",{\"2\":{\"1060\":1}}],[\"attention计算需要对每个key和value执行一次乘加\",{\"2\":{\"376\":1}}],[\"attention计算\",{\"2\":{\"351\":1}}],[\"attention应用于多模态任务\",{\"2\":{\"333\":1}}],[\"attention扩展\",{\"2\":{\"327\":1}}],[\"attention智能化\",{\"2\":{\"327\":1}}],[\"attention避免解码过程信息泄漏\",{\"2\":{\"326\":1}}],[\"attention用于融合不同序列的信息\",{\"2\":{\"326\":1}}],[\"attention用于融合来自不同序列的信息\",{\"2\":{\"188\":1}}],[\"attention用于捕捉序列内部依赖关系\",{\"2\":{\"326\":1}}],[\"attention是否可以扩展到其他领域\",{\"2\":{\"304\":1}}],[\"attention是否可以在非语言任务中有效应用\",{\"2\":{\"304\":1}}],[\"attention是否适合所有长序列任务\",{\"2\":{\"233\":1}}],[\"attention在其他模型中的应用可能性\",{\"2\":{\"1370\":1}}],[\"attention在时间序列预测中的应用\",{\"2\":{\"350\":1}}],[\"attention在不同任务上的表现\",{\"2\":{\"281\":1,\"385\":1}}],[\"attention在多模态学习中具有潜力\",{\"2\":{\"232\":1}}],[\"attention显著降低计算复杂度\",{\"2\":{\"257\":1}}],[\"attention适合局部相关性任务\",{\"2\":{\"257\":1}}],[\"attention参数\",{\"2\":{\"256\":1}}],[\"attention更智能化\",{\"2\":{\"233\":1}}],[\"attention与cross\",{\"2\":{\"209\":1}}],[\"attention会导致信息泄漏\",{\"2\":{\"209\":1}}],[\"attention允许解码器关注编码器的输出\",{\"2\":{\"188\":1}}],[\"attention可能成为特定任务的有效解决方案\",{\"2\":{\"168\":1}}],[\"attention通过移除softmax操作\",{\"2\":{\"189\":1}}],[\"attention通过限制注意力矩阵中部分区域的计算来降低复杂度\",{\"2\":{\"168\":1}}],[\"attention通过计算query与所有key之间的点积\",{\"2\":{\"112\":1}}],[\"attention主要用于捕捉输入序列内部的依赖关系\",{\"2\":{\"126\":1}}],[\"attention的io复杂度是要显著小于标准attention的io复杂度的\",{\"2\":{\"2653\":1}}],[\"attention的io复杂度为\",{\"2\":{\"2653\":1}}],[\"attention的forward计算量为\",{\"2\":{\"2643\":1}}],[\"attention的计算方式如下图所示\",{\"2\":{\"2631\":1}}],[\"attention的计算复杂度为\",{\"2\":{\"147\":1}}],[\"attention的计算复杂度问题\",{\"0\":{\"147\":1}}],[\"attention的计算复杂度\",{\"2\":{\"109\":1}}],[\"attention的切分策略\",{\"0\":{\"2626\":1},\"1\":{\"2631\":1,\"2636\":1,\"2641\":1}}],[\"attention的头数为\",{\"2\":{\"1782\":1}}],[\"attention的核心算法\",{\"2\":{\"288\":1}}],[\"attention的动态优化方法\",{\"2\":{\"281\":1}}],[\"attention的代码示例\",{\"2\":{\"213\":1}}],[\"attention的重要性\",{\"2\":{\"209\":1}}],[\"attention的基本概念\",{\"0\":{\"112\":1}}],[\"attention的创新方法\",{\"0\":{\"75\":1},\"1\":{\"87\":1,\"101\":1,\"117\":1,\"136\":1,\"156\":1,\"176\":1,\"197\":1,\"218\":1,\"241\":1,\"264\":1,\"288\":1,\"310\":1,\"333\":1,\"358\":1,\"385\":1},\"2\":{\"5\":1,\"63\":1}}],[\"attention的创新方法|\",{\"2\":{\"5\":1}}],[\"attention和feed\",{\"2\":{\"2563\":1,\"2579\":1}}],[\"attention和mask\",{\"2\":{\"1009\":1}}],[\"attention和linear\",{\"2\":{\"109\":1}}],[\"attention和cross\",{\"2\":{\"93\":1,\"256\":1}}],[\"attention机制以适应更长的序列\",{\"2\":{\"304\":1}}],[\"attention机制的效果如何\",{\"2\":{\"260\":1}}],[\"attention机制的核心思想与计算方法\",{\"0\":{\"83\":1},\"1\":{\"97\":1,\"112\":1,\"130\":1,\"150\":1}}],[\"attention机制是否可以结合其他方法\",{\"2\":{\"260\":1}}],[\"attention机制是处理序列数据的一种方法\",{\"2\":{\"97\":1}}],[\"attention机制在短序列中也有潜力\",{\"2\":{\"236\":1}}],[\"attention机制在处理长序列时表现优异\",{\"2\":{\"150\":1}}],[\"attention机制解决了长序列信息捕捉问题\",{\"2\":{\"236\":1}}],[\"attention机制不仅适用于文本序列\",{\"2\":{\"232\":1}}],[\"attention机制\",{\"0\":{\"126\":1,\"188\":1},\"1\":{\"146\":1,\"167\":1},\"2\":{\"71\":1,\"80\":1,\"92\":1,\"94\":1,\"1051\":1}}],[\"attention机制详解与应用\",{\"0\":{\"61\":1},\"1\":{\"71\":1,\"83\":1,\"97\":1,\"112\":1,\"130\":1,\"150\":1,\"171\":1,\"192\":1,\"213\":1,\"236\":1,\"260\":1,\"284\":1},\"2\":{\"63\":1}}],[\"attention机制详解与应用|attention机制详解与应用\",{\"2\":{\"5\":1}}],[\"attention\",{\"0\":{\"63\":1,\"64\":1,\"136\":1,\"146\":1,\"149\":1,\"167\":1,\"168\":1,\"170\":1,\"189\":1,\"191\":1,\"212\":1,\"1179\":1,\"2057\":1,\"2286\":1,\"2571\":1},\"1\":{\"74\":1,\"86\":1,\"100\":1,\"116\":1,\"135\":1,\"155\":1,\"175\":1,\"196\":1,\"217\":1,\"240\":1,\"2318\":1,\"2349\":1,\"2379\":1,\"2406\":1,\"2431\":1,\"2456\":1,\"2475\":1},\"2\":{\"5\":2,\"34\":2,\"63\":1,\"86\":1,\"93\":1,\"94\":2,\"101\":2,\"109\":1,\"111\":4,\"125\":1,\"130\":1,\"167\":2,\"203\":1,\"209\":1,\"213\":4,\"222\":1,\"230\":1,\"279\":1,\"293\":1,\"305\":3,\"327\":1,\"502\":2,\"881\":1,\"917\":5,\"932\":2,\"970\":1,\"999\":1,\"1009\":2,\"1011\":1,\"1041\":1,\"1069\":1,\"1088\":1,\"1179\":2,\"1255\":1,\"1278\":1,\"1358\":1,\"1490\":1,\"1535\":3,\"1912\":2,\"1991\":1,\"2043\":1,\"2129\":1,\"2218\":1,\"2275\":1,\"2300\":1,\"2442\":1,\"2449\":1,\"2500\":2,\"2510\":1,\"2618\":1,\"2641\":1}}],[\"attention注意力机制\",{\"2\":{\"5\":7}}],[\"attention注意力机制|attention注意力机制\",{\"2\":{\"5\":1}}],[\"axis=dim\",{\"2\":{\"1622\":3}}],[\"axis=\",{\"2\":{\"213\":1}}],[\"ast\",{\"2\":{\"2621\":2,\"2641\":2}}],[\"as\",{\"2\":{\"213\":1,\"266\":1,\"332\":1,\"996\":1,\"1309\":1,\"1435\":1,\"1458\":2,\"1924\":1,\"2050\":1,\"2174\":1,\"2201\":1,\"2500\":1}}],[\"aside\",{\"2\":{\"18\":1}}],[\"acyclic\",{\"2\":{\"2188\":1}}],[\"acl\",{\"2\":{\"1658\":1}}],[\"achieving\",{\"2\":{\"1420\":1}}],[\"accelerator\",{\"2\":{\"2201\":10,\"2500\":2}}],[\"accelerate\",{\"0\":{\"2006\":1,\"2055\":1},\"1\":{\"2055\":1,\"2108\":1,\"2158\":1,\"2201\":1},\"2\":{\"193\":1,\"2055\":2,\"2108\":1,\"2201\":2}}],[\"accumulation\",{\"2\":{\"2217\":4,\"2319\":1}}],[\"accumulate\",{\"2\":{\"762\":2}}],[\"accuracy\",{\"2\":{\"1797\":1,\"2354\":1}}],[\"accompanied\",{\"2\":{\"1458\":1}}],[\"academic\",{\"2\":{\"454\":1}}],[\"act\",{\"2\":{\"1569\":1}}],[\"acting\",{\"0\":{\"2011\":1}}],[\"action=4\",{\"2\":{\"646\":1,\"840\":1}}],[\"actions\",{\"2\":{\"619\":3,\"640\":3,\"656\":3,\"766\":2,\"820\":1,\"1902\":1}}],[\"action\",{\"2\":{\"619\":8,\"640\":5,\"646\":8,\"766\":9,\"820\":13,\"840\":11,\"1222\":1,\"1594\":1,\"1608\":1,\"1622\":2,\"1817\":2,\"2370\":1}}],[\"activation\",{\"0\":{\"2503\":1},\"2\":{\"435\":1,\"799\":1,\"2161\":2,\"2489\":1}}],[\"actors\",{\"2\":{\"2433\":1}}],[\"actor模型\",{\"2\":{\"1479\":1}}],[\"actorcritic\",{\"2\":{\"619\":1}}],[\"actor代表策略\",{\"2\":{\"619\":1}}],[\"actor\",{\"0\":{\"458\":1,\"619\":1,\"1433\":1,\"1780\":1},\"1\":{\"487\":1,\"518\":1,\"551\":1,\"586\":1,\"619\":1,\"654\":1,\"689\":1,\"725\":1,\"759\":1,\"791\":1,\"822\":1,\"1479\":1,\"1523\":1,\"1572\":1,\"1622\":1,\"1677\":1,\"1733\":1,\"1791\":1,\"1852\":1},\"2\":{\"151\":2,\"487\":1,\"518\":1,\"619\":10,\"766\":6,\"791\":1,\"1497\":1,\"1539\":1,\"1622\":3,\"1899\":1,\"1954\":2,\"2004\":1,\"2053\":1,\"2081\":3,\"2113\":2,\"2408\":2,\"2433\":4}}],[\"arpo\",{\"2\":{\"2213\":1}}],[\"arithmetic\",{\"2\":{\"1708\":1}}],[\"arr\",{\"2\":{\"769\":4}}],[\"array\",{\"2\":{\"213\":3}}],[\"architecture\",{\"2\":{\"715\":1,\"763\":1}}],[\"architectures\",{\"2\":{\"153\":1}}],[\"argθ​maxes∼νβ​\",{\"2\":{\"2044\":1,\"2097\":1}}],[\"arg⁡θmax⁡es∼νβ\",{\"2\":{\"2044\":1,\"2097\":1}}],[\"argument\",{\"2\":{\"1451\":1,\"1542\":1}}],[\"args\",{\"2\":{\"917\":2,\"1832\":1}}],[\"arg\",{\"2\":{\"655\":2,\"2044\":1,\"2097\":1}}],[\"argmax\",{\"2\":{\"640\":1,\"646\":1,\"840\":1}}],[\"arange\",{\"2\":{\"332\":2,\"1435\":2}}],[\"arxiv\",{\"2\":{\"153\":1,\"432\":1,\"469\":1,\"631\":1,\"873\":1,\"1290\":1,\"1492\":1,\"1647\":1,\"1920\":1,\"2345\":1,\"2368\":1}}],[\"are\",{\"2\":{\"18\":2,\"480\":2,\"508\":1,\"1395\":1,\"1420\":1,\"1458\":2,\"1462\":1,\"2433\":1}}],[\"apache\",{\"2\":{\"1347\":2}}],[\"apply\",{\"2\":{\"2500\":1}}],[\"apple\",{\"2\":{\"985\":1,\"1025\":2}}],[\"approach\",{\"2\":{\"2202\":1}}],[\"appropriate\",{\"2\":{\"2050\":1}}],[\"approx\",{\"2\":{\"2023\":1}}],[\"approximate\",{\"0\":{\"2195\":1},\"2\":{\"1377\":1}}],[\"append\",{\"2\":{\"135\":1,\"218\":1,\"647\":2,\"656\":3,\"917\":3}}],[\"apex\",{\"2\":{\"765\":1,\"1451\":2,\"1592\":2,\"1700\":1,\"1818\":1,\"1878\":1}}],[\"api网关\",{\"2\":{\"198\":1}}],[\"api集成的挑战\",{\"0\":{\"137\":1},\"1\":{\"157\":1}}],[\"api集成\",{\"2\":{\"88\":1}}],[\"api文档\",{\"2\":{\"69\":1}}],[\"api\",{\"2\":{\"49\":1}}],[\"augmentation\",{\"0\":{\"2562\":1},\"1\":{\"2570\":1,\"2578\":1,\"2586\":1}}],[\"augmented\",{\"2\":{\"1185\":1,\"1285\":1,\"1309\":1,\"1333\":1,\"1609\":1,\"1610\":1,\"1955\":1,\"2000\":1,\"2303\":1,\"2323\":1,\"2395\":1,\"2469\":1,\"2550\":1,\"2570\":1,\"2690\":1}}],[\"aux\",{\"2\":{\"1455\":1}}],[\"aurélien\",{\"2\":{\"106\":1}}],[\"autogpt\",{\"2\":{\"1439\":1}}],[\"autogen\",{\"2\":{\"1300\":1}}],[\"autonomous\",{\"0\":{\"1316\":1,\"1408\":1,\"1904\":1},\"1\":{\"1454\":1,\"1501\":1,\"1545\":1},\"2\":{\"1904\":1}}],[\"autoregressive\",{\"2\":{\"1239\":1}}],[\"automatic\",{\"2\":{\"734\":1,\"1455\":1}}],[\"auto\",{\"2\":{\"48\":2,\"2108\":1}}],[\"autoencoder\",{\"2\":{\"39\":1}}],[\"anaconda3\",{\"2\":{\"2347\":3}}],[\"analyze\",{\"2\":{\"2050\":1}}],[\"an\",{\"2\":{\"2187\":1}}],[\"any\",{\"2\":{\"1458\":1,\"2500\":2}}],[\"anthropic团队研究报告\",{\"2\":{\"1369\":1}}],[\"answer\",{\"0\":{\"2210\":1},\"2\":{\"1368\":1,\"1816\":1,\"1885\":1,\"2280\":1,\"2312\":1,\"2343\":1}}],[\"answering\",{\"2\":{\"544\":1}}],[\"ans\",{\"2\":{\"762\":4,\"769\":3,\"783\":4}}],[\"another\",{\"2\":{\"163\":1}}],[\"andrew\",{\"2\":{\"106\":1,\"165\":1,\"230\":1,\"1617\":1}}],[\"and\",{\"0\":{\"1569\":1,\"2011\":1,\"2501\":1},\"1\":{\"2514\":1,\"2525\":1},\"2\":{\"67\":1,\"106\":1,\"153\":1,\"302\":1,\"572\":1,\"632\":1,\"1310\":1,\"1364\":1,\"1368\":1,\"1403\":1,\"1455\":1,\"1458\":10,\"1569\":1,\"1832\":1,\"2050\":1,\"2113\":1,\"2202\":1,\"2229\":1,\"2265\":1,\"2275\":1,\"2368\":1,\"2433\":2,\"2514\":1,\"2554\":1}}],[\"annoy\",{\"0\":{\"2195\":1},\"2\":{\"2195\":2}}],[\"anns\",{\"2\":{\"1377\":2}}],[\"annealing\",{\"2\":{\"1267\":1}}],[\"ann\",{\"2\":{\"39\":1,\"2102\":2}}],[\"awq采用了激活感知方法\",{\"2\":{\"2085\":1}}],[\"awq\",{\"2\":{\"2085\":1}}],[\"awareness\",{\"2\":{\"2275\":1}}],[\"aware外推方法\",{\"2\":{\"534\":1}}],[\"aware\",{\"0\":{\"1160\":1,\"1209\":1},\"2\":{\"466\":1,\"1308\":1}}],[\"aware或ntk\",{\"2\":{\"359\":1}}],[\"aware和ntk\",{\"0\":{\"359\":1}}],[\"aware插值以减少越界问题\",{\"2\":{\"466\":1}}],[\"aware插值结合了外推与内插\",{\"2\":{\"386\":1}}],[\"aware插值\",{\"0\":{\"200\":1},\"1\":{\"221\":1,\"244\":1}}],[\"aware插值通过调整高频和低频区域的缩放比例\",{\"2\":{\"159\":1}}],[\"aware插值与ntk\",{\"2\":{\"159\":1}}],[\"aware到ntk\",{\"0\":{\"120\":1},\"1\":{\"139\":1,\"159\":1,\"179\":1,\"200\":1,\"221\":1,\"244\":1,\"267\":1,\"290\":1,\"312\":1,\"335\":1,\"359\":1,\"386\":1,\"412\":1,\"439\":1,\"466\":1},\"2\":{\"5\":2,\"84\":1}}],[\"aws\",{\"2\":{\"65\":1}}],[\"aime\",{\"2\":{\"2338\":3}}],[\"ai框架\",{\"2\":{\"1969\":1}}],[\"aided\",{\"0\":{\"1730\":1},\"2\":{\"1730\":1,\"1788\":1}}],[\"ai=ri−mean\",{\"2\":{\"1683\":1}}],[\"ai模型\",{\"2\":{\"999\":1}}],[\"ai模型优化\",{\"2\":{\"990\":1}}],[\"ai​=std\",{\"2\":{\"1683\":1}}],[\"ai​\",{\"2\":{\"640\":1,\"1628\":1}}],[\"ai生成技术\",{\"2\":{\"226\":1}}],[\"ai\",{\"0\":{\"1238\":1},\"2\":{\"57\":1,\"67\":1,\"640\":1,\"698\":1,\"1136\":1,\"1238\":2,\"1266\":2,\"1289\":1,\"1336\":1,\"1382\":1,\"1429\":1,\"1468\":1,\"1474\":1,\"1485\":1,\"1628\":2,\"2357\":2}}],[\"advanced\",{\"0\":{\"2366\":1,\"2484\":1},\"1\":{\"2499\":1,\"2512\":1},\"2\":{\"2366\":1,\"2368\":1,\"2484\":1}}],[\"advantages\",{\"2\":{\"1622\":3}}],[\"advantage\",{\"0\":{\"570\":1},\"2\":{\"1572\":1,\"2004\":1}}],[\"ada\",{\"2\":{\"2655\":1}}],[\"adam的优化器状态显存计算公式为\",{\"2\":{\"2192\":1}}],[\"adamw\",{\"0\":{\"1024\":1}}],[\"adam\",{\"2\":{\"619\":2,\"766\":2,\"820\":1,\"2161\":2,\"2201\":1}}],[\"adaloralayer\",{\"2\":{\"1883\":1}}],[\"adalora不仅为每个adapter分配相同的秩\",{\"2\":{\"1764\":1}}],[\"adalora实现了计算效率与性能优化的平衡\",{\"2\":{\"1653\":1}}],[\"adalora是一种创新的深度学习技术\",{\"2\":{\"1653\":1}}],[\"adalora\",{\"0\":{\"1549\":1},\"1\":{\"1599\":1,\"1653\":1,\"1706\":1,\"1764\":1,\"1824\":1,\"1883\":1,\"1938\":1,\"1988\":1,\"2040\":1,\"2092\":1,\"2142\":1},\"2\":{\"151\":1,\"1599\":1,\"2142\":1}}],[\"adaption\",{\"2\":{\"1792\":1}}],[\"adaptive\",{\"2\":{\"1658\":1,\"2213\":1,\"2605\":1,\"2662\":1}}],[\"adaptation\",{\"2\":{\"57\":2,\"1636\":2,\"1658\":3,\"2078\":1}}],[\"adapter在不同下游任务中的性能表现\",{\"2\":{\"1953\":1}}],[\"adapter的创新\",{\"2\":{\"1722\":1}}],[\"adapter是对传统adapter和prefix\",{\"2\":{\"1668\":1}}],[\"adapter\",{\"0\":{\"1615\":1},\"1\":{\"1668\":1,\"1722\":1,\"1779\":1,\"1840\":1,\"1898\":1,\"1953\":1},\"2\":{\"40\":1,\"151\":1,\"1615\":1,\"1668\":1,\"1722\":2,\"1883\":8,\"2400\":2,\"2425\":2}}],[\"additional\",{\"2\":{\"1458\":1}}],[\"adding\",{\"0\":{\"603\":1},\"2\":{\"1458\":1}}],[\"add\",{\"0\":{\"73\":1,\"89\":1,\"183\":1},\"1\":{\"104\":1,\"121\":1,\"141\":1,\"162\":1,\"183\":1,\"205\":1,\"227\":1,\"251\":1,\"275\":1,\"299\":1},\"2\":{\"5\":8,\"11\":3,\"12\":3,\"15\":3,\"73\":1,\"121\":2,\"2050\":1,\"2500\":1}}],[\"alfworld\",{\"2\":{\"1819\":1}}],[\"al\",{\"2\":{\"1658\":5}}],[\"alternatively\",{\"2\":{\"1458\":1}}],[\"algebraicstack\",{\"2\":{\"1290\":1}}],[\"algorithms\",{\"2\":{\"2378\":1}}],[\"algorithm\",{\"2\":{\"715\":1}}],[\"alpha=0\",{\"2\":{\"1329\":1}}],[\"alpha$$以优化td算法的性能\",{\"2\":{\"850\":1}}],[\"alpha$$\",{\"2\":{\"678\":1}}],[\"alpha$$为学习率\",{\"2\":{\"611\":1}}],[\"alpha$$为控制更新步长的常数参数\",{\"2\":{\"608\":1}}],[\"alphaα\",{\"2\":{\"261\":1,\"2215\":1}}],[\"alpha\",{\"2\":{\"261\":2,\"285\":1,\"608\":1,\"611\":1,\"640\":1,\"646\":4,\"672\":1,\"710\":1,\"840\":3,\"998\":1,\"1279\":1,\"1329\":1,\"1831\":3,\"1883\":3,\"2033\":2,\"2092\":1,\"2142\":1,\"2400\":2}}],[\"allreduce操作\",{\"0\":{\"2670\":1}}],[\"allreduce的过程分为两个阶段\",{\"2\":{\"2621\":1}}],[\"allreduce\",{\"2\":{\"2276\":2,\"2641\":1}}],[\"allocator\",{\"2\":{\"2118\":1}}],[\"allocated\",{\"2\":{\"2108\":2}}],[\"allocation\",{\"2\":{\"1658\":1}}],[\"allgather\",{\"2\":{\"2079\":2,\"2276\":1,\"2308\":1}}],[\"all\",{\"0\":{\"2427\":1},\"1\":{\"2452\":1},\"2\":{\"230\":1,\"1008\":1,\"2344\":1,\"2374\":1,\"2427\":1,\"2433\":1,\"2452\":1,\"2660\":1}}],[\"alibaba\",{\"2\":{\"1878\":1}}],[\"alibi是否适用于所有类型的transformer模型\",{\"2\":{\"362\":1}}],[\"alibi的设计类似于局部注意力机制\",{\"2\":{\"293\":1}}],[\"alibi\",{\"2\":{\"182\":1,\"293\":1,\"315\":1}}],[\"aligning\",{\"2\":{\"2202\":1,\"2229\":1,\"2265\":1}}],[\"alignment\",{\"2\":{\"632\":1,\"2434\":1}}],[\"aligned\",{\"2\":{\"18\":1,\"1795\":2}}],[\"also\",{\"2\":{\"18\":1}}],[\"a\",{\"2\":{\"10\":12,\"11\":2,\"12\":6,\"15\":2,\"18\":2,\"223\":2,\"537\":3,\"581\":1,\"586\":3,\"590\":7,\"611\":4,\"618\":2,\"640\":12,\"646\":1,\"647\":13,\"653\":11,\"656\":15,\"672\":4,\"676\":1,\"695\":3,\"710\":7,\"723\":5,\"732\":28,\"757\":1,\"767\":32,\"775\":6,\"778\":2,\"779\":9,\"783\":1,\"810\":15,\"840\":3,\"843\":1,\"1008\":1,\"1225\":1,\"1266\":2,\"1309\":1,\"1329\":1,\"1364\":1,\"1420\":1,\"1458\":8,\"1536\":3,\"1613\":1,\"1622\":8,\"1628\":2,\"1634\":3,\"1683\":1,\"1732\":4,\"1771\":1,\"1787\":1,\"1814\":1,\"1831\":1,\"1883\":1,\"1891\":2,\"1902\":1,\"1912\":1,\"1924\":1,\"1942\":2,\"1993\":2,\"2044\":13,\"2050\":1,\"2097\":13,\"2174\":1,\"2202\":1,\"2229\":1,\"2265\":1,\"2306\":1,\"2347\":6,\"2372\":1,\"2395\":1,\"2417\":3,\"2425\":1,\"2430\":10,\"2434\":1,\"2436\":3,\"2446\":4,\"2485\":2,\"2531\":3,\"2537\":5,\"2542\":3,\"2577\":1,\"2587\":1,\"2602\":6,\"2609\":2}}],[\"长样本的贡献可能被低估\",{\"2\":{\"2619\":1,\"2668\":1}}],[\"长对话则被高估\",{\"2\":{\"2331\":1}}],[\"长时记忆可进一步分为以下两种类型\",{\"2\":{\"2049\":1}}],[\"长时记忆能够将信息存储很长时间\",{\"2\":{\"2049\":1}}],[\"长时记忆\",{\"0\":{\"2049\":1}}],[\"长时间自主行动\",{\"2\":{\"1336\":1}}],[\"长期记忆的特点在于它能够支持信息的长时间保存与高效访问\",{\"2\":{\"1833\":1}}],[\"长期记忆为智能体\",{\"2\":{\"1833\":1}}],[\"长期记忆\",{\"0\":{\"1833\":1}}],[\"长度和模型结构影响\",{\"2\":{\"2228\":1}}],[\"长度外推的问题\",{\"2\":{\"1606\":1}}],[\"长度外推优化\",{\"2\":{\"361\":1}}],[\"长度不一致\",{\"2\":{\"1513\":1}}],[\"长上下文问题\",{\"0\":{\"1504\":1}}],[\"长上下文预训练\",{\"2\":{\"1267\":1}}],[\"长上下文模型\",{\"2\":{\"87\":1}}],[\"长上下文模型优化\",{\"0\":{\"75\":1},\"1\":{\"87\":1,\"101\":1,\"117\":1,\"136\":1,\"156\":1,\"176\":1,\"197\":1,\"218\":1,\"241\":1,\"264\":1,\"288\":1,\"310\":1,\"333\":1,\"358\":1,\"385\":1},\"2\":{\"5\":2,\"63\":1}}],[\"长文本适应性优化是否能迁移至多模态任务中\",{\"2\":{\"1577\":1}}],[\"长文本的\",{\"2\":{\"847\":1}}],[\"长文本预训练\",{\"0\":{\"1256\":1}}],[\"长文本预训练将成为大语言模型优化的重要方向\",{\"2\":{\"706\":1}}],[\"长文本预训练的技术细节\",{\"0\":{\"502\":1}}],[\"长文本继续预训练\",{\"2\":{\"475\":1}}],[\"长文本继续预训练是对基础大语言模型进行进一步优化的一种方法\",{\"2\":{\"423\":1}}],[\"长文本\",{\"2\":{\"397\":1}}],[\"长文本处理和工具使用方面进行了显著的改进\",{\"2\":{\"1028\":1}}],[\"长文本处理\",{\"2\":{\"57\":1,\"74\":1,\"436\":1,\"1018\":1}}],[\"长文本处理的新突破\",{\"0\":{\"64\":1},\"1\":{\"74\":1,\"86\":1,\"100\":1,\"116\":1,\"135\":1,\"155\":1,\"175\":1,\"196\":1,\"217\":1,\"240\":1},\"2\":{\"5\":2,\"63\":1}}],[\"长序列生成\",{\"2\":{\"1324\":1}}],[\"长序列生成和数学推理是其后训练的重点领域\",{\"2\":{\"1061\":1}}],[\"长序列任务\",{\"2\":{\"315\":1}}],[\"长序列数据处理\",{\"2\":{\"150\":1}}],[\"长波长维度可能保持绝对位置信息\",{\"2\":{\"335\":1}}],[\"长波长维度\",{\"2\":{\"290\":1}}],[\"d2m​≪1\",{\"2\":{\"2653\":1}}],[\"d^2\",{\"2\":{\"2653\":2}}],[\"dcgk​=i=1∑k​log2​\",{\"2\":{\"2137\":1}}],[\"dcgk=∑i=1krel\",{\"2\":{\"2137\":1}}],[\"dcg\",{\"0\":{\"2087\":1,\"2137\":1},\"2\":{\"2087\":1,\"2137\":1,\"2183\":2}}],[\"dca是否能替代传统长文本处理方式\",{\"2\":{\"217\":1}}],[\"dca代码实现\",{\"0\":{\"135\":1}}],[\"dca的工作流程\",{\"0\":{\"116\":1}}],[\"dca\",{\"0\":{\"64\":1},\"1\":{\"74\":1,\"86\":1,\"100\":1,\"116\":1,\"135\":1,\"155\":1,\"175\":1,\"196\":1,\"217\":1,\"240\":1},\"2\":{\"5\":1,\"63\":1,\"74\":1,\"86\":1,\"1041\":1,\"1156\":1}}],[\"dfsdt\",{\"2\":{\"1917\":1}}],[\"ddd远小于nnn\",{\"2\":{\"2643\":1}}],[\"ddd\",{\"2\":{\"1868\":1,\"2643\":1}}],[\"dkl\",{\"2\":{\"1944\":1}}],[\"dkl=ey∼π\",{\"2\":{\"1657\":1}}],[\"dkl​=ey∼π\",{\"2\":{\"1657\":1}}],[\"dkl​\",{\"2\":{\"1552\":1,\"1944\":1}}],[\"dkld\",{\"2\":{\"1552\":1}}],[\"dkv\",{\"2\":{\"283\":2}}],[\"dκlog⁡nqk⊤\",{\"2\":{\"1535\":1}}],[\"dp\",{\"0\":{\"2178\":1},\"2\":{\"1410\":1,\"1456\":1,\"1502\":1,\"2081\":2,\"2177\":1,\"2374\":1,\"2710\":1}}],[\"dpo推导章节\",{\"2\":{\"2148\":1}}],[\"dpoloss\",{\"2\":{\"1731\":1}}],[\"dpo中的损失函数\",{\"0\":{\"1727\":1}}],[\"dpo通过约束概率差值而非绝对概率\",{\"2\":{\"1675\":1}}],[\"dpo损失函数的目标是最大化偏好回答与不偏好回答之间的概率差值\",{\"2\":{\"1675\":1}}],[\"dpo优化\",{\"2\":{\"1575\":1}}],[\"dpo可以被看作是对比学习的一种特例\",{\"2\":{\"1566\":1}}],[\"dpo可以被视作一种特殊形式的对比学习\",{\"2\":{\"1517\":1}}],[\"dpo的视角\",{\"2\":{\"1566\":1}}],[\"dpo训练\",{\"0\":{\"1134\":1}}],[\"dpop算法有效地解决了好答案与坏答案同时被采样概率降低的问题\",{\"2\":{\"1795\":1}}],[\"dpop算法的痛点解决\",{\"0\":{\"1795\":1}}],[\"dpop算法通过在dpo损失基础上添加正则项\",{\"2\":{\"1681\":1}}],[\"dpop算法在优化dpo方向上\",{\"2\":{\"1626\":1}}],[\"dpop算法\",{\"2\":{\"1575\":1}}],[\"dpop\",{\"0\":{\"1524\":1},\"1\":{\"1575\":1,\"1626\":1,\"1681\":1,\"1737\":1,\"1795\":1,\"1857\":1,\"1913\":1,\"1966\":1,\"2018\":1,\"2068\":1,\"2120\":1},\"2\":{\"151\":1,\"1795\":1}}],[\"dpo\",{\"0\":{\"1432\":1},\"1\":{\"1477\":1,\"1521\":1,\"1570\":1,\"1620\":1,\"1675\":1,\"1731\":1,\"1789\":1,\"1850\":1,\"1907\":1,\"1960\":1,\"2012\":1,\"2061\":1},\"2\":{\"151\":1,\"1461\":1,\"1495\":1,\"1517\":1,\"1620\":1,\"1731\":1,\"1917\":1,\"1976\":1}}],[\"dpo公式推导\",{\"0\":{\"1415\":1},\"1\":{\"1461\":1,\"1506\":1,\"1552\":1,\"1602\":1,\"1657\":1,\"1712\":1,\"1769\":1,\"1830\":1,\"1889\":1,\"1944\":1,\"1994\":1,\"2046\":1,\"2098\":1,\"2148\":1},\"2\":{\"151\":1}}],[\"dpo介绍及rlhf\",{\"0\":{\"1401\":1},\"1\":{\"1449\":1,\"1495\":1,\"1539\":1,\"1589\":1,\"1642\":1,\"1696\":1,\"1754\":1,\"1814\":1},\"2\":{\"151\":1}}],[\"d×d\",{\"2\":{\"1227\":1}}],[\"dropped\",{\"2\":{\"2080\":2}}],[\"dropout操作\",{\"0\":{\"2611\":1}}],[\"dropout\",{\"0\":{\"2349\":1},\"2\":{\"1451\":1,\"1872\":1,\"1883\":1,\"2027\":2,\"2080\":2,\"2400\":2,\"2611\":1}}],[\"drop\",{\"2\":{\"1170\":1,\"2080\":1,\"2539\":1,\"2611\":1}}],[\"d=4个连续token\",{\"2\":{\"1127\":1}}],[\"d轮\",{\"2\":{\"647\":1}}],[\"during\",{\"2\":{\"1458\":1}}],[\"duplication\",{\"2\":{\"632\":1}}],[\"dual\",{\"0\":{\"64\":1},\"1\":{\"74\":1,\"86\":1,\"100\":1,\"116\":1,\"135\":1,\"155\":1,\"175\":1,\"196\":1,\"217\":1,\"240\":1},\"2\":{\"5\":2,\"63\":1,\"86\":1,\"1041\":1}}],[\"d4\",{\"2\":{\"632\":1}}],[\"dx\",{\"2\":{\"623\":3}}],[\"dqn与其他强化学习算法相比有哪些优势和劣势\",{\"2\":{\"913\":1}}],[\"dqn是否需要进行特别调整\",{\"2\":{\"913\":1}}],[\"dqn将在更复杂的环境中得到广泛应用\",{\"2\":{\"877\":1}}],[\"dqn的重要改进\",{\"0\":{\"674\":1},\"1\":{\"712\":1,\"746\":1}}],[\"dqn通过使q值网络的输出与时序差分目标\",{\"2\":{\"640\":1}}],[\"dqn简介\",{\"0\":{\"606\":1}}],[\"dqn\",{\"2\":{\"573\":1,\"606\":1,\"640\":3,\"2430\":1}}],[\"dynamics\",{\"2\":{\"2471\":1}}],[\"dynamic\",{\"2\":{\"466\":1}}],[\"dtype=torch\",{\"2\":{\"619\":5,\"640\":5,\"766\":5,\"820\":2,\"1928\":1}}],[\"dtype=next\",{\"2\":{\"324\":3}}],[\"dtype\",{\"2\":{\"324\":3,\"1928\":1}}],[\"dmodel​\",{\"2\":{\"1246\":1,\"2636\":1}}],[\"dmodeld\",{\"2\":{\"1246\":1}}],[\"dmodel\",{\"2\":{\"263\":2,\"287\":1,\"2636\":1}}],[\"d−2\",{\"2\":{\"221\":2}}],[\"dag\",{\"2\":{\"2188\":1}}],[\"database\",{\"2\":{\"2666\":1}}],[\"dataloader\",{\"2\":{\"2201\":1}}],[\"dataloaders\",{\"2\":{\"2055\":1}}],[\"datasets\",{\"2\":{\"2201\":1}}],[\"datasets库文档\",{\"2\":{\"375\":1}}],[\"dataset\",{\"2\":{\"741\":1,\"2201\":5,\"2233\":1}}],[\"data\",{\"0\":{\"2178\":1},\"2\":{\"302\":1,\"391\":1,\"917\":2,\"1883\":1,\"2177\":1,\"2201\":5,\"2223\":1,\"2374\":1}}],[\"dapo公式\",{\"2\":{\"2187\":3}}],[\"dapo在任务相关性上取得了更好的平衡\",{\"2\":{\"1884\":1}}],[\"dapo引入了动态采样的方法\",{\"2\":{\"1884\":1}}],[\"dapo通过移除这一约束\",{\"2\":{\"1884\":1}}],[\"dapo算法通过去掉kl散度约束项\",{\"2\":{\"1825\":1}}],[\"dapo算法的核心改进\",{\"0\":{\"1825\":1},\"1\":{\"1884\":1}}],[\"dapo算法\",{\"2\":{\"1707\":1}}],[\"dapo\",{\"0\":{\"1654\":1},\"1\":{\"1707\":1,\"1765\":1,\"1825\":1,\"1884\":1,\"1939\":1,\"1989\":1,\"2041\":1,\"2093\":1,\"2143\":1,\"2187\":1},\"2\":{\"151\":1,\"2054\":1,\"2187\":1,\"2338\":1,\"2605\":1,\"2662\":1}}],[\"daniel\",{\"2\":{\"67\":1}}],[\"diag\",{\"2\":{\"2033\":4,\"2528\":14}}],[\"directed\",{\"2\":{\"2188\":1}}],[\"directional\",{\"2\":{\"1831\":2}}],[\"direct\",{\"2\":{\"1495\":1,\"1517\":1,\"1814\":1,\"1902\":2,\"1917\":1,\"1976\":1}}],[\"dify\",{\"2\":{\"1347\":1}}],[\"diff\",{\"2\":{\"647\":3,\"656\":4}}],[\"difference\",{\"2\":{\"574\":1}}],[\"different\",{\"2\":{\"153\":1}}],[\"discussion\",{\"0\":{\"2632\":1},\"1\":{\"2637\":1,\"2642\":1,\"2647\":1,\"2652\":1,\"2657\":1,\"2661\":1}}],[\"discrete\",{\"2\":{\"2405\":1}}],[\"discounted\",{\"2\":{\"2035\":1}}],[\"disco\",{\"2\":{\"1224\":2}}],[\"dispatch\",{\"2\":{\"2108\":2}}],[\"disentangled\",{\"2\":{\"1088\":1}}],[\"distributedoptimizer\",{\"2\":{\"1832\":1}}],[\"distributions\",{\"2\":{\"619\":1,\"766\":1,\"820\":1}}],[\"distribution\",{\"2\":{\"427\":3}}],[\"distinct\",{\"2\":{\"1458\":1}}],[\"distill\",{\"2\":{\"2603\":1,\"2642\":1}}],[\"distillation\",{\"0\":{\"677\":1,\"954\":1,\"995\":1,\"1035\":1},\"1\":{\"715\":1},\"2\":{\"214\":1,\"677\":1,\"715\":1,\"763\":1,\"916\":3,\"954\":1,\"995\":2,\"1035\":2,\"2647\":1}}],[\"distilbert等\",{\"2\":{\"115\":1}}],[\"distilbert\",{\"2\":{\"40\":1,\"2608\":1}}],[\"dist\",{\"2\":{\"619\":2,\"766\":2,\"820\":2}}],[\"dict\",{\"2\":{\"619\":6,\"640\":8,\"766\":6,\"820\":4,\"2201\":1,\"2500\":2}}],[\"diverse\",{\"2\":{\"949\":1}}],[\"diversification\",{\"2\":{\"632\":1}}],[\"div\",{\"2\":{\"332\":3,\"1435\":3}}],[\"dim\",{\"2\":{\"189\":1,\"266\":6,\"619\":11,\"640\":1,\"766\":20,\"820\":13,\"996\":2,\"1622\":1,\"1912\":1,\"2597\":2,\"2636\":1}}],[\"dim=−1\",{\"2\":{\"2597\":4}}],[\"dim=0\",{\"2\":{\"1831\":2,\"2500\":1}}],[\"dim=2\",{\"2\":{\"1703\":2,\"2539\":8,\"2549\":3,\"2628\":3}}],[\"dim=300\",{\"2\":{\"996\":1}}],[\"dim=1\",{\"2\":{\"135\":1,\"766\":1,\"820\":1}}],[\"dim=\",{\"2\":{\"135\":1,\"189\":1,\"364\":2,\"1622\":1,\"1817\":1,\"1928\":2,\"2539\":1}}],[\"do\",{\"2\":{\"2050\":1,\"2406\":1,\"2449\":1}}],[\"docling\",{\"2\":{\"2270\":1}}],[\"docs\",{\"2\":{\"1984\":16}}],[\"doc\",{\"2\":{\"1089\":1,\"1823\":2,\"1837\":2,\"1951\":2,\"1984\":6}}],[\"documents\",{\"2\":{\"1823\":1}}],[\"document\",{\"2\":{\"632\":1,\"2050\":1}}],[\"done\",{\"2\":{\"647\":4,\"656\":4}}],[\"dones\",{\"2\":{\"619\":3,\"640\":3,\"766\":3}}],[\"downloaded\",{\"2\":{\"485\":2}}],[\"dora通过分解权重矩阵\",{\"2\":{\"1996\":1}}],[\"dora的基本步骤\",{\"0\":{\"1770\":1}}],[\"dora是一种用于深度学习模型的优化技术\",{\"2\":{\"1659\":1}}],[\"dora\",{\"0\":{\"1553\":1},\"1\":{\"1604\":1,\"1659\":1,\"1713\":1,\"1770\":1,\"1831\":1,\"1890\":1,\"1945\":1,\"1996\":1,\"2048\":1},\"2\":{\"151\":1,\"1604\":1,\"2048\":1}}],[\"dot\",{\"0\":{\"130\":1,\"213\":1},\"2\":{\"130\":1,\"213\":5,\"236\":1}}],[\"dots\",{\"2\":{\"76\":3,\"773\":1}}],[\"domain\",{\"2\":{\"57\":1,\"1465\":1}}],[\"dbscan\",{\"2\":{\"39\":1}}],[\"d\",{\"2\":{\"34\":1,\"130\":3,\"190\":1,\"213\":4,\"221\":6,\"228\":1,\"259\":5,\"290\":1,\"332\":6,\"470\":1,\"497\":1,\"614\":2,\"1127\":2,\"1225\":3,\"1344\":1,\"1435\":4,\"1535\":1,\"1536\":1,\"1552\":2,\"1582\":1,\"1628\":1,\"1634\":1,\"1657\":2,\"1666\":1,\"1685\":2,\"1712\":1,\"1720\":2,\"1727\":1,\"1795\":1,\"1830\":1,\"1925\":1,\"1944\":2,\"2013\":5,\"2080\":2,\"2286\":9,\"2436\":6,\"2485\":1,\"2492\":1,\"2539\":2,\"2577\":1,\"2581\":2,\"2597\":2,\"2636\":1,\"2643\":7,\"2653\":7}}],[\"depth\",{\"2\":{\"1917\":1}}],[\"denominator\",{\"2\":{\"1831\":2}}],[\"dense\",{\"0\":{\"1367\":1},\"1\":{\"1412\":1},\"2\":{\"1083\":1,\"1179\":1,\"1367\":1}}],[\"detection\",{\"2\":{\"1665\":1}}],[\"detach\",{\"2\":{\"619\":2,\"1731\":2,\"2561\":3}}],[\"descriptive\",{\"2\":{\"1458\":1}}],[\"deduplicated\",{\"2\":{\"741\":1}}],[\"de\",{\"2\":{\"632\":1}}],[\"delimiters\",{\"2\":{\"2050\":1}}],[\"delim\",{\"2\":{\"1193\":1}}],[\"delta\",{\"2\":{\"619\":2,\"1343\":3,\"1962\":1,\"2013\":1}}],[\"delete\",{\"2\":{\"48\":1}}],[\"deleted\",{\"2\":{\"18\":1}}],[\"device=\",{\"2\":{\"2539\":3}}],[\"devices\",{\"2\":{\"2217\":3}}],[\"device\",{\"2\":{\"619\":11,\"640\":8,\"766\":11,\"820\":7,\"2108\":3,\"2201\":6,\"2217\":3,\"2500\":2}}],[\"decision\",{\"2\":{\"1864\":1,\"1917\":1}}],[\"decontextualize\",{\"2\":{\"1458\":1}}],[\"decompose\",{\"2\":{\"1458\":1}}],[\"decode阶段的耗时一般是更大的\",{\"2\":{\"1927\":1}}],[\"decode阶段\",{\"0\":{\"846\":1}}],[\"decode\",{\"0\":{\"1927\":1},\"2\":{\"426\":1}}],[\"decoder端增加前缀是为了引导后续token的生成\",{\"2\":{\"1922\":1}}],[\"decoder与传统transformer的定义\",{\"2\":{\"1335\":1}}],[\"decoder部分\",{\"2\":{\"1237\":1}}],[\"decoder包含两个attention机制\",{\"2\":{\"1009\":1}}],[\"decoder结构进行文本处理\",{\"2\":{\"1137\":1}}],[\"decoder结构模型\",{\"2\":{\"1040\":1}}],[\"decoder结构\",{\"2\":{\"923\":1,\"932\":1,\"961\":1}}],[\"decoder模型\",{\"2\":{\"479\":1}}],[\"decoder中的self\",{\"0\":{\"167\":1}}],[\"decoder\",{\"0\":{\"294\":1,\"339\":1,\"1006\":1},\"2\":{\"34\":4,\"40\":2,\"93\":1,\"363\":1,\"560\":2,\"595\":3,\"889\":1,\"970\":1,\"1006\":3,\"1047\":1,\"1091\":1,\"1237\":1,\"1243\":1}}],[\"decoding=2×batch\",{\"2\":{\"2263\":2}}],[\"decoding\",{\"0\":{\"98\":1},\"2\":{\"5\":5,\"1088\":1,\"2228\":1,\"2263\":2}}],[\"decay\",{\"2\":{\"593\":1,\"1344\":1,\"1771\":8}}],[\"dead\",{\"2\":{\"238\":1,\"261\":1,\"330\":1}}],[\"def\",{\"2\":{\"189\":1,\"213\":1,\"266\":2,\"324\":1,\"332\":1,\"515\":1,\"619\":4,\"640\":2,\"646\":3,\"647\":1,\"656\":4,\"766\":7,\"820\":5,\"840\":3,\"843\":1,\"1025\":1,\"1435\":1,\"1582\":1,\"1622\":3,\"1731\":2,\"1816\":1,\"1817\":2,\"1831\":2,\"1832\":1,\"1883\":1,\"1912\":2,\"1928\":1,\"1936\":1,\"1984\":2,\"2400\":1,\"2417\":1,\"2433\":3,\"2500\":1,\"2600\":1}}],[\"definition\",{\"2\":{\"18\":2,\"1368\":1,\"1465\":1}}],[\"deberta强调相对位置的重要性\",{\"2\":{\"1187\":1}}],[\"deberta去掉了传统transformer中的第4项\",{\"2\":{\"1187\":1}}],[\"deberta的这种两阶段结构是否可以推广到其他深度学习领域\",{\"2\":{\"1472\":1}}],[\"deberta的微调过程如下\",{\"2\":{\"1288\":1}}],[\"deberta的改进基于以下公式展开\",{\"2\":{\"1187\":1}}],[\"deberta的相对位置编码与绝对位置编码解析\",{\"0\":{\"1003\":1},\"1\":{\"1044\":1,\"1088\":1,\"1135\":1,\"1187\":1,\"1237\":1,\"1288\":1,\"1335\":1,\"1381\":1,\"1427\":1,\"1472\":1},\"2\":{\"84\":1}}],[\"deberta的相对位置编码与绝对位置编码解析|deberta的相对位置编码与绝对位置编码解析\",{\"2\":{\"5\":1}}],[\"deberta位置编码的公式解析\",{\"0\":{\"1187\":1}}],[\"deberta\",{\"2\":{\"172\":1,\"1044\":1,\"1088\":1}}],[\"deepdoc\",{\"2\":{\"2270\":1}}],[\"deepmind\",{\"2\":{\"1658\":1}}],[\"deepspeed设置\",{\"2\":{\"2252\":1}}],[\"deepspeed\",{\"0\":{\"2010\":1,\"2079\":1,\"2320\":1,\"2381\":1},\"1\":{\"2059\":1,\"2112\":1,\"2161\":1,\"2204\":1,\"2241\":1,\"2276\":1,\"2308\":1,\"2339\":1,\"2351\":1,\"2369\":1,\"2381\":1,\"2397\":1,\"2408\":1,\"2422\":1,\"2433\":1,\"2447\":1,\"2468\":1,\"2486\":1},\"2\":{\"193\":1,\"765\":1,\"1404\":2,\"1542\":2,\"1592\":2,\"2055\":3,\"2059\":1,\"2079\":1,\"2081\":5,\"2118\":1,\"2129\":2,\"2131\":1,\"2241\":1,\"2320\":1,\"2381\":2}}],[\"deepseekmath\",{\"2\":{\"1290\":1,\"2199\":1}}],[\"deepseekmath实践经验\",{\"2\":{\"632\":1}}],[\"deepseekmoe采用了细粒度的专家分割以控制激活专家数量\",{\"2\":{\"1030\":1}}],[\"deepseekmoe模型结构\",{\"2\":{\"1030\":1}}],[\"deepseekv2论文解析\",{\"2\":{\"432\":1}}],[\"deepseekv2\",{\"2\":{\"212\":1}}],[\"deepseek\",{\"0\":{\"863\":1,\"872\":1,\"884\":1,\"885\":1,\"888\":1,\"962\":1,\"2248\":1,\"2315\":1,\"2580\":1},\"1\":{\"899\":1,\"908\":1,\"920\":1,\"922\":1,\"924\":1,\"934\":1,\"947\":1,\"957\":1,\"960\":1,\"962\":1,\"972\":1,\"989\":1,\"998\":1,\"1002\":1,\"1005\":1,\"1013\":1,\"1030\":1,\"1038\":1,\"1043\":1,\"1046\":1,\"1053\":1,\"1073\":1,\"1081\":1,\"1087\":1,\"1090\":1,\"1097\":1,\"1120\":1,\"1127\":1,\"1134\":1,\"1138\":1,\"1146\":1,\"1171\":1,\"1178\":1,\"1186\":1,\"1190\":1,\"1195\":1,\"1220\":1,\"1227\":1,\"1236\":1,\"1240\":1,\"1245\":1,\"1271\":1,\"1277\":1,\"1287\":1,\"1290\":1,\"1295\":1,\"1318\":1,\"1324\":1,\"1337\":1,\"1342\":1,\"1364\":1,\"1383\":1,\"1387\":1,\"1430\":1,\"1475\":1,\"2283\":1,\"2315\":1,\"2346\":1},\"2\":{\"172\":5,\"908\":1,\"920\":1,\"934\":1,\"960\":1,\"989\":1,\"1002\":1,\"1030\":1,\"1053\":1,\"1287\":2,\"1324\":1,\"1364\":1,\"1387\":1,\"1475\":1,\"1915\":1,\"1917\":1,\"2070\":1,\"2211\":1,\"2248\":1,\"2283\":1,\"2338\":1,\"2580\":2,\"2588\":1,\"2603\":6,\"2617\":1,\"2622\":3}}],[\"deeplearning\",{\"2\":{\"67\":1}}],[\"deep\",{\"2\":{\"18\":3,\"165\":3,\"230\":1,\"544\":1,\"928\":1,\"961\":1,\"1633\":1,\"1920\":1,\"2430\":1,\"2605\":1,\"2662\":1}}],[\"demonstrate\",{\"0\":{\"2536\":1},\"1\":{\"2546\":1,\"2554\":1},\"2\":{\"2546\":1}}],[\"demonstrations\",{\"2\":{\"949\":1}}],[\"demonstration\",{\"2\":{\"804\":1,\"1687\":1}}],[\"demodemo\",{\"2\":{\"20\":1}}],[\"demo\",{\"0\":{\"19\":1},\"2\":{\"18\":2,\"1347\":1}}],[\"2时的情况\",{\"0\":{\"2636\":1}}],[\"2y2​做一次all\",{\"2\":{\"2660\":1}}],[\"2y2​\",{\"2\":{\"2609\":1}}],[\"2a2​可以在第二个gpu上进行计算\",{\"2\":{\"2537\":1}}],[\"2r2​\",{\"2\":{\"2446\":1}}],[\"2ϵlow​=0\",{\"2\":{\"2327\":1}}],[\"2ϵ=0\",{\"2\":{\"2327\":1}}],[\"28ϵhigh​=0\",{\"2\":{\"2327\":1}}],[\"28\",{\"2\":{\"2327\":2,\"2479\":1}}],[\"288\",{\"2\":{\"2313\":1}}],[\"28gb\",{\"2\":{\"1178\":1}}],[\"2⋅1n⋅φ⋅n=2φ2\",{\"2\":{\"2308\":2}}],[\"2阶段\",{\"0\":{\"2308\":1}}],[\"2m1​=max\",{\"2\":{\"2176\":1}}],[\"2φ+2φ+\",{\"2\":{\"2161\":1}}],[\"2|x\",{\"2\":{\"2046\":2}}],[\"2×modelmemory\",{\"2\":{\"2023\":1}}],[\"2×modelmemoryinfermemory\",{\"2\":{\"2023\":1}}],[\"2σ2​\",{\"2\":{\"1536\":3}}],[\"2章节中\",{\"2\":{\"1375\":1}}],[\"2性能的影响\",{\"2\":{\"1350\":1}}],[\"2在不同任务中的应用场景\",{\"2\":{\"1350\":1}}],[\"299$$\",{\"2\":{\"1329\":1}}],[\"27\",{\"2\":{\"1324\":1}}],[\"2周\",{\"2\":{\"1324\":1}}],[\"2展示了大规模语言模型在多任务学习中的潜力\",{\"2\":{\"1303\":1}}],[\"2最大为15亿\",{\"2\":{\"1278\":1}}],[\"2仅有40g\",{\"2\":{\"1278\":1}}],[\"2基础上\",{\"2\":{\"1278\":1}}],[\"2区别\",{\"0\":{\"1278\":1}}],[\"21​+51​+11​\",{\"2\":{\"1756\":1}}],[\"21​\",{\"2\":{\"1756\":1}}],[\"2110\",{\"2\":{\"1297\":1}}],[\"2110×109\",{\"2\":{\"1297\":2}}],[\"210\",{\"2\":{\"1232\":1}}],[\"2168\",{\"2\":{\"909\":1}}],[\"2则主推zero\",{\"2\":{\"1228\":1}}],[\"2=0\",{\"2\":{\"1204\":1}}],[\"2x2​\",{\"2\":{\"2537\":1}}],[\"2x\",{\"2\":{\"1178\":1}}],[\"2β2​\",{\"2\":{\"1162\":1}}],[\"2t\",{\"2\":{\"1114\":1}}],[\"2验证了通过大量数据和参数训练出来的词向量模型可以迁移到其他任务中\",{\"2\":{\"1104\":1}}],[\"2相比\",{\"2\":{\"1082\":1}}],[\"2与gpt\",{\"2\":{\"1059\":1}}],[\"2模型是一个大规模的无监督语言模型\",{\"2\":{\"975\":1}}],[\"2k\",{\"2\":{\"889\":1,\"1069\":1}}],[\"2652\",{\"2\":{\"873\":1}}],[\"2+1\",{\"2\":{\"762\":1}}],[\"2倍的吞吐量\",{\"2\":{\"750\":1}}],[\"2504\",{\"2\":{\"2368\":1}}],[\"25776mib\",{\"2\":{\"2347\":1}}],[\"256\",{\"2\":{\"2233\":1,\"2655\":1}}],[\"256k\",{\"2\":{\"1398\":1,\"1483\":1}}],[\"256专家\",{\"2\":{\"1178\":1}}],[\"256个路由专家采用共享\",{\"2\":{\"998\":1}}],[\"25\",{\"2\":{\"656\":4,\"1211\":1}}],[\"25t00\",{\"0\":{\"56\":1}}],[\"2n\",{\"2\":{\"640\":1,\"2253\":1}}],[\"2n−1−12^\",{\"2\":{\"18\":1}}],[\"2n−1\",{\"2\":{\"18\":2}}],[\"2losses\",{\"2\":{\"2012\":1}}],[\"2l\",{\"2\":{\"640\":1}}],[\"2410\",{\"2\":{\"2345\":1}}],[\"2412\",{\"2\":{\"153\":1,\"1492\":1}}],[\"24~30\",{\"2\":{\"1258\":1}}],[\"24\",{\"2\":{\"556\":1,\"589\":1,\"591\":1,\"1232\":1}}],[\"2gb\",{\"2\":{\"483\":1,\"2145\":1}}],[\"2gb相比\",{\"2\":{\"455\":1}}],[\"2中文\",{\"2\":{\"474\":1}}],[\"22\",{\"2\":{\"470\":1,\"497\":1,\"1232\":1}}],[\"2πbd​​\",{\"2\":{\"290\":1}}],[\"2−1​\",{\"2\":{\"221\":2}}],[\"2−1\",{\"2\":{\"221\":2}}],[\"20image\",{\"2\":{\"1329\":2}}],[\"20b规模数据\",{\"2\":{\"534\":1}}],[\"200k\",{\"2\":{\"2564\":1}}],[\"200\",{\"2\":{\"526\":1,\"1823\":1,\"1937\":2}}],[\"20\",{\"2\":{\"245\":1,\"803\":1,\"1138\":1,\"1290\":1,\"1998\":1}}],[\"20480\",{\"2\":{\"2692\":1}}],[\"2048\",{\"2\":{\"197\":1,\"218\":1,\"917\":1,\"1483\":1,\"2233\":1}}],[\"2021\",{\"2\":{\"1493\":1,\"1658\":1}}],[\"2020250409223958\",{\"2\":{\"1329\":1}}],[\"2020250409223942\",{\"2\":{\"1329\":1}}],[\"20250409223958\",{\"2\":{\"1329\":1}}],[\"20250409223942\",{\"2\":{\"1329\":1}}],[\"2025年4月22日\",{\"2\":{\"1461\":1}}],[\"2025年4月26日\",{\"2\":{\"920\":1}}],[\"2025年4月2日\",{\"2\":{\"273\":1,\"286\":1,\"320\":1,\"344\":1,\"347\":1}}],[\"2025年4月7日\",{\"2\":{\"539\":1,\"552\":1,\"642\":1,\"659\":1}}],[\"2025年4月11日\",{\"2\":{\"550\":1,\"573\":1,\"604\":1}}],[\"2025年4月10日\",{\"2\":{\"540\":1,\"545\":1}}],[\"2025年4月1日\",{\"2\":{\"226\":1,\"229\":1,\"297\":1,\"832\":1,\"835\":1,\"836\":1,\"848\":1}}],[\"2025年4月12日\",{\"0\":{\"1005\":1,\"1067\":1,\"1691\":1,\"1734\":1,\"1815\":1,\"1841\":1,\"1900\":1,\"2686\":1},\"2\":{\"85\":1,\"88\":1,\"478\":1,\"487\":1,\"543\":1,\"617\":1,\"839\":1,\"854\":1,\"859\":1,\"861\":1,\"862\":1,\"865\":1,\"883\":1,\"887\":1,\"890\":1,\"899\":1,\"908\":1,\"922\":1,\"930\":1,\"935\":1,\"986\":1,\"987\":1,\"988\":1,\"990\":1,\"1000\":1,\"1001\":1,\"1015\":1,\"1017\":1,\"1018\":1,\"1039\":1,\"1100\":1,\"1319\":1,\"1414\":1,\"1445\":1,\"1449\":1,\"1471\":1,\"1473\":1,\"1478\":1,\"1479\":1,\"1486\":1,\"1489\":1,\"1497\":1,\"1516\":1,\"1546\":1,\"1568\":1,\"1570\":1,\"1575\":1,\"1581\":1,\"1583\":1,\"1599\":1,\"1604\":1,\"1605\":1,\"1615\":1,\"1624\":1,\"1625\":1,\"1638\":1,\"1682\":1,\"1689\":1,\"1694\":1,\"1707\":1,\"1726\":1,\"1785\":1,\"1828\":1,\"1888\":1,\"1919\":1,\"1969\":1,\"2047\":1,\"2225\":1,\"2238\":1,\"2261\":1,\"2279\":1,\"2297\":1,\"2329\":1,\"2404\":1,\"2467\":1,\"2494\":1,\"2535\":1,\"2567\":1,\"2639\":1}}],[\"2025年4月8日\",{\"2\":{\"225\":1,\"588\":1,\"641\":1}}],[\"2025年3月5日\",{\"2\":{\"139\":1,\"142\":1,\"160\":1,\"181\":1,\"182\":1}}],[\"2025年3月2日\",{\"2\":{\"104\":1,\"110\":1,\"119\":1,\"132\":1,\"154\":1,\"1044\":1,\"1063\":1,\"1070\":1,\"1085\":1,\"1098\":1}}],[\"2023年11月1日\",{\"2\":{\"2135\":1}}],[\"2023年11月2日\",{\"2\":{\"489\":1}}],[\"2023年10月xx日\",{\"0\":{\"1214\":1},\"2\":{\"1086\":1}}],[\"2023年10月27日\",{\"2\":{\"2131\":1}}],[\"2023年10月22日\",{\"2\":{\"1101\":1,\"2101\":1}}],[\"2023年10月29日\",{\"2\":{\"437\":1}}],[\"2023年10月20日\",{\"2\":{\"431\":1,\"2114\":1,\"2134\":1}}],[\"2023年10月24日\",{\"2\":{\"397\":1}}],[\"2023年10月25日\",{\"2\":{\"328\":1,\"377\":1,\"436\":1,\"484\":1,\"1148\":1,\"2067\":1,\"2116\":1}}],[\"2023年10月30日\",{\"0\":{\"2232\":1},\"2\":{\"382\":1,\"2088\":1}}],[\"2023\",{\"2\":{\"345\":1,\"384\":1,\"396\":1,\"398\":1,\"405\":1,\"413\":1,\"424\":1,\"1103\":1,\"1658\":2}}],[\"2024数据集上表现出色\",{\"2\":{\"1955\":1}}],[\"2024年3月\",{\"2\":{\"1658\":1}}],[\"2024年10月2日\",{\"2\":{\"71\":1,\"74\":1,\"80\":1,\"87\":1,\"92\":1,\"94\":1,\"96\":1}}],[\"2024\",{\"0\":{\"56\":1},\"2\":{\"1658\":1,\"2338\":3}}],[\"2️⃣\",{\"0\":{\"135\":1,\"394\":1},\"1\":{\"420\":1,\"445\":1,\"472\":1}}],[\"23646mib\",{\"2\":{\"2347\":1}}],[\"23074\",{\"2\":{\"2345\":1}}],[\"2393\",{\"2\":{\"1297\":3}}],[\"23\",{\"2\":{\"56\":4}}],[\"2e\",{\"2\":{\"40\":1}}],[\"2d\",{\"2\":{\"39\":1,\"1246\":2}}],[\"2^\",{\"2\":{\"18\":1,\"290\":1}}],[\"2\",{\"0\":{\"3\":1,\"27\":1,\"51\":1,\"77\":1,\"199\":1,\"239\":1,\"252\":1,\"293\":1,\"419\":1,\"452\":1,\"502\":1,\"535\":1,\"589\":1,\"690\":1,\"826\":1,\"845\":1,\"881\":1,\"896\":1,\"900\":1,\"944\":1,\"955\":1,\"995\":1,\"996\":1,\"1036\":2,\"1282\":1,\"1289\":1,\"1296\":1,\"1331\":1,\"1468\":1,\"1496\":1,\"1501\":1,\"1511\":1,\"1550\":1,\"1594\":1,\"1602\":1,\"1652\":1,\"1664\":1,\"1786\":1,\"1804\":1,\"1879\":1,\"1987\":1,\"2013\":1,\"2171\":1,\"2405\":1,\"2465\":1,\"2506\":1,\"2522\":1,\"2574\":1,\"2590\":1,\"2622\":1},\"1\":{\"6\":1,\"9\":1,\"13\":1,\"18\":1,\"91\":1,\"106\":1,\"480\":1,\"508\":1,\"542\":1,\"931\":1,\"935\":1,\"969\":1,\"975\":1,\"986\":1,\"996\":1,\"1010\":1,\"1016\":1,\"1026\":1,\"1036\":1,\"1050\":1,\"1059\":1,\"1069\":1,\"1094\":1,\"1104\":1,\"1114\":1,\"1143\":1,\"1154\":1,\"1164\":1,\"1203\":1,\"1213\":1,\"1254\":1,\"1264\":1,\"1303\":1,\"1311\":1,\"1350\":1,\"1357\":1,\"1395\":1,\"1403\":1,\"1559\":1,\"1657\":1,\"1712\":1,\"1935\":1},\"2\":{\"10\":1,\"15\":1,\"18\":8,\"20\":1,\"39\":1,\"49\":1,\"76\":4,\"135\":1,\"172\":2,\"199\":1,\"218\":2,\"221\":5,\"259\":2,\"290\":2,\"332\":3,\"376\":1,\"429\":1,\"443\":2,\"470\":2,\"474\":3,\"475\":1,\"497\":2,\"503\":1,\"526\":1,\"567\":1,\"640\":1,\"647\":2,\"705\":2,\"762\":4,\"769\":1,\"935\":1,\"941\":1,\"986\":1,\"1015\":1,\"1026\":2,\"1057\":2,\"1069\":1,\"1102\":1,\"1114\":1,\"1119\":1,\"1142\":2,\"1152\":1,\"1186\":1,\"1201\":1,\"1208\":1,\"1252\":1,\"1278\":1,\"1324\":3,\"1347\":2,\"1393\":1,\"1395\":1,\"1403\":1,\"1416\":1,\"1435\":3,\"1441\":3,\"1458\":1,\"1536\":6,\"1591\":2,\"1608\":1,\"1622\":1,\"1683\":2,\"1703\":4,\"1731\":2,\"1756\":3,\"1817\":3,\"1867\":1,\"1912\":4,\"1936\":1,\"2012\":2,\"2023\":1,\"2030\":21,\"2043\":1,\"2046\":1,\"2059\":1,\"2076\":1,\"2130\":6,\"2137\":1,\"2140\":3,\"2161\":1,\"2176\":6,\"2192\":1,\"2233\":2,\"2263\":2,\"2281\":1,\"2308\":2,\"2322\":2,\"2327\":4,\"2347\":1,\"2431\":2,\"2446\":2,\"2479\":1,\"2492\":4,\"2537\":5,\"2539\":1,\"2588\":1,\"2602\":6,\"2609\":2,\"2636\":3,\"2643\":1,\"2697\":1}}],[\"c1\",{\"2\":{\"2526\":1}}],[\"c0\",{\"2\":{\"2526\":1}}],[\"cto\",{\"2\":{\"2408\":1}}],[\"ctc​\",{\"2\":{\"2286\":2,\"2431\":1,\"2653\":1}}],[\"cem\",{\"2\":{\"2378\":1}}],[\"century\",{\"2\":{\"1458\":3}}],[\"centered\",{\"2\":{\"18\":1}}],[\"center\",{\"2\":{\"18\":1}}],[\"ci\",{\"2\":{\"2347\":1}}],[\"cbc​\",{\"2\":{\"2286\":4,\"2318\":1,\"2379\":1}}],[\"cbow的具体区别\",{\"2\":{\"1475\":1}}],[\"cbow的区别\",{\"2\":{\"1337\":1}}],[\"cbow适合小数据集\",{\"2\":{\"1066\":1}}],[\"cbow\",{\"2\":{\"870\":1,\"1111\":1}}],[\"cpu之间的通信量\",{\"2\":{\"2422\":1}}],[\"cpu卸载应满足以下三个方面的最优\",{\"2\":{\"2422\":1}}],[\"cpu卸载的优化目标\",{\"0\":{\"2422\":1}}],[\"cpu卸载技术不仅仅是将数据卸载到\",{\"2\":{\"2397\":1}}],[\"cpu卸载策略中\",{\"2\":{\"2486\":1}}],[\"cpu卸载策略\",{\"0\":{\"2397\":1}}],[\"cpu\",{\"0\":{\"2339\":1},\"1\":{\"2369\":1,\"2397\":1,\"2422\":1,\"2447\":1,\"2468\":1,\"2486\":1},\"2\":{\"2201\":1,\"2339\":1,\"2397\":3,\"2422\":1,\"2427\":1,\"2447\":1,\"2468\":1,\"2486\":1,\"2539\":3}}],[\"cpp要看os的第一章节并做笔记\",{\"2\":{\"56\":1}}],[\"cpp\",{\"2\":{\"56\":1}}],[\"c^\",{\"2\":{\"1329\":1}}],[\"csv数据表\",{\"2\":{\"2001\":1}}],[\"csv\",{\"2\":{\"1284\":1}}],[\"csdn博客\",{\"2\":{\"432\":1}}],[\"ccc\",{\"2\":{\"1740\":1}}],[\"cc\",{\"2\":{\"837\":1}}],[\"cntq\",{\"2\":{\"647\":2}}],[\"cnt\",{\"2\":{\"647\":2,\"656\":3}}],[\"cnn\",{\"2\":{\"39\":1,\"97\":1,\"144\":1}}],[\"c4\",{\"2\":{\"575\":1,\"741\":1,\"873\":1,\"909\":1,\"1297\":1}}],[\"cv\",{\"2\":{\"227\":1}}],[\"checkpoint\",{\"2\":{\"2177\":1,\"2233\":2,\"2252\":4}}],[\"checkpointing\",{\"0\":{\"2503\":2},\"2\":{\"2161\":1,\"2233\":1,\"2489\":1}}],[\"chenguang\",{\"2\":{\"1658\":1}}],[\"cherry\",{\"2\":{\"1025\":2}}],[\"chosen\",{\"2\":{\"1582\":4,\"1731\":8}}],[\"children\",{\"2\":{\"1458\":1}}],[\"chinese\",{\"2\":{\"1442\":1,\"1487\":1}}],[\"ch\",{\"2\":{\"783\":6}}],[\"chain→output\",{\"2\":{\"1708\":2}}],[\"chaining\",{\"0\":{\"1649\":1},\"1\":{\"1702\":1,\"1760\":1,\"1820\":1},\"2\":{\"1702\":1}}],[\"chain\",{\"0\":{\"1655\":1},\"1\":{\"1708\":1,\"1766\":1,\"1826\":1,\"1885\":1,\"1940\":1,\"1990\":1,\"2042\":1,\"2094\":1,\"2144\":1,\"2188\":1,\"2227\":1,\"2262\":1},\"2\":{\"1224\":1,\"1375\":1,\"1708\":2,\"1788\":1,\"1990\":1,\"2011\":1}}],[\"chatgpt\",{\"2\":{\"1238\":1,\"2245\":1}}],[\"chatglmconfig\",{\"2\":{\"1912\":1}}],[\"chatglm系列模型采用了一系列创新技术来提高性能和对齐效果\",{\"2\":{\"1008\":1}}],[\"chatglm技术创新\",{\"0\":{\"1008\":1}}],[\"chatglm能够处理长达1m上下文的文本\",{\"2\":{\"929\":1}}],[\"chatglm在预训练阶段使用了多语言文档\",{\"2\":{\"929\":1}}],[\"chatglm的模型结构在多个方面进行了优化\",{\"2\":{\"894\":1}}],[\"chatglm3\",{\"2\":{\"890\":1,\"926\":2,\"1007\":1,\"1092\":1,\"1292\":1}}],[\"chatglm\",{\"2\":{\"859\":1,\"926\":2,\"1007\":1,\"1008\":2,\"1092\":1,\"1292\":1}}],[\"chatglm2\",{\"2\":{\"854\":1,\"889\":1,\"925\":1,\"926\":2,\"1007\":1,\"1092\":1,\"1292\":1}}],[\"chat\",{\"2\":{\"1134\":1,\"1403\":1,\"1404\":1,\"2500\":1}}],[\"channels\",{\"2\":{\"1912\":2}}],[\"channel\",{\"0\":{\"981\":1},\"2\":{\"981\":1,\"1982\":1,\"2163\":1}}],[\"char\",{\"2\":{\"426\":1,\"783\":1}}],[\"challenges\",{\"2\":{\"153\":1}}],[\"chunking\",{\"2\":{\"2552\":1}}],[\"chunking方法通过将过长的prompt切成若干chunk\",{\"2\":{\"2386\":1}}],[\"chunking方法\",{\"0\":{\"2386\":1}}],[\"chunkllama\",{\"2\":{\"240\":1}}],[\"chunks\",{\"2\":{\"116\":1,\"135\":3,\"1321\":1}}],[\"chunk模型\",{\"2\":{\"74\":1}}],[\"chunk\",{\"0\":{\"64\":1,\"1937\":1,\"1987\":1},\"1\":{\"74\":1,\"86\":1,\"100\":1,\"116\":1,\"135\":1,\"155\":1,\"175\":1,\"196\":1,\"217\":1,\"240\":1},\"2\":{\"5\":2,\"63\":1,\"86\":1,\"135\":2,\"1041\":1,\"1450\":1,\"1513\":1,\"1823\":2,\"1937\":1,\"1987\":1,\"2141\":2,\"2420\":1}}],[\"create\",{\"2\":{\"1823\":1,\"1832\":2,\"2433\":1}}],[\"crewai\",{\"2\":{\"1300\":1}}],[\"critiquing\",{\"0\":{\"1619\":1}}],[\"critic和ppo算法都依赖于一个基于奖励的值来指导策略优化方向\",{\"2\":{\"1954\":1}}],[\"critic和reference是简单的网络实现\",{\"2\":{\"1954\":1}}],[\"critic的流程图如下\",{\"2\":{\"1619\":1}}],[\"criticize\",{\"2\":{\"1619\":1}}],[\"critic是一种利用工具交互评价来自我修正的技术框架\",{\"2\":{\"1619\":1}}],[\"critic损失函数为\",{\"2\":{\"1591\":1}}],[\"critic模型通过td\",{\"2\":{\"1591\":1}}],[\"critic模型可以通过多种方式初始化\",{\"2\":{\"1591\":1}}],[\"critic模型的初始化与更新\",{\"2\":{\"1591\":1}}],[\"critic模型的存在意义在于帮助模型生成符合人类喜好的内容\",{\"2\":{\"1541\":1}}],[\"critic模型用于预测期望总收益\",{\"2\":{\"1541\":1}}],[\"critic模型\",{\"2\":{\"1497\":1}}],[\"critic在不同应用场景下的性能表现\",{\"2\":{\"822\":1}}],[\"critic评判actor的动作好坏\",{\"2\":{\"619\":1}}],[\"critic评判actor的状态\",{\"2\":{\"518\":1}}],[\"critic代表值函数\",{\"2\":{\"619\":1}}],[\"critic\",{\"0\":{\"1497\":1,\"1619\":1,\"1780\":1},\"1\":{\"1541\":1,\"1591\":1,\"1645\":1,\"1699\":1,\"1757\":1,\"1817\":1,\"1877\":1,\"1934\":1},\"2\":{\"151\":1,\"487\":1,\"619\":11,\"766\":6,\"1497\":1,\"1539\":1,\"1591\":4,\"1899\":1,\"2004\":1,\"2148\":1}}],[\"critic算法将继续演化\",{\"2\":{\"791\":1}}],[\"critic算法简介\",{\"0\":{\"619\":1}}],[\"critic算法结合了策略梯度和值函数方法\",{\"2\":{\"518\":1}}],[\"critic算法\",{\"0\":{\"458\":1},\"1\":{\"487\":1,\"518\":1,\"551\":1,\"586\":1,\"619\":1,\"654\":1,\"689\":1,\"725\":1,\"759\":1,\"791\":1,\"822\":1},\"2\":{\"151\":1}}],[\"crowdsourcing\",{\"0\":{\"1368\":1}}],[\"cross\",{\"0\":{\"188\":1,\"1368\":1,\"2660\":1},\"2\":{\"135\":4,\"188\":2,\"232\":1,\"304\":1,\"326\":1,\"932\":1,\"970\":1,\"1009\":1,\"2201\":1,\"2378\":1}}],[\"crawl提取120b数学标记\",{\"2\":{\"1337\":1}}],[\"crawl的自然语言数据\",{\"2\":{\"1138\":1}}],[\"crawl的数据\",{\"2\":{\"1138\":1}}],[\"crawled\",{\"2\":{\"1019\":1}}],[\"crawler\",{\"2\":{\"526\":2}}],[\"crawl\",{\"2\":{\"535\":2,\"1290\":1}}],[\"clamp\",{\"2\":{\"1622\":1,\"1817\":1}}],[\"classification\",{\"2\":{\"1354\":1}}],[\"class\",{\"2\":{\"12\":1,\"39\":1,\"47\":1,\"48\":1,\"266\":1,\"619\":2,\"640\":1,\"646\":1,\"647\":1,\"656\":1,\"762\":1,\"766\":3,\"769\":1,\"783\":1,\"820\":2,\"840\":1,\"1582\":1,\"1622\":1,\"1731\":1,\"1817\":1,\"1831\":1,\"1832\":1,\"1883\":1,\"1912\":1,\"2400\":1,\"2408\":2,\"2433\":2,\"2500\":3}}],[\"clear\",{\"2\":{\"1458\":1,\"2050\":1}}],[\"clean\",{\"2\":{\"1019\":1}}],[\"clm\",{\"2\":{\"881\":1}}],[\"cls\",{\"2\":{\"542\":1,\"1771\":1,\"1832\":3}}],[\"cli\",{\"2\":{\"2233\":1}}],[\"clipped\",{\"2\":{\"1817\":2}}],[\"clip优化目标更新策略参数\",{\"2\":{\"695\":1}}],[\"clip因其简化的优化目标而广泛应用\",{\"2\":{\"521\":1}}],[\"clip\",{\"0\":{\"622\":1,\"2226\":1},\"1\":{\"2261\":1,\"2296\":1,\"2327\":1,\"2357\":1,\"2387\":1,\"2414\":1,\"2439\":1,\"2461\":1,\"2479\":1},\"2\":{\"521\":1,\"590\":3,\"868\":4,\"1258\":1,\"1399\":1,\"1622\":8,\"1628\":3,\"1817\":6,\"2044\":3,\"2097\":3,\"2261\":1,\"2296\":2,\"2327\":1,\"2439\":1,\"2485\":3}}],[\"client\",{\"2\":{\"102\":1}}],[\"cdot\",{\"2\":{\"76\":3,\"164\":3,\"189\":2,\"222\":1,\"228\":1,\"291\":1,\"307\":1,\"590\":1,\"622\":1,\"868\":1,\"998\":2,\"1142\":1,\"1179\":1,\"1279\":3,\"1297\":1,\"1329\":1,\"1343\":2,\"1344\":2,\"1591\":1,\"1622\":2,\"1676\":1,\"1732\":2,\"2033\":4,\"2044\":1,\"2046\":2,\"2097\":1,\"2140\":2,\"2142\":1,\"2145\":1,\"2308\":8,\"2322\":3}}],[\"cdots\",{\"2\":{\"18\":1,\"672\":1}}],[\"cuda\",{\"2\":{\"2108\":1}}],[\"cumulative\",{\"2\":{\"2035\":1}}],[\"cutoff\",{\"2\":{\"364\":1,\"917\":4}}],[\"cur\",{\"2\":{\"48\":6}}],[\"current\",{\"2\":{\"1883\":1}}],[\"curr\",{\"2\":{\"47\":8}}],[\"custom\",{\"0\":{\"0\":1},\"2\":{\"1458\":1}}],[\"c\",{\"2\":{\"18\":1,\"205\":1,\"223\":2,\"227\":1,\"259\":2,\"283\":3,\"381\":1,\"454\":1,\"622\":4,\"1142\":12,\"1225\":2,\"1329\":1,\"1455\":1,\"1456\":1,\"2286\":2,\"2347\":3,\"2417\":3,\"2433\":2,\"2643\":7,\"2653\":3}}],[\"capable\",{\"2\":{\"2434\":1}}],[\"capacity=max\",{\"2\":{\"1455\":1}}],[\"capacity=max⁡\",{\"2\":{\"1455\":1}}],[\"capacity=\",{\"2\":{\"1229\":2}}],[\"capacity\",{\"2\":{\"1229\":3,\"1455\":5}}],[\"call\",{\"0\":{\"2384\":1,\"2518\":1},\"2\":{\"2323\":1,\"2384\":1,\"2443\":1,\"2518\":1}}],[\"calculate\",{\"2\":{\"1984\":2}}],[\"calculator\",{\"2\":{\"12\":2}}],[\"calc\",{\"2\":{\"12\":3}}],[\"caching的优化\",{\"2\":{\"2166\":1}}],[\"caching的基本思想是对system\",{\"2\":{\"2064\":1}}],[\"cache来管理kv缓存\",{\"2\":{\"2413\":1}}],[\"cache可以显著减少不必要的重复计算\",{\"2\":{\"2166\":1}}],[\"cache属于相对高级的用法\",{\"2\":{\"2166\":1}}],[\"cache分配\",{\"0\":{\"1978\":1}}],[\"cache中\",{\"2\":{\"1782\":1,\"2356\":1}}],[\"cache使用策略以减少不必要的数据读取\",{\"2\":{\"613\":1}}],[\"cache对整体速度的微小影响\",{\"2\":{\"546\":1}}],[\"cache数据量为130kb\",{\"2\":{\"455\":1}}],[\"cache读取\",{\"0\":{\"455\":1}}],[\"cache进行推理\",{\"2\":{\"351\":1}}],[\"cache在多模态任务中的应用可能性\",{\"2\":{\"303\":1}}],[\"cache功能模块\",{\"2\":{\"303\":1}}],[\"cache能否应用于非自回归任务\",{\"2\":{\"279\":1}}],[\"cache能够显著降低延迟\",{\"2\":{\"255\":1}}],[\"cache为之前存储的key和value\",{\"2\":{\"208\":1}}],[\"cache和v\",{\"2\":{\"208\":1}}],[\"cache如何优化计算\",{\"2\":{\"208\":1}}],[\"cache的流程\",{\"0\":{\"166\":1,\"187\":1}}],[\"cache工作原理\",{\"0\":{\"125\":1}}],[\"cache通过将这些计算结果缓存下来\",{\"2\":{\"107\":1}}],[\"cache技术\",{\"2\":{\"1870\":1}}],[\"cache技术不仅提升了推理效率\",{\"2\":{\"255\":1}}],[\"cache技术的优势将更加显著\",{\"2\":{\"187\":1}}],[\"cache技术主要应用于causal\",{\"2\":{\"125\":1}}],[\"cache技术简介\",{\"0\":{\"107\":1}}],[\"cache技术详解\",{\"0\":{\"68\":1,\"78\":1},\"1\":{\"78\":1,\"92\":1,\"107\":1,\"125\":1,\"145\":1,\"166\":1,\"187\":1,\"208\":1,\"231\":1,\"255\":1,\"279\":1,\"303\":1},\"2\":{\"5\":2,\"63\":1}}],[\"cache\",{\"0\":{\"145\":1,\"2166\":1,\"2356\":1},\"1\":{\"166\":1,\"187\":1},\"2\":{\"92\":1,\"107\":1,\"208\":6,\"303\":1,\"799\":1,\"1782\":2,\"1991\":1,\"2077\":1,\"2118\":1,\"2145\":2,\"2166\":2,\"2692\":1}}],[\"cards\",{\"2\":{\"1458\":1}}],[\"carlo\",{\"2\":{\"675\":1,\"1917\":1,\"2378\":1}}],[\"caution\",{\"2\":{\"1368\":1}}],[\"camel\",{\"2\":{\"1300\":1}}],[\"case\",{\"2\":{\"2518\":1}}],[\"cases\",{\"2\":{\"285\":2,\"1344\":2,\"1364\":2}}],[\"casual\",{\"2\":{\"1006\":1}}],[\"categorical\",{\"2\":{\"619\":1,\"766\":1,\"820\":1}}],[\"cat\",{\"2\":{\"135\":1,\"2539\":2,\"2628\":3}}],[\"can\",{\"2\":{\"18\":2}}],[\"co\",{\"2\":{\"1485\":1}}],[\"coze\",{\"2\":{\"1347\":1}}],[\"correct\",{\"2\":{\"1816\":1}}],[\"correcting\",{\"0\":{\"1619\":1}}],[\"corpus\",{\"2\":{\"1019\":1,\"1290\":1}}],[\"core\",{\"2\":{\"462\":1,\"698\":1}}],[\"copy\",{\"2\":{\"656\":1}}],[\"cot推理模型\",{\"2\":{\"1939\":1}}],[\"cot\",{\"0\":{\"1224\":1,\"1708\":1,\"1766\":1,\"1826\":2,\"1885\":1,\"1940\":1,\"1990\":1,\"2042\":1},\"1\":{\"1885\":2,\"1940\":2,\"2042\":1,\"2094\":1,\"2144\":1,\"2188\":1,\"2227\":1,\"2262\":1},\"2\":{\"474\":1,\"1124\":1,\"1224\":8,\"1375\":1,\"1708\":3,\"1766\":2,\"1826\":3,\"1885\":3,\"1940\":1,\"1990\":3,\"2042\":2,\"2145\":4,\"2188\":1,\"2474\":1,\"2514\":2,\"2516\":1}}],[\"cosine\",{\"2\":{\"2217\":2,\"2319\":1}}],[\"cos⁡\",{\"2\":{\"1246\":3}}],[\"cos⁡mθsin⁡mθ−sin⁡mθcos⁡mθ\",{\"2\":{\"247\":1}}],[\"cosmθ−sinmθ​sinmθcosmθ​\",{\"2\":{\"247\":1}}],[\"cos\",{\"2\":{\"247\":2,\"332\":1,\"1246\":6,\"1435\":1}}],[\"communication\",{\"2\":{\"2081\":3}}],[\"comments\",{\"2\":{\"526\":3}}],[\"commonsense\",{\"2\":{\"1708\":1}}],[\"commoncrawl\",{\"2\":{\"575\":1,\"644\":1}}],[\"common\",{\"0\":{\"172\":1},\"2\":{\"391\":2,\"535\":2,\"1290\":1}}],[\"compare\",{\"2\":{\"2436\":3}}],[\"comparison\",{\"2\":{\"1324\":1}}],[\"completion\",{\"2\":{\"2263\":1,\"2500\":5,\"2600\":4}}],[\"complex\",{\"2\":{\"2050\":1}}],[\"compressed\",{\"0\":{\"1588\":1}}],[\"computation\",{\"2\":{\"1455\":1}}],[\"compute\",{\"2\":{\"515\":1,\"2600\":2}}],[\"compound\",{\"2\":{\"1458\":1}}],[\"compositional\",{\"2\":{\"949\":1}}],[\"component\",{\"0\":{\"0\":1},\"2\":{\"1831\":2}}],[\"com\",{\"2\":{\"469\":1,\"485\":1,\"559\":1,\"1878\":1,\"2275\":3,\"2345\":1}}],[\"count=1\",{\"2\":{\"1111\":2}}],[\"count设为1\",{\"2\":{\"846\":1}}],[\"count减去1\",{\"2\":{\"846\":1}}],[\"count\",{\"2\":{\"526\":2,\"640\":3,\"647\":1,\"783\":5}}],[\"counters\",{\"2\":{\"2433\":3}}],[\"counter\",{\"2\":{\"391\":1,\"2433\":6}}],[\"courville\",{\"2\":{\"165\":1}}],[\"coursera\",{\"2\":{\"67\":1,\"106\":1,\"165\":1,\"230\":1,\"302\":1}}],[\"course看完\",{\"2\":{\"56\":1}}],[\"cout\",{\"0\":{\"22\":1},\"2\":{\"10\":4,\"11\":3,\"12\":3,\"15\":2,\"22\":8,\"27\":2}}],[\"conv\",{\"2\":{\"2400\":1}}],[\"convert\",{\"2\":{\"2050\":1}}],[\"conversational\",{\"0\":{\"1238\":1},\"2\":{\"1238\":1}}],[\"convenient\",{\"2\":{\"1458\":1}}],[\"confidence\",{\"2\":{\"2050\":1}}],[\"config=self\",{\"2\":{\"2500\":1}}],[\"config\",{\"2\":{\"1912\":18,\"1928\":3,\"2500\":1}}],[\"concatenate和filter\",{\"0\":{\"1843\":1}}],[\"concurrency\",{\"2\":{\"526\":1}}],[\"connection\",{\"2\":{\"1458\":2}}],[\"conditional\",{\"2\":{\"1455\":1}}],[\"conda是怎么运行的\",{\"2\":{\"56\":1}}],[\"consistency\",{\"0\":{\"596\":1,\"2042\":1},\"2\":{\"739\":1,\"1990\":1}}],[\"constant\",{\"2\":{\"2217\":1}}],[\"const\",{\"2\":{\"18\":4}}],[\"controller\",{\"0\":{\"2262\":1},\"2\":{\"2227\":1}}],[\"contrastive\",{\"2\":{\"1517\":1,\"1902\":1}}],[\"contrast\",{\"2\":{\"1008\":1}}],[\"continuous\",{\"2\":{\"867\":1,\"870\":1}}],[\"continue\",{\"2\":{\"475\":1,\"501\":1,\"769\":1}}],[\"context\",{\"2\":{\"101\":1,\"240\":1,\"477\":1,\"502\":1,\"634\":1,\"740\":2,\"949\":1,\"1082\":1,\"1175\":1,\"1228\":1,\"1333\":1,\"1458\":1,\"1550\":1,\"1910\":1,\"2050\":1,\"2711\":1}}],[\"content\",{\"2\":{\"18\":6,\"1324\":1,\"1458\":2,\"2050\":1,\"2601\":1,\"2608\":1}}],[\"contain\",{\"2\":{\"18\":2}}],[\"code语料采样\",{\"0\":{\"909\":1}}],[\"codellama\",{\"2\":{\"172\":1,\"740\":1}}],[\"code\",{\"0\":{\"1674\":1},\"1\":{\"1730\":1,\"1788\":1,\"1849\":1},\"2\":{\"18\":2,\"909\":1}}],[\"collective\",{\"2\":{\"2081\":1}}],[\"colored\",{\"2\":{\"1458\":1}}],[\"colossal\",{\"2\":{\"1019\":1}}],[\"colab\",{\"2\":{\"65\":1,\"544\":1}}],[\"col\",{\"2\":{\"18\":2}}],[\"cool\",{\"2\":{\"18\":1}}],[\"c++核心\",{\"0\":{\"21\":1}}],[\"c++简介\",{\"2\":{\"16\":2}}],[\"c++\",{\"2\":{\"7\":1,\"11\":1,\"15\":1,\"16\":4,\"17\":1,\"21\":4,\"24\":3,\"27\":1,\"2408\":1}}]],\"serializationVersion\":2}"