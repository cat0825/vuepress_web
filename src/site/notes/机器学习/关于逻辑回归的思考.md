---
{"dg-publish":true,"dg-permalink":"/机器学习/逻辑回归","permalink":"/机器学习/逻辑回归/","dgPassFrontmatter":true,"noteIcon":"","created":"2025-01-05T10:20:18.000+08:00","updated":"2025-01-05T10:22:45.248+08:00"}
---



# 逻辑回归的全流程（通俗易懂版）

## 1. **问题背景**
逻辑回归是用来解决分类问题的，比如判断一封邮件是垃圾邮件还是正常邮件，或者预测一个人是否患有某种疾病。它的特点是输出是一个概率值（0到1之间），然后根据概率值做出分类决策。

---


## 2. **逻辑回归的核心思想**
逻辑回归的核心思想是：
- 先用一条直线（或超平面）对数据进行划分。
- 然后通过一个特殊的函数（S型函数）将直线输出的值转换成概率。
- 最后根据概率值判断类别。

---


## 3. **逻辑回归的全流程**

### **第一步：输入数据**
- 假设我们有一组数据，比如病人的年龄、血压、血糖等特征，以及是否患病的标签（0或1）。
- 我们的目标是通过这些特征预测一个新病人是否患病。


### **第二步：线性回归部分**
- 逻辑回归首先像线性回归一样，计算一个线性方程：
  $$
  z = w_1 \cdot x_1 + w_2 \cdot x_2 + \dots + w_n \cdot x_n + b
  $$
  其中：
  - \( x_1, x_2, \dots, x_n \) 是输入特征（比如年龄、血压等）。
  - \( w_1, w_2, \dots, w_n \) 是权重（表示每个特征的重要性）。
  - \( b \) 是偏置项（可以理解为一个调整值）。
  - \( z \) 是线性回归的输出。


### **第三步：通过S型函数转换概率**
- 线性回归的输出 \( z \) 是一个任意实数（可能是负数或很大的数），但我们想要的是一个概率值（0到1之间）。
- 于是，我们用S型函数（也叫Sigmoid函数）将 \( z \) 转换成概率：
  $$
  \sigma(z) = \frac{1}{1 + e^{-z}}
  $$
  这个函数的输出值在0到1之间，可以理解为“属于正类的概率”。


### **第四步：设定阈值进行分类**
- 得到概率值后，我们需要设定一个阈值（比如0.5）来判断类别：
  - 如果概率 ≥ 0.5，预测为正类（比如患病）。
  - 如果概率 < 0.5，预测为负类（比如健康）。


### **第五步：训练模型**
- 逻辑回归的目标是找到一组权重 \( w \) 和偏置 \( b \)，使得模型的预测结果尽可能接近真实标签。
- 训练过程是通过“最大似然估计”或“梯度下降法”来不断调整 \( w \) 和 \( b \)，使得模型的预测误差最小。


### **第六步：预测新数据**
- 当模型训练好后，我们可以用它对新的数据进行预测。比如输入一个新病人的年龄、血压等特征，模型会输出一个概率值，告诉我们这个病人患病的可能性有多大。

---


## 4. **举个例子**
假设我们用逻辑回归预测一个人是否会购买某款产品：
- 输入特征：年龄、收入、浏览时长。
- 模型计算：
  $$
  z = 0.1 \cdot \text{年龄} + 0.5 \cdot \text{收入} + 0.3 \cdot \text{浏览时长} - 5
  $$
- 通过S型函数转换：
  $$
  \sigma(z) = \frac{1}{1 + e^{-z}} = 0.7
  $$
- 因为0.7 > 0.5，所以预测这个人会购买产品。

---


## 5. **总结**
逻辑回归的全流程可以简单概括为：
1. 输入特征数据。
2. 用线性方程计算得分 \( z \)。
3. 用S型函数将 \( z \) 转换成概率。
4. 根据概率值和阈值进行分类。
5. 训练模型，调整参数，使预测更准确。
6. 用训练好的模型预测新数据。

逻辑回归虽然简单，但在很多实际问题中都非常有效，是机器学习的经典算法之一！
