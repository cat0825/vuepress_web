---
dg-publish: true
dg-permalink: /大语言模型学习/碎碎念
dg-home: false
dg-description: 在此输入笔记的描述
dg-hide: false
dg-hide-title: false
dg-show-backlinks: true
dg-show-local-graph: true
dg-show-inline-title: true
dg-pinned: false
dg-passphrase: 在此输入访问密码
dg-enable-mathjax: false
dg-enable-mermaid: false
dg-enable-uml: false
dg-note-icon: 0
dg-enable-dataview: false
tags:
  - NLP
permalink: /大语言模型学习/碎碎念/
dgShowBacklinks: true
dgShowLocalGraph: true
dgShowInlineTitle: true
dgPassFrontmatter: true
noteIcon: 0
created: 2025-02-27T12:07:19.000+08:00
updated: 2025-05-04T19:19:14.413+08:00
title: 导航
createTime: 2025/05/13 17:33:52
---

# 分词
- <span class="iconify" data-icon="mdi:format-list-bulleted"></span> [介绍](/大语言模型学习/词嵌入/介绍/)
- <span class="iconify" data-icon="mdi:format-list-bulleted"></span> [oneHot](/大语言模型学习/词嵌入/oneHot/)
- <span class="iconify" data-icon="mdi:format-list-bulleted"></span> [Word2Vec](/大语言模型学习/词嵌入/Word2Vec/)
- <span class="iconify" data-icon="mdi:format-list-bulleted"></span> [FastText](/大语言模型学习/词嵌入/FastText/)

# 词嵌入
- <span class="iconify" data-icon="mdi:vector-link"></span> [介绍](/大语言模型学习/词嵌入/介绍/)
- <span class="iconify" data-icon="mdi:vector-link"></span> [oneHot](/大语言模型学习/词嵌入/oneHot/)
- <span class="iconify" data-icon="mdi:vector-link"></span> [Word2Vec](/大语言模型学习/词嵌入/Word2Vec/)
- <span class="iconify" data-icon="mdi:vector-link"></span> [FastText](/大语言模型学习/词嵌入/FastText/)

# Attention
- <span class="iconify" data-icon="mdi:eye"></span> [Attention机制详解与应用](/大语言模型学习/Attention注意力机制/Attention机制详解与应用/)
- <span class="iconify" data-icon="mdi:eye"></span> [Transformer中的Attention详解与应用指南](/大语言模型学习/Attention注意力机制/Transformer中的Attention详解与应用指南/)
- <span class="iconify" data-icon="mdi:eye"></span> [优化Attention计算复杂度的技术探讨](/大语言模型学习/Attention注意力机制/优化Attention计算复杂度的技术探讨/)
- <span class="iconify" data-icon="mdi:eye"></span> [KV Cache技术详解：优化Transformer自回归生成效率](/大语言模型学习/Attention注意力机制/KV-Cache技术详解：优化Transformer自回归生成效率/)
- <span class="iconify" data-icon="mdi:eye"></span> [深度学习中的注意力机制优化：从MHA到MLA](/大语言模型学习/Attention注意力机制/深度学习中的注意力机制优化：从MHA到MLA/)
- <span class="iconify" data-icon="mdi:eye"></span> [DCA：长文本处理的新突破（Dual Chunk Attention）](/大语言模型学习/Attention注意力机制/DCA：长文本处理的新突破（Dual-Chunk-Attention）/)
- <span class="iconify" data-icon="mdi:eye"></span> [【长上下文模型优化】基于Shifted Sparse Attention的创新方法](/大语言模型学习/Attention注意力机制/【长上下文模型优化】基于Shifted-Sparse-Attention的创新方法/)

# FFN,Add&LN
- <span class="iconify" data-icon="mdi:plus-box"></span> [Transformer核心模块解析：FFN、Add & LN 的作用与应用](/大语言模型学习/FFN、Add-&-LN-的作用与应用/Transformer核心模块解析：FFN、Add-&-LN-的作用与应用/)
- <span class="iconify" data-icon="mdi:plus-box"></span> [深度学习中的Layer Norm设计：Post-Norm、Pre-Norm与Sandwich-Norm比较](/大语言模型学习/FFN、Add-&-LN-的作用与应用/深度学习中的Layer-Norm设计：Post-Norm、Pre-Norm与Sandwich-Norm比较/)
- <span class="iconify" data-icon="mdi:plus-box"></span> [激活函数与FFN结构优化：SwiGLU、GeGLU及其应用解析](/大语言模型学习/FFN、Add-&-LN-的作用与应用/激活函数与FFN结构优化：SwiGLU、GeGLU及其应用解析/)
- <span class="iconify" data-icon="mdi:plus-box"></span> [激活函数详解与比较：从Sigmoid到Swish](/大语言模型学习/FFN、Add-&-LN-的作用与应用/激活函数详解与比较：从Sigmoid到Swish/)

# Positional-Encoding
- <span class="iconify" data-icon="mdi:map-marker"></span> [介绍](/大语言模型学习/Positional-Encoding位置编码/介绍/)
- <span class="iconify" data-icon="mdi:map-marker"></span> [Transformer绝对位置编码详解与改进分析](/大语言模型学习/Positional-Encoding位置编码/绝对位置编码/Transformer绝对位置编码详解与改进分析/)
- <span class="iconify" data-icon="mdi:map-marker"></span> [BERT与RNN位置编码的对比与应用](/大语言模型学习/Positional-Encoding位置编码/绝对位置编码/BERT与RNN位置编码的对比与应用/)
- <span class="iconify" data-icon="mdi:map-marker"></span> [相对位置编码与XLNet位置编码详解 深入理解Transformer机制](/大语言模型学习/Positional-Encoding位置编码/相对位置编码/相对位置编码与XLNet位置编码详解-深入理解Transformer机制/)
- <span class="iconify" data-icon="mdi:map-marker"></span> [T5模型与相对位置编码优化解析](/大语言模型学习/Positional-Encoding位置编码/相对位置编码/T5模型与相对位置编码优化解析/)
- <span class="iconify" data-icon="mdi:map-marker"></span> [DeBERTa的相对位置编码与绝对位置编码解析](/大语言模型学习/Positional-Encoding位置编码/相对位置编码/DeBERTa的相对位置编码与绝对位置编码解析/)
- <span class="iconify" data-icon="mdi:map-marker"></span> [旋转位置编码与ALiBi：深度学习中的位置嵌入优化](/大语言模型学习/Positional-Encoding位置编码/旋转位置编码与ALiBi：深度学习中的位置嵌入优化/)
- <span class="iconify" data-icon="mdi:map-marker"></span> [数字输入优化与外推方法解析](/大语言模型学习/Positional-Encoding位置编码/数字输入优化与外推方法解析/)
- <span class="iconify" data-icon="mdi:map-marker"></span> [位置内插法扩展语言模型上下文长度](/大语言模型学习/Positional-Encoding位置编码/位置内插法扩展语言模型上下文长度/)
- <span class="iconify" data-icon="mdi:map-marker"></span> [NTK插值方法解析与优化：从NTK-aware到NTK-by-parts](/大语言模型学习/Positional-Encoding位置编码/NTK插值方法解析与优化：从NTK-aware到NTK-by-parts/)
- <span class="iconify" data-icon="mdi:map-marker"></span> [YaRN方法解析：扩展RoPE嵌入与注意力优化的实践](/大语言模型学习/Positional-Encoding位置编码/YaRN方法解析：扩展RoPE嵌入与注意力优化的实践/)

# Structure-&-Decoding-Policy-结构和解码策略
- <span class="iconify" data-icon="mdi:shape"></span> [大模型结构与混合专家（LLM & MoE）解析](/大语言模型学习/Structure-&-Decoding-Policy-结构和解码策略/大模型结构与混合专家（LLM-&-MoE）解析/)
- <span class="iconify" data-icon="mdi:shape"></span> [解码采样策略：Greedy Search与Beam Search的实现与优化](/大语言模型学习/Structure-&-Decoding-Policy-结构和解码策略/解码采样策略：Greedy-Search与Beam-Search的实现与优化/)
- <span class="iconify" data-icon="mdi:shape"></span> [深度解析语言模型采样方法：Top-K、Top-P、Temperature及综合策略](/大语言模型学习/Structure-&-Decoding-Policy-结构和解码策略/深度解析语言模型采样方法：Top-K、Top-P、Temperature及综合策略/)

# Pre-training-预训练
- <span class="iconify" data-icon="mdi:rocket-launch"></span> [预训练定义以及数据来源](/大语言模型学习/Pre-training-预训练/预训练定义以及数据来源/)
- <span class="iconify" data-icon="mdi:rocket-launch"></span> [数据爬取](/大语言模型学习/Pre-training-预训练/数据爬取/)
- <span class="iconify" data-icon="mdi:rocket-launch"></span> [数据清洗](/大语言模型学习/Pre-training-预训练/数据清洗/)
- <span class="iconify" data-icon="mdi:rocket-launch"></span> [模型打分与数据去重](/大语言模型学习/Pre-training-预训练/模型打分与数据去重/)
- <span class="iconify" data-icon="mdi:rocket-launch"></span> [数据多样性与模型优化探索](/大语言模型学习/Pre-training-预训练/数据多样性与模型优化探索/)
- <span class="iconify" data-icon="mdi:rocket-launch"></span> [数据配比与训练顺序优化指南](/大语言模型学习/Pre-training-预训练/数据配比与训练顺序优化指南/)
- <span class="iconify" data-icon="mdi:rocket-launch"></span> [训练Tokenizer](/大语言模型学习/Pre-training-预训练/预训练过程/训练Tokenizer/)
- <span class="iconify" data-icon="mdi:rocket-launch"></span> [高效深度学习模型训练框架选择与优化指南](/大语言模型学习/Pre-training-预训练/预训练过程/高效深度学习模型训练框架选择与优化指南/)
- <span class="iconify" data-icon="mdi:rocket-launch"></span> [预训练策略](/大语言模型学习/Pre-training-预训练/预训练过程/预训练策略/)
- <span class="iconify" data-icon="mdi:rocket-launch"></span> [训练容灾及训练监控](/大语言模型学习/Pre-training-预训练/训练容灾及训练监控/)
- <span class="iconify" data-icon="mdi:rocket-launch"></span> [预训练的Scaling Law](/大语言模型学习/Pre-training-预训练/预训练过程/预训练的Scaling-Law/)
- <span class="iconify" data-icon="mdi:rocket-launch"></span> [混合精度训练](/大语言模型学习/Pre-training-预训练/混合精度训练/)
- <span class="iconify" data-icon="mdi:rocket-launch"></span> [深度学习中的显存优化与梯度处理方法](/大语言模型学习/Pre-training-预训练/深度学习中的显存优化与梯度处理方法/)
- <span class="iconify" data-icon="mdi:rocket-launch"></span> [继续预训练](/大语言模型学习/Pre-training-预训练/继续预训练/)
- <span class="iconify" data-icon="mdi:rocket-launch"></span> [推理耗时](/大语言模型学习/Pre-training-预训练/推理耗时/)
- <span class="iconify" data-icon="mdi:rocket-launch"></span> [预训练评估](/大语言模型学习/Pre-training-预训练/预训练评估/)
- <span class="iconify" data-icon="mdi:rocket-launch"></span> [预训练评估2](/大语言模型学习/Pre-training-预训练/预训练评估2/)

# 后训练
- <span class="iconify" data-icon="mdi:history"></span> [监督微调与预训练的区别](/大语言模型学习/后训练/SFT监督微调/监督微调与预训练的区别/)
- <span class="iconify" data-icon="mdi:history"></span> [数据飞轮在SFT中的应用与优化](/大语言模型学习/后训练/SFT监督微调/SFT数据及处理/数据飞轮在SFT中的应用与优化/)
- <span class="iconify" data-icon="mdi:history"></span> [数据生产合成与质量过滤](/大语言模型学习/后训练/SFT监督微调/SFT数据及处理/数据生产合成与质量过滤/)
- <span class="iconify" data-icon="mdi:history"></span> [数据多样性探索](/大语言模型学习/后训练/SFT监督微调/SFT数据及处理/数据多样性探索/)
- <span class="iconify" data-icon="mdi:history"></span> [开源数据集](/大语言模型学习/后训练/SFT监督微调/SFT数据及处理/开源数据集/)
- <span class="iconify" data-icon="mdi:history"></span> [训练框架及参数设置](/大语言模型学习/后训练/SFT监督微调/STF训练/训练框架及参数设置/)
- <span class="iconify" data-icon="mdi:history"></span> [训练技巧和训练策略](/大语言模型学习/后训练/SFT监督微调/STF训练/训练技巧和训练策略/)
- <span class="iconify" data-icon="mdi:history"></span> [多轮对话专项提升](/大语言模型学习/后训练/SFT监督微调/STF训练/多轮对话专项提升/)
- <span class="iconify" data-icon="mdi:history"></span> [多轮对话专项提升2](/大语言模型学习/后训练/SFT监督微调/STF训练/多轮对话专项提升2/)
- <span class="iconify" data-icon="mdi:history"></span> [训练启动脚本](/大语言模型学习/后训练/SFT监督微调/STF训练/训练启动脚本/)

# 强化学习基础
- <span class="iconify" data-icon="mdi:brain"></span> [强化学习问题,流程](/大语言模型学习/RL强化学习基础/强化学习问题,流程/)
- <span class="iconify" data-icon="mdi:brain"></span> [强化学习的独特性](/大语言模型学习/RL强化学习基础/强化学习的独特性/)
- <span class="iconify" data-icon="mdi:brain"></span> [马尔可夫决策过程](/大语言模型学习/RL强化学习基础/马尔可夫决策过程/)
- <span class="iconify" data-icon="mdi:brain"></span> [贝尔曼方程](/大语言模型学习/RL强化学习基础/贝尔曼方程/)
- <span class="iconify" data-icon="mdi:brain"></span> [蒙特卡洛方法](/大语言模型学习/RL强化学习基础/蒙特卡洛方法/)
- <span class="iconify" data-icon="mdi:brain"></span> [策略迭代算法](/大语言模型学习/RL强化学习基础/策略迭代算法/)
- <span class="iconify" data-icon="mdi:brain"></span> [价值迭代算法](/大语言模型学习/RL强化学习基础/价值迭代算法/)
- <span class="iconify" data-icon="mdi:brain"></span> [时序差分算法](/大语言模型学习/RL强化学习基础/时序差分算法/)
- <span class="iconify" data-icon="mdi:brain"></span> [SARSA算法](/大语言模型学习/RL强化学习基础/SARSA算法/)
- <span class="iconify" data-icon="mdi:brain"></span> [SARSA-λ与Q-learning对比](/大语言模型学习/RL强化学习基础/SARSA-λ与Q-learning对比/)
- <span class="iconify" data-icon="mdi:brain"></span> [强化学习分类](/大语言模型学习/RL强化学习基础/强化学习分类/)
- <span class="iconify" data-icon="mdi:brain"></span> [深度Q网络](/大语言模型学习/RL强化学习基础/深度Q网络/)
- <span class="iconify" data-icon="mdi:brain"></span> [策略梯度算法](/大语言模型学习/RL强化学习基础/策略梯度算法/)
- <span class="iconify" data-icon="mdi:brain"></span> [Actor-Critic算法](/大语言模型学习/RL强化学习基础/Actor-Critic算法/)
- <span class="iconify" data-icon="mdi:brain"></span> [PPO算法](/大语言模型学习/RL强化学习基础/PPO算法/)
- <span class="iconify" data-icon="mdi:brain"></span> [RL在NLP场景下的拓展](/大语言模型学习/RL强化学习基础/RL在NLP场景下的拓展/)
- <span class="iconify" data-icon="mdi:brain"></span> [RL在NLP场景下的拓展](/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/RL在NLP场景下的拓展/)
- <span class="iconify" data-icon="mdi:brain"></span> [RLHF流程](/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/RLHF流程/)
- <span class="iconify" data-icon="mdi:brain"></span> [RLHF研究方法及研究总结](/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/RLHF研究方法及研究总结/)
- <span class="iconify" data-icon="mdi:brain"></span> [Instruct-GPT](/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/Instruct-GPT/)
- <span class="iconify" data-icon="mdi:brain"></span> [Actor-Model](/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/Actor-Model/)
- <span class="iconify" data-icon="mdi:brain"></span> [critic-model](/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/critic-model/)
- <span class="iconify" data-icon="mdi:brain"></span> [Reward-Model](/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/Reward-Model/)
- <span class="iconify" data-icon="mdi:brain"></span> [深入理解Prompt到Response的MDP模型分析](/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/深入理解Prompt到Response的MDP模型分析/)
- <span class="iconify" data-icon="mdi:brain"></span> [Reference-Model](/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/Reference-Model/)
- <span class="iconify" data-icon="mdi:brain"></span> [在线与离线RLHF的比较与应用](/大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/在线与离线RLHF的比较与应用/)
- <span class="iconify" data-icon="mdi:brain"></span> [PPO训练的trick和问题](/大语言模型学习/RL强化学习基础/PPO训练的trick和问题/)
- <span class="iconify" data-icon="mdi:brain"></span> [GRPO](/大语言模型学习/RL强化学习基础/优化PPO方向的算法/GRPO/)
- <span class="iconify" data-icon="mdi:brain"></span> [ReMax-improvement](/大语言模型学习/RL强化学习基础/优化PPO方向的算法/ReMax-improvement/)
- <span class="iconify" data-icon="mdi:brain"></span> [ReMax](/大语言模型学习/RL强化学习基础/优化PPO方向的算法/ReMax/)
- <span class="iconify" data-icon="mdi:brain"></span> [REINFORCE算法改进：RLOO与REINFORCE++](/大语言模型学习/RL强化学习基础/优化PPO方向的算法/REINFORCE算法改进：RLOO与REINFORCE++/)
- <span class="iconify" data-icon="mdi:brain"></span> [DAPO](/大语言模型学习/RL强化学习基础/优化PPO方向的算法/DAPO/)
- <span class="iconify" data-icon="mdi:brain"></span> [VAPO](/大语言模型学习/RL强化学习基础/优化PPO方向的算法/VAPO/)
- <span class="iconify" data-icon="mdi:brain"></span> [DPO介绍及RLHF-PPO缺点](/大语言模型学习/RL强化学习基础/DPO直接偏好优化/DPO介绍及RLHF-PPO缺点/)
- <span class="iconify" data-icon="mdi:brain"></span> [DPO公式推导](/大语言模型学习/RL强化学习基础/DPO直接偏好优化/DPO公式推导/)
- <span class="iconify" data-icon="mdi:brain"></span> [深度偏好优化（DPO）损失函数解析与代码示例](/大语言模型学习/RL强化学习基础/DPO直接偏好优化/深度偏好优化（DPO）损失函数解析与代码示例/)
- <span class="iconify" data-icon="mdi:brain"></span> [人类建模偏好角度理解DPO](/大语言模型学习/RL强化学习基础/DPO直接偏好优化/人类建模偏好角度理解DPO/)
- <span class="iconify" data-icon="mdi:brain"></span> [对比学习角度理解DPO](/大语言模型学习/RL强化学习基础/DPO直接偏好优化/对比学习角度理解DPO/)
- <span class="iconify" data-icon="mdi:brain"></span> [DPOP](/大语言模型学习/RL强化学习基础/优化DPO方向的算法/DPOP/)
- <span class="iconify" data-icon="mdi:brain"></span> [TDPO](/大语言模型学习/RL强化学习基础/优化DPO方向的算法/TDPO/)
- <span class="iconify" data-icon="mdi:brain"></span> [Self-Reward](/大语言模型学习/RL强化学习基础/优化DPO方向的算法/Self-Reward/)
- <span class="iconify" data-icon="mdi:brain"></span> [介绍](/大语言模型学习/RL强化学习基础/PEFT参数高效微调/介绍/)
- <span class="iconify" data-icon="mdi:brain"></span> [Prompt Tuning](/大语言模型学习/RL强化学习基础/PEFT参数高效微调/Prompt-Tuning/)
- <span class="iconify" data-icon="mdi:brain"></span> [P-Tuning](/大语言模型学习/RL强化学习基础/PEFT参数高效微调/P-Tuning/)
- <span class="iconify" data-icon="mdi:brain"></span> [Prefix-Tuning](/大语言模型学习/RL强化学习基础/PEFT参数高效微调/Prefix-Tuning/)
- <span class="iconify" data-icon="mdi:brain"></span> [P-Tuning V2](/大语言模型学习/RL强化学习基础/PEFT参数高效微调/P-Tuning-V2/)
- <span class="iconify" data-icon="mdi:brain"></span> [LLaMA-Adapter](/大语言模型学习/RL强化学习基础/PEFT参数高效微调/LLaMA-Adapter/)
- <span class="iconify" data-icon="mdi:brain"></span> [LoRA](/大语言模型学习/RL强化学习基础/LoRA及其变体/LoRA/)
- <span class="iconify" data-icon="mdi:brain"></span> [QLoRA](/大语言模型学习/RL强化学习基础/LoRA及其变体/QLoRA/)
- <span class="iconify" data-icon="mdi:brain"></span> [LoRA+](/大语言模型学习/RL强化学习基础/LoRA及其变体/LoRA+/)
- <span class="iconify" data-icon="mdi:brain"></span> [VeRA](/大语言模型学习/RL强化学习基础/LoRA及其变体/VeRA/)
- <span class="iconify" data-icon="mdi:brain"></span> [LoRA-FA](/大语言模型学习/RL强化学习基础/LoRA及其变体/LoRA-FA/)
- <span class="iconify" data-icon="mdi:brain"></span> [AdaLoRA](/大语言模型学习/RL强化学习基础/LoRA及其变体/AdaLoRA/)
- <span class="iconify" data-icon="mdi:brain"></span> [DoRA](/大语言模型学习/RL强化学习基础/LoRA及其变体/DoRA/)
- <span class="iconify" data-icon="mdi:brain"></span> [X-LoRA](/大语言模型学习/RL强化学习基础/LoRA及其变体/X-LoRA/)
- <span class="iconify" data-icon="mdi:brain"></span> [参考文献](/大语言模型学习/RL强化学习基础/LoRA及其变体/参考文献/)

# Common-Models
- <span class="iconify" data-icon="mdi:robot"></span> [发展历史](/大语言模型学习/Common-Models常见模型/发展历史/)
- <span class="iconify" data-icon="mdi:robot"></span> [介绍](/大语言模型学习/Common-Models常见模型/BERT及其变体/介绍/)
- <span class="iconify" data-icon="mdi:robot"></span> [BART](/大语言模型学习/Common-Models常见模型/BERT及其变体/BART/)
- <span class="iconify" data-icon="mdi:robot"></span> [T5](/大语言模型学习/Common-Models常见模型/BERT及其变体/T5/)
- <span class="iconify" data-icon="mdi:robot"></span> [DeBERTa](/大语言模型学习/Common-Models常见模型/BERT及其变体/DeBERTa/)
- <span class="iconify" data-icon="mdi:robot"></span> [RoBERTa](/大语言模型学习/Common-Models常见模型/BERT及其变体/RoBERTa/)
- <span class="iconify" data-icon="mdi:robot"></span> [未命名 1](/大语言模型学习/Common-Models常见模型/BERT及其变体/未命名-1/)
- <span class="iconify" data-icon="mdi:robot"></span> [PLaM](/大语言模型学习/Common-Models常见模型/PLaM系列/PLaM/)
- <span class="iconify" data-icon="mdi:robot"></span> [PLaM2](/大语言模型学习/Common-Models常见模型/PLaM系列/PLaM2/)
- <span class="iconify" data-icon="mdi:robot"></span> [GPT-1](/大语言模型学习/Common-Models常见模型/GPT系列/GPT-1/)
- <span class="iconify" data-icon="mdi:robot"></span> [GPT-2](/大语言模型学习/Common-Models常见模型/GPT系列/GPT-2/)
- <span class="iconify" data-icon="mdi:robot"></span> [GPT-3](/大语言模型学习/Common-Models常见模型/GPT系列/GPT-3/)
- <span class="iconify" data-icon="mdi:robot"></span> [LLaMA1](/大语言模型学习/Common-Models常见模型/LLama系列/LLaMA1/)
- <span class="iconify" data-icon="mdi:robot"></span> [LLama 2](/大语言模型学习/Common-Models常见模型/LLama系列/LLama-2/)
- <span class="iconify" data-icon="mdi:robot"></span> [CodeLlama](/大语言模型学习/Common-Models常见模型/LLama系列/CodeLlama/)
- <span class="iconify" data-icon="mdi:robot"></span> [LLama 3](/大语言模型学习/Common-Models常见模型/LLama系列/LLama-3/)
- <span class="iconify" data-icon="mdi:robot"></span> [GLM1](/大语言模型学习/Common-Models常见模型/GLM系列/GLM1/)
- <span class="iconify" data-icon="mdi:robot"></span> [GLM2](/大语言模型学习/Common-Models常见模型/GLM系列/GLM2/)
- <span class="iconify" data-icon="mdi:robot"></span> [GLM3](/大语言模型学习/Common-Models常见模型/GLM系列/GLM3/)
- <span class="iconify" data-icon="mdi:robot"></span> [GLM4](/大语言模型学习/Common-Models常见模型/GLM系列/GLM4/)
- <span class="iconify" data-icon="mdi:robot"></span> [Qwen1](/大语言模型学习/Common-Models常见模型/Qwen系列/Qwen1/)
- <span class="iconify" data-icon="mdi:robot"></span> [Qwen2](/大语言模型学习/Common-Models常见模型/Qwen系列/Qwen2/)
- <span class="iconify" data-icon="mdi:robot"></span> [Qwen2.5](/大语言模型学习/Common-Models常见模型/Qwen系列/Qwen2.5/)
- <span class="iconify" data-icon="mdi:robot"></span> [Deepseek-V1](/大语言模型学习/Common-Models常见模型/DeepSeek系列/Deepseek-V1/)
- <span class="iconify" data-icon="mdi:robot"></span> [Deepseek-math](/大语言模型学习/Common-Models常见模型/DeepSeek系列/Deepseek-math/)
- <span class="iconify" data-icon="mdi:robot"></span> [DeepSeek-V2](/大语言模型学习/Common-Models常见模型/DeepSeek系列/DeepSeek-V2/)
- <span class="iconify" data-icon="mdi:robot"></span> [DeepSeek-V3](/大语言模型学习/Common-Models常见模型/DeepSeek系列/DeepSeek-V3/)
- <span class="iconify" data-icon="mdi:robot"></span> [DeepSeek-R1](/大语言模型学习/Common-Models常见模型/DeepSeek系列/DeepSeek-R1/)
- <span class="iconify" data-icon="mdi:robot"></span> [GShard](/大语言模型学习/Common-Models常见模型/MOE系列/GShard/)
- <span class="iconify" data-icon="mdi:robot"></span> [Mistral](/大语言模型学习/Common-Models常见模型/MOE系列/Mistral/)
- <span class="iconify" data-icon="mdi:robot"></span> [Switch Transformer](/大语言模型学习/Common-Models常见模型/MOE系列/Switch-Transformer/)

# 训练推理优化
- <span class="iconify" data-icon="mdi:lightning-bolt"></span> [模型显存总体分析](/大语言模型学习/训练推理优化/训练推理显存占用分析/模型显存总体分析/)
- <span class="iconify" data-icon="mdi:lightning-bolt"></span> [训练阶段的显存分析](/大语言模型学习/训练推理优化/训练推理显存占用分析/训练阶段的显存分析/)
- <span class="iconify" data-icon="mdi:lightning-bolt"></span> [显存优化与推理显存分析](/大语言模型学习/训练推理优化/训练推理显存占用分析/显存优化与推理显存分析/)
- <span class="iconify" data-icon="mdi:lightning-bolt"></span> [介绍](/大语言模型学习/训练推理优化/FlashAttention/介绍/)
- <span class="iconify" data-icon="mdi:lightning-bolt"></span> [计算与内存限制](/大语言模型学习/训练推理优化/FlashAttention/计算与内存限制/)
- <span class="iconify" data-icon="mdi:lightning-bolt"></span> [标准Attention与Safe softmax](/大语言模型学习/训练推理优化/FlashAttention/标准Attention与Safe-softmax/)
- <span class="iconify" data-icon="mdi:lightning-bolt"></span> [FlashAttention Forword流程](/大语言模型学习/训练推理优化/FlashAttention/FlashAttention-Forword流程/)
- <span class="iconify" data-icon="mdi:lightning-bolt"></span> [PageAttention原理](/大语言模型学习/训练推理优化/PageAttention原理/)
- <span class="iconify" data-icon="mdi:lightning-bolt"></span> [Megatron-LM](/大语言模型学习/训练推理优化/训练框架/Megatron-LM/)
- <span class="iconify" data-icon="mdi:lightning-bolt"></span> [DeepSpeed](/大语言模型学习/训练推理优化/训练框架/DeepSpeed/)
- <span class="iconify" data-icon="mdi:lightning-bolt"></span> [X-ray](/大语言模型学习/训练推理优化/训练框架/X-ray/)
- <span class="iconify" data-icon="mdi:lightning-bolt"></span> [Accelerate](/大语言模型学习/训练推理优化/训练框架/Accelerate/)
- <span class="iconify" data-icon="mdi:lightning-bolt"></span> [Megatron和DeepSpeed后端实现的区别](/大语言模型学习/训练推理优化/训练框架/Megatron和DeepSpeed后端实现的区别/)
- <span class="iconify" data-icon="mdi:lightning-bolt"></span> [vLLM](/大语言模型学习/训练推理优化/推理框架/vLLM/)
- <span class="iconify" data-icon="mdi:lightning-bolt"></span> [HuggingFace TGI](/大语言模型学习/训练推理优化/推理框架/HuggingFace-TGI/)
- <span class="iconify" data-icon="mdi:lightning-bolt"></span> [推理耗时](/大语言模型学习/训练推理优化/推理耗时及优化/推理耗时/)
- <span class="iconify" data-icon="mdi:lightning-bolt"></span> [首Token时延优化](/大语言模型学习/训练推理优化/推理耗时及优化/首Token时延优化/)
- <span class="iconify" data-icon="mdi:lightning-bolt"></span> [大模型的packing技巧](/大语言模型学习/训练推理优化/大模型的packing技巧/)

# 模型压缩
- <span class="iconify" data-icon="mdi:compress"></span> [介绍](/大语言模型学习/模型压缩/介绍/)
- <span class="iconify" data-icon="mdi:compress"></span> [模型量化](/大语言模型学习/模型压缩/模型量化/)
- <span class="iconify" data-icon="mdi:compress"></span> [模型剪枝](/大语言模型学习/模型压缩/模型剪枝/)
- <span class="iconify" data-icon="mdi:compress"></span> [Knowledge Distillation 知识蒸馏](/大语言模型学习/模型压缩/Knowledge-Distillation-知识蒸馏/)
- <span class="iconify" data-icon="mdi:compress"></span> [Low-Rank Factorization 低秩分解](/大语言模型学习/模型压缩/Low-Rank-Factorization-低秩分解/)

# 大模型应用
- <span class="iconify" data-icon="mdi:application"></span> [Prompt Tech 提示技术](/大语言模型学习/大模型应用/Prompt-Tech-提示技术/)
- <span class="iconify" data-icon="mdi:application"></span> [定义以及历史发展](/大语言模型学习/大模型应用/LLM-based-Agent-基于大模型的智能体/定义以及历史发展/)
- <span class="iconify" data-icon="mdi:application"></span> [基于大模型的智能体原理](/大语言模型学习/大模型应用/LLM-based-Agent-基于大模型的智能体/基于大模型的智能体原理/)
- <span class="iconify" data-icon="mdi:application"></span> [智能体的分类](/大语言模型学习/大模型应用/LLM-based-Agent-基于大模型的智能体/智能体的分类/)
- <span class="iconify" data-icon="mdi:application"></span> [智能体系统分类](/大语言模型学习/大模型应用/LLM-based-Agent-基于大模型的智能体/智能体系统分类/)
- <span class="iconify" data-icon="mdi:application"></span> [智能体的框架和应用](/大语言模型学习/大模型应用/LLM-based-Agent-基于大模型的智能体/智能体的框架和应用/)
- <span class="iconify" data-icon="mdi:application"></span> [Agent评估框架汇总](/大语言模型学习/大模型应用/LLM-based-Agent-基于大模型的智能体/Agent评估框架汇总/)
- <span class="iconify" data-icon="mdi:application"></span> [RAG流程和分类](/大语言模型学习/大模型应用/RAG检索增强生成/RAG流程和分类/)
- <span class="iconify" data-icon="mdi:application"></span> [RAG评估](/大语言模型学习/大模型应用/RAG检索增强生成/RAG评估/)
- <span class="iconify" data-icon="mdi:application"></span> [RAG优化](/大语言模型学习/大模型应用/RAG检索增强生成/RAG优化/)
- <span class="iconify" data-icon="mdi:application"></span> [固定长度分块](/大语言模型学习/大模型应用/RAG检索增强生成/固定长度分块/)
- <span class="iconify" data-icon="mdi:application"></span> [基于语义分块](/大语言模型学习/大模型应用/RAG检索增强生成/基于语义分块/)
- <span class="iconify" data-icon="mdi:application"></span> [基于文档结构分块](/大语言模型学习/大模型应用/RAG检索增强生成/基于文档结构分块/)
- <span class="iconify" data-icon="mdi:application"></span> [基于大模型的分块](/大语言模型学习/大模型应用/RAG检索增强生成/基于大模型的分块/)
- <span class="iconify" data-icon="mdi:application"></span> [RAG优化中查询索引阶段](/大语言模型学习/大模型应用/RAG检索增强生成/RAG优化中查询索引阶段/)
- <span class="iconify" data-icon="mdi:application"></span> [查询索引阶段](/大语言模型学习/大模型应用/RAG检索增强生成/查询索引阶段/)
- <span class="iconify" data-icon="mdi:application"></span> [RAG方向](/大语言模型学习/大模型应用/RAG检索增强生成/RAG方向/)
- <span class="iconify" data-icon="mdi:application"></span> [常见索引优化算法实现](/大语言模型学习/大模型应用/RAG检索增强生成/常见索引优化算法实现/)
