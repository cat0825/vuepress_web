---
dg-publish: true
dg-permalink: /å¤§è¯­è¨€æ¨¡åž‹å­¦ä¹ /RLå¼ºåŒ–å­¦ä¹ åŸºç¡€/LoRAåŠå…¶å˜ä½“/LoRA+
dg-home: false
dg-description: åœ¨æ­¤è¾“å…¥ç¬”è®°çš„æè¿°
dg-hide: false
dg-hide-title: false
dg-show-backlinks: true
dg-show-local-graph: true
dg-show-inline-title: true
dg-pinned: false
dg-passphrase: åœ¨æ­¤è¾“å…¥è®¿é—®å¯†ç 
dg-enable-mathjax: false
dg-enable-mermaid: false
dg-enable-uml: false
dg-note-icon: 0
dg-enable-dataview: false
tags:
  - NLP
permalink: /å¤§è¯­è¨€æ¨¡åž‹å­¦ä¹ /RLå¼ºåŒ–å­¦ä¹ åŸºç¡€/LoRAåŠå…¶å˜ä½“/LoRA+/
dgShowBacklinks: true
dgShowLocalGraph: true
dgShowInlineTitle: true
dgPassFrontmatter: true
noteIcon: 0
created: 2025-04-24T11:15:41.000+08:00
updated: 2025-04-24T11:17:34.000+08:00
title: LoRA+
createTime: 2025/05/13 17:33:52
---



# LoRA+ä¼˜åŒ–å™¨ï¼šé«˜æ•ˆè®­ç»ƒä¸Žå­¦ä¹ çŽ‡è°ƒæ•´

## å…ƒæ•°æ®
- åˆ†ç±»ï¼šæœºå™¨å­¦ä¹ ä¼˜åŒ–
- æ ‡ç­¾ï¼šLoRA, é€‚é…å™¨, å­¦ä¹ çŽ‡, ä¼˜åŒ–å™¨, è®­ç»ƒ
- æ—¥æœŸï¼š2025å¹´4æœˆ12æ—¥


## å†…å®¹æ‘˜è¦
LoRA+æ˜¯ä¸€ç§é’ˆå¯¹LoRAé€‚é…å™¨çš„ä¼˜åŒ–æ–¹æ³•ï¼Œé€šè¿‡ä¸ºçŸ©é˜µAå’ŒBè®¾ç½®ä¸åŒçš„å­¦ä¹ çŽ‡æ¥æé«˜è®­ç»ƒæ•ˆçŽ‡ã€‚æ ¸å¿ƒè§‚ç‚¹æ˜¯ä½¿ç”¨ä¸åŒçš„å­¦ä¹ çŽ‡ç­–ç•¥ï¼Œå…¶ä¸­Bçš„å­¦ä¹ çŽ‡æ˜¯Açš„6å€ã€‚è¿™ç§æ–¹æ³•ä¸ä»…æå‡äº†æ¨¡åž‹çš„é€‚åº”æ€§ï¼Œè¿˜ç®€åŒ–äº†ä¼˜åŒ–è¿‡ç¨‹ã€‚


## æ ¸å¿ƒå†…å®¹
![Pasted-image-20250424111627.png](/img/user/%E9%99%84%E4%BB%B6/Pasted%20image%2020250424111627.png)

### LoRA+ä¼˜åŒ–å™¨åˆ›å»º
LoRA+ä¼˜åŒ–å™¨é€šè¿‡è®¾ç½®ä¸åŒçš„å­¦ä¹ çŽ‡æ¥å®žçŽ°æ›´é«˜æ•ˆçš„è®­ç»ƒã€‚å…·ä½“æ­¥éª¤å¦‚ä¸‹ï¼š

âœ… **å‚æ•°åˆ†ç»„**ï¼š
- å°†æ¨¡åž‹å‚æ•°åˆ†ä¸ºä¸åŒç»„ï¼Œåˆ†åˆ«è®¾ç½®å­¦ä¹ çŽ‡å’Œæƒé‡è¡°å‡ã€‚
- çŸ©é˜µAçš„å­¦ä¹ çŽ‡ä¸º`lr`ï¼ŒçŸ©é˜µBçš„å­¦ä¹ çŽ‡ä¸º`lr * lora_lr_ratio`ã€‚

âš ï¸ **æ³¨æ„äº‹é¡¹**ï¼š
- ç¡®ä¿æƒé‡è¡°å‡è®¾ç½®æ­£ç¡®ï¼Œé¿å…è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºçŽ°è¿‡æ‹Ÿåˆã€‚

```python
optimizer_grouped_parameters = [
    {
        "params": list(parameters["A"].values()),
        "weight_decay": weight_decay,
        "lr": lr,
    },
    {
        "params": list(parameters["embedding"].values()),
        "weight_decay": weight_decay,
        "lr": lora_lr_embedding,
    },
    {
        "params": list(parameters["B"].values()),
        "weight_decay": weight_decay,
        "lr": lr * lora_lr_ratio,
    },
    {
        "params": list(parameters["B_no_decay"].values()),
        "weight_decay": 0.0,
        "lr": lr * lora_lr_ratio,
    },
]
optimizer = optimizer_cls(optimizer_grouped_parameters, **optimizer_kwargs)
```


### è°ƒæ•´Trainerç±»æ–¹æ³•
é‡å†™Trainerç±»çš„`create_optimizer`æ–¹æ³•ä»¥æ”¯æŒLoRA+ä¼˜åŒ–å™¨ï¼š

â— **å®žçŽ°æ­¥éª¤**ï¼š
1. æ£€æŸ¥æ˜¯å¦å¯ç”¨äº†Sagemakerå¤šå¤„ç†ã€‚
2. ä½¿ç”¨`create_lorap_optimizer`æ–¹æ³•åˆ›å»ºä¼˜åŒ–å™¨ã€‚

ðŸ’¡ **å¯å‘ç‚¹**ï¼š
è¿™ç§æ–¹æ³•é€šè¿‡è°ƒæ•´å­¦ä¹ çŽ‡æé«˜äº†è®­ç»ƒæ•ˆçŽ‡ï¼Œå€¼å¾—åœ¨å…¶ä»–é€‚é…å™¨ä¸­å°è¯•ã€‚

```python
class LoraPlusTrainer(Trainer):
    def create_optimizer(self):
        opt_model = self.model_wrapped if is_sagemaker_mp_enabled() else self.model

        if self.optimizer is None:
            optimizer_cls, optimizer_kwargs = Trainer.get_optimizer_cls_and_kwargs(self.args)

            lora_lr_ratio = LORA_LR_RATIO
            lora_lr_embedding = LORA_LR_EMBEDDING

            self.optimizer = create_lorap_optimizer(opt_model, lora_lr_ratio, optimizer_cls, optimizer_kwargs, lora_lr_embedding)
            if is_sagemaker_mp_enabled():
                self.optimizer = smp.DistributedOptimizer(self.optimizer)

        return self.optimizer
```


### å…¬å¼è°ƒæ•´
å…¬å¼æ›´æ–°è¿‡ç¨‹å¦‚ä¸‹ï¼š
$$
A \leftarrow A - \eta \times G_A
$$
$$
B \leftarrow B - \lambda \eta \times G_B, \quad \lambda \gg 1
$$


## å¸¸è§é”™è¯¯
> åœ¨è°ƒæ•´å­¦ä¹ çŽ‡æ—¶ï¼Œç¡®ä¿æ¯”ä¾‹å…³ç³»æ­£ç¡®ï¼Œé¿å…å› è®¾ç½®é”™è¯¯å¯¼è‡´æ¨¡åž‹ä¸æ”¶æ•›ã€‚


## è¡ŒåŠ¨æ¸…å•
- [ ] å®žçŽ°å¹¶æµ‹è¯•LoRA+ä¼˜åŒ–å™¨åœ¨ä¸åŒæ¨¡åž‹ä¸­çš„æ•ˆæžœã€‚
- [ ] è®°å½•è®­ç»ƒè¿‡ç¨‹ä¸­çš„å‚æ•°å˜åŒ–ä»¥éªŒè¯ä¼˜åŒ–æ•ˆæžœã€‚
- [ ] æŽ¢ç´¢å…¶ä»–é€‚é…å™¨ä¸­åº”ç”¨ç±»ä¼¼ç­–ç•¥çš„å¯è¡Œæ€§ã€‚

> åŽŸå§‹å‡ºå¤„ï¼šsimple-lora-plus/tricks/lora_plus.py
