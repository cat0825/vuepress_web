---
{"dg-publish":true,"dg-permalink":"/大语言模型学习/Pre-training-预训练/数据爬取","dg-home":false,"dg-description":"在此输入笔记的描述","dg-hide":false,"dg-hide-title":false,"dg-show-backlinks":true,"dg-show-local-graph":true,"dg-show-inline-title":true,"dg-pinned":false,"dg-passphrase":"在此输入访问密码","dg-enable-mathjax":false,"dg-enable-mermaid":false,"dg-enable-uml":false,"dg-note-icon":0,"dg-enable-dataview":false,"tags":["NLP"],"permalink":"/大语言模型学习/Pre-training-预训练/数据爬取/","dgShowBacklinks":true,"dgShowLocalGraph":true,"dgShowInlineTitle":true,"dgPassFrontmatter":true,"noteIcon":0,"created":"2025-04-08T12:08:34.000+08:00","updated":"2025-04-13T13:06:02.000+08:00"}
---



# 数据爬取与技术实现指南（含爬虫配置与PDF解析方法）
---

## 元数据
**分类**：数据采集与处理  
**标签**：数据爬取、爬虫技术、PDF解析、关键词爬取  
**日期**：2023-10-11  

---


## 核心观点总结
数据爬取是现代信息处理的重要环节，尤其在高质量数据的获取上，针对不同格式的内容（如PDF文件和网页数据）需要采用不同的技术手段。本文探讨了以下几个方面：  

1. PDF格式数据的解析难点及解决方案。  
2. 爬虫的分类及具体实现方式。  
3. 爬虫配置的基本建议与代码示例。  

此外，还提供了针对特定平台（如小红书、抖音、快手、B站）的爬虫ID列表配置，以便更高效地获取目标数据。

---


## 重点内容解析

### ✅ 高质量PDF数据解析方法
- **问题**：许多高质量数据（如论文或书籍）以PDF格式存储，但传统Python库解析效果有限，尤其当PDF中包含公式或表格时。
- **解决方案**：
  1. 使用专业的PDF解析服务，提升解析准确性。
  2. 利用GPT-4等大模型进行解析，但成本可能较高。
  3. 自行训练OCR模型（前提是有足够高质量的PDF与文本对齐数据）。

💡启发点：根据需求选择合适的工具，权衡成本与效果。

---


### ✅ 爬虫分类与实现方式
爬虫主要分为以下三类：
1. **定向网站爬取**：针对特定网站的数据抓取。
2. **基于关键词爬取指定网站**：通过关键词过滤目标内容。
3. **基于搜索引擎爬取**：借助搜索引擎广泛获取相关信息。

⚠ 常见错误：定向爬取时需注意目标网站的反爬机制，合理设置并发数量及请求间隔。

---


### ⚙ 基本配置建议（代码片段）
以下是爬虫配置的关键参数：

```python
# 爬取视频/帖子的数量控制
CRAWLER_MAX_NOTES_COUNT = 200

# 并发爬虫数量控制
MAX_CONCURRENCY_NUM = 2

# 是否开启爬图片模式, 默认不开启
ENABLE_GET_IMAGES = False

# 是否开启爬评论模式, 默认开启
ENABLE_GET_COMMENTS = True

# 爬取一级评论的数量控制(单视频/帖子)
CRAWLER_MAX_COMMENTS_COUNT_SINGLENOTES = 10

# 是否开启爬二级评论模式, 默认不开启
ENABLE_GET_SUB_COMMENTS = False
```

💡启发点：合理设置并发数和内容抓取量，可以避免被目标网站封禁，同时提高数据采集效率。

---


### 📋 指定平台爬虫ID列表示例
以下是针对多个平台的数据爬虫ID列表配置：

| 平台      | ID类型          | 示例ID                                      |
|-----------|-----------------|---------------------------------------------|
| 小红书    | 笔记URL         | https://www.xiaohongshu.com/explore/...    |
| 抖音      | 视频ID          | 7280854932641664319, 7202432992642387233   |
| 快手      | 视频ID          | 3xf8enb8dbj6uig, 3x6zz972bchmvqe           |
| B站       | 视频bvid        | BV1d54y1g7db, BV1Sz4y1U77N, BV14Q4y1n7jz   |

💡启发点：通过指定ID列表，可以精准定位目标内容，减少不必要的数据抓取。

---


## 常见错误警告 ⚠️
- **错误一**：未携带必要参数（如`xsec_token`），导致小红书笔记爬取失败。
- **错误二**：并发数设置过高，引发目标网站封禁。
- **错误三**：未充分考虑目标网站的反爬机制，忽略请求间隔设置。

---


## 思考板块 [思考]
1. 如何在保证成本可控的前提下，提升PDF解析的准确性？  
2. 面对复杂的反爬机制，是否有更智能化的解决方案？  
3. 针对不同平台的数据结构差异，该如何设计通用型爬虫框架？

---

> 原始出处：[GitHub项目链接](https://github.com/NanmiCoder/MediaCrawler)

---


## 行动清单
1. 测试现有爬虫配置参数，优化并发数量设置。  
2. 调研市面上最优的PDF解析服务，进行效果对比。  
3. 针对小红书、抖音等平台，尝试抓取不同类型的数据并分析其结构。  

---


## 📈趋势预测
随着AI技术的发展，未来数据解析将更加智能化。大模型（如GPT系列）可能逐步成为主流工具，但成本控制仍是关键挑战。此外，反爬机制也会愈发复杂，对技术人员提出更高要求。

---


## 后续追踪
- 深入研究OCR模型训练方法，尝试构建自定义模型。  
- 探索更高效的反反爬技术，如动态代理池或模拟用户行为。  
- 对比多种PDF解析工具的性能，撰写评测报告。
