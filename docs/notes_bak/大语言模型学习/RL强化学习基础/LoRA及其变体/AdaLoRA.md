---
dg-publish: true
dg-permalink: /å¤§è¯­è¨€æ¨¡å‹å­¦ä¹ /RLå¼ºåŒ–å­¦ä¹ åŸºç¡€/LoRAåŠå…¶å˜ä½“/AdaLoRA
dg-home: false
dg-description: åœ¨æ­¤è¾“å…¥ç¬”è®°çš„æè¿°
dg-hide: false
dg-hide-title: false
dg-show-backlinks: true
dg-show-local-graph: true
dg-show-inline-title: true
dg-pinned: false
dg-passphrase: åœ¨æ­¤è¾“å…¥è®¿é—®å¯†ç 
dg-enable-mathjax: false
dg-enable-mermaid: false
dg-enable-uml: false
dg-note-icon: 0
dg-enable-dataview: false
tags:
  - NLP
permalink: /å¤§è¯­è¨€æ¨¡å‹å­¦ä¹ /RLå¼ºåŒ–å­¦ä¹ åŸºç¡€/LoRAåŠå…¶å˜ä½“/AdaLoRA/
dgShowBacklinks: true
dgShowLocalGraph: true
dgShowInlineTitle: true
dgPassFrontmatter: true
noteIcon: 0
created: 2025-04-24T11:18:17.739+08:00
updated: 2025-04-24T11:18:43.096+08:00
title: AdaLoRA
createTime: 2025/05/13 17:33:52
---



# AdaLoRA: åŠ¨æ€é€‚é…ä½ç§©åˆ†è§£çš„åˆ›æ–°æŠ€æœ¯

## å…ƒæ•°æ®
åˆ†ç±»ï¼šè‡ªåŠ¨æ¨æ–­

æ ‡ç­¾ï¼šåŠ¨æ€é€‚é…ã€ä½ç§©åˆ†è§£ã€å¥‡å¼‚å€¼ã€æ·±åº¦å­¦ä¹ ã€AdaLoRA

æ—¥æœŸï¼š2025å¹´4æœˆ12æ—¥


## æ ¸å¿ƒè§‚ç‚¹
AdaLoRAæ˜¯ä¸€ç§åˆ›æ–°çš„æ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼Œå®ƒé€šè¿‡åŠ¨æ€è°ƒæ•´ä¸åŒå±‚å’Œå‚æ•°ç±»å‹çš„ç§©ï¼Œæ ¹æ®ä¸‹æ¸¸ä»»åŠ¡éœ€æ±‚è¿›è¡Œä¼˜åŒ–ã€‚è¿™ç§æ–¹æ³•é‡‡ç”¨åŸºäºSVDï¼ˆå¥‡å¼‚å€¼åˆ†è§£ï¼‰çš„å‚æ•°åŒ–å½¢å¼ï¼Œå¯ä»¥æœ‰æ•ˆè£å‰ªä¸é‡è¦çš„å¥‡å¼‚å€¼ï¼Œé™ä½è®¡ç®—å¤æ‚åº¦ã€‚
![Pasted-image-20250424111842.png](../../.vuepress/public/img/user/%E9%99%84%E4%BB%B6/Pasted%20image%2020250424111842.png)
ğŸ’¡å¯å‘ç‚¹ï¼šé€šè¿‡åŠ¨æ€åˆ†é…ç§©å’Œä½¿ç”¨SVDå‚æ•°åŒ–ï¼ŒAdaLoRAå®ç°äº†è®¡ç®—æ•ˆç‡ä¸æ€§èƒ½ä¼˜åŒ–çš„å¹³è¡¡ã€‚


## é‡ç‚¹æ®µè½

### åŠ¨æ€ç§©åˆ†é…
AdaLoRAä¸ä»…ä¸ºæ¯ä¸ªAdapteråˆ†é…ç›¸åŒçš„ç§©ï¼Œè€Œæ˜¯æ ¹æ®ä»»åŠ¡éœ€æ±‚åŠ¨æ€è°ƒæ•´å„å±‚å’Œå‚æ•°ç±»å‹çš„ç§©ã€‚è¿™ç§çµæ´»æ€§ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´åŠ é«˜æ•ˆåœ°å¤„ç†ä¸åŒçš„ä»»åŠ¡ã€‚


### SVDå‚æ•°åŒ–å¢é‡æ›´æ–°
é‡‡ç”¨SVDå½¢å¼å‚æ•°åŒ–å¢é‡æ›´æ–°ï¼Œèƒ½å¤Ÿåœ¨è§„é¿å¤æ‚è®¡ç®—çš„åŒæ—¶é«˜æ•ˆè£å‰ªä¸é‡è¦çš„å¥‡å¼‚å€¼ã€‚è¿™ç§æ–¹æ³•å¤§å¤§é™ä½äº†è®¡ç®—é‡ï¼Œå¹¶æé«˜äº†æ¨¡å‹çš„é€‚åº”èƒ½åŠ›ã€‚


### æ ¸å¿ƒä»£ç è§£æ
```python
class AdaLoraLayer(LoraLayer):
    def update_layer(self, adapter_name, r, lora_alpha, lora_dropout, init_lora_weights):
        self.lora_A[adapter_name] = nn.Parameter(torch.randn(r, self.in_features))
        # Singular values
        self.lora_E[adapter_name] = nn.Parameter(torch.randn(r, 1))
        # Left singular vectors
        self.lora_B[adapter_name] = nn.Parameter(torch.randn(self.out_features, r))
        # The current rank
        self.ranknum[adapter_name] = nn.Parameter(torch.randn(1), requires_grad=False)
        self.ranknum[adapter_name].data.fill_(float(r))
        self.ranknum[adapter_name].requires_grad = False
        self.scaling[adapter_name] = lora_alpha if lora_alpha > 0 else float(r)
```


## æ“ä½œæ­¥éª¤
1. âœ… åˆå§‹åŒ–å‚æ•°çŸ©é˜µå¹¶åˆ†é…ç§©ã€‚
2. âš  ä½¿ç”¨SVDè¿›è¡Œå¥‡å¼‚å€¼è£å‰ªã€‚
3. â— æ ¹æ®ä»»åŠ¡éœ€æ±‚åŠ¨æ€è°ƒæ•´é€‚é…å™¨æƒé‡ã€‚


## å¸¸è§é”™è¯¯
> âš  åœ¨è°ƒæ•´ç§©æ—¶ï¼Œå¯èƒ½ä¼šå¿½ç•¥ç‰¹å®šä»»åŠ¡å¯¹å‚æ•°çš„ç‰¹æ®Šéœ€æ±‚ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸‹é™ã€‚


## è¡ŒåŠ¨æ¸…å•
- ç ”ç©¶AdaLoRAåœ¨ä¸åŒä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚
- æ¢ç´¢å…¶ä»–åŸºäºSVDçš„ä¼˜åŒ–æŠ€æœ¯ã€‚
- å®éªŒä¸åŒå‚æ•°è®¾ç½®å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚


## æ•°æ®è½¬æ¢
| å‚æ•° | æè¿° |
|------|------|
| r    | å½“å‰ç§© |
| lora_alpha | è°ƒæ•´å› å­ |


## å…¬å¼æ˜¾ç¤º
ä½¿ç”¨å…¬å¼è¡¨ç¤ºå¥‡å¼‚å€¼ä¸ç§©å…³ç³»ï¼š
$$ \text{ranknum} = \alpha \cdot \text{scaling} $$

> åŸå§‹å†…å®¹æ¥è‡ªPEFT/src/peft/tuners/adalora/layer.pyã€‚
