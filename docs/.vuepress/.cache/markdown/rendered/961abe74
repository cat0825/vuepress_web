{"content":"<h2 id=\"元数据\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#元数据\"><span>元数据</span></a></h2>\n<ul>\n<li>分类：深度学习优化</li>\n<li>标签：DoRA，LoRA，权重分解，深度学习</li>\n<li>日期：2025年4月12日</li>\n</ul>\n<h2 id=\"核心观点\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心观点\"><span>核心观点</span></a></h2>\n<p>DoRA是一种用于深度学习模型的优化技术，通过将预训练的权重矩阵拆分为大小向量和方向矩阵两部分，分别进行训练和处理，以提升模型性能。</p>\n<h2 id=\"重点段落\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#重点段落\"><span>重点段落</span></a></h2>\n<h3 id=\"dora的基本步骤\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#dora的基本步骤\"><span>DoRA的基本步骤</span></a></h3>\n<ol>\n<li><strong>权重矩阵拆分</strong>：将预训练的权重矩阵分解为两个部分——大小向量（<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>m</mi></mrow><annotation encoding=\"application/x-tex\">m</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">m</span></span></span></span>）和方向矩阵（<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span>）。</li>\n<li><strong>应用LoRA处理</strong>：对方向矩阵<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span>应用LoRA技术，同时单独训练大小向量<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>m</mi></mrow><annotation encoding=\"application/x-tex\">m</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">m</span></span></span></span>。</li>\n</ol>\n<h3 id=\"代码示例\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#代码示例\"><span>代码示例</span></a></h3>\n<p>以下是DoRA优化技术的核心代码实现：</p>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code><span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">class</span><span style=\"--shiki-light:#2E8F82;--shiki-dark:#5DA994\"> LinearWithDoRAMerged</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">Module</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\"> __init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> linear</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> rank</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> alpha</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">        super</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">().</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">__init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">linear </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> linear</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">lora </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> LoRALayer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">linear</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">in_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> linear</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">out_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> rank</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> alpha</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">m </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Parameter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">linear</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">weight</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">norm</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">p</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">2</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">0</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> keepdim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">True</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">))</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\"> forward</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> x</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        lora </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">lora</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">A </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">@</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">lora</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">B</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        numerator </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">linear</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">weight </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">+</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">lora</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">alpha </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">*</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> lora</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">T</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        denominator </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> numerator</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">norm</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">p</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">2</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">0</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> keepdim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">True</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        directional_component </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> numerator </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">/</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> denominator</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        new_weight </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">m </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">*</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> directional_component</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">        return</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> F</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">linear</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">x</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> new_weight</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">linear</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">bias</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h3 id=\"操作步骤\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#操作步骤\"><span>操作步骤</span></a></h3>\n<p>✅ <strong>步骤1</strong>：将预训练的权重矩阵拆分为大小向量<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>m</mi></mrow><annotation encoding=\"application/x-tex\">m</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">m</span></span></span></span>和方向矩阵<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span>。</p>\n<p>⚠ <strong>步骤2</strong>：对方向矩阵<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span>应用LoRA处理。</p>\n<p>❗ <strong>步骤3</strong>：单独训练大小向量<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>m</mi></mrow><annotation encoding=\"application/x-tex\">m</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">m</span></span></span></span>以优化模型性能。</p>\n<h2 id=\"常见错误\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#常见错误\"><span>常见错误</span></a></h2>\n<blockquote>\n<p>⚠ <strong>警告</strong>：在应用LoRA处理时，确保方向矩阵的维度与输入输出特征匹配，否则可能导致计算错误。</p>\n</blockquote>\n<h2 id=\"💡启发点\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#💡启发点\"><span>💡启发点</span></a></h2>\n<p>DoRA通过分解权重矩阵，提供了一种新的优化思路，可以在不显著增加计算复杂度的情况下提升模型性能。</p>\n<h2 id=\"行动清单\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#行动清单\"><span>行动清单</span></a></h2>\n<ul class=\"task-list-container\">\n<li class=\"task-list-item\"><input type=\"checkbox\" class=\"task-list-item-checkbox\" id=\"task-item-0\" disabled=\"disabled\"><label class=\"task-list-item-label\" for=\"task-item-0\"> 实施DoRA技术于现有模型以观察性能提升。</label></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" class=\"task-list-item-checkbox\" id=\"task-item-1\" disabled=\"disabled\"><label class=\"task-list-item-label\" for=\"task-item-1\"> 探索其他可能的权重分解方法。</label></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" class=\"task-list-item-checkbox\" id=\"task-item-2\" disabled=\"disabled\"><label class=\"task-list-item-label\" for=\"task-item-2\"> 结合其他优化技术，如剪枝或量化，进一步提高效率。</label></li>\n</ul>\n<blockquote>\n<p>原始出处：[PEFT/src/peft/tuners/lora/dora.py]</p>\n</blockquote>\n","env":{"base":"/","filePath":"/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/LoRA及其变体/DoRA.md","filePathRelative":"notes_bak/大语言模型学习/RL强化学习基础/LoRA及其变体/DoRA.md","frontmatter":{"dg-publish":true,"dg-permalink":"/大语言模型学习/RL强化学习基础/LoRA及其变体/DoRA","dg-home":false,"dg-description":"在此输入笔记的描述","dg-hide":false,"dg-hide-title":false,"dg-show-backlinks":true,"dg-show-local-graph":true,"dg-show-inline-title":true,"dg-pinned":false,"dg-passphrase":"在此输入访问密码","dg-enable-mathjax":false,"dg-enable-mermaid":false,"dg-enable-uml":false,"dg-note-icon":0,"dg-enable-dataview":false,"tags":["NLP"],"permalink":"/大语言模型学习/RL强化学习基础/LoRA及其变体/DoRA/","dgShowBacklinks":true,"dgShowLocalGraph":true,"dgShowInlineTitle":true,"dgPassFrontmatter":true,"noteIcon":0,"created":"2025-04-24T03:18:55.737Z","updated":"2025-04-24T03:19:04.342Z","title":"DoRA","createTime":"2025/05/13 17:33:52"},"sfcBlocks":{"template":{"type":"template","content":"<template><h2 id=\"元数据\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#元数据\"><span>元数据</span></a></h2>\n<ul>\n<li>分类：深度学习优化</li>\n<li>标签：DoRA，LoRA，权重分解，深度学习</li>\n<li>日期：2025年4月12日</li>\n</ul>\n<h2 id=\"核心观点\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心观点\"><span>核心观点</span></a></h2>\n<p>DoRA是一种用于深度学习模型的优化技术，通过将预训练的权重矩阵拆分为大小向量和方向矩阵两部分，分别进行训练和处理，以提升模型性能。</p>\n<h2 id=\"重点段落\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#重点段落\"><span>重点段落</span></a></h2>\n<h3 id=\"dora的基本步骤\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#dora的基本步骤\"><span>DoRA的基本步骤</span></a></h3>\n<ol>\n<li><strong>权重矩阵拆分</strong>：将预训练的权重矩阵分解为两个部分——大小向量（<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>m</mi></mrow><annotation encoding=\"application/x-tex\">m</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">m</span></span></span></span>）和方向矩阵（<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span>）。</li>\n<li><strong>应用LoRA处理</strong>：对方向矩阵<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span>应用LoRA技术，同时单独训练大小向量<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>m</mi></mrow><annotation encoding=\"application/x-tex\">m</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">m</span></span></span></span>。</li>\n</ol>\n<h3 id=\"代码示例\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#代码示例\"><span>代码示例</span></a></h3>\n<p>以下是DoRA优化技术的核心代码实现：</p>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code><span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">class</span><span style=\"--shiki-light:#2E8F82;--shiki-dark:#5DA994\"> LinearWithDoRAMerged</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">Module</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\"> __init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> linear</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> rank</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> alpha</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">        super</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">().</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">__init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">linear </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> linear</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">lora </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> LoRALayer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">linear</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">in_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> linear</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">out_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> rank</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> alpha</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">m </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Parameter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">linear</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">weight</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">norm</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">p</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">2</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">0</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> keepdim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">True</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">))</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\"> forward</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> x</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        lora </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">lora</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">A </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">@</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">lora</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">B</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        numerator </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">linear</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">weight </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">+</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">lora</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">alpha </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">*</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> lora</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">T</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        denominator </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> numerator</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">norm</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">p</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">2</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">0</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> keepdim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">True</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        directional_component </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> numerator </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">/</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> denominator</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        new_weight </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">m </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">*</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> directional_component</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">        return</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> F</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">linear</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">x</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> new_weight</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">linear</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">bias</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h3 id=\"操作步骤\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#操作步骤\"><span>操作步骤</span></a></h3>\n<p>✅ <strong>步骤1</strong>：将预训练的权重矩阵拆分为大小向量<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>m</mi></mrow><annotation encoding=\"application/x-tex\">m</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">m</span></span></span></span>和方向矩阵<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span>。</p>\n<p>⚠ <strong>步骤2</strong>：对方向矩阵<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span>应用LoRA处理。</p>\n<p>❗ <strong>步骤3</strong>：单独训练大小向量<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>m</mi></mrow><annotation encoding=\"application/x-tex\">m</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">m</span></span></span></span>以优化模型性能。</p>\n<h2 id=\"常见错误\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#常见错误\"><span>常见错误</span></a></h2>\n<blockquote>\n<p>⚠ <strong>警告</strong>：在应用LoRA处理时，确保方向矩阵的维度与输入输出特征匹配，否则可能导致计算错误。</p>\n</blockquote>\n<h2 id=\"💡启发点\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#💡启发点\"><span>💡启发点</span></a></h2>\n<p>DoRA通过分解权重矩阵，提供了一种新的优化思路，可以在不显著增加计算复杂度的情况下提升模型性能。</p>\n<h2 id=\"行动清单\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#行动清单\"><span>行动清单</span></a></h2>\n<ul class=\"task-list-container\">\n<li class=\"task-list-item\"><input type=\"checkbox\" class=\"task-list-item-checkbox\" id=\"task-item-0\" disabled=\"disabled\"><label class=\"task-list-item-label\" for=\"task-item-0\"> 实施DoRA技术于现有模型以观察性能提升。</label></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" class=\"task-list-item-checkbox\" id=\"task-item-1\" disabled=\"disabled\"><label class=\"task-list-item-label\" for=\"task-item-1\"> 探索其他可能的权重分解方法。</label></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" class=\"task-list-item-checkbox\" id=\"task-item-2\" disabled=\"disabled\"><label class=\"task-list-item-label\" for=\"task-item-2\"> 结合其他优化技术，如剪枝或量化，进一步提高效率。</label></li>\n</ul>\n<blockquote>\n<p>原始出处：[PEFT/src/peft/tuners/lora/dora.py]</p>\n</blockquote>\n</template>","contentStripped":"<h2 id=\"元数据\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#元数据\"><span>元数据</span></a></h2>\n<ul>\n<li>分类：深度学习优化</li>\n<li>标签：DoRA，LoRA，权重分解，深度学习</li>\n<li>日期：2025年4月12日</li>\n</ul>\n<h2 id=\"核心观点\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心观点\"><span>核心观点</span></a></h2>\n<p>DoRA是一种用于深度学习模型的优化技术，通过将预训练的权重矩阵拆分为大小向量和方向矩阵两部分，分别进行训练和处理，以提升模型性能。</p>\n<h2 id=\"重点段落\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#重点段落\"><span>重点段落</span></a></h2>\n<h3 id=\"dora的基本步骤\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#dora的基本步骤\"><span>DoRA的基本步骤</span></a></h3>\n<ol>\n<li><strong>权重矩阵拆分</strong>：将预训练的权重矩阵分解为两个部分——大小向量（<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>m</mi></mrow><annotation encoding=\"application/x-tex\">m</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">m</span></span></span></span>）和方向矩阵（<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span>）。</li>\n<li><strong>应用LoRA处理</strong>：对方向矩阵<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span>应用LoRA技术，同时单独训练大小向量<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>m</mi></mrow><annotation encoding=\"application/x-tex\">m</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">m</span></span></span></span>。</li>\n</ol>\n<h3 id=\"代码示例\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#代码示例\"><span>代码示例</span></a></h3>\n<p>以下是DoRA优化技术的核心代码实现：</p>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code><span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">class</span><span style=\"--shiki-light:#2E8F82;--shiki-dark:#5DA994\"> LinearWithDoRAMerged</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">Module</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\"> __init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> linear</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> rank</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> alpha</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">        super</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">().</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">__init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">linear </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> linear</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">lora </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> LoRALayer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">linear</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">in_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> linear</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">out_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> rank</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> alpha</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">m </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Parameter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">linear</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">weight</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">norm</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">p</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">2</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">0</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> keepdim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">True</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">))</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\"> forward</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> x</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        lora </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">lora</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">A </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">@</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">lora</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">B</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        numerator </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">linear</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">weight </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">+</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">lora</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">alpha </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">*</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> lora</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">T</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        denominator </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> numerator</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">norm</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">p</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">2</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">0</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> keepdim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">True</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        directional_component </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> numerator </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">/</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> denominator</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        new_weight </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">m </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">*</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> directional_component</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">        return</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> F</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">linear</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">x</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> new_weight</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">linear</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">bias</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h3 id=\"操作步骤\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#操作步骤\"><span>操作步骤</span></a></h3>\n<p>✅ <strong>步骤1</strong>：将预训练的权重矩阵拆分为大小向量<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>m</mi></mrow><annotation encoding=\"application/x-tex\">m</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">m</span></span></span></span>和方向矩阵<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span>。</p>\n<p>⚠ <strong>步骤2</strong>：对方向矩阵<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span>应用LoRA处理。</p>\n<p>❗ <strong>步骤3</strong>：单独训练大小向量<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>m</mi></mrow><annotation encoding=\"application/x-tex\">m</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">m</span></span></span></span>以优化模型性能。</p>\n<h2 id=\"常见错误\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#常见错误\"><span>常见错误</span></a></h2>\n<blockquote>\n<p>⚠ <strong>警告</strong>：在应用LoRA处理时，确保方向矩阵的维度与输入输出特征匹配，否则可能导致计算错误。</p>\n</blockquote>\n<h2 id=\"💡启发点\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#💡启发点\"><span>💡启发点</span></a></h2>\n<p>DoRA通过分解权重矩阵，提供了一种新的优化思路，可以在不显著增加计算复杂度的情况下提升模型性能。</p>\n<h2 id=\"行动清单\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#行动清单\"><span>行动清单</span></a></h2>\n<ul class=\"task-list-container\">\n<li class=\"task-list-item\"><input type=\"checkbox\" class=\"task-list-item-checkbox\" id=\"task-item-0\" disabled=\"disabled\"><label class=\"task-list-item-label\" for=\"task-item-0\"> 实施DoRA技术于现有模型以观察性能提升。</label></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" class=\"task-list-item-checkbox\" id=\"task-item-1\" disabled=\"disabled\"><label class=\"task-list-item-label\" for=\"task-item-1\"> 探索其他可能的权重分解方法。</label></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" class=\"task-list-item-checkbox\" id=\"task-item-2\" disabled=\"disabled\"><label class=\"task-list-item-label\" for=\"task-item-2\"> 结合其他优化技术，如剪枝或量化，进一步提高效率。</label></li>\n</ul>\n<blockquote>\n<p>原始出处：[PEFT/src/peft/tuners/lora/dora.py]</p>\n</blockquote>\n","tagOpen":"<template>","tagClose":"</template>"},"script":null,"scriptSetup":null,"scripts":[],"styles":[],"customBlocks":[]},"content":"\n## 元数据\n- 分类：深度学习优化\n- 标签：DoRA，LoRA，权重分解，深度学习\n- 日期：2025年4月12日\n\n\n## 核心观点\nDoRA是一种用于深度学习模型的优化技术，通过将预训练的权重矩阵拆分为大小向量和方向矩阵两部分，分别进行训练和处理，以提升模型性能。\n\n\n## 重点段落\n\n### DoRA的基本步骤\n1. **权重矩阵拆分**：将预训练的权重矩阵分解为两个部分——大小向量（$m$）和方向矩阵（$V$）。\n2. **应用LoRA处理**：对方向矩阵$V$应用LoRA技术，同时单独训练大小向量$m$。\n\n\n### 代码示例\n以下是DoRA优化技术的核心代码实现：\n\n```python\nclass LinearWithDoRAMerged(nn.Module):\n    def __init__(self, linear, rank, alpha):\n        super().__init__()\n        self.linear = linear\n        self.lora = LoRALayer(linear.in_features, linear.out_features, rank, alpha)\n        self.m = nn.Parameter(self.linear.weight.norm(p=2, dim=0, keepdim=True))\n\n    def forward(self, x):\n        lora = self.lora.A @ self.lora.B\n        numerator = self.linear.weight + self.lora.alpha * lora.T\n        denominator = numerator.norm(p=2, dim=0, keepdim=True)\n        directional_component = numerator / denominator\n        new_weight = self.m * directional_component\n        return F.linear(x, new_weight, self.linear.bias)\n```\n\n\n### 操作步骤\n✅ **步骤1**：将预训练的权重矩阵拆分为大小向量$m$和方向矩阵$V$。\n\n⚠ **步骤2**：对方向矩阵$V$应用LoRA处理。\n\n❗ **步骤3**：单独训练大小向量$m$以优化模型性能。\n\n\n## 常见错误\n> ⚠ **警告**：在应用LoRA处理时，确保方向矩阵的维度与输入输出特征匹配，否则可能导致计算错误。\n\n\n## 💡启发点\nDoRA通过分解权重矩阵，提供了一种新的优化思路，可以在不显著增加计算复杂度的情况下提升模型性能。\n\n\n## 行动清单\n- [ ] 实施DoRA技术于现有模型以观察性能提升。\n- [ ] 探索其他可能的权重分解方法。\n- [ ] 结合其他优化技术，如剪枝或量化，进一步提高效率。\n\n> 原始出处：[PEFT/src/peft/tuners/lora/dora.py]","excerpt":"","includedFiles":[],"tasklistId":3,"title":"","headers":[{"level":2,"title":"元数据","slug":"元数据","link":"#元数据","children":[]},{"level":2,"title":"核心观点","slug":"核心观点","link":"#核心观点","children":[]},{"level":2,"title":"重点段落","slug":"重点段落","link":"#重点段落","children":[{"level":3,"title":"DoRA的基本步骤","slug":"dora的基本步骤","link":"#dora的基本步骤","children":[]},{"level":3,"title":"代码示例","slug":"代码示例","link":"#代码示例","children":[]},{"level":3,"title":"操作步骤","slug":"操作步骤","link":"#操作步骤","children":[]}]},{"level":2,"title":"常见错误","slug":"常见错误","link":"#常见错误","children":[]},{"level":2,"title":"💡启发点","slug":"💡启发点","link":"#💡启发点","children":[]},{"level":2,"title":"行动清单","slug":"行动清单","link":"#行动清单","children":[]}]}}
