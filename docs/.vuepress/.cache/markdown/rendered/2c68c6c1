{"content":"<p><strong>分类</strong>：人工智能</p>\n<p><strong>标签</strong>：QWEN2、模型优化、预训练、数据合成</p>\n<p><strong>日期</strong>：2025年4月12日</p>\n<h2 id=\"模型结构与创新\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#模型结构与创新\"><span>模型结构与创新</span></a></h2>\n<p>QWEN2模型在其架构上进行了多项优化，与之前的Qwen版本相比，显著提升了性能。主要的创新包括：</p>\n<ul>\n<li><strong>GQA与YaRN+双块注意力（Dual Chunk Attention, DCA）</strong>：这些技术用于提高模型对长文本的处理能力。</li>\n<li><strong>位置编码优化</strong>：在1.5章节中详细描述了YARN技术的应用。</li>\n<li><strong>词表与编码器</strong>：采用BBPE编码器，词表大小为151643，以提高语言理解能力。</li>\n</ul>\n<h2 id=\"模型训练与数据处理\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#模型训练与数据处理\"><span>模型训练与数据处理</span></a></h2>\n<p>QWEN2的训练过程涉及多个关键步骤，以确保模型的高效性和准确性：</p>\n<h3 id=\"预训练阶段\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#预训练阶段\"><span>预训练阶段</span></a></h3>\n<ol>\n<li><strong>质量提升</strong>：通过改进过滤算法，使用Qwen模型过滤低质量数据。</li>\n<li><strong>数据扩展</strong>：收集了更大容量的高质量代码、数学和多语言数据，支持约30种语言。</li>\n<li><strong>分布改进</strong>：在小规模模型上实验以优化数据混合。</li>\n</ol>\n<h3 id=\"后训练数据合成\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#后训练数据合成\"><span>后训练数据合成</span></a></h3>\n<ol>\n<li><strong>拒绝采样</strong>：用于数学任务，以提高解决方案质量。</li>\n<li><strong>执行反馈</strong>：在编码任务中，通过编译和执行生成的解决方案来评估其有效性。</li>\n<li><strong>数据再利用</strong>：使用高质量公共领域文学作品开发指令。</li>\n</ol>\n<h2 id=\"训练过程的阶段划分\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#训练过程的阶段划分\"><span>训练过程的阶段划分</span></a></h2>\n<p>QWEN2的训练过程分为两个阶段：</p>\n<ul>\n<li><strong>离线训练阶段</strong>：使用预先收集的偏好数据集进行DPO训练。</li>\n<li><strong>在线训练阶段</strong>：利用即时反馈的奖励模型不断改进性能。</li>\n</ul>\n<h2 id=\"常见错误警告\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#常见错误警告\"><span>常见错误警告</span></a></h2>\n<blockquote>\n<p>⚠️ 在执行数据合成时，确保准确判断偏好数据与非偏好数据，以免影响模型表现。</p>\n</blockquote>\n<h2 id=\"行动清单\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#行动清单\"><span>行动清单</span></a></h2>\n<ul>\n<li>继续优化数据过滤算法，以进一步提高预训练数据质量。</li>\n<li>扩展多语言支持，增加更多语言的数据集。</li>\n<li>在小规模实验中测试新的数据混合策略。</li>\n</ul>\n<h2 id=\"💡-启发点\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#💡-启发点\"><span>💡 启发点</span></a></h2>\n<p>QWEN2通过多种技术手段提升模型对长文本和多语言的处理能力，特别是在数据合成和执行反馈方面的创新，为未来的模型训练提供了新的思路。</p>\n<blockquote>\n<p>原始出处：[QWEN2 TECHNICAL REPORT]</p>\n</blockquote>\n","env":{"base":"/","filePath":"/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Common Models常见模型/Qwen系列/Qwen2.md","filePathRelative":"notes_bak/大语言模型学习/Common Models常见模型/Qwen系列/Qwen2.md","frontmatter":{"dg-publish":true,"dg-permalink":"/大语言模型学习/Common-Models常见模型/Qwen系列/Qwen2","dg-home":false,"dg-description":"在此输入笔记的描述","dg-hide":false,"dg-hide-title":false,"dg-show-backlinks":true,"dg-show-local-graph":true,"dg-show-inline-title":true,"dg-pinned":false,"dg-passphrase":"在此输入访问密码","dg-enable-mathjax":false,"dg-enable-mermaid":false,"dg-enable-uml":false,"dg-note-icon":0,"dg-enable-dataview":false,"tags":["NLP"],"permalink":"/大语言模型学习/Common-Models常见模型/Qwen系列/Qwen2/","dgShowBacklinks":true,"dgShowLocalGraph":true,"dgShowInlineTitle":true,"dgPassFrontmatter":true,"noteIcon":0,"created":"2025-04-25T03:16:19.000Z","updated":"2025-04-25T03:16:36.000Z","title":"Qwen2","createTime":"2025/05/13 17:33:53"},"sfcBlocks":{"template":{"type":"template","content":"<template><p><strong>分类</strong>：人工智能</p>\n<p><strong>标签</strong>：QWEN2、模型优化、预训练、数据合成</p>\n<p><strong>日期</strong>：2025年4月12日</p>\n<h2 id=\"模型结构与创新\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#模型结构与创新\"><span>模型结构与创新</span></a></h2>\n<p>QWEN2模型在其架构上进行了多项优化，与之前的Qwen版本相比，显著提升了性能。主要的创新包括：</p>\n<ul>\n<li><strong>GQA与YaRN+双块注意力（Dual Chunk Attention, DCA）</strong>：这些技术用于提高模型对长文本的处理能力。</li>\n<li><strong>位置编码优化</strong>：在1.5章节中详细描述了YARN技术的应用。</li>\n<li><strong>词表与编码器</strong>：采用BBPE编码器，词表大小为151643，以提高语言理解能力。</li>\n</ul>\n<h2 id=\"模型训练与数据处理\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#模型训练与数据处理\"><span>模型训练与数据处理</span></a></h2>\n<p>QWEN2的训练过程涉及多个关键步骤，以确保模型的高效性和准确性：</p>\n<h3 id=\"预训练阶段\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#预训练阶段\"><span>预训练阶段</span></a></h3>\n<ol>\n<li><strong>质量提升</strong>：通过改进过滤算法，使用Qwen模型过滤低质量数据。</li>\n<li><strong>数据扩展</strong>：收集了更大容量的高质量代码、数学和多语言数据，支持约30种语言。</li>\n<li><strong>分布改进</strong>：在小规模模型上实验以优化数据混合。</li>\n</ol>\n<h3 id=\"后训练数据合成\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#后训练数据合成\"><span>后训练数据合成</span></a></h3>\n<ol>\n<li><strong>拒绝采样</strong>：用于数学任务，以提高解决方案质量。</li>\n<li><strong>执行反馈</strong>：在编码任务中，通过编译和执行生成的解决方案来评估其有效性。</li>\n<li><strong>数据再利用</strong>：使用高质量公共领域文学作品开发指令。</li>\n</ol>\n<h2 id=\"训练过程的阶段划分\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#训练过程的阶段划分\"><span>训练过程的阶段划分</span></a></h2>\n<p>QWEN2的训练过程分为两个阶段：</p>\n<ul>\n<li><strong>离线训练阶段</strong>：使用预先收集的偏好数据集进行DPO训练。</li>\n<li><strong>在线训练阶段</strong>：利用即时反馈的奖励模型不断改进性能。</li>\n</ul>\n<h2 id=\"常见错误警告\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#常见错误警告\"><span>常见错误警告</span></a></h2>\n<blockquote>\n<p>⚠️ 在执行数据合成时，确保准确判断偏好数据与非偏好数据，以免影响模型表现。</p>\n</blockquote>\n<h2 id=\"行动清单\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#行动清单\"><span>行动清单</span></a></h2>\n<ul>\n<li>继续优化数据过滤算法，以进一步提高预训练数据质量。</li>\n<li>扩展多语言支持，增加更多语言的数据集。</li>\n<li>在小规模实验中测试新的数据混合策略。</li>\n</ul>\n<h2 id=\"💡-启发点\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#💡-启发点\"><span>💡 启发点</span></a></h2>\n<p>QWEN2通过多种技术手段提升模型对长文本和多语言的处理能力，特别是在数据合成和执行反馈方面的创新，为未来的模型训练提供了新的思路。</p>\n<blockquote>\n<p>原始出处：[QWEN2 TECHNICAL REPORT]</p>\n</blockquote>\n</template>","contentStripped":"<p><strong>分类</strong>：人工智能</p>\n<p><strong>标签</strong>：QWEN2、模型优化、预训练、数据合成</p>\n<p><strong>日期</strong>：2025年4月12日</p>\n<h2 id=\"模型结构与创新\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#模型结构与创新\"><span>模型结构与创新</span></a></h2>\n<p>QWEN2模型在其架构上进行了多项优化，与之前的Qwen版本相比，显著提升了性能。主要的创新包括：</p>\n<ul>\n<li><strong>GQA与YaRN+双块注意力（Dual Chunk Attention, DCA）</strong>：这些技术用于提高模型对长文本的处理能力。</li>\n<li><strong>位置编码优化</strong>：在1.5章节中详细描述了YARN技术的应用。</li>\n<li><strong>词表与编码器</strong>：采用BBPE编码器，词表大小为151643，以提高语言理解能力。</li>\n</ul>\n<h2 id=\"模型训练与数据处理\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#模型训练与数据处理\"><span>模型训练与数据处理</span></a></h2>\n<p>QWEN2的训练过程涉及多个关键步骤，以确保模型的高效性和准确性：</p>\n<h3 id=\"预训练阶段\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#预训练阶段\"><span>预训练阶段</span></a></h3>\n<ol>\n<li><strong>质量提升</strong>：通过改进过滤算法，使用Qwen模型过滤低质量数据。</li>\n<li><strong>数据扩展</strong>：收集了更大容量的高质量代码、数学和多语言数据，支持约30种语言。</li>\n<li><strong>分布改进</strong>：在小规模模型上实验以优化数据混合。</li>\n</ol>\n<h3 id=\"后训练数据合成\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#后训练数据合成\"><span>后训练数据合成</span></a></h3>\n<ol>\n<li><strong>拒绝采样</strong>：用于数学任务，以提高解决方案质量。</li>\n<li><strong>执行反馈</strong>：在编码任务中，通过编译和执行生成的解决方案来评估其有效性。</li>\n<li><strong>数据再利用</strong>：使用高质量公共领域文学作品开发指令。</li>\n</ol>\n<h2 id=\"训练过程的阶段划分\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#训练过程的阶段划分\"><span>训练过程的阶段划分</span></a></h2>\n<p>QWEN2的训练过程分为两个阶段：</p>\n<ul>\n<li><strong>离线训练阶段</strong>：使用预先收集的偏好数据集进行DPO训练。</li>\n<li><strong>在线训练阶段</strong>：利用即时反馈的奖励模型不断改进性能。</li>\n</ul>\n<h2 id=\"常见错误警告\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#常见错误警告\"><span>常见错误警告</span></a></h2>\n<blockquote>\n<p>⚠️ 在执行数据合成时，确保准确判断偏好数据与非偏好数据，以免影响模型表现。</p>\n</blockquote>\n<h2 id=\"行动清单\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#行动清单\"><span>行动清单</span></a></h2>\n<ul>\n<li>继续优化数据过滤算法，以进一步提高预训练数据质量。</li>\n<li>扩展多语言支持，增加更多语言的数据集。</li>\n<li>在小规模实验中测试新的数据混合策略。</li>\n</ul>\n<h2 id=\"💡-启发点\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#💡-启发点\"><span>💡 启发点</span></a></h2>\n<p>QWEN2通过多种技术手段提升模型对长文本和多语言的处理能力，特别是在数据合成和执行反馈方面的创新，为未来的模型训练提供了新的思路。</p>\n<blockquote>\n<p>原始出处：[QWEN2 TECHNICAL REPORT]</p>\n</blockquote>\n","tagOpen":"<template>","tagClose":"</template>"},"script":null,"scriptSetup":null,"scripts":[],"styles":[],"customBlocks":[]},"content":"**分类**：人工智能\n\n**标签**：QWEN2、模型优化、预训练、数据合成\n\n**日期**：2025年4月12日\n\n## 模型结构与创新\nQWEN2模型在其架构上进行了多项优化，与之前的Qwen版本相比，显著提升了性能。主要的创新包括：\n\n- **GQA与YaRN+双块注意力（Dual Chunk Attention, DCA）**：这些技术用于提高模型对长文本的处理能力。\n- **位置编码优化**：在1.5章节中详细描述了YARN技术的应用。\n- **词表与编码器**：采用BBPE编码器，词表大小为151643，以提高语言理解能力。\n\n\n## 模型训练与数据处理\nQWEN2的训练过程涉及多个关键步骤，以确保模型的高效性和准确性：\n\n### 预训练阶段\n1. **质量提升**：通过改进过滤算法，使用Qwen模型过滤低质量数据。\n2. **数据扩展**：收集了更大容量的高质量代码、数学和多语言数据，支持约30种语言。\n3. **分布改进**：在小规模模型上实验以优化数据混合。\n\n\n### 后训练数据合成\n1. **拒绝采样**：用于数学任务，以提高解决方案质量。\n2. **执行反馈**：在编码任务中，通过编译和执行生成的解决方案来评估其有效性。\n3. **数据再利用**：使用高质量公共领域文学作品开发指令。\n\n\n## 训练过程的阶段划分\nQWEN2的训练过程分为两个阶段：\n\n- **离线训练阶段**：使用预先收集的偏好数据集进行DPO训练。\n- **在线训练阶段**：利用即时反馈的奖励模型不断改进性能。\n\n\n## 常见错误警告\n> ⚠️ 在执行数据合成时，确保准确判断偏好数据与非偏好数据，以免影响模型表现。\n\n\n## 行动清单\n- 继续优化数据过滤算法，以进一步提高预训练数据质量。\n- 扩展多语言支持，增加更多语言的数据集。\n- 在小规模实验中测试新的数据混合策略。\n\n\n## 💡 启发点\nQWEN2通过多种技术手段提升模型对长文本和多语言的处理能力，特别是在数据合成和执行反馈方面的创新，为未来的模型训练提供了新的思路。\n\n> 原始出处：[QWEN2 TECHNICAL REPORT]","excerpt":"","includedFiles":[],"tasklistId":0,"title":"","headers":[{"level":2,"title":"模型结构与创新","slug":"模型结构与创新","link":"#模型结构与创新","children":[]},{"level":2,"title":"模型训练与数据处理","slug":"模型训练与数据处理","link":"#模型训练与数据处理","children":[{"level":3,"title":"预训练阶段","slug":"预训练阶段","link":"#预训练阶段","children":[]},{"level":3,"title":"后训练数据合成","slug":"后训练数据合成","link":"#后训练数据合成","children":[]}]},{"level":2,"title":"训练过程的阶段划分","slug":"训练过程的阶段划分","link":"#训练过程的阶段划分","children":[]},{"level":2,"title":"常见错误警告","slug":"常见错误警告","link":"#常见错误警告","children":[]},{"level":2,"title":"行动清单","slug":"行动清单","link":"#行动清单","children":[]},{"level":2,"title":"💡 启发点","slug":"💡-启发点","link":"#💡-启发点","children":[]}]}}
