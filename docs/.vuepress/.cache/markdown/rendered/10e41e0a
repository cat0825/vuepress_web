{"content":"<h2 id=\"什么是基于语义分块\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#什么是基于语义分块\"><span>什么是基于语义分块？</span></a></h2>\n<p>基于语义分块是一种利用自然语言处理方法，根据语义或句子边界对文本进行切分的技术。这种方法通过在句子结尾或标点处分块，或者通过模型预测段落边界，将文档分段为有意义的单元（如句子、段落或主题部分）。其目标是尽量保证每个分块的语义独立完整。\n<img src=\"/img/user/附件/Pasted image 20250506215357.png\" alt=\"Pasted image 20250506215357.png\">\n<img src=\"/img/user/附件/Pasted image 20250506215404.png\" alt=\"Pasted image 20250506215404.png\"></p>\n<h3 id=\"做法\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#做法\"><span>做法</span></a></h3>\n<ol>\n<li><strong>语义切分</strong>：在句子结尾、标点处或通过模型预测段落边界进行分块。</li>\n<li><strong>创建 Embedding</strong>：为每个分段创建 embedding（嵌入向量）。</li>\n<li><strong>相似度计算</strong>：比较相邻分段的 embedding。如果两个分段的余弦相似度较高，则将它们合并为一个分块。</li>\n<li><strong>新片段开始</strong>：当余弦相似度显著下降时，开始一个新的片段，并重复上述步骤。</li>\n</ol>\n<h3 id=\"优势\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#优势\"><span>优势</span></a></h3>\n<ul>\n<li><strong>上下文相关性</strong>：每个分块的语义完整性更高，有助于上下文理解。</li>\n<li><strong>灵活性</strong>：适用于不同语言和文本类型。</li>\n<li><strong>提高检索准确性</strong>：内容更丰富，能够帮助语言模型（LLM）生成更连贯、更相关的回应。</li>\n</ul>\n<h3 id=\"局限性\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#局限性\"><span>局限性</span></a></h3>\n<ul>\n<li><strong>复杂性</strong>：实现过程较为复杂。</li>\n<li><strong>处理时间长</strong>：由于需要计算余弦相似度和多次迭代，处理速度较慢。</li>\n<li><strong>计算成本高</strong>：需要更多的计算资源。</li>\n<li><strong>阈值调整</strong>：余弦相似度的阈值可能因文档而异，需要手动调整。</li>\n</ul>\n<hr>\n<h2 id=\"nltk-的文本切分功能\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#nltk-的文本切分功能\"><span>NLTK 的文本切分功能</span></a></h2>\n<p>NLTK（Natural Language Toolkit）是一个广泛使用的 Python 自然语言处理库，提供了丰富的文本处理功能。其 <code v-pre>sent_tokenize</code> 方法可以自动将文本切分为句子。</p>\n<h3 id=\"原理\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#原理\"><span>原理</span></a></h3>\n<p><code v-pre>sent_tokenize</code> 方法基于论文《Unsupervised Multilingual Sentence Boundary Detection》的研究成果，使用无监督算法为缩写词、搭配词和句子开头的词建立模型，然后利用这些模型识别句子边界。这种方法在多种语言（主要是欧洲语言）上都取得了良好效果。</p>\n<h3 id=\"中文支持现状\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#中文支持现状\"><span>中文支持现状</span></a></h3>\n<ol>\n<li><strong>预训练模型缺失</strong>：NLTK 官方并未提供中文分句模型的预训练权重，因此需要用户自行训练。</li>\n<li><strong>训练接口可用</strong>：NLTK 提供了训练接口，用户可以基于自己的中文语料库训练分句模型。</li>\n</ol>\n<hr>\n<h2 id=\"在-langchain-中的应用\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#在-langchain-中的应用\"><span>在 LangChain 中的应用</span></a></h2>\n<p>LangChain 集成了 NLTK 的文本切分功能，用户可以直接调用这些功能来实现文本切分。以下是一个示例代码：</p>\n<h3 id=\"使用示例\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#使用示例\"><span>使用示例</span></a></h3>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code><span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">from</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> langchain</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">text_splitter </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">import</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> NLTKTextSplitter</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">text_splitter </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> NLTKTextSplitter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">text </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\"> \"</span><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">...</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"</span><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">  # 待处理的文本</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">texts </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> text_splitter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">split_text</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">text</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">for</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> doc </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">in</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> texts</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">:</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">    print</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">doc</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><hr>\n<h2 id=\"扩展-基于-spacy-的文本切块\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#扩展-基于-spacy-的文本切块\"><span>扩展：基于 spaCy 的文本切块</span></a></h2>\n<p>spaCy 是另一款强大的自然语言处理库，具备更高级的语言分析能力。LangChain 同样集成了 spaCy 的文本切分方法。</p>\n<h3 id=\"使用方法\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#使用方法\"><span>使用方法</span></a></h3>\n<p>只需将 <code v-pre>NLTKTextSplitter</code> 替换为 <code v-pre>SpacyTextSplitter</code> 即可：</p>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code><span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">from</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> langchain</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">text_splitter </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">import</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> SpacyTextSplitter</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">text_splitter </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> SpacyTextSplitter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">text </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\"> \"</span><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">...</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"</span><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">  # 待处理的文本</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">texts </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> text_splitter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">split_text</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">text</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">for</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> doc </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">in</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> texts</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">:</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">    print</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">doc</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h3 id=\"提示\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#提示\"><span>提示</span></a></h3>\n<p>使用 spaCy 时，需要先下载对应语言的模型。例如，对于中文处理，可以下载 spaCy 的中文语言模型。</p>\n<hr>\n","env":{"base":"/","filePath":"/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/大模型应用/RAG检索增强生成/基于语义分块.md","filePathRelative":"notes_bak/大语言模型学习/大模型应用/RAG检索增强生成/基于语义分块.md","frontmatter":{"dg-publish":true,"dg-permalink":"/大语言模型学习/大模型应用/RAG检索增强生成/基于语义分块","dg-home":false,"dg-description":"在此输入笔记的描述","dg-hide":false,"dg-hide-title":false,"dg-show-backlinks":true,"dg-show-local-graph":true,"dg-show-inline-title":true,"dg-pinned":false,"dg-passphrase":"在此输入访问密码","dg-enable-mathjax":false,"dg-enable-mermaid":false,"dg-enable-uml":false,"dg-note-icon":0,"dg-enable-dataview":false,"tags":["NLP"],"permalink":"/大语言模型学习/大模型应用/RAG检索增强生成/基于语义分块/","dgShowBacklinks":true,"dgShowLocalGraph":true,"dgShowInlineTitle":true,"dgPassFrontmatter":true,"noteIcon":0,"created":"2025-05-06T13:52:41.000Z","updated":"2025-05-07T07:21:33.000Z","title":"基于语义分块","createTime":"2025/05/13 17:33:52"},"sfcBlocks":{"template":{"type":"template","content":"<template><h2 id=\"什么是基于语义分块\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#什么是基于语义分块\"><span>什么是基于语义分块？</span></a></h2>\n<p>基于语义分块是一种利用自然语言处理方法，根据语义或句子边界对文本进行切分的技术。这种方法通过在句子结尾或标点处分块，或者通过模型预测段落边界，将文档分段为有意义的单元（如句子、段落或主题部分）。其目标是尽量保证每个分块的语义独立完整。\n<img src=\"/img/user/附件/Pasted image 20250506215357.png\" alt=\"Pasted image 20250506215357.png\">\n<img src=\"/img/user/附件/Pasted image 20250506215404.png\" alt=\"Pasted image 20250506215404.png\"></p>\n<h3 id=\"做法\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#做法\"><span>做法</span></a></h3>\n<ol>\n<li><strong>语义切分</strong>：在句子结尾、标点处或通过模型预测段落边界进行分块。</li>\n<li><strong>创建 Embedding</strong>：为每个分段创建 embedding（嵌入向量）。</li>\n<li><strong>相似度计算</strong>：比较相邻分段的 embedding。如果两个分段的余弦相似度较高，则将它们合并为一个分块。</li>\n<li><strong>新片段开始</strong>：当余弦相似度显著下降时，开始一个新的片段，并重复上述步骤。</li>\n</ol>\n<h3 id=\"优势\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#优势\"><span>优势</span></a></h3>\n<ul>\n<li><strong>上下文相关性</strong>：每个分块的语义完整性更高，有助于上下文理解。</li>\n<li><strong>灵活性</strong>：适用于不同语言和文本类型。</li>\n<li><strong>提高检索准确性</strong>：内容更丰富，能够帮助语言模型（LLM）生成更连贯、更相关的回应。</li>\n</ul>\n<h3 id=\"局限性\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#局限性\"><span>局限性</span></a></h3>\n<ul>\n<li><strong>复杂性</strong>：实现过程较为复杂。</li>\n<li><strong>处理时间长</strong>：由于需要计算余弦相似度和多次迭代，处理速度较慢。</li>\n<li><strong>计算成本高</strong>：需要更多的计算资源。</li>\n<li><strong>阈值调整</strong>：余弦相似度的阈值可能因文档而异，需要手动调整。</li>\n</ul>\n<hr>\n<h2 id=\"nltk-的文本切分功能\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#nltk-的文本切分功能\"><span>NLTK 的文本切分功能</span></a></h2>\n<p>NLTK（Natural Language Toolkit）是一个广泛使用的 Python 自然语言处理库，提供了丰富的文本处理功能。其 <code v-pre>sent_tokenize</code> 方法可以自动将文本切分为句子。</p>\n<h3 id=\"原理\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#原理\"><span>原理</span></a></h3>\n<p><code v-pre>sent_tokenize</code> 方法基于论文《Unsupervised Multilingual Sentence Boundary Detection》的研究成果，使用无监督算法为缩写词、搭配词和句子开头的词建立模型，然后利用这些模型识别句子边界。这种方法在多种语言（主要是欧洲语言）上都取得了良好效果。</p>\n<h3 id=\"中文支持现状\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#中文支持现状\"><span>中文支持现状</span></a></h3>\n<ol>\n<li><strong>预训练模型缺失</strong>：NLTK 官方并未提供中文分句模型的预训练权重，因此需要用户自行训练。</li>\n<li><strong>训练接口可用</strong>：NLTK 提供了训练接口，用户可以基于自己的中文语料库训练分句模型。</li>\n</ol>\n<hr>\n<h2 id=\"在-langchain-中的应用\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#在-langchain-中的应用\"><span>在 LangChain 中的应用</span></a></h2>\n<p>LangChain 集成了 NLTK 的文本切分功能，用户可以直接调用这些功能来实现文本切分。以下是一个示例代码：</p>\n<h3 id=\"使用示例\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#使用示例\"><span>使用示例</span></a></h3>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code><span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">from</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> langchain</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">text_splitter </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">import</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> NLTKTextSplitter</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">text_splitter </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> NLTKTextSplitter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">text </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\"> \"</span><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">...</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"</span><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">  # 待处理的文本</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">texts </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> text_splitter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">split_text</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">text</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">for</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> doc </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">in</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> texts</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">:</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">    print</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">doc</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><hr>\n<h2 id=\"扩展-基于-spacy-的文本切块\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#扩展-基于-spacy-的文本切块\"><span>扩展：基于 spaCy 的文本切块</span></a></h2>\n<p>spaCy 是另一款强大的自然语言处理库，具备更高级的语言分析能力。LangChain 同样集成了 spaCy 的文本切分方法。</p>\n<h3 id=\"使用方法\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#使用方法\"><span>使用方法</span></a></h3>\n<p>只需将 <code v-pre>NLTKTextSplitter</code> 替换为 <code v-pre>SpacyTextSplitter</code> 即可：</p>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code><span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">from</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> langchain</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">text_splitter </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">import</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> SpacyTextSplitter</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">text_splitter </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> SpacyTextSplitter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">text </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\"> \"</span><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">...</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"</span><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">  # 待处理的文本</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">texts </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> text_splitter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">split_text</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">text</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">for</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> doc </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">in</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> texts</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">:</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">    print</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">doc</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h3 id=\"提示\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#提示\"><span>提示</span></a></h3>\n<p>使用 spaCy 时，需要先下载对应语言的模型。例如，对于中文处理，可以下载 spaCy 的中文语言模型。</p>\n<hr>\n</template>","contentStripped":"<h2 id=\"什么是基于语义分块\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#什么是基于语义分块\"><span>什么是基于语义分块？</span></a></h2>\n<p>基于语义分块是一种利用自然语言处理方法，根据语义或句子边界对文本进行切分的技术。这种方法通过在句子结尾或标点处分块，或者通过模型预测段落边界，将文档分段为有意义的单元（如句子、段落或主题部分）。其目标是尽量保证每个分块的语义独立完整。\n<img src=\"/img/user/附件/Pasted image 20250506215357.png\" alt=\"Pasted image 20250506215357.png\">\n<img src=\"/img/user/附件/Pasted image 20250506215404.png\" alt=\"Pasted image 20250506215404.png\"></p>\n<h3 id=\"做法\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#做法\"><span>做法</span></a></h3>\n<ol>\n<li><strong>语义切分</strong>：在句子结尾、标点处或通过模型预测段落边界进行分块。</li>\n<li><strong>创建 Embedding</strong>：为每个分段创建 embedding（嵌入向量）。</li>\n<li><strong>相似度计算</strong>：比较相邻分段的 embedding。如果两个分段的余弦相似度较高，则将它们合并为一个分块。</li>\n<li><strong>新片段开始</strong>：当余弦相似度显著下降时，开始一个新的片段，并重复上述步骤。</li>\n</ol>\n<h3 id=\"优势\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#优势\"><span>优势</span></a></h3>\n<ul>\n<li><strong>上下文相关性</strong>：每个分块的语义完整性更高，有助于上下文理解。</li>\n<li><strong>灵活性</strong>：适用于不同语言和文本类型。</li>\n<li><strong>提高检索准确性</strong>：内容更丰富，能够帮助语言模型（LLM）生成更连贯、更相关的回应。</li>\n</ul>\n<h3 id=\"局限性\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#局限性\"><span>局限性</span></a></h3>\n<ul>\n<li><strong>复杂性</strong>：实现过程较为复杂。</li>\n<li><strong>处理时间长</strong>：由于需要计算余弦相似度和多次迭代，处理速度较慢。</li>\n<li><strong>计算成本高</strong>：需要更多的计算资源。</li>\n<li><strong>阈值调整</strong>：余弦相似度的阈值可能因文档而异，需要手动调整。</li>\n</ul>\n<hr>\n<h2 id=\"nltk-的文本切分功能\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#nltk-的文本切分功能\"><span>NLTK 的文本切分功能</span></a></h2>\n<p>NLTK（Natural Language Toolkit）是一个广泛使用的 Python 自然语言处理库，提供了丰富的文本处理功能。其 <code v-pre>sent_tokenize</code> 方法可以自动将文本切分为句子。</p>\n<h3 id=\"原理\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#原理\"><span>原理</span></a></h3>\n<p><code v-pre>sent_tokenize</code> 方法基于论文《Unsupervised Multilingual Sentence Boundary Detection》的研究成果，使用无监督算法为缩写词、搭配词和句子开头的词建立模型，然后利用这些模型识别句子边界。这种方法在多种语言（主要是欧洲语言）上都取得了良好效果。</p>\n<h3 id=\"中文支持现状\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#中文支持现状\"><span>中文支持现状</span></a></h3>\n<ol>\n<li><strong>预训练模型缺失</strong>：NLTK 官方并未提供中文分句模型的预训练权重，因此需要用户自行训练。</li>\n<li><strong>训练接口可用</strong>：NLTK 提供了训练接口，用户可以基于自己的中文语料库训练分句模型。</li>\n</ol>\n<hr>\n<h2 id=\"在-langchain-中的应用\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#在-langchain-中的应用\"><span>在 LangChain 中的应用</span></a></h2>\n<p>LangChain 集成了 NLTK 的文本切分功能，用户可以直接调用这些功能来实现文本切分。以下是一个示例代码：</p>\n<h3 id=\"使用示例\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#使用示例\"><span>使用示例</span></a></h3>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code><span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">from</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> langchain</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">text_splitter </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">import</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> NLTKTextSplitter</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">text_splitter </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> NLTKTextSplitter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">text </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\"> \"</span><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">...</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"</span><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">  # 待处理的文本</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">texts </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> text_splitter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">split_text</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">text</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">for</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> doc </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">in</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> texts</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">:</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">    print</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">doc</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><hr>\n<h2 id=\"扩展-基于-spacy-的文本切块\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#扩展-基于-spacy-的文本切块\"><span>扩展：基于 spaCy 的文本切块</span></a></h2>\n<p>spaCy 是另一款强大的自然语言处理库，具备更高级的语言分析能力。LangChain 同样集成了 spaCy 的文本切分方法。</p>\n<h3 id=\"使用方法\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#使用方法\"><span>使用方法</span></a></h3>\n<p>只需将 <code v-pre>NLTKTextSplitter</code> 替换为 <code v-pre>SpacyTextSplitter</code> 即可：</p>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code><span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">from</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> langchain</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">text_splitter </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">import</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> SpacyTextSplitter</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">text_splitter </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> SpacyTextSplitter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">text </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\"> \"</span><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">...</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"</span><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">  # 待处理的文本</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">texts </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> text_splitter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">split_text</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">text</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">for</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> doc </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">in</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> texts</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">:</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">    print</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">doc</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h3 id=\"提示\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#提示\"><span>提示</span></a></h3>\n<p>使用 spaCy 时，需要先下载对应语言的模型。例如，对于中文处理，可以下载 spaCy 的中文语言模型。</p>\n<hr>\n","tagOpen":"<template>","tagClose":"</template>"},"script":null,"scriptSetup":null,"scripts":[],"styles":[],"customBlocks":[]},"content":"\n## 什么是基于语义分块？\n基于语义分块是一种利用自然语言处理方法，根据语义或句子边界对文本进行切分的技术。这种方法通过在句子结尾或标点处分块，或者通过模型预测段落边界，将文档分段为有意义的单元（如句子、段落或主题部分）。其目标是尽量保证每个分块的语义独立完整。\n![Pasted image 20250506215357.png](/img/user/%E9%99%84%E4%BB%B6/Pasted%20image%2020250506215357.png)\n![Pasted image 20250506215404.png](/img/user/%E9%99%84%E4%BB%B6/Pasted%20image%2020250506215404.png)\n\n### 做法\n1. **语义切分**：在句子结尾、标点处或通过模型预测段落边界进行分块。\n2. **创建 Embedding**：为每个分段创建 embedding（嵌入向量）。\n3. **相似度计算**：比较相邻分段的 embedding。如果两个分段的余弦相似度较高，则将它们合并为一个分块。\n4. **新片段开始**：当余弦相似度显著下降时，开始一个新的片段，并重复上述步骤。\n\n\n### 优势\n- **上下文相关性**：每个分块的语义完整性更高，有助于上下文理解。\n- **灵活性**：适用于不同语言和文本类型。\n- **提高检索准确性**：内容更丰富，能够帮助语言模型（LLM）生成更连贯、更相关的回应。\n\n\n### 局限性\n- **复杂性**：实现过程较为复杂。\n- **处理时间长**：由于需要计算余弦相似度和多次迭代，处理速度较慢。\n- **计算成本高**：需要更多的计算资源。\n- **阈值调整**：余弦相似度的阈值可能因文档而异，需要手动调整。\n\n---\n\n\n## NLTK 的文本切分功能\nNLTK（Natural Language Toolkit）是一个广泛使用的 Python 自然语言处理库，提供了丰富的文本处理功能。其 `sent_tokenize` 方法可以自动将文本切分为句子。\n\n### 原理\n`sent_tokenize` 方法基于论文《Unsupervised Multilingual Sentence Boundary Detection》的研究成果，使用无监督算法为缩写词、搭配词和句子开头的词建立模型，然后利用这些模型识别句子边界。这种方法在多种语言（主要是欧洲语言）上都取得了良好效果。\n\n\n### 中文支持现状\n1. **预训练模型缺失**：NLTK 官方并未提供中文分句模型的预训练权重，因此需要用户自行训练。\n2. **训练接口可用**：NLTK 提供了训练接口，用户可以基于自己的中文语料库训练分句模型。\n\n---\n\n\n## 在 LangChain 中的应用\nLangChain 集成了 NLTK 的文本切分功能，用户可以直接调用这些功能来实现文本切分。以下是一个示例代码：\n\n### 使用示例\n```python\nfrom langchain.text_splitter import NLTKTextSplitter\n\ntext_splitter = NLTKTextSplitter()\n\ntext = \"...\"  # 待处理的文本\n\ntexts = text_splitter.split_text(text)\n\nfor doc in texts:\n    print(doc)\n```\n\n---\n\n\n## 扩展：基于 spaCy 的文本切块\nspaCy 是另一款强大的自然语言处理库，具备更高级的语言分析能力。LangChain 同样集成了 spaCy 的文本切分方法。\n\n### 使用方法\n只需将 `NLTKTextSplitter` 替换为 `SpacyTextSplitter` 即可：\n\n```python\nfrom langchain.text_splitter import SpacyTextSplitter\n\ntext_splitter = SpacyTextSplitter()\n\ntext = \"...\"  # 待处理的文本\n\ntexts = text_splitter.split_text(text)\n\nfor doc in texts:\n    print(doc)\n```\n\n\n### 提示\n使用 spaCy 时，需要先下载对应语言的模型。例如，对于中文处理，可以下载 spaCy 的中文语言模型。\n\n---","excerpt":"","includedFiles":[],"tasklistId":0,"title":"","headers":[{"level":2,"title":"什么是基于语义分块？","slug":"什么是基于语义分块","link":"#什么是基于语义分块","children":[{"level":3,"title":"做法","slug":"做法","link":"#做法","children":[]},{"level":3,"title":"优势","slug":"优势","link":"#优势","children":[]},{"level":3,"title":"局限性","slug":"局限性","link":"#局限性","children":[]}]},{"level":2,"title":"NLTK 的文本切分功能","slug":"nltk-的文本切分功能","link":"#nltk-的文本切分功能","children":[{"level":3,"title":"原理","slug":"原理","link":"#原理","children":[]},{"level":3,"title":"中文支持现状","slug":"中文支持现状","link":"#中文支持现状","children":[]}]},{"level":2,"title":"在 LangChain 中的应用","slug":"在-langchain-中的应用","link":"#在-langchain-中的应用","children":[{"level":3,"title":"使用示例","slug":"使用示例","link":"#使用示例","children":[]}]},{"level":2,"title":"扩展：基于 spaCy 的文本切块","slug":"扩展-基于-spacy-的文本切块","link":"#扩展-基于-spacy-的文本切块","children":[{"level":3,"title":"使用方法","slug":"使用方法","link":"#使用方法","children":[]},{"level":3,"title":"提示","slug":"提示","link":"#提示","children":[]}]}]}}
