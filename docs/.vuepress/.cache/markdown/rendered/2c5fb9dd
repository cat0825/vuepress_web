{"content":"<hr>\n<p><strong>元数据：</strong><br>\n<strong>分类：</strong> 自然语言处理<br>\n<strong>标签：</strong> 语言模型、采样方法、AI生成技术<br>\n<strong>日期：</strong> 2025年4月1日</p>\n<hr>\n<h2 id=\"什么是语言模型采样方法\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#什么是语言模型采样方法\"><span>什么是语言模型采样方法？</span></a></h2>\n<p>在生成式语言模型中，采样方法决定了输出文本的多样性和质量。这些方法通过调整模型选择词语的概率分布，来平衡生成内容的随机性与稳定性。以下是几种主流采样技术的核心概念及应用场景。</p>\n<hr>\n<h2 id=\"top-k-sampling\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#top-k-sampling\"><span>Top-K Sampling</span></a></h2>\n<h3 id=\"核心概念\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心概念\"><span>核心概念：</span></a></h3>\n<p>Top-K Sampling 是一种从排名靠前的 k 个词中随机选择的方法。它允许高概率词语有更大的被选中机会，同时保留一定的随机性。这种方式可以提升生成质量，但也可能在以下两种情况下出现问题：</p>\n<ol>\n<li><strong>分布尖锐时</strong>：可能导致生成内容不连贯或胡言乱语。</li>\n<li><strong>分布平坦时</strong>：限制了模型的创造力。\n<img src=\"/img/user/附件/Pasted image 20250407180356.png\" alt=\"Pasted image 20250407180356.png\"></li>\n</ol>\n<hr>\n<h2 id=\"top-p-sampling\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#top-p-sampling\"><span>Top-P Sampling</span></a></h2>\n<h3 id=\"核心概念-1\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心概念-1\"><span>核心概念：</span></a></h3>\n<p>Top-P Sampling（又称核采样）通过累积概率设定一个阈值 $$P$$，从满足该阈值的最小词集合中随机采样。这种方式动态调整候选词集合大小，更适合应对概率分布变化较大的场景。</p>\n<h3 id=\"代码实现\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#代码实现\"><span>代码实现：</span></a></h3>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code><span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">masked_probs </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">gather</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">probs</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">-</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> index</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">sorted_indices</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[:,</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> :</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">cutoff_idx </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">+</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">])</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># 重新归一化剩余概率</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">masked_probs </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> masked_probs </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">/</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> masked_probs</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">sum</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">-</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> keepdim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">True</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># 从候选词中随机选择一个词</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">selected_idx </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">multinomial</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">masked_probs</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">return</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> sorted_indices</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">gather</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">-</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> selected_idx</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p><img src=\"/img/user/附件/Pasted image 20250407180404.png\" alt=\"Pasted image 20250407180404.png\"></p>\n<hr>\n<h2 id=\"temperature-sampling\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#temperature-sampling\"><span>Temperature Sampling</span></a></h2>\n<h3 id=\"核心概念-2\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心概念-2\"><span>核心概念：</span></a></h3>\n<p>通过调整 Softmax 的温度系数来影响输出词的概率分布：</p>\n<ul>\n<li><strong>温度高</strong>（如 $$T &gt; 1$$）：概率分布更平坦，生成更随机。</li>\n<li><strong>温度低</strong>（如 $$T &lt; 1$$）：概率分布更集中，生成更稳定。</li>\n</ul>\n<p>这种方法适用于需要控制生成文本风格和随机程度的场景。</p>\n<hr>\n<h2 id=\"综合采样策略-kpt\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#综合采样策略-kpt\"><span>综合采样策略：KPT</span></a></h2>\n<h3 id=\"核心概念-3\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心概念-3\"><span>核心概念：</span></a></h3>\n<p>KPT 是一种结合 Top-K、Top-P 和 Temperature 的综合方法，逐步进行采样以提升生成效果。通过多层筛选，KPT 能在保持随机性的同时提高生成质量。</p>\n<hr>\n<h2 id=\"多答案选择策略\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#多答案选择策略\"><span>多答案选择策略</span></a></h2>\n<h3 id=\"best-of-n\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#best-of-n\"><span>Best-of-N</span></a></h3>\n<p>让模型生成 N 个回答，通过评分机制（如 Verifier 或 PRM）选择得分最高的答案作为最终结果。\n<img src=\"/img/user/附件/Pasted image 20250407180419.png\" alt=\"Pasted image 20250407180419.png\"></p>\n<h3 id=\"majority-vote\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#majority-vote\"><span>Majority Vote</span></a></h3>\n<p>让模型输出多个答案，以一致性最多的答案作为最终结果。</p>\n<h3 id=\"self-consistency\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#self-consistency\"><span>Self-consistency</span></a></h3>\n<p>通过生成多个推理路径，再用多数投票选出最合理的答案。这种方法在复杂推理任务中表现尤为突出。</p>\n<hr>\n<h2 id=\"常见错误-⚠️\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#常见错误-⚠️\"><span>常见错误 ⚠️</span></a></h2>\n<ol>\n<li><strong>参数设置不当</strong>：\n<ul>\n<li>K 值过小可能导致生成内容单一。</li>\n<li>P 值过大可能引入低质量候选词。</li>\n<li>温度过高可能使输出过于随机。</li>\n</ul>\n</li>\n<li><strong>忽略采样方法组合</strong>：单一方法可能难以应对复杂场景，需结合多种策略。</li>\n</ol>\n<hr>\n<h2 id=\"💡启发点\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#💡启发点\"><span>💡启发点</span></a></h2>\n<ul>\n<li><strong>动态调整采样参数</strong>：根据任务需求实时调整 K、P 和温度值。</li>\n<li><strong>结合多答案选择策略</strong>：提升复杂任务的推理准确性。</li>\n</ul>\n<hr>\n<h2 id=\"📈趋势预测\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#📈趋势预测\"><span>📈趋势预测</span></a></h2>\n<ol>\n<li><strong>自动化参数优化</strong>：未来可能出现基于任务自动调整采样参数的技术。</li>\n<li><strong>强化学习结合采样策略</strong>：通过奖励机制优化生成质量。</li>\n</ol>\n<hr>\n<h2 id=\"行动清单\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#行动清单\"><span>行动清单</span></a></h2>\n<ol>\n<li>实现不同采样方法的代码，并测试其在文本生成中的效果。</li>\n<li>探索 KPT 综合采样策略对生成质量的提升。</li>\n<li>应用 Self-consistency 方法于复杂推理任务。</li>\n</ol>\n<hr>\n<h2 id=\"思考-延伸问题\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#思考-延伸问题\"><span>[思考]延伸问题</span></a></h2>\n<ol>\n<li>如何设计动态调整 K 和 P 的算法，使其适应不同场景？</li>\n<li>是否可以结合语义理解优化采样过程？</li>\n<li>如何评估生成内容的创造力与准确性之间的平衡？</li>\n</ol>\n<hr>\n<blockquote>\n<p><strong>来源：</strong> 原文内容整理自技术文档，部分代码示例来自 PyTorch 实现。</p>\n</blockquote>\n","env":{"base":"/","filePath":"/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Structure & Decoding Policy 结构和解码策略/深度解析语言模型采样方法：Top-K、Top-P、Temperature及综合策略.md","filePathRelative":"notes_bak/大语言模型学习/Structure & Decoding Policy 结构和解码策略/深度解析语言模型采样方法：Top-K、Top-P、Temperature及综合策略.md","frontmatter":{"dg-publish":true,"dg-permalink":"/大语言模型学习/Structure-&-Decoding-Policy-结构和解码策略/深度解析语言模型采样方法：Top-K、Top-P、Temperature及综合策略","dg-home":false,"dg-description":"在此输入笔记的描述","dg-hide":false,"dg-hide-title":false,"dg-show-backlinks":true,"dg-show-local-graph":true,"dg-show-inline-title":true,"dg-pinned":false,"dg-passphrase":"在此输入访问密码","dg-enable-mathjax":false,"dg-enable-mermaid":false,"dg-enable-uml":false,"dg-note-icon":0,"dg-enable-dataview":false,"tags":["NLP"],"permalink":"/大语言模型学习/Structure-&-Decoding-Policy-结构和解码策略/深度解析语言模型采样方法：Top-K、Top-P、Temperature及综合策略/","dgShowBacklinks":true,"dgShowLocalGraph":true,"dgShowInlineTitle":true,"dgPassFrontmatter":true,"noteIcon":0,"created":"2025-04-07T10:03:18.000Z","updated":"2025-04-13T05:06:02.000Z","title":"深度解析语言模型采样方法：Top-K、Top-P、Temperature及综合策略","createTime":"2025/05/13 17:33:52"},"sfcBlocks":{"template":{"type":"template","content":"<template><hr>\n<p><strong>元数据：</strong><br>\n<strong>分类：</strong> 自然语言处理<br>\n<strong>标签：</strong> 语言模型、采样方法、AI生成技术<br>\n<strong>日期：</strong> 2025年4月1日</p>\n<hr>\n<h2 id=\"什么是语言模型采样方法\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#什么是语言模型采样方法\"><span>什么是语言模型采样方法？</span></a></h2>\n<p>在生成式语言模型中，采样方法决定了输出文本的多样性和质量。这些方法通过调整模型选择词语的概率分布，来平衡生成内容的随机性与稳定性。以下是几种主流采样技术的核心概念及应用场景。</p>\n<hr>\n<h2 id=\"top-k-sampling\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#top-k-sampling\"><span>Top-K Sampling</span></a></h2>\n<h3 id=\"核心概念\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心概念\"><span>核心概念：</span></a></h3>\n<p>Top-K Sampling 是一种从排名靠前的 k 个词中随机选择的方法。它允许高概率词语有更大的被选中机会，同时保留一定的随机性。这种方式可以提升生成质量，但也可能在以下两种情况下出现问题：</p>\n<ol>\n<li><strong>分布尖锐时</strong>：可能导致生成内容不连贯或胡言乱语。</li>\n<li><strong>分布平坦时</strong>：限制了模型的创造力。\n<img src=\"/img/user/附件/Pasted image 20250407180356.png\" alt=\"Pasted image 20250407180356.png\"></li>\n</ol>\n<hr>\n<h2 id=\"top-p-sampling\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#top-p-sampling\"><span>Top-P Sampling</span></a></h2>\n<h3 id=\"核心概念-1\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心概念-1\"><span>核心概念：</span></a></h3>\n<p>Top-P Sampling（又称核采样）通过累积概率设定一个阈值 $$P$$，从满足该阈值的最小词集合中随机采样。这种方式动态调整候选词集合大小，更适合应对概率分布变化较大的场景。</p>\n<h3 id=\"代码实现\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#代码实现\"><span>代码实现：</span></a></h3>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code><span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">masked_probs </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">gather</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">probs</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">-</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> index</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">sorted_indices</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[:,</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> :</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">cutoff_idx </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">+</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">])</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># 重新归一化剩余概率</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">masked_probs </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> masked_probs </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">/</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> masked_probs</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">sum</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">-</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> keepdim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">True</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># 从候选词中随机选择一个词</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">selected_idx </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">multinomial</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">masked_probs</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">return</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> sorted_indices</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">gather</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">-</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> selected_idx</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p><img src=\"/img/user/附件/Pasted image 20250407180404.png\" alt=\"Pasted image 20250407180404.png\"></p>\n<hr>\n<h2 id=\"temperature-sampling\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#temperature-sampling\"><span>Temperature Sampling</span></a></h2>\n<h3 id=\"核心概念-2\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心概念-2\"><span>核心概念：</span></a></h3>\n<p>通过调整 Softmax 的温度系数来影响输出词的概率分布：</p>\n<ul>\n<li><strong>温度高</strong>（如 $$T &gt; 1$$）：概率分布更平坦，生成更随机。</li>\n<li><strong>温度低</strong>（如 $$T &lt; 1$$）：概率分布更集中，生成更稳定。</li>\n</ul>\n<p>这种方法适用于需要控制生成文本风格和随机程度的场景。</p>\n<hr>\n<h2 id=\"综合采样策略-kpt\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#综合采样策略-kpt\"><span>综合采样策略：KPT</span></a></h2>\n<h3 id=\"核心概念-3\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心概念-3\"><span>核心概念：</span></a></h3>\n<p>KPT 是一种结合 Top-K、Top-P 和 Temperature 的综合方法，逐步进行采样以提升生成效果。通过多层筛选，KPT 能在保持随机性的同时提高生成质量。</p>\n<hr>\n<h2 id=\"多答案选择策略\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#多答案选择策略\"><span>多答案选择策略</span></a></h2>\n<h3 id=\"best-of-n\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#best-of-n\"><span>Best-of-N</span></a></h3>\n<p>让模型生成 N 个回答，通过评分机制（如 Verifier 或 PRM）选择得分最高的答案作为最终结果。\n<img src=\"/img/user/附件/Pasted image 20250407180419.png\" alt=\"Pasted image 20250407180419.png\"></p>\n<h3 id=\"majority-vote\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#majority-vote\"><span>Majority Vote</span></a></h3>\n<p>让模型输出多个答案，以一致性最多的答案作为最终结果。</p>\n<h3 id=\"self-consistency\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#self-consistency\"><span>Self-consistency</span></a></h3>\n<p>通过生成多个推理路径，再用多数投票选出最合理的答案。这种方法在复杂推理任务中表现尤为突出。</p>\n<hr>\n<h2 id=\"常见错误-⚠️\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#常见错误-⚠️\"><span>常见错误 ⚠️</span></a></h2>\n<ol>\n<li><strong>参数设置不当</strong>：\n<ul>\n<li>K 值过小可能导致生成内容单一。</li>\n<li>P 值过大可能引入低质量候选词。</li>\n<li>温度过高可能使输出过于随机。</li>\n</ul>\n</li>\n<li><strong>忽略采样方法组合</strong>：单一方法可能难以应对复杂场景，需结合多种策略。</li>\n</ol>\n<hr>\n<h2 id=\"💡启发点\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#💡启发点\"><span>💡启发点</span></a></h2>\n<ul>\n<li><strong>动态调整采样参数</strong>：根据任务需求实时调整 K、P 和温度值。</li>\n<li><strong>结合多答案选择策略</strong>：提升复杂任务的推理准确性。</li>\n</ul>\n<hr>\n<h2 id=\"📈趋势预测\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#📈趋势预测\"><span>📈趋势预测</span></a></h2>\n<ol>\n<li><strong>自动化参数优化</strong>：未来可能出现基于任务自动调整采样参数的技术。</li>\n<li><strong>强化学习结合采样策略</strong>：通过奖励机制优化生成质量。</li>\n</ol>\n<hr>\n<h2 id=\"行动清单\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#行动清单\"><span>行动清单</span></a></h2>\n<ol>\n<li>实现不同采样方法的代码，并测试其在文本生成中的效果。</li>\n<li>探索 KPT 综合采样策略对生成质量的提升。</li>\n<li>应用 Self-consistency 方法于复杂推理任务。</li>\n</ol>\n<hr>\n<h2 id=\"思考-延伸问题\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#思考-延伸问题\"><span>[思考]延伸问题</span></a></h2>\n<ol>\n<li>如何设计动态调整 K 和 P 的算法，使其适应不同场景？</li>\n<li>是否可以结合语义理解优化采样过程？</li>\n<li>如何评估生成内容的创造力与准确性之间的平衡？</li>\n</ol>\n<hr>\n<blockquote>\n<p><strong>来源：</strong> 原文内容整理自技术文档，部分代码示例来自 PyTorch 实现。</p>\n</blockquote>\n</template>","contentStripped":"<hr>\n<p><strong>元数据：</strong><br>\n<strong>分类：</strong> 自然语言处理<br>\n<strong>标签：</strong> 语言模型、采样方法、AI生成技术<br>\n<strong>日期：</strong> 2025年4月1日</p>\n<hr>\n<h2 id=\"什么是语言模型采样方法\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#什么是语言模型采样方法\"><span>什么是语言模型采样方法？</span></a></h2>\n<p>在生成式语言模型中，采样方法决定了输出文本的多样性和质量。这些方法通过调整模型选择词语的概率分布，来平衡生成内容的随机性与稳定性。以下是几种主流采样技术的核心概念及应用场景。</p>\n<hr>\n<h2 id=\"top-k-sampling\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#top-k-sampling\"><span>Top-K Sampling</span></a></h2>\n<h3 id=\"核心概念\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心概念\"><span>核心概念：</span></a></h3>\n<p>Top-K Sampling 是一种从排名靠前的 k 个词中随机选择的方法。它允许高概率词语有更大的被选中机会，同时保留一定的随机性。这种方式可以提升生成质量，但也可能在以下两种情况下出现问题：</p>\n<ol>\n<li><strong>分布尖锐时</strong>：可能导致生成内容不连贯或胡言乱语。</li>\n<li><strong>分布平坦时</strong>：限制了模型的创造力。\n<img src=\"/img/user/附件/Pasted image 20250407180356.png\" alt=\"Pasted image 20250407180356.png\"></li>\n</ol>\n<hr>\n<h2 id=\"top-p-sampling\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#top-p-sampling\"><span>Top-P Sampling</span></a></h2>\n<h3 id=\"核心概念-1\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心概念-1\"><span>核心概念：</span></a></h3>\n<p>Top-P Sampling（又称核采样）通过累积概率设定一个阈值 $$P$$，从满足该阈值的最小词集合中随机采样。这种方式动态调整候选词集合大小，更适合应对概率分布变化较大的场景。</p>\n<h3 id=\"代码实现\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#代码实现\"><span>代码实现：</span></a></h3>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code><span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">masked_probs </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">gather</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">probs</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">-</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> index</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">sorted_indices</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[:,</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> :</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">cutoff_idx </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">+</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">])</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># 重新归一化剩余概率</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">masked_probs </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> masked_probs </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">/</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> masked_probs</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">sum</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">-</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> keepdim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">True</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># 从候选词中随机选择一个词</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">selected_idx </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">multinomial</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">masked_probs</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">return</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> sorted_indices</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">gather</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">-</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> selected_idx</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p><img src=\"/img/user/附件/Pasted image 20250407180404.png\" alt=\"Pasted image 20250407180404.png\"></p>\n<hr>\n<h2 id=\"temperature-sampling\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#temperature-sampling\"><span>Temperature Sampling</span></a></h2>\n<h3 id=\"核心概念-2\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心概念-2\"><span>核心概念：</span></a></h3>\n<p>通过调整 Softmax 的温度系数来影响输出词的概率分布：</p>\n<ul>\n<li><strong>温度高</strong>（如 $$T &gt; 1$$）：概率分布更平坦，生成更随机。</li>\n<li><strong>温度低</strong>（如 $$T &lt; 1$$）：概率分布更集中，生成更稳定。</li>\n</ul>\n<p>这种方法适用于需要控制生成文本风格和随机程度的场景。</p>\n<hr>\n<h2 id=\"综合采样策略-kpt\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#综合采样策略-kpt\"><span>综合采样策略：KPT</span></a></h2>\n<h3 id=\"核心概念-3\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心概念-3\"><span>核心概念：</span></a></h3>\n<p>KPT 是一种结合 Top-K、Top-P 和 Temperature 的综合方法，逐步进行采样以提升生成效果。通过多层筛选，KPT 能在保持随机性的同时提高生成质量。</p>\n<hr>\n<h2 id=\"多答案选择策略\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#多答案选择策略\"><span>多答案选择策略</span></a></h2>\n<h3 id=\"best-of-n\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#best-of-n\"><span>Best-of-N</span></a></h3>\n<p>让模型生成 N 个回答，通过评分机制（如 Verifier 或 PRM）选择得分最高的答案作为最终结果。\n<img src=\"/img/user/附件/Pasted image 20250407180419.png\" alt=\"Pasted image 20250407180419.png\"></p>\n<h3 id=\"majority-vote\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#majority-vote\"><span>Majority Vote</span></a></h3>\n<p>让模型输出多个答案，以一致性最多的答案作为最终结果。</p>\n<h3 id=\"self-consistency\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#self-consistency\"><span>Self-consistency</span></a></h3>\n<p>通过生成多个推理路径，再用多数投票选出最合理的答案。这种方法在复杂推理任务中表现尤为突出。</p>\n<hr>\n<h2 id=\"常见错误-⚠️\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#常见错误-⚠️\"><span>常见错误 ⚠️</span></a></h2>\n<ol>\n<li><strong>参数设置不当</strong>：\n<ul>\n<li>K 值过小可能导致生成内容单一。</li>\n<li>P 值过大可能引入低质量候选词。</li>\n<li>温度过高可能使输出过于随机。</li>\n</ul>\n</li>\n<li><strong>忽略采样方法组合</strong>：单一方法可能难以应对复杂场景，需结合多种策略。</li>\n</ol>\n<hr>\n<h2 id=\"💡启发点\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#💡启发点\"><span>💡启发点</span></a></h2>\n<ul>\n<li><strong>动态调整采样参数</strong>：根据任务需求实时调整 K、P 和温度值。</li>\n<li><strong>结合多答案选择策略</strong>：提升复杂任务的推理准确性。</li>\n</ul>\n<hr>\n<h2 id=\"📈趋势预测\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#📈趋势预测\"><span>📈趋势预测</span></a></h2>\n<ol>\n<li><strong>自动化参数优化</strong>：未来可能出现基于任务自动调整采样参数的技术。</li>\n<li><strong>强化学习结合采样策略</strong>：通过奖励机制优化生成质量。</li>\n</ol>\n<hr>\n<h2 id=\"行动清单\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#行动清单\"><span>行动清单</span></a></h2>\n<ol>\n<li>实现不同采样方法的代码，并测试其在文本生成中的效果。</li>\n<li>探索 KPT 综合采样策略对生成质量的提升。</li>\n<li>应用 Self-consistency 方法于复杂推理任务。</li>\n</ol>\n<hr>\n<h2 id=\"思考-延伸问题\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#思考-延伸问题\"><span>[思考]延伸问题</span></a></h2>\n<ol>\n<li>如何设计动态调整 K 和 P 的算法，使其适应不同场景？</li>\n<li>是否可以结合语义理解优化采样过程？</li>\n<li>如何评估生成内容的创造力与准确性之间的平衡？</li>\n</ol>\n<hr>\n<blockquote>\n<p><strong>来源：</strong> 原文内容整理自技术文档，部分代码示例来自 PyTorch 实现。</p>\n</blockquote>\n","tagOpen":"<template>","tagClose":"</template>"},"script":null,"scriptSetup":null,"scripts":[],"styles":[],"customBlocks":[]},"content":"---\n**元数据：**  \n**分类：** 自然语言处理  \n**标签：** 语言模型、采样方法、AI生成技术  \n**日期：** 2025年4月1日    \n\n---\n\n\n\n## 什么是语言模型采样方法？\n在生成式语言模型中，采样方法决定了输出文本的多样性和质量。这些方法通过调整模型选择词语的概率分布，来平衡生成内容的随机性与稳定性。以下是几种主流采样技术的核心概念及应用场景。\n\n---\n\n\n\n## Top-K Sampling\n\n### 核心概念：\nTop-K Sampling 是一种从排名靠前的 k 个词中随机选择的方法。它允许高概率词语有更大的被选中机会，同时保留一定的随机性。这种方式可以提升生成质量，但也可能在以下两种情况下出现问题：\n1. **分布尖锐时**：可能导致生成内容不连贯或胡言乱语。\n2. **分布平坦时**：限制了模型的创造力。\n![Pasted image 20250407180356.png](/img/user/%E9%99%84%E4%BB%B6/Pasted%20image%2020250407180356.png)\n---\n\n\n\n## Top-P Sampling\n\n### 核心概念：\nTop-P Sampling（又称核采样）通过累积概率设定一个阈值 $$P$$，从满足该阈值的最小词集合中随机采样。这种方式动态调整候选词集合大小，更适合应对概率分布变化较大的场景。\n\n\n### 代码实现：\n```python\nmasked_probs = torch.gather(probs, dim=-1, index=sorted_indices[:, :cutoff_idx + 1])\n\n# 重新归一化剩余概率\nmasked_probs = masked_probs / masked_probs.sum(dim=-1, keepdim=True)\n\n# 从候选词中随机选择一个词\nselected_idx = torch.multinomial(masked_probs, 1)\n\nreturn sorted_indices.gather(-1, selected_idx)\n```\n\n![Pasted image 20250407180404.png](/img/user/%E9%99%84%E4%BB%B6/Pasted%20image%2020250407180404.png)\n\n---\n\n\n\n## Temperature Sampling\n\n### 核心概念：\n通过调整 Softmax 的温度系数来影响输出词的概率分布：\n- **温度高**（如 $$T > 1$$）：概率分布更平坦，生成更随机。\n- **温度低**（如 $$T < 1$$）：概率分布更集中，生成更稳定。\n\n这种方法适用于需要控制生成文本风格和随机程度的场景。\n\n---\n\n\n\n## 综合采样策略：KPT\n\n### 核心概念：\nKPT 是一种结合 Top-K、Top-P 和 Temperature 的综合方法，逐步进行采样以提升生成效果。通过多层筛选，KPT 能在保持随机性的同时提高生成质量。\n\n---\n\n\n\n## 多答案选择策略\n\n### Best-of-N\n让模型生成 N 个回答，通过评分机制（如 Verifier 或 PRM）选择得分最高的答案作为最终结果。\n![Pasted image 20250407180419.png](/img/user/%E9%99%84%E4%BB%B6/Pasted%20image%2020250407180419.png)\n\n\n### Majority Vote\n让模型输出多个答案，以一致性最多的答案作为最终结果。\n\n\n### Self-consistency\n通过生成多个推理路径，再用多数投票选出最合理的答案。这种方法在复杂推理任务中表现尤为突出。\n\n---\n\n\n\n## 常见错误 ⚠️\n1. **参数设置不当**：\n   - K 值过小可能导致生成内容单一。\n   - P 值过大可能引入低质量候选词。\n   - 温度过高可能使输出过于随机。\n2. **忽略采样方法组合**：单一方法可能难以应对复杂场景，需结合多种策略。\n\n---\n\n\n\n## 💡启发点\n- **动态调整采样参数**：根据任务需求实时调整 K、P 和温度值。\n- **结合多答案选择策略**：提升复杂任务的推理准确性。\n\n---\n\n\n\n## 📈趋势预测\n1. **自动化参数优化**：未来可能出现基于任务自动调整采样参数的技术。\n2. **强化学习结合采样策略**：通过奖励机制优化生成质量。\n\n---\n\n\n\n## 行动清单\n1. 实现不同采样方法的代码，并测试其在文本生成中的效果。\n2. 探索 KPT 综合采样策略对生成质量的提升。\n3. 应用 Self-consistency 方法于复杂推理任务。\n\n---\n\n\n\n## [思考]延伸问题\n1. 如何设计动态调整 K 和 P 的算法，使其适应不同场景？\n2. 是否可以结合语义理解优化采样过程？\n3. 如何评估生成内容的创造力与准确性之间的平衡？\n\n---\n\n> **来源：** 原文内容整理自技术文档，部分代码示例来自 PyTorch 实现。","excerpt":"","includedFiles":[],"tasklistId":0,"title":"","headers":[{"level":2,"title":"什么是语言模型采样方法？","slug":"什么是语言模型采样方法","link":"#什么是语言模型采样方法","children":[]},{"level":2,"title":"Top-K Sampling","slug":"top-k-sampling","link":"#top-k-sampling","children":[{"level":3,"title":"核心概念：","slug":"核心概念","link":"#核心概念","children":[]}]},{"level":2,"title":"Top-P Sampling","slug":"top-p-sampling","link":"#top-p-sampling","children":[{"level":3,"title":"核心概念：","slug":"核心概念-1","link":"#核心概念-1","children":[]},{"level":3,"title":"代码实现：","slug":"代码实现","link":"#代码实现","children":[]}]},{"level":2,"title":"Temperature Sampling","slug":"temperature-sampling","link":"#temperature-sampling","children":[{"level":3,"title":"核心概念：","slug":"核心概念-2","link":"#核心概念-2","children":[]}]},{"level":2,"title":"综合采样策略：KPT","slug":"综合采样策略-kpt","link":"#综合采样策略-kpt","children":[{"level":3,"title":"核心概念：","slug":"核心概念-3","link":"#核心概念-3","children":[]}]},{"level":2,"title":"多答案选择策略","slug":"多答案选择策略","link":"#多答案选择策略","children":[{"level":3,"title":"Best-of-N","slug":"best-of-n","link":"#best-of-n","children":[]},{"level":3,"title":"Majority Vote","slug":"majority-vote","link":"#majority-vote","children":[]},{"level":3,"title":"Self-consistency","slug":"self-consistency","link":"#self-consistency","children":[]}]},{"level":2,"title":"常见错误 ⚠️","slug":"常见错误-⚠️","link":"#常见错误-⚠️","children":[]},{"level":2,"title":"💡启发点","slug":"💡启发点","link":"#💡启发点","children":[]},{"level":2,"title":"📈趋势预测","slug":"📈趋势预测","link":"#📈趋势预测","children":[]},{"level":2,"title":"行动清单","slug":"行动清单","link":"#行动清单","children":[]},{"level":2,"title":"[思考]延伸问题","slug":"思考-延伸问题","link":"#思考-延伸问题","children":[]}]}}
