---
{"dg-publish":true,"dg-permalink":"/å¤§è¯­è¨€æ¨¡å‹å­¦ä¹ /RLå¼ºåŒ–å­¦ä¹ åŸºç¡€/ç­–ç•¥è¿­ä»£ç®—æ³•","dg-home":false,"dg-description":"åœ¨æ­¤è¾“å…¥ç¬”è®°çš„æè¿°","dg-hide":false,"dg-hide-title":false,"dg-show-backlinks":true,"dg-show-local-graph":true,"dg-show-inline-title":true,"dg-pinned":false,"dg-passphrase":"åœ¨æ­¤è¾“å…¥è®¿é—®å¯†ç ","dg-enable-mathjax":false,"dg-enable-mermaid":false,"dg-enable-uml":false,"dg-note-icon":0,"dg-enable-dataview":false,"tags":["NLP"],"permalink":"/å¤§è¯­è¨€æ¨¡å‹å­¦ä¹ /RLå¼ºåŒ–å­¦ä¹ åŸºç¡€/ç­–ç•¥è¿­ä»£ç®—æ³•/","dgShowBacklinks":true,"dgShowLocalGraph":true,"dgShowInlineTitle":true,"dgPassFrontmatter":true,"noteIcon":0,"created":"2025-04-11T13:28:54.000+08:00","updated":"2025-04-13T13:06:02.000+08:00"}
---



# åŠ¨æ€è§„åˆ’ä¸å¼ºåŒ–å­¦ä¹ ç®—æ³•è§£æï¼šç­–ç•¥è¿­ä»£ä¸ä»·å€¼è¿­ä»£
åˆ†ç±»ï¼šè‡ªåŠ¨æ¨æ–­

æ ‡ç­¾ï¼šåŠ¨æ€è§„åˆ’ï¼Œå¼ºåŒ–å­¦ä¹ ï¼Œç­–ç•¥è¿­ä»£ï¼Œä»·å€¼è¿­ä»£

æ—¥æœŸï¼š2025å¹´4æœˆ8æ—¥

## æ ¸å¿ƒè§‚ç‚¹æ€»ç»“
åŠ¨æ€è§„åˆ’æ˜¯ä¸€ç§å°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºæ›´å°å­é—®é¢˜çš„æ–¹æ³•ï¼Œé€‚ç”¨äºå·²çŸ¥ç¯å¢ƒåŠ¨æ€çš„ model-based æ–¹æ³•ã€‚å…¶åœ¨å¼ºåŒ–å­¦ä¹ ä¸­çš„åº”ç”¨ä¸»è¦ä½“ç°åœ¨ç­–ç•¥è¿­ä»£å’Œä»·å€¼è¿­ä»£ä¸¤ç§ç®—æ³•ä¸­ã€‚ç­–ç•¥è¿­ä»£é€šè¿‡äº¤æ›¿è¿›è¡Œç­–ç•¥è¯„ä¼°å’Œç­–ç•¥æå‡æ¥è·å¾—æœ€ä¼˜ç­–ç•¥ï¼Œè€Œä»·å€¼è¿­ä»£åˆ™ç›´æ¥æ›´æ–°çŠ¶æ€ä»·å€¼å‡½æ•°ã€‚


## é‡ç‚¹æ®µè½
1. **åŠ¨æ€è§„åˆ’çš„åŸºæœ¬æ€æƒ³**ï¼šé€šè¿‡åˆ†è§£é—®é¢˜å¹¶ä¿å­˜å­é—®é¢˜çš„è§£æ¥é¿å…é‡å¤è®¡ç®—ã€‚  
   ğŸ’¡ å¯å‘ç‚¹ï¼šæ­¤æ–¹æ³•ç‰¹åˆ«é€‚ç”¨äºå·²çŸ¥ç¯å¢ƒåŠ¨æ€çš„æƒ…å†µã€‚

2. **ç­–ç•¥è¿­ä»£çš„è¿‡ç¨‹**ï¼šé€šè¿‡ç­–ç•¥è¯„ä¼°å’Œç­–ç•¥æå‡äº¤æ›¿è¿›è¡Œï¼Œé€æ­¥é€¼è¿‘æœ€ä¼˜ç­–ç•¥ã€‚  
   âœ… æ“ä½œæ­¥éª¤ï¼š
   - ç­–ç•¥è¯„ä¼°ï¼šè®¡ç®—å½“å‰ç­–ç•¥çš„çŠ¶æ€ä»·å€¼å‡½æ•°ã€‚
   - ç­–ç•¥æå‡ï¼šåŸºäºçŠ¶æ€ä»·å€¼å‡½æ•°æ”¹è¿›ç­–ç•¥ã€‚

3. **ä»·å€¼å‡½æ•°çš„è®¡ç®—å…¬å¼**ï¼š
   $$
   V^{\pi}(s) = \sum_{a \in A} \pi(a|s) \left( r(s, a) + \gamma \sum_{s' \in S} p(s'|s, a) V^{\pi}(s') \right)
   $$

4. **ç­–ç•¥è¯„ä¼°å’Œæå‡çš„ç»ˆæ­¢æ¡ä»¶**ï¼šå½“å½“å‰è¿­ä»£ä¸ä¸Šä¸€è½®çš„çŠ¶æ€ä»·å€¼å‡½æ•°å·®å°äºé˜ˆå€¼ $$\epsilon$$ æ—¶ï¼Œå¯ä»¥åœæ­¢ç­–ç•¥è¯„ä¼°ã€‚

5. **ä»·å€¼è¿­ä»£çš„æ–¹æ³•**ï¼šç›´æ¥é€šè¿‡æ›´æ–°çŠ¶æ€ä»·å€¼å‡½æ•°æ¥æ±‚è§£æœ€ä¼˜ç­–ç•¥ã€‚

```Python
class PolicyIteration:
    """ç­–ç•¥è¿­ä»£ç®—æ³•"""
    
    def __init__(self, env, theta, gamma):
        self.env = env
        self.v = [0] * (self.env.ncol * self.env.nrow)  # çŠ¶æ€ä»·å€¼å‡½æ•°åˆå§‹åŒ–
        self.pi = [
            [0.25, 0.25, 0.25, 0.25]  # å‡åŒ€éšæœºç­–ç•¥ï¼ˆå››ä¸ªåŠ¨ä½œï¼‰
            for _ in range(self.env.ncol * self.env.nrow)
        ]
        self.theta = theta  # ç­–ç•¥è¯„ä¼°æ”¶æ•›é˜ˆå€¼
        self.gamma = gamma  # æŠ˜æ‰£å› å­

    def policy_evaluation(self):
        """ç­–ç•¥è¯„ä¼°ï¼ˆé¢„æµ‹ï¼‰"""
        cnt = 1
        while True:
            max_diff = 0
            new_v = [0] * (self.env.ncol * self.env.nrow)
            
            for s in range(self.env.ncol * self.env.nrow):
                qsa_list = []
                for a in range(4):  # å››ä¸ªåŠ¨ä½œæ–¹å‘
                    qsa = 0
                    for p, next_state, r, done in self.env.P[s][a]:
                        qsa += p * (
                            r + self.gamma * self.v[next_state] * (1 - done)
                        )
                    qsa_list.append(self.pi[s][a] * qsa)
                    
                new_v[s] = sum(qsa_list)
                max_diff = max(max_diff, abs(new_v[s] - self.v[s]))
                
            self.v = new_v
            if max_diff < self.theta:
                break
            cnt += 1
            
        print(f"ç­–ç•¥è¯„ä¼°å®Œæˆï¼ˆå…±è¿­ä»£{cnt}è½®ï¼‰")
        return self.v

    def policy_improvement(self):
        """ç­–ç•¥æ”¹è¿›ï¼ˆæ§åˆ¶ï¼‰"""
        new_pi = []
        for s in range(self.env.nrow * self.env.ncol):
            q_values = []
            for a in range(4):
                qsa = 0
                for p, next_state, r, done in self.env.P[s][a]:
                    qsa += p * (
                        r + self.gamma * self.v[next_state] * (1 - done)
                    )
                q_values.append(qsa)
            
            max_q = max(q_values)
            optimal_actions = [i for i, q in enumerate(q_values) if q == max_q]
            new_pi.append([
                1/len(optimal_actions) if a in optimal_actions else 0 
                for a in range(4)
            ])
            
        print("ç­–ç•¥æå‡å®Œæˆ")
        self.pi = new_pi
        return self.pi

    def policy_iteration(self):
        """ç­–ç•¥è¿­ä»£ä¸»å¾ªç¯"""
        while True:
            self.policy_evaluation()
            old_pi = [row.copy() for row in self.pi]
            self.policy_improvement()
            if old_pi == self.pi:
                break
        return self.pi
```


## å¸¸è§é”™è¯¯
> âš  åœ¨åŠ¨æ€è§„åˆ’ä¸­ï¼Œé”™è¯¯åœ°å‡è®¾ç¯å¢ƒåŠ¨æ€æœªçŸ¥ä¼šå¯¼è‡´ç®—æ³•æ— æ³•æ­£å¸¸è¿ä½œã€‚


## ä¸ªäººè§è§£ [æ€è€ƒ]
1. åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¦‚ä½•é€‰æ‹©ç­–ç•¥è¿­ä»£ä¸ä»·å€¼è¿­ä»£ï¼Ÿ
2. åŠ¨æ€è§„åˆ’å¦‚ä½•åœ¨éé™æ€ç¯å¢ƒä¸­æœ‰æ•ˆåº”ç”¨ï¼Ÿ
3. æœ‰å“ªäº›æ–¹æ³•å¯ä»¥é™ä½åŠ¨æ€è§„åˆ’çš„è®¡ç®—å¤æ‚åº¦ï¼Ÿ


## è¡ŒåŠ¨æ¸…å•
- è¿›ä¸€æ­¥ç ”ç©¶åŠ¨æ€è§„åˆ’åœ¨ä¸åŒç±»å‹é—®é¢˜ä¸­çš„åº”ç”¨ã€‚
- æ¢ç´¢å¦‚ä½•åœ¨ä¸å®Œå…¨å·²çŸ¥ç¯å¢ƒä¸­åº”ç”¨åŠ¨æ€è§„åˆ’ã€‚
- å®æ–½ä»£ç ç¤ºä¾‹ä»¥åŠ æ·±å¯¹ç®—æ³•è¿‡ç¨‹çš„ç†è§£ã€‚


## ğŸ“ˆè¶‹åŠ¿é¢„æµ‹
éšç€è®¡ç®—èƒ½åŠ›çš„æå‡å’Œæ›´å¤šå¤æ‚ç¯å¢ƒæ¨¡æ‹Ÿå™¨çš„å¼€å‘ï¼ŒåŠ¨æ€è§„åˆ’å°†åœ¨æ›´å¤šå®é™…åº”ç”¨ä¸­å¾—åˆ°å¹¿æ³›ä½¿ç”¨ã€‚


## åç»­è¿½è¸ª
- ç ”ç©¶åŠ¨æ€è§„åˆ’åœ¨éšæœºç¯å¢ƒä¸­çš„æ‰©å±•ã€‚
- æ¢è®¨ç»“åˆæ·±åº¦å­¦ä¹ çš„æ–¹æ³•ä»¥æå‡åŠ¨æ€è§„åˆ’çš„æ•ˆç‡ã€‚

> æ¥æºï¼šåŸå§‹å†…å®¹æ¥è‡ªäºæŸå¼ºåŒ–å­¦ä¹ æ•™ç¨‹ã€‚
