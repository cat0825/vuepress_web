---
{"dg-publish":true,"dg-permalink":"/大语言模型学习/分词/分词算法的比较","dg-home":false,"dg-description":"在此输入笔记的描述","dg-hide":false,"dg-hide-title":false,"dg-show-backlinks":true,"dg-show-local-graph":true,"dg-show-inline-title":true,"dg-pinned":false,"dg-passphrase":"在此输入访问密码","dg-enable-mathjax":false,"dg-enable-mermaid":false,"dg-enable-uml":false,"dg-note-icon":0,"dg-enable-dataview":false,"tags":["NLP"],"permalink":"/大语言模型学习/分词/分词算法的比较/","dgShowBacklinks":true,"dgShowLocalGraph":true,"dgShowInlineTitle":true,"dgPassFrontmatter":true,"noteIcon":0,"created":"2025-03-27T12:53:34.473+08:00","updated":"2025-04-13T17:57:13.445+08:00"}
---



# 分词方法对比：WordPiece、BPE与ULM的核心差异解析

## 元数据
- **分类**：自然语言处理 (NLP)
- **标签**：分词方法、WordPiece、BPE、ULM
- **日期**：2025年4月2日  

---


## 1️⃣ 核心观点总结
分词是自然语言处理中的基础步骤，不同的分词方法会显著影响模型性能。本文对比了三种常见的分词方法：WordPiece、BPE（Byte Pair Encoding）和ULM（Unigram Language Model），并分析了它们在词表生成策略和合并规则上的差异。

---


## 2️⃣ 重点内容解析

### 💡 **WordPiece与BPE的对比**
- **共同点**：  
  两者都基于“合并”的思想，先将语料拆分为最小单位（如英文中的26个字母和符号），再逐步合并，生成从小到大的词表。
  
- **区别**：

| 方法            | 合并依据            |
| ------------- | --------------- |
| **WordPiece** | 基于词与词之间的互信息（MI） |
| **BPE**       | 基于词的共现频率        |
|               |                 |


  📈 **趋势预测**：随着更多上下文感知模型的引入，基于互信息的WordPiece可能更受欢迎。

---


### 💡 **WordPiece与ULM的对比**
- **共同点**：  
  两者都使用语言模型来选择子词，基于概率评估分词效果。
  
- **区别**：
 

| 方法            | 词表构建策略   | 输出结果       |
| ------------- | -------- | ---------- |
| **WordPiece** | 从小到大逐步合并 | 单一分词方案     |
| **ULM**       | 从大到小逐步删除 | 多个带概率的分词结果 |

  ✅ **启发点**：ULM通过保留多个分词可能性，为下游任务提供更多灵活性。

---


### ⚠️ **常见错误**
1. 将BPE误认为是基于互信息的方法，而实际上它是基于共现频率。
2. 忽略ULM输出的多样性，错误地将其与其他单一分词方法混为一谈。

---


## 3️⃣ 技术术语通俗解读
- **互信息（Mutual Information, MI）**：用来衡量两个词同时出现时的信息增益，类似于“关联强度”。
- **共现频率**：统计两个词在语料中一起出现的次数。
- **语言模型（Language Model）**：预测句子中某个词出现的概率模型。

---


## 4️⃣ 行动清单
1. ✅ 探索实际项目中不同分词方法对模型性能的影响。
2. ✅ 实现一个简单的BPE算法，理解其合并过程。
3. ✅ 深入研究ULM对多样性分词输出的具体应用场景。

---


## [思考] 板块
1. 如何在实际应用中选择适合的分词方法？是否需要根据任务动态调整？
2. ULM输出多个分词结果是否会增加模型复杂度？如何权衡？
3. 是否可以结合WordPiece和ULM的方法，既保留互信息的优势，又实现多样性输出？

---

> 来源：原文内容整理自自然语言处理领域基础知识。
