---
{"dg-publish":true,"tags":["NLP"],"title":"使用Byte Pair Encoding (BPE)优化子词分词的技巧与实践","dg-permalink":"/大语言模型学习/分词/BPE","permalink":"/大语言模型学习/分词/BPE/","dgPassFrontmatter":true,"noteIcon":"","created":"2025-03-27T09:54:11.996+08:00","updated":"2025-04-13T17:21:31.527+08:00"}
---



## 元数据
- **分类**：自然语言处理（NLP）
- **标签**：BPE、分词算法、子词编码、自然语言处理、优化
- **日期**：2025年4月1日  

---



## 核心观点概述
Byte Pair Encoding (BPE) 是一种常见的子词分词算法，通过逐步合并频率最高的字符对，生成一个高效的子词词表。它被广泛用于自然语言处理（NLP）任务中，尤其是在神经机器翻译（NMT）中，用以解决稀有词问题。

💡 **启发点**：BPE通过贪婪算法逐步构建子词表，能够在词汇表大小和编码效率之间取得平衡。

---



## 重点内容提取

### ## BPE的核心思想
- BPE从一个基础的小型词表出发，不断合并频率最高的字符对，逐步生成新的子词单元。
- 其目标是在子词粒度和词汇表大小之间找到平衡，使得模型既能高效编码，又能处理稀有词。


### ## BPE的操作步骤
1. **✅ 准备基础词表**：例如英文中包含26个字母及符号（如 `_` 表示单词结尾）。
2. **⚠️ 拆分语料为最小单元**：将训练语料中的单词拆解为单个字符。
3. **❗️ 统计频率并合并**：找到语料中频率最高的相邻字符对，并将其合并为新的子词。
4. **重复迭代**：直到达到预设的子词表大小或频率阈值。

---


### ## 示例：从语料库中生成子词表
以下是一个简单的BPE操作示例。

#### 初始语料库（带频次）
| 词频 | 单词        |
|------|-------------|
| [5]  | low_        |
| [2]  | lowest_     |
| [6]  | newer_      |
| [3]  | wider_      |
| [2]  | new_        |


#### 基础字符频次统计
| 字符 | 频次 |
|------|------|
| `_`  | 18   |
| `d`  | 3    |
| `e`  | 19   |
| `i`  | 3    |
| `l`  | 7    |
| `n`  | 8    |
| `o`  | 7    |
| `r`  | 9    |
| `s`  | 2    |
| `t`  | 2    |
| `w`  | 22   |


#### 第一次迭代：合并频率最高的字符对
- 合并 `r` 和 `_`，形成新子词 `r_`，更新后的频次为9。
- 更新后的字符频次表：
  
| 字符 | 频次 |
|------|------|
| `_`  | 9    |
| `d`  | 3    |
| `e`  | 19   |
| `i`  | 3    |
| `l`  | 7    |
| `n`  | 8    |
| `o`  | 7    |
| `r`  | 0    |
| `s`  | 2    |
| `t`  | 2    |
| `w`  | 22   |
| `r_` | 9    |

---


### ## 优缺点分析
- **优点**：
    - 高效平衡了词汇表大小和编码步数。
    - 能够处理稀有词，避免OOV（Out of Vocabulary）问题。
- **缺点**：
    - 基于贪婪算法，无法生成带概率的多种分词结果。
    - 解码时可能存在歧义问题，例如同一输入可对应多种分词方式。

---



## 常见错误与注意事项
⚠️ **分词歧义问题**：例如，"Hello World" 的分词结果可能出现多种形式，如 "Hell/o/world" 或 "He/llo/world"。

⚠️ **贪婪算法局限性**：BPE仅考虑当前最优合并对，可能错过全局最优解。

---



## 行动清单
- [x] 实现一个简单的BPE算法，用于小型语料库测试。
- [x] 探索不同BPE参数（如词汇表大小）对模型性能的影响。
- [x] 比较BPE与其他分词方法（如WordPiece）的实际效果。

---



## [思考] 延伸问题
1. 如何改进BPE算法，使其支持概率分词？
2. 在多语言模型中，BPE如何适配不同语言的特性？
	1. - 任务是跨语言迁移/翻译 → 建议 **共享 BPE + 语言前缀**
	2. 如果是低资源语言建模 → 考虑 **独立子词表** 或 BBPE 分配资源更公平
3.  以结合深度学习技术优化BPE的子词选择过程？

---

> **来源**：本文内容摘自论文《Neural Machine Translation of Rare Words with Subword Units》，链接：[https://arxiv.org/pdf/1508.07909](https://arxiv.org/pdf/1508.07909)
