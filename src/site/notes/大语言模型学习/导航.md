---
{"dg-publish":true,"dg-permalink":"/大语言模型学习/碎碎念","dg-home":false,"dg-description":"在此输入笔记的描述","dg-hide":false,"dg-hide-title":false,"dg-show-backlinks":true,"dg-show-local-graph":true,"dg-show-inline-title":true,"dg-pinned":false,"dg-passphrase":"在此输入访问密码","dg-enable-mathjax":false,"dg-enable-mermaid":false,"dg-enable-uml":false,"dg-note-icon":0,"dg-enable-dataview":false,"tags":["NLP"],"permalink":"/大语言模型学习/碎碎念/","dgShowBacklinks":true,"dgShowLocalGraph":true,"dgShowInlineTitle":true,"dgPassFrontmatter":true,"noteIcon":0,"created":"2025-02-27T12:07:19.000+08:00","updated":"2025-05-04T19:19:14.413+08:00"}
---



# 分词
- [[大语言模型学习/词嵌入/介绍\|介绍]]
- [[大语言模型学习/词嵌入/oneHot\|oneHot]]
- [[大语言模型学习/词嵌入/Word2Vec\|Word2Vec]]
- [[大语言模型学习/词嵌入/FastText\|FastText]]

{ .block-language-dataview}



# 词嵌入
- [[大语言模型学习/词嵌入/介绍\|介绍]]
- [[大语言模型学习/词嵌入/oneHot\|oneHot]]
- [[大语言模型学习/词嵌入/Word2Vec\|Word2Vec]]
- [[大语言模型学习/词嵌入/FastText\|FastText]]

{ .block-language-dataview}



# Attention
- [[大语言模型学习/Attention注意力机制/Attention机制详解与应用\|Attention机制详解与应用]]
- [[大语言模型学习/Attention注意力机制/Transformer中的Attention详解与应用指南\|Transformer中的Attention详解与应用指南]]
- [[大语言模型学习/Attention注意力机制/优化Attention计算复杂度的技术探讨\|优化Attention计算复杂度的技术探讨]]
- [[大语言模型学习/Attention注意力机制/KV Cache技术详解：优化Transformer自回归生成效率\|KV Cache技术详解：优化Transformer自回归生成效率]]
- [[大语言模型学习/Attention注意力机制/深度学习中的注意力机制优化：从MHA到MLA\|深度学习中的注意力机制优化：从MHA到MLA]]
- [[大语言模型学习/Attention注意力机制/DCA：长文本处理的新突破（Dual Chunk Attention）\|DCA：长文本处理的新突破（Dual Chunk Attention）]]
- [[大语言模型学习/Attention注意力机制/【长上下文模型优化】基于Shifted Sparse Attention的创新方法\|【长上下文模型优化】基于Shifted Sparse Attention的创新方法]]

{ .block-language-dataview}



# FFN,Add&LN
- [[大语言模型学习/FFN、Add & LN 的作用与应用/Transformer核心模块解析：FFN、Add & LN 的作用与应用\|Transformer核心模块解析：FFN、Add & LN 的作用与应用]]
- [[大语言模型学习/FFN、Add & LN 的作用与应用/深度学习中的Layer Norm设计：Post-Norm、Pre-Norm与Sandwich-Norm比较\|深度学习中的Layer Norm设计：Post-Norm、Pre-Norm与Sandwich-Norm比较]]
- [[大语言模型学习/FFN、Add & LN 的作用与应用/激活函数与FFN结构优化：SwiGLU、GeGLU及其应用解析\|激活函数与FFN结构优化：SwiGLU、GeGLU及其应用解析]]
- [[大语言模型学习/FFN、Add & LN 的作用与应用/激活函数详解与比较：从Sigmoid到Swish\|激活函数详解与比较：从Sigmoid到Swish]]

{ .block-language-dataview}



# Positional Encoding
- [[大语言模型学习/Positional Encoding位置编码/介绍\|介绍]]
- [[大语言模型学习/Positional Encoding位置编码/绝对位置编码/Transformer绝对位置编码详解与改进分析\|Transformer绝对位置编码详解与改进分析]]
- [[大语言模型学习/Positional Encoding位置编码/绝对位置编码/BERT与RNN位置编码的对比与应用\|BERT与RNN位置编码的对比与应用]]
- [[大语言模型学习/Positional Encoding位置编码/相对位置编码/相对位置编码与XLNet位置编码详解 深入理解Transformer机制\|相对位置编码与XLNet位置编码详解 深入理解Transformer机制]]
- [[大语言模型学习/Positional Encoding位置编码/相对位置编码/T5模型与相对位置编码优化解析\|T5模型与相对位置编码优化解析]]
- [[大语言模型学习/Positional Encoding位置编码/相对位置编码/DeBERTa的相对位置编码与绝对位置编码解析\|DeBERTa的相对位置编码与绝对位置编码解析]]
- [[大语言模型学习/Positional Encoding位置编码/旋转位置编码与ALiBi：深度学习中的位置嵌入优化\|旋转位置编码与ALiBi：深度学习中的位置嵌入优化]]
- [[大语言模型学习/Positional Encoding位置编码/数字输入优化与外推方法解析\|数字输入优化与外推方法解析]]
- [[大语言模型学习/Positional Encoding位置编码/位置内插法扩展语言模型上下文长度\|位置内插法扩展语言模型上下文长度]]
- [[大语言模型学习/Positional Encoding位置编码/NTK插值方法解析与优化：从NTK-aware到NTK-by-parts\|NTK插值方法解析与优化：从NTK-aware到NTK-by-parts]]
- [[大语言模型学习/Positional Encoding位置编码/YaRN方法解析：扩展RoPE嵌入与注意力优化的实践\|YaRN方法解析：扩展RoPE嵌入与注意力优化的实践]]

{ .block-language-dataview}



# Structure & Decoding Policy 结构和解码策略
- [[大语言模型学习/Structure & Decoding Policy 结构和解码策略/大模型结构与混合专家（LLM & MoE）解析\|大模型结构与混合专家（LLM & MoE）解析]]
- [[大语言模型学习/Structure & Decoding Policy 结构和解码策略/解码采样策略：Greedy Search与Beam Search的实现与优化\|解码采样策略：Greedy Search与Beam Search的实现与优化]]
- [[大语言模型学习/Structure & Decoding Policy 结构和解码策略/深度解析语言模型采样方法：Top-K、Top-P、Temperature及综合策略\|深度解析语言模型采样方法：Top-K、Top-P、Temperature及综合策略]]

{ .block-language-dataview}



# Pre-training 预训练
- [[大语言模型学习/Pre-training 预训练/预训练定义以及数据来源\|预训练定义以及数据来源]]
- [[大语言模型学习/Pre-training 预训练/数据爬取\|数据爬取]]
- [[大语言模型学习/Pre-training 预训练/数据清洗\|数据清洗]]
- [[大语言模型学习/Pre-training 预训练/模型打分与数据去重\|模型打分与数据去重]]
- [[大语言模型学习/Pre-training 预训练/数据多样性与模型优化探索\|数据多样性与模型优化探索]]
- [[大语言模型学习/Pre-training 预训练/数据配比与训练顺序优化指南\|数据配比与训练顺序优化指南]]
- [[大语言模型学习/Pre-training 预训练/预训练过程/训练Tokenizer\|训练Tokenizer]]
- [[大语言模型学习/Pre-training 预训练/预训练过程/高效深度学习模型训练框架选择与优化指南\|高效深度学习模型训练框架选择与优化指南]]
- [[大语言模型学习/Pre-training 预训练/预训练过程/预训练策略\|预训练策略]]
- [[大语言模型学习/Pre-training 预训练/训练容灾及训练监控\|训练容灾及训练监控]]
- [[大语言模型学习/Pre-training 预训练/预训练过程/预训练的Scaling Law\|预训练的Scaling Law]]
- [[大语言模型学习/Pre-training 预训练/混合精度训练\|混合精度训练]]
- [[大语言模型学习/Pre-training 预训练/深度学习中的显存优化与梯度处理方法\|深度学习中的显存优化与梯度处理方法]]
- [[大语言模型学习/Pre-training 预训练/继续预训练\|继续预训练]]
- [[大语言模型学习/Pre-training 预训练/推理耗时\|推理耗时]]
- [[大语言模型学习/Pre-training 预训练/预训练评估\|预训练评估]]
- [[大语言模型学习/Pre-training 预训练/预训练评估2\|预训练评估2]]

{ .block-language-dataview}



# 后训练
- [[大语言模型学习/后训练/SFT监督微调/监督微调与预训练的区别\|监督微调与预训练的区别]]
- [[大语言模型学习/后训练/SFT监督微调/SFT数据及处理/数据飞轮在SFT中的应用与优化\|数据飞轮在SFT中的应用与优化]]
- [[大语言模型学习/后训练/SFT监督微调/SFT数据及处理/数据生产合成与质量过滤\|数据生产合成与质量过滤]]
- [[大语言模型学习/后训练/SFT监督微调/SFT数据及处理/数据多样性探索\|数据多样性探索]]
- [[大语言模型学习/后训练/SFT监督微调/SFT数据及处理/开源数据集\|开源数据集]]
- [[大语言模型学习/后训练/SFT监督微调/STF训练/训练框架及参数设置\|训练框架及参数设置]]
- [[大语言模型学习/后训练/SFT监督微调/STF训练/训练技巧和训练策略\|训练技巧和训练策略]]
- [[大语言模型学习/后训练/SFT监督微调/STF训练/多轮对话专项提升\|多轮对话专项提升]]
- [[大语言模型学习/后训练/SFT监督微调/STF训练/多轮对话专项提升2\|多轮对话专项提升2]]
- [[大语言模型学习/后训练/SFT监督微调/STF训练/训练启动脚本\|训练启动脚本]]

{ .block-language-dataview}



# 强化学习基础
- [[大语言模型学习/RL强化学习基础/强化学习问题,流程\|强化学习问题,流程]]
- [[大语言模型学习/RL强化学习基础/强化学习的独特性\|强化学习的独特性]]
- [[大语言模型学习/RL强化学习基础/马尔可夫决策过程\|马尔可夫决策过程]]
- [[大语言模型学习/RL强化学习基础/贝尔曼方程\|贝尔曼方程]]
- [[大语言模型学习/RL强化学习基础/蒙特卡洛方法\|蒙特卡洛方法]]
- [[大语言模型学习/RL强化学习基础/策略迭代算法\|策略迭代算法]]
- [[大语言模型学习/RL强化学习基础/价值迭代算法\|价值迭代算法]]
- [[大语言模型学习/RL强化学习基础/时序差分算法\|时序差分算法]]
- [[大语言模型学习/RL强化学习基础/SARSA算法\|SARSA算法]]
- [[大语言模型学习/RL强化学习基础/SARSA-λ与Q-learning对比\|SARSA-λ与Q-learning对比]]
- [[大语言模型学习/RL强化学习基础/强化学习分类\|强化学习分类]]
- [[大语言模型学习/RL强化学习基础/深度Q网络\|深度Q网络]]
- [[大语言模型学习/RL强化学习基础/策略梯度算法\|策略梯度算法]]
- [[大语言模型学习/RL强化学习基础/Actor-Critic算法\|Actor-Critic算法]]
- [[大语言模型学习/RL强化学习基础/PPO算法\|PPO算法]]
- [[大语言模型学习/RL强化学习基础/RL在NLP场景下的拓展\|RL在NLP场景下的拓展]]
- [[大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/RL在NLP场景下的拓展\|RL在NLP场景下的拓展]]
- [[大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/RLHF流程\|RLHF流程]]
- [[大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/RLHF研究方法及研究总结\|RLHF研究方法及研究总结]]
- [[大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/Instruct-GPT\|Instruct-GPT]]
- [[大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/Actor-Model\|Actor-Model]]
- [[大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/critic-model\|critic-model]]
- [[大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/Reward-Model\|Reward-Model]]
- [[大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/深入理解Prompt到Response的MDP模型分析\|深入理解Prompt到Response的MDP模型分析]]
- [[大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/Reference-Model\|Reference-Model]]
- [[大语言模型学习/RL强化学习基础/RLHF基于人类反馈的强化学习/在线与离线RLHF的比较与应用\|在线与离线RLHF的比较与应用]]
- [[大语言模型学习/RL强化学习基础/PPO训练的trick和问题\|PPO训练的trick和问题]]
- [[大语言模型学习/RL强化学习基础/优化PPO方向的算法/GRPO\|GRPO]]
- [[大语言模型学习/RL强化学习基础/优化PPO方向的算法/ReMax-improvement\|ReMax-improvement]]
- [[大语言模型学习/RL强化学习基础/优化PPO方向的算法/ReMax\|ReMax]]
- [[大语言模型学习/RL强化学习基础/优化PPO方向的算法/REINFORCE算法改进：RLOO与REINFORCE++\|REINFORCE算法改进：RLOO与REINFORCE++]]
- [[大语言模型学习/RL强化学习基础/优化PPO方向的算法/DAPO\|DAPO]]
- [[大语言模型学习/RL强化学习基础/优化PPO方向的算法/VAPO\|VAPO]]
- [[大语言模型学习/RL强化学习基础/DPO直接偏好优化/DPO介绍及RLHF-PPO缺点\|DPO介绍及RLHF-PPO缺点]]
- [[大语言模型学习/RL强化学习基础/DPO直接偏好优化/DPO公式推导\|DPO公式推导]]
- [[大语言模型学习/RL强化学习基础/DPO直接偏好优化/深度偏好优化（DPO）损失函数解析与代码示例\|深度偏好优化（DPO）损失函数解析与代码示例]]
- [[大语言模型学习/RL强化学习基础/DPO直接偏好优化/人类建模偏好角度理解DPO\|人类建模偏好角度理解DPO]]
- [[大语言模型学习/RL强化学习基础/DPO直接偏好优化/对比学习角度理解DPO\|对比学习角度理解DPO]]
- [[大语言模型学习/RL强化学习基础/优化DPO方向的算法/DPOP\|DPOP]]
- [[大语言模型学习/RL强化学习基础/优化DPO方向的算法/TDPO\|TDPO]]
- [[大语言模型学习/RL强化学习基础/优化DPO方向的算法/Self-Reward\|Self-Reward]]
- [[大语言模型学习/RL强化学习基础/PEFT参数高效微调/介绍\|介绍]]
- [[大语言模型学习/RL强化学习基础/PEFT参数高效微调/Prompt Tuning\|Prompt Tuning]]
- [[大语言模型学习/RL强化学习基础/PEFT参数高效微调/P-Tuning\|P-Tuning]]
- [[大语言模型学习/RL强化学习基础/PEFT参数高效微调/Prefix-Tuning\|Prefix-Tuning]]
- [[大语言模型学习/RL强化学习基础/PEFT参数高效微调/P-Tuning V2\|P-Tuning V2]]
- [[大语言模型学习/RL强化学习基础/PEFT参数高效微调/LLaMA-Adapter\|LLaMA-Adapter]]
- [[大语言模型学习/RL强化学习基础/LoRA及其变体/LoRA\|LoRA]]
- [[大语言模型学习/RL强化学习基础/LoRA及其变体/QLoRA\|QLoRA]]
- [[大语言模型学习/RL强化学习基础/LoRA及其变体/LoRA+\|LoRA+]]
- [[大语言模型学习/RL强化学习基础/LoRA及其变体/VeRA\|VeRA]]
- [[大语言模型学习/RL强化学习基础/LoRA及其变体/LoRA-FA\|LoRA-FA]]
- [[大语言模型学习/RL强化学习基础/LoRA及其变体/AdaLoRA\|AdaLoRA]]
- [[大语言模型学习/RL强化学习基础/LoRA及其变体/DoRA\|DoRA]]
- [[大语言模型学习/RL强化学习基础/LoRA及其变体/X-LoRA\|X-LoRA]]
- [[大语言模型学习/RL强化学习基础/LoRA及其变体/参考文献\|参考文献]]

{ .block-language-dataview}



# Common Models
- [[大语言模型学习/Common Models常见模型/发展历史\|发展历史]]
- [[大语言模型学习/Common Models常见模型/BERT及其变体/介绍\|介绍]]
- [[大语言模型学习/Common Models常见模型/BERT及其变体/BART\|BART]]
- [[大语言模型学习/Common Models常见模型/BERT及其变体/T5\|T5]]
- [[大语言模型学习/Common Models常见模型/BERT及其变体/DeBERTa\|DeBERTa]]
- [[大语言模型学习/Common Models常见模型/BERT及其变体/RoBERTa\|RoBERTa]]
- [[大语言模型学习/Common Models常见模型/BERT及其变体/未命名 1\|未命名 1]]
- [[大语言模型学习/Common Models常见模型/PLaM系列/PLaM\|PLaM]]
- [[大语言模型学习/Common Models常见模型/PLaM系列/PLaM2\|PLaM2]]
- [[大语言模型学习/Common Models常见模型/GPT系列/GPT-1\|GPT-1]]
- [[大语言模型学习/Common Models常见模型/GPT系列/GPT-2\|GPT-2]]
- [[大语言模型学习/Common Models常见模型/GPT系列/GPT-3\|GPT-3]]
- [[大语言模型学习/Common Models常见模型/LLama系列/LLaMA1\|LLaMA1]]
- [[大语言模型学习/Common Models常见模型/LLama系列/LLama 2\|LLama 2]]
- [[大语言模型学习/Common Models常见模型/LLama系列/CodeLlama\|CodeLlama]]
- [[大语言模型学习/Common Models常见模型/LLama系列/LLama 3\|LLama 3]]
- [[大语言模型学习/Common Models常见模型/GLM系列/GLM1\|GLM1]]
- [[大语言模型学习/Common Models常见模型/GLM系列/GLM2\|GLM2]]
- [[大语言模型学习/Common Models常见模型/GLM系列/GLM3\|GLM3]]
- [[大语言模型学习/Common Models常见模型/GLM系列/GLM4\|GLM4]]
- [[大语言模型学习/Common Models常见模型/Qwen系列/Qwen1\|Qwen1]]
- [[大语言模型学习/Common Models常见模型/Qwen系列/Qwen2\|Qwen2]]
- [[大语言模型学习/Common Models常见模型/Qwen系列/Qwen2.5\|Qwen2.5]]
- [[大语言模型学习/Common Models常见模型/DeepSeek系列/Deepseek-V1\|Deepseek-V1]]
- [[大语言模型学习/Common Models常见模型/DeepSeek系列/Deepseek-math\|Deepseek-math]]
- [[大语言模型学习/Common Models常见模型/DeepSeek系列/DeepSeek-V2\|DeepSeek-V2]]
- [[大语言模型学习/Common Models常见模型/DeepSeek系列/DeepSeek-V3\|DeepSeek-V3]]
- [[大语言模型学习/Common Models常见模型/DeepSeek系列/DeepSeek-R1\|DeepSeek-R1]]
- [[大语言模型学习/Common Models常见模型/MOE系列/GShard\|GShard]]
- [[大语言模型学习/Common Models常见模型/MOE系列/Mistral\|Mistral]]
- [[大语言模型学习/Common Models常见模型/MOE系列/Switch Transformer\|Switch Transformer]]

{ .block-language-dataview}



# 训练推理优化
- [[大语言模型学习/训练推理优化/训练推理显存占用分析/模型显存总体分析\|模型显存总体分析]]
- [[大语言模型学习/训练推理优化/训练推理显存占用分析/训练阶段的显存分析\|训练阶段的显存分析]]
- [[大语言模型学习/训练推理优化/训练推理显存占用分析/显存优化与推理显存分析\|显存优化与推理显存分析]]
- [[大语言模型学习/训练推理优化/FlashAttention/介绍\|介绍]]
- [[大语言模型学习/训练推理优化/FlashAttention/计算与内存限制\|计算与内存限制]]
- [[大语言模型学习/训练推理优化/FlashAttention/标准Attention与Safe softmax\|标准Attention与Safe softmax]]
- [[大语言模型学习/训练推理优化/FlashAttention/FlashAttention Forword流程\|FlashAttention Forword流程]]
- [[大语言模型学习/训练推理优化/PageAttention原理\|PageAttention原理]]
- [[大语言模型学习/训练推理优化/训练框架/Megatron-LM\|Megatron-LM]]
- [[大语言模型学习/训练推理优化/训练框架/DeepSpeed\|DeepSpeed]]
- [[大语言模型学习/训练推理优化/训练框架/X-ray\|X-ray]]
- [[大语言模型学习/训练推理优化/训练框架/Accelerate\|Accelerate]]
- [[大语言模型学习/训练推理优化/训练框架/Megatron和DeepSpeed后端实现的区别\|Megatron和DeepSpeed后端实现的区别]]
- [[大语言模型学习/训练推理优化/推理框架/vLLM\|vLLM]]
- [[大语言模型学习/训练推理优化/推理框架/HuggingFace TGI\|HuggingFace TGI]]
- [[大语言模型学习/训练推理优化/推理耗时及优化/推理耗时\|推理耗时]]
- [[大语言模型学习/训练推理优化/推理耗时及优化/首Token时延优化\|首Token时延优化]]
- [[大语言模型学习/训练推理优化/大模型的packing技巧\|大模型的packing技巧]]

{ .block-language-dataview}



# 模型压缩
- [[大语言模型学习/模型压缩/介绍\|介绍]]
- [[大语言模型学习/模型压缩/模型量化\|模型量化]]
- [[大语言模型学习/模型压缩/模型剪枝\|模型剪枝]]
- [[大语言模型学习/模型压缩/Knowledge Distillation 知识蒸馏\|Knowledge Distillation 知识蒸馏]]
- [[大语言模型学习/模型压缩/Low-Rank Factorization 低秩分解\|Low-Rank Factorization 低秩分解]]

{ .block-language-dataview}



# 大模型应用
- [[大语言模型学习/大模型应用/Prompt Tech 提示技术\|Prompt Tech 提示技术]]
- [[大语言模型学习/大模型应用/LLM-based Agent 基于大模型的智能体/定义以及历史发展\|定义以及历史发展]]
- [[大语言模型学习/大模型应用/LLM-based Agent 基于大模型的智能体/基于大模型的智能体原理\|基于大模型的智能体原理]]
- [[大语言模型学习/大模型应用/LLM-based Agent 基于大模型的智能体/智能体的分类\|智能体的分类]]
- [[大语言模型学习/大模型应用/LLM-based Agent 基于大模型的智能体/智能体系统分类\|智能体系统分类]]
- [[大语言模型学习/大模型应用/LLM-based Agent 基于大模型的智能体/智能体的框架和应用\|智能体的框架和应用]]
- [[大语言模型学习/大模型应用/LLM-based Agent 基于大模型的智能体/Agent评估框架汇总\|Agent评估框架汇总]]
- [[大语言模型学习/大模型应用/RAG检索增强生成/RAG流程和分类\|RAG流程和分类]]
- [[大语言模型学习/大模型应用/RAG检索增强生成/RAG评估\|RAG评估]]
- [[大语言模型学习/大模型应用/RAG检索增强生成/RAG优化\|RAG优化]]
- [[大语言模型学习/大模型应用/RAG检索增强生成/固定长度分块\|固定长度分块]]
- [[大语言模型学习/大模型应用/RAG检索增强生成/基于语义分块\|基于语义分块]]
- [[大语言模型学习/大模型应用/RAG检索增强生成/基于文档结构分块\|基于文档结构分块]]
- [[大语言模型学习/大模型应用/RAG检索增强生成/基于大模型的分块\|基于大模型的分块]]
- [[大语言模型学习/大模型应用/RAG检索增强生成/RAG优化中查询索引阶段\|RAG优化中查询索引阶段]]
- [[大语言模型学习/大模型应用/RAG检索增强生成/查询索引阶段\|查询索引阶段]]
- [[大语言模型学习/大模型应用/RAG检索增强生成/RAG方向\|RAG方向]]
- [[大语言模型学习/大模型应用/RAG检索增强生成/常见索引优化算法实现\|常见索引优化算法实现]]

{ .block-language-dataview}
