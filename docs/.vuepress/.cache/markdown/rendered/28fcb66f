{"content":"<h3 id=\"推理机制\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#推理机制\"><span>推理机制</span></a></h3>\n<h4 id=\"传统推理方式\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#传统推理方式\"><span>传统推理方式：</span></a></h4>\n<p>逐 token 生成，无法并行。</p>\n<h4 id=\"过程建模两种方式\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#过程建模两种方式\"><span>过程建模两种方式：</span></a></h4>\n<ol>\n<li>矩阵-向量乘法：一个大矩阵（例如 <span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>8192</mn><mo>×</mo><mn>8192</mn></mrow><annotation encoding=\"application/x-tex\">8192 \\times 8192</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">8192</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">8192</span></span></span></span>）乘以一个向量，得到另一个向量。</li>\n<li>Attention 计算：利用 KV-cache 进行推理。</li>\n</ol>\n<h4 id=\"瓶颈分析-浮点运算的主要来源\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#瓶颈分析-浮点运算的主要来源\"><span>瓶颈分析：浮点运算的主要来源</span></a></h4>\n<ul>\n<li>矩阵-向量乘法对每个矩阵元素执行一次乘加运算（2 FLOPs）。</li>\n<li>Attention 对每个 key 执行一次乘加，对每个 value 执行一次乘加。</li>\n</ul>\n<h3 id=\"时延计算\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#时延计算\"><span>时延计算</span></a></h3>\n<h4 id=\"计算一个-token-所需要的数据量\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#计算一个-token-所需要的数据量\"><span>计算一个 token 所需要的数据量</span></a></h4>\n<p>在 NVIDIA RTX 4090（1008 GB/s）上，14.2GB (fp16) 需要约 14.1ms 读取，因此可以预期对于位置靠前的 token，每个 token 大约需要 14.1ms（KV-cache 影响可以忽略不计）。如果使用 8bit 权重，需要读取 7.1GB，这需要大约 7.0ms。这些都是理论下限，代表了生成每个 token 的最小可能时间。</p>\n<p>参考来源：《LLM inference speed of light》</p>\n<p>通俗来说，模型的预测时间可以近似理解为：</p>\n<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>y</mi><mo>=</mo><mi>k</mi><mo>⋅</mo><mi>x</mi><mo>+</mo><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">y = k \\cdot x + b\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">b</span></span></span></span></span></p>\n<p>其中 <span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">b</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">b</span></span></span></span> 是首个 token 的耗时，<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span> 是后续每个 token 的耗时，<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">x</span></span></span></span> 是生成 token 的总数量。更具体的，<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">b</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">b</span></span></span></span> 会是 <span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span> 的十几倍或更多，和 prompt 的长度几乎呈正相关。这个耗时的近似估算和 KV-cache 机制有关，不熟悉的可以自行搜索。</p>\n<p>这也就是为什么众人都知 CoT 效果好，众人又都不使用 CoT（但是现在 o1、R1 的大模型推理增强还是需要很多 CoT 数据的），因为我们可以几乎下断言“模型的生成速度和生成 token 数量呈正相关”，而 CoT 恰恰又引入了大量的生成 token。</p>\n<h3 id=\"推理-tps-计算\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#推理-tps-计算\"><span>推理 TPS 计算</span></a></h3>\n<h4 id=\"如何计算-tps\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#如何计算-tps\"><span>如何计算 TPS？</span></a></h4>\n<p>部署 LLM 时，每秒生成的 token 数量 TPS（Tokens Per Second）是衡量推理性能的重要指标：</p>\n<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>T</mi><mi>P</mi><mi>S</mi><mo>=</mo><mfrac><mtext>生成的 token 总数</mtext><mtext>总延迟时间（秒）</mtext></mfrac></mrow><annotation encoding=\"application/x-tex\">TPS = \\frac{\\text{生成的 token 总数}}{\\text{总延迟时间（秒）}}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">TPS</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.0574em;vertical-align:-0.686em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3714em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord text\"><span class=\"mord cjk_fallback\">总延迟时间（秒）</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord text\"><span class=\"mord cjk_fallback\">生成的</span><span class=\"mord\"> token </span><span class=\"mord cjk_fallback\">总数</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>总延迟时间包括两个阶段：</p>\n<ul>\n<li>TTFT（Time To First Token）：从输入到生成第一个 token 的延迟时间，主要受 prompt 长度和模型结构影响，也就是在 Prefilling 阶段。</li>\n<li>TPOT（Time Per Output Token）：生成每个后续 token 所需的平均时间，也就是在 Decoding 阶段。</li>\n</ul>\n<p>总延迟可表示为：</p>\n<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>Latency</mtext><mo>=</mo><mtext>TTFT</mtext><mo>+</mo><mtext>TPOT</mtext><mo>×</mo><mtext>输出 token 数量</mtext></mrow><annotation encoding=\"application/x-tex\">\\text{Latency} = \\text{TTFT} + \\text{TPOT} \\times \\text{输出 token 数量}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord text\"><span class=\"mord\">Latency</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord text\"><span class=\"mord\">TTFT</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord text\"><span class=\"mord\">TPOT</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">输出</span><span class=\"mord\"> token </span><span class=\"mord cjk_fallback\">数量</span></span></span></span></span></span></p>\n<p>所以 TPS 可以表示为：</p>\n<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>T</mi><mi>P</mi><mi>S</mi><mo>=</mo><mfrac><mtext>输出 token 数量</mtext><mrow><mtext>TTFT</mtext><mo>+</mo><mtext>TPOT</mtext><mo>×</mo><mtext>输出 token 数量</mtext></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">TPS = \\frac{\\text{输出 token 数量}}{\\text{TTFT} + \\text{TPOT} \\times \\text{输出 token 数量}}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">TPS</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.1408em;vertical-align:-0.7693em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3714em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord text\"><span class=\"mord\">TTFT</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord text\"><span class=\"mord\">TPOT</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">输出</span><span class=\"mord\"> token </span><span class=\"mord cjk_fallback\">数量</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord text\"><span class=\"mord cjk_fallback\">输出</span><span class=\"mord\"> token </span><span class=\"mord cjk_fallback\">数量</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7693em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<h3 id=\"tps-估算方法\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#tps-估算方法\"><span>TPS 估算方法</span></a></h3>\n<ol>\n<li>\n<p>确定模型参数量：<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi><mi>B</mi></mrow><annotation encoding=\"application/x-tex\">X B</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">XB</span></span></span></span></p>\n</li>\n<li>\n<p>计算 Prefilling 阶段的 FLOPs：</p>\n<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>FLOPs prefill</mtext><mo>=</mo><mn>2</mn><mo>×</mo><mtext>Batch Size</mtext><mo>×</mo><mtext>Prompt Length</mtext><mo>×</mo><mtext>模型参数量</mtext></mrow><annotation encoding=\"application/x-tex\">\\text{FLOPs prefill} = 2 \\times \\text{Batch Size} \\times \\text{Prompt Length} \\times \\text{模型参数量}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\"><span class=\"mord\">FLOPs prefill</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7778em;vertical-align:-0.0833em;\"></span><span class=\"mord text\"><span class=\"mord\">Batch Size</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\"><span class=\"mord\">Prompt Length</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">模型参数量</span></span></span></span></span></span></p>\n</li>\n<li>\n<p>计算 Decoding 阶段的 FLOPs：\n使用公式：</p>\n<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>FLOPs decoding</mtext><mo>=</mo><mn>2</mn><mo>×</mo><mtext>Batch size</mtext><mo>×</mo><mtext>Completion Size</mtext><mo>×</mo><mtext>模型参数量</mtext></mrow><annotation encoding=\"application/x-tex\">\\text{FLOPs decoding} = 2 \\times \\text{Batch size} \\times \\text{Completion Size} \\times \\text{模型参数量}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\"><span class=\"mord\">FLOPs decoding</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7778em;vertical-align:-0.0833em;\"></span><span class=\"mord text\"><span class=\"mord\">Batch size</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\"><span class=\"mord\">Completion Size</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">模型参数量</span></span></span></span></span></span></p>\n</li>\n</ol>\n<p>通过以上分析，我们可以更好地理解推理过程中各个阶段的性能瓶颈，并针对性地进行优化，以提升模型的推理效率。</p>\n","env":{"base":"/","filePath":"/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/训练推理优化/推理耗时及优化/推理耗时.md","filePathRelative":"notes_bak/大语言模型学习/训练推理优化/推理耗时及优化/推理耗时.md","frontmatter":{"dg-publish":true,"dg-permalink":"/大语言模型学习/训练推理优化/推理耗时及优化/推理耗时","dg-home":false,"dg-description":"在此输入笔记的描述","dg-hide":false,"dg-hide-title":false,"dg-show-backlinks":true,"dg-show-local-graph":true,"dg-show-inline-title":true,"dg-pinned":false,"dg-passphrase":"在此输入访问密码","dg-enable-mathjax":false,"dg-enable-mermaid":false,"dg-enable-uml":false,"dg-note-icon":0,"dg-enable-dataview":false,"tags":["NLP"],"permalink":"/大语言模型学习/训练推理优化/推理耗时及优化/推理耗时/","dgShowBacklinks":true,"dgShowLocalGraph":true,"dgShowInlineTitle":true,"dgPassFrontmatter":true,"noteIcon":0,"created":"2025-04-30T14:32:46.000Z","updated":"2025-05-06T02:29:38.000Z","title":"推理耗时","createTime":"2025/05/13 17:33:53"},"sfcBlocks":{"template":{"type":"template","content":"<template><h3 id=\"推理机制\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#推理机制\"><span>推理机制</span></a></h3>\n<h4 id=\"传统推理方式\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#传统推理方式\"><span>传统推理方式：</span></a></h4>\n<p>逐 token 生成，无法并行。</p>\n<h4 id=\"过程建模两种方式\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#过程建模两种方式\"><span>过程建模两种方式：</span></a></h4>\n<ol>\n<li>矩阵-向量乘法：一个大矩阵（例如 <span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>8192</mn><mo>×</mo><mn>8192</mn></mrow><annotation encoding=\"application/x-tex\">8192 \\times 8192</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">8192</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">8192</span></span></span></span>）乘以一个向量，得到另一个向量。</li>\n<li>Attention 计算：利用 KV-cache 进行推理。</li>\n</ol>\n<h4 id=\"瓶颈分析-浮点运算的主要来源\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#瓶颈分析-浮点运算的主要来源\"><span>瓶颈分析：浮点运算的主要来源</span></a></h4>\n<ul>\n<li>矩阵-向量乘法对每个矩阵元素执行一次乘加运算（2 FLOPs）。</li>\n<li>Attention 对每个 key 执行一次乘加，对每个 value 执行一次乘加。</li>\n</ul>\n<h3 id=\"时延计算\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#时延计算\"><span>时延计算</span></a></h3>\n<h4 id=\"计算一个-token-所需要的数据量\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#计算一个-token-所需要的数据量\"><span>计算一个 token 所需要的数据量</span></a></h4>\n<p>在 NVIDIA RTX 4090（1008 GB/s）上，14.2GB (fp16) 需要约 14.1ms 读取，因此可以预期对于位置靠前的 token，每个 token 大约需要 14.1ms（KV-cache 影响可以忽略不计）。如果使用 8bit 权重，需要读取 7.1GB，这需要大约 7.0ms。这些都是理论下限，代表了生成每个 token 的最小可能时间。</p>\n<p>参考来源：《LLM inference speed of light》</p>\n<p>通俗来说，模型的预测时间可以近似理解为：</p>\n<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>y</mi><mo>=</mo><mi>k</mi><mo>⋅</mo><mi>x</mi><mo>+</mo><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">y = k \\cdot x + b\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">b</span></span></span></span></span></p>\n<p>其中 <span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">b</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">b</span></span></span></span> 是首个 token 的耗时，<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span> 是后续每个 token 的耗时，<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">x</span></span></span></span> 是生成 token 的总数量。更具体的，<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">b</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">b</span></span></span></span> 会是 <span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span> 的十几倍或更多，和 prompt 的长度几乎呈正相关。这个耗时的近似估算和 KV-cache 机制有关，不熟悉的可以自行搜索。</p>\n<p>这也就是为什么众人都知 CoT 效果好，众人又都不使用 CoT（但是现在 o1、R1 的大模型推理增强还是需要很多 CoT 数据的），因为我们可以几乎下断言“模型的生成速度和生成 token 数量呈正相关”，而 CoT 恰恰又引入了大量的生成 token。</p>\n<h3 id=\"推理-tps-计算\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#推理-tps-计算\"><span>推理 TPS 计算</span></a></h3>\n<h4 id=\"如何计算-tps\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#如何计算-tps\"><span>如何计算 TPS？</span></a></h4>\n<p>部署 LLM 时，每秒生成的 token 数量 TPS（Tokens Per Second）是衡量推理性能的重要指标：</p>\n<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>T</mi><mi>P</mi><mi>S</mi><mo>=</mo><mfrac><mtext>生成的 token 总数</mtext><mtext>总延迟时间（秒）</mtext></mfrac></mrow><annotation encoding=\"application/x-tex\">TPS = \\frac{\\text{生成的 token 总数}}{\\text{总延迟时间（秒）}}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">TPS</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.0574em;vertical-align:-0.686em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3714em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord text\"><span class=\"mord cjk_fallback\">总延迟时间（秒）</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord text\"><span class=\"mord cjk_fallback\">生成的</span><span class=\"mord\"> token </span><span class=\"mord cjk_fallback\">总数</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>总延迟时间包括两个阶段：</p>\n<ul>\n<li>TTFT（Time To First Token）：从输入到生成第一个 token 的延迟时间，主要受 prompt 长度和模型结构影响，也就是在 Prefilling 阶段。</li>\n<li>TPOT（Time Per Output Token）：生成每个后续 token 所需的平均时间，也就是在 Decoding 阶段。</li>\n</ul>\n<p>总延迟可表示为：</p>\n<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>Latency</mtext><mo>=</mo><mtext>TTFT</mtext><mo>+</mo><mtext>TPOT</mtext><mo>×</mo><mtext>输出 token 数量</mtext></mrow><annotation encoding=\"application/x-tex\">\\text{Latency} = \\text{TTFT} + \\text{TPOT} \\times \\text{输出 token 数量}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord text\"><span class=\"mord\">Latency</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord text\"><span class=\"mord\">TTFT</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord text\"><span class=\"mord\">TPOT</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">输出</span><span class=\"mord\"> token </span><span class=\"mord cjk_fallback\">数量</span></span></span></span></span></span></p>\n<p>所以 TPS 可以表示为：</p>\n<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>T</mi><mi>P</mi><mi>S</mi><mo>=</mo><mfrac><mtext>输出 token 数量</mtext><mrow><mtext>TTFT</mtext><mo>+</mo><mtext>TPOT</mtext><mo>×</mo><mtext>输出 token 数量</mtext></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">TPS = \\frac{\\text{输出 token 数量}}{\\text{TTFT} + \\text{TPOT} \\times \\text{输出 token 数量}}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">TPS</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.1408em;vertical-align:-0.7693em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3714em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord text\"><span class=\"mord\">TTFT</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord text\"><span class=\"mord\">TPOT</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">输出</span><span class=\"mord\"> token </span><span class=\"mord cjk_fallback\">数量</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord text\"><span class=\"mord cjk_fallback\">输出</span><span class=\"mord\"> token </span><span class=\"mord cjk_fallback\">数量</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7693em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<h3 id=\"tps-估算方法\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#tps-估算方法\"><span>TPS 估算方法</span></a></h3>\n<ol>\n<li>\n<p>确定模型参数量：<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi><mi>B</mi></mrow><annotation encoding=\"application/x-tex\">X B</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">XB</span></span></span></span></p>\n</li>\n<li>\n<p>计算 Prefilling 阶段的 FLOPs：</p>\n<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>FLOPs prefill</mtext><mo>=</mo><mn>2</mn><mo>×</mo><mtext>Batch Size</mtext><mo>×</mo><mtext>Prompt Length</mtext><mo>×</mo><mtext>模型参数量</mtext></mrow><annotation encoding=\"application/x-tex\">\\text{FLOPs prefill} = 2 \\times \\text{Batch Size} \\times \\text{Prompt Length} \\times \\text{模型参数量}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\"><span class=\"mord\">FLOPs prefill</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7778em;vertical-align:-0.0833em;\"></span><span class=\"mord text\"><span class=\"mord\">Batch Size</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\"><span class=\"mord\">Prompt Length</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">模型参数量</span></span></span></span></span></span></p>\n</li>\n<li>\n<p>计算 Decoding 阶段的 FLOPs：\n使用公式：</p>\n<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>FLOPs decoding</mtext><mo>=</mo><mn>2</mn><mo>×</mo><mtext>Batch size</mtext><mo>×</mo><mtext>Completion Size</mtext><mo>×</mo><mtext>模型参数量</mtext></mrow><annotation encoding=\"application/x-tex\">\\text{FLOPs decoding} = 2 \\times \\text{Batch size} \\times \\text{Completion Size} \\times \\text{模型参数量}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\"><span class=\"mord\">FLOPs decoding</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7778em;vertical-align:-0.0833em;\"></span><span class=\"mord text\"><span class=\"mord\">Batch size</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\"><span class=\"mord\">Completion Size</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">模型参数量</span></span></span></span></span></span></p>\n</li>\n</ol>\n<p>通过以上分析，我们可以更好地理解推理过程中各个阶段的性能瓶颈，并针对性地进行优化，以提升模型的推理效率。</p>\n</template>","contentStripped":"<h3 id=\"推理机制\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#推理机制\"><span>推理机制</span></a></h3>\n<h4 id=\"传统推理方式\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#传统推理方式\"><span>传统推理方式：</span></a></h4>\n<p>逐 token 生成，无法并行。</p>\n<h4 id=\"过程建模两种方式\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#过程建模两种方式\"><span>过程建模两种方式：</span></a></h4>\n<ol>\n<li>矩阵-向量乘法：一个大矩阵（例如 <span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>8192</mn><mo>×</mo><mn>8192</mn></mrow><annotation encoding=\"application/x-tex\">8192 \\times 8192</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">8192</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">8192</span></span></span></span>）乘以一个向量，得到另一个向量。</li>\n<li>Attention 计算：利用 KV-cache 进行推理。</li>\n</ol>\n<h4 id=\"瓶颈分析-浮点运算的主要来源\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#瓶颈分析-浮点运算的主要来源\"><span>瓶颈分析：浮点运算的主要来源</span></a></h4>\n<ul>\n<li>矩阵-向量乘法对每个矩阵元素执行一次乘加运算（2 FLOPs）。</li>\n<li>Attention 对每个 key 执行一次乘加，对每个 value 执行一次乘加。</li>\n</ul>\n<h3 id=\"时延计算\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#时延计算\"><span>时延计算</span></a></h3>\n<h4 id=\"计算一个-token-所需要的数据量\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#计算一个-token-所需要的数据量\"><span>计算一个 token 所需要的数据量</span></a></h4>\n<p>在 NVIDIA RTX 4090（1008 GB/s）上，14.2GB (fp16) 需要约 14.1ms 读取，因此可以预期对于位置靠前的 token，每个 token 大约需要 14.1ms（KV-cache 影响可以忽略不计）。如果使用 8bit 权重，需要读取 7.1GB，这需要大约 7.0ms。这些都是理论下限，代表了生成每个 token 的最小可能时间。</p>\n<p>参考来源：《LLM inference speed of light》</p>\n<p>通俗来说，模型的预测时间可以近似理解为：</p>\n<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>y</mi><mo>=</mo><mi>k</mi><mo>⋅</mo><mi>x</mi><mo>+</mo><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">y = k \\cdot x + b\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">b</span></span></span></span></span></p>\n<p>其中 <span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">b</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">b</span></span></span></span> 是首个 token 的耗时，<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span> 是后续每个 token 的耗时，<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">x</span></span></span></span> 是生成 token 的总数量。更具体的，<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">b</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">b</span></span></span></span> 会是 <span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span> 的十几倍或更多，和 prompt 的长度几乎呈正相关。这个耗时的近似估算和 KV-cache 机制有关，不熟悉的可以自行搜索。</p>\n<p>这也就是为什么众人都知 CoT 效果好，众人又都不使用 CoT（但是现在 o1、R1 的大模型推理增强还是需要很多 CoT 数据的），因为我们可以几乎下断言“模型的生成速度和生成 token 数量呈正相关”，而 CoT 恰恰又引入了大量的生成 token。</p>\n<h3 id=\"推理-tps-计算\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#推理-tps-计算\"><span>推理 TPS 计算</span></a></h3>\n<h4 id=\"如何计算-tps\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#如何计算-tps\"><span>如何计算 TPS？</span></a></h4>\n<p>部署 LLM 时，每秒生成的 token 数量 TPS（Tokens Per Second）是衡量推理性能的重要指标：</p>\n<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>T</mi><mi>P</mi><mi>S</mi><mo>=</mo><mfrac><mtext>生成的 token 总数</mtext><mtext>总延迟时间（秒）</mtext></mfrac></mrow><annotation encoding=\"application/x-tex\">TPS = \\frac{\\text{生成的 token 总数}}{\\text{总延迟时间（秒）}}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">TPS</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.0574em;vertical-align:-0.686em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3714em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord text\"><span class=\"mord cjk_fallback\">总延迟时间（秒）</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord text\"><span class=\"mord cjk_fallback\">生成的</span><span class=\"mord\"> token </span><span class=\"mord cjk_fallback\">总数</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>总延迟时间包括两个阶段：</p>\n<ul>\n<li>TTFT（Time To First Token）：从输入到生成第一个 token 的延迟时间，主要受 prompt 长度和模型结构影响，也就是在 Prefilling 阶段。</li>\n<li>TPOT（Time Per Output Token）：生成每个后续 token 所需的平均时间，也就是在 Decoding 阶段。</li>\n</ul>\n<p>总延迟可表示为：</p>\n<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>Latency</mtext><mo>=</mo><mtext>TTFT</mtext><mo>+</mo><mtext>TPOT</mtext><mo>×</mo><mtext>输出 token 数量</mtext></mrow><annotation encoding=\"application/x-tex\">\\text{Latency} = \\text{TTFT} + \\text{TPOT} \\times \\text{输出 token 数量}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord text\"><span class=\"mord\">Latency</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord text\"><span class=\"mord\">TTFT</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord text\"><span class=\"mord\">TPOT</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">输出</span><span class=\"mord\"> token </span><span class=\"mord cjk_fallback\">数量</span></span></span></span></span></span></p>\n<p>所以 TPS 可以表示为：</p>\n<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>T</mi><mi>P</mi><mi>S</mi><mo>=</mo><mfrac><mtext>输出 token 数量</mtext><mrow><mtext>TTFT</mtext><mo>+</mo><mtext>TPOT</mtext><mo>×</mo><mtext>输出 token 数量</mtext></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">TPS = \\frac{\\text{输出 token 数量}}{\\text{TTFT} + \\text{TPOT} \\times \\text{输出 token 数量}}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">TPS</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.1408em;vertical-align:-0.7693em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3714em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord text\"><span class=\"mord\">TTFT</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord text\"><span class=\"mord\">TPOT</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">输出</span><span class=\"mord\"> token </span><span class=\"mord cjk_fallback\">数量</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord text\"><span class=\"mord cjk_fallback\">输出</span><span class=\"mord\"> token </span><span class=\"mord cjk_fallback\">数量</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7693em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<h3 id=\"tps-估算方法\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#tps-估算方法\"><span>TPS 估算方法</span></a></h3>\n<ol>\n<li>\n<p>确定模型参数量：<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi><mi>B</mi></mrow><annotation encoding=\"application/x-tex\">X B</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">XB</span></span></span></span></p>\n</li>\n<li>\n<p>计算 Prefilling 阶段的 FLOPs：</p>\n<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>FLOPs prefill</mtext><mo>=</mo><mn>2</mn><mo>×</mo><mtext>Batch Size</mtext><mo>×</mo><mtext>Prompt Length</mtext><mo>×</mo><mtext>模型参数量</mtext></mrow><annotation encoding=\"application/x-tex\">\\text{FLOPs prefill} = 2 \\times \\text{Batch Size} \\times \\text{Prompt Length} \\times \\text{模型参数量}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\"><span class=\"mord\">FLOPs prefill</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7778em;vertical-align:-0.0833em;\"></span><span class=\"mord text\"><span class=\"mord\">Batch Size</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\"><span class=\"mord\">Prompt Length</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">模型参数量</span></span></span></span></span></span></p>\n</li>\n<li>\n<p>计算 Decoding 阶段的 FLOPs：\n使用公式：</p>\n<p v-pre class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>FLOPs decoding</mtext><mo>=</mo><mn>2</mn><mo>×</mo><mtext>Batch size</mtext><mo>×</mo><mtext>Completion Size</mtext><mo>×</mo><mtext>模型参数量</mtext></mrow><annotation encoding=\"application/x-tex\">\\text{FLOPs decoding} = 2 \\times \\text{Batch size} \\times \\text{Completion Size} \\times \\text{模型参数量}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\"><span class=\"mord\">FLOPs decoding</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7778em;vertical-align:-0.0833em;\"></span><span class=\"mord text\"><span class=\"mord\">Batch size</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\"><span class=\"mord\">Completion Size</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord text\"><span class=\"mord cjk_fallback\">模型参数量</span></span></span></span></span></span></p>\n</li>\n</ol>\n<p>通过以上分析，我们可以更好地理解推理过程中各个阶段的性能瓶颈，并针对性地进行优化，以提升模型的推理效率。</p>\n","tagOpen":"<template>","tagClose":"</template>"},"script":null,"scriptSetup":null,"scripts":[],"styles":[],"customBlocks":[]},"content":"### 推理机制\n\n#### 传统推理方式：\n逐 token 生成，无法并行。\n\n\n#### 过程建模两种方式：\n1. 矩阵-向量乘法：一个大矩阵（例如 $8192 \\times 8192$）乘以一个向量，得到另一个向量。\n2. Attention 计算：利用 KV-cache 进行推理。\n\n\n#### 瓶颈分析：浮点运算的主要来源\n- 矩阵-向量乘法对每个矩阵元素执行一次乘加运算（2 FLOPs）。\n- Attention 对每个 key 执行一次乘加，对每个 value 执行一次乘加。\n\n\n\n### 时延计算\n\n#### 计算一个 token 所需要的数据量\n在 NVIDIA RTX 4090（1008 GB/s）上，14.2GB (fp16) 需要约 14.1ms 读取，因此可以预期对于位置靠前的 token，每个 token 大约需要 14.1ms（KV-cache 影响可以忽略不计）。如果使用 8bit 权重，需要读取 7.1GB，这需要大约 7.0ms。这些都是理论下限，代表了生成每个 token 的最小可能时间。\n\n参考来源：《LLM inference speed of light》\n\n通俗来说，模型的预测时间可以近似理解为：\n$$\ny = k \\cdot x + b\n$$\n\n其中 $b$ 是首个 token 的耗时，$k$ 是后续每个 token 的耗时，$x$ 是生成 token 的总数量。更具体的，$b$ 会是 $k$ 的十几倍或更多，和 prompt 的长度几乎呈正相关。这个耗时的近似估算和 KV-cache 机制有关，不熟悉的可以自行搜索。\n\n这也就是为什么众人都知 CoT 效果好，众人又都不使用 CoT（但是现在 o1、R1 的大模型推理增强还是需要很多 CoT 数据的），因为我们可以几乎下断言“模型的生成速度和生成 token 数量呈正相关”，而 CoT 恰恰又引入了大量的生成 token。\n\n\n\n### 推理 TPS 计算\n\n#### 如何计算 TPS？\n部署 LLM 时，每秒生成的 token 数量 TPS（Tokens Per Second）是衡量推理性能的重要指标：\n$$\nTPS = \\frac{\\text{生成的 token 总数}}{\\text{总延迟时间（秒）}}\n$$\n\n总延迟时间包括两个阶段：\n\n- TTFT（Time To First Token）：从输入到生成第一个 token 的延迟时间，主要受 prompt 长度和模型结构影响，也就是在 Prefilling 阶段。\n- TPOT（Time Per Output Token）：生成每个后续 token 所需的平均时间，也就是在 Decoding 阶段。\n\n总延迟可表示为：\n$$\n\\text{Latency} = \\text{TTFT} + \\text{TPOT} \\times \\text{输出 token 数量}\n$$\n\n所以 TPS 可以表示为：\n$$\nTPS = \\frac{\\text{输出 token 数量}}{\\text{TTFT} + \\text{TPOT} \\times \\text{输出 token 数量}}\n$$\n\n\n\n### TPS 估算方法\n1. 确定模型参数量：$X B$\n\n2. 计算 Prefilling 阶段的 FLOPs：\n   $$\n   \\text{FLOPs prefill} = 2 \\times \\text{Batch Size} \\times \\text{Prompt Length} \\times \\text{模型参数量}\n   $$\n\n3. 计算 Decoding 阶段的 FLOPs：\n   使用公式：\n   $$\n   \\text{FLOPs decoding} = 2 \\times \\text{Batch size} \\times \\text{Completion Size} \\times \\text{模型参数量}\n   $$\n\n通过以上分析，我们可以更好地理解推理过程中各个阶段的性能瓶颈，并针对性地进行优化，以提升模型的推理效率。","excerpt":"","includedFiles":[],"tasklistId":0,"title":"","headers":[{"level":3,"title":"推理机制","slug":"推理机制","link":"#推理机制","children":[]},{"level":3,"title":"时延计算","slug":"时延计算","link":"#时延计算","children":[]},{"level":3,"title":"推理 TPS 计算","slug":"推理-tps-计算","link":"#推理-tps-计算","children":[]},{"level":3,"title":"TPS 估算方法","slug":"tps-估算方法","link":"#tps-估算方法","children":[]}]}}
