{"content":"<p>元数据：</p>\n<ul>\n<li>分类：算法与优化</li>\n<li>标签：TDPO, KL约束, 强化学习, PPO, 前向KL</li>\n<li>日期：2025年4月12日</li>\n</ul>\n<h2 id=\"tdpo与ppo中的kl约束\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#tdpo与ppo中的kl约束\"><span>TDPO与PPO中的KL约束</span></a></h2>\n<p>TDPO（Trust Region Policy Optimization）算法通过引入PPO（Proximal Policy Optimization）中的KL约束来优化策略。不同于PPO使用的backward KL，TDPO采用forward KL来计算KL惩罚。这种选择的原因在于KL距离的非对称性：forward KL旨在尽可能覆盖整个分布的大部分，而backward KL则专注于拟合分布中的某一部分。\n<img src=\"/img/user/附件/Pasted image 20250423224032.png\" alt=\"Pasted image 20250423224032.png\"></p>\n<h2 id=\"tdpo的优势\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#tdpo的优势\"><span>TDPO的优势</span></a></h2>\n<p>由于TDPO使用forward KL进行训练，其模型在输出多样性上更为自由。相比之下，PPO训练后的模型输出风格趋于一致，因为输出分布已聚集到一个局部分布上，导致reward方差小于SFT（Softmax Function Transformation）。</p>\n<p>💡 启发点：TDPO在多样性输出上的优势使其在需要多种可能性探索的任务中表现更佳。</p>\n<h2 id=\"代码示例与计算步骤\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#代码示例与计算步骤\"><span>代码示例与计算步骤</span></a></h2>\n<p>在实现TDPO时，forward KL的计算方式可以通过以下代码实现：</p>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code><span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">vocab_logps </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> logits</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">log_softmax</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">-</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">reference_vocab_ps </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> reference_logits</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">softmax</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">-</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">reference_vocab_logps </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> reference_vocab_ps</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">log</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># Forward KL 计算</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">per_position_kl </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> (</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">reference_vocab_ps </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">*</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> (</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">reference_vocab_logps </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">-</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> vocab_logps</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)).</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">sum</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">-</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">per_token_logps </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">gather</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">vocab_logps</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">2</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> index</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">labels</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">unsqueeze</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">2</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)).</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">squeeze</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">2</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">per_reference_token_logps </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">gather</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">reference_vocab_logps</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">2</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> index</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">labels</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">unsqueeze</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">2</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)).</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">squeeze</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">2</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h3 id=\"操作步骤\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#操作步骤\"><span>操作步骤</span></a></h3>\n<ol>\n<li>✅ 初始化策略模型与参考模型的logits。</li>\n<li>⚠ 计算logits的softmax并取log。</li>\n<li>❗ 计算每个位置的forward KL值。</li>\n</ol>\n<h2 id=\"常见错误\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#常见错误\"><span>常见错误</span></a></h2>\n<blockquote>\n<p><strong>注意</strong>：在实现TDPO时，务必确保forward KL计算的准确性，以避免模型输出的多样性不足。</p>\n</blockquote>\n<h2 id=\"行动清单\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#行动清单\"><span>行动清单</span></a></h2>\n<ul>\n<li>研究TDPO在不同任务中的表现。</li>\n<li>比较TDPO和PPO在相同环境下的效果。</li>\n<li>探索更多应用场景中的KL约束优化。</li>\n</ul>\n<blockquote>\n<p>原始出处：[原文提供者未注明]</p>\n</blockquote>\n<p>通过以上内容，我们总结了TDPO算法的核心概念及其与PPO的区别，特别是在KL约束的应用上。希望这篇笔记能够帮助你更好地理解TDPO算法及其优势。</p>\n","env":{"base":"/","filePath":"/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/RL强化学习基础/优化DPO方向的算法/TDPO.md","filePathRelative":"notes_bak/大语言模型学习/RL强化学习基础/优化DPO方向的算法/TDPO.md","frontmatter":{"dg-publish":true,"dg-permalink":"/大语言模型学习/RL强化学习基础/优化DPO方向的算法/TDPO","dg-home":false,"dg-description":"在此输入笔记的描述","dg-hide":false,"dg-hide-title":false,"dg-show-backlinks":true,"dg-show-local-graph":true,"dg-show-inline-title":true,"dg-pinned":false,"dg-passphrase":"在此输入访问密码","dg-enable-mathjax":false,"dg-enable-mermaid":false,"dg-enable-uml":false,"dg-note-icon":0,"dg-enable-dataview":false,"tags":["NLP"],"permalink":"/大语言模型学习/RL强化学习基础/优化DPO方向的算法/TDPO/","dgShowBacklinks":true,"dgShowLocalGraph":true,"dgShowInlineTitle":true,"dgPassFrontmatter":true,"noteIcon":0,"created":"2025-04-23T14:40:04.000Z","updated":"2025-04-23T14:40:35.087Z","title":"TDPO","createTime":"2025/05/13 17:33:52"},"sfcBlocks":{"template":{"type":"template","content":"<template><p>元数据：</p>\n<ul>\n<li>分类：算法与优化</li>\n<li>标签：TDPO, KL约束, 强化学习, PPO, 前向KL</li>\n<li>日期：2025年4月12日</li>\n</ul>\n<h2 id=\"tdpo与ppo中的kl约束\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#tdpo与ppo中的kl约束\"><span>TDPO与PPO中的KL约束</span></a></h2>\n<p>TDPO（Trust Region Policy Optimization）算法通过引入PPO（Proximal Policy Optimization）中的KL约束来优化策略。不同于PPO使用的backward KL，TDPO采用forward KL来计算KL惩罚。这种选择的原因在于KL距离的非对称性：forward KL旨在尽可能覆盖整个分布的大部分，而backward KL则专注于拟合分布中的某一部分。\n<img src=\"/img/user/附件/Pasted image 20250423224032.png\" alt=\"Pasted image 20250423224032.png\"></p>\n<h2 id=\"tdpo的优势\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#tdpo的优势\"><span>TDPO的优势</span></a></h2>\n<p>由于TDPO使用forward KL进行训练，其模型在输出多样性上更为自由。相比之下，PPO训练后的模型输出风格趋于一致，因为输出分布已聚集到一个局部分布上，导致reward方差小于SFT（Softmax Function Transformation）。</p>\n<p>💡 启发点：TDPO在多样性输出上的优势使其在需要多种可能性探索的任务中表现更佳。</p>\n<h2 id=\"代码示例与计算步骤\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#代码示例与计算步骤\"><span>代码示例与计算步骤</span></a></h2>\n<p>在实现TDPO时，forward KL的计算方式可以通过以下代码实现：</p>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code><span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">vocab_logps </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> logits</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">log_softmax</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">-</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">reference_vocab_ps </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> reference_logits</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">softmax</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">-</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">reference_vocab_logps </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> reference_vocab_ps</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">log</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># Forward KL 计算</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">per_position_kl </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> (</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">reference_vocab_ps </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">*</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> (</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">reference_vocab_logps </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">-</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> vocab_logps</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)).</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">sum</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">-</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">per_token_logps </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">gather</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">vocab_logps</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">2</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> index</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">labels</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">unsqueeze</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">2</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)).</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">squeeze</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">2</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">per_reference_token_logps </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">gather</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">reference_vocab_logps</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">2</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> index</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">labels</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">unsqueeze</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">2</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)).</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">squeeze</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">2</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h3 id=\"操作步骤\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#操作步骤\"><span>操作步骤</span></a></h3>\n<ol>\n<li>✅ 初始化策略模型与参考模型的logits。</li>\n<li>⚠ 计算logits的softmax并取log。</li>\n<li>❗ 计算每个位置的forward KL值。</li>\n</ol>\n<h2 id=\"常见错误\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#常见错误\"><span>常见错误</span></a></h2>\n<blockquote>\n<p><strong>注意</strong>：在实现TDPO时，务必确保forward KL计算的准确性，以避免模型输出的多样性不足。</p>\n</blockquote>\n<h2 id=\"行动清单\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#行动清单\"><span>行动清单</span></a></h2>\n<ul>\n<li>研究TDPO在不同任务中的表现。</li>\n<li>比较TDPO和PPO在相同环境下的效果。</li>\n<li>探索更多应用场景中的KL约束优化。</li>\n</ul>\n<blockquote>\n<p>原始出处：[原文提供者未注明]</p>\n</blockquote>\n<p>通过以上内容，我们总结了TDPO算法的核心概念及其与PPO的区别，特别是在KL约束的应用上。希望这篇笔记能够帮助你更好地理解TDPO算法及其优势。</p>\n</template>","contentStripped":"<p>元数据：</p>\n<ul>\n<li>分类：算法与优化</li>\n<li>标签：TDPO, KL约束, 强化学习, PPO, 前向KL</li>\n<li>日期：2025年4月12日</li>\n</ul>\n<h2 id=\"tdpo与ppo中的kl约束\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#tdpo与ppo中的kl约束\"><span>TDPO与PPO中的KL约束</span></a></h2>\n<p>TDPO（Trust Region Policy Optimization）算法通过引入PPO（Proximal Policy Optimization）中的KL约束来优化策略。不同于PPO使用的backward KL，TDPO采用forward KL来计算KL惩罚。这种选择的原因在于KL距离的非对称性：forward KL旨在尽可能覆盖整个分布的大部分，而backward KL则专注于拟合分布中的某一部分。\n<img src=\"/img/user/附件/Pasted image 20250423224032.png\" alt=\"Pasted image 20250423224032.png\"></p>\n<h2 id=\"tdpo的优势\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#tdpo的优势\"><span>TDPO的优势</span></a></h2>\n<p>由于TDPO使用forward KL进行训练，其模型在输出多样性上更为自由。相比之下，PPO训练后的模型输出风格趋于一致，因为输出分布已聚集到一个局部分布上，导致reward方差小于SFT（Softmax Function Transformation）。</p>\n<p>💡 启发点：TDPO在多样性输出上的优势使其在需要多种可能性探索的任务中表现更佳。</p>\n<h2 id=\"代码示例与计算步骤\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#代码示例与计算步骤\"><span>代码示例与计算步骤</span></a></h2>\n<p>在实现TDPO时，forward KL的计算方式可以通过以下代码实现：</p>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code><span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">vocab_logps </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> logits</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">log_softmax</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">-</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">reference_vocab_ps </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> reference_logits</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">softmax</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">-</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">reference_vocab_logps </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> reference_vocab_ps</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">log</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># Forward KL 计算</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">per_position_kl </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> (</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">reference_vocab_ps </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">*</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> (</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">reference_vocab_logps </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">-</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> vocab_logps</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)).</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">sum</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">-</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">per_token_logps </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">gather</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">vocab_logps</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">2</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> index</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">labels</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">unsqueeze</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">2</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)).</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">squeeze</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">2</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">per_reference_token_logps </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">gather</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">reference_vocab_logps</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">2</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> index</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">labels</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">unsqueeze</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">2</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)).</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">squeeze</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">2</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h3 id=\"操作步骤\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#操作步骤\"><span>操作步骤</span></a></h3>\n<ol>\n<li>✅ 初始化策略模型与参考模型的logits。</li>\n<li>⚠ 计算logits的softmax并取log。</li>\n<li>❗ 计算每个位置的forward KL值。</li>\n</ol>\n<h2 id=\"常见错误\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#常见错误\"><span>常见错误</span></a></h2>\n<blockquote>\n<p><strong>注意</strong>：在实现TDPO时，务必确保forward KL计算的准确性，以避免模型输出的多样性不足。</p>\n</blockquote>\n<h2 id=\"行动清单\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#行动清单\"><span>行动清单</span></a></h2>\n<ul>\n<li>研究TDPO在不同任务中的表现。</li>\n<li>比较TDPO和PPO在相同环境下的效果。</li>\n<li>探索更多应用场景中的KL约束优化。</li>\n</ul>\n<blockquote>\n<p>原始出处：[原文提供者未注明]</p>\n</blockquote>\n<p>通过以上内容，我们总结了TDPO算法的核心概念及其与PPO的区别，特别是在KL约束的应用上。希望这篇笔记能够帮助你更好地理解TDPO算法及其优势。</p>\n","tagOpen":"<template>","tagClose":"</template>"},"script":null,"scriptSetup":null,"scripts":[],"styles":[],"customBlocks":[]},"content":"元数据：\n\n- 分类：算法与优化\n- 标签：TDPO, KL约束, 强化学习, PPO, 前向KL\n- 日期：2025年4月12日\n\n## TDPO与PPO中的KL约束\nTDPO（Trust Region Policy Optimization）算法通过引入PPO（Proximal Policy Optimization）中的KL约束来优化策略。不同于PPO使用的backward KL，TDPO采用forward KL来计算KL惩罚。这种选择的原因在于KL距离的非对称性：forward KL旨在尽可能覆盖整个分布的大部分，而backward KL则专注于拟合分布中的某一部分。\n![Pasted image 20250423224032.png](/img/user/%E9%99%84%E4%BB%B6/Pasted%20image%2020250423224032.png)\n\n\n## TDPO的优势\n由于TDPO使用forward KL进行训练，其模型在输出多样性上更为自由。相比之下，PPO训练后的模型输出风格趋于一致，因为输出分布已聚集到一个局部分布上，导致reward方差小于SFT（Softmax Function Transformation）。\n\n💡 启发点：TDPO在多样性输出上的优势使其在需要多种可能性探索的任务中表现更佳。\n\n\n## 代码示例与计算步骤\n在实现TDPO时，forward KL的计算方式可以通过以下代码实现：\n\n```python\nvocab_logps = logits.log_softmax(-1)\nreference_vocab_ps = reference_logits.softmax(-1)\nreference_vocab_logps = reference_vocab_ps.log()\n\n# Forward KL 计算\nper_position_kl = (reference_vocab_ps * (reference_vocab_logps - vocab_logps)).sum(-1)\nper_token_logps = torch.gather(vocab_logps, dim=2, index=labels.unsqueeze(2)).squeeze(2)\nper_reference_token_logps = torch.gather(reference_vocab_logps, dim=2, index=labels.unsqueeze(2)).squeeze(2)\n```\n\n### 操作步骤\n1. ✅ 初始化策略模型与参考模型的logits。\n2. ⚠ 计算logits的softmax并取log。\n3. ❗ 计算每个位置的forward KL值。\n\n\n## 常见错误\n> **注意**：在实现TDPO时，务必确保forward KL计算的准确性，以避免模型输出的多样性不足。\n\n\n## 行动清单\n- 研究TDPO在不同任务中的表现。\n- 比较TDPO和PPO在相同环境下的效果。\n- 探索更多应用场景中的KL约束优化。\n\n> 原始出处：[原文提供者未注明]\n\n通过以上内容，我们总结了TDPO算法的核心概念及其与PPO的区别，特别是在KL约束的应用上。希望这篇笔记能够帮助你更好地理解TDPO算法及其优势。","excerpt":"","includedFiles":[],"tasklistId":0,"title":"","headers":[{"level":2,"title":"TDPO与PPO中的KL约束","slug":"tdpo与ppo中的kl约束","link":"#tdpo与ppo中的kl约束","children":[]},{"level":2,"title":"TDPO的优势","slug":"tdpo的优势","link":"#tdpo的优势","children":[]},{"level":2,"title":"代码示例与计算步骤","slug":"代码示例与计算步骤","link":"#代码示例与计算步骤","children":[{"level":3,"title":"操作步骤","slug":"操作步骤","link":"#操作步骤","children":[]}]},{"level":2,"title":"常见错误","slug":"常见错误","link":"#常见错误","children":[]},{"level":2,"title":"行动清单","slug":"行动清单","link":"#行动清单","children":[]}]}}
