{"content":"<h2 id=\"构建思想\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#构建思想\"><span>构建思想</span></a></h2>\n<p>在强化学习中，特别是基于人类反馈的强化学习（RLHF），通常需要多个模型之间进行交互通信。这种通信具有数据量较小、交互模式灵活性要求高的特点，因此非常适合使用 Ray 的 Actor Programming 编程范式来实现模型间通信（inter model communication）。</p>\n<p>大模型的训练通常采用 3D 并行技术，其前向、反向和生成过程涉及到大量数据通信。为了高效地实现这些通信，通常采用 GPU NCCL 的集合通信（collective communication）。开源工具如 Deepspeed 和 Megatron 已经提供了模型内通信（intra model communication）的高效解决方案。</p>\n<p>通过构建模型间通信和模型内通信的层次化通信平面，我们可以实现以下目标：</p>\n<ul>\n<li>模型间：基于 Ray 的 Actor Programming 编程范式，实现高效的异步通信。</li>\n<li>模型内：集成 Megatron 的 TP/PP/DP 并行算法，集成 Deepspeed 的 DP（Zero）并行算法，具备完整的 3D 并行加速方案。</li>\n</ul>\n<p>同时，借鉴 trlX 对 PPO 等算法的实现（该算法已经过实战测试），我们采用了 trlX 的 PPO 算法流程。</p>\n<p>此外，引入 Deepspeed Inference 和 vLLM 推理加速方案，加速 Actor 的 token 生成效率，支持两种后端组合：Megatron 训练 + vLLM 推理，以及 Deepspeed Zero3 训练 + Deepspeed Inference 推理。</p>\n<h2 id=\"大模型并行训练\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#大模型并行训练\"><span>大模型并行训练</span></a></h2>\n<p>在训练大模型时，必然伴随着大数据的处理。并行训练主要涉及以下几个技术：</p>\n<h3 id=\"数据并行-data-parallel-dp\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#数据并行-data-parallel-dp\"><span>数据并行（Data Parallel，DP）</span></a></h3>\n<p>在数据并行中，数据在模型副本之间分摊，在反向传播时副本之间交换梯度。更多细节可以参考 <a href=\"https://pytorch.org/tutorials/intermediate/ddp_tutorial.html\" target=\"_blank\" rel=\"noopener noreferrer\">PyTorch 的教程</a>。</p>\n<h3 id=\"张量并行-tensor-parallel-tp\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#张量并行-tensor-parallel-tp\"><span>张量并行（Tensor Parallel，TP）</span></a></h3>\n<p>张量并行涉及 Intra Layer 内的拆分。例如，在 Transformer 结构上按照 Attention Heads 进行 <span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">N</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span></span></span></span> 等分，同时也会对 Feed Forward Network 进行 <span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">N</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span></span></span></span> 等分。关于这方面的详细信息，可以参考 [Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism]</p>\n<h3 id=\"流水线并行-pipeline-parallel-pp\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#流水线并行-pipeline-parallel-pp\"><span>流水线并行（Pipeline Parallel，PP）</span></a></h3>\n<p>流水线并行涉及 Inter Layer 间的拆分。例如，[0，<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">N</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span></span></span></span>) 层在 GPU 0，[N, 2N) 层在 GPU 1。关于这方面的详细信息，可以参考 GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism。</p>\n<h3 id=\"zero-zero-redundancy-optimizer\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#zero-zero-redundancy-optimizer\"><span>ZeRO （Zero Redundancy Optimizer），</span></a></h3>\n<p>思想上类似 Parameter Server 架构，GPU 间互为参数服务器，参数服务器根据不同模式存储着优化器参数、梯度、模型参数。ZeRO 本质上是数据并行，即一张卡上会发生一次完整的前向和反向。\n<img src=\"/img/user/附件/Pasted image 20250430221131.png\" alt=\"Pasted image 20250430221131.png\">\n<img src=\"/img/user/附件/Pasted image 20250430221143.png\" alt=\"Pasted image 20250430221143.png\"></p>\n<h1 id=\"megatron-lm、deepspeed-与-ray-分布式计算的利器\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#megatron-lm、deepspeed-与-ray-分布式计算的利器\"><span>Megatron-LM、Deepspeed 与 Ray：分布式计算的利器</span></a></h1>\n<p>在当今大数据和深度学习的时代，分布式计算框架成为了不可或缺的工具。本文将介绍三个重要的分布式计算框架：Megatron-LM、Deepspeed 和 Ray，并探讨它们各自的特点和优势。</p>\n<h2 id=\"megatron-lm\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#megatron-lm\"><span>Megatron-LM</span></a></h2>\n<p>Megatron-LM 是一个性能极高的深度学习模型训练框架，包含了大量的优化技巧。它通过算子融合和通信计算并行化等技术，极大地提高了模型训练的效率。然而，Megatron-LM 支持的模型类型较少，适配 Hugging Face 模型的成本较高，这使得它在某些应用场景中的灵活性受到限制。</p>\n<h2 id=\"deepspeed\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#deepspeed\"><span>Deepspeed</span></a></h2>\n<p>Deepspeed 是另一个广泛使用的深度学习框架，其最大的优势在于无缝支持 Hugging Face 的大量模型。Deepspeed 采用原生 torch 算子实现，因此性能相对一般，但其兼容性和易用性使得它成为许多开发者的首选。</p>\n<h2 id=\"ray\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#ray\"><span>Ray</span></a></h2>\n<p>Ray 是一个高性能分布式执行框架，为解决世界上最复杂和要求苛刻的计算问题提供了强大的支持。正如 OpenAI 的 CTO 和联合创始人 Greg Brockman 所说：</p>\n<blockquote>\n<p>“在 OpenAI，我们正在解决世界上一些最复杂和要求苛刻的计算问题。Ray 为我们提供了解决这些棘手问题的动力，并使我们能够比以往更快地进行大规模迭代。”</p>\n</blockquote>\n<p>Ray 提供了简单但通用的分布式编程抽象，处于较低的抽象层次，可以在其上构建各种分布式计算系统。Ray 的编程前端包括 Python、Java 和 C++（实验性），其去中心化的构建思想体现在分布式共享内存 object store、分布式引用计数和分布式调度。\n<img src=\"/img/user/附件/Pasted image 20250430222252.png\" alt=\"Pasted image 20250430222252.png\">\n在 Ray 的编程抽象中，Actor 实现为一个 Python Class，代表的是一个 Long Running Python Process。我们可以通过调用 Class 的方法向 Ray Actor 发送请求。</p>\n<h3 id=\"代码示例\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#代码示例\"><span>代码示例</span></a></h3>\n<p>以下是一个简单的 Ray Actor 示例代码：</p>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code><span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">import</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> ray</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">@</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">ray</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">remote</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">class</span><span style=\"--shiki-light:#2E8F82;--shiki-dark:#5DA994\"> Counter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">:</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\"> __init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">value </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 0</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\"> increment</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">value </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">+=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 1</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">        return</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">value</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\"> get_counter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">        return</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">value</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># Create ten Counter actors.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">counters </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> [</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Counter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">remote</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\"> for</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> _ </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">in</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\"> range</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">10</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)]</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># Increment each Counter once and get the results. These tasks all happen in</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># parallel.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">results </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> ray</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">get</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">([</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">c</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">increment</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">remote</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\"> for</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> c </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">in</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> counters</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">])</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">print</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">results</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># Increment the first Counter five times. These tasks are executed serially</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># and share state.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">results </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> ray</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">get</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">([</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">counters</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">0</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">].</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">increment</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">remote</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\"> for</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> _ </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">in</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\"> range</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">5</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)])</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">print</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">results</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>通过这个示例，我们可以看到 Ray 如何使用 Python Class 来实现 Actor 模型，使得开发者能够轻松地构建分布式应用程序。</p>\n<p>为了构建大语言模型分布式强化学习框架，我们抽象出 <code v-pre>Workhorse</code> 和 <code v-pre>WholeModel</code> 两个核心类：</p>\n<p><code v-pre>Workhorse</code>，是一个 <code v-pre>Ray Actor</code>，其持有一张 <code v-pre>GPU</code> 卡，是模型的一个分片。</p>\n<p><code v-pre>WholeModel</code>，是一个 <code v-pre>Ray Actor</code>，它代表了一个模型整体，是一个代理，而模型本身可能被 <code v-pre>shard</code> / <code v-pre>replicate</code> 到多机多卡上，它持有着多个 <code v-pre>Workhorse</code>。\n<img src=\"/img/user/附件/Pasted image 20250430222338.png\" alt=\"Pasted image 20250430222338.png\"></p>\n","env":{"base":"/","filePath":"/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/训练推理优化/训练框架/X-ray.md","filePathRelative":"notes_bak/大语言模型学习/训练推理优化/训练框架/X-ray.md","frontmatter":{"dg-publish":true,"dg-permalink":"/大语言模型学习/训练推理优化/训练框架/X-ray","dg-home":false,"dg-description":"在此输入笔记的描述","dg-hide":false,"dg-hide-title":false,"dg-show-backlinks":true,"dg-show-local-graph":true,"dg-show-inline-title":true,"dg-pinned":false,"dg-passphrase":"在此输入访问密码","dg-enable-mathjax":false,"dg-enable-mermaid":false,"dg-enable-uml":false,"dg-note-icon":0,"dg-enable-dataview":false,"tags":["NLP"],"permalink":"/大语言模型学习/训练推理优化/训练框架/X-ray/","dgShowBacklinks":true,"dgShowLocalGraph":true,"dgShowInlineTitle":true,"dgPassFrontmatter":true,"noteIcon":0,"created":"2025-04-29T14:54:30.000Z","updated":"2025-04-30T14:23:41.511Z","title":"X-ray","createTime":"2025/05/13 17:33:53"},"sfcBlocks":{"template":{"type":"template","content":"<template><h2 id=\"构建思想\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#构建思想\"><span>构建思想</span></a></h2>\n<p>在强化学习中，特别是基于人类反馈的强化学习（RLHF），通常需要多个模型之间进行交互通信。这种通信具有数据量较小、交互模式灵活性要求高的特点，因此非常适合使用 Ray 的 Actor Programming 编程范式来实现模型间通信（inter model communication）。</p>\n<p>大模型的训练通常采用 3D 并行技术，其前向、反向和生成过程涉及到大量数据通信。为了高效地实现这些通信，通常采用 GPU NCCL 的集合通信（collective communication）。开源工具如 Deepspeed 和 Megatron 已经提供了模型内通信（intra model communication）的高效解决方案。</p>\n<p>通过构建模型间通信和模型内通信的层次化通信平面，我们可以实现以下目标：</p>\n<ul>\n<li>模型间：基于 Ray 的 Actor Programming 编程范式，实现高效的异步通信。</li>\n<li>模型内：集成 Megatron 的 TP/PP/DP 并行算法，集成 Deepspeed 的 DP（Zero）并行算法，具备完整的 3D 并行加速方案。</li>\n</ul>\n<p>同时，借鉴 trlX 对 PPO 等算法的实现（该算法已经过实战测试），我们采用了 trlX 的 PPO 算法流程。</p>\n<p>此外，引入 Deepspeed Inference 和 vLLM 推理加速方案，加速 Actor 的 token 生成效率，支持两种后端组合：Megatron 训练 + vLLM 推理，以及 Deepspeed Zero3 训练 + Deepspeed Inference 推理。</p>\n<h2 id=\"大模型并行训练\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#大模型并行训练\"><span>大模型并行训练</span></a></h2>\n<p>在训练大模型时，必然伴随着大数据的处理。并行训练主要涉及以下几个技术：</p>\n<h3 id=\"数据并行-data-parallel-dp\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#数据并行-data-parallel-dp\"><span>数据并行（Data Parallel，DP）</span></a></h3>\n<p>在数据并行中，数据在模型副本之间分摊，在反向传播时副本之间交换梯度。更多细节可以参考 <a href=\"https://pytorch.org/tutorials/intermediate/ddp_tutorial.html\" target=\"_blank\" rel=\"noopener noreferrer\">PyTorch 的教程</a>。</p>\n<h3 id=\"张量并行-tensor-parallel-tp\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#张量并行-tensor-parallel-tp\"><span>张量并行（Tensor Parallel，TP）</span></a></h3>\n<p>张量并行涉及 Intra Layer 内的拆分。例如，在 Transformer 结构上按照 Attention Heads 进行 <span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">N</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span></span></span></span> 等分，同时也会对 Feed Forward Network 进行 <span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">N</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span></span></span></span> 等分。关于这方面的详细信息，可以参考 [Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism]</p>\n<h3 id=\"流水线并行-pipeline-parallel-pp\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#流水线并行-pipeline-parallel-pp\"><span>流水线并行（Pipeline Parallel，PP）</span></a></h3>\n<p>流水线并行涉及 Inter Layer 间的拆分。例如，[0，<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">N</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span></span></span></span>) 层在 GPU 0，[N, 2N) 层在 GPU 1。关于这方面的详细信息，可以参考 GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism。</p>\n<h3 id=\"zero-zero-redundancy-optimizer\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#zero-zero-redundancy-optimizer\"><span>ZeRO （Zero Redundancy Optimizer），</span></a></h3>\n<p>思想上类似 Parameter Server 架构，GPU 间互为参数服务器，参数服务器根据不同模式存储着优化器参数、梯度、模型参数。ZeRO 本质上是数据并行，即一张卡上会发生一次完整的前向和反向。\n<img src=\"/img/user/附件/Pasted image 20250430221131.png\" alt=\"Pasted image 20250430221131.png\">\n<img src=\"/img/user/附件/Pasted image 20250430221143.png\" alt=\"Pasted image 20250430221143.png\"></p>\n<h1 id=\"megatron-lm、deepspeed-与-ray-分布式计算的利器\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#megatron-lm、deepspeed-与-ray-分布式计算的利器\"><span>Megatron-LM、Deepspeed 与 Ray：分布式计算的利器</span></a></h1>\n<p>在当今大数据和深度学习的时代，分布式计算框架成为了不可或缺的工具。本文将介绍三个重要的分布式计算框架：Megatron-LM、Deepspeed 和 Ray，并探讨它们各自的特点和优势。</p>\n<h2 id=\"megatron-lm\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#megatron-lm\"><span>Megatron-LM</span></a></h2>\n<p>Megatron-LM 是一个性能极高的深度学习模型训练框架，包含了大量的优化技巧。它通过算子融合和通信计算并行化等技术，极大地提高了模型训练的效率。然而，Megatron-LM 支持的模型类型较少，适配 Hugging Face 模型的成本较高，这使得它在某些应用场景中的灵活性受到限制。</p>\n<h2 id=\"deepspeed\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#deepspeed\"><span>Deepspeed</span></a></h2>\n<p>Deepspeed 是另一个广泛使用的深度学习框架，其最大的优势在于无缝支持 Hugging Face 的大量模型。Deepspeed 采用原生 torch 算子实现，因此性能相对一般，但其兼容性和易用性使得它成为许多开发者的首选。</p>\n<h2 id=\"ray\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#ray\"><span>Ray</span></a></h2>\n<p>Ray 是一个高性能分布式执行框架，为解决世界上最复杂和要求苛刻的计算问题提供了强大的支持。正如 OpenAI 的 CTO 和联合创始人 Greg Brockman 所说：</p>\n<blockquote>\n<p>“在 OpenAI，我们正在解决世界上一些最复杂和要求苛刻的计算问题。Ray 为我们提供了解决这些棘手问题的动力，并使我们能够比以往更快地进行大规模迭代。”</p>\n</blockquote>\n<p>Ray 提供了简单但通用的分布式编程抽象，处于较低的抽象层次，可以在其上构建各种分布式计算系统。Ray 的编程前端包括 Python、Java 和 C++（实验性），其去中心化的构建思想体现在分布式共享内存 object store、分布式引用计数和分布式调度。\n<img src=\"/img/user/附件/Pasted image 20250430222252.png\" alt=\"Pasted image 20250430222252.png\">\n在 Ray 的编程抽象中，Actor 实现为一个 Python Class，代表的是一个 Long Running Python Process。我们可以通过调用 Class 的方法向 Ray Actor 发送请求。</p>\n<h3 id=\"代码示例\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#代码示例\"><span>代码示例</span></a></h3>\n<p>以下是一个简单的 Ray Actor 示例代码：</p>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code><span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">import</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> ray</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">@</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">ray</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">remote</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">class</span><span style=\"--shiki-light:#2E8F82;--shiki-dark:#5DA994\"> Counter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">:</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\"> __init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">value </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 0</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\"> increment</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">value </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">+=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 1</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">        return</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">value</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\"> get_counter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">        return</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">value</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># Create ten Counter actors.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">counters </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> [</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Counter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">remote</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\"> for</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> _ </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">in</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\"> range</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">10</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)]</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># Increment each Counter once and get the results. These tasks all happen in</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># parallel.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">results </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> ray</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">get</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">([</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">c</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">increment</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">remote</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\"> for</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> c </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">in</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> counters</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">])</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">print</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">results</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># Increment the first Counter five times. These tasks are executed serially</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># and share state.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">results </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> ray</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">get</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">([</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">counters</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">0</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">].</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">increment</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">remote</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\"> for</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> _ </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">in</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\"> range</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">5</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)])</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">print</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">results</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>通过这个示例，我们可以看到 Ray 如何使用 Python Class 来实现 Actor 模型，使得开发者能够轻松地构建分布式应用程序。</p>\n<p>为了构建大语言模型分布式强化学习框架，我们抽象出 <code v-pre>Workhorse</code> 和 <code v-pre>WholeModel</code> 两个核心类：</p>\n<p><code v-pre>Workhorse</code>，是一个 <code v-pre>Ray Actor</code>，其持有一张 <code v-pre>GPU</code> 卡，是模型的一个分片。</p>\n<p><code v-pre>WholeModel</code>，是一个 <code v-pre>Ray Actor</code>，它代表了一个模型整体，是一个代理，而模型本身可能被 <code v-pre>shard</code> / <code v-pre>replicate</code> 到多机多卡上，它持有着多个 <code v-pre>Workhorse</code>。\n<img src=\"/img/user/附件/Pasted image 20250430222338.png\" alt=\"Pasted image 20250430222338.png\"></p>\n</template>","contentStripped":"<h2 id=\"构建思想\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#构建思想\"><span>构建思想</span></a></h2>\n<p>在强化学习中，特别是基于人类反馈的强化学习（RLHF），通常需要多个模型之间进行交互通信。这种通信具有数据量较小、交互模式灵活性要求高的特点，因此非常适合使用 Ray 的 Actor Programming 编程范式来实现模型间通信（inter model communication）。</p>\n<p>大模型的训练通常采用 3D 并行技术，其前向、反向和生成过程涉及到大量数据通信。为了高效地实现这些通信，通常采用 GPU NCCL 的集合通信（collective communication）。开源工具如 Deepspeed 和 Megatron 已经提供了模型内通信（intra model communication）的高效解决方案。</p>\n<p>通过构建模型间通信和模型内通信的层次化通信平面，我们可以实现以下目标：</p>\n<ul>\n<li>模型间：基于 Ray 的 Actor Programming 编程范式，实现高效的异步通信。</li>\n<li>模型内：集成 Megatron 的 TP/PP/DP 并行算法，集成 Deepspeed 的 DP（Zero）并行算法，具备完整的 3D 并行加速方案。</li>\n</ul>\n<p>同时，借鉴 trlX 对 PPO 等算法的实现（该算法已经过实战测试），我们采用了 trlX 的 PPO 算法流程。</p>\n<p>此外，引入 Deepspeed Inference 和 vLLM 推理加速方案，加速 Actor 的 token 生成效率，支持两种后端组合：Megatron 训练 + vLLM 推理，以及 Deepspeed Zero3 训练 + Deepspeed Inference 推理。</p>\n<h2 id=\"大模型并行训练\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#大模型并行训练\"><span>大模型并行训练</span></a></h2>\n<p>在训练大模型时，必然伴随着大数据的处理。并行训练主要涉及以下几个技术：</p>\n<h3 id=\"数据并行-data-parallel-dp\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#数据并行-data-parallel-dp\"><span>数据并行（Data Parallel，DP）</span></a></h3>\n<p>在数据并行中，数据在模型副本之间分摊，在反向传播时副本之间交换梯度。更多细节可以参考 <a href=\"https://pytorch.org/tutorials/intermediate/ddp_tutorial.html\" target=\"_blank\" rel=\"noopener noreferrer\">PyTorch 的教程</a>。</p>\n<h3 id=\"张量并行-tensor-parallel-tp\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#张量并行-tensor-parallel-tp\"><span>张量并行（Tensor Parallel，TP）</span></a></h3>\n<p>张量并行涉及 Intra Layer 内的拆分。例如，在 Transformer 结构上按照 Attention Heads 进行 <span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">N</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span></span></span></span> 等分，同时也会对 Feed Forward Network 进行 <span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">N</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span></span></span></span> 等分。关于这方面的详细信息，可以参考 [Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism]</p>\n<h3 id=\"流水线并行-pipeline-parallel-pp\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#流水线并行-pipeline-parallel-pp\"><span>流水线并行（Pipeline Parallel，PP）</span></a></h3>\n<p>流水线并行涉及 Inter Layer 间的拆分。例如，[0，<span v-pre class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">N</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span></span></span></span>) 层在 GPU 0，[N, 2N) 层在 GPU 1。关于这方面的详细信息，可以参考 GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism。</p>\n<h3 id=\"zero-zero-redundancy-optimizer\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#zero-zero-redundancy-optimizer\"><span>ZeRO （Zero Redundancy Optimizer），</span></a></h3>\n<p>思想上类似 Parameter Server 架构，GPU 间互为参数服务器，参数服务器根据不同模式存储着优化器参数、梯度、模型参数。ZeRO 本质上是数据并行，即一张卡上会发生一次完整的前向和反向。\n<img src=\"/img/user/附件/Pasted image 20250430221131.png\" alt=\"Pasted image 20250430221131.png\">\n<img src=\"/img/user/附件/Pasted image 20250430221143.png\" alt=\"Pasted image 20250430221143.png\"></p>\n<h1 id=\"megatron-lm、deepspeed-与-ray-分布式计算的利器\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#megatron-lm、deepspeed-与-ray-分布式计算的利器\"><span>Megatron-LM、Deepspeed 与 Ray：分布式计算的利器</span></a></h1>\n<p>在当今大数据和深度学习的时代，分布式计算框架成为了不可或缺的工具。本文将介绍三个重要的分布式计算框架：Megatron-LM、Deepspeed 和 Ray，并探讨它们各自的特点和优势。</p>\n<h2 id=\"megatron-lm\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#megatron-lm\"><span>Megatron-LM</span></a></h2>\n<p>Megatron-LM 是一个性能极高的深度学习模型训练框架，包含了大量的优化技巧。它通过算子融合和通信计算并行化等技术，极大地提高了模型训练的效率。然而，Megatron-LM 支持的模型类型较少，适配 Hugging Face 模型的成本较高，这使得它在某些应用场景中的灵活性受到限制。</p>\n<h2 id=\"deepspeed\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#deepspeed\"><span>Deepspeed</span></a></h2>\n<p>Deepspeed 是另一个广泛使用的深度学习框架，其最大的优势在于无缝支持 Hugging Face 的大量模型。Deepspeed 采用原生 torch 算子实现，因此性能相对一般，但其兼容性和易用性使得它成为许多开发者的首选。</p>\n<h2 id=\"ray\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#ray\"><span>Ray</span></a></h2>\n<p>Ray 是一个高性能分布式执行框架，为解决世界上最复杂和要求苛刻的计算问题提供了强大的支持。正如 OpenAI 的 CTO 和联合创始人 Greg Brockman 所说：</p>\n<blockquote>\n<p>“在 OpenAI，我们正在解决世界上一些最复杂和要求苛刻的计算问题。Ray 为我们提供了解决这些棘手问题的动力，并使我们能够比以往更快地进行大规模迭代。”</p>\n</blockquote>\n<p>Ray 提供了简单但通用的分布式编程抽象，处于较低的抽象层次，可以在其上构建各种分布式计算系统。Ray 的编程前端包括 Python、Java 和 C++（实验性），其去中心化的构建思想体现在分布式共享内存 object store、分布式引用计数和分布式调度。\n<img src=\"/img/user/附件/Pasted image 20250430222252.png\" alt=\"Pasted image 20250430222252.png\">\n在 Ray 的编程抽象中，Actor 实现为一个 Python Class，代表的是一个 Long Running Python Process。我们可以通过调用 Class 的方法向 Ray Actor 发送请求。</p>\n<h3 id=\"代码示例\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#代码示例\"><span>代码示例</span></a></h3>\n<p>以下是一个简单的 Ray Actor 示例代码：</p>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code><span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">import</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> ray</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">@</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">ray</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">remote</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">class</span><span style=\"--shiki-light:#2E8F82;--shiki-dark:#5DA994\"> Counter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">:</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\"> __init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">value </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 0</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\"> increment</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">value </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">+=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 1</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">        return</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">value</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\"> get_counter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">        return</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">value</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># Create ten Counter actors.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">counters </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\"> [</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Counter</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">remote</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\"> for</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> _ </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">in</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\"> range</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">10</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)]</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># Increment each Counter once and get the results. These tasks all happen in</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># parallel.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">results </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> ray</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">get</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">([</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">c</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">increment</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">remote</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\"> for</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> c </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">in</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> counters</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">])</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">print</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">results</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># Increment the first Counter five times. These tasks are executed serially</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># and share state.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">results </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> ray</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">get</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">([</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">counters</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">0</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">].</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">increment</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">remote</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\"> for</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> _ </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">in</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\"> range</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">5</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)])</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">print</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">results</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>通过这个示例，我们可以看到 Ray 如何使用 Python Class 来实现 Actor 模型，使得开发者能够轻松地构建分布式应用程序。</p>\n<p>为了构建大语言模型分布式强化学习框架，我们抽象出 <code v-pre>Workhorse</code> 和 <code v-pre>WholeModel</code> 两个核心类：</p>\n<p><code v-pre>Workhorse</code>，是一个 <code v-pre>Ray Actor</code>，其持有一张 <code v-pre>GPU</code> 卡，是模型的一个分片。</p>\n<p><code v-pre>WholeModel</code>，是一个 <code v-pre>Ray Actor</code>，它代表了一个模型整体，是一个代理，而模型本身可能被 <code v-pre>shard</code> / <code v-pre>replicate</code> 到多机多卡上，它持有着多个 <code v-pre>Workhorse</code>。\n<img src=\"/img/user/附件/Pasted image 20250430222338.png\" alt=\"Pasted image 20250430222338.png\"></p>\n","tagOpen":"<template>","tagClose":"</template>"},"script":null,"scriptSetup":null,"scripts":[],"styles":[],"customBlocks":[]},"content":"\n## 构建思想\n在强化学习中，特别是基于人类反馈的强化学习（RLHF），通常需要多个模型之间进行交互通信。这种通信具有数据量较小、交互模式灵活性要求高的特点，因此非常适合使用 Ray 的 Actor Programming 编程范式来实现模型间通信（inter model communication）。\n\n大模型的训练通常采用 3D 并行技术，其前向、反向和生成过程涉及到大量数据通信。为了高效地实现这些通信，通常采用 GPU NCCL 的集合通信（collective communication）。开源工具如 Deepspeed 和 Megatron 已经提供了模型内通信（intra model communication）的高效解决方案。\n\n通过构建模型间通信和模型内通信的层次化通信平面，我们可以实现以下目标：\n- 模型间：基于 Ray 的 Actor Programming 编程范式，实现高效的异步通信。\n- 模型内：集成 Megatron 的 TP/PP/DP 并行算法，集成 Deepspeed 的 DP（Zero）并行算法，具备完整的 3D 并行加速方案。\n\n同时，借鉴 trlX 对 PPO 等算法的实现（该算法已经过实战测试），我们采用了 trlX 的 PPO 算法流程。\n\n此外，引入 Deepspeed Inference 和 vLLM 推理加速方案，加速 Actor 的 token 生成效率，支持两种后端组合：Megatron 训练 + vLLM 推理，以及 Deepspeed Zero3 训练 + Deepspeed Inference 推理。\n\n\n## 大模型并行训练\n在训练大模型时，必然伴随着大数据的处理。并行训练主要涉及以下几个技术：\n\n### 数据并行（Data Parallel，DP）\n在数据并行中，数据在模型副本之间分摊，在反向传播时副本之间交换梯度。更多细节可以参考 [PyTorch 的教程](https://pytorch.org/tutorials/intermediate/ddp_tutorial.html)。\n\n\n### 张量并行（Tensor Parallel，TP）\n张量并行涉及 Intra Layer 内的拆分。例如，在 Transformer 结构上按照 Attention Heads 进行 $N$ 等分，同时也会对 Feed Forward Network 进行 $N$ 等分。关于这方面的详细信息，可以参考 [Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism]\n\n\n### 流水线并行（Pipeline Parallel，PP）\n流水线并行涉及 Inter Layer 间的拆分。例如，[0，$N$) 层在 GPU 0，[N, 2N) 层在 GPU 1。关于这方面的详细信息，可以参考 GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism。\n\n\n### ZeRO （Zero Redundancy Optimizer），\n思想上类似 Parameter Server 架构，GPU 间互为参数服务器，参数服务器根据不同模式存储着优化器参数、梯度、模型参数。ZeRO 本质上是数据并行，即一张卡上会发生一次完整的前向和反向。\n![Pasted image 20250430221131.png](/img/user/%E9%99%84%E4%BB%B6/Pasted%20image%2020250430221131.png)\n![Pasted image 20250430221143.png](/img/user/%E9%99%84%E4%BB%B6/Pasted%20image%2020250430221143.png)\n\n\n\n# Megatron-LM、Deepspeed 与 Ray：分布式计算的利器\n在当今大数据和深度学习的时代，分布式计算框架成为了不可或缺的工具。本文将介绍三个重要的分布式计算框架：Megatron-LM、Deepspeed 和 Ray，并探讨它们各自的特点和优势。\n\n## Megatron-LM\nMegatron-LM 是一个性能极高的深度学习模型训练框架，包含了大量的优化技巧。它通过算子融合和通信计算并行化等技术，极大地提高了模型训练的效率。然而，Megatron-LM 支持的模型类型较少，适配 Hugging Face 模型的成本较高，这使得它在某些应用场景中的灵活性受到限制。\n\n\n## Deepspeed\nDeepspeed 是另一个广泛使用的深度学习框架，其最大的优势在于无缝支持 Hugging Face 的大量模型。Deepspeed 采用原生 torch 算子实现，因此性能相对一般，但其兼容性和易用性使得它成为许多开发者的首选。\n\n\n## Ray\nRay 是一个高性能分布式执行框架，为解决世界上最复杂和要求苛刻的计算问题提供了强大的支持。正如 OpenAI 的 CTO 和联合创始人 Greg Brockman 所说：\n\n> “在 OpenAI，我们正在解决世界上一些最复杂和要求苛刻的计算问题。Ray 为我们提供了解决这些棘手问题的动力，并使我们能够比以往更快地进行大规模迭代。”\n\nRay 提供了简单但通用的分布式编程抽象，处于较低的抽象层次，可以在其上构建各种分布式计算系统。Ray 的编程前端包括 Python、Java 和 C++（实验性），其去中心化的构建思想体现在分布式共享内存 object store、分布式引用计数和分布式调度。\n![Pasted image 20250430222252.png](/img/user/%E9%99%84%E4%BB%B6/Pasted%20image%2020250430222252.png)\n在 Ray 的编程抽象中，Actor 实现为一个 Python Class，代表的是一个 Long Running Python Process。我们可以通过调用 Class 的方法向 Ray Actor 发送请求。\n\n### 代码示例\n以下是一个简单的 Ray Actor 示例代码：\n\n```python\nimport ray\n\n@ray.remote\nclass Counter:\n    def __init__(self):\n        self.value = 0\n\n    def increment(self):\n        self.value += 1\n        return self.value\n\n    def get_counter(self):\n        return self.value\n\n# Create ten Counter actors.\ncounters = [Counter.remote() for _ in range(10)]\n\n# Increment each Counter once and get the results. These tasks all happen in\n# parallel.\nresults = ray.get([c.increment.remote() for c in counters])\nprint(results)\n\n# Increment the first Counter five times. These tasks are executed serially\n# and share state.\nresults = ray.get([counters[0].increment.remote() for _ in range(5)])\nprint(results)\n\n```\n\n通过这个示例，我们可以看到 Ray 如何使用 Python Class 来实现 Actor 模型，使得开发者能够轻松地构建分布式应用程序。\n\n\n为了构建大语言模型分布式强化学习框架，我们抽象出 `Workhorse` 和 `WholeModel` 两个核心类：\n\n`Workhorse`，是一个 `Ray Actor`，其持有一张 `GPU` 卡，是模型的一个分片。\n\n`WholeModel`，是一个 `Ray Actor`，它代表了一个模型整体，是一个代理，而模型本身可能被 `shard` / `replicate` 到多机多卡上，它持有着多个 `Workhorse`。\n![Pasted image 20250430222338.png](/img/user/%E9%99%84%E4%BB%B6/Pasted%20image%2020250430222338.png)","excerpt":"","includedFiles":[],"tasklistId":0,"title":"Megatron-LM、Deepspeed 与 Ray：分布式计算的利器","headers":[{"level":2,"title":"构建思想","slug":"构建思想","link":"#构建思想","children":[]},{"level":2,"title":"大模型并行训练","slug":"大模型并行训练","link":"#大模型并行训练","children":[{"level":3,"title":"数据并行（Data Parallel，DP）","slug":"数据并行-data-parallel-dp","link":"#数据并行-data-parallel-dp","children":[]},{"level":3,"title":"张量并行（Tensor Parallel，TP）","slug":"张量并行-tensor-parallel-tp","link":"#张量并行-tensor-parallel-tp","children":[]},{"level":3,"title":"流水线并行（Pipeline Parallel，PP）","slug":"流水线并行-pipeline-parallel-pp","link":"#流水线并行-pipeline-parallel-pp","children":[]},{"level":3,"title":"ZeRO （Zero Redundancy Optimizer），","slug":"zero-zero-redundancy-optimizer","link":"#zero-zero-redundancy-optimizer","children":[]}]},{"level":2,"title":"Megatron-LM","slug":"megatron-lm","link":"#megatron-lm","children":[]},{"level":2,"title":"Deepspeed","slug":"deepspeed","link":"#deepspeed","children":[]},{"level":2,"title":"Ray","slug":"ray","link":"#ray","children":[{"level":3,"title":"代码示例","slug":"代码示例","link":"#代码示例","children":[]}]}]}}
