{"content":"<h2 id=\"分类-自动推断\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#分类-自动推断\"><span>分类：自动推断</span></a></h2>\n<h2 id=\"标签-数学预训练、强化学习、数据处理、deepseek\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#标签-数学预训练、强化学习、数据处理、deepseek\"><span>标签：数学预训练、强化学习、数据处理、DeepSeek</span></a></h2>\n<h2 id=\"日期-2025年4月12日\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#日期-2025年4月12日\"><span>日期：2025年4月12日</span></a></h2>\n<h2 id=\"核心观点总结\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心观点总结\"><span>核心观点总结</span></a></h2>\n<p>本文探讨了Deepseek-math项目的主要贡献，包括可扩展的数学预训练和对强化学习的探索与分析。重点介绍了数据处理过程，涉及训练数据的收集与清洗、预训练模型的参数设置、以及指令微调和强化学习过程。\n<img src=\"/img/user/附件/Pasted image 20250426221755.png\" alt=\"Pasted image 20250426221755.png\"></p>\n<h2 id=\"重点段落与数据\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#重点段落与数据\"><span>重点段落与数据</span></a></h2>\n<h3 id=\"训练数据与来源\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#训练数据与来源\"><span>训练数据与来源</span></a></h3>\n<ul>\n<li>120B数学标记来自Common Crawl的数据，使用fastText分类器提取，多语言支持。</li>\n<li>数据分布：56%来自DeepSeekMath语料库，4%来自AlgebraicStack，10%来自arXiv，20%是Github代码，其余10%是Common Crawl的自然语言数据。</li>\n</ul>\n<h3 id=\"数据集收集和清洗过程\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#数据集收集和清洗过程\"><span>数据集收集和清洗过程</span></a></h3>\n<ul>\n<li><strong>去重和召回</strong>：确保数据唯一性，避免冗余。</li>\n<li><strong>去污染</strong>：过滤掉包含英语和中文数学基准测试题目或答案的网页，以免基准污染。</li>\n</ul>\n<h3 id=\"指令微调与强化学习\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#指令微调与强化学习\"><span>指令微调与强化学习</span></a></h3>\n<ul>\n<li>构建了一个数学指令调优数据集，共776K个样本。</li>\n<li>使用GRPO进行强化学习，group size设为64。</li>\n</ul>\n<h2 id=\"数据表格\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#数据表格\"><span>数据表格</span></a></h2>\n<table>\n<thead>\n<tr>\n<th>数据来源</th>\n<th>占比</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>DeepSeekMath Corpus</td>\n<td>56%</td>\n</tr>\n<tr>\n<td>AlgebraicStack</td>\n<td>4%</td>\n</tr>\n<tr>\n<td>arXiv</td>\n<td>10%</td>\n</tr>\n<tr>\n<td>Github代码</td>\n<td>20%</td>\n</tr>\n<tr>\n<td>Common Crawl</td>\n<td>10%</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"操作步骤\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#操作步骤\"><span>操作步骤</span></a></h2>\n<ol>\n<li>✅ <strong>收集数据</strong>：从Common Crawl提取120B数学标记。</li>\n<li>⚠ <strong>训练fastText模型</strong>：注意与word2vec CBOW的区别。</li>\n<li>❗ <strong>去污染</strong>：确保基准测试题目或答案不被包含在训练数据中。</li>\n</ol>\n<h2 id=\"常见错误\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#常见错误\"><span>常见错误</span></a></h2>\n<blockquote>\n<p>注意在数据去重和召回过程中，可能会遗漏重要的数据片段，需特别小心。</p>\n</blockquote>\n<h2 id=\"💡启发点\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#💡启发点\"><span>💡启发点</span></a></h2>\n<ul>\n<li>数据去污染策略有效防止了基准测试的污染，为模型的公平评估奠定了基础。</li>\n</ul>\n<h2 id=\"行动清单\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#行动清单\"><span>行动清单</span></a></h2>\n<ul class=\"task-list-container\">\n<li class=\"task-list-item\"><input type=\"checkbox\" class=\"task-list-item-checkbox\" id=\"task-item-0\" disabled=\"disabled\"><label class=\"task-list-item-label\" for=\"task-item-0\"> 研究fastText与word2vec CBOW的具体区别。</label></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" class=\"task-list-item-checkbox\" id=\"task-item-1\" disabled=\"disabled\"><label class=\"task-list-item-label\" for=\"task-item-1\"> 探索如何优化GRPO在强化学习中的应用。</label></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" class=\"task-list-item-checkbox\" id=\"task-item-2\" disabled=\"disabled\"><label class=\"task-list-item-label\" for=\"task-item-2\"> 分析不同数据来源对模型性能的影响。</label></li>\n</ul>\n<blockquote>\n<p>原始出处：[Deepseek-math项目文档]</p>\n</blockquote>\n","env":{"base":"/","filePath":"/Users/qianyuhe/Desktop/my-project/docs/notes_bak/大语言模型学习/Common Models常见模型/DeepSeek系列/Deepseek-math.md","filePathRelative":"notes_bak/大语言模型学习/Common Models常见模型/DeepSeek系列/Deepseek-math.md","frontmatter":{"dg-publish":true,"dg-permalink":"/大语言模型学习/Common-Models常见模型/DeepSeek系列/Deepseek-math","dg-home":false,"dg-description":"在此输入笔记的描述","dg-hide":false,"dg-hide-title":false,"dg-show-backlinks":true,"dg-show-local-graph":true,"dg-show-inline-title":true,"dg-pinned":false,"dg-passphrase":"在此输入访问密码","dg-enable-mathjax":false,"dg-enable-mermaid":false,"dg-enable-uml":false,"dg-note-icon":0,"dg-enable-dataview":false,"tags":["NLP"],"permalink":"/大语言模型学习/Common-Models常见模型/DeepSeek系列/Deepseek-math/","dgShowBacklinks":true,"dgShowLocalGraph":true,"dgShowInlineTitle":true,"dgPassFrontmatter":true,"noteIcon":0,"created":"2025-04-26T14:17:29.893Z","updated":"2025-04-26T14:17:57.132Z","title":"Deepseek-math","createTime":"2025/05/13 17:33:53"},"sfcBlocks":{"template":{"type":"template","content":"<template><h2 id=\"分类-自动推断\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#分类-自动推断\"><span>分类：自动推断</span></a></h2>\n<h2 id=\"标签-数学预训练、强化学习、数据处理、deepseek\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#标签-数学预训练、强化学习、数据处理、deepseek\"><span>标签：数学预训练、强化学习、数据处理、DeepSeek</span></a></h2>\n<h2 id=\"日期-2025年4月12日\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#日期-2025年4月12日\"><span>日期：2025年4月12日</span></a></h2>\n<h2 id=\"核心观点总结\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心观点总结\"><span>核心观点总结</span></a></h2>\n<p>本文探讨了Deepseek-math项目的主要贡献，包括可扩展的数学预训练和对强化学习的探索与分析。重点介绍了数据处理过程，涉及训练数据的收集与清洗、预训练模型的参数设置、以及指令微调和强化学习过程。\n<img src=\"/img/user/附件/Pasted image 20250426221755.png\" alt=\"Pasted image 20250426221755.png\"></p>\n<h2 id=\"重点段落与数据\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#重点段落与数据\"><span>重点段落与数据</span></a></h2>\n<h3 id=\"训练数据与来源\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#训练数据与来源\"><span>训练数据与来源</span></a></h3>\n<ul>\n<li>120B数学标记来自Common Crawl的数据，使用fastText分类器提取，多语言支持。</li>\n<li>数据分布：56%来自DeepSeekMath语料库，4%来自AlgebraicStack，10%来自arXiv，20%是Github代码，其余10%是Common Crawl的自然语言数据。</li>\n</ul>\n<h3 id=\"数据集收集和清洗过程\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#数据集收集和清洗过程\"><span>数据集收集和清洗过程</span></a></h3>\n<ul>\n<li><strong>去重和召回</strong>：确保数据唯一性，避免冗余。</li>\n<li><strong>去污染</strong>：过滤掉包含英语和中文数学基准测试题目或答案的网页，以免基准污染。</li>\n</ul>\n<h3 id=\"指令微调与强化学习\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#指令微调与强化学习\"><span>指令微调与强化学习</span></a></h3>\n<ul>\n<li>构建了一个数学指令调优数据集，共776K个样本。</li>\n<li>使用GRPO进行强化学习，group size设为64。</li>\n</ul>\n<h2 id=\"数据表格\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#数据表格\"><span>数据表格</span></a></h2>\n<table>\n<thead>\n<tr>\n<th>数据来源</th>\n<th>占比</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>DeepSeekMath Corpus</td>\n<td>56%</td>\n</tr>\n<tr>\n<td>AlgebraicStack</td>\n<td>4%</td>\n</tr>\n<tr>\n<td>arXiv</td>\n<td>10%</td>\n</tr>\n<tr>\n<td>Github代码</td>\n<td>20%</td>\n</tr>\n<tr>\n<td>Common Crawl</td>\n<td>10%</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"操作步骤\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#操作步骤\"><span>操作步骤</span></a></h2>\n<ol>\n<li>✅ <strong>收集数据</strong>：从Common Crawl提取120B数学标记。</li>\n<li>⚠ <strong>训练fastText模型</strong>：注意与word2vec CBOW的区别。</li>\n<li>❗ <strong>去污染</strong>：确保基准测试题目或答案不被包含在训练数据中。</li>\n</ol>\n<h2 id=\"常见错误\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#常见错误\"><span>常见错误</span></a></h2>\n<blockquote>\n<p>注意在数据去重和召回过程中，可能会遗漏重要的数据片段，需特别小心。</p>\n</blockquote>\n<h2 id=\"💡启发点\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#💡启发点\"><span>💡启发点</span></a></h2>\n<ul>\n<li>数据去污染策略有效防止了基准测试的污染，为模型的公平评估奠定了基础。</li>\n</ul>\n<h2 id=\"行动清单\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#行动清单\"><span>行动清单</span></a></h2>\n<ul class=\"task-list-container\">\n<li class=\"task-list-item\"><input type=\"checkbox\" class=\"task-list-item-checkbox\" id=\"task-item-0\" disabled=\"disabled\"><label class=\"task-list-item-label\" for=\"task-item-0\"> 研究fastText与word2vec CBOW的具体区别。</label></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" class=\"task-list-item-checkbox\" id=\"task-item-1\" disabled=\"disabled\"><label class=\"task-list-item-label\" for=\"task-item-1\"> 探索如何优化GRPO在强化学习中的应用。</label></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" class=\"task-list-item-checkbox\" id=\"task-item-2\" disabled=\"disabled\"><label class=\"task-list-item-label\" for=\"task-item-2\"> 分析不同数据来源对模型性能的影响。</label></li>\n</ul>\n<blockquote>\n<p>原始出处：[Deepseek-math项目文档]</p>\n</blockquote>\n</template>","contentStripped":"<h2 id=\"分类-自动推断\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#分类-自动推断\"><span>分类：自动推断</span></a></h2>\n<h2 id=\"标签-数学预训练、强化学习、数据处理、deepseek\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#标签-数学预训练、强化学习、数据处理、deepseek\"><span>标签：数学预训练、强化学习、数据处理、DeepSeek</span></a></h2>\n<h2 id=\"日期-2025年4月12日\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#日期-2025年4月12日\"><span>日期：2025年4月12日</span></a></h2>\n<h2 id=\"核心观点总结\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心观点总结\"><span>核心观点总结</span></a></h2>\n<p>本文探讨了Deepseek-math项目的主要贡献，包括可扩展的数学预训练和对强化学习的探索与分析。重点介绍了数据处理过程，涉及训练数据的收集与清洗、预训练模型的参数设置、以及指令微调和强化学习过程。\n<img src=\"/img/user/附件/Pasted image 20250426221755.png\" alt=\"Pasted image 20250426221755.png\"></p>\n<h2 id=\"重点段落与数据\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#重点段落与数据\"><span>重点段落与数据</span></a></h2>\n<h3 id=\"训练数据与来源\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#训练数据与来源\"><span>训练数据与来源</span></a></h3>\n<ul>\n<li>120B数学标记来自Common Crawl的数据，使用fastText分类器提取，多语言支持。</li>\n<li>数据分布：56%来自DeepSeekMath语料库，4%来自AlgebraicStack，10%来自arXiv，20%是Github代码，其余10%是Common Crawl的自然语言数据。</li>\n</ul>\n<h3 id=\"数据集收集和清洗过程\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#数据集收集和清洗过程\"><span>数据集收集和清洗过程</span></a></h3>\n<ul>\n<li><strong>去重和召回</strong>：确保数据唯一性，避免冗余。</li>\n<li><strong>去污染</strong>：过滤掉包含英语和中文数学基准测试题目或答案的网页，以免基准污染。</li>\n</ul>\n<h3 id=\"指令微调与强化学习\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#指令微调与强化学习\"><span>指令微调与强化学习</span></a></h3>\n<ul>\n<li>构建了一个数学指令调优数据集，共776K个样本。</li>\n<li>使用GRPO进行强化学习，group size设为64。</li>\n</ul>\n<h2 id=\"数据表格\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#数据表格\"><span>数据表格</span></a></h2>\n<table>\n<thead>\n<tr>\n<th>数据来源</th>\n<th>占比</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>DeepSeekMath Corpus</td>\n<td>56%</td>\n</tr>\n<tr>\n<td>AlgebraicStack</td>\n<td>4%</td>\n</tr>\n<tr>\n<td>arXiv</td>\n<td>10%</td>\n</tr>\n<tr>\n<td>Github代码</td>\n<td>20%</td>\n</tr>\n<tr>\n<td>Common Crawl</td>\n<td>10%</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"操作步骤\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#操作步骤\"><span>操作步骤</span></a></h2>\n<ol>\n<li>✅ <strong>收集数据</strong>：从Common Crawl提取120B数学标记。</li>\n<li>⚠ <strong>训练fastText模型</strong>：注意与word2vec CBOW的区别。</li>\n<li>❗ <strong>去污染</strong>：确保基准测试题目或答案不被包含在训练数据中。</li>\n</ol>\n<h2 id=\"常见错误\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#常见错误\"><span>常见错误</span></a></h2>\n<blockquote>\n<p>注意在数据去重和召回过程中，可能会遗漏重要的数据片段，需特别小心。</p>\n</blockquote>\n<h2 id=\"💡启发点\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#💡启发点\"><span>💡启发点</span></a></h2>\n<ul>\n<li>数据去污染策略有效防止了基准测试的污染，为模型的公平评估奠定了基础。</li>\n</ul>\n<h2 id=\"行动清单\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#行动清单\"><span>行动清单</span></a></h2>\n<ul class=\"task-list-container\">\n<li class=\"task-list-item\"><input type=\"checkbox\" class=\"task-list-item-checkbox\" id=\"task-item-0\" disabled=\"disabled\"><label class=\"task-list-item-label\" for=\"task-item-0\"> 研究fastText与word2vec CBOW的具体区别。</label></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" class=\"task-list-item-checkbox\" id=\"task-item-1\" disabled=\"disabled\"><label class=\"task-list-item-label\" for=\"task-item-1\"> 探索如何优化GRPO在强化学习中的应用。</label></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" class=\"task-list-item-checkbox\" id=\"task-item-2\" disabled=\"disabled\"><label class=\"task-list-item-label\" for=\"task-item-2\"> 分析不同数据来源对模型性能的影响。</label></li>\n</ul>\n<blockquote>\n<p>原始出处：[Deepseek-math项目文档]</p>\n</blockquote>\n","tagOpen":"<template>","tagClose":"</template>"},"script":null,"scriptSetup":null,"scripts":[],"styles":[],"customBlocks":[]},"content":"\n## 分类：自动推断\n\n\n## 标签：数学预训练、强化学习、数据处理、DeepSeek\n\n\n## 日期：2025年4月12日\n\n\n## 核心观点总结\n本文探讨了Deepseek-math项目的主要贡献，包括可扩展的数学预训练和对强化学习的探索与分析。重点介绍了数据处理过程，涉及训练数据的收集与清洗、预训练模型的参数设置、以及指令微调和强化学习过程。\n![Pasted image 20250426221755.png](/img/user/%E9%99%84%E4%BB%B6/Pasted%20image%2020250426221755.png)\n\n\n## 重点段落与数据\n\n### 训练数据与来源\n- 120B数学标记来自Common Crawl的数据，使用fastText分类器提取，多语言支持。\n- 数据分布：56%来自DeepSeekMath语料库，4%来自AlgebraicStack，10%来自arXiv，20%是Github代码，其余10%是Common Crawl的自然语言数据。\n\n\n### 数据集收集和清洗过程\n- **去重和召回**：确保数据唯一性，避免冗余。\n- **去污染**：过滤掉包含英语和中文数学基准测试题目或答案的网页，以免基准污染。\n\n\n### 指令微调与强化学习\n- 构建了一个数学指令调优数据集，共776K个样本。\n- 使用GRPO进行强化学习，group size设为64。\n\n\n## 数据表格\n| 数据来源            | 占比  |\n|-----------------|-----|\n| DeepSeekMath Corpus | 56% |\n| AlgebraicStack     | 4%  |\n| arXiv              | 10% |\n| Github代码         | 20% |\n| Common Crawl       | 10% |\n\n\n## 操作步骤\n1. ✅ **收集数据**：从Common Crawl提取120B数学标记。\n2. ⚠ **训练fastText模型**：注意与word2vec CBOW的区别。\n3. ❗ **去污染**：确保基准测试题目或答案不被包含在训练数据中。\n\n\n## 常见错误\n> 注意在数据去重和召回过程中，可能会遗漏重要的数据片段，需特别小心。\n\n\n## 💡启发点\n- 数据去污染策略有效防止了基准测试的污染，为模型的公平评估奠定了基础。\n\n\n## 行动清单\n- [ ] 研究fastText与word2vec CBOW的具体区别。\n- [ ] 探索如何优化GRPO在强化学习中的应用。\n- [ ] 分析不同数据来源对模型性能的影响。\n\n> 原始出处：[Deepseek-math项目文档]","excerpt":"","includedFiles":[],"tasklistId":3,"title":"","headers":[{"level":2,"title":"分类：自动推断","slug":"分类-自动推断","link":"#分类-自动推断","children":[]},{"level":2,"title":"标签：数学预训练、强化学习、数据处理、DeepSeek","slug":"标签-数学预训练、强化学习、数据处理、deepseek","link":"#标签-数学预训练、强化学习、数据处理、deepseek","children":[]},{"level":2,"title":"日期：2025年4月12日","slug":"日期-2025年4月12日","link":"#日期-2025年4月12日","children":[]},{"level":2,"title":"核心观点总结","slug":"核心观点总结","link":"#核心观点总结","children":[]},{"level":2,"title":"重点段落与数据","slug":"重点段落与数据","link":"#重点段落与数据","children":[{"level":3,"title":"训练数据与来源","slug":"训练数据与来源","link":"#训练数据与来源","children":[]},{"level":3,"title":"数据集收集和清洗过程","slug":"数据集收集和清洗过程","link":"#数据集收集和清洗过程","children":[]},{"level":3,"title":"指令微调与强化学习","slug":"指令微调与强化学习","link":"#指令微调与强化学习","children":[]}]},{"level":2,"title":"数据表格","slug":"数据表格","link":"#数据表格","children":[]},{"level":2,"title":"操作步骤","slug":"操作步骤","link":"#操作步骤","children":[]},{"level":2,"title":"常见错误","slug":"常见错误","link":"#常见错误","children":[]},{"level":2,"title":"💡启发点","slug":"💡启发点","link":"#💡启发点","children":[]},{"level":2,"title":"行动清单","slug":"行动清单","link":"#行动清单","children":[]}]}}
