---
{"dg-publish":true,"dg-permalink":"/å¤§è¯­è¨€æ¨¡å‹å­¦ä¹ /RLå¼ºåŒ–å­¦ä¹ åŸºç¡€/æ·±åº¦Qç½‘ç»œ","dg-home":false,"dg-description":"åœ¨æ­¤è¾“å…¥ç¬”è®°çš„æè¿°","dg-hide":false,"dg-hide-title":false,"dg-show-backlinks":true,"dg-show-local-graph":true,"dg-show-inline-title":true,"dg-pinned":false,"dg-passphrase":"åœ¨æ­¤è¾“å…¥è®¿é—®å¯†ç ","dg-enable-mathjax":false,"dg-enable-mermaid":false,"dg-enable-uml":false,"dg-note-icon":0,"dg-enable-dataview":false,"tags":["NLP"],"permalink":"/å¤§è¯­è¨€æ¨¡å‹å­¦ä¹ /RLå¼ºåŒ–å­¦ä¹ åŸºç¡€/æ·±åº¦Qç½‘ç»œ/","dgShowBacklinks":true,"dgShowLocalGraph":true,"dgShowInlineTitle":true,"dgPassFrontmatter":true,"noteIcon":0,"created":"2025-04-11T13:41:20.000+08:00","updated":"2025-04-13T13:06:02.000+08:00"}
---



# æ·±åº¦Qç½‘ç»œï¼ˆDQNï¼‰åœ¨å¼ºåŒ–å­¦ä¹ ä¸­çš„åº”ç”¨
å…ƒæ•°æ®ï¼š
- åˆ†ç±»ï¼šå¼ºåŒ–å­¦ä¹ 
- æ ‡ç­¾ï¼šæ·±åº¦å­¦ä¹ ï¼ŒDQNï¼Œå¼ºåŒ–å­¦ä¹ ï¼ŒQ-learning
- æ—¥æœŸï¼š2025å¹´4æœˆ11æ—¥

## DQNç®€ä»‹
æ·±åº¦Qç½‘ç»œï¼ˆDQNï¼‰æ˜¯å¯¹ä¼ ç»ŸQ-learningç®—æ³•çš„æ‰©å±•ï¼Œä¸“ä¸ºå¤„ç†çŠ¶æ€å’ŒåŠ¨ä½œç©ºé—´éå¸¸å¤§çš„æƒ…å†µè€Œè®¾è®¡ï¼Œå¦‚å›¾åƒæˆ–è¿ç»­å˜é‡ã€‚ä¼ ç»Ÿçš„è¡¨æ ¼æ³•åœ¨è¿™ç§æƒ…å†µä¸‹æ— æ³•æœ‰æ•ˆè®°å½•çŠ¶æ€åŠ¨ä½œå¯¹çš„Qå€¼ï¼Œå› æ­¤DQNé‡‡ç”¨ç¥ç»ç½‘ç»œæ¥æ‹ŸåˆQå€¼å‡½æ•°ã€‚


## Q-learningçš„æ›´æ–°æ–¹å¼
æ›´æ–°å…¬å¼å¦‚ä¸‹ï¼š
$$
Q(s_t, a_t) \leftarrow Q(s_t, a_t) + \alpha [r_t + \gamma \max_a Q(s_{t+1}, a) - Q(s_t, a_t)]
$$

DQNé€šè¿‡ä½¿Qå€¼ç½‘ç»œçš„è¾“å‡ºä¸æ—¶åºå·®åˆ†ç›®æ ‡ï¼ˆTD targetï¼‰æ¥è¿‘æ¥æ„é€ å‡æ–¹è¯¯å·®æŸå¤±å‡½æ•°å½¢å¼ï¼š
$$
L_{DQN} = \frac{1}{2N} \sum_{i=1}^{N} [Q_w(s_i, a_i) - (r_i + \gamma \max_{a'} Q_w(s'_i, a'))]^2
$$

```Python
class ReplayBuffer: 
    ''' ç»éªŒå›æ”¾æ±  ''' 
    self.target_update = target_update # ç›®æ ‡ç½‘ç»œæ›´æ–°é¢‘ç‡ 
    self.count = 0 # è®¡æ•°å™¨,è®°å½•æ›´æ–°æ¬¡æ•° 
    self.device = device 

    def take_action(self, state): # epsilon-è´ªå©ªç­–ç•¥é‡‡å–åŠ¨ä½œ 
        if np.random.random() < self.epsilon: 
            action = np.random.randint(self.action_dim) 
        else: 
            state = torch.tensor([state], dtype=torch.float).to(self.device) 
            action = self.q_net(state).argmax().item() 
        return action 

    def update(self, transition_dict): 
        states = torch.tensor(transition_dict['states'], dtype=torch.float).to(self.device) 
        actions = torch.tensor(transition_dict['actions']).view(-1, 1).to(self.device) 
        rewards = torch.tensor(transition_dict['rewards'], dtype=torch.float).view(-1, 1).to(self.device) 
        next_states = torch.tensor(transition_dict['next_states'], dtype=torch.float).to(self.device) 
        dones = torch.tensor(transition_dict['dones'], dtype=torch.float).view(-1, 1).to(self.device) 

        q_values = self.q_net(states).gather(1, actions) # Qå€¼ 
        # ä¸‹ä¸ªçŠ¶æ€çš„æœ€å¤§Qå€¼ 
        max_next_q_values = self.target_q_net(next_states).max(1)[0].view(-1, 1) 
        q_targets = rewards + self.gamma * max_next_q_values * (1 - dones) # TDè¯¯å·®ç›®æ ‡ 
        dqn_loss = torch.mean(F.mse_loss(q_values, q_targets)) # å‡æ–¹è¯¯å·®æŸå¤±å‡½æ•° 

        self.optimizer.zero_grad() # PyTorchä¸­é»˜è®¤æ¢¯åº¦ä¼šç´¯ç§¯,è¿™é‡Œéœ€è¦æ˜¾å¼å°†æ¢¯åº¦ç½®ä¸º0 
        dqn_loss.backward() # åå‘ä¼ æ’­æ›´æ–°å‚æ•° 
        self.optimizer.step() 

        if self.count % self.target_update == 0: 
            self.target_q_net.load_state_dict(self.q_net.state_dict()) # æ›´æ–°ç›®æ ‡ç½‘ç»œ 

        self.count += 1

```


## DQNçš„é‡è¦æ”¹è¿›

### Repaly Bufferï¼ˆç»éªŒå›æ”¾ï¼‰
- âœ… **ä½¿æ ·æœ¬æ»¡è¶³ç‹¬ç«‹å‡è®¾**ï¼šé€šè¿‡ç»´æŠ¤ä¸€ä¸ªReplay Bufferï¼Œæ‰“ç ´æ ·æœ¬ä¹‹é—´çš„ç›¸å…³æ€§ã€‚
- â— **æé«˜æ ·æœ¬æ•ˆç‡**ï¼šæ¯ä¸ªæ ·æœ¬å¯ä»¥è¢«ä½¿ç”¨å¤šæ¬¡ï¼Œé€‚åˆæ·±åº¦ç¥ç»ç½‘ç»œçš„æ¢¯åº¦å­¦ä¹ ã€‚


### Target Networkï¼ˆç›®æ ‡ç½‘ç»œï¼‰
- âš  **ç›®æ ‡ç¨³å®šæ€§**ï¼šå¼•å…¥ç›®æ ‡ç½‘ç»œæ¥è®¡ç®—TDç›®æ ‡ï¼Œé¿å…ç›®æ ‡ä¸æ–­å˜åŒ–å¯¼è‡´è®­ç»ƒä¸ç¨³å®šã€‚


## å¸¸è§é”™è¯¯
> åœ¨æ›´æ–°ç½‘ç»œå‚æ•°æ—¶ï¼Œå¦‚æœä¸ä½¿ç”¨ç›®æ ‡ç½‘ç»œï¼Œå®¹æ˜“å‡ºç°ç›®æ ‡æ¼‚ç§»ç°è±¡ï¼Œå¯¼è‡´è®­ç»ƒä¸ç¨³å®šã€‚


## ğŸ’¡å¯å‘ç‚¹
- ä½¿ç”¨Replay Bufferå’ŒTarget Networkæ˜¯æé«˜DQNè®­ç»ƒç¨³å®šæ€§çš„é‡è¦ç­–ç•¥ã€‚


## è¡ŒåŠ¨æ¸…å•
1. æ¢ç´¢å¦‚ä½•ä¼˜åŒ–Replay Bufferçš„é‡‡æ ·ç­–ç•¥ã€‚
2. ç ”ç©¶Target Networkæ›´æ–°é¢‘ç‡å¯¹è®­ç»ƒæ•ˆæœçš„å½±å“ã€‚
3. å®éªŒä¸åŒç½‘ç»œæ¶æ„å¯¹DQNæ€§èƒ½çš„å½±å“ã€‚


## ğŸ“ˆè¶‹åŠ¿é¢„æµ‹
éšç€è®¡ç®—èƒ½åŠ›çš„æå‡ï¼ŒDQNå°†åœ¨æ›´å¤æ‚çš„ç¯å¢ƒä¸­å¾—åˆ°å¹¿æ³›åº”ç”¨ï¼Œå¯èƒ½ä¼šç»“åˆæ›´å¤šå…ˆè¿›æŠ€æœ¯å¦‚åˆ†å¸ƒå¼è®­ç»ƒå’Œè‡ªé€‚åº”é‡‡æ ·ç­–ç•¥ã€‚


## åç»­è¿½è¸ª
- ç ”ç©¶å¦‚ä½•å°†DQNåº”ç”¨äºå®æ—¶å†³ç­–ç³»ç»Ÿã€‚
- æ¢è®¨DQNåœ¨å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­çš„è¡¨ç°ã€‚

> åŸå§‹å‡ºå¤„ï¼š[æ·±åº¦å¼ºåŒ–å­¦ä¹ ç›¸å…³æ–‡æ¡£]

[æ€è€ƒ]
1. å¦‚ä½•è¿›ä¸€æ­¥ä¼˜åŒ–DQNä»¥é€‚åº”æ›´å¤æ‚çš„çŠ¶æ€ç©ºé—´ï¼Ÿ
2. åœ¨å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­ï¼ŒDQNæ˜¯å¦éœ€è¦è¿›è¡Œç‰¹åˆ«è°ƒæ•´ï¼Ÿ
3. DQNä¸å…¶ä»–å¼ºåŒ–å­¦ä¹ ç®—æ³•ç›¸æ¯”æœ‰å“ªäº›ä¼˜åŠ¿å’ŒåŠ£åŠ¿ï¼Ÿ
